/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:26:07 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:26:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:26:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:26:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:26:07 visual_prompt]: Training with config:
[09/26 07:26:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:26:07 visual_prompt]: Loading training data...
2023-09-26 07:26:07.428315: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-26 07:26:07.478304: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-26 07:26:08.745290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/26 07:26:10 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:26:12 visual_prompt]: Number of images: 800
[09/26 07:26:12 visual_prompt]: Number of classes: 18 / 18
[09/26 07:26:12 visual_prompt]: Loading validation data...
[09/26 07:26:12 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:26:13 visual_prompt]: Number of images: 200
[09/26 07:26:13 visual_prompt]: Number of classes: 18 / 18
[09/26 07:26:13 visual_prompt]: Constructing models...
[09/26 07:26:15 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 07:26:15 visual_prompt]: tuned percent:0.550
[09/26 07:26:17 visual_prompt]: Device used for model: 0
[09/26 07:26:17 visual_prompt]: Setting up Evaluator...
[09/26 07:26:17 visual_prompt]: Setting up Trainer...
[09/26 07:26:17 visual_prompt]: 	Setting up the optimizer...
[09/26 07:26:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:26:28 visual_prompt]: Epoch 1 / 100: avg data time: 1.94e-01, avg batch time: 0.8107, average train loss: 3.2413
[09/26 07:26:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1669, average loss: 3.1895
[09/26 07:26:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 07:26:30 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 07:26:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:26:36 visual_prompt]: Epoch 2 / 100: avg data time: 5.03e-02, avg batch time: 0.4917, average train loss: 10.1403
[09/26 07:26:38 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1672, average loss: 15.8312
[09/26 07:26:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:26:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:26:44 visual_prompt]: Epoch 3 / 100: avg data time: 3.65e-02, avg batch time: 0.4799, average train loss: 24.1478
[09/26 07:26:45 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1670, average loss: 38.7951
[09/26 07:26:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:26:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:26:52 visual_prompt]: Epoch 4 / 100: avg data time: 4.42e-02, avg batch time: 0.4890, average train loss: 50.5812
[09/26 07:26:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1675, average loss: 58.4431
[09/26 07:26:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 07:26:53 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:27:00 visual_prompt]: Epoch 5 / 100: avg data time: 4.60e-02, avg batch time: 0.4906, average train loss: 97.1740
[09/26 07:27:01 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1683, average loss: 93.2719
[09/26 07:27:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:27:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:27:08 visual_prompt]: Epoch 6 / 100: avg data time: 4.66e-02, avg batch time: 0.4917, average train loss: 142.0106
[09/26 07:27:09 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1680, average loss: 113.9784
[09/26 07:27:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 07:27:09 visual_prompt]: Best epoch 6: best metric: 0.085
[09/26 07:27:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:27:16 visual_prompt]: Epoch 7 / 100: avg data time: 5.04e-02, avg batch time: 0.4952, average train loss: 154.4392
[09/26 07:27:18 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1684, average loss: 138.9259
[09/26 07:27:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 07:27:18 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:27:24 visual_prompt]: Epoch 8 / 100: avg data time: 4.45e-02, avg batch time: 0.4913, average train loss: 158.5583
[09/26 07:27:26 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1684, average loss: 137.6465
[09/26 07:27:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 07:27:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:27:32 visual_prompt]: Epoch 9 / 100: avg data time: 3.94e-02, avg batch time: 0.4864, average train loss: 140.1060
[09/26 07:27:34 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1684, average loss: 162.5158
[09/26 07:27:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 07:27:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:27:40 visual_prompt]: Epoch 10 / 100: avg data time: 5.19e-02, avg batch time: 0.4991, average train loss: 175.2600
[09/26 07:27:42 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1687, average loss: 137.0521
[09/26 07:27:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 07:27:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:27:48 visual_prompt]: Epoch 11 / 100: avg data time: 4.49e-02, avg batch time: 0.4925, average train loss: 183.6101
[09/26 07:27:50 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1688, average loss: 237.2846
[09/26 07:27:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 07:27:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:27:56 visual_prompt]: Epoch 12 / 100: avg data time: 3.76e-02, avg batch time: 0.4858, average train loss: 243.6309
[09/26 07:27:58 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1689, average loss: 227.8591
[09/26 07:27:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:27:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:28:04 visual_prompt]: Epoch 13 / 100: avg data time: 4.76e-02, avg batch time: 0.4963, average train loss: 233.8875
[09/26 07:28:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1689, average loss: 270.1682
[09/26 07:28:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 07:28:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:28:12 visual_prompt]: Epoch 14 / 100: avg data time: 4.45e-02, avg batch time: 0.4923, average train loss: 256.3796
[09/26 07:28:14 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1688, average loss: 237.2491
[09/26 07:28:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 07:28:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:28:20 visual_prompt]: Epoch 15 / 100: avg data time: 4.13e-02, avg batch time: 0.4900, average train loss: 271.9680
[09/26 07:28:22 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1692, average loss: 322.7666
[09/26 07:28:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 07:28:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:28:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.28e-02, avg batch time: 0.5005, average train loss: 296.9629
[09/26 07:28:30 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1688, average loss: 308.4120
[09/26 07:28:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 07:28:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:28:37 visual_prompt]: Epoch 17 / 100: avg data time: 4.89e-02, avg batch time: 0.4969, average train loss: 298.6223
[09/26 07:28:38 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1688, average loss: 181.0928
[09/26 07:28:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 07:28:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:28:45 visual_prompt]: Epoch 18 / 100: avg data time: 4.51e-02, avg batch time: 0.4940, average train loss: 268.0611
[09/26 07:28:46 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1691, average loss: 266.4896
[09/26 07:28:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:28:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:28:53 visual_prompt]: Epoch 19 / 100: avg data time: 5.39e-02, avg batch time: 0.5018, average train loss: 234.3563
[09/26 07:28:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1690, average loss: 233.1636
[09/26 07:28:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 07:28:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:29:01 visual_prompt]: Epoch 20 / 100: avg data time: 4.71e-02, avg batch time: 0.4962, average train loss: 232.1899
[09/26 07:29:02 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1696, average loss: 281.1877
[09/26 07:29:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 07:29:02 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:29:09 visual_prompt]: Epoch 21 / 100: avg data time: 4.16e-02, avg batch time: 0.4916, average train loss: 215.1889
[09/26 07:29:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1697, average loss: 227.1065
[09/26 07:29:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 07:29:10 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:29:17 visual_prompt]: Epoch 22 / 100: avg data time: 4.87e-02, avg batch time: 0.4968, average train loss: 233.7589
[09/26 07:29:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1691, average loss: 259.3752
[09/26 07:29:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 07:29:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:29:25 visual_prompt]: Epoch 23 / 100: avg data time: 5.82e-02, avg batch time: 0.5059, average train loss: 256.5013
[09/26 07:29:27 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1694, average loss: 221.4237
[09/26 07:29:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.00	
[09/26 07:29:27 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:29:33 visual_prompt]: Epoch 24 / 100: avg data time: 5.43e-02, avg batch time: 0.5031, average train loss: 236.6112
[09/26 07:29:35 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1694, average loss: 164.5719
[09/26 07:29:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 23.50	
[09/26 07:29:35 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:29:42 visual_prompt]: Epoch 25 / 100: avg data time: 4.88e-02, avg batch time: 0.4977, average train loss: 190.2114
[09/26 07:29:43 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1696, average loss: 168.4654
[09/26 07:29:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 07:29:43 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:29:50 visual_prompt]: Epoch 26 / 100: avg data time: 4.04e-02, avg batch time: 0.4931, average train loss: 177.5247
[09/26 07:29:51 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1693, average loss: 175.9463
[09/26 07:29:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 07:29:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:29:58 visual_prompt]: Epoch 27 / 100: avg data time: 4.76e-02, avg batch time: 0.4974, average train loss: 197.4419
[09/26 07:29:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1689, average loss: 199.3295
[09/26 07:29:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:29:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:30:06 visual_prompt]: Epoch 28 / 100: avg data time: 5.43e-02, avg batch time: 0.5026, average train loss: 210.4279
[09/26 07:30:07 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1691, average loss: 229.7309
[09/26 07:30:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 07:30:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:30:14 visual_prompt]: Epoch 29 / 100: avg data time: 5.18e-02, avg batch time: 0.5003, average train loss: 206.9153
[09/26 07:30:15 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1690, average loss: 243.1865
[09/26 07:30:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:30:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:30:22 visual_prompt]: Epoch 30 / 100: avg data time: 5.99e-02, avg batch time: 0.5091, average train loss: 221.9772
[09/26 07:30:24 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1693, average loss: 170.6088
[09/26 07:30:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 07:30:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:30:30 visual_prompt]: Epoch 31 / 100: avg data time: 5.15e-02, avg batch time: 0.5009, average train loss: 188.2538
[09/26 07:30:32 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1694, average loss: 160.2075
[09/26 07:30:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 07:30:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:30:39 visual_prompt]: Epoch 32 / 100: avg data time: 4.69e-02, avg batch time: 0.4960, average train loss: 228.5947
[09/26 07:30:40 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1694, average loss: 179.5442
[09/26 07:30:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 07:30:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:30:47 visual_prompt]: Epoch 33 / 100: avg data time: 4.34e-02, avg batch time: 0.4935, average train loss: 220.4296
[09/26 07:30:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1694, average loss: 171.9370
[09/26 07:30:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 07:30:48 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:30:55 visual_prompt]: Epoch 34 / 100: avg data time: 5.33e-02, avg batch time: 0.5023, average train loss: 216.1122
[09/26 07:30:56 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1692, average loss: 217.4470
[09/26 07:30:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 07:30:56 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:31:03 visual_prompt]: Epoch 35 / 100: avg data time: 5.28e-02, avg batch time: 0.5016, average train loss: 229.2761
[09/26 07:31:04 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1693, average loss: 163.9070
[09/26 07:31:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 07:31:04 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:31:11 visual_prompt]: Epoch 36 / 100: avg data time: 5.82e-02, avg batch time: 0.5066, average train loss: 205.3114
[09/26 07:31:13 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1696, average loss: 169.3332
[09/26 07:31:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 07:31:13 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:31:19 visual_prompt]: Epoch 37 / 100: avg data time: 5.27e-02, avg batch time: 0.5011, average train loss: 179.2147
[09/26 07:31:21 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1695, average loss: 170.7799
[09/26 07:31:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 07:31:21 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:31:27 visual_prompt]: Epoch 38 / 100: avg data time: 5.05e-02, avg batch time: 0.4995, average train loss: 190.6779
[09/26 07:31:29 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1696, average loss: 160.2309
[09/26 07:31:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:31:29 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:31:36 visual_prompt]: Epoch 39 / 100: avg data time: 5.11e-02, avg batch time: 0.4999, average train loss: 172.9052
[09/26 07:31:37 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1694, average loss: 137.3974
[09/26 07:31:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.50	
[09/26 07:31:37 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:31:44 visual_prompt]: Epoch 40 / 100: avg data time: 5.27e-02, avg batch time: 0.5022, average train loss: 161.1462
[09/26 07:31:45 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1691, average loss: 137.6787
[09/26 07:31:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:31:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:31:52 visual_prompt]: Epoch 41 / 100: avg data time: 5.40e-02, avg batch time: 0.5023, average train loss: 181.5328
[09/26 07:31:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1698, average loss: 142.6965
[09/26 07:31:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 07:31:53 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:32:00 visual_prompt]: Epoch 42 / 100: avg data time: 5.60e-02, avg batch time: 0.5053, average train loss: 191.9914
[09/26 07:32:02 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1696, average loss: 234.6299
[09/26 07:32:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 07:32:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:32:08 visual_prompt]: Epoch 43 / 100: avg data time: 5.63e-02, avg batch time: 0.5049, average train loss: 200.8420
[09/26 07:32:10 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1699, average loss: 229.7753
[09/26 07:32:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:32:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:32:17 visual_prompt]: Epoch 44 / 100: avg data time: 5.63e-02, avg batch time: 0.5052, average train loss: 218.9425
[09/26 07:32:18 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1692, average loss: 161.0132
[09/26 07:32:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:32:18 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:32:25 visual_prompt]: Epoch 45 / 100: avg data time: 5.51e-02, avg batch time: 0.5031, average train loss: 152.0819
[09/26 07:32:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 109.8193
[09/26 07:32:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 07:32:26 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 07:32:33 visual_prompt]: Epoch 46 / 100: avg data time: 4.15e-02, avg batch time: 0.4911, average train loss: 154.7614
[09/26 07:32:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1695, average loss: 136.1533
[09/26 07:32:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 07:32:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 07:32:41 visual_prompt]: Epoch 47 / 100: avg data time: 6.06e-02, avg batch time: 0.5091, average train loss: 170.7501
[09/26 07:32:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1697, average loss: 158.2180
[09/26 07:32:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 07:32:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 07:32:49 visual_prompt]: Epoch 48 / 100: avg data time: 5.45e-02, avg batch time: 0.5036, average train loss: 129.4360
[09/26 07:32:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1698, average loss: 182.4200
[09/26 07:32:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 07:32:51 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 07:32:57 visual_prompt]: Epoch 49 / 100: avg data time: 5.67e-02, avg batch time: 0.5048, average train loss: 144.0938
[09/26 07:32:59 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1691, average loss: 183.4312
[09/26 07:32:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 07:32:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 07:33:06 visual_prompt]: Epoch 50 / 100: avg data time: 5.94e-02, avg batch time: 0.5072, average train loss: 150.2834
[09/26 07:33:07 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1691, average loss: 118.7714
[09/26 07:33:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 07:33:07 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 07:33:14 visual_prompt]: Epoch 51 / 100: avg data time: 6.10e-02, avg batch time: 0.5093, average train loss: 134.1574
[09/26 07:33:15 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1697, average loss: 119.3932
[09/26 07:33:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 07:33:15 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 07:33:22 visual_prompt]: Epoch 52 / 100: avg data time: 5.13e-02, avg batch time: 0.5008, average train loss: 139.0945
[09/26 07:33:24 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1692, average loss: 157.2305
[09/26 07:33:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 22.00	
[09/26 07:33:24 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 07:33:30 visual_prompt]: Epoch 53 / 100: avg data time: 5.09e-02, avg batch time: 0.4991, average train loss: 146.5036
[09/26 07:33:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1695, average loss: 131.9924
[09/26 07:33:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.00	
[09/26 07:33:32 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 07:33:39 visual_prompt]: Epoch 54 / 100: avg data time: 6.20e-02, avg batch time: 0.5107, average train loss: 184.9606
[09/26 07:33:40 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1691, average loss: 157.2885
[09/26 07:33:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 07:33:40 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 07:33:47 visual_prompt]: Epoch 55 / 100: avg data time: 5.61e-02, avg batch time: 0.5046, average train loss: 143.7963
[09/26 07:33:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1693, average loss: 141.7908
[09/26 07:33:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 07:33:48 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 07:33:55 visual_prompt]: Epoch 56 / 100: avg data time: 5.30e-02, avg batch time: 0.5028, average train loss: 135.8479
[09/26 07:33:57 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1700, average loss: 102.6609
[09/26 07:33:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 07:33:57 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 07:34:03 visual_prompt]: Epoch 57 / 100: avg data time: 5.39e-02, avg batch time: 0.5026, average train loss: 117.4217
[09/26 07:34:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1694, average loss: 140.0477
[09/26 07:34:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 35.50	
[09/26 07:34:05 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 07:34:12 visual_prompt]: Epoch 58 / 100: avg data time: 5.40e-02, avg batch time: 0.5030, average train loss: 109.4217
[09/26 07:34:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1699, average loss: 94.9234
[09/26 07:34:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 07:34:13 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 07:34:20 visual_prompt]: Epoch 59 / 100: avg data time: 5.24e-02, avg batch time: 0.5020, average train loss: 94.1642
[09/26 07:34:21 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1697, average loss: 107.1897
[09/26 07:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 07:34:21 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 07:34:28 visual_prompt]: Epoch 60 / 100: avg data time: 5.17e-02, avg batch time: 0.5002, average train loss: 106.6066
[09/26 07:34:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 145.5322
[09/26 07:34:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 07:34:29 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 07:34:36 visual_prompt]: Epoch 61 / 100: avg data time: 5.63e-02, avg batch time: 0.5050, average train loss: 111.4401
[09/26 07:34:37 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1694, average loss: 137.5599
[09/26 07:34:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 07:34:37 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 07:34:44 visual_prompt]: Epoch 62 / 100: avg data time: 5.71e-02, avg batch time: 0.5059, average train loss: 107.1372
[09/26 07:34:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1695, average loss: 57.9348
[09/26 07:34:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 07:34:46 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 07:34:52 visual_prompt]: Epoch 63 / 100: avg data time: 4.50e-02, avg batch time: 0.4949, average train loss: 83.7974
[09/26 07:34:54 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1690, average loss: 67.8488
[09/26 07:34:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:34:54 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 07:35:01 visual_prompt]: Epoch 64 / 100: avg data time: 5.31e-02, avg batch time: 0.5015, average train loss: 84.0523
[09/26 07:35:02 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1693, average loss: 44.2004
[09/26 07:35:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 07:35:02 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 07:35:09 visual_prompt]: Epoch 65 / 100: avg data time: 5.87e-02, avg batch time: 0.5080, average train loss: 62.8098
[09/26 07:35:10 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1692, average loss: 57.9606
[09/26 07:35:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 07:35:10 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 07:35:17 visual_prompt]: Epoch 66 / 100: avg data time: 4.78e-02, avg batch time: 0.4965, average train loss: 61.3480
[09/26 07:35:18 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1693, average loss: 53.7300
[09/26 07:35:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 07:35:18 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 07:35:25 visual_prompt]: Epoch 67 / 100: avg data time: 5.41e-02, avg batch time: 0.5031, average train loss: 69.0311
[09/26 07:35:27 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1700, average loss: 69.1236
[09/26 07:35:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 07:35:27 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:35:33 visual_prompt]: Epoch 68 / 100: avg data time: 4.54e-02, avg batch time: 0.4953, average train loss: 50.6774
[09/26 07:35:35 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1690, average loss: 56.9914
[09/26 07:35:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.50	
[09/26 07:35:35 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:35:42 visual_prompt]: Epoch 69 / 100: avg data time: 5.31e-02, avg batch time: 0.5030, average train loss: 57.5432
[09/26 07:35:43 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1693, average loss: 48.0823
[09/26 07:35:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 07:35:43 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:35:49 visual_prompt]: Epoch 70 / 100: avg data time: 4.05e-02, avg batch time: 0.4898, average train loss: 57.0965
[09/26 07:35:51 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1690, average loss: 58.4654
[09/26 07:35:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:35:51 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:35:58 visual_prompt]: Epoch 71 / 100: avg data time: 5.91e-02, avg batch time: 0.5075, average train loss: 57.8425
[09/26 07:35:59 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1696, average loss: 43.2864
[09/26 07:35:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 07:35:59 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:36:06 visual_prompt]: Epoch 72 / 100: avg data time: 4.47e-02, avg batch time: 0.4936, average train loss: 50.9950
[09/26 07:36:07 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1693, average loss: 48.9629
[09/26 07:36:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 07:36:07 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:36:14 visual_prompt]: Epoch 73 / 100: avg data time: 4.35e-02, avg batch time: 0.4928, average train loss: 49.2181
[09/26 07:36:15 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1692, average loss: 57.9717
[09/26 07:36:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 07:36:15 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:36:22 visual_prompt]: Epoch 74 / 100: avg data time: 4.34e-02, avg batch time: 0.4948, average train loss: 38.9925
[09/26 07:36:23 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1694, average loss: 43.3057
[09/26 07:36:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 33.00	
[09/26 07:36:23 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:36:30 visual_prompt]: Epoch 75 / 100: avg data time: 4.78e-02, avg batch time: 0.4966, average train loss: 54.1328
[09/26 07:36:31 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1692, average loss: 88.9914
[09/26 07:36:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 07:36:31 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:36:38 visual_prompt]: Epoch 76 / 100: avg data time: 5.16e-02, avg batch time: 0.5007, average train loss: 42.1149
[09/26 07:36:39 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1697, average loss: 28.4895
[09/26 07:36:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 07:36:39 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:36:46 visual_prompt]: Epoch 77 / 100: avg data time: 4.65e-02, avg batch time: 0.4973, average train loss: 43.1897
[09/26 07:36:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1692, average loss: 45.2946
[09/26 07:36:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:36:48 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:36:54 visual_prompt]: Epoch 78 / 100: avg data time: 4.38e-02, avg batch time: 0.4933, average train loss: 37.4577
[09/26 07:36:56 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1691, average loss: 30.6577
[09/26 07:36:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 25.50	
[09/26 07:36:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:37:02 visual_prompt]: Epoch 79 / 100: avg data time: 4.31e-02, avg batch time: 0.4922, average train loss: 28.6069
[09/26 07:37:04 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1692, average loss: 36.5757
[09/26 07:37:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.50	
[09/26 07:37:04 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:37:10 visual_prompt]: Epoch 80 / 100: avg data time: 4.57e-02, avg batch time: 0.4964, average train loss: 24.4468
[09/26 07:37:12 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1696, average loss: 22.1460
[09/26 07:37:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 07:37:12 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:37:18 visual_prompt]: Epoch 81 / 100: avg data time: 4.56e-02, avg batch time: 0.4957, average train loss: 27.8902
[09/26 07:37:20 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1696, average loss: 30.8596
[09/26 07:37:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.50	
[09/26 07:37:20 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:37:26 visual_prompt]: Epoch 82 / 100: avg data time: 5.03e-02, avg batch time: 0.5012, average train loss: 27.1278
[09/26 07:37:28 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1696, average loss: 36.0434
[09/26 07:37:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 07:37:28 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:37:34 visual_prompt]: Epoch 83 / 100: avg data time: 3.92e-02, avg batch time: 0.4887, average train loss: 24.5894
[09/26 07:37:36 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1694, average loss: 15.8802
[09/26 07:37:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 07:37:36 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:37:43 visual_prompt]: Epoch 84 / 100: avg data time: 4.10e-02, avg batch time: 0.4928, average train loss: 19.3182
[09/26 07:37:44 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1694, average loss: 18.6145
[09/26 07:37:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:37:44 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:37:51 visual_prompt]: Epoch 85 / 100: avg data time: 5.15e-02, avg batch time: 0.5019, average train loss: 11.5751
[09/26 07:37:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1696, average loss: 6.3925
[09/26 07:37:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 07:37:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:37:59 visual_prompt]: Epoch 86 / 100: avg data time: 4.05e-02, avg batch time: 0.4902, average train loss: 8.8379
[09/26 07:38:00 visual_prompt]: Inference (val):avg data time: 1.62e-05, avg batch time: 0.1695, average loss: 16.2340
[09/26 07:38:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 07:38:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:38:07 visual_prompt]: Epoch 87 / 100: avg data time: 4.71e-02, avg batch time: 0.4973, average train loss: 9.3586
[09/26 07:38:08 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1699, average loss: 13.1355
[09/26 07:38:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 28.00	
[09/26 07:38:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:38:15 visual_prompt]: Epoch 88 / 100: avg data time: 4.67e-02, avg batch time: 0.4976, average train loss: 7.4161
[09/26 07:38:16 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1692, average loss: 9.9685
[09/26 07:38:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:38:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:38:23 visual_prompt]: Epoch 89 / 100: avg data time: 5.56e-02, avg batch time: 0.5055, average train loss: 9.5135
[09/26 07:38:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1696, average loss: 8.6400
[09/26 07:38:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 07:38:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:38:32 visual_prompt]: Epoch 90 / 100: avg data time: 5.48e-02, avg batch time: 0.5039, average train loss: 5.5662
[09/26 07:38:33 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1693, average loss: 3.4547
[09/26 07:38:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 07:38:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:38:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.63e-02, avg batch time: 0.5053, average train loss: 3.5764
[09/26 07:38:41 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1696, average loss: 3.3739
[09/26 07:38:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:38:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:38:48 visual_prompt]: Epoch 92 / 100: avg data time: 5.72e-02, avg batch time: 0.5071, average train loss: 3.2075
[09/26 07:38:49 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1693, average loss: 3.0152
[09/26 07:38:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 07:38:49 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:38:56 visual_prompt]: Epoch 93 / 100: avg data time: 5.48e-02, avg batch time: 0.5033, average train loss: 3.1176
[09/26 07:38:58 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1694, average loss: 2.9772
[09/26 07:38:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 07:38:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:39:04 visual_prompt]: Epoch 94 / 100: avg data time: 5.00e-02, avg batch time: 0.4987, average train loss: 2.9655
[09/26 07:39:06 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1700, average loss: 3.0729
[09/26 07:39:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:39:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:39:12 visual_prompt]: Epoch 95 / 100: avg data time: 4.84e-02, avg batch time: 0.4983, average train loss: 2.9603
[09/26 07:39:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1695, average loss: 3.0259
[09/26 07:39:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 07:39:14 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:39:21 visual_prompt]: Epoch 96 / 100: avg data time: 5.77e-02, avg batch time: 0.5073, average train loss: 2.9289
[09/26 07:39:22 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1699, average loss: 2.9150
[09/26 07:39:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 07:39:22 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:39:29 visual_prompt]: Epoch 97 / 100: avg data time: 5.67e-02, avg batch time: 0.5052, average train loss: 2.9178
[09/26 07:39:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1696, average loss: 2.9147
[09/26 07:39:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:39:30 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:39:37 visual_prompt]: Epoch 98 / 100: avg data time: 5.32e-02, avg batch time: 0.5017, average train loss: 2.8989
[09/26 07:39:39 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1693, average loss: 2.9080
[09/26 07:39:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.50	
[09/26 07:39:39 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:39:45 visual_prompt]: Epoch 99 / 100: avg data time: 5.22e-02, avg batch time: 0.5008, average train loss: 2.8877
[09/26 07:39:47 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1698, average loss: 2.9106
[09/26 07:39:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 07:39:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:39:53 visual_prompt]: Epoch 100 / 100: avg data time: 5.12e-02, avg batch time: 0.5009, average train loss: 2.8821
[09/26 07:39:55 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1697, average loss: 2.9104
[09/26 07:39:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 07:39:55 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:39:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:39:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:39:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:39:55 visual_prompt]: Training with config:
[09/26 07:39:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:39:55 visual_prompt]: Loading training data...
[09/26 07:39:55 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:39:56 visual_prompt]: Number of images: 800
[09/26 07:39:56 visual_prompt]: Number of classes: 18 / 18
[09/26 07:39:56 visual_prompt]: Loading validation data...
[09/26 07:39:56 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:39:56 visual_prompt]: Number of images: 200
[09/26 07:39:56 visual_prompt]: Number of classes: 18 / 18
[09/26 07:39:56 visual_prompt]: Constructing models...
[09/26 07:39:59 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 07:39:59 visual_prompt]: tuned percent:0.550
[09/26 07:39:59 visual_prompt]: Device used for model: 0
[09/26 07:39:59 visual_prompt]: Setting up Evaluator...
[09/26 07:39:59 visual_prompt]: Setting up Trainer...
[09/26 07:39:59 visual_prompt]: 	Setting up the optimizer...
[09/26 07:39:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:40:06 visual_prompt]: Epoch 1 / 100: avg data time: 6.11e-02, avg batch time: 0.5087, average train loss: 3.2539
[09/26 07:40:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1686, average loss: 3.1895
[09/26 07:40:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 07:40:08 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 07:40:08 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:40:14 visual_prompt]: Epoch 2 / 100: avg data time: 4.76e-02, avg batch time: 0.4951, average train loss: 11.0570
[09/26 07:40:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 16.4988
[09/26 07:40:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:40:16 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:40:22 visual_prompt]: Epoch 3 / 100: avg data time: 4.30e-02, avg batch time: 0.4914, average train loss: 43.9891
[09/26 07:40:24 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1689, average loss: 68.4155
[09/26 07:40:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 07:40:24 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 07:40:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:40:31 visual_prompt]: Epoch 4 / 100: avg data time: 5.72e-02, avg batch time: 0.5048, average train loss: 95.2470
[09/26 07:40:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1688, average loss: 128.9048
[09/26 07:40:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:40:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:40:39 visual_prompt]: Epoch 5 / 100: avg data time: 4.20e-02, avg batch time: 0.4897, average train loss: 94.4608
[09/26 07:40:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 110.8901
[09/26 07:40:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 35.50	
[09/26 07:40:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:40:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.14e-02, avg batch time: 0.5000, average train loss: 128.4500
[09/26 07:40:48 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1686, average loss: 132.2294
[09/26 07:40:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 07:40:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:40:55 visual_prompt]: Epoch 7 / 100: avg data time: 4.06e-02, avg batch time: 0.4924, average train loss: 164.1039
[09/26 07:40:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1686, average loss: 114.8834
[09/26 07:40:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 07:40:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:41:03 visual_prompt]: Epoch 8 / 100: avg data time: 5.63e-02, avg batch time: 0.5063, average train loss: 177.0740
[09/26 07:41:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 145.1670
[09/26 07:41:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 07:41:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:41:11 visual_prompt]: Epoch 9 / 100: avg data time: 4.63e-02, avg batch time: 0.4947, average train loss: 160.4245
[09/26 07:41:13 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1689, average loss: 248.0824
[09/26 07:41:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.00	
[09/26 07:41:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:41:20 visual_prompt]: Epoch 10 / 100: avg data time: 4.14e-02, avg batch time: 0.4905, average train loss: 286.4791
[09/26 07:41:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 140.1879
[09/26 07:41:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 07:41:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:41:28 visual_prompt]: Epoch 11 / 100: avg data time: 5.57e-02, avg batch time: 0.5048, average train loss: 234.8935
[09/26 07:41:29 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1691, average loss: 190.5883
[09/26 07:41:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:41:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:41:36 visual_prompt]: Epoch 12 / 100: avg data time: 5.37e-02, avg batch time: 0.5024, average train loss: 254.0432
[09/26 07:41:38 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1690, average loss: 211.2707
[09/26 07:41:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 07:41:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:41:44 visual_prompt]: Epoch 13 / 100: avg data time: 4.27e-02, avg batch time: 0.4902, average train loss: 285.1706
[09/26 07:41:46 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1692, average loss: 329.6364
[09/26 07:41:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 07:41:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:41:53 visual_prompt]: Epoch 14 / 100: avg data time: 5.91e-02, avg batch time: 0.5068, average train loss: 315.1893
[09/26 07:41:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1690, average loss: 318.3512
[09/26 07:41:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 07:41:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:42:01 visual_prompt]: Epoch 15 / 100: avg data time: 5.46e-02, avg batch time: 0.5024, average train loss: 282.7568
[09/26 07:42:02 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 285.1299
[09/26 07:42:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 07:42:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:42:09 visual_prompt]: Epoch 16 / 100: avg data time: 5.38e-02, avg batch time: 0.5017, average train loss: 237.3917
[09/26 07:42:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1687, average loss: 274.5186
[09/26 07:42:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 07:42:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:42:17 visual_prompt]: Epoch 17 / 100: avg data time: 4.98e-02, avg batch time: 0.4983, average train loss: 221.3873
[09/26 07:42:19 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1691, average loss: 221.6043
[09/26 07:42:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 07:42:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:42:26 visual_prompt]: Epoch 18 / 100: avg data time: 5.90e-02, avg batch time: 0.5074, average train loss: 238.0350
[09/26 07:42:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 308.7835
[09/26 07:42:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 07:42:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:42:34 visual_prompt]: Epoch 19 / 100: avg data time: 5.38e-02, avg batch time: 0.5029, average train loss: 247.1609
[09/26 07:42:35 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 162.5892
[09/26 07:42:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 07:42:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:42:42 visual_prompt]: Epoch 20 / 100: avg data time: 6.02e-02, avg batch time: 0.5095, average train loss: 215.0944
[09/26 07:42:44 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1689, average loss: 460.8184
[09/26 07:42:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 07:42:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:42:51 visual_prompt]: Epoch 21 / 100: avg data time: 5.67e-02, avg batch time: 0.5054, average train loss: 354.7966
[09/26 07:42:52 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1694, average loss: 254.4407
[09/26 07:42:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 07:42:52 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:42:59 visual_prompt]: Epoch 22 / 100: avg data time: 4.20e-02, avg batch time: 0.4919, average train loss: 358.0917
[09/26 07:43:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1694, average loss: 383.1724
[09/26 07:43:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 07:43:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:43:07 visual_prompt]: Epoch 23 / 100: avg data time: 4.42e-02, avg batch time: 0.4920, average train loss: 307.2490
[09/26 07:43:09 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1690, average loss: 284.7725
[09/26 07:43:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 07:43:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:43:15 visual_prompt]: Epoch 24 / 100: avg data time: 5.93e-02, avg batch time: 0.5080, average train loss: 369.4934
[09/26 07:43:17 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1689, average loss: 258.3035
[09/26 07:43:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 07:43:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:43:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.49e-02, avg batch time: 0.5026, average train loss: 217.8941
[09/26 07:43:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1687, average loss: 289.2608
[09/26 07:43:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 07:43:25 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:43:32 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e-02, avg batch time: 0.4984, average train loss: 278.3058
[09/26 07:43:33 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1692, average loss: 281.6324
[09/26 07:43:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 07:43:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:43:40 visual_prompt]: Epoch 27 / 100: avg data time: 4.21e-02, avg batch time: 0.4939, average train loss: 285.5634
[09/26 07:43:42 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1692, average loss: 236.9602
[09/26 07:43:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 07:43:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:43:48 visual_prompt]: Epoch 28 / 100: avg data time: 4.82e-02, avg batch time: 0.4965, average train loss: 211.8008
[09/26 07:43:50 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1689, average loss: 259.2845
[09/26 07:43:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 07:43:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:43:57 visual_prompt]: Epoch 29 / 100: avg data time: 5.80e-02, avg batch time: 0.5065, average train loss: 228.3064
[09/26 07:43:58 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1688, average loss: 226.9480
[09/26 07:43:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 07:43:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:44:05 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e-02, avg batch time: 0.5051, average train loss: 235.5189
[09/26 07:44:06 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1690, average loss: 243.8979
[09/26 07:44:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 23.00	
[09/26 07:44:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:44:13 visual_prompt]: Epoch 31 / 100: avg data time: 5.05e-02, avg batch time: 0.4986, average train loss: 232.5960
[09/26 07:44:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 440.1835
[09/26 07:44:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 07:44:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:44:22 visual_prompt]: Epoch 32 / 100: avg data time: 5.44e-02, avg batch time: 0.5032, average train loss: 222.1722
[09/26 07:44:23 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1690, average loss: 223.2169
[09/26 07:44:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 07:44:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:44:30 visual_prompt]: Epoch 33 / 100: avg data time: 5.27e-02, avg batch time: 0.5007, average train loss: 247.6930
[09/26 07:44:31 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1693, average loss: 293.8622
[09/26 07:44:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 07:44:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:44:38 visual_prompt]: Epoch 34 / 100: avg data time: 5.63e-02, avg batch time: 0.5050, average train loss: 222.6386
[09/26 07:44:40 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1692, average loss: 236.9787
[09/26 07:44:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:44:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:44:46 visual_prompt]: Epoch 35 / 100: avg data time: 4.74e-02, avg batch time: 0.4978, average train loss: 189.0795
[09/26 07:44:48 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1692, average loss: 162.2783
[09/26 07:44:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 07:44:48 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:44:55 visual_prompt]: Epoch 36 / 100: avg data time: 5.59e-02, avg batch time: 0.5034, average train loss: 216.7000
[09/26 07:44:56 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1694, average loss: 224.4331
[09/26 07:44:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.50	
[09/26 07:44:56 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:45:03 visual_prompt]: Epoch 37 / 100: avg data time: 4.89e-02, avg batch time: 0.4979, average train loss: 229.5225
[09/26 07:45:04 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1691, average loss: 161.0530
[09/26 07:45:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 07:45:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:45:11 visual_prompt]: Epoch 38 / 100: avg data time: 5.70e-02, avg batch time: 0.5052, average train loss: 246.4225
[09/26 07:45:13 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 199.1659
[09/26 07:45:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 07:45:13 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:45:19 visual_prompt]: Epoch 39 / 100: avg data time: 4.67e-02, avg batch time: 0.4961, average train loss: 199.3273
[09/26 07:45:21 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1692, average loss: 143.1533
[09/26 07:45:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 07:45:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:45:28 visual_prompt]: Epoch 40 / 100: avg data time: 4.89e-02, avg batch time: 0.4988, average train loss: 160.4758
[09/26 07:45:29 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1694, average loss: 237.7197
[09/26 07:45:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 07:45:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:45:36 visual_prompt]: Epoch 41 / 100: avg data time: 4.42e-02, avg batch time: 0.4919, average train loss: 223.5368
[09/26 07:45:37 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1695, average loss: 196.1378
[09/26 07:45:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 07:45:37 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:45:44 visual_prompt]: Epoch 42 / 100: avg data time: 5.91e-02, avg batch time: 0.5075, average train loss: 194.7064
[09/26 07:45:46 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1698, average loss: 140.7248
[09/26 07:45:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 07:45:46 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:45:52 visual_prompt]: Epoch 43 / 100: avg data time: 5.66e-02, avg batch time: 0.5054, average train loss: 221.5375
[09/26 07:45:54 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1688, average loss: 234.9926
[09/26 07:45:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:45:54 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:46:01 visual_prompt]: Epoch 44 / 100: avg data time: 4.19e-02, avg batch time: 0.4919, average train loss: 151.4199
[09/26 07:46:02 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1701, average loss: 204.2783
[09/26 07:46:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 07:46:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:46:09 visual_prompt]: Epoch 45 / 100: avg data time: 4.07e-02, avg batch time: 0.4912, average train loss: 146.6402
[09/26 07:46:10 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1688, average loss: 213.1696
[09/26 07:46:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 07:46:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 07:46:17 visual_prompt]: Epoch 46 / 100: avg data time: 4.21e-02, avg batch time: 0.4931, average train loss: 223.6123
[09/26 07:46:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 229.4953
[09/26 07:46:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 07:46:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 07:46:25 visual_prompt]: Epoch 47 / 100: avg data time: 4.85e-02, avg batch time: 0.4975, average train loss: 203.0714
[09/26 07:46:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 159.1670
[09/26 07:46:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 07:46:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 07:46:34 visual_prompt]: Epoch 48 / 100: avg data time: 5.31e-02, avg batch time: 0.5026, average train loss: 154.4460
[09/26 07:46:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1687, average loss: 143.8186
[09/26 07:46:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 07:46:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 07:46:42 visual_prompt]: Epoch 49 / 100: avg data time: 5.67e-02, avg batch time: 0.5045, average train loss: 173.7143
[09/26 07:46:43 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1692, average loss: 85.8095
[09/26 07:46:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 07:46:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 07:46:50 visual_prompt]: Epoch 50 / 100: avg data time: 4.34e-02, avg batch time: 0.4912, average train loss: 146.8447
[09/26 07:46:51 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 166.8888
[09/26 07:46:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:46:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 07:46:58 visual_prompt]: Epoch 51 / 100: avg data time: 4.78e-02, avg batch time: 0.4970, average train loss: 175.5179
[09/26 07:47:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 164.5809
[09/26 07:47:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.50	
[09/26 07:47:00 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 07:47:06 visual_prompt]: Epoch 52 / 100: avg data time: 4.96e-02, avg batch time: 0.4982, average train loss: 198.4491
[09/26 07:47:08 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1687, average loss: 107.9726
[09/26 07:47:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 07:47:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 07:47:14 visual_prompt]: Epoch 53 / 100: avg data time: 3.98e-02, avg batch time: 0.4894, average train loss: 148.0834
[09/26 07:47:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1691, average loss: 164.9555
[09/26 07:47:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 07:47:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 07:47:23 visual_prompt]: Epoch 54 / 100: avg data time: 4.65e-02, avg batch time: 0.4951, average train loss: 160.2127
[09/26 07:47:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 149.7269
[09/26 07:47:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 07:47:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 07:47:31 visual_prompt]: Epoch 55 / 100: avg data time: 4.18e-02, avg batch time: 0.4936, average train loss: 128.5670
[09/26 07:47:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1692, average loss: 144.0862
[09/26 07:47:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:47:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 07:47:39 visual_prompt]: Epoch 56 / 100: avg data time: 4.96e-02, avg batch time: 0.4986, average train loss: 143.5900
[09/26 07:47:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1687, average loss: 134.2919
[09/26 07:47:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 07:47:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 07:47:47 visual_prompt]: Epoch 57 / 100: avg data time: 4.12e-02, avg batch time: 0.4892, average train loss: 124.8627
[09/26 07:47:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1692, average loss: 113.5397
[09/26 07:47:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 35.00	
[09/26 07:47:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 07:47:55 visual_prompt]: Epoch 58 / 100: avg data time: 4.22e-02, avg batch time: 0.4935, average train loss: 109.7948
[09/26 07:47:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 160.4785
[09/26 07:47:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 07:47:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 07:48:03 visual_prompt]: Epoch 59 / 100: avg data time: 5.22e-02, avg batch time: 0.5014, average train loss: 139.1154
[09/26 07:48:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 123.8283
[09/26 07:48:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 07:48:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 07:48:12 visual_prompt]: Epoch 60 / 100: avg data time: 4.30e-02, avg batch time: 0.4925, average train loss: 96.2054
[09/26 07:48:13 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1687, average loss: 103.6730
[09/26 07:48:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 07:48:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 07:48:20 visual_prompt]: Epoch 61 / 100: avg data time: 5.47e-02, avg batch time: 0.5043, average train loss: 122.8846
[09/26 07:48:21 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1694, average loss: 111.2479
[09/26 07:48:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 07:48:21 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 07:48:28 visual_prompt]: Epoch 62 / 100: avg data time: 5.62e-02, avg batch time: 0.5059, average train loss: 120.6416
[09/26 07:48:30 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1689, average loss: 89.1924
[09/26 07:48:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 07:48:30 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 07:48:36 visual_prompt]: Epoch 63 / 100: avg data time: 4.66e-02, avg batch time: 0.4980, average train loss: 93.4882
[09/26 07:48:38 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1694, average loss: 86.1958
[09/26 07:48:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 07:48:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 07:48:45 visual_prompt]: Epoch 64 / 100: avg data time: 5.42e-02, avg batch time: 0.5032, average train loss: 116.0233
[09/26 07:48:46 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1689, average loss: 80.5441
[09/26 07:48:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 07:48:46 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 07:48:53 visual_prompt]: Epoch 65 / 100: avg data time: 4.61e-02, avg batch time: 0.4966, average train loss: 100.6514
[09/26 07:48:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1695, average loss: 107.5670
[09/26 07:48:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:48:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 07:49:01 visual_prompt]: Epoch 66 / 100: avg data time: 4.78e-02, avg batch time: 0.4984, average train loss: 106.8439
[09/26 07:49:03 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1693, average loss: 106.3938
[09/26 07:49:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 07:49:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 07:49:10 visual_prompt]: Epoch 67 / 100: avg data time: 5.88e-02, avg batch time: 0.5086, average train loss: 81.0040
[09/26 07:49:11 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1692, average loss: 86.7511
[09/26 07:49:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 07:49:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:49:18 visual_prompt]: Epoch 68 / 100: avg data time: 4.42e-02, avg batch time: 0.4924, average train loss: 116.0798
[09/26 07:49:19 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1696, average loss: 114.2979
[09/26 07:49:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 07:49:19 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:49:26 visual_prompt]: Epoch 69 / 100: avg data time: 5.55e-02, avg batch time: 0.5034, average train loss: 84.9600
[09/26 07:49:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 73.2401
[09/26 07:49:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 07:49:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:49:35 visual_prompt]: Epoch 70 / 100: avg data time: 5.65e-02, avg batch time: 0.5059, average train loss: 72.1952
[09/26 07:49:36 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1696, average loss: 47.8080
[09/26 07:49:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 07:49:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:49:43 visual_prompt]: Epoch 71 / 100: avg data time: 4.17e-02, avg batch time: 0.4920, average train loss: 63.3942
[09/26 07:49:44 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1691, average loss: 61.8118
[09/26 07:49:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 07:49:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:49:51 visual_prompt]: Epoch 72 / 100: avg data time: 4.75e-02, avg batch time: 0.4965, average train loss: 62.2641
[09/26 07:49:52 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1689, average loss: 47.9665
[09/26 07:49:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 07:49:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:49:59 visual_prompt]: Epoch 73 / 100: avg data time: 5.70e-02, avg batch time: 0.5058, average train loss: 77.7771
[09/26 07:50:01 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1699, average loss: 67.0555
[09/26 07:50:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 07:50:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:50:08 visual_prompt]: Epoch 74 / 100: avg data time: 4.28e-02, avg batch time: 0.4931, average train loss: 83.8116
[09/26 07:50:09 visual_prompt]: Inference (val):avg data time: 4.75e-05, avg batch time: 0.1690, average loss: 77.0825
[09/26 07:50:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.00	
[09/26 07:50:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:50:16 visual_prompt]: Epoch 75 / 100: avg data time: 5.38e-02, avg batch time: 0.5028, average train loss: 65.1429
[09/26 07:50:17 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1694, average loss: 40.4843
[09/26 07:50:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 07:50:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:50:24 visual_prompt]: Epoch 76 / 100: avg data time: 5.53e-02, avg batch time: 0.5040, average train loss: 52.3701
[09/26 07:50:26 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1690, average loss: 47.5304
[09/26 07:50:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 07:50:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:50:33 visual_prompt]: Epoch 77 / 100: avg data time: 5.47e-02, avg batch time: 0.5031, average train loss: 37.5438
[09/26 07:50:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 25.8177
[09/26 07:50:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.00	
[09/26 07:50:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:50:41 visual_prompt]: Epoch 78 / 100: avg data time: 5.84e-02, avg batch time: 0.5060, average train loss: 27.5327
[09/26 07:50:42 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1690, average loss: 27.2090
[09/26 07:50:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 07:50:42 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:50:49 visual_prompt]: Epoch 79 / 100: avg data time: 4.28e-02, avg batch time: 0.4926, average train loss: 29.2139
[09/26 07:50:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 21.8641
[09/26 07:50:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 07:50:51 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:50:57 visual_prompt]: Epoch 80 / 100: avg data time: 4.48e-02, avg batch time: 0.4938, average train loss: 23.1498
[09/26 07:50:59 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 21.4477
[09/26 07:50:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 07:50:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:51:06 visual_prompt]: Epoch 81 / 100: avg data time: 5.57e-02, avg batch time: 0.5043, average train loss: 18.8660
[09/26 07:51:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 13.8990
[09/26 07:51:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.50	
[09/26 07:51:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:51:14 visual_prompt]: Epoch 82 / 100: avg data time: 5.67e-02, avg batch time: 0.5056, average train loss: 22.4087
[09/26 07:51:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 26.1329
[09/26 07:51:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 07:51:16 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:51:22 visual_prompt]: Epoch 83 / 100: avg data time: 4.79e-02, avg batch time: 0.4978, average train loss: 17.6336
[09/26 07:51:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1693, average loss: 15.0906
[09/26 07:51:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 34.00	
[09/26 07:51:24 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:51:31 visual_prompt]: Epoch 84 / 100: avg data time: 5.67e-02, avg batch time: 0.5059, average train loss: 15.8726
[09/26 07:51:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 15.9243
[09/26 07:51:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.50	
[09/26 07:51:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:51:39 visual_prompt]: Epoch 85 / 100: avg data time: 5.08e-02, avg batch time: 0.4998, average train loss: 13.9071
[09/26 07:51:40 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 8.8236
[09/26 07:51:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 07:51:40 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:51:47 visual_prompt]: Epoch 86 / 100: avg data time: 4.98e-02, avg batch time: 0.5005, average train loss: 6.7830
[09/26 07:51:49 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 4.4321
[09/26 07:51:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 07:51:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:51:55 visual_prompt]: Epoch 87 / 100: avg data time: 5.75e-02, avg batch time: 0.5081, average train loss: 4.0266
[09/26 07:51:57 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1687, average loss: 3.6350
[09/26 07:51:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 07:51:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:52:04 visual_prompt]: Epoch 88 / 100: avg data time: 4.53e-02, avg batch time: 0.4944, average train loss: 3.4369
[09/26 07:52:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1691, average loss: 3.4018
[09/26 07:52:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 07:52:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:52:12 visual_prompt]: Epoch 89 / 100: avg data time: 5.23e-02, avg batch time: 0.5015, average train loss: 3.2132
[09/26 07:52:13 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1691, average loss: 3.0292
[09/26 07:52:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 07:52:13 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:52:20 visual_prompt]: Epoch 90 / 100: avg data time: 4.72e-02, avg batch time: 0.4976, average train loss: 3.0990
[09/26 07:52:22 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1689, average loss: 3.2646
[09/26 07:52:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 07:52:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:52:28 visual_prompt]: Epoch 91 / 100: avg data time: 4.24e-02, avg batch time: 0.4918, average train loss: 3.0824
[09/26 07:52:30 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 3.1423
[09/26 07:52:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 07:52:30 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:52:36 visual_prompt]: Epoch 92 / 100: avg data time: 5.46e-02, avg batch time: 0.5031, average train loss: 2.9861
[09/26 07:52:38 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 2.9901
[09/26 07:52:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 07:52:38 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:52:45 visual_prompt]: Epoch 93 / 100: avg data time: 4.47e-02, avg batch time: 0.4944, average train loss: 2.9661
[09/26 07:52:46 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1691, average loss: 2.9241
[09/26 07:52:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 07:52:46 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:52:53 visual_prompt]: Epoch 94 / 100: avg data time: 5.45e-02, avg batch time: 0.5031, average train loss: 2.9588
[09/26 07:52:54 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1689, average loss: 2.9407
[09/26 07:52:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 07:52:54 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:53:01 visual_prompt]: Epoch 95 / 100: avg data time: 4.70e-02, avg batch time: 0.4950, average train loss: 2.9203
[09/26 07:53:02 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 2.9421
[09/26 07:53:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 07:53:02 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:53:09 visual_prompt]: Epoch 96 / 100: avg data time: 4.19e-02, avg batch time: 0.4948, average train loss: 2.9232
[09/26 07:53:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1694, average loss: 2.9213
[09/26 07:53:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 07:53:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:53:17 visual_prompt]: Epoch 97 / 100: avg data time: 5.26e-02, avg batch time: 0.5007, average train loss: 2.9033
[09/26 07:53:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 2.9086
[09/26 07:53:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 07:53:19 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:53:26 visual_prompt]: Epoch 98 / 100: avg data time: 5.21e-02, avg batch time: 0.5007, average train loss: 2.8879
[09/26 07:53:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 2.9061
[09/26 07:53:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 07:53:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:53:34 visual_prompt]: Epoch 99 / 100: avg data time: 5.37e-02, avg batch time: 0.5040, average train loss: 2.8820
[09/26 07:53:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1689, average loss: 2.9074
[09/26 07:53:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 07:53:35 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:53:42 visual_prompt]: Epoch 100 / 100: avg data time: 4.48e-02, avg batch time: 0.4936, average train loss: 2.8773
[09/26 07:53:43 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 2.9080
[09/26 07:53:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 27.00	
[09/26 07:53:43 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:53:43 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:53:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:53:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:53:43 visual_prompt]: Training with config:
[09/26 07:53:43 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:53:43 visual_prompt]: Loading training data...
[09/26 07:53:43 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:53:45 visual_prompt]: Number of images: 800
[09/26 07:53:45 visual_prompt]: Number of classes: 18 / 18
[09/26 07:53:45 visual_prompt]: Loading validation data...
[09/26 07:53:45 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 07:53:45 visual_prompt]: Number of images: 200
[09/26 07:53:45 visual_prompt]: Number of classes: 18 / 18
[09/26 07:53:45 visual_prompt]: Constructing models...
[09/26 07:53:47 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 07:53:47 visual_prompt]: tuned percent:0.550
[09/26 07:53:47 visual_prompt]: Device used for model: 0
[09/26 07:53:47 visual_prompt]: Setting up Evaluator...
[09/26 07:53:47 visual_prompt]: Setting up Trainer...
[09/26 07:53:47 visual_prompt]: 	Setting up the optimizer...
[09/26 07:53:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:53:54 visual_prompt]: Epoch 1 / 100: avg data time: 5.35e-02, avg batch time: 0.5023, average train loss: 3.2541
[09/26 07:53:56 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1690, average loss: 3.1895
[09/26 07:53:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 07:53:56 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 07:53:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:54:03 visual_prompt]: Epoch 2 / 100: avg data time: 4.31e-02, avg batch time: 0.4934, average train loss: 15.1728
[09/26 07:54:04 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1687, average loss: 25.3094
[09/26 07:54:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 07:54:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:54:11 visual_prompt]: Epoch 3 / 100: avg data time: 4.52e-02, avg batch time: 0.4941, average train loss: 60.9718
[09/26 07:54:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1686, average loss: 70.1106
[09/26 07:54:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 07:54:12 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 07:54:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:54:19 visual_prompt]: Epoch 4 / 100: avg data time: 4.49e-02, avg batch time: 0.4931, average train loss: 133.2399
[09/26 07:54:20 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1690, average loss: 113.8082
[09/26 07:54:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 07:54:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:54:27 visual_prompt]: Epoch 5 / 100: avg data time: 6.36e-02, avg batch time: 0.5110, average train loss: 142.1982
[09/26 07:54:29 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1685, average loss: 163.0350
[09/26 07:54:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 07:54:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:54:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.09e-02, avg batch time: 0.4998, average train loss: 187.7942
[09/26 07:54:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 183.9904
[09/26 07:54:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 07:54:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:54:44 visual_prompt]: Epoch 7 / 100: avg data time: 4.85e-02, avg batch time: 0.4961, average train loss: 217.7161
[09/26 07:54:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1688, average loss: 242.6034
[09/26 07:54:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 07:54:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:54:52 visual_prompt]: Epoch 8 / 100: avg data time: 4.97e-02, avg batch time: 0.4980, average train loss: 242.6907
[09/26 07:54:53 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1689, average loss: 258.1663
[09/26 07:54:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 07:54:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:55:00 visual_prompt]: Epoch 9 / 100: avg data time: 4.21e-02, avg batch time: 0.4912, average train loss: 268.9043
[09/26 07:55:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 243.2954
[09/26 07:55:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 07:55:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:55:08 visual_prompt]: Epoch 10 / 100: avg data time: 4.13e-02, avg batch time: 0.4898, average train loss: 374.3071
[09/26 07:55:10 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 472.4879
[09/26 07:55:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:55:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:55:16 visual_prompt]: Epoch 11 / 100: avg data time: 5.53e-02, avg batch time: 0.5045, average train loss: 317.8043
[09/26 07:55:18 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1688, average loss: 387.8888
[09/26 07:55:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 24.00	
[09/26 07:55:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:55:25 visual_prompt]: Epoch 12 / 100: avg data time: 3.88e-02, avg batch time: 0.4890, average train loss: 354.4152
[09/26 07:55:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1690, average loss: 249.4224
[09/26 07:55:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 07:55:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:55:33 visual_prompt]: Epoch 13 / 100: avg data time: 4.29e-02, avg batch time: 0.4906, average train loss: 324.0086
[09/26 07:55:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1688, average loss: 363.3678
[09/26 07:55:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 07:55:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:55:41 visual_prompt]: Epoch 14 / 100: avg data time: 4.70e-02, avg batch time: 0.4961, average train loss: 404.1170
[09/26 07:55:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 245.5883
[09/26 07:55:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 07:55:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:55:49 visual_prompt]: Epoch 15 / 100: avg data time: 4.20e-02, avg batch time: 0.4918, average train loss: 273.4845
[09/26 07:55:50 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 315.3005
[09/26 07:55:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:55:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:55:57 visual_prompt]: Epoch 16 / 100: avg data time: 5.44e-02, avg batch time: 0.5034, average train loss: 432.3765
[09/26 07:55:59 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1699, average loss: 362.0053
[09/26 07:55:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 07:55:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:56:05 visual_prompt]: Epoch 17 / 100: avg data time: 5.20e-02, avg batch time: 0.5006, average train loss: 433.6031
[09/26 07:56:07 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1694, average loss: 410.9417
[09/26 07:56:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 07:56:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:56:14 visual_prompt]: Epoch 18 / 100: avg data time: 5.30e-02, avg batch time: 0.5025, average train loss: 358.3948
[09/26 07:56:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 315.2173
[09/26 07:56:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 07:56:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:56:22 visual_prompt]: Epoch 19 / 100: avg data time: 5.36e-02, avg batch time: 0.5026, average train loss: 331.0530
[09/26 07:56:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1689, average loss: 211.6951
[09/26 07:56:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 07:56:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:56:30 visual_prompt]: Epoch 20 / 100: avg data time: 4.20e-02, avg batch time: 0.4912, average train loss: 253.9657
[09/26 07:56:31 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1695, average loss: 277.5384
[09/26 07:56:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 07:56:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:56:38 visual_prompt]: Epoch 21 / 100: avg data time: 5.26e-02, avg batch time: 0.5024, average train loss: 322.5825
[09/26 07:56:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1695, average loss: 222.5927
[09/26 07:56:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 07:56:40 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:56:47 visual_prompt]: Epoch 22 / 100: avg data time: 4.67e-02, avg batch time: 0.4957, average train loss: 250.3925
[09/26 07:56:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1694, average loss: 279.3160
[09/26 07:56:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:56:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:56:55 visual_prompt]: Epoch 23 / 100: avg data time: 4.27e-02, avg batch time: 0.4942, average train loss: 265.3565
[09/26 07:56:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 347.9451
[09/26 07:56:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 07:56:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:57:03 visual_prompt]: Epoch 24 / 100: avg data time: 5.44e-02, avg batch time: 0.5029, average train loss: 195.4391
[09/26 07:57:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1689, average loss: 217.6998
[09/26 07:57:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 07:57:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:57:11 visual_prompt]: Epoch 25 / 100: avg data time: 6.04e-02, avg batch time: 0.5091, average train loss: 183.4588
[09/26 07:57:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 154.1959
[09/26 07:57:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 07:57:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:57:20 visual_prompt]: Epoch 26 / 100: avg data time: 5.69e-02, avg batch time: 0.5070, average train loss: 173.7870
[09/26 07:57:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 297.5713
[09/26 07:57:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 07:57:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:57:28 visual_prompt]: Epoch 27 / 100: avg data time: 5.46e-02, avg batch time: 0.5045, average train loss: 242.0584
[09/26 07:57:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 215.0226
[09/26 07:57:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.50	
[09/26 07:57:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:57:36 visual_prompt]: Epoch 28 / 100: avg data time: 5.28e-02, avg batch time: 0.5003, average train loss: 202.8155
[09/26 07:57:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 153.0672
[09/26 07:57:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 07:57:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:57:44 visual_prompt]: Epoch 29 / 100: avg data time: 5.71e-02, avg batch time: 0.5053, average train loss: 211.4302
[09/26 07:57:46 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 194.0302
[09/26 07:57:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 07:57:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:57:53 visual_prompt]: Epoch 30 / 100: avg data time: 4.62e-02, avg batch time: 0.4948, average train loss: 183.2731
[09/26 07:57:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1687, average loss: 190.7281
[09/26 07:57:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 07:57:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:58:01 visual_prompt]: Epoch 31 / 100: avg data time: 6.15e-02, avg batch time: 0.5089, average train loss: 218.5074
[09/26 07:58:02 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1690, average loss: 151.3618
[09/26 07:58:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 07:58:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:58:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.56e-02, avg batch time: 0.5035, average train loss: 200.3729
[09/26 07:58:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1688, average loss: 203.5159
[09/26 07:58:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 07:58:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:58:18 visual_prompt]: Epoch 33 / 100: avg data time: 6.29e-02, avg batch time: 0.5110, average train loss: 179.1355
[09/26 07:58:19 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 144.8220
[09/26 07:58:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 07:58:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:58:26 visual_prompt]: Epoch 34 / 100: avg data time: 6.29e-02, avg batch time: 0.5114, average train loss: 230.7959
[09/26 07:58:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 299.0516
[09/26 07:58:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 07:58:28 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:58:34 visual_prompt]: Epoch 35 / 100: avg data time: 5.07e-02, avg batch time: 0.4992, average train loss: 244.4676
[09/26 07:58:36 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1696, average loss: 157.5493
[09/26 07:58:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 07:58:36 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:58:42 visual_prompt]: Epoch 36 / 100: avg data time: 4.62e-02, avg batch time: 0.4952, average train loss: 262.1050
[09/26 07:58:44 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 388.1786
[09/26 07:58:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 07:58:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:58:51 visual_prompt]: Epoch 37 / 100: avg data time: 5.30e-02, avg batch time: 0.5023, average train loss: 325.2293
[09/26 07:58:52 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1694, average loss: 235.6461
[09/26 07:58:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 07:58:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:58:59 visual_prompt]: Epoch 38 / 100: avg data time: 4.25e-02, avg batch time: 0.4916, average train loss: 257.3933
[09/26 07:59:00 visual_prompt]: Inference (val):avg data time: 5.86e-05, avg batch time: 0.1693, average loss: 245.3931
[09/26 07:59:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 07:59:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:59:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.47e-02, avg batch time: 0.5035, average train loss: 236.4340
[09/26 07:59:09 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1691, average loss: 269.3783
[09/26 07:59:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 07:59:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:59:15 visual_prompt]: Epoch 40 / 100: avg data time: 5.42e-02, avg batch time: 0.5027, average train loss: 265.7959
[09/26 07:59:17 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1691, average loss: 126.5946
[09/26 07:59:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 07:59:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:59:24 visual_prompt]: Epoch 41 / 100: avg data time: 4.78e-02, avg batch time: 0.4973, average train loss: 190.0342
[09/26 07:59:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1690, average loss: 173.8367
[09/26 07:59:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 07:59:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:59:32 visual_prompt]: Epoch 42 / 100: avg data time: 6.20e-02, avg batch time: 0.5092, average train loss: 160.4119
[09/26 07:59:33 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1688, average loss: 116.2066
[09/26 07:59:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 07:59:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:59:40 visual_prompt]: Epoch 43 / 100: avg data time: 5.68e-02, avg batch time: 0.5039, average train loss: 120.2827
[09/26 07:59:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 122.8130
[09/26 07:59:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 07:59:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:59:48 visual_prompt]: Epoch 44 / 100: avg data time: 4.31e-02, avg batch time: 0.4929, average train loss: 151.6273
[09/26 07:59:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1690, average loss: 130.3791
[09/26 07:59:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 07:59:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:59:57 visual_prompt]: Epoch 45 / 100: avg data time: 5.42e-02, avg batch time: 0.5012, average train loss: 125.4387
[09/26 07:59:58 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1689, average loss: 153.1712
[09/26 07:59:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 07:59:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 08:00:05 visual_prompt]: Epoch 46 / 100: avg data time: 5.41e-02, avg batch time: 0.5014, average train loss: 163.3012
[09/26 08:00:06 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1691, average loss: 129.8013
[09/26 08:00:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 08:00:06 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 08:00:13 visual_prompt]: Epoch 47 / 100: avg data time: 6.08e-02, avg batch time: 0.5091, average train loss: 138.5643
[09/26 08:00:15 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1696, average loss: 96.6414
[09/26 08:00:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 08:00:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 08:00:21 visual_prompt]: Epoch 48 / 100: avg data time: 5.93e-02, avg batch time: 0.5068, average train loss: 141.3557
[09/26 08:00:23 visual_prompt]: Inference (val):avg data time: 4.79e-05, avg batch time: 0.1689, average loss: 125.6353
[09/26 08:00:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.50	
[09/26 08:00:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 08:00:30 visual_prompt]: Epoch 49 / 100: avg data time: 5.43e-02, avg batch time: 0.5018, average train loss: 126.9747
[09/26 08:00:31 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1691, average loss: 144.5119
[09/26 08:00:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:00:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 08:00:38 visual_prompt]: Epoch 50 / 100: avg data time: 5.47e-02, avg batch time: 0.5025, average train loss: 143.5415
[09/26 08:00:40 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1692, average loss: 115.8057
[09/26 08:00:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:00:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 08:00:46 visual_prompt]: Epoch 51 / 100: avg data time: 4.64e-02, avg batch time: 0.4955, average train loss: 115.0580
[09/26 08:00:48 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1692, average loss: 147.6744
[09/26 08:00:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 08:00:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 08:00:55 visual_prompt]: Epoch 52 / 100: avg data time: 5.57e-02, avg batch time: 0.5041, average train loss: 127.5572
[09/26 08:00:56 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1692, average loss: 149.3196
[09/26 08:00:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:00:56 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 08:01:03 visual_prompt]: Epoch 53 / 100: avg data time: 5.56e-02, avg batch time: 0.5029, average train loss: 137.6285
[09/26 08:01:04 visual_prompt]: Inference (val):avg data time: 4.83e-05, avg batch time: 0.1689, average loss: 135.1431
[09/26 08:01:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 08:01:04 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 08:01:11 visual_prompt]: Epoch 54 / 100: avg data time: 5.50e-02, avg batch time: 0.5033, average train loss: 124.3650
[09/26 08:01:13 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 124.1295
[09/26 08:01:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:01:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 08:01:19 visual_prompt]: Epoch 55 / 100: avg data time: 4.99e-02, avg batch time: 0.4986, average train loss: 160.0021
[09/26 08:01:21 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 139.9888
[09/26 08:01:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 08:01:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 08:01:28 visual_prompt]: Epoch 56 / 100: avg data time: 4.28e-02, avg batch time: 0.4925, average train loss: 132.6451
[09/26 08:01:29 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1692, average loss: 190.0815
[09/26 08:01:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:01:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 08:01:36 visual_prompt]: Epoch 57 / 100: avg data time: 4.16e-02, avg batch time: 0.4916, average train loss: 128.0251
[09/26 08:01:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 88.3507
[09/26 08:01:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 08:01:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 08:01:44 visual_prompt]: Epoch 58 / 100: avg data time: 5.13e-02, avg batch time: 0.5010, average train loss: 129.7430
[09/26 08:01:45 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1695, average loss: 73.8417
[09/26 08:01:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 08:01:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 08:01:52 visual_prompt]: Epoch 59 / 100: avg data time: 4.35e-02, avg batch time: 0.4931, average train loss: 101.4225
[09/26 08:01:54 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1695, average loss: 97.1171
[09/26 08:01:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 08:01:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 08:02:00 visual_prompt]: Epoch 60 / 100: avg data time: 4.59e-02, avg batch time: 0.4951, average train loss: 83.3106
[09/26 08:02:02 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1697, average loss: 77.2274
[09/26 08:02:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 08:02:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 08:02:09 visual_prompt]: Epoch 61 / 100: avg data time: 5.28e-02, avg batch time: 0.5017, average train loss: 113.5989
[09/26 08:02:10 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 140.3091
[09/26 08:02:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 08:02:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 08:02:17 visual_prompt]: Epoch 62 / 100: avg data time: 5.18e-02, avg batch time: 0.4999, average train loss: 91.7164
[09/26 08:02:18 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1691, average loss: 119.3371
[09/26 08:02:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 34.00	
[09/26 08:02:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 08:02:25 visual_prompt]: Epoch 63 / 100: avg data time: 5.50e-02, avg batch time: 0.5042, average train loss: 75.7895
[09/26 08:02:26 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 65.2868
[09/26 08:02:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 08:02:26 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 08:02:33 visual_prompt]: Epoch 64 / 100: avg data time: 5.78e-02, avg batch time: 0.5061, average train loss: 79.0758
[09/26 08:02:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1699, average loss: 61.9773
[09/26 08:02:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 08:02:35 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 08:02:41 visual_prompt]: Epoch 65 / 100: avg data time: 5.52e-02, avg batch time: 0.5035, average train loss: 57.0150
[09/26 08:02:43 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1694, average loss: 67.4505
[09/26 08:02:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 08:02:43 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 08:02:50 visual_prompt]: Epoch 66 / 100: avg data time: 4.07e-02, avg batch time: 0.4889, average train loss: 51.6962
[09/26 08:02:51 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1695, average loss: 56.4811
[09/26 08:02:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:02:51 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 08:02:58 visual_prompt]: Epoch 67 / 100: avg data time: 5.91e-02, avg batch time: 0.5070, average train loss: 53.3792
[09/26 08:02:59 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 30.3090
[09/26 08:02:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 08:02:59 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 08:03:06 visual_prompt]: Epoch 68 / 100: avg data time: 4.34e-02, avg batch time: 0.4935, average train loss: 39.6490
[09/26 08:03:07 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 47.0845
[09/26 08:03:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 08:03:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 08:03:14 visual_prompt]: Epoch 69 / 100: avg data time: 4.76e-02, avg batch time: 0.4991, average train loss: 49.3706
[09/26 08:03:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1690, average loss: 37.4933
[09/26 08:03:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 08:03:16 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 08:03:22 visual_prompt]: Epoch 70 / 100: avg data time: 4.31e-02, avg batch time: 0.4925, average train loss: 33.1226
[09/26 08:03:24 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1691, average loss: 37.1119
[09/26 08:03:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 08:03:24 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 08:03:31 visual_prompt]: Epoch 71 / 100: avg data time: 5.53e-02, avg batch time: 0.5037, average train loss: 41.5761
[09/26 08:03:32 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1692, average loss: 48.1444
[09/26 08:03:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 08:03:32 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 08:03:39 visual_prompt]: Epoch 72 / 100: avg data time: 6.09e-02, avg batch time: 0.5087, average train loss: 39.0821
[09/26 08:03:41 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1692, average loss: 31.1888
[09/26 08:03:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:03:41 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 08:03:47 visual_prompt]: Epoch 73 / 100: avg data time: 5.38e-02, avg batch time: 0.5036, average train loss: 35.4978
[09/26 08:03:49 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1691, average loss: 27.3403
[09/26 08:03:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:03:49 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 08:03:56 visual_prompt]: Epoch 74 / 100: avg data time: 5.05e-02, avg batch time: 0.4999, average train loss: 32.1541
[09/26 08:03:57 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 31.6890
[09/26 08:03:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:03:57 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 08:04:04 visual_prompt]: Epoch 75 / 100: avg data time: 5.02e-02, avg batch time: 0.5003, average train loss: 22.4005
[09/26 08:04:05 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1692, average loss: 28.8796
[09/26 08:04:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 08:04:05 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 08:04:12 visual_prompt]: Epoch 76 / 100: avg data time: 5.66e-02, avg batch time: 0.5057, average train loss: 21.6290
[09/26 08:04:14 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 12.3924
[09/26 08:04:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 08:04:14 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 08:04:21 visual_prompt]: Epoch 77 / 100: avg data time: 5.13e-02, avg batch time: 0.5011, average train loss: 15.5716
[09/26 08:04:22 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1695, average loss: 19.8008
[09/26 08:04:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 08:04:22 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 08:04:29 visual_prompt]: Epoch 78 / 100: avg data time: 4.71e-02, avg batch time: 0.4964, average train loss: 17.5162
[09/26 08:04:30 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1691, average loss: 10.2432
[09/26 08:04:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:04:30 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 08:04:37 visual_prompt]: Epoch 79 / 100: avg data time: 4.53e-02, avg batch time: 0.4938, average train loss: 13.2770
[09/26 08:04:39 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1691, average loss: 12.9928
[09/26 08:04:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:04:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 08:04:45 visual_prompt]: Epoch 80 / 100: avg data time: 4.22e-02, avg batch time: 0.4907, average train loss: 9.6770
[09/26 08:04:47 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 8.0712
[09/26 08:04:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 08:04:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 08:04:53 visual_prompt]: Epoch 81 / 100: avg data time: 4.54e-02, avg batch time: 0.4951, average train loss: 6.2045
[09/26 08:04:55 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 4.6610
[09/26 08:04:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 08:04:55 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 08:05:02 visual_prompt]: Epoch 82 / 100: avg data time: 4.13e-02, avg batch time: 0.4931, average train loss: 4.3593
[09/26 08:05:03 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1688, average loss: 3.7045
[09/26 08:05:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:05:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 08:05:10 visual_prompt]: Epoch 83 / 100: avg data time: 5.21e-02, avg batch time: 0.5007, average train loss: 3.5368
[09/26 08:05:11 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1690, average loss: 3.4715
[09/26 08:05:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:05:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 08:05:18 visual_prompt]: Epoch 84 / 100: avg data time: 4.40e-02, avg batch time: 0.4947, average train loss: 3.3066
[09/26 08:05:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 3.1723
[09/26 08:05:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 08:05:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 08:05:26 visual_prompt]: Epoch 85 / 100: avg data time: 4.23e-02, avg batch time: 0.4936, average train loss: 3.1187
[09/26 08:05:28 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1693, average loss: 3.1717
[09/26 08:05:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 08:05:28 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 08:05:35 visual_prompt]: Epoch 86 / 100: avg data time: 5.88e-02, avg batch time: 0.5071, average train loss: 3.0417
[09/26 08:05:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 3.0100
[09/26 08:05:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:05:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 08:05:43 visual_prompt]: Epoch 87 / 100: avg data time: 5.31e-02, avg batch time: 0.5013, average train loss: 3.1487
[09/26 08:05:44 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 3.0176
[09/26 08:05:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:05:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 08:05:51 visual_prompt]: Epoch 88 / 100: avg data time: 6.23e-02, avg batch time: 0.5112, average train loss: 3.0606
[09/26 08:05:53 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 3.0133
[09/26 08:05:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 08:05:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 08:05:59 visual_prompt]: Epoch 89 / 100: avg data time: 4.07e-02, avg batch time: 0.4900, average train loss: 3.0507
[09/26 08:06:01 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1691, average loss: 2.9379
[09/26 08:06:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 08:06:01 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 08:06:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.12e-02, avg batch time: 0.5004, average train loss: 3.0326
[09/26 08:06:09 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1691, average loss: 3.0424
[09/26 08:06:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 08:06:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 08:06:16 visual_prompt]: Epoch 91 / 100: avg data time: 3.87e-02, avg batch time: 0.4892, average train loss: 3.0856
[09/26 08:06:17 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1692, average loss: 3.1067
[09/26 08:06:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 08:06:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 08:06:24 visual_prompt]: Epoch 92 / 100: avg data time: 5.36e-02, avg batch time: 0.5026, average train loss: 3.0368
[09/26 08:06:26 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 2.9646
[09/26 08:06:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.00	
[09/26 08:06:26 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 08:06:32 visual_prompt]: Epoch 93 / 100: avg data time: 4.45e-02, avg batch time: 0.4952, average train loss: 2.9765
[09/26 08:06:34 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 2.9716
[09/26 08:06:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 08:06:34 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 08:06:40 visual_prompt]: Epoch 94 / 100: avg data time: 3.91e-02, avg batch time: 0.4904, average train loss: 2.9276
[09/26 08:06:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 2.9132
[09/26 08:06:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 08:06:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 08:06:49 visual_prompt]: Epoch 95 / 100: avg data time: 5.06e-02, avg batch time: 0.5001, average train loss: 2.9149
[09/26 08:06:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 2.9307
[09/26 08:06:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:06:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 08:06:57 visual_prompt]: Epoch 96 / 100: avg data time: 4.29e-02, avg batch time: 0.4927, average train loss: 2.8958
[09/26 08:06:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1692, average loss: 2.9034
[09/26 08:06:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 08:06:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 08:07:05 visual_prompt]: Epoch 97 / 100: avg data time: 4.15e-02, avg batch time: 0.4914, average train loss: 2.8888
[09/26 08:07:06 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 2.9077
[09/26 08:07:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:07:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 08:07:13 visual_prompt]: Epoch 98 / 100: avg data time: 4.71e-02, avg batch time: 0.4985, average train loss: 2.8854
[09/26 08:07:15 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1695, average loss: 2.8980
[09/26 08:07:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 08:07:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 08:07:21 visual_prompt]: Epoch 99 / 100: avg data time: 4.10e-02, avg batch time: 0.4938, average train loss: 2.8859
[09/26 08:07:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1692, average loss: 2.9014
[09/26 08:07:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.00	
[09/26 08:07:23 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 08:07:29 visual_prompt]: Epoch 100 / 100: avg data time: 4.22e-02, avg batch time: 0.4925, average train loss: 2.8766
[09/26 08:07:31 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1690, average loss: 2.9016
[09/26 08:07:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.50	
[09/26 08:07:31 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:07:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:07:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:07:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:07:31 visual_prompt]: Training with config:
[09/26 08:07:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:07:31 visual_prompt]: Loading training data...
[09/26 08:07:31 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:07:32 visual_prompt]: Number of images: 800
[09/26 08:07:32 visual_prompt]: Number of classes: 18 / 18
[09/26 08:07:32 visual_prompt]: Loading validation data...
[09/26 08:07:32 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:07:32 visual_prompt]: Number of images: 200
[09/26 08:07:32 visual_prompt]: Number of classes: 18 / 18
[09/26 08:07:32 visual_prompt]: Constructing models...
[09/26 08:07:35 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 08:07:35 visual_prompt]: tuned percent:0.550
[09/26 08:07:35 visual_prompt]: Device used for model: 0
[09/26 08:07:35 visual_prompt]: Setting up Evaluator...
[09/26 08:07:35 visual_prompt]: Setting up Trainer...
[09/26 08:07:35 visual_prompt]: 	Setting up the optimizer...
[09/26 08:07:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:07:42 visual_prompt]: Epoch 1 / 100: avg data time: 5.44e-02, avg batch time: 0.5052, average train loss: 3.2502
[09/26 08:07:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 3.1895
[09/26 08:07:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 08:07:43 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 08:07:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 08:07:50 visual_prompt]: Epoch 2 / 100: avg data time: 5.42e-02, avg batch time: 0.5024, average train loss: 12.1167
[09/26 08:07:52 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1690, average loss: 19.9826
[09/26 08:07:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 08:07:52 visual_prompt]: Best epoch 2: best metric: 0.070
[09/26 08:07:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 08:07:58 visual_prompt]: Epoch 3 / 100: avg data time: 5.70e-02, avg batch time: 0.5031, average train loss: 47.1182
[09/26 08:08:00 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1684, average loss: 85.4424
[09/26 08:08:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 08:08:00 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 08:08:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 08:08:07 visual_prompt]: Epoch 4 / 100: avg data time: 5.41e-02, avg batch time: 0.5016, average train loss: 114.8170
[09/26 08:08:08 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1690, average loss: 94.7700
[09/26 08:08:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 08:08:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 08:08:15 visual_prompt]: Epoch 5 / 100: avg data time: 4.24e-02, avg batch time: 0.4917, average train loss: 129.3761
[09/26 08:08:16 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1694, average loss: 141.0160
[09/26 08:08:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 08:08:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 08:08:23 visual_prompt]: Epoch 6 / 100: avg data time: 5.42e-02, avg batch time: 0.5041, average train loss: 131.5782
[09/26 08:08:25 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1692, average loss: 160.7042
[09/26 08:08:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:08:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 08:08:31 visual_prompt]: Epoch 7 / 100: avg data time: 5.36e-02, avg batch time: 0.5016, average train loss: 145.6420
[09/26 08:08:33 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1693, average loss: 135.7140
[09/26 08:08:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 08:08:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 08:08:39 visual_prompt]: Epoch 8 / 100: avg data time: 4.46e-02, avg batch time: 0.4925, average train loss: 142.0664
[09/26 08:08:41 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1694, average loss: 118.0450
[09/26 08:08:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 22.50	
[09/26 08:08:41 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 08:08:48 visual_prompt]: Epoch 9 / 100: avg data time: 5.80e-02, avg batch time: 0.5058, average train loss: 120.7498
[09/26 08:08:49 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1692, average loss: 192.5233
[09/26 08:08:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:08:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 08:08:56 visual_prompt]: Epoch 10 / 100: avg data time: 5.81e-02, avg batch time: 0.5058, average train loss: 206.3942
[09/26 08:08:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1692, average loss: 155.0841
[09/26 08:08:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:08:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 08:09:04 visual_prompt]: Epoch 11 / 100: avg data time: 5.66e-02, avg batch time: 0.5060, average train loss: 207.1948
[09/26 08:09:06 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1695, average loss: 243.4531
[09/26 08:09:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 08:09:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 08:09:13 visual_prompt]: Epoch 12 / 100: avg data time: 6.06e-02, avg batch time: 0.5086, average train loss: 188.3766
[09/26 08:09:14 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 168.0715
[09/26 08:09:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:09:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 08:09:21 visual_prompt]: Epoch 13 / 100: avg data time: 5.57e-02, avg batch time: 0.5034, average train loss: 165.8273
[09/26 08:09:23 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 213.3218
[09/26 08:09:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:09:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 08:09:29 visual_prompt]: Epoch 14 / 100: avg data time: 5.59e-02, avg batch time: 0.5051, average train loss: 169.2674
[09/26 08:09:31 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1691, average loss: 249.5062
[09/26 08:09:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 08:09:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 08:09:38 visual_prompt]: Epoch 15 / 100: avg data time: 5.86e-02, avg batch time: 0.5065, average train loss: 214.3953
[09/26 08:09:39 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1690, average loss: 168.5900
[09/26 08:09:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 08:09:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 08:09:46 visual_prompt]: Epoch 16 / 100: avg data time: 5.87e-02, avg batch time: 0.5077, average train loss: 187.4193
[09/26 08:09:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1688, average loss: 150.7905
[09/26 08:09:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 08:09:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 08:09:54 visual_prompt]: Epoch 17 / 100: avg data time: 5.57e-02, avg batch time: 0.5034, average train loss: 139.5391
[09/26 08:09:56 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1689, average loss: 95.5616
[09/26 08:09:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:09:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 08:10:03 visual_prompt]: Epoch 18 / 100: avg data time: 4.92e-02, avg batch time: 0.4975, average train loss: 113.3186
[09/26 08:10:04 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 200.6306
[09/26 08:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:10:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 08:10:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.78e-02, avg batch time: 0.5052, average train loss: 145.2648
[09/26 08:10:12 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1689, average loss: 98.8866
[09/26 08:10:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 08:10:12 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 08:10:19 visual_prompt]: Epoch 20 / 100: avg data time: 4.15e-02, avg batch time: 0.4901, average train loss: 118.4138
[09/26 08:10:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1688, average loss: 129.6873
[09/26 08:10:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:10:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 08:10:27 visual_prompt]: Epoch 21 / 100: avg data time: 4.79e-02, avg batch time: 0.4963, average train loss: 132.1013
[09/26 08:10:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 96.1926
[09/26 08:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 08:10:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 08:10:36 visual_prompt]: Epoch 22 / 100: avg data time: 5.47e-02, avg batch time: 0.5036, average train loss: 128.4712
[09/26 08:10:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1686, average loss: 92.9968
[09/26 08:10:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 08:10:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 08:10:44 visual_prompt]: Epoch 23 / 100: avg data time: 5.97e-02, avg batch time: 0.5080, average train loss: 126.9554
[09/26 08:10:45 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1690, average loss: 133.8103
[09/26 08:10:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 08:10:45 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 08:10:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.74e-02, avg batch time: 0.5072, average train loss: 128.1965
[09/26 08:10:54 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1690, average loss: 125.6035
[09/26 08:10:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 21.00	
[09/26 08:10:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 08:11:00 visual_prompt]: Epoch 25 / 100: avg data time: 5.41e-02, avg batch time: 0.5035, average train loss: 101.0192
[09/26 08:11:02 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1693, average loss: 131.0739
[09/26 08:11:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.50	
[09/26 08:11:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 08:11:09 visual_prompt]: Epoch 26 / 100: avg data time: 5.77e-02, avg batch time: 0.5065, average train loss: 122.8267
[09/26 08:11:10 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1687, average loss: 131.9608
[09/26 08:11:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:11:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 08:11:17 visual_prompt]: Epoch 27 / 100: avg data time: 5.77e-02, avg batch time: 0.5061, average train loss: 108.3039
[09/26 08:11:19 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1690, average loss: 121.8324
[09/26 08:11:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:11:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 08:11:25 visual_prompt]: Epoch 28 / 100: avg data time: 5.45e-02, avg batch time: 0.5030, average train loss: 86.3899
[09/26 08:11:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 111.3485
[09/26 08:11:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 25.50	
[09/26 08:11:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 08:11:34 visual_prompt]: Epoch 29 / 100: avg data time: 4.85e-02, avg batch time: 0.4984, average train loss: 105.6721
[09/26 08:11:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 92.9370
[09/26 08:11:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 27.00	
[09/26 08:11:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 08:11:42 visual_prompt]: Epoch 30 / 100: avg data time: 4.86e-02, avg batch time: 0.4960, average train loss: 93.8701
[09/26 08:11:43 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1691, average loss: 113.7500
[09/26 08:11:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:11:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 08:11:50 visual_prompt]: Epoch 31 / 100: avg data time: 5.54e-02, avg batch time: 0.5028, average train loss: 128.5755
[09/26 08:11:51 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1693, average loss: 127.8990
[09/26 08:11:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:11:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 08:11:58 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e-02, avg batch time: 0.4993, average train loss: 135.6147
[09/26 08:12:00 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 137.6523
[09/26 08:12:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 08:12:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 08:12:06 visual_prompt]: Epoch 33 / 100: avg data time: 5.49e-02, avg batch time: 0.5027, average train loss: 121.5851
[09/26 08:12:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1689, average loss: 84.0979
[09/26 08:12:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 08:12:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 08:12:15 visual_prompt]: Epoch 34 / 100: avg data time: 5.12e-02, avg batch time: 0.4990, average train loss: 105.0196
[09/26 08:12:16 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 137.6900
[09/26 08:12:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 08:12:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 08:12:23 visual_prompt]: Epoch 35 / 100: avg data time: 5.68e-02, avg batch time: 0.5057, average train loss: 120.1593
[09/26 08:12:25 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1687, average loss: 103.9257
[09/26 08:12:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:12:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 08:12:31 visual_prompt]: Epoch 36 / 100: avg data time: 5.17e-02, avg batch time: 0.5010, average train loss: 110.0842
[09/26 08:12:33 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1693, average loss: 122.4978
[09/26 08:12:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 08:12:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 08:12:39 visual_prompt]: Epoch 37 / 100: avg data time: 4.82e-02, avg batch time: 0.4961, average train loss: 109.4381
[09/26 08:12:41 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 95.2155
[09/26 08:12:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:12:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 08:12:48 visual_prompt]: Epoch 38 / 100: avg data time: 5.87e-02, avg batch time: 0.5060, average train loss: 96.3322
[09/26 08:12:49 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1692, average loss: 84.4599
[09/26 08:12:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 08:12:49 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 08:12:56 visual_prompt]: Epoch 39 / 100: avg data time: 4.84e-02, avg batch time: 0.4975, average train loss: 105.7726
[09/26 08:12:57 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 93.8823
[09/26 08:12:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 08:12:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 08:13:04 visual_prompt]: Epoch 40 / 100: avg data time: 4.63e-02, avg batch time: 0.4944, average train loss: 94.6307
[09/26 08:13:06 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1699, average loss: 65.7753
[09/26 08:13:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 08:13:06 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 08:13:12 visual_prompt]: Epoch 41 / 100: avg data time: 4.36e-02, avg batch time: 0.4921, average train loss: 98.4952
[09/26 08:13:14 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1695, average loss: 131.5825
[09/26 08:13:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:13:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 08:13:20 visual_prompt]: Epoch 42 / 100: avg data time: 4.88e-02, avg batch time: 0.4962, average train loss: 84.1095
[09/26 08:13:22 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1692, average loss: 90.0515
[09/26 08:13:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 08:13:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 08:13:29 visual_prompt]: Epoch 43 / 100: avg data time: 5.71e-02, avg batch time: 0.5047, average train loss: 74.4055
[09/26 08:13:30 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 64.2136
[09/26 08:13:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 08:13:30 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 08:13:37 visual_prompt]: Epoch 44 / 100: avg data time: 5.01e-02, avg batch time: 0.4992, average train loss: 68.3837
[09/26 08:13:39 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1692, average loss: 62.3239
[09/26 08:13:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:13:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 08:13:45 visual_prompt]: Epoch 45 / 100: avg data time: 5.93e-02, avg batch time: 0.5065, average train loss: 67.5694
[09/26 08:13:47 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1691, average loss: 67.0035
[09/26 08:13:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 08:13:47 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 08:13:54 visual_prompt]: Epoch 46 / 100: avg data time: 5.27e-02, avg batch time: 0.5001, average train loss: 81.2566
[09/26 08:13:55 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1691, average loss: 83.2347
[09/26 08:13:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:13:55 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 08:14:02 visual_prompt]: Epoch 47 / 100: avg data time: 5.87e-02, avg batch time: 0.5069, average train loss: 69.9084
[09/26 08:14:03 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 69.0203
[09/26 08:14:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:14:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 08:14:10 visual_prompt]: Epoch 48 / 100: avg data time: 6.52e-02, avg batch time: 0.5130, average train loss: 86.8790
[09/26 08:14:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 62.6624
[09/26 08:14:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 08:14:12 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 08:14:19 visual_prompt]: Epoch 49 / 100: avg data time: 4.32e-02, avg batch time: 0.4920, average train loss: 71.1665
[09/26 08:14:20 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1688, average loss: 77.2922
[09/26 08:14:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 08:14:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 08:14:27 visual_prompt]: Epoch 50 / 100: avg data time: 5.28e-02, avg batch time: 0.5019, average train loss: 72.5748
[09/26 08:14:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1688, average loss: 71.8144
[09/26 08:14:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 08:14:28 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 08:14:35 visual_prompt]: Epoch 51 / 100: avg data time: 4.92e-02, avg batch time: 0.4982, average train loss: 53.6642
[09/26 08:14:37 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1691, average loss: 59.5312
[09/26 08:14:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 08:14:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 08:14:43 visual_prompt]: Epoch 52 / 100: avg data time: 5.66e-02, avg batch time: 0.5048, average train loss: 64.3475
[09/26 08:14:45 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1694, average loss: 62.9782
[09/26 08:14:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.50	
[09/26 08:14:45 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 08:14:52 visual_prompt]: Epoch 53 / 100: avg data time: 6.14e-02, avg batch time: 0.5091, average train loss: 54.8536
[09/26 08:14:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1693, average loss: 59.1977
[09/26 08:14:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 08:14:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 08:15:00 visual_prompt]: Epoch 54 / 100: avg data time: 5.52e-02, avg batch time: 0.5037, average train loss: 50.5740
[09/26 08:15:02 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1695, average loss: 48.4443
[09/26 08:15:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:15:02 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 08:15:08 visual_prompt]: Epoch 55 / 100: avg data time: 5.44e-02, avg batch time: 0.5038, average train loss: 43.8201
[09/26 08:15:10 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 50.6518
[09/26 08:15:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:15:10 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 08:15:17 visual_prompt]: Epoch 56 / 100: avg data time: 5.67e-02, avg batch time: 0.5041, average train loss: 48.8548
[09/26 08:15:18 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1690, average loss: 55.9116
[09/26 08:15:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 08:15:18 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 08:15:25 visual_prompt]: Epoch 57 / 100: avg data time: 5.25e-02, avg batch time: 0.5023, average train loss: 52.1986
[09/26 08:15:27 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1693, average loss: 44.1463
[09/26 08:15:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.50	
[09/26 08:15:27 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 08:15:33 visual_prompt]: Epoch 58 / 100: avg data time: 5.82e-02, avg batch time: 0.5061, average train loss: 49.4766
[09/26 08:15:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1690, average loss: 35.4671
[09/26 08:15:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:15:35 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 08:15:42 visual_prompt]: Epoch 59 / 100: avg data time: 3.88e-02, avg batch time: 0.4913, average train loss: 49.6728
[09/26 08:15:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 50.3672
[09/26 08:15:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:15:43 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 08:15:50 visual_prompt]: Epoch 60 / 100: avg data time: 5.34e-02, avg batch time: 0.5024, average train loss: 40.1081
[09/26 08:15:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 35.3814
[09/26 08:15:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:15:51 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 08:15:58 visual_prompt]: Epoch 61 / 100: avg data time: 5.49e-02, avg batch time: 0.5024, average train loss: 33.2280
[09/26 08:15:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 38.0836
[09/26 08:15:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:15:59 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 08:16:06 visual_prompt]: Epoch 62 / 100: avg data time: 5.05e-02, avg batch time: 0.4994, average train loss: 33.6063
[09/26 08:16:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1688, average loss: 38.1896
[09/26 08:16:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:16:08 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 08:16:14 visual_prompt]: Epoch 63 / 100: avg data time: 5.76e-02, avg batch time: 0.5064, average train loss: 27.0487
[09/26 08:16:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 19.7056
[09/26 08:16:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 27.50	
[09/26 08:16:16 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 08:16:23 visual_prompt]: Epoch 64 / 100: avg data time: 5.44e-02, avg batch time: 0.5018, average train loss: 24.7992
[09/26 08:16:24 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1689, average loss: 28.3307
[09/26 08:16:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:16:24 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 08:16:31 visual_prompt]: Epoch 65 / 100: avg data time: 5.57e-02, avg batch time: 0.5045, average train loss: 25.8108
[09/26 08:16:33 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1690, average loss: 26.5609
[09/26 08:16:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 08:16:33 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 08:16:39 visual_prompt]: Epoch 66 / 100: avg data time: 5.59e-02, avg batch time: 0.5044, average train loss: 28.3574
[09/26 08:16:41 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 25.4249
[09/26 08:16:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 21.50	
[09/26 08:16:41 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 08:16:47 visual_prompt]: Epoch 67 / 100: avg data time: 4.20e-02, avg batch time: 0.4902, average train loss: 25.4689
[09/26 08:16:49 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1693, average loss: 30.3437
[09/26 08:16:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 08:16:49 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 08:16:56 visual_prompt]: Epoch 68 / 100: avg data time: 4.10e-02, avg batch time: 0.4903, average train loss: 23.8033
[09/26 08:16:57 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 21.4065
[09/26 08:16:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.50	
[09/26 08:16:57 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 08:17:04 visual_prompt]: Epoch 69 / 100: avg data time: 5.46e-02, avg batch time: 0.5027, average train loss: 19.1945
[09/26 08:17:05 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1693, average loss: 16.7873
[09/26 08:17:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:17:05 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 08:17:12 visual_prompt]: Epoch 70 / 100: avg data time: 5.49e-02, avg batch time: 0.5032, average train loss: 14.3810
[09/26 08:17:14 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 12.9562
[09/26 08:17:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 08:17:14 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 08:17:20 visual_prompt]: Epoch 71 / 100: avg data time: 5.47e-02, avg batch time: 0.5044, average train loss: 10.1157
[09/26 08:17:22 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 9.2646
[09/26 08:17:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 08:17:22 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 08:17:29 visual_prompt]: Epoch 72 / 100: avg data time: 5.32e-02, avg batch time: 0.5033, average train loss: 8.3428
[09/26 08:17:30 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 6.4170
[09/26 08:17:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 08:17:30 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 08:17:37 visual_prompt]: Epoch 73 / 100: avg data time: 5.30e-02, avg batch time: 0.5021, average train loss: 6.1608
[09/26 08:17:39 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 4.9516
[09/26 08:17:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 08:17:39 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 08:17:45 visual_prompt]: Epoch 74 / 100: avg data time: 5.25e-02, avg batch time: 0.5005, average train loss: 4.9074
[09/26 08:17:47 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 5.0279
[09/26 08:17:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:17:47 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 08:17:54 visual_prompt]: Epoch 75 / 100: avg data time: 4.15e-02, avg batch time: 0.4918, average train loss: 4.8255
[09/26 08:17:55 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1690, average loss: 4.3025
[09/26 08:17:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:17:55 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 08:18:02 visual_prompt]: Epoch 76 / 100: avg data time: 5.68e-02, avg batch time: 0.5044, average train loss: 4.4784
[09/26 08:18:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 3.8477
[09/26 08:18:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.50	
[09/26 08:18:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 08:18:10 visual_prompt]: Epoch 77 / 100: avg data time: 5.31e-02, avg batch time: 0.5008, average train loss: 4.0471
[09/26 08:18:12 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1691, average loss: 3.7320
[09/26 08:18:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 08:18:12 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 08:18:18 visual_prompt]: Epoch 78 / 100: avg data time: 5.64e-02, avg batch time: 0.5056, average train loss: 4.2789
[09/26 08:18:20 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1692, average loss: 3.9957
[09/26 08:18:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.00	
[09/26 08:18:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 08:18:27 visual_prompt]: Epoch 79 / 100: avg data time: 4.70e-02, avg batch time: 0.4957, average train loss: 4.1081
[09/26 08:18:28 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 4.4031
[09/26 08:18:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:18:28 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 08:18:35 visual_prompt]: Epoch 80 / 100: avg data time: 6.17e-02, avg batch time: 0.5093, average train loss: 4.3038
[09/26 08:18:37 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1689, average loss: 3.3474
[09/26 08:18:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 08:18:37 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 08:18:43 visual_prompt]: Epoch 81 / 100: avg data time: 5.70e-02, avg batch time: 0.5046, average train loss: 4.1769
[09/26 08:18:45 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1692, average loss: 3.5517
[09/26 08:18:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:18:45 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 08:18:52 visual_prompt]: Epoch 82 / 100: avg data time: 4.85e-02, avg batch time: 0.4975, average train loss: 3.9117
[09/26 08:18:53 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.5386
[09/26 08:18:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 08:18:53 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 08:19:00 visual_prompt]: Epoch 83 / 100: avg data time: 4.99e-02, avg batch time: 0.4986, average train loss: 3.9481
[09/26 08:19:02 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1690, average loss: 3.5366
[09/26 08:19:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.50	
[09/26 08:19:02 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 08:19:08 visual_prompt]: Epoch 84 / 100: avg data time: 4.83e-02, avg batch time: 0.4961, average train loss: 3.8446
[09/26 08:19:10 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1693, average loss: 3.7860
[09/26 08:19:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 08:19:10 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 08:19:17 visual_prompt]: Epoch 85 / 100: avg data time: 5.50e-02, avg batch time: 0.5034, average train loss: 3.8178
[09/26 08:19:18 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 3.6717
[09/26 08:19:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 08:19:18 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 08:19:25 visual_prompt]: Epoch 86 / 100: avg data time: 5.16e-02, avg batch time: 0.4992, average train loss: 3.7972
[09/26 08:19:26 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 3.5323
[09/26 08:19:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 08:19:26 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 08:19:33 visual_prompt]: Epoch 87 / 100: avg data time: 5.11e-02, avg batch time: 0.5013, average train loss: 3.7696
[09/26 08:19:35 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1692, average loss: 3.3506
[09/26 08:19:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.00	
[09/26 08:19:35 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 08:19:41 visual_prompt]: Epoch 88 / 100: avg data time: 5.57e-02, avg batch time: 0.5042, average train loss: 3.7065
[09/26 08:19:43 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1691, average loss: 3.5019
[09/26 08:19:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.00	
[09/26 08:19:43 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 08:19:50 visual_prompt]: Epoch 89 / 100: avg data time: 5.62e-02, avg batch time: 0.5048, average train loss: 3.7168
[09/26 08:19:51 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1691, average loss: 3.3139
[09/26 08:19:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 08:19:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 08:19:58 visual_prompt]: Epoch 90 / 100: avg data time: 4.98e-02, avg batch time: 0.4987, average train loss: 3.5372
[09/26 08:20:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1693, average loss: 3.2658
[09/26 08:20:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.00	
[09/26 08:20:00 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 08:20:06 visual_prompt]: Epoch 91 / 100: avg data time: 5.02e-02, avg batch time: 0.4996, average train loss: 3.5281
[09/26 08:20:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 3.3283
[09/26 08:20:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 08:20:08 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 08:20:15 visual_prompt]: Epoch 92 / 100: avg data time: 4.33e-02, avg batch time: 0.4944, average train loss: 3.5847
[09/26 08:20:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 3.2749
[09/26 08:20:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 31.00	
[09/26 08:20:16 visual_prompt]: Best epoch 92: best metric: 0.095
[09/26 08:20:16 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 08:20:23 visual_prompt]: Epoch 93 / 100: avg data time: 4.17e-02, avg batch time: 0.4910, average train loss: 3.6172
[09/26 08:20:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1688, average loss: 3.2819
[09/26 08:20:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 29.00	
[09/26 08:20:24 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 08:20:31 visual_prompt]: Epoch 94 / 100: avg data time: 5.99e-02, avg batch time: 0.5085, average train loss: 3.4954
[09/26 08:20:33 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1691, average loss: 3.3172
[09/26 08:20:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 08:20:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 08:20:39 visual_prompt]: Epoch 95 / 100: avg data time: 4.20e-02, avg batch time: 0.4902, average train loss: 3.4632
[09/26 08:20:41 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1690, average loss: 3.2724
[09/26 08:20:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 08:20:41 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 08:20:47 visual_prompt]: Epoch 96 / 100: avg data time: 5.48e-02, avg batch time: 0.5044, average train loss: 3.5324
[09/26 08:20:49 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 3.2723
[09/26 08:20:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:20:49 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 08:20:56 visual_prompt]: Epoch 97 / 100: avg data time: 5.53e-02, avg batch time: 0.5028, average train loss: 3.4768
[09/26 08:20:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 3.2707
[09/26 08:20:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.00	
[09/26 08:20:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 08:21:04 visual_prompt]: Epoch 98 / 100: avg data time: 5.61e-02, avg batch time: 0.5043, average train loss: 3.5160
[09/26 08:21:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1689, average loss: 3.2520
[09/26 08:21:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 08:21:06 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 08:21:12 visual_prompt]: Epoch 99 / 100: avg data time: 4.32e-02, avg batch time: 0.4911, average train loss: 3.5011
[09/26 08:21:14 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1688, average loss: 3.2552
[09/26 08:21:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 29.50	
[09/26 08:21:14 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 08:21:21 visual_prompt]: Epoch 100 / 100: avg data time: 5.71e-02, avg batch time: 0.5066, average train loss: 3.4694
[09/26 08:21:22 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1692, average loss: 3.2548
[09/26 08:21:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 30.50	
[09/26 08:21:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:21:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:21:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:21:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:21:22 visual_prompt]: Training with config:
[09/26 08:21:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:21:22 visual_prompt]: Loading training data...
[09/26 08:21:22 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:21:23 visual_prompt]: Number of images: 800
[09/26 08:21:23 visual_prompt]: Number of classes: 18 / 18
[09/26 08:21:23 visual_prompt]: Loading validation data...
[09/26 08:21:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:21:24 visual_prompt]: Number of images: 200
[09/26 08:21:24 visual_prompt]: Number of classes: 18 / 18
[09/26 08:21:24 visual_prompt]: Constructing models...
[09/26 08:21:26 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 08:21:26 visual_prompt]: tuned percent:0.550
[09/26 08:21:26 visual_prompt]: Device used for model: 0
[09/26 08:21:26 visual_prompt]: Setting up Evaluator...
[09/26 08:21:26 visual_prompt]: Setting up Trainer...
[09/26 08:21:26 visual_prompt]: 	Setting up the optimizer...
[09/26 08:21:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:21:33 visual_prompt]: Epoch 1 / 100: avg data time: 5.16e-02, avg batch time: 0.5004, average train loss: 3.2548
[09/26 08:21:35 visual_prompt]: Inference (val):avg data time: 4.34e-05, avg batch time: 0.1693, average loss: 3.1895
[09/26 08:21:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 08:21:35 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 08:21:35 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:21:41 visual_prompt]: Epoch 2 / 100: avg data time: 4.70e-02, avg batch time: 0.4958, average train loss: 5.3907
[09/26 08:21:43 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1683, average loss: 5.8872
[09/26 08:21:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:21:43 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:21:50 visual_prompt]: Epoch 3 / 100: avg data time: 5.37e-02, avg batch time: 0.5011, average train loss: 6.8766
[09/26 08:21:51 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1686, average loss: 7.9147
[09/26 08:21:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 08:21:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:21:58 visual_prompt]: Epoch 4 / 100: avg data time: 4.39e-02, avg batch time: 0.4936, average train loss: 12.5812
[09/26 08:21:59 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1691, average loss: 15.8350
[09/26 08:21:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:21:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:22:06 visual_prompt]: Epoch 5 / 100: avg data time: 4.27e-02, avg batch time: 0.4901, average train loss: 25.1484
[09/26 08:22:08 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1692, average loss: 32.2061
[09/26 08:22:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:22:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:22:14 visual_prompt]: Epoch 6 / 100: avg data time: 5.60e-02, avg batch time: 0.5035, average train loss: 36.1533
[09/26 08:22:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 82.7279
[09/26 08:22:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 08:22:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:22:22 visual_prompt]: Epoch 7 / 100: avg data time: 4.19e-02, avg batch time: 0.4907, average train loss: 53.9551
[09/26 08:22:24 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 52.5358
[09/26 08:22:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 34.00	
[09/26 08:22:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:22:31 visual_prompt]: Epoch 8 / 100: avg data time: 5.20e-02, avg batch time: 0.4995, average train loss: 75.9497
[09/26 08:22:32 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1693, average loss: 75.5865
[09/26 08:22:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 08:22:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:22:39 visual_prompt]: Epoch 9 / 100: avg data time: 4.29e-02, avg batch time: 0.4919, average train loss: 74.4352
[09/26 08:22:41 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 91.0247
[09/26 08:22:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 08:22:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:22:47 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e-02, avg batch time: 0.5000, average train loss: 92.5801
[09/26 08:22:49 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1690, average loss: 98.3356
[09/26 08:22:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 08:22:49 visual_prompt]: Best epoch 10: best metric: 0.085
[09/26 08:22:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:22:56 visual_prompt]: Epoch 11 / 100: avg data time: 5.10e-02, avg batch time: 0.5024, average train loss: 109.6955
[09/26 08:22:57 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1692, average loss: 103.8195
[09/26 08:22:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 08:22:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:23:04 visual_prompt]: Epoch 12 / 100: avg data time: 4.25e-02, avg batch time: 0.4921, average train loss: 106.0158
[09/26 08:23:05 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 100.3108
[09/26 08:23:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:23:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:23:12 visual_prompt]: Epoch 13 / 100: avg data time: 4.91e-02, avg batch time: 0.4987, average train loss: 95.1076
[09/26 08:23:13 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 94.6889
[09/26 08:23:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 08:23:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:23:20 visual_prompt]: Epoch 14 / 100: avg data time: 5.72e-02, avg batch time: 0.5063, average train loss: 99.3713
[09/26 08:23:22 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 105.2000
[09/26 08:23:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 24.50	
[09/26 08:23:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:23:29 visual_prompt]: Epoch 15 / 100: avg data time: 4.17e-02, avg batch time: 0.4912, average train loss: 100.0804
[09/26 08:23:30 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1689, average loss: 123.6705
[09/26 08:23:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 08:23:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:23:37 visual_prompt]: Epoch 16 / 100: avg data time: 5.56e-02, avg batch time: 0.5037, average train loss: 126.0117
[09/26 08:23:38 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 114.7260
[09/26 08:23:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.50	
[09/26 08:23:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:23:45 visual_prompt]: Epoch 17 / 100: avg data time: 4.89e-02, avg batch time: 0.4975, average train loss: 124.2885
[09/26 08:23:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1689, average loss: 85.6456
[09/26 08:23:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 08:23:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:23:53 visual_prompt]: Epoch 18 / 100: avg data time: 4.87e-02, avg batch time: 0.4988, average train loss: 138.6478
[09/26 08:23:55 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 84.4404
[09/26 08:23:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:23:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:24:01 visual_prompt]: Epoch 19 / 100: avg data time: 5.38e-02, avg batch time: 0.5018, average train loss: 132.8339
[09/26 08:24:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 125.5461
[09/26 08:24:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 08:24:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:24:10 visual_prompt]: Epoch 20 / 100: avg data time: 4.15e-02, avg batch time: 0.4923, average train loss: 109.5970
[09/26 08:24:11 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1692, average loss: 117.7172
[09/26 08:24:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 08:24:11 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:24:18 visual_prompt]: Epoch 21 / 100: avg data time: 4.78e-02, avg batch time: 0.4968, average train loss: 112.2252
[09/26 08:24:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1690, average loss: 89.8516
[09/26 08:24:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 08:24:19 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:24:26 visual_prompt]: Epoch 22 / 100: avg data time: 4.13e-02, avg batch time: 0.4919, average train loss: 99.0900
[09/26 08:24:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 113.4022
[09/26 08:24:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.50	
[09/26 08:24:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:24:34 visual_prompt]: Epoch 23 / 100: avg data time: 4.70e-02, avg batch time: 0.4965, average train loss: 108.8172
[09/26 08:24:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1694, average loss: 121.8597
[09/26 08:24:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:24:36 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:24:42 visual_prompt]: Epoch 24 / 100: avg data time: 4.17e-02, avg batch time: 0.4918, average train loss: 107.2258
[09/26 08:24:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1693, average loss: 90.2456
[09/26 08:24:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 08:24:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:24:51 visual_prompt]: Epoch 25 / 100: avg data time: 5.34e-02, avg batch time: 0.5030, average train loss: 94.0122
[09/26 08:24:52 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1691, average loss: 107.2428
[09/26 08:24:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 22.50	
[09/26 08:24:52 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:24:59 visual_prompt]: Epoch 26 / 100: avg data time: 4.27e-02, avg batch time: 0.4920, average train loss: 93.4087
[09/26 08:25:00 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 87.1351
[09/26 08:25:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 08:25:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:25:07 visual_prompt]: Epoch 27 / 100: avg data time: 5.18e-02, avg batch time: 0.5030, average train loss: 102.8690
[09/26 08:25:09 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1690, average loss: 123.3416
[09/26 08:25:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:25:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:25:15 visual_prompt]: Epoch 28 / 100: avg data time: 4.84e-02, avg batch time: 0.4965, average train loss: 130.9073
[09/26 08:25:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 52.8577
[09/26 08:25:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 08:25:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:25:24 visual_prompt]: Epoch 29 / 100: avg data time: 4.55e-02, avg batch time: 0.4961, average train loss: 97.9211
[09/26 08:25:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1693, average loss: 76.0354
[09/26 08:25:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 08:25:25 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:25:32 visual_prompt]: Epoch 30 / 100: avg data time: 4.27e-02, avg batch time: 0.4929, average train loss: 105.5208
[09/26 08:25:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 81.5580
[09/26 08:25:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 08:25:33 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:25:40 visual_prompt]: Epoch 31 / 100: avg data time: 5.23e-02, avg batch time: 0.5010, average train loss: 97.4691
[09/26 08:25:41 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1692, average loss: 70.2497
[09/26 08:25:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.00	
[09/26 08:25:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:25:48 visual_prompt]: Epoch 32 / 100: avg data time: 4.41e-02, avg batch time: 0.4944, average train loss: 96.4637
[09/26 08:25:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 68.6265
[09/26 08:25:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:25:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:25:57 visual_prompt]: Epoch 33 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 101.5118
[09/26 08:25:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1692, average loss: 111.4598
[09/26 08:25:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 35.00	
[09/26 08:25:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:26:05 visual_prompt]: Epoch 34 / 100: avg data time: 4.73e-02, avg batch time: 0.4965, average train loss: 96.4932
[09/26 08:26:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 133.0855
[09/26 08:26:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:26:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:26:13 visual_prompt]: Epoch 35 / 100: avg data time: 4.29e-02, avg batch time: 0.4935, average train loss: 104.6263
[09/26 08:26:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 112.1770
[09/26 08:26:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 08:26:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:26:21 visual_prompt]: Epoch 36 / 100: avg data time: 4.82e-02, avg batch time: 0.4977, average train loss: 93.6816
[09/26 08:26:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 97.9745
[09/26 08:26:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.50	
[09/26 08:26:23 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:26:29 visual_prompt]: Epoch 37 / 100: avg data time: 4.16e-02, avg batch time: 0.4921, average train loss: 92.8572
[09/26 08:26:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1695, average loss: 111.0178
[09/26 08:26:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 08:26:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:26:38 visual_prompt]: Epoch 38 / 100: avg data time: 5.95e-02, avg batch time: 0.5093, average train loss: 105.9722
[09/26 08:26:39 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1687, average loss: 81.4730
[09/26 08:26:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:26:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:26:46 visual_prompt]: Epoch 39 / 100: avg data time: 5.57e-02, avg batch time: 0.5038, average train loss: 95.0291
[09/26 08:26:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 76.3177
[09/26 08:26:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 08:26:48 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:26:54 visual_prompt]: Epoch 40 / 100: avg data time: 5.45e-02, avg batch time: 0.5035, average train loss: 102.7238
[09/26 08:26:56 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 92.0707
[09/26 08:26:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:26:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:27:03 visual_prompt]: Epoch 41 / 100: avg data time: 4.32e-02, avg batch time: 0.4931, average train loss: 86.0681
[09/26 08:27:04 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 129.5891
[09/26 08:27:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 08:27:04 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:27:11 visual_prompt]: Epoch 42 / 100: avg data time: 6.16e-02, avg batch time: 0.5094, average train loss: 84.2203
[09/26 08:27:13 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1690, average loss: 67.7698
[09/26 08:27:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 08:27:13 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:27:19 visual_prompt]: Epoch 43 / 100: avg data time: 4.83e-02, avg batch time: 0.4977, average train loss: 67.5069
[09/26 08:27:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1693, average loss: 77.3641
[09/26 08:27:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 08:27:21 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:27:28 visual_prompt]: Epoch 44 / 100: avg data time: 5.45e-02, avg batch time: 0.5036, average train loss: 85.8101
[09/26 08:27:29 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1696, average loss: 86.8377
[09/26 08:27:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:27:29 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:27:36 visual_prompt]: Epoch 45 / 100: avg data time: 4.21e-02, avg batch time: 0.4921, average train loss: 82.5610
[09/26 08:27:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1694, average loss: 126.9901
[09/26 08:27:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 08:27:37 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:27:44 visual_prompt]: Epoch 46 / 100: avg data time: 4.27e-02, avg batch time: 0.4916, average train loss: 82.0632
[09/26 08:27:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 84.8094
[09/26 08:27:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 08:27:45 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:27:52 visual_prompt]: Epoch 47 / 100: avg data time: 4.96e-02, avg batch time: 0.4992, average train loss: 59.8655
[09/26 08:27:53 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1689, average loss: 62.8433
[09/26 08:27:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:27:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:28:00 visual_prompt]: Epoch 48 / 100: avg data time: 4.40e-02, avg batch time: 0.4932, average train loss: 71.0320
[09/26 08:28:02 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 79.4468
[09/26 08:28:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 08:28:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:28:08 visual_prompt]: Epoch 49 / 100: avg data time: 5.13e-02, avg batch time: 0.4995, average train loss: 102.5891
[09/26 08:28:10 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1695, average loss: 87.4258
[09/26 08:28:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 08:28:10 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:28:17 visual_prompt]: Epoch 50 / 100: avg data time: 5.63e-02, avg batch time: 0.5041, average train loss: 88.7734
[09/26 08:28:18 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1691, average loss: 64.5063
[09/26 08:28:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 27.50	
[09/26 08:28:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:28:25 visual_prompt]: Epoch 51 / 100: avg data time: 5.25e-02, avg batch time: 0.5003, average train loss: 64.4948
[09/26 08:28:26 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 66.2405
[09/26 08:28:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:28:26 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:28:33 visual_prompt]: Epoch 52 / 100: avg data time: 5.47e-02, avg batch time: 0.5047, average train loss: 76.8207
[09/26 08:28:35 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 92.6790
[09/26 08:28:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 08:28:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:28:42 visual_prompt]: Epoch 53 / 100: avg data time: 5.45e-02, avg batch time: 0.5022, average train loss: 66.7957
[09/26 08:28:43 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1693, average loss: 80.2879
[09/26 08:28:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:28:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:28:50 visual_prompt]: Epoch 54 / 100: avg data time: 5.04e-02, avg batch time: 0.5004, average train loss: 63.4778
[09/26 08:28:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 73.7851
[09/26 08:28:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:28:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:28:58 visual_prompt]: Epoch 55 / 100: avg data time: 5.16e-02, avg batch time: 0.5005, average train loss: 70.6522
[09/26 08:29:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 73.9159
[09/26 08:29:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 08:29:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:29:06 visual_prompt]: Epoch 56 / 100: avg data time: 5.22e-02, avg batch time: 0.5019, average train loss: 77.0857
[09/26 08:29:08 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1693, average loss: 74.3079
[09/26 08:29:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 08:29:08 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:29:15 visual_prompt]: Epoch 57 / 100: avg data time: 4.29e-02, avg batch time: 0.4945, average train loss: 64.8819
[09/26 08:29:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1692, average loss: 52.8040
[09/26 08:29:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 08:29:16 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:29:23 visual_prompt]: Epoch 58 / 100: avg data time: 4.36e-02, avg batch time: 0.4928, average train loss: 56.9380
[09/26 08:29:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 73.5239
[09/26 08:29:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 08:29:24 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:29:31 visual_prompt]: Epoch 59 / 100: avg data time: 5.31e-02, avg batch time: 0.5014, average train loss: 52.7195
[09/26 08:29:33 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1693, average loss: 58.8393
[09/26 08:29:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 26.50	
[09/26 08:29:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:29:39 visual_prompt]: Epoch 60 / 100: avg data time: 5.81e-02, avg batch time: 0.5070, average train loss: 38.2574
[09/26 08:29:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 30.7647
[09/26 08:29:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 08:29:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:29:48 visual_prompt]: Epoch 61 / 100: avg data time: 4.35e-02, avg batch time: 0.4922, average train loss: 36.6498
[09/26 08:29:49 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1688, average loss: 28.8489
[09/26 08:29:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 08:29:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:29:56 visual_prompt]: Epoch 62 / 100: avg data time: 5.03e-02, avg batch time: 0.4996, average train loss: 42.6591
[09/26 08:29:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1695, average loss: 49.9400
[09/26 08:29:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:29:57 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:30:04 visual_prompt]: Epoch 63 / 100: avg data time: 5.16e-02, avg batch time: 0.5005, average train loss: 40.4300
[09/26 08:30:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1688, average loss: 34.9832
[09/26 08:30:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:30:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:30:12 visual_prompt]: Epoch 64 / 100: avg data time: 4.28e-02, avg batch time: 0.4912, average train loss: 39.5762
[09/26 08:30:14 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 32.2802
[09/26 08:30:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 08:30:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:30:21 visual_prompt]: Epoch 65 / 100: avg data time: 4.34e-02, avg batch time: 0.5413, average train loss: 37.3161
[09/26 08:30:22 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1690, average loss: 36.3015
[09/26 08:30:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 08:30:22 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:30:29 visual_prompt]: Epoch 66 / 100: avg data time: 4.53e-02, avg batch time: 0.4952, average train loss: 34.6538
[09/26 08:30:31 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 30.2678
[09/26 08:30:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 08:30:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:30:37 visual_prompt]: Epoch 67 / 100: avg data time: 4.22e-02, avg batch time: 0.4915, average train loss: 29.7549
[09/26 08:30:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 18.4594
[09/26 08:30:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:30:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:30:46 visual_prompt]: Epoch 68 / 100: avg data time: 5.25e-02, avg batch time: 0.5021, average train loss: 27.5282
[09/26 08:30:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1687, average loss: 34.6158
[09/26 08:30:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:30:47 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:30:54 visual_prompt]: Epoch 69 / 100: avg data time: 5.45e-02, avg batch time: 0.5037, average train loss: 27.5186
[09/26 08:30:55 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1686, average loss: 33.5303
[09/26 08:30:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:30:55 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:31:02 visual_prompt]: Epoch 70 / 100: avg data time: 5.40e-02, avg batch time: 0.5022, average train loss: 29.0001
[09/26 08:31:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 21.2021
[09/26 08:31:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 08:31:04 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:31:11 visual_prompt]: Epoch 71 / 100: avg data time: 5.85e-02, avg batch time: 0.5060, average train loss: 21.8731
[09/26 08:31:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 24.3272
[09/26 08:31:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:31:12 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:31:19 visual_prompt]: Epoch 72 / 100: avg data time: 5.68e-02, avg batch time: 0.5387, average train loss: 20.1975
[09/26 08:31:21 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1690, average loss: 22.5251
[09/26 08:31:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.50	
[09/26 08:31:21 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:31:28 visual_prompt]: Epoch 73 / 100: avg data time: 4.22e-02, avg batch time: 0.4918, average train loss: 19.7426
[09/26 08:31:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1690, average loss: 26.3593
[09/26 08:31:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:31:29 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:31:36 visual_prompt]: Epoch 74 / 100: avg data time: 5.89e-02, avg batch time: 0.5065, average train loss: 21.6002
[09/26 08:31:37 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1689, average loss: 24.9322
[09/26 08:31:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 08:31:37 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:31:44 visual_prompt]: Epoch 75 / 100: avg data time: 4.96e-02, avg batch time: 0.4992, average train loss: 20.2731
[09/26 08:31:46 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1689, average loss: 15.1951
[09/26 08:31:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:31:46 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:31:53 visual_prompt]: Epoch 76 / 100: avg data time: 5.28e-02, avg batch time: 0.5012, average train loss: 13.4848
[09/26 08:31:54 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 10.9650
[09/26 08:31:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 08:31:54 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:32:01 visual_prompt]: Epoch 77 / 100: avg data time: 4.76e-02, avg batch time: 0.4978, average train loss: 15.7209
[09/26 08:32:02 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1693, average loss: 12.2062
[09/26 08:32:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.50	
[09/26 08:32:02 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:32:09 visual_prompt]: Epoch 78 / 100: avg data time: 5.77e-02, avg batch time: 0.5056, average train loss: 13.3626
[09/26 08:32:11 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1692, average loss: 13.1298
[09/26 08:32:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:32:11 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 08:32:17 visual_prompt]: Epoch 79 / 100: avg data time: 5.48e-02, avg batch time: 0.5025, average train loss: 11.2482
[09/26 08:32:19 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1694, average loss: 6.4648
[09/26 08:32:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:32:19 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 08:32:26 visual_prompt]: Epoch 80 / 100: avg data time: 5.24e-02, avg batch time: 0.5021, average train loss: 7.1897
[09/26 08:32:27 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1692, average loss: 8.1768
[09/26 08:32:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 08:32:27 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 08:32:34 visual_prompt]: Epoch 81 / 100: avg data time: 5.56e-02, avg batch time: 0.5043, average train loss: 8.2381
[09/26 08:32:35 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 5.7916
[09/26 08:32:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 32.00	
[09/26 08:32:35 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 08:32:42 visual_prompt]: Epoch 82 / 100: avg data time: 5.58e-02, avg batch time: 0.5039, average train loss: 6.1780
[09/26 08:32:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1693, average loss: 8.3320
[09/26 08:32:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:32:44 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 08:32:50 visual_prompt]: Epoch 83 / 100: avg data time: 5.45e-02, avg batch time: 0.5040, average train loss: 8.1509
[09/26 08:32:52 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1695, average loss: 7.1469
[09/26 08:32:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 36.00	
[09/26 08:32:52 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 08:32:59 visual_prompt]: Epoch 84 / 100: avg data time: 5.82e-02, avg batch time: 0.5080, average train loss: 8.2902
[09/26 08:33:00 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 6.7777
[09/26 08:33:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 08:33:00 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 08:33:07 visual_prompt]: Epoch 85 / 100: avg data time: 5.06e-02, avg batch time: 0.5000, average train loss: 7.5653
[09/26 08:33:09 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1695, average loss: 5.1589
[09/26 08:33:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:33:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 08:33:15 visual_prompt]: Epoch 86 / 100: avg data time: 4.42e-02, avg batch time: 0.4932, average train loss: 5.0091
[09/26 08:33:17 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1693, average loss: 4.1814
[09/26 08:33:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:33:17 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 08:33:24 visual_prompt]: Epoch 87 / 100: avg data time: 6.05e-02, avg batch time: 0.5088, average train loss: 3.7810
[09/26 08:33:25 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1696, average loss: 3.2397
[09/26 08:33:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:33:25 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 08:33:32 visual_prompt]: Epoch 88 / 100: avg data time: 4.46e-02, avg batch time: 0.4959, average train loss: 3.2584
[09/26 08:33:33 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 3.1119
[09/26 08:33:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:33:33 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 08:33:40 visual_prompt]: Epoch 89 / 100: avg data time: 5.12e-02, avg batch time: 0.4988, average train loss: 3.0607
[09/26 08:33:42 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 2.9717
[09/26 08:33:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 08:33:42 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 08:33:48 visual_prompt]: Epoch 90 / 100: avg data time: 4.16e-02, avg batch time: 0.4927, average train loss: 3.0718
[09/26 08:33:50 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1693, average loss: 2.9520
[09/26 08:33:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 08:33:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 08:33:57 visual_prompt]: Epoch 91 / 100: avg data time: 5.49e-02, avg batch time: 0.5043, average train loss: 2.9979
[09/26 08:33:58 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1690, average loss: 2.9639
[09/26 08:33:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 08:33:58 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 08:34:05 visual_prompt]: Epoch 92 / 100: avg data time: 5.52e-02, avg batch time: 0.5049, average train loss: 2.9825
[09/26 08:34:07 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1690, average loss: 2.9648
[09/26 08:34:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 08:34:07 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 08:34:13 visual_prompt]: Epoch 93 / 100: avg data time: 4.99e-02, avg batch time: 0.4998, average train loss: 2.9417
[09/26 08:34:15 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1694, average loss: 2.9053
[09/26 08:34:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 08:34:15 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 08:34:22 visual_prompt]: Epoch 94 / 100: avg data time: 5.26e-02, avg batch time: 0.5007, average train loss: 2.9198
[09/26 08:34:23 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1693, average loss: 2.9045
[09/26 08:34:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 08:34:23 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 08:34:30 visual_prompt]: Epoch 95 / 100: avg data time: 4.32e-02, avg batch time: 0.4921, average train loss: 2.9347
[09/26 08:34:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1693, average loss: 2.9064
[09/26 08:34:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 08:34:31 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 08:34:38 visual_prompt]: Epoch 96 / 100: avg data time: 4.26e-02, avg batch time: 0.4931, average train loss: 2.9070
[09/26 08:34:40 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1694, average loss: 2.9017
[09/26 08:34:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 08:34:40 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 08:34:47 visual_prompt]: Epoch 97 / 100: avg data time: 5.83e-02, avg batch time: 0.5069, average train loss: 2.8976
[09/26 08:34:48 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1692, average loss: 2.9057
[09/26 08:34:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:34:48 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 08:34:55 visual_prompt]: Epoch 98 / 100: avg data time: 5.27e-02, avg batch time: 0.5028, average train loss: 2.8868
[09/26 08:34:56 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1692, average loss: 2.9017
[09/26 08:34:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 08:34:56 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 08:35:03 visual_prompt]: Epoch 99 / 100: avg data time: 5.51e-02, avg batch time: 0.5039, average train loss: 2.8825
[09/26 08:35:05 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1696, average loss: 2.8984
[09/26 08:35:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:35:05 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 08:35:12 visual_prompt]: Epoch 100 / 100: avg data time: 5.67e-02, avg batch time: 0.5061, average train loss: 2.8796
[09/26 08:35:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1690, average loss: 2.8996
[09/26 08:35:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 08:35:13 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:35:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:35:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:35:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:35:13 visual_prompt]: Training with config:
[09/26 08:35:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:35:13 visual_prompt]: Loading training data...
[09/26 08:35:13 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:35:14 visual_prompt]: Number of images: 800
[09/26 08:35:14 visual_prompt]: Number of classes: 18 / 18
[09/26 08:35:14 visual_prompt]: Loading validation data...
[09/26 08:35:14 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:35:15 visual_prompt]: Number of images: 200
[09/26 08:35:15 visual_prompt]: Number of classes: 18 / 18
[09/26 08:35:15 visual_prompt]: Constructing models...
[09/26 08:35:17 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 08:35:17 visual_prompt]: tuned percent:0.550
[09/26 08:35:17 visual_prompt]: Device used for model: 0
[09/26 08:35:17 visual_prompt]: Setting up Evaluator...
[09/26 08:35:17 visual_prompt]: Setting up Trainer...
[09/26 08:35:17 visual_prompt]: 	Setting up the optimizer...
[09/26 08:35:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:35:24 visual_prompt]: Epoch 1 / 100: avg data time: 4.20e-02, avg batch time: 0.4890, average train loss: 3.2468
[09/26 08:35:25 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1689, average loss: 3.1895
[09/26 08:35:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 08:35:25 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 08:35:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:35:32 visual_prompt]: Epoch 2 / 100: avg data time: 5.32e-02, avg batch time: 0.5025, average train loss: 10.4590
[09/26 08:35:34 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1689, average loss: 9.5994
[09/26 08:35:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:35:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:35:40 visual_prompt]: Epoch 3 / 100: avg data time: 4.54e-02, avg batch time: 0.4928, average train loss: 9.7753
[09/26 08:35:42 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1683, average loss: 14.2620
[09/26 08:35:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 08:35:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:35:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.04e-02, avg batch time: 0.4977, average train loss: 28.0095
[09/26 08:35:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 27.3463
[09/26 08:35:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.50	
[09/26 08:35:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:35:57 visual_prompt]: Epoch 5 / 100: avg data time: 6.20e-02, avg batch time: 0.5087, average train loss: 41.2362
[09/26 08:35:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1691, average loss: 82.8189
[09/26 08:35:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 08:35:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:36:05 visual_prompt]: Epoch 6 / 100: avg data time: 5.09e-02, avg batch time: 0.4984, average train loss: 114.8558
[09/26 08:36:07 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1686, average loss: 100.3615
[09/26 08:36:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 08:36:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:36:13 visual_prompt]: Epoch 7 / 100: avg data time: 5.12e-02, avg batch time: 0.4982, average train loss: 92.0563
[09/26 08:36:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1689, average loss: 82.1658
[09/26 08:36:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.50	
[09/26 08:36:15 visual_prompt]: Best epoch 7: best metric: 0.065
[09/26 08:36:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:36:22 visual_prompt]: Epoch 8 / 100: avg data time: 5.83e-02, avg batch time: 0.5053, average train loss: 93.4940
[09/26 08:36:23 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 96.2452
[09/26 08:36:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 08:36:23 visual_prompt]: Best epoch 8: best metric: 0.085
[09/26 08:36:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:36:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.15e-02, avg batch time: 0.4906, average train loss: 101.8424
[09/26 08:36:31 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1694, average loss: 72.2803
[09/26 08:36:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 31.00	
[09/26 08:36:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:36:38 visual_prompt]: Epoch 10 / 100: avg data time: 4.38e-02, avg batch time: 0.4927, average train loss: 117.6058
[09/26 08:36:40 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 77.2295
[09/26 08:36:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 08:36:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:36:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.26e-02, avg batch time: 0.5005, average train loss: 130.9985
[09/26 08:36:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 119.3327
[09/26 08:36:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:36:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:36:55 visual_prompt]: Epoch 12 / 100: avg data time: 5.55e-02, avg batch time: 0.5040, average train loss: 152.8110
[09/26 08:36:56 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1694, average loss: 146.0438
[09/26 08:36:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 08:36:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:37:03 visual_prompt]: Epoch 13 / 100: avg data time: 5.57e-02, avg batch time: 0.5058, average train loss: 161.9415
[09/26 08:37:05 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1692, average loss: 115.9994
[09/26 08:37:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.00	
[09/26 08:37:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:37:11 visual_prompt]: Epoch 14 / 100: avg data time: 5.36e-02, avg batch time: 0.5022, average train loss: 154.7363
[09/26 08:37:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1696, average loss: 80.4041
[09/26 08:37:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 08:37:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:37:20 visual_prompt]: Epoch 15 / 100: avg data time: 5.24e-02, avg batch time: 0.5012, average train loss: 139.4510
[09/26 08:37:21 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1690, average loss: 110.7252
[09/26 08:37:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 08:37:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:37:28 visual_prompt]: Epoch 16 / 100: avg data time: 6.44e-02, avg batch time: 0.5124, average train loss: 117.7720
[09/26 08:37:30 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1692, average loss: 135.6043
[09/26 08:37:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 08:37:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:37:37 visual_prompt]: Epoch 17 / 100: avg data time: 4.13e-02, avg batch time: 0.4905, average train loss: 112.5352
[09/26 08:37:38 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1694, average loss: 148.7526
[09/26 08:37:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:37:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:37:45 visual_prompt]: Epoch 18 / 100: avg data time: 6.24e-02, avg batch time: 0.5105, average train loss: 180.7721
[09/26 08:37:46 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1691, average loss: 196.7398
[09/26 08:37:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:37:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:37:53 visual_prompt]: Epoch 19 / 100: avg data time: 5.75e-02, avg batch time: 0.5054, average train loss: 129.4330
[09/26 08:37:55 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 149.3937
[09/26 08:37:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 08:37:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:38:01 visual_prompt]: Epoch 20 / 100: avg data time: 4.57e-02, avg batch time: 0.4967, average train loss: 137.8207
[09/26 08:38:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1693, average loss: 113.6662
[09/26 08:38:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:38:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:38:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.47e-02, avg batch time: 0.5037, average train loss: 97.6124
[09/26 08:38:11 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1688, average loss: 115.8818
[09/26 08:38:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 08:38:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:38:18 visual_prompt]: Epoch 22 / 100: avg data time: 5.15e-02, avg batch time: 0.5000, average train loss: 152.2333
[09/26 08:38:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 100.1287
[09/26 08:38:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 08:38:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:38:26 visual_prompt]: Epoch 23 / 100: avg data time: 4.99e-02, avg batch time: 0.4982, average train loss: 137.6024
[09/26 08:38:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1689, average loss: 137.0038
[09/26 08:38:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 08:38:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:38:34 visual_prompt]: Epoch 24 / 100: avg data time: 4.24e-02, avg batch time: 0.4911, average train loss: 119.3763
[09/26 08:38:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1693, average loss: 108.7798
[09/26 08:38:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 08:38:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:38:43 visual_prompt]: Epoch 25 / 100: avg data time: 4.57e-02, avg batch time: 0.4955, average train loss: 147.2172
[09/26 08:38:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1693, average loss: 157.5900
[09/26 08:38:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 08:38:44 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:38:51 visual_prompt]: Epoch 26 / 100: avg data time: 5.05e-02, avg batch time: 0.4996, average train loss: 137.4566
[09/26 08:38:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1690, average loss: 120.6771
[09/26 08:38:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 08:38:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:38:59 visual_prompt]: Epoch 27 / 100: avg data time: 5.32e-02, avg batch time: 0.5018, average train loss: 81.4323
[09/26 08:39:01 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1697, average loss: 63.2956
[09/26 08:39:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.00	
[09/26 08:39:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:39:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.42e-02, avg batch time: 0.4925, average train loss: 100.1749
[09/26 08:39:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 145.3387
[09/26 08:39:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 08:39:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:39:16 visual_prompt]: Epoch 29 / 100: avg data time: 5.11e-02, avg batch time: 0.5004, average train loss: 134.3478
[09/26 08:39:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1688, average loss: 171.8479
[09/26 08:39:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:39:17 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:39:24 visual_prompt]: Epoch 30 / 100: avg data time: 4.54e-02, avg batch time: 0.4954, average train loss: 138.3200
[09/26 08:39:25 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 175.4337
[09/26 08:39:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:39:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:39:32 visual_prompt]: Epoch 31 / 100: avg data time: 5.01e-02, avg batch time: 0.4982, average train loss: 121.7220
[09/26 08:39:34 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1693, average loss: 108.3107
[09/26 08:39:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:39:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:39:40 visual_prompt]: Epoch 32 / 100: avg data time: 5.71e-02, avg batch time: 0.5067, average train loss: 142.0668
[09/26 08:39:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 123.6237
[09/26 08:39:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 08:39:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:39:49 visual_prompt]: Epoch 33 / 100: avg data time: 4.85e-02, avg batch time: 0.4975, average train loss: 124.5794
[09/26 08:39:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 105.5434
[09/26 08:39:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 08:39:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:39:57 visual_prompt]: Epoch 34 / 100: avg data time: 4.26e-02, avg batch time: 0.4919, average train loss: 107.5794
[09/26 08:39:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1693, average loss: 190.1807
[09/26 08:39:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 08:39:58 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:40:05 visual_prompt]: Epoch 35 / 100: avg data time: 4.51e-02, avg batch time: 0.4959, average train loss: 133.5757
[09/26 08:40:06 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1697, average loss: 105.2721
[09/26 08:40:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 08:40:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:40:13 visual_prompt]: Epoch 36 / 100: avg data time: 5.84e-02, avg batch time: 0.5075, average train loss: 124.4842
[09/26 08:40:15 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1686, average loss: 73.2599
[09/26 08:40:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 08:40:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:40:21 visual_prompt]: Epoch 37 / 100: avg data time: 5.51e-02, avg batch time: 0.5033, average train loss: 110.4033
[09/26 08:40:23 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1698, average loss: 91.6074
[09/26 08:40:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 08:40:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:40:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.19e-02, avg batch time: 0.4915, average train loss: 96.6793
[09/26 08:40:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 105.8732
[09/26 08:40:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 08:40:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:40:38 visual_prompt]: Epoch 39 / 100: avg data time: 4.83e-02, avg batch time: 0.4968, average train loss: 105.0180
[09/26 08:40:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 149.6771
[09/26 08:40:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:40:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:40:46 visual_prompt]: Epoch 40 / 100: avg data time: 4.10e-02, avg batch time: 0.4901, average train loss: 137.2461
[09/26 08:40:47 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 129.7259
[09/26 08:40:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 08:40:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:40:54 visual_prompt]: Epoch 41 / 100: avg data time: 5.24e-02, avg batch time: 0.5010, average train loss: 89.3495
[09/26 08:40:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1690, average loss: 126.3753
[09/26 08:40:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 08:40:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:41:02 visual_prompt]: Epoch 42 / 100: avg data time: 5.19e-02, avg batch time: 0.5000, average train loss: 119.4281
[09/26 08:41:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 95.8536
[09/26 08:41:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 08:41:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:41:11 visual_prompt]: Epoch 43 / 100: avg data time: 4.91e-02, avg batch time: 0.4974, average train loss: 85.7107
[09/26 08:41:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1699, average loss: 129.6636
[09/26 08:41:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 08:41:12 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:41:19 visual_prompt]: Epoch 44 / 100: avg data time: 5.10e-02, avg batch time: 0.4995, average train loss: 128.4969
[09/26 08:41:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 67.8153
[09/26 08:41:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 08:41:20 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:41:27 visual_prompt]: Epoch 45 / 100: avg data time: 5.32e-02, avg batch time: 0.5024, average train loss: 104.8989
[09/26 08:41:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 133.7216
[09/26 08:41:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:41:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:41:35 visual_prompt]: Epoch 46 / 100: avg data time: 4.32e-02, avg batch time: 0.4933, average train loss: 114.1799
[09/26 08:41:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1694, average loss: 99.5775
[09/26 08:41:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:41:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:41:43 visual_prompt]: Epoch 47 / 100: avg data time: 4.25e-02, avg batch time: 0.4931, average train loss: 89.0358
[09/26 08:41:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1691, average loss: 108.3880
[09/26 08:41:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 24.50	
[09/26 08:41:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:41:52 visual_prompt]: Epoch 48 / 100: avg data time: 4.78e-02, avg batch time: 0.4993, average train loss: 82.0970
[09/26 08:41:53 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1689, average loss: 87.0313
[09/26 08:41:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.00	
[09/26 08:41:53 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:42:00 visual_prompt]: Epoch 49 / 100: avg data time: 4.66e-02, avg batch time: 0.4971, average train loss: 117.6518
[09/26 08:42:01 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1691, average loss: 98.4171
[09/26 08:42:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 08:42:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:42:08 visual_prompt]: Epoch 50 / 100: avg data time: 5.08e-02, avg batch time: 0.4999, average train loss: 121.6247
[09/26 08:42:10 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 117.4571
[09/26 08:42:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 08:42:10 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:42:16 visual_prompt]: Epoch 51 / 100: avg data time: 6.05e-02, avg batch time: 0.5098, average train loss: 142.1009
[09/26 08:42:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 182.7637
[09/26 08:42:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 08:42:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:42:25 visual_prompt]: Epoch 52 / 100: avg data time: 5.56e-02, avg batch time: 0.5043, average train loss: 116.1005
[09/26 08:42:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 93.3798
[09/26 08:42:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 08:42:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:42:33 visual_prompt]: Epoch 53 / 100: avg data time: 4.92e-02, avg batch time: 0.4990, average train loss: 84.5190
[09/26 08:42:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 73.2339
[09/26 08:42:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 08:42:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:42:41 visual_prompt]: Epoch 54 / 100: avg data time: 4.88e-02, avg batch time: 0.5000, average train loss: 101.2291
[09/26 08:42:43 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 71.1649
[09/26 08:42:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.50	
[09/26 08:42:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:42:49 visual_prompt]: Epoch 55 / 100: avg data time: 4.75e-02, avg batch time: 0.4979, average train loss: 66.2394
[09/26 08:42:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 79.4987
[09/26 08:42:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.00	
[09/26 08:42:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:42:58 visual_prompt]: Epoch 56 / 100: avg data time: 5.09e-02, avg batch time: 0.5013, average train loss: 64.7100
[09/26 08:42:59 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1687, average loss: 44.8511
[09/26 08:42:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 08:42:59 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:43:06 visual_prompt]: Epoch 57 / 100: avg data time: 5.24e-02, avg batch time: 0.5000, average train loss: 73.3403
[09/26 08:43:08 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 54.6312
[09/26 08:43:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 08:43:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:43:14 visual_prompt]: Epoch 58 / 100: avg data time: 4.67e-02, avg batch time: 0.4959, average train loss: 81.7950
[09/26 08:43:16 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1700, average loss: 95.6618
[09/26 08:43:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:43:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:43:22 visual_prompt]: Epoch 59 / 100: avg data time: 4.38e-02, avg batch time: 0.4939, average train loss: 67.4301
[09/26 08:43:24 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 84.0674
[09/26 08:43:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 08:43:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:43:30 visual_prompt]: Epoch 60 / 100: avg data time: 4.66e-02, avg batch time: 0.4972, average train loss: 65.3961
[09/26 08:43:32 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1690, average loss: 62.6861
[09/26 08:43:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:43:32 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:43:39 visual_prompt]: Epoch 61 / 100: avg data time: 4.16e-02, avg batch time: 0.4912, average train loss: 56.3851
[09/26 08:43:40 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1694, average loss: 60.2343
[09/26 08:43:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:43:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:43:47 visual_prompt]: Epoch 62 / 100: avg data time: 5.30e-02, avg batch time: 0.5030, average train loss: 40.5413
[09/26 08:43:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 60.7100
[09/26 08:43:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 08:43:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:43:55 visual_prompt]: Epoch 63 / 100: avg data time: 5.75e-02, avg batch time: 0.5061, average train loss: 53.0891
[09/26 08:43:57 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1687, average loss: 48.7050
[09/26 08:43:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.50	
[09/26 08:43:57 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:44:03 visual_prompt]: Epoch 64 / 100: avg data time: 4.20e-02, avg batch time: 0.4926, average train loss: 47.5925
[09/26 08:44:05 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 55.0049
[09/26 08:44:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:44:05 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:44:12 visual_prompt]: Epoch 65 / 100: avg data time: 5.44e-02, avg batch time: 0.5021, average train loss: 55.1587
[09/26 08:44:13 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 44.9686
[09/26 08:44:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 08:44:13 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:44:20 visual_prompt]: Epoch 66 / 100: avg data time: 4.62e-02, avg batch time: 0.4956, average train loss: 41.8662
[09/26 08:44:21 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1696, average loss: 43.7752
[09/26 08:44:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:44:21 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:44:28 visual_prompt]: Epoch 67 / 100: avg data time: 5.57e-02, avg batch time: 0.5048, average train loss: 41.9280
[09/26 08:44:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 42.1596
[09/26 08:44:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 08:44:30 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:44:36 visual_prompt]: Epoch 68 / 100: avg data time: 4.29e-02, avg batch time: 0.4934, average train loss: 40.5563
[09/26 08:44:38 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1689, average loss: 48.9968
[09/26 08:44:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 08:44:38 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:44:45 visual_prompt]: Epoch 69 / 100: avg data time: 5.95e-02, avg batch time: 0.5076, average train loss: 30.3596
[09/26 08:44:46 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1695, average loss: 30.8244
[09/26 08:44:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 08:44:46 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:44:53 visual_prompt]: Epoch 70 / 100: avg data time: 5.05e-02, avg batch time: 0.4999, average train loss: 49.6455
[09/26 08:44:55 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1691, average loss: 42.8852
[09/26 08:44:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 08:44:55 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:45:01 visual_prompt]: Epoch 71 / 100: avg data time: 5.51e-02, avg batch time: 0.5040, average train loss: 36.2039
[09/26 08:45:03 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1694, average loss: 34.3630
[09/26 08:45:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:45:03 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:45:10 visual_prompt]: Epoch 72 / 100: avg data time: 5.82e-02, avg batch time: 0.5071, average train loss: 37.7924
[09/26 08:45:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1688, average loss: 47.1249
[09/26 08:45:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:45:11 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:45:18 visual_prompt]: Epoch 73 / 100: avg data time: 5.37e-02, avg batch time: 0.5016, average train loss: 36.5631
[09/26 08:45:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1691, average loss: 23.0864
[09/26 08:45:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 08:45:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:45:26 visual_prompt]: Epoch 74 / 100: avg data time: 5.58e-02, avg batch time: 0.5037, average train loss: 27.6724
[09/26 08:45:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 14.5581
[09/26 08:45:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 08:45:28 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:45:35 visual_prompt]: Epoch 75 / 100: avg data time: 4.44e-02, avg batch time: 0.4936, average train loss: 18.7906
[09/26 08:45:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1694, average loss: 21.3984
[09/26 08:45:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:45:36 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:45:43 visual_prompt]: Epoch 76 / 100: avg data time: 5.56e-02, avg batch time: 0.5041, average train loss: 17.6849
[09/26 08:45:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1687, average loss: 13.9905
[09/26 08:45:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:45:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:45:51 visual_prompt]: Epoch 77 / 100: avg data time: 5.67e-02, avg batch time: 0.5051, average train loss: 23.1352
[09/26 08:45:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 20.0176
[09/26 08:45:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 08:45:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:46:00 visual_prompt]: Epoch 78 / 100: avg data time: 5.21e-02, avg batch time: 0.5002, average train loss: 16.0885
[09/26 08:46:01 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1689, average loss: 13.7363
[09/26 08:46:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 08:46:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 08:46:08 visual_prompt]: Epoch 79 / 100: avg data time: 6.08e-02, avg batch time: 0.5095, average train loss: 9.2786
[09/26 08:46:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1697, average loss: 5.3241
[09/26 08:46:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 08:46:09 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 08:46:16 visual_prompt]: Epoch 80 / 100: avg data time: 4.59e-02, avg batch time: 0.4944, average train loss: 5.4443
[09/26 08:46:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1695, average loss: 4.6497
[09/26 08:46:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 08:46:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 08:46:24 visual_prompt]: Epoch 81 / 100: avg data time: 4.13e-02, avg batch time: 0.4921, average train loss: 4.1756
[09/26 08:46:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1695, average loss: 3.7658
[09/26 08:46:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 23.50	
[09/26 08:46:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 08:46:32 visual_prompt]: Epoch 82 / 100: avg data time: 4.89e-02, avg batch time: 0.4986, average train loss: 3.5445
[09/26 08:46:34 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1696, average loss: 3.6929
[09/26 08:46:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:46:34 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 08:46:41 visual_prompt]: Epoch 83 / 100: avg data time: 5.74e-02, avg batch time: 0.5054, average train loss: 3.3314
[09/26 08:46:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 3.1718
[09/26 08:46:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 08:46:42 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 08:46:49 visual_prompt]: Epoch 84 / 100: avg data time: 5.20e-02, avg batch time: 0.5005, average train loss: 3.1214
[09/26 08:46:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1691, average loss: 3.1363
[09/26 08:46:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.00	
[09/26 08:46:50 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 08:46:57 visual_prompt]: Epoch 85 / 100: avg data time: 5.21e-02, avg batch time: 0.5006, average train loss: 3.1645
[09/26 08:46:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1695, average loss: 2.9292
[09/26 08:46:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 08:46:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 08:47:06 visual_prompt]: Epoch 86 / 100: avg data time: 4.79e-02, avg batch time: 0.4987, average train loss: 2.9980
[09/26 08:47:07 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1692, average loss: 3.0942
[09/26 08:47:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.50	
[09/26 08:47:07 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 08:47:14 visual_prompt]: Epoch 87 / 100: avg data time: 6.03e-02, avg batch time: 0.5085, average train loss: 3.0294
[09/26 08:47:15 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.1692, average loss: 3.1147
[09/26 08:47:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 08:47:15 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 08:47:22 visual_prompt]: Epoch 88 / 100: avg data time: 5.80e-02, avg batch time: 0.5067, average train loss: 3.0439
[09/26 08:47:24 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 3.0082
[09/26 08:47:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 08:47:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 08:47:31 visual_prompt]: Epoch 89 / 100: avg data time: 4.15e-02, avg batch time: 0.4912, average train loss: 2.9772
[09/26 08:47:32 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1697, average loss: 3.0258
[09/26 08:47:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 08:47:32 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 08:47:39 visual_prompt]: Epoch 90 / 100: avg data time: 5.26e-02, avg batch time: 0.5015, average train loss: 2.9814
[09/26 08:47:40 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 3.0404
[09/26 08:47:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.50	
[09/26 08:47:40 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 08:47:47 visual_prompt]: Epoch 91 / 100: avg data time: 5.40e-02, avg batch time: 0.5040, average train loss: 2.9384
[09/26 08:47:49 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1695, average loss: 2.9196
[09/26 08:47:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 34.50	
[09/26 08:47:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 08:47:56 visual_prompt]: Epoch 92 / 100: avg data time: 6.15e-02, avg batch time: 0.5113, average train loss: 2.9520
[09/26 08:47:57 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 3.0008
[09/26 08:47:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 08:47:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 08:48:04 visual_prompt]: Epoch 93 / 100: avg data time: 5.41e-02, avg batch time: 0.5022, average train loss: 2.9394
[09/26 08:48:05 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1689, average loss: 2.9599
[09/26 08:48:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 08:48:05 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 08:48:12 visual_prompt]: Epoch 94 / 100: avg data time: 6.23e-02, avg batch time: 0.5113, average train loss: 2.9307
[09/26 08:48:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1692, average loss: 2.9203
[09/26 08:48:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 08:48:14 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 08:48:21 visual_prompt]: Epoch 95 / 100: avg data time: 5.39e-02, avg batch time: 0.5034, average train loss: 2.9080
[09/26 08:48:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1696, average loss: 2.9217
[09/26 08:48:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 26.50	
[09/26 08:48:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 08:48:29 visual_prompt]: Epoch 96 / 100: avg data time: 4.76e-02, avg batch time: 0.4973, average train loss: 2.8908
[09/26 08:48:31 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1694, average loss: 2.9095
[09/26 08:48:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 28.00	
[09/26 08:48:31 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 08:48:37 visual_prompt]: Epoch 97 / 100: avg data time: 4.92e-02, avg batch time: 0.4986, average train loss: 2.8889
[09/26 08:48:39 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1694, average loss: 2.9008
[09/26 08:48:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 08:48:39 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 08:48:46 visual_prompt]: Epoch 98 / 100: avg data time: 4.97e-02, avg batch time: 0.4989, average train loss: 2.8750
[09/26 08:48:47 visual_prompt]: Inference (val):avg data time: 4.97e-05, avg batch time: 0.1692, average loss: 2.9027
[09/26 08:48:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 08:48:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 08:48:54 visual_prompt]: Epoch 99 / 100: avg data time: 5.87e-02, avg batch time: 0.5067, average train loss: 2.8755
[09/26 08:48:55 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1694, average loss: 2.9063
[09/26 08:48:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 27.00	
[09/26 08:48:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 08:49:02 visual_prompt]: Epoch 100 / 100: avg data time: 5.40e-02, avg batch time: 0.5021, average train loss: 2.8734
[09/26 08:49:04 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1695, average loss: 2.9051
[09/26 08:49:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 08:49:04 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:49:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:49:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:49:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:49:04 visual_prompt]: Training with config:
[09/26 08:49:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:49:04 visual_prompt]: Loading training data...
[09/26 08:49:04 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:49:05 visual_prompt]: Number of images: 800
[09/26 08:49:05 visual_prompt]: Number of classes: 18 / 18
[09/26 08:49:05 visual_prompt]: Loading validation data...
[09/26 08:49:05 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 08:49:05 visual_prompt]: Number of images: 200
[09/26 08:49:05 visual_prompt]: Number of classes: 18 / 18
[09/26 08:49:05 visual_prompt]: Constructing models...
[09/26 08:49:08 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 08:49:08 visual_prompt]: tuned percent:0.550
[09/26 08:49:08 visual_prompt]: Device used for model: 0
[09/26 08:49:08 visual_prompt]: Setting up Evaluator...
[09/26 08:49:08 visual_prompt]: Setting up Trainer...
[09/26 08:49:08 visual_prompt]: 	Setting up the optimizer...
[09/26 08:49:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:49:15 visual_prompt]: Epoch 1 / 100: avg data time: 5.57e-02, avg batch time: 0.5036, average train loss: 3.2519
[09/26 08:49:16 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1686, average loss: 3.1895
[09/26 08:49:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 08:49:16 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 08:49:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:49:23 visual_prompt]: Epoch 2 / 100: avg data time: 5.79e-02, avg batch time: 0.5053, average train loss: 7.2794
[09/26 08:49:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1687, average loss: 10.3074
[09/26 08:49:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:49:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:49:31 visual_prompt]: Epoch 3 / 100: avg data time: 5.64e-02, avg batch time: 0.5032, average train loss: 14.7686
[09/26 08:49:33 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 22.9491
[09/26 08:49:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 08:49:33 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:49:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.96e-02, avg batch time: 0.5078, average train loss: 32.1161
[09/26 08:49:41 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1687, average loss: 53.9334
[09/26 08:49:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 08:49:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:49:48 visual_prompt]: Epoch 5 / 100: avg data time: 5.36e-02, avg batch time: 0.5016, average train loss: 54.4656
[09/26 08:49:49 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 50.9718
[09/26 08:49:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 08:49:49 visual_prompt]: Best epoch 5: best metric: 0.065
[09/26 08:49:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:49:56 visual_prompt]: Epoch 6 / 100: avg data time: 5.67e-02, avg batch time: 0.5049, average train loss: 74.6531
[09/26 08:49:58 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1687, average loss: 76.7763
[09/26 08:49:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:49:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:50:05 visual_prompt]: Epoch 7 / 100: avg data time: 5.83e-02, avg batch time: 0.5068, average train loss: 84.9883
[09/26 08:50:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 98.0715
[09/26 08:50:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 08:50:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:50:13 visual_prompt]: Epoch 8 / 100: avg data time: 5.64e-02, avg batch time: 0.5044, average train loss: 99.9513
[09/26 08:50:14 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1687, average loss: 118.2862
[09/26 08:50:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 08:50:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:50:21 visual_prompt]: Epoch 9 / 100: avg data time: 5.67e-02, avg batch time: 0.5045, average train loss: 121.4769
[09/26 08:50:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 99.8984
[09/26 08:50:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 08:50:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:50:29 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e-02, avg batch time: 0.4971, average train loss: 129.7145
[09/26 08:50:31 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 67.6013
[09/26 08:50:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:50:31 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:50:38 visual_prompt]: Epoch 11 / 100: avg data time: 5.51e-02, avg batch time: 0.5035, average train loss: 120.3324
[09/26 08:50:39 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1690, average loss: 152.2587
[09/26 08:50:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 08:50:39 visual_prompt]: Best epoch 11: best metric: 0.070
[09/26 08:50:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:50:46 visual_prompt]: Epoch 12 / 100: avg data time: 4.24e-02, avg batch time: 0.4906, average train loss: 149.9869
[09/26 08:50:47 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1693, average loss: 89.2097
[09/26 08:50:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 08:50:47 visual_prompt]: Best epoch 12: best metric: 0.085
[09/26 08:50:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:50:54 visual_prompt]: Epoch 13 / 100: avg data time: 5.07e-02, avg batch time: 0.5001, average train loss: 111.6068
[09/26 08:50:55 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1690, average loss: 121.6957
[09/26 08:50:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 08:50:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:51:02 visual_prompt]: Epoch 14 / 100: avg data time: 4.33e-02, avg batch time: 0.4918, average train loss: 144.8333
[09/26 08:51:03 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 129.5805
[09/26 08:51:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.00	
[09/26 08:51:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:51:10 visual_prompt]: Epoch 15 / 100: avg data time: 5.83e-02, avg batch time: 0.5058, average train loss: 164.5096
[09/26 08:51:12 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1688, average loss: 179.6944
[09/26 08:51:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 08:51:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:51:18 visual_prompt]: Epoch 16 / 100: avg data time: 4.48e-02, avg batch time: 0.4959, average train loss: 128.4217
[09/26 08:51:20 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1692, average loss: 150.2762
[09/26 08:51:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:51:20 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:51:27 visual_prompt]: Epoch 17 / 100: avg data time: 4.84e-02, avg batch time: 0.4976, average train loss: 150.5891
[09/26 08:51:28 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 132.2211
[09/26 08:51:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:51:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:51:35 visual_prompt]: Epoch 18 / 100: avg data time: 5.05e-02, avg batch time: 0.4979, average train loss: 137.0205
[09/26 08:51:36 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1691, average loss: 124.7258
[09/26 08:51:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:51:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:51:43 visual_prompt]: Epoch 19 / 100: avg data time: 3.89e-02, avg batch time: 0.4887, average train loss: 109.6817
[09/26 08:51:45 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1690, average loss: 83.8340
[09/26 08:51:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 08:51:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:51:51 visual_prompt]: Epoch 20 / 100: avg data time: 4.72e-02, avg batch time: 0.4969, average train loss: 86.9740
[09/26 08:51:53 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1691, average loss: 131.8998
[09/26 08:51:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 08:51:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:52:00 visual_prompt]: Epoch 21 / 100: avg data time: 4.21e-02, avg batch time: 0.4923, average train loss: 107.3115
[09/26 08:52:01 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1691, average loss: 116.3780
[09/26 08:52:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.00	
[09/26 08:52:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:52:08 visual_prompt]: Epoch 22 / 100: avg data time: 5.84e-02, avg batch time: 0.5064, average train loss: 94.9440
[09/26 08:52:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 83.4438
[09/26 08:52:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 08:52:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:52:16 visual_prompt]: Epoch 23 / 100: avg data time: 4.37e-02, avg batch time: 0.4928, average train loss: 87.9397
[09/26 08:52:18 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1689, average loss: 150.7275
[09/26 08:52:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:52:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:52:25 visual_prompt]: Epoch 24 / 100: avg data time: 4.58e-02, avg batch time: 0.4965, average train loss: 148.3325
[09/26 08:52:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 128.4815
[09/26 08:52:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 08:52:26 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:52:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.77e-02, avg batch time: 0.5057, average train loss: 124.1626
[09/26 08:52:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 123.0983
[09/26 08:52:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:52:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:52:41 visual_prompt]: Epoch 26 / 100: avg data time: 4.70e-02, avg batch time: 0.4974, average train loss: 125.9920
[09/26 08:52:43 visual_prompt]: Inference (val):avg data time: 4.48e-05, avg batch time: 0.1693, average loss: 117.4181
[09/26 08:52:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 08:52:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:52:50 visual_prompt]: Epoch 27 / 100: avg data time: 5.53e-02, avg batch time: 0.5040, average train loss: 116.5028
[09/26 08:52:51 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1690, average loss: 98.5768
[09/26 08:52:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:52:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:52:58 visual_prompt]: Epoch 28 / 100: avg data time: 5.07e-02, avg batch time: 0.4984, average train loss: 113.6940
[09/26 08:53:00 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1689, average loss: 118.9374
[09/26 08:53:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 08:53:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:53:06 visual_prompt]: Epoch 29 / 100: avg data time: 5.38e-02, avg batch time: 0.5025, average train loss: 92.8481
[09/26 08:53:08 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1689, average loss: 79.0810
[09/26 08:53:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:53:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:53:15 visual_prompt]: Epoch 30 / 100: avg data time: 4.80e-02, avg batch time: 0.4963, average train loss: 97.7624
[09/26 08:53:16 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1691, average loss: 86.5279
[09/26 08:53:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 08:53:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:53:23 visual_prompt]: Epoch 31 / 100: avg data time: 4.52e-02, avg batch time: 0.4950, average train loss: 90.6208
[09/26 08:53:24 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1694, average loss: 60.7446
[09/26 08:53:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 08:53:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:53:31 visual_prompt]: Epoch 32 / 100: avg data time: 5.31e-02, avg batch time: 0.5025, average train loss: 79.6033
[09/26 08:53:33 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1689, average loss: 133.4091
[09/26 08:53:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 08:53:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:53:40 visual_prompt]: Epoch 33 / 100: avg data time: 5.95e-02, avg batch time: 0.5077, average train loss: 88.2809
[09/26 08:53:41 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1689, average loss: 116.2169
[09/26 08:53:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 08:53:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:53:48 visual_prompt]: Epoch 34 / 100: avg data time: 5.49e-02, avg batch time: 0.5027, average train loss: 130.7948
[09/26 08:53:49 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1692, average loss: 147.2030
[09/26 08:53:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 08:53:49 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:53:56 visual_prompt]: Epoch 35 / 100: avg data time: 6.09e-02, avg batch time: 0.5092, average train loss: 108.2264
[09/26 08:53:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1691, average loss: 70.6745
[09/26 08:53:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 08:53:58 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:54:05 visual_prompt]: Epoch 36 / 100: avg data time: 5.88e-02, avg batch time: 0.5075, average train loss: 117.3921
[09/26 08:54:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1692, average loss: 117.3842
[09/26 08:54:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 08:54:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:54:13 visual_prompt]: Epoch 37 / 100: avg data time: 5.90e-02, avg batch time: 0.5064, average train loss: 104.4694
[09/26 08:54:15 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1686, average loss: 120.2595
[09/26 08:54:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 08:54:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:54:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.74e-02, avg batch time: 0.5053, average train loss: 112.7123
[09/26 08:54:23 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 126.8104
[09/26 08:54:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 08:54:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:54:30 visual_prompt]: Epoch 39 / 100: avg data time: 5.20e-02, avg batch time: 0.5009, average train loss: 86.0106
[09/26 08:54:32 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1694, average loss: 92.1474
[09/26 08:54:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 08:54:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:54:38 visual_prompt]: Epoch 40 / 100: avg data time: 4.53e-02, avg batch time: 0.4954, average train loss: 82.7972
[09/26 08:54:40 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1694, average loss: 57.8197
[09/26 08:54:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:54:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:54:46 visual_prompt]: Epoch 41 / 100: avg data time: 4.86e-02, avg batch time: 0.4972, average train loss: 86.9055
[09/26 08:54:48 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 123.4298
[09/26 08:54:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 08:54:48 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:54:55 visual_prompt]: Epoch 42 / 100: avg data time: 5.31e-02, avg batch time: 0.5016, average train loss: 75.8490
[09/26 08:54:56 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1690, average loss: 137.0720
[09/26 08:54:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 08:54:56 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:55:03 visual_prompt]: Epoch 43 / 100: avg data time: 4.74e-02, avg batch time: 0.4963, average train loss: 95.3396
[09/26 08:55:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 72.7651
[09/26 08:55:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 08:55:04 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:55:11 visual_prompt]: Epoch 44 / 100: avg data time: 5.00e-02, avg batch time: 0.4985, average train loss: 106.5436
[09/26 08:55:13 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 105.8615
[09/26 08:55:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 08:55:13 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:55:19 visual_prompt]: Epoch 45 / 100: avg data time: 4.40e-02, avg batch time: 0.4945, average train loss: 80.1108
[09/26 08:55:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 162.9095
[09/26 08:55:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 08:55:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:55:28 visual_prompt]: Epoch 46 / 100: avg data time: 4.67e-02, avg batch time: 0.4951, average train loss: 132.4438
[09/26 08:55:29 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 125.4426
[09/26 08:55:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 22.50	
[09/26 08:55:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:55:36 visual_prompt]: Epoch 47 / 100: avg data time: 4.24e-02, avg batch time: 0.4915, average train loss: 84.7538
[09/26 08:55:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 70.8723
[09/26 08:55:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:55:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:55:44 visual_prompt]: Epoch 48 / 100: avg data time: 6.49e-02, avg batch time: 0.5130, average train loss: 73.2878
[09/26 08:55:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1688, average loss: 66.7269
[09/26 08:55:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 08:55:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:55:52 visual_prompt]: Epoch 49 / 100: avg data time: 5.12e-02, avg batch time: 0.5006, average train loss: 53.3237
[09/26 08:55:54 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1690, average loss: 50.4197
[09/26 08:55:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 08:55:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:56:01 visual_prompt]: Epoch 50 / 100: avg data time: 5.76e-02, avg batch time: 0.5050, average train loss: 61.7153
[09/26 08:56:02 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1691, average loss: 73.8162
[09/26 08:56:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 08:56:02 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:56:09 visual_prompt]: Epoch 51 / 100: avg data time: 6.16e-02, avg batch time: 0.5090, average train loss: 44.9050
[09/26 08:56:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1689, average loss: 53.3078
[09/26 08:56:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 08:56:11 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:56:17 visual_prompt]: Epoch 52 / 100: avg data time: 4.46e-02, avg batch time: 0.4933, average train loss: 54.6980
[09/26 08:56:19 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1692, average loss: 80.7251
[09/26 08:56:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 08:56:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:56:26 visual_prompt]: Epoch 53 / 100: avg data time: 5.86e-02, avg batch time: 0.5060, average train loss: 47.1137
[09/26 08:56:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 42.6309
[09/26 08:56:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 08:56:27 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:56:34 visual_prompt]: Epoch 54 / 100: avg data time: 5.00e-02, avg batch time: 0.4984, average train loss: 40.4569
[09/26 08:56:35 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1688, average loss: 33.3781
[09/26 08:56:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 08:56:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:56:42 visual_prompt]: Epoch 55 / 100: avg data time: 5.57e-02, avg batch time: 0.5042, average train loss: 38.7892
[09/26 08:56:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 38.3400
[09/26 08:56:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:56:44 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:56:51 visual_prompt]: Epoch 56 / 100: avg data time: 5.44e-02, avg batch time: 0.5029, average train loss: 35.8893
[09/26 08:56:52 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 44.0841
[09/26 08:56:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 08:56:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:56:59 visual_prompt]: Epoch 57 / 100: avg data time: 4.69e-02, avg batch time: 0.4962, average train loss: 37.9180
[09/26 08:57:00 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1691, average loss: 39.2091
[09/26 08:57:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 08:57:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:57:07 visual_prompt]: Epoch 58 / 100: avg data time: 4.22e-02, avg batch time: 0.4921, average train loss: 43.1282
[09/26 08:57:09 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1688, average loss: 33.9894
[09/26 08:57:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.50	
[09/26 08:57:09 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:57:15 visual_prompt]: Epoch 59 / 100: avg data time: 4.74e-02, avg batch time: 0.4981, average train loss: 40.6525
[09/26 08:57:17 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1685, average loss: 45.7803
[09/26 08:57:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 08:57:17 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:57:24 visual_prompt]: Epoch 60 / 100: avg data time: 4.73e-02, avg batch time: 0.4963, average train loss: 34.5957
[09/26 08:57:25 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 34.6037
[09/26 08:57:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:57:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:57:32 visual_prompt]: Epoch 61 / 100: avg data time: 4.97e-02, avg batch time: 0.4991, average train loss: 28.1218
[09/26 08:57:33 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1688, average loss: 25.7519
[09/26 08:57:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 08:57:33 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:57:40 visual_prompt]: Epoch 62 / 100: avg data time: 5.62e-02, avg batch time: 0.5034, average train loss: 19.6620
[09/26 08:57:42 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 18.7118
[09/26 08:57:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 08:57:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:57:48 visual_prompt]: Epoch 63 / 100: avg data time: 4.57e-02, avg batch time: 0.4931, average train loss: 20.3544
[09/26 08:57:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 18.3291
[09/26 08:57:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 08:57:50 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:57:56 visual_prompt]: Epoch 64 / 100: avg data time: 5.68e-02, avg batch time: 0.5041, average train loss: 19.8203
[09/26 08:57:58 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 19.8403
[09/26 08:57:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 08:57:58 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:58:05 visual_prompt]: Epoch 65 / 100: avg data time: 5.33e-02, avg batch time: 0.5023, average train loss: 17.8443
[09/26 08:58:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 15.0815
[09/26 08:58:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 08:58:06 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:58:13 visual_prompt]: Epoch 66 / 100: avg data time: 5.64e-02, avg batch time: 0.5039, average train loss: 17.3920
[09/26 08:58:15 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 13.5103
[09/26 08:58:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 08:58:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:58:21 visual_prompt]: Epoch 67 / 100: avg data time: 5.80e-02, avg batch time: 0.5064, average train loss: 10.7562
[09/26 08:58:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 11.2083
[09/26 08:58:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 08:58:23 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:58:30 visual_prompt]: Epoch 68 / 100: avg data time: 5.73e-02, avg batch time: 0.5046, average train loss: 9.9328
[09/26 08:58:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1688, average loss: 7.6088
[09/26 08:58:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 08:58:31 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:58:38 visual_prompt]: Epoch 69 / 100: avg data time: 5.25e-02, avg batch time: 0.5033, average train loss: 5.8384
[09/26 08:58:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1689, average loss: 5.7443
[09/26 08:58:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 08:58:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:58:46 visual_prompt]: Epoch 70 / 100: avg data time: 4.22e-02, avg batch time: 0.4916, average train loss: 4.5340
[09/26 08:58:48 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1688, average loss: 4.3568
[09/26 08:58:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 08:58:48 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:58:54 visual_prompt]: Epoch 71 / 100: avg data time: 5.12e-02, avg batch time: 0.4987, average train loss: 3.8021
[09/26 08:58:56 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1689, average loss: 3.5821
[09/26 08:58:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 08:58:56 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:59:03 visual_prompt]: Epoch 72 / 100: avg data time: 5.03e-02, avg batch time: 0.4975, average train loss: 3.4096
[09/26 08:59:04 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1690, average loss: 3.3464
[09/26 08:59:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 08:59:04 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:59:11 visual_prompt]: Epoch 73 / 100: avg data time: 4.28e-02, avg batch time: 0.4906, average train loss: 3.3791
[09/26 08:59:12 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 3.5683
[09/26 08:59:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 08:59:12 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:59:19 visual_prompt]: Epoch 74 / 100: avg data time: 4.39e-02, avg batch time: 0.4939, average train loss: 3.2645
[09/26 08:59:21 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 3.2242
[09/26 08:59:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 08:59:21 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:59:27 visual_prompt]: Epoch 75 / 100: avg data time: 5.57e-02, avg batch time: 0.5035, average train loss: 3.1646
[09/26 08:59:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 3.3104
[09/26 08:59:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 08:59:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:59:36 visual_prompt]: Epoch 76 / 100: avg data time: 5.35e-02, avg batch time: 0.5007, average train loss: 3.1385
[09/26 08:59:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 3.0910
[09/26 08:59:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 08:59:37 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:59:44 visual_prompt]: Epoch 77 / 100: avg data time: 5.13e-02, avg batch time: 0.4984, average train loss: 3.0621
[09/26 08:59:45 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 3.1970
[09/26 08:59:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 08:59:45 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:59:52 visual_prompt]: Epoch 78 / 100: avg data time: 4.70e-02, avg batch time: 0.4984, average train loss: 3.0869
[09/26 08:59:54 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 3.1948
[09/26 08:59:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 08:59:54 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 09:00:00 visual_prompt]: Epoch 79 / 100: avg data time: 5.42e-02, avg batch time: 0.5018, average train loss: 3.1398
[09/26 09:00:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1688, average loss: 3.0112
[09/26 09:00:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 09:00:02 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 09:00:09 visual_prompt]: Epoch 80 / 100: avg data time: 4.27e-02, avg batch time: 0.4951, average train loss: 3.1444
[09/26 09:00:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1688, average loss: 2.9972
[09/26 09:00:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 09:00:10 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 09:00:17 visual_prompt]: Epoch 81 / 100: avg data time: 5.19e-02, avg batch time: 0.5006, average train loss: 3.1149
[09/26 09:00:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1687, average loss: 3.0439
[09/26 09:00:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 09:00:19 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 09:00:25 visual_prompt]: Epoch 82 / 100: avg data time: 4.86e-02, avg batch time: 0.4984, average train loss: 3.0318
[09/26 09:00:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1686, average loss: 2.9823
[09/26 09:00:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 09:00:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 09:00:34 visual_prompt]: Epoch 83 / 100: avg data time: 5.12e-02, avg batch time: 0.5001, average train loss: 3.0350
[09/26 09:00:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 2.9629
[09/26 09:00:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.50	
[09/26 09:00:35 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 09:00:42 visual_prompt]: Epoch 84 / 100: avg data time: 4.80e-02, avg batch time: 0.4961, average train loss: 3.0365
[09/26 09:00:43 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 2.9759
[09/26 09:00:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 09:00:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 09:00:50 visual_prompt]: Epoch 85 / 100: avg data time: 4.31e-02, avg batch time: 0.4914, average train loss: 2.9592
[09/26 09:00:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 3.0039
[09/26 09:00:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 09:00:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 09:00:58 visual_prompt]: Epoch 86 / 100: avg data time: 4.97e-02, avg batch time: 0.4988, average train loss: 2.9663
[09/26 09:00:59 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1687, average loss: 3.0439
[09/26 09:01:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 09:01:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 09:01:06 visual_prompt]: Epoch 87 / 100: avg data time: 5.72e-02, avg batch time: 0.5045, average train loss: 2.9753
[09/26 09:01:08 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 2.9655
[09/26 09:01:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 09:01:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 09:01:15 visual_prompt]: Epoch 88 / 100: avg data time: 4.64e-02, avg batch time: 0.4945, average train loss: 2.9478
[09/26 09:01:16 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 2.9629
[09/26 09:01:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 09:01:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 09:01:23 visual_prompt]: Epoch 89 / 100: avg data time: 5.90e-02, avg batch time: 0.5069, average train loss: 2.9279
[09/26 09:01:25 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 2.9071
[09/26 09:01:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.50	
[09/26 09:01:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 09:01:31 visual_prompt]: Epoch 90 / 100: avg data time: 5.35e-02, avg batch time: 0.5009, average train loss: 2.9204
[09/26 09:01:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 2.9062
[09/26 09:01:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 09:01:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 09:01:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.43e-02, avg batch time: 0.5029, average train loss: 2.9098
[09/26 09:01:41 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1691, average loss: 2.9160
[09/26 09:01:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:01:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 09:01:48 visual_prompt]: Epoch 92 / 100: avg data time: 5.61e-02, avg batch time: 0.5044, average train loss: 2.9016
[09/26 09:01:50 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1686, average loss: 2.9046
[09/26 09:01:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 09:01:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 09:01:56 visual_prompt]: Epoch 93 / 100: avg data time: 4.16e-02, avg batch time: 0.4902, average train loss: 2.8834
[09/26 09:01:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1689, average loss: 2.9037
[09/26 09:01:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 09:01:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 09:02:04 visual_prompt]: Epoch 94 / 100: avg data time: 5.08e-02, avg batch time: 0.5003, average train loss: 2.8821
[09/26 09:02:06 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1690, average loss: 2.9031
[09/26 09:02:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 28.50	
[09/26 09:02:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 09:02:13 visual_prompt]: Epoch 95 / 100: avg data time: 5.87e-02, avg batch time: 0.5065, average train loss: 2.8777
[09/26 09:02:14 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1691, average loss: 2.9070
[09/26 09:02:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 09:02:14 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 09:02:21 visual_prompt]: Epoch 96 / 100: avg data time: 5.33e-02, avg batch time: 0.5004, average train loss: 2.8757
[09/26 09:02:23 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 2.8954
[09/26 09:02:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 09:02:23 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 09:02:30 visual_prompt]: Epoch 97 / 100: avg data time: 5.75e-02, avg batch time: 0.5052, average train loss: 2.8705
[09/26 09:02:31 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 2.8954
[09/26 09:02:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 09:02:31 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 09:02:38 visual_prompt]: Epoch 98 / 100: avg data time: 5.35e-02, avg batch time: 0.5017, average train loss: 2.8690
[09/26 09:02:40 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 2.8978
[09/26 09:02:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 09:02:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 09:02:46 visual_prompt]: Epoch 99 / 100: avg data time: 6.33e-02, avg batch time: 0.5103, average train loss: 2.8669
[09/26 09:02:48 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 2.8976
[09/26 09:02:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 09:02:48 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 09:02:55 visual_prompt]: Epoch 100 / 100: avg data time: 4.67e-02, avg batch time: 0.4974, average train loss: 2.8662
[09/26 09:02:56 visual_prompt]: Inference (val):avg data time: 5.79e-05, avg batch time: 0.1687, average loss: 2.8978
[09/26 09:02:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 09:02:56 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:02:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:02:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:02:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:02:56 visual_prompt]: Training with config:
[09/26 09:02:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:02:56 visual_prompt]: Loading training data...
[09/26 09:02:56 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:02:57 visual_prompt]: Number of images: 800
[09/26 09:02:57 visual_prompt]: Number of classes: 18 / 18
[09/26 09:02:57 visual_prompt]: Loading validation data...
[09/26 09:02:57 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:02:58 visual_prompt]: Number of images: 200
[09/26 09:02:58 visual_prompt]: Number of classes: 18 / 18
[09/26 09:02:58 visual_prompt]: Constructing models...
[09/26 09:03:01 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 09:03:01 visual_prompt]: tuned percent:0.550
[09/26 09:03:01 visual_prompt]: Device used for model: 0
[09/26 09:03:01 visual_prompt]: Setting up Evaluator...
[09/26 09:03:01 visual_prompt]: Setting up Trainer...
[09/26 09:03:01 visual_prompt]: 	Setting up the optimizer...
[09/26 09:03:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:03:07 visual_prompt]: Epoch 1 / 100: avg data time: 4.47e-02, avg batch time: 0.4926, average train loss: 3.2526
[09/26 09:03:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1688, average loss: 3.1895
[09/26 09:03:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 09:03:09 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 09:03:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 09:03:16 visual_prompt]: Epoch 2 / 100: avg data time: 4.80e-02, avg batch time: 0.4951, average train loss: 6.4537
[09/26 09:03:17 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1688, average loss: 8.0737
[09/26 09:03:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 09:03:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 09:03:24 visual_prompt]: Epoch 3 / 100: avg data time: 4.70e-02, avg batch time: 0.4982, average train loss: 11.8124
[09/26 09:03:25 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1688, average loss: 7.5726
[09/26 09:03:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 09:03:25 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 09:03:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 09:03:32 visual_prompt]: Epoch 4 / 100: avg data time: 5.74e-02, avg batch time: 0.5057, average train loss: 27.8988
[09/26 09:03:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1686, average loss: 57.1098
[09/26 09:03:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 09:03:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 09:03:40 visual_prompt]: Epoch 5 / 100: avg data time: 5.41e-02, avg batch time: 0.5020, average train loss: 48.1684
[09/26 09:03:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 57.2407
[09/26 09:03:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 09:03:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 09:03:49 visual_prompt]: Epoch 6 / 100: avg data time: 5.34e-02, avg batch time: 0.5014, average train loss: 69.1018
[09/26 09:03:50 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1688, average loss: 77.3674
[09/26 09:03:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:03:50 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 09:03:57 visual_prompt]: Epoch 7 / 100: avg data time: 5.72e-02, avg batch time: 0.5048, average train loss: 83.9665
[09/26 09:03:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 75.1451
[09/26 09:03:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 09:03:59 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 09:03:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 09:04:05 visual_prompt]: Epoch 8 / 100: avg data time: 5.16e-02, avg batch time: 0.4995, average train loss: 79.2774
[09/26 09:04:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 78.3620
[09/26 09:04:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 09:04:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 09:04:14 visual_prompt]: Epoch 9 / 100: avg data time: 5.95e-02, avg batch time: 0.5074, average train loss: 76.0556
[09/26 09:04:15 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1688, average loss: 90.1996
[09/26 09:04:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 09:04:15 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 09:04:22 visual_prompt]: Epoch 10 / 100: avg data time: 5.57e-02, avg batch time: 0.5032, average train loss: 113.0141
[09/26 09:04:24 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1689, average loss: 101.5960
[09/26 09:04:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 09:04:24 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 09:04:31 visual_prompt]: Epoch 11 / 100: avg data time: 5.86e-02, avg batch time: 0.5064, average train loss: 112.6494
[09/26 09:04:32 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1690, average loss: 132.8887
[09/26 09:04:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 09:04:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 09:04:39 visual_prompt]: Epoch 12 / 100: avg data time: 4.33e-02, avg batch time: 0.4918, average train loss: 101.8733
[09/26 09:04:40 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 97.7734
[09/26 09:04:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 09:04:40 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 09:04:47 visual_prompt]: Epoch 13 / 100: avg data time: 5.66e-02, avg batch time: 0.5053, average train loss: 93.0995
[09/26 09:04:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 74.4883
[09/26 09:04:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:04:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 09:04:55 visual_prompt]: Epoch 14 / 100: avg data time: 5.52e-02, avg batch time: 0.5034, average train loss: 84.4989
[09/26 09:04:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1689, average loss: 100.1195
[09/26 09:04:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 21.50	
[09/26 09:04:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 09:05:03 visual_prompt]: Epoch 15 / 100: avg data time: 4.79e-02, avg batch time: 0.4962, average train loss: 108.9995
[09/26 09:05:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1687, average loss: 77.3907
[09/26 09:05:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 09:05:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 09:05:12 visual_prompt]: Epoch 16 / 100: avg data time: 5.87e-02, avg batch time: 0.5063, average train loss: 82.0177
[09/26 09:05:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1686, average loss: 81.9991
[09/26 09:05:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 09:05:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 09:05:20 visual_prompt]: Epoch 17 / 100: avg data time: 5.77e-02, avg batch time: 0.5058, average train loss: 94.0917
[09/26 09:05:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 102.2540
[09/26 09:05:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:05:22 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 09:05:29 visual_prompt]: Epoch 18 / 100: avg data time: 5.60e-02, avg batch time: 0.5036, average train loss: 76.5567
[09/26 09:05:30 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1691, average loss: 64.6050
[09/26 09:05:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.50	
[09/26 09:05:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 09:05:37 visual_prompt]: Epoch 19 / 100: avg data time: 5.92e-02, avg batch time: 0.5069, average train loss: 56.8135
[09/26 09:05:39 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1689, average loss: 67.1902
[09/26 09:05:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 09:05:39 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 09:05:45 visual_prompt]: Epoch 20 / 100: avg data time: 5.39e-02, avg batch time: 0.5021, average train loss: 64.3477
[09/26 09:05:47 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 63.9181
[09/26 09:05:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 09:05:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 09:05:54 visual_prompt]: Epoch 21 / 100: avg data time: 3.99e-02, avg batch time: 0.4890, average train loss: 64.3250
[09/26 09:05:55 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 64.8630
[09/26 09:05:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 09:05:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 09:06:02 visual_prompt]: Epoch 22 / 100: avg data time: 5.67e-02, avg batch time: 0.5047, average train loss: 50.1813
[09/26 09:06:03 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 56.3466
[09/26 09:06:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 09:06:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 09:06:10 visual_prompt]: Epoch 23 / 100: avg data time: 5.26e-02, avg batch time: 0.5018, average train loss: 53.6511
[09/26 09:06:12 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 58.9406
[09/26 09:06:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 09:06:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 09:06:19 visual_prompt]: Epoch 24 / 100: avg data time: 5.49e-02, avg batch time: 0.5024, average train loss: 58.7096
[09/26 09:06:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 50.0166
[09/26 09:06:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 09:06:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 09:06:27 visual_prompt]: Epoch 25 / 100: avg data time: 5.65e-02, avg batch time: 0.5063, average train loss: 60.1761
[09/26 09:06:28 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 42.6082
[09/26 09:06:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 09:06:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 09:06:35 visual_prompt]: Epoch 26 / 100: avg data time: 4.90e-02, avg batch time: 0.4973, average train loss: 52.9507
[09/26 09:06:37 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1687, average loss: 36.9610
[09/26 09:06:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.50	
[09/26 09:06:37 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 09:06:44 visual_prompt]: Epoch 27 / 100: avg data time: 5.52e-02, avg batch time: 0.5048, average train loss: 48.0626
[09/26 09:06:45 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 51.5056
[09/26 09:06:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 09:06:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 09:06:52 visual_prompt]: Epoch 28 / 100: avg data time: 5.61e-02, avg batch time: 0.5051, average train loss: 41.8629
[09/26 09:06:54 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 40.4646
[09/26 09:06:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 2.50	top5: 27.00	
[09/26 09:06:54 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 09:07:00 visual_prompt]: Epoch 29 / 100: avg data time: 5.93e-02, avg batch time: 0.5073, average train loss: 37.9915
[09/26 09:07:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 60.4460
[09/26 09:07:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 09:07:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 09:07:09 visual_prompt]: Epoch 30 / 100: avg data time: 4.70e-02, avg batch time: 0.4943, average train loss: 49.6795
[09/26 09:07:10 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1687, average loss: 41.3252
[09/26 09:07:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.50	
[09/26 09:07:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 09:07:17 visual_prompt]: Epoch 31 / 100: avg data time: 4.20e-02, avg batch time: 0.4908, average train loss: 49.6363
[09/26 09:07:18 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1689, average loss: 43.5789
[09/26 09:07:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 09:07:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 09:07:25 visual_prompt]: Epoch 32 / 100: avg data time: 5.30e-02, avg batch time: 0.5016, average train loss: 56.1180
[09/26 09:07:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 49.1583
[09/26 09:07:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 09:07:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 09:07:33 visual_prompt]: Epoch 33 / 100: avg data time: 4.86e-02, avg batch time: 0.4973, average train loss: 49.3203
[09/26 09:07:35 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 41.9335
[09/26 09:07:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:07:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 09:07:42 visual_prompt]: Epoch 34 / 100: avg data time: 5.93e-02, avg batch time: 0.5100, average train loss: 55.3973
[09/26 09:07:43 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 54.7820
[09/26 09:07:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 09:07:43 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 09:07:50 visual_prompt]: Epoch 35 / 100: avg data time: 4.22e-02, avg batch time: 0.4928, average train loss: 42.5828
[09/26 09:07:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 45.1195
[09/26 09:07:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.00	
[09/26 09:07:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 09:07:58 visual_prompt]: Epoch 36 / 100: avg data time: 5.43e-02, avg batch time: 0.5025, average train loss: 51.2951
[09/26 09:08:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 33.4512
[09/26 09:08:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 09:08:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 09:08:06 visual_prompt]: Epoch 37 / 100: avg data time: 5.03e-02, avg batch time: 0.4983, average train loss: 37.1189
[09/26 09:08:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1686, average loss: 29.2487
[09/26 09:08:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 09:08:08 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 09:08:15 visual_prompt]: Epoch 38 / 100: avg data time: 4.99e-02, avg batch time: 0.4993, average train loss: 42.1688
[09/26 09:08:16 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1691, average loss: 57.9124
[09/26 09:08:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 09:08:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 09:08:23 visual_prompt]: Epoch 39 / 100: avg data time: 4.66e-02, avg batch time: 0.4979, average train loss: 44.5927
[09/26 09:08:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 48.5073
[09/26 09:08:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 09:08:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 09:08:31 visual_prompt]: Epoch 40 / 100: avg data time: 4.66e-02, avg batch time: 0.4968, average train loss: 47.8305
[09/26 09:08:33 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1698, average loss: 41.1042
[09/26 09:08:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 09:08:33 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 09:08:39 visual_prompt]: Epoch 41 / 100: avg data time: 5.31e-02, avg batch time: 0.5017, average train loss: 38.8878
[09/26 09:08:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1690, average loss: 45.8734
[09/26 09:08:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 09:08:41 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 09:08:48 visual_prompt]: Epoch 42 / 100: avg data time: 4.71e-02, avg batch time: 0.4963, average train loss: 40.2844
[09/26 09:08:49 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 42.4190
[09/26 09:08:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 09:08:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 09:08:56 visual_prompt]: Epoch 43 / 100: avg data time: 5.26e-02, avg batch time: 0.5005, average train loss: 41.8779
[09/26 09:08:57 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 37.8517
[09/26 09:08:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 09:08:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 09:09:04 visual_prompt]: Epoch 44 / 100: avg data time: 5.31e-02, avg batch time: 0.5025, average train loss: 39.9517
[09/26 09:09:06 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 46.8216
[09/26 09:09:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:09:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 09:09:12 visual_prompt]: Epoch 45 / 100: avg data time: 4.18e-02, avg batch time: 0.4909, average train loss: 41.6382
[09/26 09:09:14 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1689, average loss: 40.6416
[09/26 09:09:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 09:09:14 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 09:09:21 visual_prompt]: Epoch 46 / 100: avg data time: 5.30e-02, avg batch time: 0.5014, average train loss: 35.7651
[09/26 09:09:22 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1692, average loss: 36.5136
[09/26 09:09:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 09:09:22 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 09:09:29 visual_prompt]: Epoch 47 / 100: avg data time: 5.79e-02, avg batch time: 0.5069, average train loss: 32.6700
[09/26 09:09:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1689, average loss: 27.6327
[09/26 09:09:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:09:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 09:09:37 visual_prompt]: Epoch 48 / 100: avg data time: 5.03e-02, avg batch time: 0.4994, average train loss: 28.8816
[09/26 09:09:39 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1688, average loss: 24.8426
[09/26 09:09:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 09:09:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 09:09:46 visual_prompt]: Epoch 49 / 100: avg data time: 5.17e-02, avg batch time: 0.5006, average train loss: 24.4038
[09/26 09:09:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1687, average loss: 28.5597
[09/26 09:09:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 09:09:47 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 09:09:54 visual_prompt]: Epoch 50 / 100: avg data time: 4.71e-02, avg batch time: 0.4991, average train loss: 20.8494
[09/26 09:09:55 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 20.1621
[09/26 09:09:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:09:55 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 09:10:02 visual_prompt]: Epoch 51 / 100: avg data time: 5.08e-02, avg batch time: 0.4995, average train loss: 20.9531
[09/26 09:10:04 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1691, average loss: 22.2035
[09/26 09:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 26.00	
[09/26 09:10:04 visual_prompt]: Best epoch 51: best metric: 0.095
[09/26 09:10:04 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 09:10:11 visual_prompt]: Epoch 52 / 100: avg data time: 5.65e-02, avg batch time: 0.5052, average train loss: 22.0629
[09/26 09:10:12 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1691, average loss: 20.5979
[09/26 09:10:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:10:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 09:10:19 visual_prompt]: Epoch 53 / 100: avg data time: 5.13e-02, avg batch time: 0.4992, average train loss: 16.2966
[09/26 09:10:20 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 15.5502
[09/26 09:10:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:10:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 09:10:27 visual_prompt]: Epoch 54 / 100: avg data time: 5.58e-02, avg batch time: 0.5038, average train loss: 15.4362
[09/26 09:10:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1692, average loss: 21.8889
[09/26 09:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:10:29 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 09:10:36 visual_prompt]: Epoch 55 / 100: avg data time: 5.70e-02, avg batch time: 0.5058, average train loss: 19.7750
[09/26 09:10:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 23.6661
[09/26 09:10:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 09:10:37 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 09:10:44 visual_prompt]: Epoch 56 / 100: avg data time: 5.30e-02, avg batch time: 0.5017, average train loss: 22.9093
[09/26 09:10:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 19.8206
[09/26 09:10:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 09:10:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 09:10:52 visual_prompt]: Epoch 57 / 100: avg data time: 4.79e-02, avg batch time: 0.4960, average train loss: 16.0490
[09/26 09:10:54 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1688, average loss: 15.8873
[09/26 09:10:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.50	
[09/26 09:10:54 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 09:11:00 visual_prompt]: Epoch 58 / 100: avg data time: 4.70e-02, avg batch time: 0.4972, average train loss: 13.4680
[09/26 09:11:02 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 9.8350
[09/26 09:11:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 09:11:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 09:11:09 visual_prompt]: Epoch 59 / 100: avg data time: 6.15e-02, avg batch time: 0.5094, average train loss: 9.9241
[09/26 09:11:10 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1689, average loss: 7.4272
[09/26 09:11:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:11:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 09:11:17 visual_prompt]: Epoch 60 / 100: avg data time: 4.48e-02, avg batch time: 0.4944, average train loss: 7.9748
[09/26 09:11:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1695, average loss: 8.8714
[09/26 09:11:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 09:11:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 09:11:25 visual_prompt]: Epoch 61 / 100: avg data time: 4.48e-02, avg batch time: 0.4967, average train loss: 7.5532
[09/26 09:11:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 6.8555
[09/26 09:11:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 09:11:27 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 09:11:33 visual_prompt]: Epoch 62 / 100: avg data time: 5.06e-02, avg batch time: 0.5013, average train loss: 6.0375
[09/26 09:11:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 4.9534
[09/26 09:11:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 09:11:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 09:11:42 visual_prompt]: Epoch 63 / 100: avg data time: 4.66e-02, avg batch time: 0.4958, average train loss: 4.6775
[09/26 09:11:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 3.5279
[09/26 09:11:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.00	
[09/26 09:11:43 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 09:11:50 visual_prompt]: Epoch 64 / 100: avg data time: 5.20e-02, avg batch time: 0.5007, average train loss: 3.7463
[09/26 09:11:51 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1693, average loss: 4.1814
[09/26 09:11:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.50	
[09/26 09:11:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 09:11:58 visual_prompt]: Epoch 65 / 100: avg data time: 4.71e-02, avg batch time: 0.4971, average train loss: 4.0105
[09/26 09:12:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 4.0655
[09/26 09:12:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:12:00 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 09:12:06 visual_prompt]: Epoch 66 / 100: avg data time: 4.94e-02, avg batch time: 0.5003, average train loss: 3.6629
[09/26 09:12:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 4.0298
[09/26 09:12:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:12:08 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 09:12:15 visual_prompt]: Epoch 67 / 100: avg data time: 4.48e-02, avg batch time: 0.4952, average train loss: 3.7073
[09/26 09:12:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 3.9473
[09/26 09:12:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 09:12:16 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 09:12:23 visual_prompt]: Epoch 68 / 100: avg data time: 5.12e-02, avg batch time: 0.4991, average train loss: 3.6204
[09/26 09:12:24 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1696, average loss: 3.3575
[09/26 09:12:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 31.50	
[09/26 09:12:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 09:12:31 visual_prompt]: Epoch 69 / 100: avg data time: 4.45e-02, avg batch time: 0.4943, average train loss: 3.4904
[09/26 09:12:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1689, average loss: 3.6262
[09/26 09:12:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 09:12:32 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 09:12:39 visual_prompt]: Epoch 70 / 100: avg data time: 4.77e-02, avg batch time: 0.4963, average train loss: 3.4321
[09/26 09:12:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1687, average loss: 3.1549
[09/26 09:12:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 35.00	
[09/26 09:12:41 visual_prompt]: Best epoch 70: best metric: 0.100
[09/26 09:12:41 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 09:12:48 visual_prompt]: Epoch 71 / 100: avg data time: 6.03e-02, avg batch time: 0.5091, average train loss: 3.2282
[09/26 09:12:49 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1689, average loss: 3.2896
[09/26 09:12:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 30.50	
[09/26 09:12:49 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 09:12:56 visual_prompt]: Epoch 72 / 100: avg data time: 5.49e-02, avg batch time: 0.5046, average train loss: 3.4397
[09/26 09:12:57 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1691, average loss: 3.3495
[09/26 09:12:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 32.00	
[09/26 09:12:57 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 09:13:04 visual_prompt]: Epoch 73 / 100: avg data time: 4.75e-02, avg batch time: 0.4969, average train loss: 3.3212
[09/26 09:13:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 3.4490
[09/26 09:13:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 09:13:06 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 09:13:12 visual_prompt]: Epoch 74 / 100: avg data time: 4.76e-02, avg batch time: 0.4973, average train loss: 3.3124
[09/26 09:13:14 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1690, average loss: 3.2267
[09/26 09:13:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 37.00	
[09/26 09:13:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 09:13:21 visual_prompt]: Epoch 75 / 100: avg data time: 5.07e-02, avg batch time: 0.5000, average train loss: 3.2866
[09/26 09:13:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1695, average loss: 3.2021
[09/26 09:13:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.50	
[09/26 09:13:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 09:13:29 visual_prompt]: Epoch 76 / 100: avg data time: 4.55e-02, avg batch time: 0.4963, average train loss: 3.2174
[09/26 09:13:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1691, average loss: 3.3016
[09/26 09:13:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 32.00	
[09/26 09:13:30 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 09:13:37 visual_prompt]: Epoch 77 / 100: avg data time: 5.11e-02, avg batch time: 0.5015, average train loss: 3.2580
[09/26 09:13:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 3.2206
[09/26 09:13:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 31.00	
[09/26 09:13:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 09:13:45 visual_prompt]: Epoch 78 / 100: avg data time: 4.81e-02, avg batch time: 0.4962, average train loss: 3.1421
[09/26 09:13:47 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1689, average loss: 3.2707
[09/26 09:13:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.50	
[09/26 09:13:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 09:13:54 visual_prompt]: Epoch 79 / 100: avg data time: 4.84e-02, avg batch time: 0.4988, average train loss: 3.1139
[09/26 09:13:55 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 3.2256
[09/26 09:13:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.00	
[09/26 09:13:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 09:14:02 visual_prompt]: Epoch 80 / 100: avg data time: 5.47e-02, avg batch time: 0.5045, average train loss: 3.0936
[09/26 09:14:04 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.1692, average loss: 3.2284
[09/26 09:14:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 29.50	
[09/26 09:14:04 visual_prompt]: Best epoch 80: best metric: 0.110
[09/26 09:14:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 09:14:10 visual_prompt]: Epoch 81 / 100: avg data time: 4.81e-02, avg batch time: 0.4970, average train loss: 3.0562
[09/26 09:14:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1690, average loss: 3.2354
[09/26 09:14:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 09:14:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 09:14:18 visual_prompt]: Epoch 82 / 100: avg data time: 4.54e-02, avg batch time: 0.4965, average train loss: 3.0891
[09/26 09:14:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 3.1639
[09/26 09:14:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 33.00	
[09/26 09:14:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 09:14:27 visual_prompt]: Epoch 83 / 100: avg data time: 4.81e-02, avg batch time: 0.4965, average train loss: 3.0563
[09/26 09:14:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1692, average loss: 2.9612
[09/26 09:14:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 37.00	
[09/26 09:14:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 09:14:35 visual_prompt]: Epoch 84 / 100: avg data time: 4.95e-02, avg batch time: 0.4990, average train loss: 3.0116
[09/26 09:14:36 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 3.0428
[09/26 09:14:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 33.00	
[09/26 09:14:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 09:14:43 visual_prompt]: Epoch 85 / 100: avg data time: 5.90e-02, avg batch time: 0.5079, average train loss: 3.0291
[09/26 09:14:45 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 3.0056
[09/26 09:14:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 36.00	
[09/26 09:14:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 09:14:52 visual_prompt]: Epoch 86 / 100: avg data time: 5.30e-02, avg batch time: 0.5011, average train loss: 2.9171
[09/26 09:14:53 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1691, average loss: 2.9896
[09/26 09:14:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 34.00	
[09/26 09:14:53 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 09:15:00 visual_prompt]: Epoch 87 / 100: avg data time: 6.19e-02, avg batch time: 0.5107, average train loss: 2.9700
[09/26 09:15:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 2.9762
[09/26 09:15:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 09:15:01 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 09:15:08 visual_prompt]: Epoch 88 / 100: avg data time: 5.80e-02, avg batch time: 0.5068, average train loss: 2.9458
[09/26 09:15:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 2.9697
[09/26 09:15:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 35.00	
[09/26 09:15:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 09:15:17 visual_prompt]: Epoch 89 / 100: avg data time: 5.73e-02, avg batch time: 0.5049, average train loss: 2.9091
[09/26 09:15:18 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 2.9357
[09/26 09:15:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 37.00	
[09/26 09:15:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 09:15:25 visual_prompt]: Epoch 90 / 100: avg data time: 5.36e-02, avg batch time: 0.5043, average train loss: 2.9065
[09/26 09:15:27 visual_prompt]: Inference (val):avg data time: 5.46e-05, avg batch time: 0.1693, average loss: 2.9574
[09/26 09:15:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 35.00	
[09/26 09:15:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 09:15:33 visual_prompt]: Epoch 91 / 100: avg data time: 4.89e-02, avg batch time: 0.4983, average train loss: 2.9035
[09/26 09:15:35 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1690, average loss: 2.9215
[09/26 09:15:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 35.00	
[09/26 09:15:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 09:15:42 visual_prompt]: Epoch 92 / 100: avg data time: 5.25e-02, avg batch time: 0.5013, average train loss: 2.9232
[09/26 09:15:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 2.9284
[09/26 09:15:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.50	
[09/26 09:15:43 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 09:15:50 visual_prompt]: Epoch 93 / 100: avg data time: 6.10e-02, avg batch time: 0.5104, average train loss: 2.8962
[09/26 09:15:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1690, average loss: 2.9329
[09/26 09:15:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.50	
[09/26 09:15:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 09:15:58 visual_prompt]: Epoch 94 / 100: avg data time: 5.72e-02, avg batch time: 0.5059, average train loss: 2.8814
[09/26 09:16:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1695, average loss: 2.9242
[09/26 09:16:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 37.50	
[09/26 09:16:00 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 09:16:07 visual_prompt]: Epoch 95 / 100: avg data time: 5.11e-02, avg batch time: 0.5005, average train loss: 2.8647
[09/26 09:16:08 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 2.9251
[09/26 09:16:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 35.50	
[09/26 09:16:08 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 09:16:15 visual_prompt]: Epoch 96 / 100: avg data time: 6.24e-02, avg batch time: 0.5106, average train loss: 2.8567
[09/26 09:16:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1689, average loss: 2.9256
[09/26 09:16:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 36.00	
[09/26 09:16:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 09:16:23 visual_prompt]: Epoch 97 / 100: avg data time: 5.33e-02, avg batch time: 0.5017, average train loss: 2.8481
[09/26 09:16:25 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 2.9133
[09/26 09:16:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 35.50	
[09/26 09:16:25 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 09:16:32 visual_prompt]: Epoch 98 / 100: avg data time: 5.75e-02, avg batch time: 0.5061, average train loss: 2.8411
[09/26 09:16:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 2.9164
[09/26 09:16:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 35.50	
[09/26 09:16:33 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 09:16:40 visual_prompt]: Epoch 99 / 100: avg data time: 5.40e-02, avg batch time: 0.5023, average train loss: 2.8361
[09/26 09:16:42 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 2.9195
[09/26 09:16:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 36.00	
[09/26 09:16:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 09:16:48 visual_prompt]: Epoch 100 / 100: avg data time: 5.57e-02, avg batch time: 0.5047, average train loss: 2.8652
[09/26 09:16:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1695, average loss: 2.9187
[09/26 09:16:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 36.00	
[09/26 09:16:50 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:16:50 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:16:50 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:16:50 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:16:50 visual_prompt]: Training with config:
[09/26 09:16:50 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:16:50 visual_prompt]: Loading training data...
[09/26 09:16:50 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:16:51 visual_prompt]: Number of images: 800
[09/26 09:16:51 visual_prompt]: Number of classes: 18 / 18
[09/26 09:16:51 visual_prompt]: Loading validation data...
[09/26 09:16:51 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:16:52 visual_prompt]: Number of images: 200
[09/26 09:16:52 visual_prompt]: Number of classes: 18 / 18
[09/26 09:16:52 visual_prompt]: Constructing models...
[09/26 09:16:54 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 09:16:54 visual_prompt]: tuned percent:0.550
[09/26 09:16:54 visual_prompt]: Device used for model: 0
[09/26 09:16:54 visual_prompt]: Setting up Evaluator...
[09/26 09:16:54 visual_prompt]: Setting up Trainer...
[09/26 09:16:54 visual_prompt]: 	Setting up the optimizer...
[09/26 09:16:54 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:17:01 visual_prompt]: Epoch 1 / 100: avg data time: 4.66e-02, avg batch time: 0.4972, average train loss: 3.2569
[09/26 09:17:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1689, average loss: 3.1895
[09/26 09:17:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 09:17:03 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 09:17:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:17:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.79e-02, avg batch time: 0.5053, average train loss: 4.0289
[09/26 09:17:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1690, average loss: 3.3141
[09/26 09:17:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 09:17:11 visual_prompt]: Best epoch 2: best metric: 0.065
[09/26 09:17:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:17:18 visual_prompt]: Epoch 3 / 100: avg data time: 5.75e-02, avg batch time: 0.5058, average train loss: 3.3665
[09/26 09:17:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1689, average loss: 3.1470
[09/26 09:17:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:17:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:17:26 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e-02, avg batch time: 0.4977, average train loss: 3.1913
[09/26 09:17:28 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1689, average loss: 3.2707
[09/26 09:17:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:17:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:17:34 visual_prompt]: Epoch 5 / 100: avg data time: 6.04e-02, avg batch time: 0.5080, average train loss: 3.1972
[09/26 09:17:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 3.2271
[09/26 09:17:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:17:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:17:43 visual_prompt]: Epoch 6 / 100: avg data time: 4.57e-02, avg batch time: 0.4929, average train loss: 4.3578
[09/26 09:17:44 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1692, average loss: 4.7073
[09/26 09:17:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:17:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:17:51 visual_prompt]: Epoch 7 / 100: avg data time: 6.05e-02, avg batch time: 0.5085, average train loss: 11.4275
[09/26 09:17:53 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1692, average loss: 16.7649
[09/26 09:17:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:17:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:17:59 visual_prompt]: Epoch 8 / 100: avg data time: 5.61e-02, avg batch time: 0.5048, average train loss: 20.0704
[09/26 09:18:01 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 23.8742
[09/26 09:18:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 09:18:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:18:08 visual_prompt]: Epoch 9 / 100: avg data time: 5.40e-02, avg batch time: 0.5042, average train loss: 25.1080
[09/26 09:18:09 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 17.4711
[09/26 09:18:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 09:18:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 09:18:16 visual_prompt]: Epoch 10 / 100: avg data time: 4.85e-02, avg batch time: 0.4965, average train loss: 37.1285
[09/26 09:18:18 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1699, average loss: 42.1929
[09/26 09:18:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 28.50	
[09/26 09:18:18 visual_prompt]: Best epoch 10: best metric: 0.090
[09/26 09:18:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 09:18:24 visual_prompt]: Epoch 11 / 100: avg data time: 4.52e-02, avg batch time: 0.4947, average train loss: 40.5762
[09/26 09:18:26 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 35.7130
[09/26 09:18:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 09:18:26 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 09:18:33 visual_prompt]: Epoch 12 / 100: avg data time: 5.49e-02, avg batch time: 0.5038, average train loss: 50.4277
[09/26 09:18:34 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 46.8205
[09/26 09:18:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:18:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 09:18:41 visual_prompt]: Epoch 13 / 100: avg data time: 6.00e-02, avg batch time: 0.5086, average train loss: 42.3003
[09/26 09:18:43 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1692, average loss: 47.2453
[09/26 09:18:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 09:18:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 09:18:49 visual_prompt]: Epoch 14 / 100: avg data time: 4.36e-02, avg batch time: 0.4913, average train loss: 42.2624
[09/26 09:18:51 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 62.1209
[09/26 09:18:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 09:18:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 09:18:58 visual_prompt]: Epoch 15 / 100: avg data time: 5.20e-02, avg batch time: 0.5019, average train loss: 45.2149
[09/26 09:18:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1696, average loss: 29.3068
[09/26 09:18:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 09:18:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 09:19:06 visual_prompt]: Epoch 16 / 100: avg data time: 4.63e-02, avg batch time: 0.4969, average train loss: 46.5093
[09/26 09:19:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 38.9059
[09/26 09:19:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 09:19:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 09:19:15 visual_prompt]: Epoch 17 / 100: avg data time: 4.68e-02, avg batch time: 0.5350, average train loss: 38.3874
[09/26 09:19:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 41.6389
[09/26 09:19:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 09:19:16 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 09:19:23 visual_prompt]: Epoch 18 / 100: avg data time: 5.10e-02, avg batch time: 0.5003, average train loss: 51.0822
[09/26 09:19:24 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1693, average loss: 52.1048
[09/26 09:19:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:19:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 09:19:31 visual_prompt]: Epoch 19 / 100: avg data time: 4.50e-02, avg batch time: 0.4963, average train loss: 47.9983
[09/26 09:19:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 31.2069
[09/26 09:19:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:19:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 09:19:39 visual_prompt]: Epoch 20 / 100: avg data time: 4.98e-02, avg batch time: 0.4992, average train loss: 38.7596
[09/26 09:19:41 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1691, average loss: 46.1793
[09/26 09:19:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 09:19:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 09:19:48 visual_prompt]: Epoch 21 / 100: avg data time: 4.78e-02, avg batch time: 0.4984, average train loss: 42.7662
[09/26 09:19:49 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1695, average loss: 41.9760
[09/26 09:19:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 09:19:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 09:19:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.49e-02, avg batch time: 0.5043, average train loss: 37.9472
[09/26 09:19:57 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1699, average loss: 31.7416
[09/26 09:19:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:19:57 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 09:20:04 visual_prompt]: Epoch 23 / 100: avg data time: 4.53e-02, avg batch time: 0.4967, average train loss: 38.6120
[09/26 09:20:06 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1695, average loss: 29.3825
[09/26 09:20:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 09:20:06 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 09:20:13 visual_prompt]: Epoch 24 / 100: avg data time: 5.62e-02, avg batch time: 0.5063, average train loss: 35.2542
[09/26 09:20:14 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 25.2001
[09/26 09:20:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 09:20:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 09:20:21 visual_prompt]: Epoch 25 / 100: avg data time: 5.45e-02, avg batch time: 0.5027, average train loss: 51.6958
[09/26 09:20:22 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 47.1674
[09/26 09:20:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 09:20:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 09:20:29 visual_prompt]: Epoch 26 / 100: avg data time: 4.71e-02, avg batch time: 0.4950, average train loss: 61.4208
[09/26 09:20:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1694, average loss: 30.0811
[09/26 09:20:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 09:20:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 09:20:38 visual_prompt]: Epoch 27 / 100: avg data time: 5.64e-02, avg batch time: 0.5053, average train loss: 41.1382
[09/26 09:20:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1690, average loss: 55.4760
[09/26 09:20:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 09:20:39 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 09:20:46 visual_prompt]: Epoch 28 / 100: avg data time: 4.63e-02, avg batch time: 0.4951, average train loss: 41.8634
[09/26 09:20:47 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1695, average loss: 37.7110
[09/26 09:20:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:20:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 09:20:54 visual_prompt]: Epoch 29 / 100: avg data time: 4.36e-02, avg batch time: 0.4924, average train loss: 42.9989
[09/26 09:20:55 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1693, average loss: 38.5892
[09/26 09:20:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 09:20:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 09:21:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.92e-02, avg batch time: 0.5092, average train loss: 43.4539
[09/26 09:21:04 visual_prompt]: Inference (val):avg data time: 4.55e-05, avg batch time: 0.1694, average loss: 38.1608
[09/26 09:21:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 09:21:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:21:11 visual_prompt]: Epoch 31 / 100: avg data time: 4.30e-02, avg batch time: 0.4917, average train loss: 38.4173
[09/26 09:21:12 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1694, average loss: 28.4658
[09/26 09:21:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:21:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:21:19 visual_prompt]: Epoch 32 / 100: avg data time: 5.69e-02, avg batch time: 0.5047, average train loss: 32.2658
[09/26 09:21:21 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1695, average loss: 35.8208
[09/26 09:21:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:21:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:21:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.62e-02, avg batch time: 0.5050, average train loss: 34.6794
[09/26 09:21:29 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1695, average loss: 35.1264
[09/26 09:21:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 09:21:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:21:36 visual_prompt]: Epoch 34 / 100: avg data time: 4.94e-02, avg batch time: 0.4987, average train loss: 31.0930
[09/26 09:21:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1692, average loss: 33.3312
[09/26 09:21:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 09:21:37 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:21:44 visual_prompt]: Epoch 35 / 100: avg data time: 5.18e-02, avg batch time: 0.5012, average train loss: 25.4506
[09/26 09:21:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 18.0825
[09/26 09:21:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:21:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:21:52 visual_prompt]: Epoch 36 / 100: avg data time: 4.09e-02, avg batch time: 0.4906, average train loss: 40.8456
[09/26 09:21:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1693, average loss: 45.4296
[09/26 09:21:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:21:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:22:00 visual_prompt]: Epoch 37 / 100: avg data time: 4.54e-02, avg batch time: 0.4955, average train loss: 34.1153
[09/26 09:22:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 22.1161
[09/26 09:22:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:22:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:22:09 visual_prompt]: Epoch 38 / 100: avg data time: 4.97e-02, avg batch time: 0.4979, average train loss: 31.2121
[09/26 09:22:10 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1693, average loss: 20.9058
[09/26 09:22:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 09:22:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:22:17 visual_prompt]: Epoch 39 / 100: avg data time: 4.66e-02, avg batch time: 0.4958, average train loss: 30.2875
[09/26 09:22:18 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1695, average loss: 35.6235
[09/26 09:22:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.50	
[09/26 09:22:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:22:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.26e-02, avg batch time: 0.4917, average train loss: 26.9792
[09/26 09:22:27 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1695, average loss: 19.0576
[09/26 09:22:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 09:22:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:22:34 visual_prompt]: Epoch 41 / 100: avg data time: 5.24e-02, avg batch time: 0.5020, average train loss: 24.2729
[09/26 09:22:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1691, average loss: 35.6220
[09/26 09:22:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 09:22:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:22:42 visual_prompt]: Epoch 42 / 100: avg data time: 4.31e-02, avg batch time: 0.4949, average train loss: 30.6103
[09/26 09:22:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1694, average loss: 24.9070
[09/26 09:22:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 09:22:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:22:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.21e-02, avg batch time: 0.5020, average train loss: 25.6753
[09/26 09:22:52 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 37.9143
[09/26 09:22:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:22:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:22:58 visual_prompt]: Epoch 44 / 100: avg data time: 4.68e-02, avg batch time: 0.4957, average train loss: 29.0101
[09/26 09:23:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1692, average loss: 27.9210
[09/26 09:23:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 21.50	
[09/26 09:23:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:23:07 visual_prompt]: Epoch 45 / 100: avg data time: 4.97e-02, avg batch time: 0.4990, average train loss: 32.3292
[09/26 09:23:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1693, average loss: 29.7514
[09/26 09:23:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 09:23:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:23:15 visual_prompt]: Epoch 46 / 100: avg data time: 4.55e-02, avg batch time: 0.4957, average train loss: 23.1456
[09/26 09:23:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1694, average loss: 23.1727
[09/26 09:23:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:23:16 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:23:23 visual_prompt]: Epoch 47 / 100: avg data time: 5.00e-02, avg batch time: 0.5000, average train loss: 28.1790
[09/26 09:23:25 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1694, average loss: 28.9697
[09/26 09:23:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:23:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:23:32 visual_prompt]: Epoch 48 / 100: avg data time: 5.07e-02, avg batch time: 0.5005, average train loss: 29.1150
[09/26 09:23:33 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1689, average loss: 29.7619
[09/26 09:23:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 09:23:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:23:40 visual_prompt]: Epoch 49 / 100: avg data time: 4.56e-02, avg batch time: 0.4938, average train loss: 27.2478
[09/26 09:23:41 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1695, average loss: 28.5747
[09/26 09:23:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:23:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:23:48 visual_prompt]: Epoch 50 / 100: avg data time: 5.45e-02, avg batch time: 0.5040, average train loss: 21.9860
[09/26 09:23:50 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1694, average loss: 22.8446
[09/26 09:23:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 09:23:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:23:56 visual_prompt]: Epoch 51 / 100: avg data time: 4.22e-02, avg batch time: 0.4914, average train loss: 19.1902
[09/26 09:23:58 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1692, average loss: 17.5831
[09/26 09:23:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 09:23:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:24:05 visual_prompt]: Epoch 52 / 100: avg data time: 4.85e-02, avg batch time: 0.4980, average train loss: 17.2545
[09/26 09:24:06 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 16.8008
[09/26 09:24:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:24:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:24:13 visual_prompt]: Epoch 53 / 100: avg data time: 5.11e-02, avg batch time: 0.5005, average train loss: 17.3802
[09/26 09:24:15 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 20.7997
[09/26 09:24:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:24:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:24:21 visual_prompt]: Epoch 54 / 100: avg data time: 5.55e-02, avg batch time: 0.5048, average train loss: 20.5044
[09/26 09:24:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 18.2720
[09/26 09:24:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.00	
[09/26 09:24:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:24:30 visual_prompt]: Epoch 55 / 100: avg data time: 4.71e-02, avg batch time: 0.4968, average train loss: 15.3305
[09/26 09:24:31 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1695, average loss: 16.6767
[09/26 09:24:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 09:24:31 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:24:38 visual_prompt]: Epoch 56 / 100: avg data time: 5.61e-02, avg batch time: 0.5045, average train loss: 24.1151
[09/26 09:24:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1695, average loss: 22.6867
[09/26 09:24:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:24:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:24:46 visual_prompt]: Epoch 57 / 100: avg data time: 4.76e-02, avg batch time: 0.4970, average train loss: 26.2276
[09/26 09:24:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1692, average loss: 27.3662
[09/26 09:24:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:24:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:24:55 visual_prompt]: Epoch 58 / 100: avg data time: 4.91e-02, avg batch time: 0.4989, average train loss: 17.1650
[09/26 09:24:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1694, average loss: 18.7399
[09/26 09:24:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:24:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:25:03 visual_prompt]: Epoch 59 / 100: avg data time: 6.02e-02, avg batch time: 0.5093, average train loss: 18.7428
[09/26 09:25:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1692, average loss: 15.3816
[09/26 09:25:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 09:25:04 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:25:11 visual_prompt]: Epoch 60 / 100: avg data time: 5.57e-02, avg batch time: 0.5049, average train loss: 17.5775
[09/26 09:25:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 10.4695
[09/26 09:25:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:25:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:25:19 visual_prompt]: Epoch 61 / 100: avg data time: 4.31e-02, avg batch time: 0.4940, average train loss: 13.4335
[09/26 09:25:21 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1696, average loss: 12.7727
[09/26 09:25:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 09:25:21 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:25:28 visual_prompt]: Epoch 62 / 100: avg data time: 5.27e-02, avg batch time: 0.5013, average train loss: 15.0735
[09/26 09:25:29 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1690, average loss: 13.2705
[09/26 09:25:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 09:25:29 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:25:36 visual_prompt]: Epoch 63 / 100: avg data time: 4.62e-02, avg batch time: 0.4957, average train loss: 13.5317
[09/26 09:25:37 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1697, average loss: 12.0937
[09/26 09:25:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 09:25:37 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:25:44 visual_prompt]: Epoch 64 / 100: avg data time: 4.63e-02, avg batch time: 0.4964, average train loss: 7.7794
[09/26 09:25:45 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1693, average loss: 9.7949
[09/26 09:25:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 09:25:45 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:25:52 visual_prompt]: Epoch 65 / 100: avg data time: 4.29e-02, avg batch time: 0.4938, average train loss: 6.1933
[09/26 09:25:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1697, average loss: 7.6081
[09/26 09:25:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:25:54 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:26:00 visual_prompt]: Epoch 66 / 100: avg data time: 5.69e-02, avg batch time: 0.5061, average train loss: 7.2827
[09/26 09:26:02 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1690, average loss: 6.0061
[09/26 09:26:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 09:26:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:26:09 visual_prompt]: Epoch 67 / 100: avg data time: 4.66e-02, avg batch time: 0.4972, average train loss: 5.3860
[09/26 09:26:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 4.2780
[09/26 09:26:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 09:26:10 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:26:17 visual_prompt]: Epoch 68 / 100: avg data time: 5.08e-02, avg batch time: 0.5004, average train loss: 4.4922
[09/26 09:26:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1690, average loss: 4.1979
[09/26 09:26:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 09:26:18 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:26:25 visual_prompt]: Epoch 69 / 100: avg data time: 5.91e-02, avg batch time: 0.5088, average train loss: 4.0645
[09/26 09:26:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 3.5082
[09/26 09:26:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 09:26:27 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:26:34 visual_prompt]: Epoch 70 / 100: avg data time: 5.15e-02, avg batch time: 0.4996, average train loss: 4.2090
[09/26 09:26:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1699, average loss: 4.1724
[09/26 09:26:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 09:26:35 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:26:42 visual_prompt]: Epoch 71 / 100: avg data time: 5.98e-02, avg batch time: 0.5092, average train loss: 3.9576
[09/26 09:26:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1697, average loss: 3.3142
[09/26 09:26:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:26:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:26:50 visual_prompt]: Epoch 72 / 100: avg data time: 5.96e-02, avg batch time: 0.5086, average train loss: 3.6051
[09/26 09:26:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1693, average loss: 4.2033
[09/26 09:26:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 09:26:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:26:59 visual_prompt]: Epoch 73 / 100: avg data time: 5.31e-02, avg batch time: 0.5029, average train loss: 3.8395
[09/26 09:27:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1694, average loss: 3.8377
[09/26 09:27:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 09:27:00 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:27:07 visual_prompt]: Epoch 74 / 100: avg data time: 6.02e-02, avg batch time: 0.5097, average train loss: 3.3961
[09/26 09:27:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 3.1495
[09/26 09:27:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:27:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:27:15 visual_prompt]: Epoch 75 / 100: avg data time: 5.56e-02, avg batch time: 0.5046, average train loss: 3.1586
[09/26 09:27:17 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 3.1392
[09/26 09:27:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:27:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:27:24 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.5072, average train loss: 3.2121
[09/26 09:27:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1697, average loss: 3.0424
[09/26 09:27:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 09:27:25 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:27:32 visual_prompt]: Epoch 77 / 100: avg data time: 5.79e-02, avg batch time: 0.5066, average train loss: 3.1380
[09/26 09:27:34 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1697, average loss: 3.1246
[09/26 09:27:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 09:27:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:27:41 visual_prompt]: Epoch 78 / 100: avg data time: 5.24e-02, avg batch time: 0.5007, average train loss: 3.0968
[09/26 09:27:42 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1694, average loss: 3.0223
[09/26 09:27:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 34.00	
[09/26 09:27:42 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:27:49 visual_prompt]: Epoch 79 / 100: avg data time: 5.66e-02, avg batch time: 0.5057, average train loss: 3.0722
[09/26 09:27:50 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 3.0666
[09/26 09:27:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 09:27:50 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:27:57 visual_prompt]: Epoch 80 / 100: avg data time: 5.71e-02, avg batch time: 0.5063, average train loss: 3.0064
[09/26 09:27:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1694, average loss: 3.0782
[09/26 09:27:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:27:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:28:06 visual_prompt]: Epoch 81 / 100: avg data time: 5.24e-02, avg batch time: 0.5018, average train loss: 2.9672
[09/26 09:28:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 3.0973
[09/26 09:28:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 09:28:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:28:14 visual_prompt]: Epoch 82 / 100: avg data time: 5.19e-02, avg batch time: 0.5003, average train loss: 2.9709
[09/26 09:28:16 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1695, average loss: 2.9844
[09/26 09:28:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:28:16 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:28:22 visual_prompt]: Epoch 83 / 100: avg data time: 4.94e-02, avg batch time: 0.4998, average train loss: 2.9591
[09/26 09:28:24 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1695, average loss: 2.9882
[09/26 09:28:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:28:24 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:28:31 visual_prompt]: Epoch 84 / 100: avg data time: 5.65e-02, avg batch time: 0.5067, average train loss: 2.9564
[09/26 09:28:32 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1694, average loss: 2.9634
[09/26 09:28:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 09:28:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:28:39 visual_prompt]: Epoch 85 / 100: avg data time: 5.34e-02, avg batch time: 0.5025, average train loss: 2.9525
[09/26 09:28:41 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 2.9298
[09/26 09:28:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 09:28:41 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:28:47 visual_prompt]: Epoch 86 / 100: avg data time: 5.11e-02, avg batch time: 0.4994, average train loss: 2.9461
[09/26 09:28:49 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1697, average loss: 2.9540
[09/26 09:28:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:28:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:28:56 visual_prompt]: Epoch 87 / 100: avg data time: 5.33e-02, avg batch time: 0.5018, average train loss: 2.9360
[09/26 09:28:57 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 2.9501
[09/26 09:28:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 09:28:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:29:04 visual_prompt]: Epoch 88 / 100: avg data time: 4.48e-02, avg batch time: 0.4941, average train loss: 2.9378
[09/26 09:29:05 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1691, average loss: 2.9375
[09/26 09:29:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:29:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:29:12 visual_prompt]: Epoch 89 / 100: avg data time: 4.76e-02, avg batch time: 0.4965, average train loss: 2.9167
[09/26 09:29:14 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1699, average loss: 2.9004
[09/26 09:29:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.50	
[09/26 09:29:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:29:21 visual_prompt]: Epoch 90 / 100: avg data time: 5.71e-02, avg batch time: 0.5062, average train loss: 2.9125
[09/26 09:29:22 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1697, average loss: 2.9187
[09/26 09:29:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:29:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:29:29 visual_prompt]: Epoch 91 / 100: avg data time: 5.12e-02, avg batch time: 0.5000, average train loss: 2.9077
[09/26 09:29:30 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 2.8993
[09/26 09:29:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 09:29:30 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:29:37 visual_prompt]: Epoch 92 / 100: avg data time: 5.77e-02, avg batch time: 0.5059, average train loss: 2.8991
[09/26 09:29:39 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 2.9033
[09/26 09:29:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 09:29:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:29:46 visual_prompt]: Epoch 93 / 100: avg data time: 4.98e-02, avg batch time: 0.4983, average train loss: 2.8935
[09/26 09:29:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1695, average loss: 2.9031
[09/26 09:29:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 09:29:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:29:54 visual_prompt]: Epoch 94 / 100: avg data time: 4.94e-02, avg batch time: 0.4981, average train loss: 2.8895
[09/26 09:29:55 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 2.9015
[09/26 09:29:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 09:29:55 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:30:02 visual_prompt]: Epoch 95 / 100: avg data time: 5.33e-02, avg batch time: 0.5027, average train loss: 2.8870
[09/26 09:30:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1692, average loss: 2.9116
[09/26 09:30:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 09:30:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:30:11 visual_prompt]: Epoch 96 / 100: avg data time: 5.46e-02, avg batch time: 0.5043, average train loss: 2.8867
[09/26 09:30:12 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 2.9018
[09/26 09:30:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 09:30:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:30:19 visual_prompt]: Epoch 97 / 100: avg data time: 5.51e-02, avg batch time: 0.5039, average train loss: 2.8822
[09/26 09:30:20 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 2.9077
[09/26 09:30:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 09:30:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:30:27 visual_prompt]: Epoch 98 / 100: avg data time: 5.41e-02, avg batch time: 0.5026, average train loss: 2.8797
[09/26 09:30:29 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1694, average loss: 2.9077
[09/26 09:30:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 09:30:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:30:35 visual_prompt]: Epoch 99 / 100: avg data time: 5.10e-02, avg batch time: 0.5003, average train loss: 2.8797
[09/26 09:30:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 2.9053
[09/26 09:30:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 09:30:37 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:30:44 visual_prompt]: Epoch 100 / 100: avg data time: 5.96e-02, avg batch time: 0.5076, average train loss: 2.8787
[09/26 09:30:45 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1690, average loss: 2.9054
[09/26 09:30:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 09:30:45 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:30:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:30:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:30:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:30:45 visual_prompt]: Training with config:
[09/26 09:30:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:30:45 visual_prompt]: Loading training data...
[09/26 09:30:45 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:30:46 visual_prompt]: Number of images: 800
[09/26 09:30:46 visual_prompt]: Number of classes: 18 / 18
[09/26 09:30:46 visual_prompt]: Loading validation data...
[09/26 09:30:46 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:30:47 visual_prompt]: Number of images: 200
[09/26 09:30:47 visual_prompt]: Number of classes: 18 / 18
[09/26 09:30:47 visual_prompt]: Constructing models...
[09/26 09:30:49 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 09:30:49 visual_prompt]: tuned percent:0.550
[09/26 09:30:49 visual_prompt]: Device used for model: 0
[09/26 09:30:49 visual_prompt]: Setting up Evaluator...
[09/26 09:30:49 visual_prompt]: Setting up Trainer...
[09/26 09:30:49 visual_prompt]: 	Setting up the optimizer...
[09/26 09:30:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:30:56 visual_prompt]: Epoch 1 / 100: avg data time: 4.27e-02, avg batch time: 0.4912, average train loss: 3.2445
[09/26 09:30:58 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1690, average loss: 3.1895
[09/26 09:30:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 09:30:58 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 09:30:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:31:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.15e-02, avg batch time: 0.5006, average train loss: 4.0335
[09/26 09:31:06 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1689, average loss: 3.6212
[09/26 09:31:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 09:31:06 visual_prompt]: Best epoch 2: best metric: 0.065
[09/26 09:31:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:31:13 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e-02, avg batch time: 0.4959, average train loss: 3.3416
[09/26 09:31:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 3.2546
[09/26 09:31:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 09:31:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:31:21 visual_prompt]: Epoch 4 / 100: avg data time: 6.00e-02, avg batch time: 0.5094, average train loss: 3.3119
[09/26 09:31:23 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1688, average loss: 3.6937
[09/26 09:31:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 09:31:23 visual_prompt]: Best epoch 4: best metric: 0.070
[09/26 09:31:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:31:29 visual_prompt]: Epoch 5 / 100: avg data time: 5.63e-02, avg batch time: 0.5051, average train loss: 3.6535
[09/26 09:31:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1686, average loss: 3.7032
[09/26 09:31:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 33.00	
[09/26 09:31:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:31:38 visual_prompt]: Epoch 6 / 100: avg data time: 5.43e-02, avg batch time: 0.5010, average train loss: 4.5400
[09/26 09:31:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1688, average loss: 7.3871
[09/26 09:31:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 09:31:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:31:46 visual_prompt]: Epoch 7 / 100: avg data time: 4.77e-02, avg batch time: 0.4966, average train loss: 14.0940
[09/26 09:31:48 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1689, average loss: 18.1132
[09/26 09:31:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:31:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:31:55 visual_prompt]: Epoch 8 / 100: avg data time: 6.08e-02, avg batch time: 0.5089, average train loss: 41.2515
[09/26 09:31:56 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1694, average loss: 52.4646
[09/26 09:31:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 09:31:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:32:03 visual_prompt]: Epoch 9 / 100: avg data time: 5.79e-02, avg batch time: 0.5063, average train loss: 46.0520
[09/26 09:32:04 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1691, average loss: 54.6995
[09/26 09:32:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:32:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 09:32:11 visual_prompt]: Epoch 10 / 100: avg data time: 5.60e-02, avg batch time: 0.5041, average train loss: 39.4397
[09/26 09:32:13 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 32.9406
[09/26 09:32:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:32:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 09:32:20 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e-02, avg batch time: 0.5045, average train loss: 45.4331
[09/26 09:32:21 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1692, average loss: 62.4778
[09/26 09:32:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 09:32:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 09:32:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.44e-02, avg batch time: 0.5037, average train loss: 73.1278
[09/26 09:32:30 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1694, average loss: 47.8966
[09/26 09:32:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 09:32:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 09:32:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.38e-02, avg batch time: 0.5042, average train loss: 56.6274
[09/26 09:32:38 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 48.8155
[09/26 09:32:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 09:32:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 09:32:45 visual_prompt]: Epoch 14 / 100: avg data time: 5.17e-02, avg batch time: 0.4995, average train loss: 67.4340
[09/26 09:32:46 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 57.5184
[09/26 09:32:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:32:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 09:32:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.60e-02, avg batch time: 0.5053, average train loss: 45.0540
[09/26 09:32:55 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1694, average loss: 53.7312
[09/26 09:32:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 09:32:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 09:33:01 visual_prompt]: Epoch 16 / 100: avg data time: 4.69e-02, avg batch time: 0.4965, average train loss: 49.5453
[09/26 09:33:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 58.8896
[09/26 09:33:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 09:33:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 09:33:10 visual_prompt]: Epoch 17 / 100: avg data time: 5.88e-02, avg batch time: 0.5077, average train loss: 55.8552
[09/26 09:33:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 49.1773
[09/26 09:33:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 09:33:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 09:33:18 visual_prompt]: Epoch 18 / 100: avg data time: 5.18e-02, avg batch time: 0.4999, average train loss: 48.9196
[09/26 09:33:19 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1696, average loss: 57.2478
[09/26 09:33:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.00	
[09/26 09:33:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 09:33:26 visual_prompt]: Epoch 19 / 100: avg data time: 4.70e-02, avg batch time: 0.4959, average train loss: 62.5463
[09/26 09:33:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 92.1687
[09/26 09:33:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:33:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 09:33:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.39e-02, avg batch time: 0.5032, average train loss: 52.7824
[09/26 09:33:36 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1691, average loss: 43.4007
[09/26 09:33:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 09:33:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 09:33:43 visual_prompt]: Epoch 21 / 100: avg data time: 4.33e-02, avg batch time: 0.4928, average train loss: 54.9089
[09/26 09:33:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 75.9416
[09/26 09:33:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 09:33:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 09:33:51 visual_prompt]: Epoch 22 / 100: avg data time: 5.07e-02, avg batch time: 0.4998, average train loss: 74.5331
[09/26 09:33:52 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1696, average loss: 88.0838
[09/26 09:33:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.00	
[09/26 09:33:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 09:33:59 visual_prompt]: Epoch 23 / 100: avg data time: 4.93e-02, avg batch time: 0.5008, average train loss: 75.4995
[09/26 09:34:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 40.4248
[09/26 09:34:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 24.50	
[09/26 09:34:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 09:34:08 visual_prompt]: Epoch 24 / 100: avg data time: 5.49e-02, avg batch time: 0.5040, average train loss: 57.4665
[09/26 09:34:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1694, average loss: 54.1553
[09/26 09:34:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 09:34:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 09:34:16 visual_prompt]: Epoch 25 / 100: avg data time: 4.72e-02, avg batch time: 0.4956, average train loss: 50.8541
[09/26 09:34:17 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 46.7545
[09/26 09:34:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 09:34:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 09:34:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.37e-02, avg batch time: 0.5025, average train loss: 54.6038
[09/26 09:34:26 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1692, average loss: 100.8963
[09/26 09:34:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 09:34:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 09:34:32 visual_prompt]: Epoch 27 / 100: avg data time: 4.24e-02, avg batch time: 0.4912, average train loss: 74.7895
[09/26 09:34:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 61.6371
[09/26 09:34:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 09:34:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 09:34:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.69e-02, avg batch time: 0.5046, average train loss: 64.6294
[09/26 09:34:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1692, average loss: 51.3620
[09/26 09:34:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 09:34:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 09:34:49 visual_prompt]: Epoch 29 / 100: avg data time: 5.51e-02, avg batch time: 0.5040, average train loss: 60.2515
[09/26 09:34:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1695, average loss: 39.3022
[09/26 09:34:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 09:34:50 visual_prompt]: Best epoch 29: best metric: 0.085
[09/26 09:34:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 09:34:57 visual_prompt]: Epoch 30 / 100: avg data time: 5.50e-02, avg batch time: 0.5034, average train loss: 46.7718
[09/26 09:34:59 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1690, average loss: 55.0435
[09/26 09:34:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 09:34:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:35:06 visual_prompt]: Epoch 31 / 100: avg data time: 5.64e-02, avg batch time: 0.5048, average train loss: 51.8040
[09/26 09:35:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 52.3283
[09/26 09:35:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:35:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:35:14 visual_prompt]: Epoch 32 / 100: avg data time: 4.91e-02, avg batch time: 0.4978, average train loss: 57.2247
[09/26 09:35:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 42.1516
[09/26 09:35:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 09:35:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:35:22 visual_prompt]: Epoch 33 / 100: avg data time: 4.26e-02, avg batch time: 0.4926, average train loss: 49.7946
[09/26 09:35:23 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1695, average loss: 37.8846
[09/26 09:35:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 09:35:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:35:30 visual_prompt]: Epoch 34 / 100: avg data time: 5.51e-02, avg batch time: 0.5055, average train loss: 46.6455
[09/26 09:35:32 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 41.4988
[09/26 09:35:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 09:35:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:35:39 visual_prompt]: Epoch 35 / 100: avg data time: 5.21e-02, avg batch time: 0.5008, average train loss: 34.0905
[09/26 09:35:40 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 40.9497
[09/26 09:35:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 09:35:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:35:47 visual_prompt]: Epoch 36 / 100: avg data time: 5.48e-02, avg batch time: 0.5033, average train loss: 34.8729
[09/26 09:35:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 31.8822
[09/26 09:35:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 09:35:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:35:55 visual_prompt]: Epoch 37 / 100: avg data time: 5.34e-02, avg batch time: 0.5017, average train loss: 37.1992
[09/26 09:35:57 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1689, average loss: 52.8683
[09/26 09:35:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 09:35:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:36:04 visual_prompt]: Epoch 38 / 100: avg data time: 5.53e-02, avg batch time: 0.5041, average train loss: 43.9075
[09/26 09:36:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 36.9078
[09/26 09:36:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 09:36:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:36:12 visual_prompt]: Epoch 39 / 100: avg data time: 4.35e-02, avg batch time: 0.4945, average train loss: 45.8267
[09/26 09:36:13 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1692, average loss: 36.5774
[09/26 09:36:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 09:36:13 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:36:20 visual_prompt]: Epoch 40 / 100: avg data time: 5.98e-02, avg batch time: 0.5085, average train loss: 43.8554
[09/26 09:36:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1691, average loss: 48.1335
[09/26 09:36:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:36:22 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:36:29 visual_prompt]: Epoch 41 / 100: avg data time: 6.28e-02, avg batch time: 0.5121, average train loss: 35.2573
[09/26 09:36:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 43.1349
[09/26 09:36:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 09:36:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:36:37 visual_prompt]: Epoch 42 / 100: avg data time: 5.33e-02, avg batch time: 0.5025, average train loss: 59.0352
[09/26 09:36:38 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1694, average loss: 35.5033
[09/26 09:36:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 09:36:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:36:45 visual_prompt]: Epoch 43 / 100: avg data time: 4.54e-02, avg batch time: 0.4956, average train loss: 38.1197
[09/26 09:36:47 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1692, average loss: 38.0909
[09/26 09:36:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 26.50	
[09/26 09:36:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:36:54 visual_prompt]: Epoch 44 / 100: avg data time: 5.54e-02, avg batch time: 0.5049, average train loss: 29.4438
[09/26 09:36:55 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1697, average loss: 35.2126
[09/26 09:36:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 09:36:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:37:02 visual_prompt]: Epoch 45 / 100: avg data time: 5.77e-02, avg batch time: 0.5054, average train loss: 46.1731
[09/26 09:37:03 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1695, average loss: 50.5599
[09/26 09:37:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:37:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:37:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.81e-02, avg batch time: 0.5073, average train loss: 36.0381
[09/26 09:37:12 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1699, average loss: 16.2958
[09/26 09:37:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:37:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:37:19 visual_prompt]: Epoch 47 / 100: avg data time: 4.46e-02, avg batch time: 0.4953, average train loss: 23.5756
[09/26 09:37:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 27.2829
[09/26 09:37:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 09:37:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:37:27 visual_prompt]: Epoch 48 / 100: avg data time: 6.01e-02, avg batch time: 0.5092, average train loss: 23.7193
[09/26 09:37:28 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 29.8408
[09/26 09:37:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 09:37:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:37:35 visual_prompt]: Epoch 49 / 100: avg data time: 5.40e-02, avg batch time: 0.5027, average train loss: 34.5166
[09/26 09:37:37 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1693, average loss: 32.9704
[09/26 09:37:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 09:37:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:37:43 visual_prompt]: Epoch 50 / 100: avg data time: 4.92e-02, avg batch time: 0.4996, average train loss: 22.6561
[09/26 09:37:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1695, average loss: 15.7614
[09/26 09:37:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:37:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:37:52 visual_prompt]: Epoch 51 / 100: avg data time: 4.68e-02, avg batch time: 0.4959, average train loss: 15.8533
[09/26 09:37:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 9.1367
[09/26 09:37:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 29.50	
[09/26 09:37:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:38:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.65e-02, avg batch time: 0.5058, average train loss: 14.7667
[09/26 09:38:02 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 16.8621
[09/26 09:38:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 09:38:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:38:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.32e-02, avg batch time: 0.5024, average train loss: 18.2378
[09/26 09:38:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 16.3488
[09/26 09:38:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 09:38:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:38:17 visual_prompt]: Epoch 54 / 100: avg data time: 4.25e-02, avg batch time: 0.4932, average train loss: 17.2072
[09/26 09:38:18 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 19.5832
[09/26 09:38:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:38:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:38:25 visual_prompt]: Epoch 55 / 100: avg data time: 4.22e-02, avg batch time: 0.4907, average train loss: 17.8878
[09/26 09:38:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1689, average loss: 17.0479
[09/26 09:38:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 09:38:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:38:33 visual_prompt]: Epoch 56 / 100: avg data time: 5.20e-02, avg batch time: 0.5008, average train loss: 14.2077
[09/26 09:38:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 20.6158
[09/26 09:38:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 09:38:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:38:41 visual_prompt]: Epoch 57 / 100: avg data time: 5.34e-02, avg batch time: 0.5028, average train loss: 19.6658
[09/26 09:38:43 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 30.2006
[09/26 09:38:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 09:38:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:38:50 visual_prompt]: Epoch 58 / 100: avg data time: 5.33e-02, avg batch time: 0.5022, average train loss: 30.6172
[09/26 09:38:51 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 22.6810
[09/26 09:38:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 09:38:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:38:58 visual_prompt]: Epoch 59 / 100: avg data time: 5.37e-02, avg batch time: 0.5014, average train loss: 15.6212
[09/26 09:38:59 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 10.8686
[09/26 09:38:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.50	
[09/26 09:38:59 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:39:06 visual_prompt]: Epoch 60 / 100: avg data time: 4.17e-02, avg batch time: 0.4887, average train loss: 7.9995
[09/26 09:39:07 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1696, average loss: 4.7827
[09/26 09:39:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:39:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:39:14 visual_prompt]: Epoch 61 / 100: avg data time: 5.98e-02, avg batch time: 0.5070, average train loss: 4.6053
[09/26 09:39:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1691, average loss: 3.5751
[09/26 09:39:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 09:39:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:39:23 visual_prompt]: Epoch 62 / 100: avg data time: 5.02e-02, avg batch time: 0.4988, average train loss: 3.3708
[09/26 09:39:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 3.3902
[09/26 09:39:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 09:39:24 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:39:31 visual_prompt]: Epoch 63 / 100: avg data time: 4.92e-02, avg batch time: 0.4977, average train loss: 3.4576
[09/26 09:39:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 4.1909
[09/26 09:39:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 09:39:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:39:39 visual_prompt]: Epoch 64 / 100: avg data time: 5.25e-02, avg batch time: 0.5005, average train loss: 3.4478
[09/26 09:39:41 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1692, average loss: 3.3523
[09/26 09:39:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 09:39:41 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:39:47 visual_prompt]: Epoch 65 / 100: avg data time: 6.01e-02, avg batch time: 0.5076, average train loss: 3.1888
[09/26 09:39:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 3.1633
[09/26 09:39:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 09:39:49 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:39:56 visual_prompt]: Epoch 66 / 100: avg data time: 5.54e-02, avg batch time: 0.5029, average train loss: 3.2335
[09/26 09:39:57 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 3.1621
[09/26 09:39:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 09:39:57 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:40:04 visual_prompt]: Epoch 67 / 100: avg data time: 4.84e-02, avg batch time: 0.4968, average train loss: 3.0658
[09/26 09:40:05 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1695, average loss: 2.9899
[09/26 09:40:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 09:40:05 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:40:12 visual_prompt]: Epoch 68 / 100: avg data time: 5.36e-02, avg batch time: 0.5036, average train loss: 3.0125
[09/26 09:40:14 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1692, average loss: 3.0841
[09/26 09:40:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:40:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:40:21 visual_prompt]: Epoch 69 / 100: avg data time: 5.16e-02, avg batch time: 0.5002, average train loss: 2.9998
[09/26 09:40:22 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 2.9933
[09/26 09:40:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:40:22 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:40:29 visual_prompt]: Epoch 70 / 100: avg data time: 5.33e-02, avg batch time: 0.5018, average train loss: 3.0309
[09/26 09:40:30 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 3.1929
[09/26 09:40:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 09:40:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:40:37 visual_prompt]: Epoch 71 / 100: avg data time: 5.26e-02, avg batch time: 0.5017, average train loss: 3.1236
[09/26 09:40:39 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 3.1427
[09/26 09:40:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 09:40:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:40:46 visual_prompt]: Epoch 72 / 100: avg data time: 4.88e-02, avg batch time: 0.4977, average train loss: 3.0862
[09/26 09:40:47 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1696, average loss: 3.0615
[09/26 09:40:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:40:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:40:54 visual_prompt]: Epoch 73 / 100: avg data time: 4.83e-02, avg batch time: 0.4987, average train loss: 3.0359
[09/26 09:40:55 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1692, average loss: 2.9921
[09/26 09:40:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 09:40:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:41:02 visual_prompt]: Epoch 74 / 100: avg data time: 6.21e-02, avg batch time: 0.5114, average train loss: 3.0164
[09/26 09:41:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1696, average loss: 3.0771
[09/26 09:41:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:41:04 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:41:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.58e-02, avg batch time: 0.5037, average train loss: 3.0309
[09/26 09:41:12 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 3.0002
[09/26 09:41:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 09:41:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:41:19 visual_prompt]: Epoch 76 / 100: avg data time: 4.83e-02, avg batch time: 0.4966, average train loss: 2.9664
[09/26 09:41:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 3.0066
[09/26 09:41:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 09:41:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:41:27 visual_prompt]: Epoch 77 / 100: avg data time: 5.72e-02, avg batch time: 0.5064, average train loss: 3.0163
[09/26 09:41:29 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1696, average loss: 2.9502
[09/26 09:41:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 09:41:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:41:35 visual_prompt]: Epoch 78 / 100: avg data time: 4.68e-02, avg batch time: 0.4967, average train loss: 2.9651
[09/26 09:41:37 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1695, average loss: 2.9694
[09/26 09:41:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 09:41:37 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:41:44 visual_prompt]: Epoch 79 / 100: avg data time: 5.71e-02, avg batch time: 0.5070, average train loss: 2.9651
[09/26 09:41:45 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1694, average loss: 2.9167
[09/26 09:41:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 09:41:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:41:52 visual_prompt]: Epoch 80 / 100: avg data time: 5.68e-02, avg batch time: 0.5055, average train loss: 2.9453
[09/26 09:41:54 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 2.9444
[09/26 09:41:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 09:41:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:42:00 visual_prompt]: Epoch 81 / 100: avg data time: 5.52e-02, avg batch time: 0.5037, average train loss: 2.9416
[09/26 09:42:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 2.9756
[09/26 09:42:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:42:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:42:09 visual_prompt]: Epoch 82 / 100: avg data time: 4.38e-02, avg batch time: 0.4927, average train loss: 2.9392
[09/26 09:42:10 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1692, average loss: 2.9052
[09/26 09:42:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 09:42:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:42:17 visual_prompt]: Epoch 83 / 100: avg data time: 5.30e-02, avg batch time: 0.5015, average train loss: 2.9319
[09/26 09:42:18 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1697, average loss: 2.9051
[09/26 09:42:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 09:42:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:42:25 visual_prompt]: Epoch 84 / 100: avg data time: 4.97e-02, avg batch time: 0.4987, average train loss: 2.9258
[09/26 09:42:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1693, average loss: 2.9571
[09/26 09:42:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 09:42:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:42:33 visual_prompt]: Epoch 85 / 100: avg data time: 5.77e-02, avg batch time: 0.5073, average train loss: 2.9007
[09/26 09:42:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1698, average loss: 2.9042
[09/26 09:42:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.50	
[09/26 09:42:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:42:42 visual_prompt]: Epoch 86 / 100: avg data time: 4.30e-02, avg batch time: 0.4922, average train loss: 2.9156
[09/26 09:42:43 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1695, average loss: 2.9579
[09/26 09:42:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 09:42:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:42:50 visual_prompt]: Epoch 87 / 100: avg data time: 4.31e-02, avg batch time: 0.4923, average train loss: 2.9133
[09/26 09:42:51 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1695, average loss: 2.9070
[09/26 09:42:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 09:42:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:42:58 visual_prompt]: Epoch 88 / 100: avg data time: 5.25e-02, avg batch time: 0.5004, average train loss: 2.9136
[09/26 09:43:00 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1692, average loss: 2.9125
[09/26 09:43:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 09:43:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:43:06 visual_prompt]: Epoch 89 / 100: avg data time: 4.47e-02, avg batch time: 0.4932, average train loss: 2.9063
[09/26 09:43:08 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 2.8934
[09/26 09:43:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 09:43:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:43:14 visual_prompt]: Epoch 90 / 100: avg data time: 4.79e-02, avg batch time: 0.4951, average train loss: 2.8999
[09/26 09:43:16 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1689, average loss: 2.9095
[09/26 09:43:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 09:43:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:43:23 visual_prompt]: Epoch 91 / 100: avg data time: 5.29e-02, avg batch time: 0.5016, average train loss: 2.8939
[09/26 09:43:24 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1693, average loss: 2.8973
[09/26 09:43:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 31.50	
[09/26 09:43:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:43:31 visual_prompt]: Epoch 92 / 100: avg data time: 4.35e-02, avg batch time: 0.4921, average train loss: 2.8870
[09/26 09:43:32 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1689, average loss: 2.8912
[09/26 09:43:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 31.50	
[09/26 09:43:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:43:39 visual_prompt]: Epoch 93 / 100: avg data time: 5.08e-02, avg batch time: 0.4988, average train loss: 2.8825
[09/26 09:43:41 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1698, average loss: 2.9137
[09/26 09:43:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 09:43:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:43:47 visual_prompt]: Epoch 94 / 100: avg data time: 5.52e-02, avg batch time: 0.5025, average train loss: 2.8728
[09/26 09:43:49 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1693, average loss: 2.8969
[09/26 09:43:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.50	
[09/26 09:43:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:43:56 visual_prompt]: Epoch 95 / 100: avg data time: 5.28e-02, avg batch time: 0.5004, average train loss: 2.8726
[09/26 09:43:57 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1693, average loss: 2.9221
[09/26 09:43:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 09:43:57 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:44:04 visual_prompt]: Epoch 96 / 100: avg data time: 5.66e-02, avg batch time: 0.5062, average train loss: 2.8693
[09/26 09:44:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 2.8935
[09/26 09:44:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 09:44:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:44:13 visual_prompt]: Epoch 97 / 100: avg data time: 5.38e-02, avg batch time: 0.5024, average train loss: 2.8656
[09/26 09:44:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 2.9029
[09/26 09:44:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 31.00	
[09/26 09:44:14 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:44:21 visual_prompt]: Epoch 98 / 100: avg data time: 5.79e-02, avg batch time: 0.5056, average train loss: 2.8625
[09/26 09:44:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 2.9009
[09/26 09:44:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 09:44:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:44:29 visual_prompt]: Epoch 99 / 100: avg data time: 5.90e-02, avg batch time: 0.5076, average train loss: 2.8608
[09/26 09:44:31 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 2.9038
[09/26 09:44:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 09:44:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:44:37 visual_prompt]: Epoch 100 / 100: avg data time: 4.38e-02, avg batch time: 0.4939, average train loss: 2.8597
[09/26 09:44:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1687, average loss: 2.9044
[09/26 09:44:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 09:44:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:44:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:44:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:44:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:44:39 visual_prompt]: Training with config:
[09/26 09:44:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:44:39 visual_prompt]: Loading training data...
[09/26 09:44:39 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:44:40 visual_prompt]: Number of images: 800
[09/26 09:44:40 visual_prompt]: Number of classes: 18 / 18
[09/26 09:44:40 visual_prompt]: Loading validation data...
[09/26 09:44:40 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:44:40 visual_prompt]: Number of images: 200
[09/26 09:44:40 visual_prompt]: Number of classes: 18 / 18
[09/26 09:44:40 visual_prompt]: Constructing models...
[09/26 09:44:43 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 09:44:43 visual_prompt]: tuned percent:0.550
[09/26 09:44:43 visual_prompt]: Device used for model: 0
[09/26 09:44:43 visual_prompt]: Setting up Evaluator...
[09/26 09:44:43 visual_prompt]: Setting up Trainer...
[09/26 09:44:43 visual_prompt]: 	Setting up the optimizer...
[09/26 09:44:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:44:50 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e-02, avg batch time: 0.5000, average train loss: 3.2612
[09/26 09:44:51 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1691, average loss: 3.1895
[09/26 09:44:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 09:44:51 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 09:44:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:44:58 visual_prompt]: Epoch 2 / 100: avg data time: 4.37e-02, avg batch time: 0.4939, average train loss: 4.1912
[09/26 09:45:00 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 4.5560
[09/26 09:45:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 09:45:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:45:06 visual_prompt]: Epoch 3 / 100: avg data time: 4.70e-02, avg batch time: 0.4953, average train loss: 3.5064
[09/26 09:45:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1689, average loss: 3.3592
[09/26 09:45:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 09:45:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:45:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.64e-02, avg batch time: 0.5038, average train loss: 3.4839
[09/26 09:45:16 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 3.2033
[09/26 09:45:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 31.50	
[09/26 09:45:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:45:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.90e-02, avg batch time: 0.5069, average train loss: 3.7092
[09/26 09:45:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 4.7482
[09/26 09:45:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 09:45:25 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 09:45:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:45:31 visual_prompt]: Epoch 6 / 100: avg data time: 5.12e-02, avg batch time: 0.4998, average train loss: 6.0722
[09/26 09:45:33 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1694, average loss: 6.6614
[09/26 09:45:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 09:45:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:45:40 visual_prompt]: Epoch 7 / 100: avg data time: 6.08e-02, avg batch time: 0.5094, average train loss: 7.5562
[09/26 09:45:41 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1694, average loss: 7.0424
[09/26 09:45:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.50	
[09/26 09:45:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:45:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.76e-02, avg batch time: 0.5068, average train loss: 7.8292
[09/26 09:45:50 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1688, average loss: 6.5998
[09/26 09:45:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:45:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:45:56 visual_prompt]: Epoch 9 / 100: avg data time: 4.50e-02, avg batch time: 0.4936, average train loss: 20.8531
[09/26 09:45:58 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1690, average loss: 30.5111
[09/26 09:45:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.50	
[09/26 09:45:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 09:46:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.98e-02, avg batch time: 0.5068, average train loss: 35.2987
[09/26 09:46:06 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1686, average loss: 46.8648
[09/26 09:46:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 09:46:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 09:46:13 visual_prompt]: Epoch 11 / 100: avg data time: 6.23e-02, avg batch time: 0.5102, average train loss: 53.1046
[09/26 09:46:15 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1695, average loss: 46.1018
[09/26 09:46:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:46:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 09:46:22 visual_prompt]: Epoch 12 / 100: avg data time: 4.41e-02, avg batch time: 0.4930, average train loss: 41.5984
[09/26 09:46:23 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1691, average loss: 49.9782
[09/26 09:46:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.50	
[09/26 09:46:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 09:46:30 visual_prompt]: Epoch 13 / 100: avg data time: 5.18e-02, avg batch time: 0.5004, average train loss: 51.3024
[09/26 09:46:31 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 46.4294
[09/26 09:46:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 09:46:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 09:46:38 visual_prompt]: Epoch 14 / 100: avg data time: 4.71e-02, avg batch time: 0.4961, average train loss: 50.8565
[09/26 09:46:40 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1692, average loss: 56.8823
[09/26 09:46:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 09:46:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 09:46:47 visual_prompt]: Epoch 15 / 100: avg data time: 5.16e-02, avg batch time: 0.5000, average train loss: 40.0788
[09/26 09:46:48 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 33.6384
[09/26 09:46:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 09:46:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 09:46:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.03e-02, avg batch time: 0.4990, average train loss: 41.0301
[09/26 09:46:56 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1694, average loss: 22.2966
[09/26 09:46:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.50	
[09/26 09:46:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 09:47:03 visual_prompt]: Epoch 17 / 100: avg data time: 4.14e-02, avg batch time: 0.4900, average train loss: 22.7281
[09/26 09:47:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 23.0072
[09/26 09:47:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 09:47:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 09:47:11 visual_prompt]: Epoch 18 / 100: avg data time: 5.75e-02, avg batch time: 0.5050, average train loss: 28.7683
[09/26 09:47:13 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1690, average loss: 27.3328
[09/26 09:47:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:47:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 09:47:20 visual_prompt]: Epoch 19 / 100: avg data time: 4.90e-02, avg batch time: 0.4967, average train loss: 35.3528
[09/26 09:47:21 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1691, average loss: 24.2949
[09/26 09:47:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 09:47:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 09:47:28 visual_prompt]: Epoch 20 / 100: avg data time: 5.58e-02, avg batch time: 0.5046, average train loss: 23.6276
[09/26 09:47:29 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1691, average loss: 22.8344
[09/26 09:47:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 09:47:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 09:47:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.28e-02, avg batch time: 0.4906, average train loss: 27.7051
[09/26 09:47:38 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1690, average loss: 27.7005
[09/26 09:47:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 09:47:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 09:47:44 visual_prompt]: Epoch 22 / 100: avg data time: 4.49e-02, avg batch time: 0.4935, average train loss: 29.0905
[09/26 09:47:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 25.8220
[09/26 09:47:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 09:47:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 09:47:53 visual_prompt]: Epoch 23 / 100: avg data time: 4.33e-02, avg batch time: 0.4932, average train loss: 29.4903
[09/26 09:47:54 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1690, average loss: 23.3304
[09/26 09:47:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 09:47:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 09:48:01 visual_prompt]: Epoch 24 / 100: avg data time: 4.15e-02, avg batch time: 0.4903, average train loss: 30.1178
[09/26 09:48:02 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1692, average loss: 31.4133
[09/26 09:48:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 09:48:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 09:48:09 visual_prompt]: Epoch 25 / 100: avg data time: 6.08e-02, avg batch time: 0.5092, average train loss: 28.3263
[09/26 09:48:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 26.4977
[09/26 09:48:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 09:48:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 09:48:18 visual_prompt]: Epoch 26 / 100: avg data time: 5.32e-02, avg batch time: 0.5020, average train loss: 25.2708
[09/26 09:48:19 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 23.6662
[09/26 09:48:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 09:48:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 09:48:26 visual_prompt]: Epoch 27 / 100: avg data time: 5.24e-02, avg batch time: 0.4997, average train loss: 28.0940
[09/26 09:48:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1692, average loss: 58.6646
[09/26 09:48:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:48:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 09:48:34 visual_prompt]: Epoch 28 / 100: avg data time: 5.15e-02, avg batch time: 0.5002, average train loss: 44.6429
[09/26 09:48:36 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1691, average loss: 43.2476
[09/26 09:48:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 09:48:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 09:48:43 visual_prompt]: Epoch 29 / 100: avg data time: 5.55e-02, avg batch time: 0.5052, average train loss: 36.2387
[09/26 09:48:44 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 38.1496
[09/26 09:48:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 09:48:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 09:48:51 visual_prompt]: Epoch 30 / 100: avg data time: 4.41e-02, avg batch time: 0.4935, average train loss: 32.0694
[09/26 09:48:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1692, average loss: 22.9001
[09/26 09:48:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 09:48:52 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:48:59 visual_prompt]: Epoch 31 / 100: avg data time: 5.58e-02, avg batch time: 0.5035, average train loss: 21.7150
[09/26 09:49:01 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1689, average loss: 18.0600
[09/26 09:49:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 09:49:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:49:07 visual_prompt]: Epoch 32 / 100: avg data time: 4.51e-02, avg batch time: 0.4952, average train loss: 22.1645
[09/26 09:49:09 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1693, average loss: 21.4766
[09/26 09:49:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 09:49:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:49:15 visual_prompt]: Epoch 33 / 100: avg data time: 4.19e-02, avg batch time: 0.4910, average train loss: 24.3287
[09/26 09:49:17 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1691, average loss: 25.8187
[09/26 09:49:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 09:49:17 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:49:24 visual_prompt]: Epoch 34 / 100: avg data time: 5.64e-02, avg batch time: 0.5048, average train loss: 18.3510
[09/26 09:49:25 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1689, average loss: 15.8520
[09/26 09:49:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 09:49:25 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:49:32 visual_prompt]: Epoch 35 / 100: avg data time: 5.77e-02, avg batch time: 0.5058, average train loss: 17.1393
[09/26 09:49:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1692, average loss: 16.4160
[09/26 09:49:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 09:49:34 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:49:40 visual_prompt]: Epoch 36 / 100: avg data time: 4.78e-02, avg batch time: 0.4984, average train loss: 14.7056
[09/26 09:49:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 14.1030
[09/26 09:49:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 09:49:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:49:49 visual_prompt]: Epoch 37 / 100: avg data time: 5.60e-02, avg batch time: 0.5053, average train loss: 12.3897
[09/26 09:49:50 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1687, average loss: 11.0671
[09/26 09:49:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 09:49:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:49:57 visual_prompt]: Epoch 38 / 100: avg data time: 4.60e-02, avg batch time: 0.4953, average train loss: 10.5637
[09/26 09:49:59 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 10.3153
[09/26 09:49:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 09:49:59 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:50:05 visual_prompt]: Epoch 39 / 100: avg data time: 5.37e-02, avg batch time: 0.5018, average train loss: 9.8781
[09/26 09:50:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1690, average loss: 8.0210
[09/26 09:50:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 09:50:07 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:50:14 visual_prompt]: Epoch 40 / 100: avg data time: 5.14e-02, avg batch time: 0.5019, average train loss: 8.7508
[09/26 09:50:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 8.0601
[09/26 09:50:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 09:50:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:50:22 visual_prompt]: Epoch 41 / 100: avg data time: 5.96e-02, avg batch time: 0.5084, average train loss: 6.5118
[09/26 09:50:24 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1687, average loss: 5.3555
[09/26 09:50:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.00	
[09/26 09:50:24 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:50:31 visual_prompt]: Epoch 42 / 100: avg data time: 5.91e-02, avg batch time: 0.5078, average train loss: 5.1459
[09/26 09:50:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 4.2637
[09/26 09:50:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 09:50:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:50:39 visual_prompt]: Epoch 43 / 100: avg data time: 4.99e-02, avg batch time: 0.4989, average train loss: 3.7797
[09/26 09:50:40 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1690, average loss: 3.7863
[09/26 09:50:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 23.00	
[09/26 09:50:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:50:47 visual_prompt]: Epoch 44 / 100: avg data time: 4.85e-02, avg batch time: 0.4994, average train loss: 3.7965
[09/26 09:50:49 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 3.3955
[09/26 09:50:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 09:50:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:50:56 visual_prompt]: Epoch 45 / 100: avg data time: 5.49e-02, avg batch time: 0.5041, average train loss: 3.4185
[09/26 09:50:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1691, average loss: 3.3215
[09/26 09:50:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 09:50:57 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:51:04 visual_prompt]: Epoch 46 / 100: avg data time: 4.35e-02, avg batch time: 0.4927, average train loss: 3.3464
[09/26 09:51:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1689, average loss: 3.3607
[09/26 09:51:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 09:51:05 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:51:12 visual_prompt]: Epoch 47 / 100: avg data time: 4.91e-02, avg batch time: 0.4986, average train loss: 3.4594
[09/26 09:51:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1694, average loss: 3.5225
[09/26 09:51:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 09:51:14 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:51:20 visual_prompt]: Epoch 48 / 100: avg data time: 5.62e-02, avg batch time: 0.5054, average train loss: 3.3116
[09/26 09:51:22 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1690, average loss: 3.2870
[09/26 09:51:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 09:51:22 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:51:29 visual_prompt]: Epoch 49 / 100: avg data time: 4.22e-02, avg batch time: 0.4940, average train loss: 3.2735
[09/26 09:51:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1689, average loss: 3.5184
[09/26 09:51:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 09:51:30 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:51:37 visual_prompt]: Epoch 50 / 100: avg data time: 5.00e-02, avg batch time: 0.4997, average train loss: 3.2892
[09/26 09:51:38 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1695, average loss: 3.2350
[09/26 09:51:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 29.00	
[09/26 09:51:38 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:51:45 visual_prompt]: Epoch 51 / 100: avg data time: 4.65e-02, avg batch time: 0.4951, average train loss: 3.3469
[09/26 09:51:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 3.5873
[09/26 09:51:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 09:51:47 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:51:54 visual_prompt]: Epoch 52 / 100: avg data time: 5.67e-02, avg batch time: 0.5043, average train loss: 3.3167
[09/26 09:51:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 3.3805
[09/26 09:51:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 09:51:55 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:52:02 visual_prompt]: Epoch 53 / 100: avg data time: 4.50e-02, avg batch time: 0.4955, average train loss: 3.1249
[09/26 09:52:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 3.1542
[09/26 09:52:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 09:52:03 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:52:10 visual_prompt]: Epoch 54 / 100: avg data time: 5.17e-02, avg batch time: 0.5011, average train loss: 3.2076
[09/26 09:52:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1689, average loss: 3.2196
[09/26 09:52:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.50	
[09/26 09:52:12 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:52:19 visual_prompt]: Epoch 55 / 100: avg data time: 5.35e-02, avg batch time: 0.5017, average train loss: 3.1359
[09/26 09:52:20 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1693, average loss: 3.2359
[09/26 09:52:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 27.50	
[09/26 09:52:20 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:52:27 visual_prompt]: Epoch 56 / 100: avg data time: 5.40e-02, avg batch time: 0.5035, average train loss: 3.1619
[09/26 09:52:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 3.2580
[09/26 09:52:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 09:52:28 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:52:35 visual_prompt]: Epoch 57 / 100: avg data time: 5.76e-02, avg batch time: 0.5064, average train loss: 3.1724
[09/26 09:52:37 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1694, average loss: 3.3116
[09/26 09:52:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 09:52:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:52:44 visual_prompt]: Epoch 58 / 100: avg data time: 5.25e-02, avg batch time: 0.5043, average train loss: 3.1548
[09/26 09:52:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1691, average loss: 3.1208
[09/26 09:52:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 09:52:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:52:52 visual_prompt]: Epoch 59 / 100: avg data time: 6.11e-02, avg batch time: 0.5103, average train loss: 3.0384
[09/26 09:52:54 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1694, average loss: 3.2882
[09/26 09:52:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 31.50	
[09/26 09:52:54 visual_prompt]: Best epoch 59: best metric: 0.105
[09/26 09:52:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:53:00 visual_prompt]: Epoch 60 / 100: avg data time: 4.90e-02, avg batch time: 0.4979, average train loss: 3.0985
[09/26 09:53:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 3.2601
[09/26 09:53:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.50	
[09/26 09:53:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:53:09 visual_prompt]: Epoch 61 / 100: avg data time: 5.72e-02, avg batch time: 0.5067, average train loss: 3.0338
[09/26 09:53:10 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 3.0299
[09/26 09:53:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 36.00	
[09/26 09:53:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:53:17 visual_prompt]: Epoch 62 / 100: avg data time: 4.45e-02, avg batch time: 0.4940, average train loss: 3.0376
[09/26 09:53:18 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1694, average loss: 2.9570
[09/26 09:53:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 09:53:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:53:25 visual_prompt]: Epoch 63 / 100: avg data time: 5.64e-02, avg batch time: 0.5051, average train loss: 3.0313
[09/26 09:53:27 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 2.8929
[09/26 09:53:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 36.50	
[09/26 09:53:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:53:34 visual_prompt]: Epoch 64 / 100: avg data time: 4.34e-02, avg batch time: 0.4920, average train loss: 2.9660
[09/26 09:53:35 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1693, average loss: 3.0075
[09/26 09:53:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 43.50	
[09/26 09:53:35 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:53:42 visual_prompt]: Epoch 65 / 100: avg data time: 4.87e-02, avg batch time: 0.4979, average train loss: 2.8792
[09/26 09:53:43 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 3.0075
[09/26 09:53:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.50	
[09/26 09:53:43 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:53:50 visual_prompt]: Epoch 66 / 100: avg data time: 4.43e-02, avg batch time: 0.4945, average train loss: 2.9076
[09/26 09:53:52 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 2.8426
[09/26 09:53:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 36.00	
[09/26 09:53:52 visual_prompt]: Best epoch 66: best metric: 0.115
[09/26 09:53:52 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:53:58 visual_prompt]: Epoch 67 / 100: avg data time: 4.45e-02, avg batch time: 0.4945, average train loss: 2.8645
[09/26 09:54:00 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1696, average loss: 2.9478
[09/26 09:54:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 36.00	
[09/26 09:54:00 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:54:07 visual_prompt]: Epoch 68 / 100: avg data time: 5.34e-02, avg batch time: 0.5035, average train loss: 2.8166
[09/26 09:54:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 2.8795
[09/26 09:54:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 41.00	
[09/26 09:54:08 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:54:15 visual_prompt]: Epoch 69 / 100: avg data time: 4.39e-02, avg batch time: 0.4950, average train loss: 2.8358
[09/26 09:54:16 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 2.9542
[09/26 09:54:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 40.00	
[09/26 09:54:16 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:54:23 visual_prompt]: Epoch 70 / 100: avg data time: 4.45e-02, avg batch time: 0.4945, average train loss: 2.8043
[09/26 09:54:25 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 2.9842
[09/26 09:54:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 38.00	
[09/26 09:54:25 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:54:31 visual_prompt]: Epoch 71 / 100: avg data time: 4.93e-02, avg batch time: 0.4994, average train loss: 2.8007
[09/26 09:54:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1696, average loss: 2.9226
[09/26 09:54:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 39.50	
[09/26 09:54:33 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:54:40 visual_prompt]: Epoch 72 / 100: avg data time: 4.38e-02, avg batch time: 0.4934, average train loss: 2.7634
[09/26 09:54:41 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1691, average loss: 2.8690
[09/26 09:54:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 44.00	
[09/26 09:54:41 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:54:48 visual_prompt]: Epoch 73 / 100: avg data time: 6.88e-02, avg batch time: 0.5171, average train loss: 2.7369
[09/26 09:54:50 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1692, average loss: 2.9538
[09/26 09:54:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 39.00	
[09/26 09:54:50 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:54:57 visual_prompt]: Epoch 74 / 100: avg data time: 5.59e-02, avg batch time: 0.5046, average train loss: 2.6452
[09/26 09:54:58 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1695, average loss: 2.8440
[09/26 09:54:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 45.00	
[09/26 09:54:58 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:55:05 visual_prompt]: Epoch 75 / 100: avg data time: 4.66e-02, avg batch time: 0.4954, average train loss: 2.5769
[09/26 09:55:06 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1696, average loss: 2.7668
[09/26 09:55:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 47.00	
[09/26 09:55:06 visual_prompt]: Best epoch 75: best metric: 0.125
[09/26 09:55:06 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:55:13 visual_prompt]: Epoch 76 / 100: avg data time: 4.87e-02, avg batch time: 0.4982, average train loss: 2.5148
[09/26 09:55:15 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1694, average loss: 2.8012
[09/26 09:55:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 51.00	
[09/26 09:55:15 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:55:21 visual_prompt]: Epoch 77 / 100: avg data time: 6.07e-02, avg batch time: 0.5102, average train loss: 2.4390
[09/26 09:55:23 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1693, average loss: 2.8316
[09/26 09:55:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 51.50	
[09/26 09:55:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:55:30 visual_prompt]: Epoch 78 / 100: avg data time: 6.22e-02, avg batch time: 0.5112, average train loss: 2.3746
[09/26 09:55:32 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 2.6776
[09/26 09:55:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 60.00	
[09/26 09:55:32 visual_prompt]: Best epoch 78: best metric: 0.130
[09/26 09:55:32 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:55:39 visual_prompt]: Epoch 79 / 100: avg data time: 4.70e-02, avg batch time: 0.4966, average train loss: 2.2140
[09/26 09:55:40 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 3.0466
[09/26 09:55:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 53.00	
[09/26 09:55:40 visual_prompt]: Best epoch 79: best metric: 0.135
[09/26 09:55:40 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:55:47 visual_prompt]: Epoch 80 / 100: avg data time: 4.84e-02, avg batch time: 0.4977, average train loss: 2.2680
[09/26 09:55:48 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 2.7322
[09/26 09:55:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.50	
[09/26 09:55:48 visual_prompt]: Best epoch 80: best metric: 0.155
[09/26 09:55:48 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:55:55 visual_prompt]: Epoch 81 / 100: avg data time: 4.75e-02, avg batch time: 0.4961, average train loss: 2.2088
[09/26 09:55:57 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1692, average loss: 2.8077
[09/26 09:55:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 58.00	
[09/26 09:55:57 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:56:03 visual_prompt]: Epoch 82 / 100: avg data time: 5.15e-02, avg batch time: 0.5004, average train loss: 2.0901
[09/26 09:56:05 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1695, average loss: 2.8781
[09/26 09:56:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 61.00	
[09/26 09:56:05 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:56:12 visual_prompt]: Epoch 83 / 100: avg data time: 5.37e-02, avg batch time: 0.5030, average train loss: 1.9962
[09/26 09:56:13 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1697, average loss: 2.8957
[09/26 09:56:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 58.00	
[09/26 09:56:13 visual_prompt]: Best epoch 83: best metric: 0.160
[09/26 09:56:13 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:56:20 visual_prompt]: Epoch 84 / 100: avg data time: 5.49e-02, avg batch time: 0.5039, average train loss: 1.9760
[09/26 09:56:22 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1693, average loss: 2.9179
[09/26 09:56:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.50	
[09/26 09:56:22 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:56:28 visual_prompt]: Epoch 85 / 100: avg data time: 4.47e-02, avg batch time: 0.4947, average train loss: 1.8038
[09/26 09:56:30 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 2.9889
[09/26 09:56:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 09:56:30 visual_prompt]: Best epoch 85: best metric: 0.180
[09/26 09:56:30 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:56:37 visual_prompt]: Epoch 86 / 100: avg data time: 6.06e-02, avg batch time: 0.5097, average train loss: 1.6740
[09/26 09:56:38 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1698, average loss: 3.4318
[09/26 09:56:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 58.50	
[09/26 09:56:38 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:56:45 visual_prompt]: Epoch 87 / 100: avg data time: 5.56e-02, avg batch time: 0.5051, average train loss: 1.5997
[09/26 09:56:46 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1701, average loss: 3.3567
[09/26 09:56:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 59.00	
[09/26 09:56:46 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:56:53 visual_prompt]: Epoch 88 / 100: avg data time: 6.04e-02, avg batch time: 0.5102, average train loss: 1.5313
[09/26 09:56:55 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1695, average loss: 3.2808
[09/26 09:56:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 58.00	
[09/26 09:56:55 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:57:02 visual_prompt]: Epoch 89 / 100: avg data time: 4.46e-02, avg batch time: 0.4942, average train loss: 1.3804
[09/26 09:57:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 3.6465
[09/26 09:57:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 58.50	
[09/26 09:57:03 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:57:10 visual_prompt]: Epoch 90 / 100: avg data time: 6.23e-02, avg batch time: 0.5110, average train loss: 1.2263
[09/26 09:57:11 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 3.7732
[09/26 09:57:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.50	
[09/26 09:57:11 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:57:18 visual_prompt]: Epoch 91 / 100: avg data time: 5.34e-02, avg batch time: 0.5034, average train loss: 1.0883
[09/26 09:57:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1691, average loss: 3.8026
[09/26 09:57:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 58.50	
[09/26 09:57:20 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:57:27 visual_prompt]: Epoch 92 / 100: avg data time: 5.42e-02, avg batch time: 0.5027, average train loss: 0.9506
[09/26 09:57:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1694, average loss: 4.4450
[09/26 09:57:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 59.00	
[09/26 09:57:28 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:57:35 visual_prompt]: Epoch 93 / 100: avg data time: 5.62e-02, avg batch time: 0.5054, average train loss: 0.8333
[09/26 09:57:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1694, average loss: 4.1893
[09/26 09:57:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.00	
[09/26 09:57:36 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:57:43 visual_prompt]: Epoch 94 / 100: avg data time: 5.63e-02, avg batch time: 0.5061, average train loss: 0.6726
[09/26 09:57:45 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1696, average loss: 4.3050
[09/26 09:57:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 09:57:45 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:57:51 visual_prompt]: Epoch 95 / 100: avg data time: 5.40e-02, avg batch time: 0.5035, average train loss: 0.6086
[09/26 09:57:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 4.4611
[09/26 09:57:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 59.00	
[09/26 09:57:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:58:00 visual_prompt]: Epoch 96 / 100: avg data time: 5.93e-02, avg batch time: 0.5077, average train loss: 0.5131
[09/26 09:58:01 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1694, average loss: 4.5842
[09/26 09:58:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 61.50	
[09/26 09:58:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:58:08 visual_prompt]: Epoch 97 / 100: avg data time: 4.52e-02, avg batch time: 0.4961, average train loss: 0.4490
[09/26 09:58:10 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1691, average loss: 4.5279
[09/26 09:58:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 60.50	
[09/26 09:58:10 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:58:16 visual_prompt]: Epoch 98 / 100: avg data time: 4.76e-02, avg batch time: 0.4980, average train loss: 0.4232
[09/26 09:58:18 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1694, average loss: 4.5988
[09/26 09:58:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 60.50	
[09/26 09:58:18 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:58:25 visual_prompt]: Epoch 99 / 100: avg data time: 5.22e-02, avg batch time: 0.5010, average train loss: 0.4090
[09/26 09:58:26 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1693, average loss: 4.5628
[09/26 09:58:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 09:58:26 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:58:33 visual_prompt]: Epoch 100 / 100: avg data time: 4.52e-02, avg batch time: 0.4963, average train loss: 0.3910
[09/26 09:58:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 4.5637
[09/26 09:58:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 09:58:35 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:58:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:58:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:58:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:58:35 visual_prompt]: Training with config:
[09/26 09:58:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:58:35 visual_prompt]: Loading training data...
[09/26 09:58:35 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:58:36 visual_prompt]: Number of images: 800
[09/26 09:58:36 visual_prompt]: Number of classes: 18 / 18
[09/26 09:58:36 visual_prompt]: Loading validation data...
[09/26 09:58:36 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 09:58:36 visual_prompt]: Number of images: 200
[09/26 09:58:36 visual_prompt]: Number of classes: 18 / 18
[09/26 09:58:36 visual_prompt]: Constructing models...
[09/26 09:58:39 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 09:58:39 visual_prompt]: tuned percent:0.550
[09/26 09:58:39 visual_prompt]: Device used for model: 0
[09/26 09:58:39 visual_prompt]: Setting up Evaluator...
[09/26 09:58:39 visual_prompt]: Setting up Trainer...
[09/26 09:58:39 visual_prompt]: 	Setting up the optimizer...
[09/26 09:58:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:58:45 visual_prompt]: Epoch 1 / 100: avg data time: 4.66e-02, avg batch time: 0.4957, average train loss: 3.2556
[09/26 09:58:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 09:58:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 09:58:47 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 09:58:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:58:54 visual_prompt]: Epoch 2 / 100: avg data time: 4.83e-02, avg batch time: 0.4964, average train loss: 4.2696
[09/26 09:58:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1686, average loss: 3.7801
[09/26 09:58:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 09:58:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:59:02 visual_prompt]: Epoch 3 / 100: avg data time: 5.18e-02, avg batch time: 0.5007, average train loss: 3.5545
[09/26 09:59:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1691, average loss: 3.2496
[09/26 09:59:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 09:59:03 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 09:59:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:59:10 visual_prompt]: Epoch 4 / 100: avg data time: 4.27e-02, avg batch time: 0.4930, average train loss: 3.6261
[09/26 09:59:12 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1694, average loss: 3.5999
[09/26 09:59:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 09:59:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:59:18 visual_prompt]: Epoch 5 / 100: avg data time: 5.60e-02, avg batch time: 0.5037, average train loss: 3.6757
[09/26 09:59:20 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1693, average loss: 3.7359
[09/26 09:59:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.50	
[09/26 09:59:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:59:27 visual_prompt]: Epoch 6 / 100: avg data time: 4.51e-02, avg batch time: 0.4944, average train loss: 3.6564
[09/26 09:59:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 3.7335
[09/26 09:59:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 09:59:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:59:35 visual_prompt]: Epoch 7 / 100: avg data time: 5.36e-02, avg batch time: 0.5017, average train loss: 4.3321
[09/26 09:59:36 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 6.5005
[09/26 09:59:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 23.50	
[09/26 09:59:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:59:43 visual_prompt]: Epoch 8 / 100: avg data time: 4.69e-02, avg batch time: 0.4967, average train loss: 8.1728
[09/26 09:59:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 13.9149
[09/26 09:59:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 09:59:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:59:51 visual_prompt]: Epoch 9 / 100: avg data time: 5.25e-02, avg batch time: 0.5020, average train loss: 23.8445
[09/26 09:59:53 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1691, average loss: 37.2240
[09/26 09:59:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 09:59:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 10:00:00 visual_prompt]: Epoch 10 / 100: avg data time: 5.69e-02, avg batch time: 0.5058, average train loss: 38.9641
[09/26 10:00:02 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1687, average loss: 46.7451
[09/26 10:00:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 10:00:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 10:00:08 visual_prompt]: Epoch 11 / 100: avg data time: 4.69e-02, avg batch time: 0.4960, average train loss: 43.9652
[09/26 10:00:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 55.2132
[09/26 10:00:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 25.50	
[09/26 10:00:10 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 10:00:17 visual_prompt]: Epoch 12 / 100: avg data time: 5.86e-02, avg batch time: 0.5089, average train loss: 53.3991
[09/26 10:00:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 50.3788
[09/26 10:00:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 10:00:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 10:00:25 visual_prompt]: Epoch 13 / 100: avg data time: 5.79e-02, avg batch time: 0.5074, average train loss: 64.7933
[09/26 10:00:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 57.2833
[09/26 10:00:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.50	
[09/26 10:00:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 10:00:33 visual_prompt]: Epoch 14 / 100: avg data time: 5.85e-02, avg batch time: 0.5064, average train loss: 45.4536
[09/26 10:00:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1692, average loss: 27.2350
[09/26 10:00:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 10:00:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 10:00:42 visual_prompt]: Epoch 15 / 100: avg data time: 4.60e-02, avg batch time: 0.4948, average train loss: 36.9551
[09/26 10:00:43 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1694, average loss: 35.9864
[09/26 10:00:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 10:00:43 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 10:00:50 visual_prompt]: Epoch 16 / 100: avg data time: 5.27e-02, avg batch time: 0.5022, average train loss: 39.2705
[09/26 10:00:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 43.1090
[09/26 10:00:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 10:00:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 10:00:58 visual_prompt]: Epoch 17 / 100: avg data time: 4.54e-02, avg batch time: 0.4950, average train loss: 34.8685
[09/26 10:01:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 42.5212
[09/26 10:01:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.50	
[09/26 10:01:00 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 10:01:07 visual_prompt]: Epoch 18 / 100: avg data time: 5.34e-02, avg batch time: 0.5035, average train loss: 44.3412
[09/26 10:01:08 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 24.4611
[09/26 10:01:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 10:01:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 10:01:15 visual_prompt]: Epoch 19 / 100: avg data time: 5.53e-02, avg batch time: 0.5039, average train loss: 27.0288
[09/26 10:01:16 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1692, average loss: 35.0309
[09/26 10:01:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 10:01:16 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 10:01:23 visual_prompt]: Epoch 20 / 100: avg data time: 4.65e-02, avg batch time: 0.4958, average train loss: 32.6349
[09/26 10:01:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1698, average loss: 23.1995
[09/26 10:01:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 10:01:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 10:01:31 visual_prompt]: Epoch 21 / 100: avg data time: 4.34e-02, avg batch time: 0.4953, average train loss: 24.4292
[09/26 10:01:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 24.8291
[09/26 10:01:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 10:01:33 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 10:01:40 visual_prompt]: Epoch 22 / 100: avg data time: 4.48e-02, avg batch time: 0.4950, average train loss: 19.5249
[09/26 10:01:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 14.1549
[09/26 10:01:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 34.50	
[09/26 10:01:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 10:01:48 visual_prompt]: Epoch 23 / 100: avg data time: 4.61e-02, avg batch time: 0.4959, average train loss: 19.8512
[09/26 10:01:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1695, average loss: 21.3826
[09/26 10:01:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 10:01:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 10:01:56 visual_prompt]: Epoch 24 / 100: avg data time: 4.44e-02, avg batch time: 0.4935, average train loss: 15.4323
[09/26 10:01:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 16.8931
[09/26 10:01:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:01:58 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 10:02:04 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e-02, avg batch time: 0.5000, average train loss: 17.1764
[09/26 10:02:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 14.1198
[09/26 10:02:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:02:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 10:02:13 visual_prompt]: Epoch 26 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 16.3778
[09/26 10:02:14 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1696, average loss: 13.0541
[09/26 10:02:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:02:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 10:02:21 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e-02, avg batch time: 0.4999, average train loss: 15.7365
[09/26 10:02:22 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1693, average loss: 15.9982
[09/26 10:02:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 10:02:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 10:02:29 visual_prompt]: Epoch 28 / 100: avg data time: 5.53e-02, avg batch time: 0.5046, average train loss: 15.1430
[09/26 10:02:31 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1695, average loss: 16.5675
[09/26 10:02:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 10:02:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 10:02:38 visual_prompt]: Epoch 29 / 100: avg data time: 6.04e-02, avg batch time: 0.5105, average train loss: 14.3760
[09/26 10:02:39 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1691, average loss: 12.6572
[09/26 10:02:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 10:02:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 10:02:46 visual_prompt]: Epoch 30 / 100: avg data time: 5.56e-02, avg batch time: 0.5039, average train loss: 12.3208
[09/26 10:02:48 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 12.9407
[09/26 10:02:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 10:02:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 10:02:54 visual_prompt]: Epoch 31 / 100: avg data time: 5.04e-02, avg batch time: 0.5017, average train loss: 11.3865
[09/26 10:02:56 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1696, average loss: 10.9762
[09/26 10:02:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 10:02:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 10:03:03 visual_prompt]: Epoch 32 / 100: avg data time: 5.22e-02, avg batch time: 0.5019, average train loss: 8.8149
[09/26 10:03:04 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1696, average loss: 9.5858
[09/26 10:03:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 10:03:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 10:03:11 visual_prompt]: Epoch 33 / 100: avg data time: 4.97e-02, avg batch time: 0.4991, average train loss: 7.9141
[09/26 10:03:13 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1690, average loss: 6.2457
[09/26 10:03:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 10:03:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 10:03:19 visual_prompt]: Epoch 34 / 100: avg data time: 5.29e-02, avg batch time: 0.5035, average train loss: 6.0021
[09/26 10:03:21 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1695, average loss: 5.4529
[09/26 10:03:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 10:03:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 10:03:28 visual_prompt]: Epoch 35 / 100: avg data time: 5.75e-02, avg batch time: 0.5065, average train loss: 4.9330
[09/26 10:03:29 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1696, average loss: 3.7675
[09/26 10:03:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 10:03:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 10:03:36 visual_prompt]: Epoch 36 / 100: avg data time: 6.23e-02, avg batch time: 0.5107, average train loss: 3.9202
[09/26 10:03:38 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 3.7668
[09/26 10:03:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 31.00	
[09/26 10:03:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 10:03:45 visual_prompt]: Epoch 37 / 100: avg data time: 5.13e-02, avg batch time: 0.5002, average train loss: 3.7299
[09/26 10:03:46 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1694, average loss: 3.6001
[09/26 10:03:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 10:03:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 10:03:53 visual_prompt]: Epoch 38 / 100: avg data time: 5.21e-02, avg batch time: 0.5005, average train loss: 3.6468
[09/26 10:03:54 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 3.1894
[09/26 10:03:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.50	
[09/26 10:03:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 10:04:01 visual_prompt]: Epoch 39 / 100: avg data time: 5.44e-02, avg batch time: 0.5029, average train loss: 3.3766
[09/26 10:04:03 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1698, average loss: 3.6199
[09/26 10:04:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 27.50	
[09/26 10:04:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 10:04:10 visual_prompt]: Epoch 40 / 100: avg data time: 5.86e-02, avg batch time: 0.5078, average train loss: 3.5600
[09/26 10:04:11 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1693, average loss: 3.3337
[09/26 10:04:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 10:04:11 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 10:04:18 visual_prompt]: Epoch 41 / 100: avg data time: 5.76e-02, avg batch time: 0.5081, average train loss: 3.4046
[09/26 10:04:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1696, average loss: 3.3586
[09/26 10:04:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 36.50	
[09/26 10:04:20 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 10:04:26 visual_prompt]: Epoch 42 / 100: avg data time: 4.81e-02, avg batch time: 0.4977, average train loss: 3.3752
[09/26 10:04:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1694, average loss: 3.5349
[09/26 10:04:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 34.00	
[09/26 10:04:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 10:04:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.70e-02, avg batch time: 0.5059, average train loss: 3.4762
[09/26 10:04:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 3.5040
[09/26 10:04:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 10:04:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 10:04:43 visual_prompt]: Epoch 44 / 100: avg data time: 5.27e-02, avg batch time: 0.5021, average train loss: 3.3653
[09/26 10:04:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1701, average loss: 3.7206
[09/26 10:04:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.00	
[09/26 10:04:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 10:04:51 visual_prompt]: Epoch 45 / 100: avg data time: 5.97e-02, avg batch time: 0.5085, average train loss: 3.4201
[09/26 10:04:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1694, average loss: 3.4899
[09/26 10:04:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 10:04:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 10:05:00 visual_prompt]: Epoch 46 / 100: avg data time: 5.85e-02, avg batch time: 0.5085, average train loss: 3.5979
[09/26 10:05:01 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1695, average loss: 3.7633
[09/26 10:05:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 10:05:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 10:05:08 visual_prompt]: Epoch 47 / 100: avg data time: 5.45e-02, avg batch time: 0.5036, average train loss: 3.5889
[09/26 10:05:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1697, average loss: 3.9173
[09/26 10:05:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 10:05:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 10:05:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.32e-02, avg batch time: 0.5011, average train loss: 3.4927
[09/26 10:05:18 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1696, average loss: 3.6716
[09/26 10:05:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 10:05:18 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 10:05:25 visual_prompt]: Epoch 49 / 100: avg data time: 5.79e-02, avg batch time: 0.5070, average train loss: 3.2567
[09/26 10:05:27 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1693, average loss: 3.5020
[09/26 10:05:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.50	
[09/26 10:05:27 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 10:05:33 visual_prompt]: Epoch 50 / 100: avg data time: 4.31e-02, avg batch time: 0.4919, average train loss: 3.1993
[09/26 10:05:35 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1694, average loss: 3.1136
[09/26 10:05:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 34.00	
[09/26 10:05:35 visual_prompt]: Best epoch 50: best metric: 0.105
[09/26 10:05:35 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 10:05:41 visual_prompt]: Epoch 51 / 100: avg data time: 4.37e-02, avg batch time: 0.4936, average train loss: 3.1505
[09/26 10:05:43 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1697, average loss: 3.2893
[09/26 10:05:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 10:05:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 10:05:50 visual_prompt]: Epoch 52 / 100: avg data time: 5.69e-02, avg batch time: 0.5067, average train loss: 3.0479
[09/26 10:05:51 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1689, average loss: 3.4239
[09/26 10:05:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.50	
[09/26 10:05:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 10:05:58 visual_prompt]: Epoch 53 / 100: avg data time: 6.12e-02, avg batch time: 0.5104, average train loss: 3.2192
[09/26 10:06:00 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1694, average loss: 3.5102
[09/26 10:06:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:06:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 10:06:07 visual_prompt]: Epoch 54 / 100: avg data time: 5.69e-02, avg batch time: 0.5067, average train loss: 3.1439
[09/26 10:06:08 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1693, average loss: 2.9717
[09/26 10:06:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 35.50	
[09/26 10:06:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 10:06:15 visual_prompt]: Epoch 55 / 100: avg data time: 5.72e-02, avg batch time: 0.5054, average train loss: 3.0624
[09/26 10:06:17 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1697, average loss: 3.1780
[09/26 10:06:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 10:06:17 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 10:06:23 visual_prompt]: Epoch 56 / 100: avg data time: 5.41e-02, avg batch time: 0.5024, average train loss: 2.9569
[09/26 10:06:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1693, average loss: 3.1229
[09/26 10:06:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 10:06:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 10:06:32 visual_prompt]: Epoch 57 / 100: avg data time: 5.93e-02, avg batch time: 0.5080, average train loss: 2.9557
[09/26 10:06:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1697, average loss: 3.3190
[09/26 10:06:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 35.00	
[09/26 10:06:33 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 10:06:40 visual_prompt]: Epoch 58 / 100: avg data time: 6.00e-02, avg batch time: 0.5105, average train loss: 3.0377
[09/26 10:06:42 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1698, average loss: 3.4636
[09/26 10:06:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.50	
[09/26 10:06:42 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 10:06:49 visual_prompt]: Epoch 59 / 100: avg data time: 5.68e-02, avg batch time: 0.5052, average train loss: 3.0557
[09/26 10:06:50 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1694, average loss: 3.4162
[09/26 10:06:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 2.50	top5: 32.50	
[09/26 10:06:50 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 10:06:57 visual_prompt]: Epoch 60 / 100: avg data time: 6.24e-02, avg batch time: 0.5107, average train loss: 3.0011
[09/26 10:06:59 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.1694, average loss: 3.2107
[09/26 10:06:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 36.50	
[09/26 10:06:59 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 10:07:05 visual_prompt]: Epoch 61 / 100: avg data time: 4.27e-02, avg batch time: 0.4933, average train loss: 2.9121
[09/26 10:07:07 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1694, average loss: 3.0548
[09/26 10:07:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 34.50	
[09/26 10:07:07 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 10:07:14 visual_prompt]: Epoch 62 / 100: avg data time: 5.77e-02, avg batch time: 0.5066, average train loss: 2.9078
[09/26 10:07:15 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.1695, average loss: 3.0785
[09/26 10:07:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 38.50	
[09/26 10:07:15 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 10:07:22 visual_prompt]: Epoch 63 / 100: avg data time: 5.18e-02, avg batch time: 0.5013, average train loss: 2.8760
[09/26 10:07:23 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1694, average loss: 3.0872
[09/26 10:07:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 40.50	
[09/26 10:07:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 10:07:30 visual_prompt]: Epoch 64 / 100: avg data time: 5.48e-02, avg batch time: 0.5041, average train loss: 2.8108
[09/26 10:07:32 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1695, average loss: 2.9738
[09/26 10:07:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 40.00	
[09/26 10:07:32 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 10:07:39 visual_prompt]: Epoch 65 / 100: avg data time: 5.51e-02, avg batch time: 0.5042, average train loss: 2.8038
[09/26 10:07:40 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1693, average loss: 2.9019
[09/26 10:07:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 45.00	
[09/26 10:07:40 visual_prompt]: Best epoch 65: best metric: 0.120
[09/26 10:07:40 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 10:07:47 visual_prompt]: Epoch 66 / 100: avg data time: 5.79e-02, avg batch time: 0.5071, average train loss: 2.7997
[09/26 10:07:49 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1694, average loss: 2.9031
[09/26 10:07:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 46.50	
[09/26 10:07:49 visual_prompt]: Best epoch 66: best metric: 0.125
[09/26 10:07:49 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 10:07:55 visual_prompt]: Epoch 67 / 100: avg data time: 5.44e-02, avg batch time: 0.5035, average train loss: 2.7084
[09/26 10:07:57 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1691, average loss: 2.9213
[09/26 10:07:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 44.50	
[09/26 10:07:57 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 10:08:04 visual_prompt]: Epoch 68 / 100: avg data time: 5.16e-02, avg batch time: 0.5002, average train loss: 2.7004
[09/26 10:08:05 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1691, average loss: 2.9383
[09/26 10:08:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 40.50	
[09/26 10:08:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 10:08:12 visual_prompt]: Epoch 69 / 100: avg data time: 5.46e-02, avg batch time: 0.5047, average train loss: 2.7360
[09/26 10:08:14 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 2.9367
[09/26 10:08:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 43.00	
[09/26 10:08:14 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 10:08:20 visual_prompt]: Epoch 70 / 100: avg data time: 6.04e-02, avg batch time: 0.5108, average train loss: 2.7394
[09/26 10:08:22 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1696, average loss: 2.9183
[09/26 10:08:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 46.00	
[09/26 10:08:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 10:08:29 visual_prompt]: Epoch 71 / 100: avg data time: 5.91e-02, avg batch time: 0.5092, average train loss: 2.7772
[09/26 10:08:30 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 2.9277
[09/26 10:08:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 43.50	
[09/26 10:08:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 10:08:37 visual_prompt]: Epoch 72 / 100: avg data time: 5.83e-02, avg batch time: 0.5086, average train loss: 2.6989
[09/26 10:08:39 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1696, average loss: 2.9828
[09/26 10:08:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 45.50	
[09/26 10:08:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 10:08:46 visual_prompt]: Epoch 73 / 100: avg data time: 4.88e-02, avg batch time: 0.4975, average train loss: 2.6164
[09/26 10:08:47 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 2.9022
[09/26 10:08:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 43.50	
[09/26 10:08:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 10:08:54 visual_prompt]: Epoch 74 / 100: avg data time: 6.54e-02, avg batch time: 0.5140, average train loss: 2.5851
[09/26 10:08:56 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1695, average loss: 2.8294
[09/26 10:08:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 48.00	
[09/26 10:08:56 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 10:09:02 visual_prompt]: Epoch 75 / 100: avg data time: 5.61e-02, avg batch time: 0.5063, average train loss: 2.5726
[09/26 10:09:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 2.8211
[09/26 10:09:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 52.00	
[09/26 10:09:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 10:09:11 visual_prompt]: Epoch 76 / 100: avg data time: 4.27e-02, avg batch time: 0.4935, average train loss: 2.5519
[09/26 10:09:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1696, average loss: 2.8206
[09/26 10:09:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 47.00	
[09/26 10:09:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 10:09:19 visual_prompt]: Epoch 77 / 100: avg data time: 4.80e-02, avg batch time: 0.4966, average train loss: 2.4881
[09/26 10:09:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 2.8124
[09/26 10:09:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 50.00	
[09/26 10:09:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 10:09:27 visual_prompt]: Epoch 78 / 100: avg data time: 5.45e-02, avg batch time: 0.5029, average train loss: 2.5383
[09/26 10:09:29 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1696, average loss: 2.8523
[09/26 10:09:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 47.00	
[09/26 10:09:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 10:09:35 visual_prompt]: Epoch 79 / 100: avg data time: 5.08e-02, avg batch time: 0.5003, average train loss: 2.5099
[09/26 10:09:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 2.7678
[09/26 10:09:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 52.00	
[09/26 10:09:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 10:09:44 visual_prompt]: Epoch 80 / 100: avg data time: 4.28e-02, avg batch time: 0.4922, average train loss: 2.5092
[09/26 10:09:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1696, average loss: 2.8494
[09/26 10:09:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 48.50	
[09/26 10:09:45 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 10:09:52 visual_prompt]: Epoch 81 / 100: avg data time: 5.27e-02, avg batch time: 0.5022, average train loss: 2.4570
[09/26 10:09:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1693, average loss: 2.8317
[09/26 10:09:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 50.50	
[09/26 10:09:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 10:10:00 visual_prompt]: Epoch 82 / 100: avg data time: 5.34e-02, avg batch time: 0.5018, average train loss: 2.4758
[09/26 10:10:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1696, average loss: 2.7123
[09/26 10:10:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.50	
[09/26 10:10:02 visual_prompt]: Best epoch 82: best metric: 0.140
[09/26 10:10:02 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 10:10:09 visual_prompt]: Epoch 83 / 100: avg data time: 5.48e-02, avg batch time: 0.5031, average train loss: 2.4512
[09/26 10:10:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1695, average loss: 2.8040
[09/26 10:10:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 51.50	
[09/26 10:10:10 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 10:10:17 visual_prompt]: Epoch 84 / 100: avg data time: 4.18e-02, avg batch time: 0.4907, average train loss: 2.4186
[09/26 10:10:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 2.6882
[09/26 10:10:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.00	
[09/26 10:10:18 visual_prompt]: Best epoch 84: best metric: 0.155
[09/26 10:10:18 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 10:10:25 visual_prompt]: Epoch 85 / 100: avg data time: 5.28e-02, avg batch time: 0.5024, average train loss: 2.3835
[09/26 10:10:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1692, average loss: 2.7351
[09/26 10:10:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 51.50	
[09/26 10:10:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 10:10:33 visual_prompt]: Epoch 86 / 100: avg data time: 6.10e-02, avg batch time: 0.5098, average train loss: 2.4120
[09/26 10:10:35 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 2.7195
[09/26 10:10:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 53.50	
[09/26 10:10:35 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 10:10:42 visual_prompt]: Epoch 87 / 100: avg data time: 6.24e-02, avg batch time: 0.5108, average train loss: 2.3948
[09/26 10:10:44 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1695, average loss: 2.7047
[09/26 10:10:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.50	
[09/26 10:10:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 10:10:50 visual_prompt]: Epoch 88 / 100: avg data time: 5.76e-02, avg batch time: 0.5068, average train loss: 2.3649
[09/26 10:10:52 visual_prompt]: Inference (val):avg data time: 5.04e-05, avg batch time: 0.1693, average loss: 2.7120
[09/26 10:10:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 54.00	
[09/26 10:10:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 10:10:59 visual_prompt]: Epoch 89 / 100: avg data time: 5.38e-02, avg batch time: 0.5040, average train loss: 2.3536
[09/26 10:11:00 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1694, average loss: 2.6950
[09/26 10:11:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.50	
[09/26 10:11:00 visual_prompt]: Best epoch 89: best metric: 0.160
[09/26 10:11:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 10:11:07 visual_prompt]: Epoch 90 / 100: avg data time: 5.00e-02, avg batch time: 0.4986, average train loss: 2.3597
[09/26 10:11:09 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1693, average loss: 2.6997
[09/26 10:11:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 58.00	
[09/26 10:11:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 10:11:15 visual_prompt]: Epoch 91 / 100: avg data time: 5.42e-02, avg batch time: 0.5024, average train loss: 2.3148
[09/26 10:11:17 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1696, average loss: 2.6909
[09/26 10:11:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 10:11:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 10:11:24 visual_prompt]: Epoch 92 / 100: avg data time: 3.94e-02, avg batch time: 0.4908, average train loss: 2.3443
[09/26 10:11:25 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1695, average loss: 2.6908
[09/26 10:11:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 56.00	
[09/26 10:11:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 10:11:32 visual_prompt]: Epoch 93 / 100: avg data time: 5.72e-02, avg batch time: 0.5068, average train loss: 2.3504
[09/26 10:11:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1691, average loss: 2.6908
[09/26 10:11:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.00	
[09/26 10:11:34 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 10:11:41 visual_prompt]: Epoch 94 / 100: avg data time: 6.32e-02, avg batch time: 0.5122, average train loss: 2.3207
[09/26 10:11:42 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 2.7082
[09/26 10:11:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 53.50	
[09/26 10:11:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 10:11:49 visual_prompt]: Epoch 95 / 100: avg data time: 5.43e-02, avg batch time: 0.5038, average train loss: 2.3256
[09/26 10:11:50 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 2.7005
[09/26 10:11:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.50	
[09/26 10:11:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 10:11:57 visual_prompt]: Epoch 96 / 100: avg data time: 5.67e-02, avg batch time: 0.5049, average train loss: 2.3125
[09/26 10:11:59 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 2.7008
[09/26 10:11:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 56.00	
[09/26 10:11:59 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 10:12:06 visual_prompt]: Epoch 97 / 100: avg data time: 6.28e-02, avg batch time: 0.5112, average train loss: 2.3052
[09/26 10:12:07 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1694, average loss: 2.6981
[09/26 10:12:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 10:12:07 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 10:12:14 visual_prompt]: Epoch 98 / 100: avg data time: 6.39e-02, avg batch time: 0.5131, average train loss: 2.3493
[09/26 10:12:16 visual_prompt]: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1695, average loss: 2.6989
[09/26 10:12:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.00	
[09/26 10:12:16 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 10:12:23 visual_prompt]: Epoch 99 / 100: avg data time: 6.11e-02, avg batch time: 0.5105, average train loss: 2.3042
[09/26 10:12:24 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1694, average loss: 2.6988
[09/26 10:12:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 56.00	
[09/26 10:12:24 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 10:12:31 visual_prompt]: Epoch 100 / 100: avg data time: 4.93e-02, avg batch time: 0.4982, average train loss: 2.3099
[09/26 10:12:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1695, average loss: 2.6987
[09/26 10:12:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 56.00	
[09/26 10:12:33 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:12:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:12:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:12:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:12:33 visual_prompt]: Training with config:
[09/26 10:12:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:12:33 visual_prompt]: Loading training data...
[09/26 10:12:33 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:12:34 visual_prompt]: Number of images: 800
[09/26 10:12:34 visual_prompt]: Number of classes: 18 / 18
[09/26 10:12:34 visual_prompt]: Loading validation data...
[09/26 10:12:34 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:12:34 visual_prompt]: Number of images: 200
[09/26 10:12:34 visual_prompt]: Number of classes: 18 / 18
[09/26 10:12:34 visual_prompt]: Constructing models...
[09/26 10:12:36 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 10:12:36 visual_prompt]: tuned percent:0.550
[09/26 10:12:37 visual_prompt]: Device used for model: 0
[09/26 10:12:37 visual_prompt]: Setting up Evaluator...
[09/26 10:12:37 visual_prompt]: Setting up Trainer...
[09/26 10:12:37 visual_prompt]: 	Setting up the optimizer...
[09/26 10:12:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:12:43 visual_prompt]: Epoch 1 / 100: avg data time: 6.15e-02, avg batch time: 0.5110, average train loss: 3.2488
[09/26 10:12:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1692, average loss: 3.1895
[09/26 10:12:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 10:12:45 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 10:12:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:12:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.20e-02, avg batch time: 0.5011, average train loss: 3.5019
[09/26 10:12:53 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1687, average loss: 3.1762
[09/26 10:12:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 10:12:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:13:00 visual_prompt]: Epoch 3 / 100: avg data time: 5.62e-02, avg batch time: 0.5037, average train loss: 3.0486
[09/26 10:13:02 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1683, average loss: 3.0363
[09/26 10:13:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.50	
[09/26 10:13:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:13:08 visual_prompt]: Epoch 4 / 100: avg data time: 5.75e-02, avg batch time: 0.5035, average train loss: 3.0232
[09/26 10:13:10 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1686, average loss: 3.0394
[09/26 10:13:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 10:13:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:13:17 visual_prompt]: Epoch 5 / 100: avg data time: 6.07e-02, avg batch time: 0.5070, average train loss: 3.0345
[09/26 10:13:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 2.9873
[09/26 10:13:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 10:13:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:13:25 visual_prompt]: Epoch 6 / 100: avg data time: 5.74e-02, avg batch time: 0.5053, average train loss: 3.0707
[09/26 10:13:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1694, average loss: 3.0815
[09/26 10:13:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 10:13:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:13:33 visual_prompt]: Epoch 7 / 100: avg data time: 4.14e-02, avg batch time: 0.4948, average train loss: 3.2395
[09/26 10:13:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 3.2520
[09/26 10:13:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:13:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:13:42 visual_prompt]: Epoch 8 / 100: avg data time: 5.56e-02, avg batch time: 0.5041, average train loss: 3.5346
[09/26 10:13:43 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 4.7256
[09/26 10:13:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 10:13:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:13:50 visual_prompt]: Epoch 9 / 100: avg data time: 5.89e-02, avg batch time: 0.5063, average train loss: 5.6070
[09/26 10:13:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 7.4701
[09/26 10:13:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 10:13:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:13:58 visual_prompt]: Epoch 10 / 100: avg data time: 6.56e-02, avg batch time: 0.5127, average train loss: 8.6885
[09/26 10:14:00 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1694, average loss: 8.9109
[09/26 10:14:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 10:14:00 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:14:07 visual_prompt]: Epoch 11 / 100: avg data time: 6.21e-02, avg batch time: 0.5099, average train loss: 9.5155
[09/26 10:14:08 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1695, average loss: 10.0251
[09/26 10:14:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 10:14:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:14:15 visual_prompt]: Epoch 12 / 100: avg data time: 5.47e-02, avg batch time: 0.5025, average train loss: 10.0238
[09/26 10:14:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 11.2257
[09/26 10:14:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 10:14:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:14:24 visual_prompt]: Epoch 13 / 100: avg data time: 5.62e-02, avg batch time: 0.5047, average train loss: 13.5323
[09/26 10:14:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 14.9556
[09/26 10:14:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 10:14:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:14:32 visual_prompt]: Epoch 14 / 100: avg data time: 4.92e-02, avg batch time: 0.4990, average train loss: 14.1936
[09/26 10:14:33 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1695, average loss: 13.8365
[09/26 10:14:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 10:14:33 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:14:40 visual_prompt]: Epoch 15 / 100: avg data time: 5.96e-02, avg batch time: 0.5076, average train loss: 16.9424
[09/26 10:14:42 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1691, average loss: 16.3622
[09/26 10:14:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 2.50	top5: 27.00	
[09/26 10:14:42 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:14:49 visual_prompt]: Epoch 16 / 100: avg data time: 6.43e-02, avg batch time: 0.5124, average train loss: 13.3860
[09/26 10:14:50 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1690, average loss: 10.2530
[09/26 10:14:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 10:14:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:14:57 visual_prompt]: Epoch 17 / 100: avg data time: 5.49e-02, avg batch time: 0.5034, average train loss: 12.6555
[09/26 10:14:59 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1691, average loss: 17.7798
[09/26 10:14:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 10:14:59 visual_prompt]: Best epoch 17: best metric: 0.065
[09/26 10:14:59 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:15:05 visual_prompt]: Epoch 18 / 100: avg data time: 4.67e-02, avg batch time: 0.4967, average train loss: 30.6397
[09/26 10:15:07 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1684, average loss: 34.2616
[09/26 10:15:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 10:15:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:15:14 visual_prompt]: Epoch 19 / 100: avg data time: 5.67e-02, avg batch time: 0.5050, average train loss: 19.6236
[09/26 10:15:15 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1693, average loss: 12.7104
[09/26 10:15:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 35.00	
[09/26 10:15:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:15:22 visual_prompt]: Epoch 20 / 100: avg data time: 5.84e-02, avg batch time: 0.5064, average train loss: 15.2855
[09/26 10:15:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 22.9116
[09/26 10:15:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 10:15:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:15:30 visual_prompt]: Epoch 21 / 100: avg data time: 4.87e-02, avg batch time: 0.4971, average train loss: 28.5725
[09/26 10:15:32 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1692, average loss: 22.9604
[09/26 10:15:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 10:15:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:15:39 visual_prompt]: Epoch 22 / 100: avg data time: 5.30e-02, avg batch time: 0.5017, average train loss: 20.5776
[09/26 10:15:40 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 13.7238
[09/26 10:15:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 10:15:40 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:15:47 visual_prompt]: Epoch 23 / 100: avg data time: 5.94e-02, avg batch time: 0.5069, average train loss: 17.3121
[09/26 10:15:49 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 18.7387
[09/26 10:15:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 10:15:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:15:56 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e-02, avg batch time: 0.5001, average train loss: 17.8590
[09/26 10:15:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 16.1521
[09/26 10:15:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:15:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:16:04 visual_prompt]: Epoch 25 / 100: avg data time: 5.40e-02, avg batch time: 0.5019, average train loss: 21.9022
[09/26 10:16:05 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1690, average loss: 14.0863
[09/26 10:16:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 10:16:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:16:12 visual_prompt]: Epoch 26 / 100: avg data time: 4.65e-02, avg batch time: 0.4968, average train loss: 19.6189
[09/26 10:16:14 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1689, average loss: 17.9702
[09/26 10:16:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 10:16:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:16:21 visual_prompt]: Epoch 27 / 100: avg data time: 6.06e-02, avg batch time: 0.5081, average train loss: 18.3273
[09/26 10:16:22 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1692, average loss: 10.7340
[09/26 10:16:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 10:16:22 visual_prompt]: Best epoch 27: best metric: 0.085
[09/26 10:16:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:16:29 visual_prompt]: Epoch 28 / 100: avg data time: 5.63e-02, avg batch time: 0.5052, average train loss: 15.6616
[09/26 10:16:31 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1690, average loss: 19.8185
[09/26 10:16:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 10:16:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:16:37 visual_prompt]: Epoch 29 / 100: avg data time: 5.72e-02, avg batch time: 0.5064, average train loss: 18.8390
[09/26 10:16:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 9.8495
[09/26 10:16:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 10:16:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:16:46 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e-02, avg batch time: 0.5044, average train loss: 19.7141
[09/26 10:16:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 17.4604
[09/26 10:16:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 10:16:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:16:54 visual_prompt]: Epoch 31 / 100: avg data time: 5.29e-02, avg batch time: 0.5007, average train loss: 15.5759
[09/26 10:16:56 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1686, average loss: 12.9683
[09/26 10:16:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 10:16:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:17:03 visual_prompt]: Epoch 32 / 100: avg data time: 4.70e-02, avg batch time: 0.4960, average train loss: 17.9144
[09/26 10:17:04 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1687, average loss: 20.6247
[09/26 10:17:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 10:17:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:17:11 visual_prompt]: Epoch 33 / 100: avg data time: 4.28e-02, avg batch time: 0.4913, average train loss: 16.8337
[09/26 10:17:12 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 13.6023
[09/26 10:17:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 10:17:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:17:19 visual_prompt]: Epoch 34 / 100: avg data time: 4.31e-02, avg batch time: 0.4927, average train loss: 18.4413
[09/26 10:17:21 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1690, average loss: 22.4206
[09/26 10:17:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 10:17:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:17:27 visual_prompt]: Epoch 35 / 100: avg data time: 4.45e-02, avg batch time: 0.4933, average train loss: 26.4990
[09/26 10:17:29 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1695, average loss: 19.9715
[09/26 10:17:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:17:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:17:36 visual_prompt]: Epoch 36 / 100: avg data time: 5.56e-02, avg batch time: 0.5045, average train loss: 13.6955
[09/26 10:17:37 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1687, average loss: 14.3923
[09/26 10:17:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 10:17:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:17:44 visual_prompt]: Epoch 37 / 100: avg data time: 5.22e-02, avg batch time: 0.5004, average train loss: 14.5716
[09/26 10:17:45 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1697, average loss: 15.7119
[09/26 10:17:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 10:17:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 10:17:52 visual_prompt]: Epoch 38 / 100: avg data time: 4.94e-02, avg batch time: 0.4987, average train loss: 15.2336
[09/26 10:17:54 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1694, average loss: 15.6831
[09/26 10:17:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 10:17:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 10:18:01 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e-02, avg batch time: 0.5053, average train loss: 15.0217
[09/26 10:18:02 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1693, average loss: 9.0066
[09/26 10:18:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:18:02 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 10:18:09 visual_prompt]: Epoch 40 / 100: avg data time: 4.88e-02, avg batch time: 0.4973, average train loss: 17.8872
[09/26 10:18:10 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1696, average loss: 25.9158
[09/26 10:18:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 10:18:10 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 10:18:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.39e-02, avg batch time: 0.5026, average train loss: 22.3401
[09/26 10:18:19 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 18.1738
[09/26 10:18:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 10:18:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 10:18:26 visual_prompt]: Epoch 42 / 100: avg data time: 5.11e-02, avg batch time: 0.5007, average train loss: 14.6564
[09/26 10:18:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 14.4144
[09/26 10:18:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.50	
[09/26 10:18:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 10:18:34 visual_prompt]: Epoch 43 / 100: avg data time: 4.57e-02, avg batch time: 0.4949, average train loss: 12.1373
[09/26 10:18:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 13.8391
[09/26 10:18:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 10:18:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 10:18:42 visual_prompt]: Epoch 44 / 100: avg data time: 4.70e-02, avg batch time: 0.4983, average train loss: 10.4434
[09/26 10:18:44 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 10.0311
[09/26 10:18:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 10:18:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 10:18:51 visual_prompt]: Epoch 45 / 100: avg data time: 5.00e-02, avg batch time: 0.5003, average train loss: 7.0938
[09/26 10:18:52 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1691, average loss: 4.3779
[09/26 10:18:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 10:18:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 10:18:59 visual_prompt]: Epoch 46 / 100: avg data time: 5.33e-02, avg batch time: 0.5016, average train loss: 6.8170
[09/26 10:19:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1686, average loss: 8.8971
[09/26 10:19:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 24.00	
[09/26 10:19:00 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 10:19:07 visual_prompt]: Epoch 47 / 100: avg data time: 5.66e-02, avg batch time: 0.5056, average train loss: 8.4717
[09/26 10:19:09 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 8.7956
[09/26 10:19:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 31.00	
[09/26 10:19:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 10:19:16 visual_prompt]: Epoch 48 / 100: avg data time: 6.13e-02, avg batch time: 0.5097, average train loss: 7.5987
[09/26 10:19:17 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 5.4600
[09/26 10:19:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:19:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 10:19:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.91e-02, avg batch time: 0.5079, average train loss: 4.9953
[09/26 10:19:26 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1693, average loss: 5.1762
[09/26 10:19:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.50	
[09/26 10:19:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 10:19:33 visual_prompt]: Epoch 50 / 100: avg data time: 5.75e-02, avg batch time: 0.5061, average train loss: 4.5488
[09/26 10:19:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 4.9032
[09/26 10:19:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 10:19:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 10:19:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.58e-02, avg batch time: 0.5052, average train loss: 5.4164
[09/26 10:19:42 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1693, average loss: 4.6643
[09/26 10:19:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 10:19:42 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 10:19:49 visual_prompt]: Epoch 52 / 100: avg data time: 4.99e-02, avg batch time: 0.4988, average train loss: 3.6938
[09/26 10:19:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 3.4614
[09/26 10:19:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 10:19:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 10:19:58 visual_prompt]: Epoch 53 / 100: avg data time: 5.63e-02, avg batch time: 0.5046, average train loss: 3.7863
[09/26 10:19:59 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 4.9735
[09/26 10:19:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 10:19:59 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 10:20:06 visual_prompt]: Epoch 54 / 100: avg data time: 4.50e-02, avg batch time: 0.4948, average train loss: 5.0018
[09/26 10:20:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1696, average loss: 7.6736
[09/26 10:20:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.00	
[09/26 10:20:07 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 10:20:14 visual_prompt]: Epoch 55 / 100: avg data time: 4.65e-02, avg batch time: 0.4949, average train loss: 6.2688
[09/26 10:20:16 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1696, average loss: 4.5002
[09/26 10:20:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 10:20:16 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 10:20:23 visual_prompt]: Epoch 56 / 100: avg data time: 4.78e-02, avg batch time: 0.4981, average train loss: 5.1083
[09/26 10:20:24 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1694, average loss: 26.0327
[09/26 10:20:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.00	
[09/26 10:20:24 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 10:20:31 visual_prompt]: Epoch 57 / 100: avg data time: 5.60e-02, avg batch time: 0.5056, average train loss: 6.7341
[09/26 10:20:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1695, average loss: 3.3775
[09/26 10:20:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.00	
[09/26 10:20:33 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 10:20:39 visual_prompt]: Epoch 58 / 100: avg data time: 5.90e-02, avg batch time: 0.5070, average train loss: 6.0852
[09/26 10:20:41 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 7.8053
[09/26 10:20:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 21.50	
[09/26 10:20:41 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:20:48 visual_prompt]: Epoch 59 / 100: avg data time: 5.81e-02, avg batch time: 0.5071, average train loss: 6.4992
[09/26 10:20:49 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1693, average loss: 4.1257
[09/26 10:20:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 10:20:49 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:20:56 visual_prompt]: Epoch 60 / 100: avg data time: 6.27e-02, avg batch time: 0.5109, average train loss: 5.3324
[09/26 10:20:58 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1693, average loss: 5.8230
[09/26 10:20:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 10:20:58 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:21:05 visual_prompt]: Epoch 61 / 100: avg data time: 5.06e-02, avg batch time: 0.4993, average train loss: 5.3226
[09/26 10:21:06 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 4.8432
[09/26 10:21:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 23.50	
[09/26 10:21:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:21:13 visual_prompt]: Epoch 62 / 100: avg data time: 5.76e-02, avg batch time: 0.5068, average train loss: 4.6578
[09/26 10:21:15 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1689, average loss: 5.5001
[09/26 10:21:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:21:15 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:21:21 visual_prompt]: Epoch 63 / 100: avg data time: 5.84e-02, avg batch time: 0.5066, average train loss: 4.6346
[09/26 10:21:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 4.3044
[09/26 10:21:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 10:21:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:21:30 visual_prompt]: Epoch 64 / 100: avg data time: 5.80e-02, avg batch time: 0.5066, average train loss: 4.0176
[09/26 10:21:31 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 3.6924
[09/26 10:21:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 10:21:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:21:38 visual_prompt]: Epoch 65 / 100: avg data time: 5.33e-02, avg batch time: 0.5011, average train loss: 3.7611
[09/26 10:21:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1696, average loss: 3.7911
[09/26 10:21:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 10:21:40 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:21:47 visual_prompt]: Epoch 66 / 100: avg data time: 5.29e-02, avg batch time: 0.5013, average train loss: 3.3945
[09/26 10:21:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 3.2885
[09/26 10:21:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 10:21:48 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:21:55 visual_prompt]: Epoch 67 / 100: avg data time: 5.40e-02, avg batch time: 0.5046, average train loss: 3.1586
[09/26 10:21:57 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1688, average loss: 3.2116
[09/26 10:21:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 10:21:57 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:22:03 visual_prompt]: Epoch 68 / 100: avg data time: 5.26e-02, avg batch time: 0.5022, average train loss: 3.0536
[09/26 10:22:05 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1696, average loss: 3.1430
[09/26 10:22:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.50	
[09/26 10:22:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:22:12 visual_prompt]: Epoch 69 / 100: avg data time: 4.86e-02, avg batch time: 0.4978, average train loss: 3.0207
[09/26 10:22:13 visual_prompt]: Inference (val):avg data time: 4.27e-05, avg batch time: 0.1693, average loss: 3.0067
[09/26 10:22:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:22:13 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:22:20 visual_prompt]: Epoch 70 / 100: avg data time: 4.69e-02, avg batch time: 0.4964, average train loss: 3.0176
[09/26 10:22:22 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 3.0136
[09/26 10:22:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 10:22:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:22:28 visual_prompt]: Epoch 71 / 100: avg data time: 5.12e-02, avg batch time: 0.5008, average train loss: 2.9837
[09/26 10:22:30 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1689, average loss: 3.1040
[09/26 10:22:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 10:22:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:22:37 visual_prompt]: Epoch 72 / 100: avg data time: 4.78e-02, avg batch time: 0.4970, average train loss: 2.9807
[09/26 10:22:38 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1694, average loss: 2.9464
[09/26 10:22:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 10:22:38 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:22:45 visual_prompt]: Epoch 73 / 100: avg data time: 6.16e-02, avg batch time: 0.5088, average train loss: 2.9603
[09/26 10:22:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1694, average loss: 2.9785
[09/26 10:22:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 10:22:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:22:53 visual_prompt]: Epoch 74 / 100: avg data time: 4.65e-02, avg batch time: 0.4955, average train loss: 3.0182
[09/26 10:22:55 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1689, average loss: 3.0433
[09/26 10:22:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 25.50	
[09/26 10:22:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:23:02 visual_prompt]: Epoch 75 / 100: avg data time: 5.43e-02, avg batch time: 0.5021, average train loss: 2.9704
[09/26 10:23:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 2.9755
[09/26 10:23:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.00	
[09/26 10:23:03 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:23:10 visual_prompt]: Epoch 76 / 100: avg data time: 5.73e-02, avg batch time: 0.5063, average train loss: 2.9457
[09/26 10:23:12 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1685, average loss: 2.9646
[09/26 10:23:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 10:23:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:23:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.48e-02, avg batch time: 0.5041, average train loss: 2.9560
[09/26 10:23:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 2.9406
[09/26 10:23:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 10:23:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:23:27 visual_prompt]: Epoch 78 / 100: avg data time: 5.34e-02, avg batch time: 0.5026, average train loss: 2.9374
[09/26 10:23:28 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 2.9151
[09/26 10:23:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.00	
[09/26 10:23:28 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:23:35 visual_prompt]: Epoch 79 / 100: avg data time: 5.69e-02, avg batch time: 0.5053, average train loss: 2.9350
[09/26 10:23:37 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 2.9338
[09/26 10:23:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:23:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:23:44 visual_prompt]: Epoch 80 / 100: avg data time: 5.67e-02, avg batch time: 0.5066, average train loss: 2.9566
[09/26 10:23:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1689, average loss: 2.9941
[09/26 10:23:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 10:23:45 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:23:52 visual_prompt]: Epoch 81 / 100: avg data time: 5.68e-02, avg batch time: 0.5047, average train loss: 2.9621
[09/26 10:23:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1689, average loss: 2.9157
[09/26 10:23:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 10:23:54 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:24:00 visual_prompt]: Epoch 82 / 100: avg data time: 5.15e-02, avg batch time: 0.5001, average train loss: 2.9266
[09/26 10:24:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1688, average loss: 2.9281
[09/26 10:24:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 10:24:02 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:24:09 visual_prompt]: Epoch 83 / 100: avg data time: 5.71e-02, avg batch time: 0.5047, average train loss: 2.9113
[09/26 10:24:10 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 2.9177
[09/26 10:24:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 10:24:10 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:24:17 visual_prompt]: Epoch 84 / 100: avg data time: 5.05e-02, avg batch time: 0.4986, average train loss: 2.9042
[09/26 10:24:18 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 2.9166
[09/26 10:24:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 10:24:18 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:24:25 visual_prompt]: Epoch 85 / 100: avg data time: 5.25e-02, avg batch time: 0.5013, average train loss: 2.8995
[09/26 10:24:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1697, average loss: 2.9054
[09/26 10:24:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 10:24:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:24:33 visual_prompt]: Epoch 86 / 100: avg data time: 4.78e-02, avg batch time: 0.4972, average train loss: 2.9071
[09/26 10:24:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1694, average loss: 2.9112
[09/26 10:24:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:24:35 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:24:42 visual_prompt]: Epoch 87 / 100: avg data time: 5.74e-02, avg batch time: 0.5057, average train loss: 2.9004
[09/26 10:24:43 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1688, average loss: 2.9097
[09/26 10:24:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 10:24:43 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:24:50 visual_prompt]: Epoch 88 / 100: avg data time: 5.41e-02, avg batch time: 0.5030, average train loss: 2.9025
[09/26 10:24:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 2.9109
[09/26 10:24:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 10:24:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:24:58 visual_prompt]: Epoch 89 / 100: avg data time: 4.42e-02, avg batch time: 0.4939, average train loss: 2.9022
[09/26 10:25:00 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 2.9515
[09/26 10:25:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 10:25:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:25:07 visual_prompt]: Epoch 90 / 100: avg data time: 5.32e-02, avg batch time: 0.5018, average train loss: 2.9012
[09/26 10:25:08 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1687, average loss: 2.9082
[09/26 10:25:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 10:25:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:25:15 visual_prompt]: Epoch 91 / 100: avg data time: 5.38e-02, avg batch time: 0.5032, average train loss: 2.8945
[09/26 10:25:17 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1690, average loss: 2.9114
[09/26 10:25:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 10:25:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:25:23 visual_prompt]: Epoch 92 / 100: avg data time: 5.40e-02, avg batch time: 0.5046, average train loss: 2.8953
[09/26 10:25:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 2.9122
[09/26 10:25:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 10:25:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:25:32 visual_prompt]: Epoch 93 / 100: avg data time: 5.50e-02, avg batch time: 0.5035, average train loss: 2.8895
[09/26 10:25:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1694, average loss: 2.9033
[09/26 10:25:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 10:25:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:25:40 visual_prompt]: Epoch 94 / 100: avg data time: 4.75e-02, avg batch time: 0.4967, average train loss: 2.8842
[09/26 10:25:42 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1694, average loss: 2.9070
[09/26 10:25:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 10:25:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:25:48 visual_prompt]: Epoch 95 / 100: avg data time: 5.45e-02, avg batch time: 0.5039, average train loss: 2.8843
[09/26 10:25:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1700, average loss: 2.9029
[09/26 10:25:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 10:25:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:25:57 visual_prompt]: Epoch 96 / 100: avg data time: 4.73e-02, avg batch time: 0.4974, average train loss: 2.8805
[09/26 10:25:58 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 2.9069
[09/26 10:25:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 10:25:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:26:05 visual_prompt]: Epoch 97 / 100: avg data time: 5.04e-02, avg batch time: 0.4996, average train loss: 2.8806
[09/26 10:26:06 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1692, average loss: 2.9063
[09/26 10:26:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 10:26:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:26:13 visual_prompt]: Epoch 98 / 100: avg data time: 5.55e-02, avg batch time: 0.5038, average train loss: 2.8795
[09/26 10:26:15 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1692, average loss: 2.9075
[09/26 10:26:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 10:26:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:26:22 visual_prompt]: Epoch 99 / 100: avg data time: 5.31e-02, avg batch time: 0.5029, average train loss: 2.8787
[09/26 10:26:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 2.9068
[09/26 10:26:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 10:26:23 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:26:30 visual_prompt]: Epoch 100 / 100: avg data time: 5.43e-02, avg batch time: 0.5029, average train loss: 2.8781
[09/26 10:26:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 2.9068
[09/26 10:26:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 10:26:32 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:26:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:26:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:26:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:26:32 visual_prompt]: Training with config:
[09/26 10:26:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:26:32 visual_prompt]: Loading training data...
[09/26 10:26:32 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:26:33 visual_prompt]: Number of images: 800
[09/26 10:26:33 visual_prompt]: Number of classes: 18 / 18
[09/26 10:26:33 visual_prompt]: Loading validation data...
[09/26 10:26:33 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:26:33 visual_prompt]: Number of images: 200
[09/26 10:26:33 visual_prompt]: Number of classes: 18 / 18
[09/26 10:26:33 visual_prompt]: Constructing models...
[09/26 10:26:36 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 10:26:36 visual_prompt]: tuned percent:0.550
[09/26 10:26:36 visual_prompt]: Device used for model: 0
[09/26 10:26:36 visual_prompt]: Setting up Evaluator...
[09/26 10:26:36 visual_prompt]: Setting up Trainer...
[09/26 10:26:36 visual_prompt]: 	Setting up the optimizer...
[09/26 10:26:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:26:43 visual_prompt]: Epoch 1 / 100: avg data time: 6.62e-02, avg batch time: 0.5141, average train loss: 3.2541
[09/26 10:26:44 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1689, average loss: 3.1895
[09/26 10:26:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 10:26:44 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 10:26:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:26:51 visual_prompt]: Epoch 2 / 100: avg data time: 5.26e-02, avg batch time: 0.4996, average train loss: 3.4840
[09/26 10:26:52 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 3.3462
[09/26 10:26:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:26:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:26:59 visual_prompt]: Epoch 3 / 100: avg data time: 5.84e-02, avg batch time: 0.5062, average train loss: 3.1166
[09/26 10:27:01 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 3.1067
[09/26 10:27:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 10:27:01 visual_prompt]: Best epoch 3: best metric: 0.065
[09/26 10:27:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:27:07 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.5000, average train loss: 3.0961
[09/26 10:27:09 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1690, average loss: 3.0488
[09/26 10:27:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 10:27:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:27:16 visual_prompt]: Epoch 5 / 100: avg data time: 5.73e-02, avg batch time: 0.5053, average train loss: 3.1296
[09/26 10:27:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1693, average loss: 3.2808
[09/26 10:27:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 10:27:17 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 10:27:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:27:24 visual_prompt]: Epoch 6 / 100: avg data time: 5.20e-02, avg batch time: 0.5024, average train loss: 3.3119
[09/26 10:27:25 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1693, average loss: 3.3225
[09/26 10:27:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 10:27:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:27:32 visual_prompt]: Epoch 7 / 100: avg data time: 4.15e-02, avg batch time: 0.4910, average train loss: 3.2416
[09/26 10:27:34 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 3.2599
[09/26 10:27:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:27:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:27:40 visual_prompt]: Epoch 8 / 100: avg data time: 5.29e-02, avg batch time: 0.5019, average train loss: 3.6345
[09/26 10:27:42 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1688, average loss: 3.7018
[09/26 10:27:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.50	
[09/26 10:27:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:27:49 visual_prompt]: Epoch 9 / 100: avg data time: 5.57e-02, avg batch time: 0.5020, average train loss: 3.6023
[09/26 10:27:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 3.2854
[09/26 10:27:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 10:27:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:27:57 visual_prompt]: Epoch 10 / 100: avg data time: 5.39e-02, avg batch time: 0.5016, average train loss: 3.3062
[09/26 10:27:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1688, average loss: 3.2637
[09/26 10:27:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 10:27:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:28:06 visual_prompt]: Epoch 11 / 100: avg data time: 6.26e-02, avg batch time: 0.5111, average train loss: 3.2765
[09/26 10:28:07 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 3.2756
[09/26 10:28:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 10:28:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:28:14 visual_prompt]: Epoch 12 / 100: avg data time: 4.19e-02, avg batch time: 0.4903, average train loss: 3.4436
[09/26 10:28:15 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1688, average loss: 4.6341
[09/26 10:28:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 10:28:15 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:28:22 visual_prompt]: Epoch 13 / 100: avg data time: 5.53e-02, avg batch time: 0.5031, average train loss: 4.2522
[09/26 10:28:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1692, average loss: 4.0126
[09/26 10:28:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 10:28:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:28:30 visual_prompt]: Epoch 14 / 100: avg data time: 5.63e-02, avg batch time: 0.5038, average train loss: 4.6602
[09/26 10:28:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 5.0766
[09/26 10:28:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 10:28:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:28:39 visual_prompt]: Epoch 15 / 100: avg data time: 4.74e-02, avg batch time: 0.4945, average train loss: 4.5433
[09/26 10:28:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 4.2746
[09/26 10:28:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.00	
[09/26 10:28:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:28:47 visual_prompt]: Epoch 16 / 100: avg data time: 5.79e-02, avg batch time: 0.5051, average train loss: 3.7029
[09/26 10:28:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1693, average loss: 3.8935
[09/26 10:28:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 10:28:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:28:55 visual_prompt]: Epoch 17 / 100: avg data time: 5.33e-02, avg batch time: 0.5015, average train loss: 3.4259
[09/26 10:28:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 3.2467
[09/26 10:28:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 10:28:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:29:03 visual_prompt]: Epoch 18 / 100: avg data time: 4.34e-02, avg batch time: 0.4961, average train loss: 3.3889
[09/26 10:29:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 3.4045
[09/26 10:29:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:29:05 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:29:12 visual_prompt]: Epoch 19 / 100: avg data time: 5.14e-02, avg batch time: 0.4997, average train loss: 3.3128
[09/26 10:29:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1688, average loss: 3.2908
[09/26 10:29:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:29:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:29:20 visual_prompt]: Epoch 20 / 100: avg data time: 5.58e-02, avg batch time: 0.5029, average train loss: 3.1948
[09/26 10:29:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1690, average loss: 3.1412
[09/26 10:29:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:29:22 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:29:28 visual_prompt]: Epoch 21 / 100: avg data time: 5.70e-02, avg batch time: 0.5054, average train loss: 3.2954
[09/26 10:29:30 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1688, average loss: 3.7444
[09/26 10:29:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 10:29:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:29:37 visual_prompt]: Epoch 22 / 100: avg data time: 5.29e-02, avg batch time: 0.5016, average train loss: 3.5225
[09/26 10:29:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1687, average loss: 3.8597
[09/26 10:29:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 10:29:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:29:45 visual_prompt]: Epoch 23 / 100: avg data time: 5.34e-02, avg batch time: 0.5019, average train loss: 4.5310
[09/26 10:29:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 3.6366
[09/26 10:29:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 10:29:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:29:53 visual_prompt]: Epoch 24 / 100: avg data time: 5.40e-02, avg batch time: 0.5011, average train loss: 3.9991
[09/26 10:29:55 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1689, average loss: 6.0437
[09/26 10:29:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 10:29:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:30:02 visual_prompt]: Epoch 25 / 100: avg data time: 4.93e-02, avg batch time: 0.4984, average train loss: 5.8046
[09/26 10:30:03 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1695, average loss: 4.2376
[09/26 10:30:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 10:30:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:30:10 visual_prompt]: Epoch 26 / 100: avg data time: 4.91e-02, avg batch time: 0.4990, average train loss: 5.5631
[09/26 10:30:11 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 4.8340
[09/26 10:30:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:30:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:30:18 visual_prompt]: Epoch 27 / 100: avg data time: 5.60e-02, avg batch time: 0.5041, average train loss: 4.9938
[09/26 10:30:20 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1692, average loss: 5.5873
[09/26 10:30:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 10:30:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:30:27 visual_prompt]: Epoch 28 / 100: avg data time: 5.97e-02, avg batch time: 0.5078, average train loss: 4.5174
[09/26 10:30:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 3.8332
[09/26 10:30:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 10:30:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:30:35 visual_prompt]: Epoch 29 / 100: avg data time: 5.66e-02, avg batch time: 0.5061, average train loss: 3.4340
[09/26 10:30:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1689, average loss: 3.4033
[09/26 10:30:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 10:30:37 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:30:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.71e-02, avg batch time: 0.5052, average train loss: 3.3231
[09/26 10:30:45 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 3.3287
[09/26 10:30:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 10:30:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:30:52 visual_prompt]: Epoch 31 / 100: avg data time: 5.61e-02, avg batch time: 0.5050, average train loss: 3.3242
[09/26 10:30:53 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1691, average loss: 3.5313
[09/26 10:30:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 10:30:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:31:00 visual_prompt]: Epoch 32 / 100: avg data time: 5.92e-02, avg batch time: 0.5064, average train loss: 3.3162
[09/26 10:31:02 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.1687, average loss: 3.1265
[09/26 10:31:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 10:31:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:31:09 visual_prompt]: Epoch 33 / 100: avg data time: 5.49e-02, avg batch time: 0.5034, average train loss: 3.1386
[09/26 10:31:10 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1692, average loss: 3.0870
[09/26 10:31:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 10:31:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:31:17 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e-02, avg batch time: 0.4991, average train loss: 3.0868
[09/26 10:31:19 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1692, average loss: 3.1277
[09/26 10:31:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.50	
[09/26 10:31:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:31:25 visual_prompt]: Epoch 35 / 100: avg data time: 6.36e-02, avg batch time: 0.5112, average train loss: 3.1316
[09/26 10:31:27 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1692, average loss: 3.0717
[09/26 10:31:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 10:31:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:31:34 visual_prompt]: Epoch 36 / 100: avg data time: 7.14e-02, avg batch time: 0.5187, average train loss: 3.1993
[09/26 10:31:36 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 3.5176
[09/26 10:31:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 10:31:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:31:42 visual_prompt]: Epoch 37 / 100: avg data time: 4.95e-02, avg batch time: 0.4974, average train loss: 3.4711
[09/26 10:31:44 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1704, average loss: 3.5202
[09/26 10:31:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:31:44 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 10:31:51 visual_prompt]: Epoch 38 / 100: avg data time: 6.13e-02, avg batch time: 0.5093, average train loss: 3.2858
[09/26 10:31:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1689, average loss: 3.5211
[09/26 10:31:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:31:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 10:31:59 visual_prompt]: Epoch 39 / 100: avg data time: 5.57e-02, avg batch time: 0.5027, average train loss: 3.2747
[09/26 10:32:01 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1696, average loss: 3.6740
[09/26 10:32:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 10:32:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 10:32:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.33e-02, avg batch time: 0.5006, average train loss: 3.3322
[09/26 10:32:09 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 3.7527
[09/26 10:32:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 10:32:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 10:32:16 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.5079, average train loss: 3.3715
[09/26 10:32:17 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1691, average loss: 3.5238
[09/26 10:32:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 10:32:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 10:32:24 visual_prompt]: Epoch 42 / 100: avg data time: 5.13e-02, avg batch time: 0.5008, average train loss: 3.2856
[09/26 10:32:26 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1687, average loss: 3.5434
[09/26 10:32:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 10:32:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 10:32:32 visual_prompt]: Epoch 43 / 100: avg data time: 4.45e-02, avg batch time: 0.4933, average train loss: 3.2919
[09/26 10:32:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 3.3140
[09/26 10:32:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 10:32:34 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 10:32:40 visual_prompt]: Epoch 44 / 100: avg data time: 4.30e-02, avg batch time: 0.4914, average train loss: 3.1614
[09/26 10:32:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1688, average loss: 3.0777
[09/26 10:32:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 10:32:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 10:32:49 visual_prompt]: Epoch 45 / 100: avg data time: 4.60e-02, avg batch time: 0.4938, average train loss: 3.0465
[09/26 10:32:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1688, average loss: 3.3522
[09/26 10:32:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 10:32:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 10:32:57 visual_prompt]: Epoch 46 / 100: avg data time: 4.61e-02, avg batch time: 0.4938, average train loss: 3.1469
[09/26 10:32:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1695, average loss: 3.2515
[09/26 10:32:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 10:32:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 10:33:05 visual_prompt]: Epoch 47 / 100: avg data time: 4.28e-02, avg batch time: 0.4920, average train loss: 3.0372
[09/26 10:33:07 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1693, average loss: 3.1019
[09/26 10:33:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 10:33:07 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 10:33:13 visual_prompt]: Epoch 48 / 100: avg data time: 4.51e-02, avg batch time: 0.4957, average train loss: 3.1949
[09/26 10:33:15 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1694, average loss: 3.1485
[09/26 10:33:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:33:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 10:33:22 visual_prompt]: Epoch 49 / 100: avg data time: 5.66e-02, avg batch time: 0.5060, average train loss: 3.1061
[09/26 10:33:23 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 3.3771
[09/26 10:33:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.50	
[09/26 10:33:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 10:33:30 visual_prompt]: Epoch 50 / 100: avg data time: 4.98e-02, avg batch time: 0.4978, average train loss: 3.0993
[09/26 10:33:32 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1692, average loss: 3.1940
[09/26 10:33:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:33:32 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 10:33:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.32e-02, avg batch time: 0.4930, average train loss: 3.1861
[09/26 10:33:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 3.1370
[09/26 10:33:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 10:33:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 10:33:47 visual_prompt]: Epoch 52 / 100: avg data time: 5.23e-02, avg batch time: 0.5007, average train loss: 3.1265
[09/26 10:33:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1693, average loss: 3.3339
[09/26 10:33:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 10:33:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 10:33:55 visual_prompt]: Epoch 53 / 100: avg data time: 5.67e-02, avg batch time: 0.5045, average train loss: 3.1343
[09/26 10:33:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1691, average loss: 3.0684
[09/26 10:33:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 10:33:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 10:34:03 visual_prompt]: Epoch 54 / 100: avg data time: 5.18e-02, avg batch time: 0.5002, average train loss: 3.1082
[09/26 10:34:05 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1691, average loss: 3.0903
[09/26 10:34:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:34:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 10:34:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.02e-02, avg batch time: 0.5076, average train loss: 3.1048
[09/26 10:34:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 3.1541
[09/26 10:34:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 10:34:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 10:34:20 visual_prompt]: Epoch 56 / 100: avg data time: 4.71e-02, avg batch time: 0.4964, average train loss: 3.0281
[09/26 10:34:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 2.9938
[09/26 10:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 10:34:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 10:34:28 visual_prompt]: Epoch 57 / 100: avg data time: 6.28e-02, avg batch time: 0.5111, average train loss: 3.0638
[09/26 10:34:30 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 2.9970
[09/26 10:34:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 10:34:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 10:34:37 visual_prompt]: Epoch 58 / 100: avg data time: 6.69e-02, avg batch time: 0.5144, average train loss: 3.0288
[09/26 10:34:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1686, average loss: 3.0966
[09/26 10:34:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 10:34:38 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:34:45 visual_prompt]: Epoch 59 / 100: avg data time: 5.33e-02, avg batch time: 0.5016, average train loss: 3.0556
[09/26 10:34:47 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 3.0141
[09/26 10:34:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 10:34:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:34:53 visual_prompt]: Epoch 60 / 100: avg data time: 4.40e-02, avg batch time: 0.4913, average train loss: 3.0327
[09/26 10:34:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1691, average loss: 3.0581
[09/26 10:34:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 10:34:55 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:35:02 visual_prompt]: Epoch 61 / 100: avg data time: 5.55e-02, avg batch time: 0.5029, average train loss: 3.0546
[09/26 10:35:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 3.0665
[09/26 10:35:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 10:35:03 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:35:10 visual_prompt]: Epoch 62 / 100: avg data time: 5.04e-02, avg batch time: 0.4988, average train loss: 3.0272
[09/26 10:35:11 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1691, average loss: 3.0550
[09/26 10:35:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 10:35:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:35:18 visual_prompt]: Epoch 63 / 100: avg data time: 5.35e-02, avg batch time: 0.5013, average train loss: 2.9856
[09/26 10:35:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 3.0292
[09/26 10:35:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 10:35:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:35:26 visual_prompt]: Epoch 64 / 100: avg data time: 4.55e-02, avg batch time: 0.4965, average train loss: 2.9845
[09/26 10:35:28 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1693, average loss: 3.0194
[09/26 10:35:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 10:35:28 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:35:35 visual_prompt]: Epoch 65 / 100: avg data time: 5.32e-02, avg batch time: 0.5036, average train loss: 2.9740
[09/26 10:35:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1695, average loss: 2.9912
[09/26 10:35:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 10:35:36 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:35:43 visual_prompt]: Epoch 66 / 100: avg data time: 5.98e-02, avg batch time: 0.5091, average train loss: 2.9882
[09/26 10:35:45 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1690, average loss: 3.0113
[09/26 10:35:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 10:35:45 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:35:52 visual_prompt]: Epoch 67 / 100: avg data time: 5.59e-02, avg batch time: 0.5066, average train loss: 2.9674
[09/26 10:35:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 3.0212
[09/26 10:35:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 10:35:53 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:36:00 visual_prompt]: Epoch 68 / 100: avg data time: 5.44e-02, avg batch time: 0.5037, average train loss: 2.9785
[09/26 10:36:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 2.9928
[09/26 10:36:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 10:36:01 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:36:08 visual_prompt]: Epoch 69 / 100: avg data time: 6.62e-02, avg batch time: 0.5144, average train loss: 2.9744
[09/26 10:36:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 2.9613
[09/26 10:36:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 10:36:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:36:17 visual_prompt]: Epoch 70 / 100: avg data time: 5.78e-02, avg batch time: 0.5054, average train loss: 2.9492
[09/26 10:36:19 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1694, average loss: 3.0142
[09/26 10:36:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 22.50	
[09/26 10:36:19 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:36:25 visual_prompt]: Epoch 71 / 100: avg data time: 6.29e-02, avg batch time: 0.5108, average train loss: 2.9462
[09/26 10:36:27 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1694, average loss: 2.9502
[09/26 10:36:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.50	
[09/26 10:36:27 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:36:34 visual_prompt]: Epoch 72 / 100: avg data time: 5.11e-02, avg batch time: 0.5016, average train loss: 2.9447
[09/26 10:36:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 2.9304
[09/26 10:36:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.00	
[09/26 10:36:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:36:42 visual_prompt]: Epoch 73 / 100: avg data time: 4.74e-02, avg batch time: 0.4988, average train loss: 2.9444
[09/26 10:36:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1692, average loss: 2.9584
[09/26 10:36:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:36:44 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:36:51 visual_prompt]: Epoch 74 / 100: avg data time: 6.56e-02, avg batch time: 0.5131, average train loss: 2.9307
[09/26 10:36:52 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1694, average loss: 2.9590
[09/26 10:36:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 10:36:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:36:59 visual_prompt]: Epoch 75 / 100: avg data time: 4.88e-02, avg batch time: 0.4996, average train loss: 2.9207
[09/26 10:37:00 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1695, average loss: 2.9260
[09/26 10:37:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 10:37:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:37:07 visual_prompt]: Epoch 76 / 100: avg data time: 4.86e-02, avg batch time: 0.4977, average train loss: 2.9114
[09/26 10:37:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1696, average loss: 2.9173
[09/26 10:37:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 10:37:09 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:37:15 visual_prompt]: Epoch 77 / 100: avg data time: 4.64e-02, avg batch time: 0.4956, average train loss: 2.9202
[09/26 10:37:17 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 2.9140
[09/26 10:37:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 10:37:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:37:24 visual_prompt]: Epoch 78 / 100: avg data time: 5.13e-02, avg batch time: 0.5005, average train loss: 2.9127
[09/26 10:37:25 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1689, average loss: 2.9169
[09/26 10:37:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 10:37:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:37:32 visual_prompt]: Epoch 79 / 100: avg data time: 5.59e-02, avg batch time: 0.5045, average train loss: 2.9115
[09/26 10:37:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1694, average loss: 2.9121
[09/26 10:37:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.00	
[09/26 10:37:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:37:41 visual_prompt]: Epoch 80 / 100: avg data time: 5.85e-02, avg batch time: 0.5062, average train loss: 2.9077
[09/26 10:37:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1692, average loss: 2.9059
[09/26 10:37:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 31.00	
[09/26 10:37:42 visual_prompt]: Best epoch 80: best metric: 0.095
[09/26 10:37:42 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:37:49 visual_prompt]: Epoch 81 / 100: avg data time: 5.87e-02, avg batch time: 0.5064, average train loss: 2.8988
[09/26 10:37:50 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1696, average loss: 2.8932
[09/26 10:37:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 10:37:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:37:57 visual_prompt]: Epoch 82 / 100: avg data time: 5.21e-02, avg batch time: 0.5021, average train loss: 2.9121
[09/26 10:37:59 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 2.9039
[09/26 10:37:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 31.50	
[09/26 10:37:59 visual_prompt]: Best epoch 82: best metric: 0.105
[09/26 10:37:59 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:38:06 visual_prompt]: Epoch 83 / 100: avg data time: 5.16e-02, avg batch time: 0.4988, average train loss: 2.8935
[09/26 10:38:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 2.8975
[09/26 10:38:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 10:38:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:38:14 visual_prompt]: Epoch 84 / 100: avg data time: 5.51e-02, avg batch time: 0.5027, average train loss: 2.8959
[09/26 10:38:16 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1689, average loss: 2.9099
[09/26 10:38:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 10:38:16 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:38:22 visual_prompt]: Epoch 85 / 100: avg data time: 4.42e-02, avg batch time: 0.4927, average train loss: 2.8918
[09/26 10:38:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1689, average loss: 2.9031
[09/26 10:38:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 32.50	
[09/26 10:38:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:38:31 visual_prompt]: Epoch 86 / 100: avg data time: 5.95e-02, avg batch time: 0.5084, average train loss: 2.8890
[09/26 10:38:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 2.9058
[09/26 10:38:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 10:38:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:38:39 visual_prompt]: Epoch 87 / 100: avg data time: 5.77e-02, avg batch time: 0.5058, average train loss: 2.8806
[09/26 10:38:41 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1689, average loss: 2.9220
[09/26 10:38:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 10:38:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:38:48 visual_prompt]: Epoch 88 / 100: avg data time: 5.87e-02, avg batch time: 0.5074, average train loss: 2.8798
[09/26 10:38:49 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 2.9045
[09/26 10:38:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.00	
[09/26 10:38:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:38:56 visual_prompt]: Epoch 89 / 100: avg data time: 4.53e-02, avg batch time: 0.4944, average train loss: 2.8808
[09/26 10:38:57 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1691, average loss: 2.9076
[09/26 10:38:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 10:38:57 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:39:04 visual_prompt]: Epoch 90 / 100: avg data time: 5.71e-02, avg batch time: 0.5062, average train loss: 2.8727
[09/26 10:39:06 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 2.8898
[09/26 10:39:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.00	
[09/26 10:39:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:39:13 visual_prompt]: Epoch 91 / 100: avg data time: 5.77e-02, avg batch time: 0.5053, average train loss: 2.8739
[09/26 10:39:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 2.8954
[09/26 10:39:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 10:39:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:39:21 visual_prompt]: Epoch 92 / 100: avg data time: 4.71e-02, avg batch time: 0.4965, average train loss: 2.8694
[09/26 10:39:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 2.9240
[09/26 10:39:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.00	
[09/26 10:39:23 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:39:29 visual_prompt]: Epoch 93 / 100: avg data time: 6.12e-02, avg batch time: 0.5092, average train loss: 2.8655
[09/26 10:39:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 2.8980
[09/26 10:39:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 10:39:31 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:39:38 visual_prompt]: Epoch 94 / 100: avg data time: 4.95e-02, avg batch time: 0.4982, average train loss: 2.8620
[09/26 10:39:39 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 2.9099
[09/26 10:39:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 10:39:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:39:46 visual_prompt]: Epoch 95 / 100: avg data time: 5.82e-02, avg batch time: 0.5075, average train loss: 2.8606
[09/26 10:39:48 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 2.9072
[09/26 10:39:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 10:39:48 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:39:54 visual_prompt]: Epoch 96 / 100: avg data time: 5.35e-02, avg batch time: 0.5012, average train loss: 2.8588
[09/26 10:39:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 2.9066
[09/26 10:39:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.00	
[09/26 10:39:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:40:03 visual_prompt]: Epoch 97 / 100: avg data time: 4.39e-02, avg batch time: 0.4917, average train loss: 2.8574
[09/26 10:40:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 2.9068
[09/26 10:40:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 31.00	
[09/26 10:40:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:40:11 visual_prompt]: Epoch 98 / 100: avg data time: 7.95e-02, avg batch time: 0.5268, average train loss: 2.8566
[09/26 10:40:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1693, average loss: 2.9094
[09/26 10:40:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 10:40:13 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:40:20 visual_prompt]: Epoch 99 / 100: avg data time: 5.78e-02, avg batch time: 0.5063, average train loss: 2.8557
[09/26 10:40:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 2.9094
[09/26 10:40:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 10:40:21 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:40:28 visual_prompt]: Epoch 100 / 100: avg data time: 5.97e-02, avg batch time: 0.5084, average train loss: 2.8561
[09/26 10:40:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 2.9099
[09/26 10:40:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 10:40:30 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:40:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:40:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:40:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:40:30 visual_prompt]: Training with config:
[09/26 10:40:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:40:30 visual_prompt]: Loading training data...
[09/26 10:40:30 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:40:31 visual_prompt]: Number of images: 800
[09/26 10:40:31 visual_prompt]: Number of classes: 18 / 18
[09/26 10:40:31 visual_prompt]: Loading validation data...
[09/26 10:40:31 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:40:31 visual_prompt]: Number of images: 200
[09/26 10:40:31 visual_prompt]: Number of classes: 18 / 18
[09/26 10:40:31 visual_prompt]: Constructing models...
[09/26 10:40:34 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 10:40:34 visual_prompt]: tuned percent:0.550
[09/26 10:40:34 visual_prompt]: Device used for model: 0
[09/26 10:40:34 visual_prompt]: Setting up Evaluator...
[09/26 10:40:34 visual_prompt]: Setting up Trainer...
[09/26 10:40:34 visual_prompt]: 	Setting up the optimizer...
[09/26 10:40:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:40:41 visual_prompt]: Epoch 1 / 100: avg data time: 4.73e-02, avg batch time: 0.4948, average train loss: 3.2537
[09/26 10:40:42 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 3.1895
[09/26 10:40:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 10:40:42 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 10:40:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:40:49 visual_prompt]: Epoch 2 / 100: avg data time: 5.76e-02, avg batch time: 0.5043, average train loss: 3.5905
[09/26 10:40:51 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1689, average loss: 3.4310
[09/26 10:40:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 10:40:51 visual_prompt]: Best epoch 2: best metric: 0.065
[09/26 10:40:51 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:40:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.55e-02, avg batch time: 0.4947, average train loss: 3.2030
[09/26 10:40:59 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 3.2412
[09/26 10:40:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 10:40:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:41:06 visual_prompt]: Epoch 4 / 100: avg data time: 4.58e-02, avg batch time: 0.4959, average train loss: 3.1251
[09/26 10:41:07 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1700, average loss: 3.1602
[09/26 10:41:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 10:41:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:41:14 visual_prompt]: Epoch 5 / 100: avg data time: 5.00e-02, avg batch time: 0.4975, average train loss: 3.1791
[09/26 10:41:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1689, average loss: 3.2241
[09/26 10:41:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 10:41:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:41:22 visual_prompt]: Epoch 6 / 100: avg data time: 5.76e-02, avg batch time: 0.5053, average train loss: 3.2619
[09/26 10:41:24 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1689, average loss: 3.6364
[09/26 10:41:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 10:41:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:41:31 visual_prompt]: Epoch 7 / 100: avg data time: 5.62e-02, avg batch time: 0.5038, average train loss: 3.5047
[09/26 10:41:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 3.4733
[09/26 10:41:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 10:41:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:41:39 visual_prompt]: Epoch 8 / 100: avg data time: 4.27e-02, avg batch time: 0.4947, average train loss: 3.4974
[09/26 10:41:40 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 3.1151
[09/26 10:41:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 10:41:40 visual_prompt]: Best epoch 8: best metric: 0.085
[09/26 10:41:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:41:47 visual_prompt]: Epoch 9 / 100: avg data time: 4.61e-02, avg batch time: 0.4938, average train loss: 3.2712
[09/26 10:41:49 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1693, average loss: 3.2425
[09/26 10:41:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 10:41:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:41:55 visual_prompt]: Epoch 10 / 100: avg data time: 5.80e-02, avg batch time: 0.5062, average train loss: 3.3677
[09/26 10:41:57 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 3.7029
[09/26 10:41:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 10:41:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:42:04 visual_prompt]: Epoch 11 / 100: avg data time: 6.23e-02, avg batch time: 0.5101, average train loss: 3.5366
[09/26 10:42:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 3.4625
[09/26 10:42:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 37.00	
[09/26 10:42:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:42:12 visual_prompt]: Epoch 12 / 100: avg data time: 5.81e-02, avg batch time: 0.5061, average train loss: 3.5666
[09/26 10:42:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1694, average loss: 3.3195
[09/26 10:42:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 10:42:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:42:21 visual_prompt]: Epoch 13 / 100: avg data time: 5.89e-02, avg batch time: 0.5071, average train loss: 3.3797
[09/26 10:42:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1692, average loss: 3.3314
[09/26 10:42:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 10:42:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:42:29 visual_prompt]: Epoch 14 / 100: avg data time: 6.81e-02, avg batch time: 0.5161, average train loss: 3.6046
[09/26 10:42:31 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 4.3433
[09/26 10:42:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 10:42:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:42:38 visual_prompt]: Epoch 15 / 100: avg data time: 6.44e-02, avg batch time: 0.5123, average train loss: 3.9875
[09/26 10:42:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1694, average loss: 3.6469
[09/26 10:42:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.00	
[09/26 10:42:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:42:46 visual_prompt]: Epoch 16 / 100: avg data time: 4.54e-02, avg batch time: 0.4951, average train loss: 4.1785
[09/26 10:42:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1689, average loss: 4.1877
[09/26 10:42:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 10:42:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:42:54 visual_prompt]: Epoch 17 / 100: avg data time: 5.16e-02, avg batch time: 0.5001, average train loss: 3.6637
[09/26 10:42:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1692, average loss: 3.4116
[09/26 10:42:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 36.00	
[09/26 10:42:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:43:03 visual_prompt]: Epoch 18 / 100: avg data time: 6.12e-02, avg batch time: 0.5103, average train loss: 3.2923
[09/26 10:43:04 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1692, average loss: 3.4147
[09/26 10:43:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 39.50	
[09/26 10:43:04 visual_prompt]: Best epoch 18: best metric: 0.090
[09/26 10:43:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:43:11 visual_prompt]: Epoch 19 / 100: avg data time: 6.00e-02, avg batch time: 0.5086, average train loss: 3.2853
[09/26 10:43:13 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1694, average loss: 3.2739
[09/26 10:43:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 46.50	
[09/26 10:43:13 visual_prompt]: Best epoch 19: best metric: 0.095
[09/26 10:43:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:43:19 visual_prompt]: Epoch 20 / 100: avg data time: 4.50e-02, avg batch time: 0.4948, average train loss: 3.0160
[09/26 10:43:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1696, average loss: 3.3523
[09/26 10:43:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 36.00	
[09/26 10:43:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:43:28 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e-02, avg batch time: 0.5063, average train loss: 2.9021
[09/26 10:43:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 2.9851
[09/26 10:43:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 50.50	
[09/26 10:43:29 visual_prompt]: Best epoch 21: best metric: 0.140
[09/26 10:43:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:43:36 visual_prompt]: Epoch 22 / 100: avg data time: 5.42e-02, avg batch time: 0.5040, average train loss: 2.7828
[09/26 10:43:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1692, average loss: 2.8468
[09/26 10:43:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 52.50	
[09/26 10:43:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:43:45 visual_prompt]: Epoch 23 / 100: avg data time: 5.82e-02, avg batch time: 0.5067, average train loss: 2.5577
[09/26 10:43:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1690, average loss: 2.9992
[09/26 10:43:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 10:43:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:43:53 visual_prompt]: Epoch 24 / 100: avg data time: 4.63e-02, avg batch time: 0.4963, average train loss: 2.4371
[09/26 10:43:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 2.7688
[09/26 10:43:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 63.50	
[09/26 10:43:55 visual_prompt]: Best epoch 24: best metric: 0.210
[09/26 10:43:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:44:01 visual_prompt]: Epoch 25 / 100: avg data time: 4.85e-02, avg batch time: 0.4984, average train loss: 2.4409
[09/26 10:44:03 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1694, average loss: 3.9022
[09/26 10:44:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 52.00	
[09/26 10:44:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:44:10 visual_prompt]: Epoch 26 / 100: avg data time: 4.08e-02, avg batch time: 0.4913, average train loss: 2.4587
[09/26 10:44:11 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1696, average loss: 2.9267
[09/26 10:44:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.00	
[09/26 10:44:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:44:18 visual_prompt]: Epoch 27 / 100: avg data time: 6.19e-02, avg batch time: 0.5112, average train loss: 2.5077
[09/26 10:44:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 3.1471
[09/26 10:44:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 57.50	
[09/26 10:44:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:44:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.06e-02, avg batch time: 0.4995, average train loss: 2.2547
[09/26 10:44:28 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1695, average loss: 2.6242
[09/26 10:44:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 71.00	
[09/26 10:44:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:44:35 visual_prompt]: Epoch 29 / 100: avg data time: 5.75e-02, avg batch time: 0.5084, average train loss: 1.9269
[09/26 10:44:36 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 3.1190
[09/26 10:44:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 58.50	
[09/26 10:44:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:44:43 visual_prompt]: Epoch 30 / 100: avg data time: 5.33e-02, avg batch time: 0.5029, average train loss: 1.7763
[09/26 10:44:45 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 3.6929
[09/26 10:44:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 10:44:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:44:52 visual_prompt]: Epoch 31 / 100: avg data time: 6.28e-02, avg batch time: 0.5120, average train loss: 1.8717
[09/26 10:44:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1694, average loss: 3.1997
[09/26 10:44:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 68.00	
[09/26 10:44:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:45:00 visual_prompt]: Epoch 32 / 100: avg data time: 5.93e-02, avg batch time: 0.5091, average train loss: 1.5506
[09/26 10:45:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1693, average loss: 3.4115
[09/26 10:45:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 64.00	
[09/26 10:45:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:45:08 visual_prompt]: Epoch 33 / 100: avg data time: 5.64e-02, avg batch time: 0.5050, average train loss: 1.3500
[09/26 10:45:10 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1696, average loss: 3.3741
[09/26 10:45:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.50	
[09/26 10:45:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:45:17 visual_prompt]: Epoch 34 / 100: avg data time: 5.23e-02, avg batch time: 0.5020, average train loss: 1.2819
[09/26 10:45:18 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 3.7929
[09/26 10:45:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.50	
[09/26 10:45:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:45:25 visual_prompt]: Epoch 35 / 100: avg data time: 5.02e-02, avg batch time: 0.4999, average train loss: 1.0612
[09/26 10:45:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1697, average loss: 5.2788
[09/26 10:45:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 10:45:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:45:33 visual_prompt]: Epoch 36 / 100: avg data time: 6.03e-02, avg batch time: 0.5112, average train loss: 1.3634
[09/26 10:45:35 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1694, average loss: 3.7027
[09/26 10:45:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 10:45:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:45:42 visual_prompt]: Epoch 37 / 100: avg data time: 4.63e-02, avg batch time: 0.4972, average train loss: 1.1512
[09/26 10:45:43 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.1696, average loss: 4.1049
[09/26 10:45:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 66.50	
[09/26 10:45:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 10:45:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.26e-02, avg batch time: 0.5022, average train loss: 0.9251
[09/26 10:45:51 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1697, average loss: 3.9999
[09/26 10:45:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 58.50	
[09/26 10:45:51 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 10:45:58 visual_prompt]: Epoch 39 / 100: avg data time: 5.95e-02, avg batch time: 0.5089, average train loss: 0.8071
[09/26 10:46:00 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1699, average loss: 4.3858
[09/26 10:46:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 68.50	
[09/26 10:46:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 10:46:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.09e-02, avg batch time: 0.5015, average train loss: 0.6530
[09/26 10:46:08 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1695, average loss: 4.8170
[09/26 10:46:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 64.00	
[09/26 10:46:08 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 10:46:15 visual_prompt]: Epoch 41 / 100: avg data time: 4.81e-02, avg batch time: 0.4996, average train loss: 0.8131
[09/26 10:46:17 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1696, average loss: 4.1697
[09/26 10:46:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 70.00	
[09/26 10:46:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 10:46:24 visual_prompt]: Epoch 42 / 100: avg data time: 5.59e-02, avg batch time: 0.5062, average train loss: 0.4792
[09/26 10:46:25 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 6.3389
[09/26 10:46:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 57.50	
[09/26 10:46:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 10:46:32 visual_prompt]: Epoch 43 / 100: avg data time: 6.83e-02, avg batch time: 0.5171, average train loss: 0.9620
[09/26 10:46:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1693, average loss: 5.3229
[09/26 10:46:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.00	
[09/26 10:46:34 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 10:46:41 visual_prompt]: Epoch 44 / 100: avg data time: 6.44e-02, avg batch time: 0.5140, average train loss: 0.8142
[09/26 10:46:42 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1693, average loss: 4.4068
[09/26 10:46:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.50	
[09/26 10:46:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 10:46:49 visual_prompt]: Epoch 45 / 100: avg data time: 6.08e-02, avg batch time: 0.5101, average train loss: 0.5694
[09/26 10:46:51 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1692, average loss: 5.1780
[09/26 10:46:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.00	
[09/26 10:46:51 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 10:46:58 visual_prompt]: Epoch 46 / 100: avg data time: 6.51e-02, avg batch time: 0.5138, average train loss: 0.5142
[09/26 10:46:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 6.2212
[09/26 10:46:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.50	
[09/26 10:46:59 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 10:47:06 visual_prompt]: Epoch 47 / 100: avg data time: 5.75e-02, avg batch time: 0.5080, average train loss: 0.7406
[09/26 10:47:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1697, average loss: 4.4400
[09/26 10:47:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 67.50	
[09/26 10:47:07 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 10:47:14 visual_prompt]: Epoch 48 / 100: avg data time: 5.62e-02, avg batch time: 0.5048, average train loss: 0.5775
[09/26 10:47:16 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1697, average loss: 5.8466
[09/26 10:47:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 10:47:16 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 10:47:23 visual_prompt]: Epoch 49 / 100: avg data time: 5.60e-02, avg batch time: 0.5051, average train loss: 0.5222
[09/26 10:47:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1695, average loss: 5.8246
[09/26 10:47:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 61.00	
[09/26 10:47:24 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 10:47:31 visual_prompt]: Epoch 50 / 100: avg data time: 4.58e-02, avg batch time: 0.4972, average train loss: 0.4619
[09/26 10:47:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1693, average loss: 5.6621
[09/26 10:47:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 60.00	
[09/26 10:47:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 10:47:39 visual_prompt]: Epoch 51 / 100: avg data time: 5.10e-02, avg batch time: 0.5004, average train loss: 0.4052
[09/26 10:47:41 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1694, average loss: 4.9567
[09/26 10:47:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.00	
[09/26 10:47:41 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 10:47:48 visual_prompt]: Epoch 52 / 100: avg data time: 4.50e-02, avg batch time: 0.4974, average train loss: 0.3532
[09/26 10:47:49 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1697, average loss: 6.5560
[09/26 10:47:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.00	
[09/26 10:47:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 10:47:56 visual_prompt]: Epoch 53 / 100: avg data time: 6.02e-02, avg batch time: 0.5095, average train loss: 0.2849
[09/26 10:47:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1696, average loss: 6.8520
[09/26 10:47:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 10:47:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 10:48:04 visual_prompt]: Epoch 54 / 100: avg data time: 5.33e-02, avg batch time: 0.5021, average train loss: 0.2319
[09/26 10:48:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1698, average loss: 6.7086
[09/26 10:48:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.00	
[09/26 10:48:06 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 10:48:13 visual_prompt]: Epoch 55 / 100: avg data time: 4.86e-02, avg batch time: 0.4988, average train loss: 0.3545
[09/26 10:48:14 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1701, average loss: 6.5788
[09/26 10:48:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.00	
[09/26 10:48:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 10:48:21 visual_prompt]: Epoch 56 / 100: avg data time: 5.01e-02, avg batch time: 0.5005, average train loss: 0.3791
[09/26 10:48:23 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1691, average loss: 5.7506
[09/26 10:48:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 10:48:23 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 10:48:30 visual_prompt]: Epoch 57 / 100: avg data time: 5.36e-02, avg batch time: 0.5036, average train loss: 0.3010
[09/26 10:48:31 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1692, average loss: 6.7193
[09/26 10:48:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 10:48:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 10:48:38 visual_prompt]: Epoch 58 / 100: avg data time: 4.82e-02, avg batch time: 0.4981, average train loss: 0.2972
[09/26 10:48:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1695, average loss: 6.8316
[09/26 10:48:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 57.50	
[09/26 10:48:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:48:46 visual_prompt]: Epoch 59 / 100: avg data time: 6.01e-02, avg batch time: 0.5095, average train loss: 0.2621
[09/26 10:48:48 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1694, average loss: 6.1591
[09/26 10:48:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 10:48:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:48:55 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.5070, average train loss: 0.1272
[09/26 10:48:56 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1697, average loss: 7.1207
[09/26 10:48:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 10:48:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:49:03 visual_prompt]: Epoch 61 / 100: avg data time: 6.33e-02, avg batch time: 0.5131, average train loss: 0.1606
[09/26 10:49:05 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 7.3242
[09/26 10:49:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 10:49:05 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:49:12 visual_prompt]: Epoch 62 / 100: avg data time: 6.12e-02, avg batch time: 0.5111, average train loss: 0.2002
[09/26 10:49:13 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1696, average loss: 6.7149
[09/26 10:49:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 10:49:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:49:20 visual_prompt]: Epoch 63 / 100: avg data time: 4.43e-02, avg batch time: 0.4938, average train loss: 0.1617
[09/26 10:49:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1699, average loss: 6.7486
[09/26 10:49:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 62.50	
[09/26 10:49:21 visual_prompt]: Best epoch 63: best metric: 0.215
[09/26 10:49:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:49:28 visual_prompt]: Epoch 64 / 100: avg data time: 5.39e-02, avg batch time: 0.5064, average train loss: 0.1601
[09/26 10:49:30 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1694, average loss: 6.6949
[09/26 10:49:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 62.00	
[09/26 10:49:30 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:49:36 visual_prompt]: Epoch 65 / 100: avg data time: 5.29e-02, avg batch time: 0.5033, average train loss: 0.0936
[09/26 10:49:38 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 6.4560
[09/26 10:49:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 61.00	
[09/26 10:49:38 visual_prompt]: Best epoch 65: best metric: 0.230
[09/26 10:49:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:49:45 visual_prompt]: Epoch 66 / 100: avg data time: 4.32e-02, avg batch time: 0.4933, average train loss: 0.0956
[09/26 10:49:46 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1694, average loss: 6.8616
[09/26 10:49:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 10:49:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:49:53 visual_prompt]: Epoch 67 / 100: avg data time: 5.68e-02, avg batch time: 0.5068, average train loss: 0.0712
[09/26 10:49:55 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 6.8086
[09/26 10:49:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 60.50	
[09/26 10:49:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:50:02 visual_prompt]: Epoch 68 / 100: avg data time: 6.60e-02, avg batch time: 0.5155, average train loss: 0.0640
[09/26 10:50:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1694, average loss: 6.6516
[09/26 10:50:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 64.50	
[09/26 10:50:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:50:10 visual_prompt]: Epoch 69 / 100: avg data time: 6.30e-02, avg batch time: 0.5118, average train loss: 0.0792
[09/26 10:50:12 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1691, average loss: 7.0615
[09/26 10:50:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 10:50:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:50:18 visual_prompt]: Epoch 70 / 100: avg data time: 4.67e-02, avg batch time: 0.4971, average train loss: 0.0386
[09/26 10:50:20 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1695, average loss: 6.6601
[09/26 10:50:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 10:50:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:50:27 visual_prompt]: Epoch 71 / 100: avg data time: 6.01e-02, avg batch time: 0.5099, average train loss: 0.0185
[09/26 10:50:28 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 7.0776
[09/26 10:50:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 10:50:28 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:50:35 visual_prompt]: Epoch 72 / 100: avg data time: 6.12e-02, avg batch time: 0.5104, average train loss: 0.0089
[09/26 10:50:37 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1696, average loss: 6.9848
[09/26 10:50:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.00	
[09/26 10:50:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:50:44 visual_prompt]: Epoch 73 / 100: avg data time: 5.39e-02, avg batch time: 0.5025, average train loss: 0.0067
[09/26 10:50:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1696, average loss: 6.7626
[09/26 10:50:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:50:45 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:50:52 visual_prompt]: Epoch 74 / 100: avg data time: 4.63e-02, avg batch time: 0.4969, average train loss: 0.0020
[09/26 10:50:53 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1690, average loss: 6.7159
[09/26 10:50:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 65.00	
[09/26 10:50:53 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:51:00 visual_prompt]: Epoch 75 / 100: avg data time: 6.49e-02, avg batch time: 0.5142, average train loss: 0.0023
[09/26 10:51:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 6.7123
[09/26 10:51:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 10:51:02 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:51:09 visual_prompt]: Epoch 76 / 100: avg data time: 5.60e-02, avg batch time: 0.5060, average train loss: 0.0015
[09/26 10:51:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 6.6529
[09/26 10:51:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:51:10 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:51:17 visual_prompt]: Epoch 77 / 100: avg data time: 6.32e-02, avg batch time: 0.5123, average train loss: 0.0018
[09/26 10:51:19 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 6.5828
[09/26 10:51:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:51:19 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:51:26 visual_prompt]: Epoch 78 / 100: avg data time: 5.91e-02, avg batch time: 0.5080, average train loss: 0.0012
[09/26 10:51:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1695, average loss: 6.5352
[09/26 10:51:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:51:27 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:51:34 visual_prompt]: Epoch 79 / 100: avg data time: 6.32e-02, avg batch time: 0.5121, average train loss: 0.0011
[09/26 10:51:36 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1695, average loss: 6.4865
[09/26 10:51:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:51:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:51:43 visual_prompt]: Epoch 80 / 100: avg data time: 6.68e-02, avg batch time: 0.5155, average train loss: 0.0014
[09/26 10:51:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1696, average loss: 6.4469
[09/26 10:51:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 10:51:44 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:51:51 visual_prompt]: Epoch 81 / 100: avg data time: 6.13e-02, avg batch time: 0.5103, average train loss: 0.0009
[09/26 10:51:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1695, average loss: 6.4027
[09/26 10:51:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.50	
[09/26 10:51:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:52:00 visual_prompt]: Epoch 82 / 100: avg data time: 5.40e-02, avg batch time: 0.5027, average train loss: 0.0011
[09/26 10:52:01 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1696, average loss: 6.3749
[09/26 10:52:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 10:52:01 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:52:08 visual_prompt]: Epoch 83 / 100: avg data time: 6.44e-02, avg batch time: 0.5134, average train loss: 0.0012
[09/26 10:52:10 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1698, average loss: 6.3488
[09/26 10:52:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 10:52:10 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:52:17 visual_prompt]: Epoch 84 / 100: avg data time: 5.31e-02, avg batch time: 0.5034, average train loss: 0.0012
[09/26 10:52:18 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1696, average loss: 6.3126
[09/26 10:52:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 10:52:18 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:52:25 visual_prompt]: Epoch 85 / 100: avg data time: 5.91e-02, avg batch time: 0.5077, average train loss: 0.0011
[09/26 10:52:27 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1694, average loss: 6.2823
[09/26 10:52:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:52:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:52:33 visual_prompt]: Epoch 86 / 100: avg data time: 6.29e-02, avg batch time: 0.5123, average train loss: 0.0011
[09/26 10:52:35 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1696, average loss: 6.2608
[09/26 10:52:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:52:35 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:52:42 visual_prompt]: Epoch 87 / 100: avg data time: 5.23e-02, avg batch time: 0.5016, average train loss: 0.0011
[09/26 10:52:43 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 6.2396
[09/26 10:52:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:52:43 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:52:50 visual_prompt]: Epoch 88 / 100: avg data time: 5.60e-02, avg batch time: 0.5055, average train loss: 0.0014
[09/26 10:52:52 visual_prompt]: Inference (val):avg data time: 4.95e-05, avg batch time: 0.1698, average loss: 6.2215
[09/26 10:52:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 10:52:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:52:59 visual_prompt]: Epoch 89 / 100: avg data time: 5.81e-02, avg batch time: 0.5076, average train loss: 0.0012
[09/26 10:53:00 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1696, average loss: 6.2055
[09/26 10:53:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 10:53:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:53:07 visual_prompt]: Epoch 90 / 100: avg data time: 5.64e-02, avg batch time: 0.5058, average train loss: 0.0011
[09/26 10:53:09 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 6.1938
[09/26 10:53:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:09 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:53:16 visual_prompt]: Epoch 91 / 100: avg data time: 5.59e-02, avg batch time: 0.5049, average train loss: 0.0011
[09/26 10:53:17 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1694, average loss: 6.1827
[09/26 10:53:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:53:24 visual_prompt]: Epoch 92 / 100: avg data time: 5.93e-02, avg batch time: 0.5091, average train loss: 0.0016
[09/26 10:53:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1698, average loss: 6.1772
[09/26 10:53:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:26 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:53:33 visual_prompt]: Epoch 93 / 100: avg data time: 6.72e-02, avg batch time: 0.5154, average train loss: 0.0012
[09/26 10:53:35 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1699, average loss: 6.1717
[09/26 10:53:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:53:42 visual_prompt]: Epoch 94 / 100: avg data time: 5.87e-02, avg batch time: 0.5071, average train loss: 0.0011
[09/26 10:53:43 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1696, average loss: 6.1674
[09/26 10:53:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:43 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:53:50 visual_prompt]: Epoch 95 / 100: avg data time: 6.29e-02, avg batch time: 0.5128, average train loss: 0.0011
[09/26 10:53:52 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1697, average loss: 6.1634
[09/26 10:53:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:53:52 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:53:59 visual_prompt]: Epoch 96 / 100: avg data time: 6.15e-02, avg batch time: 0.5121, average train loss: 0.0010
[09/26 10:54:00 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 6.1602
[09/26 10:54:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:54:00 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:54:07 visual_prompt]: Epoch 97 / 100: avg data time: 5.34e-02, avg batch time: 0.5031, average train loss: 0.0013
[09/26 10:54:09 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1696, average loss: 6.1591
[09/26 10:54:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:54:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:54:16 visual_prompt]: Epoch 98 / 100: avg data time: 6.10e-02, avg batch time: 0.5118, average train loss: 0.0012
[09/26 10:54:17 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1696, average loss: 6.1584
[09/26 10:54:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:54:17 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:54:24 visual_prompt]: Epoch 99 / 100: avg data time: 6.83e-02, avg batch time: 0.5170, average train loss: 0.0012
[09/26 10:54:26 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1695, average loss: 6.1581
[09/26 10:54:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:54:26 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:54:32 visual_prompt]: Epoch 100 / 100: avg data time: 5.62e-02, avg batch time: 0.5066, average train loss: 0.0011
[09/26 10:54:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 6.1580
[09/26 10:54:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 10:54:34 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:54:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:54:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:54:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:54:34 visual_prompt]: Training with config:
[09/26 10:54:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:54:34 visual_prompt]: Loading training data...
[09/26 10:54:34 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:54:35 visual_prompt]: Number of images: 800
[09/26 10:54:35 visual_prompt]: Number of classes: 18 / 18
[09/26 10:54:35 visual_prompt]: Loading validation data...
[09/26 10:54:35 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 10:54:36 visual_prompt]: Number of images: 200
[09/26 10:54:36 visual_prompt]: Number of classes: 18 / 18
[09/26 10:54:36 visual_prompt]: Constructing models...
[09/26 10:54:38 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 10:54:38 visual_prompt]: tuned percent:0.550
[09/26 10:54:38 visual_prompt]: Device used for model: 0
[09/26 10:54:38 visual_prompt]: Setting up Evaluator...
[09/26 10:54:38 visual_prompt]: Setting up Trainer...
[09/26 10:54:38 visual_prompt]: 	Setting up the optimizer...
[09/26 10:54:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:54:45 visual_prompt]: Epoch 1 / 100: avg data time: 4.91e-02, avg batch time: 0.4984, average train loss: 3.2530
[09/26 10:54:47 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 3.1895
[09/26 10:54:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 10:54:47 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 10:54:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:54:53 visual_prompt]: Epoch 2 / 100: avg data time: 6.19e-02, avg batch time: 0.5089, average train loss: 3.5126
[09/26 10:54:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1690, average loss: 3.3146
[09/26 10:54:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 10:54:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:55:02 visual_prompt]: Epoch 3 / 100: avg data time: 4.83e-02, avg batch time: 0.4958, average train loss: 3.1082
[09/26 10:55:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 3.0124
[09/26 10:55:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 10:55:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:55:10 visual_prompt]: Epoch 4 / 100: avg data time: 5.99e-02, avg batch time: 0.5072, average train loss: 3.1889
[09/26 10:55:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1687, average loss: 3.2432
[09/26 10:55:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 10:55:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:55:19 visual_prompt]: Epoch 5 / 100: avg data time: 5.48e-02, avg batch time: 0.5030, average train loss: 3.2540
[09/26 10:55:20 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1688, average loss: 3.2731
[09/26 10:55:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 10:55:20 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 10:55:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:55:27 visual_prompt]: Epoch 6 / 100: avg data time: 6.54e-02, avg batch time: 0.5127, average train loss: 3.2531
[09/26 10:55:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 3.4172
[09/26 10:55:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 10:55:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:55:36 visual_prompt]: Epoch 7 / 100: avg data time: 7.63e-02, avg batch time: 0.5234, average train loss: 3.4714
[09/26 10:55:38 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1689, average loss: 3.7201
[09/26 10:55:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 10:55:38 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:55:44 visual_prompt]: Epoch 8 / 100: avg data time: 4.94e-02, avg batch time: 0.4976, average train loss: 3.7298
[09/26 10:55:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1692, average loss: 3.9955
[09/26 10:55:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 10:55:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:55:53 visual_prompt]: Epoch 9 / 100: avg data time: 5.85e-02, avg batch time: 0.5078, average train loss: 3.8090
[09/26 10:55:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1693, average loss: 3.6784
[09/26 10:55:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 10:55:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:56:01 visual_prompt]: Epoch 10 / 100: avg data time: 5.01e-02, avg batch time: 0.4995, average train loss: 4.0056
[09/26 10:56:03 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1688, average loss: 4.0788
[09/26 10:56:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.50	
[09/26 10:56:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:56:10 visual_prompt]: Epoch 11 / 100: avg data time: 6.28e-02, avg batch time: 0.5116, average train loss: 4.6583
[09/26 10:56:11 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 4.8383
[09/26 10:56:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.50	
[09/26 10:56:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:56:18 visual_prompt]: Epoch 12 / 100: avg data time: 5.83e-02, avg batch time: 0.5065, average train loss: 4.4471
[09/26 10:56:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1688, average loss: 4.9964
[09/26 10:56:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 10:56:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:56:27 visual_prompt]: Epoch 13 / 100: avg data time: 5.53e-02, avg batch time: 0.5029, average train loss: 4.3884
[09/26 10:56:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 4.3515
[09/26 10:56:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 10:56:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:56:35 visual_prompt]: Epoch 14 / 100: avg data time: 5.98e-02, avg batch time: 0.5078, average train loss: 4.4090
[09/26 10:56:37 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1691, average loss: 3.6365
[09/26 10:56:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 10:56:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:56:44 visual_prompt]: Epoch 15 / 100: avg data time: 6.21e-02, avg batch time: 0.5104, average train loss: 3.9275
[09/26 10:56:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 4.8529
[09/26 10:56:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 10:56:45 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:56:52 visual_prompt]: Epoch 16 / 100: avg data time: 5.53e-02, avg batch time: 0.5032, average train loss: 4.1512
[09/26 10:56:54 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1691, average loss: 3.2767
[09/26 10:56:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 10:56:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:57:01 visual_prompt]: Epoch 17 / 100: avg data time: 7.84e-02, avg batch time: 0.5255, average train loss: 3.4440
[09/26 10:57:03 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 3.3862
[09/26 10:57:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 25.00	
[09/26 10:57:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:57:10 visual_prompt]: Epoch 18 / 100: avg data time: 7.65e-02, avg batch time: 0.5236, average train loss: 3.3277
[09/26 10:57:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 3.0754
[09/26 10:57:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 10:57:11 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:57:18 visual_prompt]: Epoch 19 / 100: avg data time: 6.24e-02, avg batch time: 0.5113, average train loss: 3.1039
[09/26 10:57:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 3.1388
[09/26 10:57:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 36.00	
[09/26 10:57:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:57:27 visual_prompt]: Epoch 20 / 100: avg data time: 6.71e-02, avg batch time: 0.5147, average train loss: 3.0074
[09/26 10:57:28 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1692, average loss: 2.9557
[09/26 10:57:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 38.00	
[09/26 10:57:28 visual_prompt]: Best epoch 20: best metric: 0.105
[09/26 10:57:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:57:35 visual_prompt]: Epoch 21 / 100: avg data time: 7.21e-02, avg batch time: 0.5194, average train loss: 3.0459
[09/26 10:57:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 3.2097
[09/26 10:57:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 37.00	
[09/26 10:57:37 visual_prompt]: Best epoch 21: best metric: 0.125
[09/26 10:57:37 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:57:44 visual_prompt]: Epoch 22 / 100: avg data time: 5.66e-02, avg batch time: 0.5053, average train loss: 2.9616
[09/26 10:57:45 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1689, average loss: 3.0951
[09/26 10:57:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 48.00	
[09/26 10:57:45 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:57:52 visual_prompt]: Epoch 23 / 100: avg data time: 6.11e-02, avg batch time: 0.5089, average train loss: 2.8156
[09/26 10:57:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 3.1226
[09/26 10:57:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 43.50	
[09/26 10:57:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:58:01 visual_prompt]: Epoch 24 / 100: avg data time: 5.81e-02, avg batch time: 0.5079, average train loss: 2.6729
[09/26 10:58:02 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1694, average loss: 2.9244
[09/26 10:58:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 45.50	
[09/26 10:58:02 visual_prompt]: Best epoch 24: best metric: 0.135
[09/26 10:58:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:58:09 visual_prompt]: Epoch 25 / 100: avg data time: 5.67e-02, avg batch time: 0.5067, average train loss: 2.5803
[09/26 10:58:11 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1695, average loss: 2.8663
[09/26 10:58:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 57.00	
[09/26 10:58:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:58:18 visual_prompt]: Epoch 26 / 100: avg data time: 6.87e-02, avg batch time: 0.5169, average train loss: 2.5294
[09/26 10:58:19 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1693, average loss: 3.0572
[09/26 10:58:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 56.00	
[09/26 10:58:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:58:26 visual_prompt]: Epoch 27 / 100: avg data time: 6.11e-02, avg batch time: 0.5095, average train loss: 2.1468
[09/26 10:58:28 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1693, average loss: 2.9870
[09/26 10:58:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 59.50	
[09/26 10:58:28 visual_prompt]: Best epoch 27: best metric: 0.170
[09/26 10:58:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:58:35 visual_prompt]: Epoch 28 / 100: avg data time: 5.84e-02, avg batch time: 0.5065, average train loss: 1.9783
[09/26 10:58:36 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1693, average loss: 3.3695
[09/26 10:58:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 52.50	
[09/26 10:58:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:58:43 visual_prompt]: Epoch 29 / 100: avg data time: 5.67e-02, avg batch time: 0.5055, average train loss: 1.8671
[09/26 10:58:45 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1696, average loss: 3.4083
[09/26 10:58:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.00	
[09/26 10:58:45 visual_prompt]: Best epoch 29: best metric: 0.175
[09/26 10:58:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:58:51 visual_prompt]: Epoch 30 / 100: avg data time: 4.92e-02, avg batch time: 0.4991, average train loss: 1.7892
[09/26 10:58:53 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1693, average loss: 3.4701
[09/26 10:58:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 57.50	
[09/26 10:58:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:59:00 visual_prompt]: Epoch 31 / 100: avg data time: 6.88e-02, avg batch time: 0.5178, average train loss: 1.6339
[09/26 10:59:02 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1693, average loss: 3.5303
[09/26 10:59:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 57.00	
[09/26 10:59:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:59:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.53e-02, avg batch time: 0.5044, average train loss: 1.3680
[09/26 10:59:10 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1695, average loss: 3.8314
[09/26 10:59:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.00	
[09/26 10:59:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:59:17 visual_prompt]: Epoch 33 / 100: avg data time: 6.35e-02, avg batch time: 0.5115, average train loss: 1.2104
[09/26 10:59:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 3.8042
[09/26 10:59:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.00	
[09/26 10:59:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:59:26 visual_prompt]: Epoch 34 / 100: avg data time: 6.50e-02, avg batch time: 0.5131, average train loss: 1.1103
[09/26 10:59:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1695, average loss: 4.2170
[09/26 10:59:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.00	
[09/26 10:59:28 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:59:35 visual_prompt]: Epoch 35 / 100: avg data time: 6.44e-02, avg batch time: 0.5132, average train loss: 1.1306
[09/26 10:59:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 4.4898
[09/26 10:59:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 58.50	
[09/26 10:59:36 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:59:43 visual_prompt]: Epoch 36 / 100: avg data time: 6.33e-02, avg batch time: 0.5115, average train loss: 0.9618
[09/26 10:59:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 4.0291
[09/26 10:59:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 64.00	
[09/26 10:59:45 visual_prompt]: Best epoch 36: best metric: 0.180
[09/26 10:59:45 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:59:52 visual_prompt]: Epoch 37 / 100: avg data time: 5.73e-02, avg batch time: 0.5062, average train loss: 0.6873
[09/26 10:59:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1693, average loss: 4.6876
[09/26 10:59:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.00	
[09/26 10:59:53 visual_prompt]: Best epoch 37: best metric: 0.205
[09/26 10:59:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 11:00:00 visual_prompt]: Epoch 38 / 100: avg data time: 6.65e-02, avg batch time: 0.5145, average train loss: 0.8050
[09/26 11:00:02 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1690, average loss: 5.2688
[09/26 11:00:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.50	
[09/26 11:00:02 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 11:00:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.16e-02, avg batch time: 0.4998, average train loss: 0.7162
[09/26 11:00:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 4.7969
[09/26 11:00:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.50	
[09/26 11:00:10 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 11:00:17 visual_prompt]: Epoch 40 / 100: avg data time: 5.94e-02, avg batch time: 0.5100, average train loss: 0.5195
[09/26 11:00:19 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 5.4726
[09/26 11:00:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 60.00	
[09/26 11:00:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 11:00:26 visual_prompt]: Epoch 41 / 100: avg data time: 6.40e-02, avg batch time: 0.5128, average train loss: 0.4270
[09/26 11:00:27 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1695, average loss: 6.1054
[09/26 11:00:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.50	
[09/26 11:00:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 11:00:34 visual_prompt]: Epoch 42 / 100: avg data time: 6.49e-02, avg batch time: 0.5129, average train loss: 0.3426
[09/26 11:00:36 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1693, average loss: 6.4503
[09/26 11:00:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.50	
[09/26 11:00:36 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 11:00:43 visual_prompt]: Epoch 43 / 100: avg data time: 6.58e-02, avg batch time: 0.5139, average train loss: 0.3278
[09/26 11:00:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1695, average loss: 6.0378
[09/26 11:00:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 11:00:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 11:00:51 visual_prompt]: Epoch 44 / 100: avg data time: 6.33e-02, avg batch time: 0.5136, average train loss: 0.2893
[09/26 11:00:53 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1693, average loss: 6.7324
[09/26 11:00:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.50	
[09/26 11:00:53 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 11:01:00 visual_prompt]: Epoch 45 / 100: avg data time: 6.58e-02, avg batch time: 0.5148, average train loss: 0.2727
[09/26 11:01:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 6.9178
[09/26 11:01:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.50	
[09/26 11:01:02 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 11:01:09 visual_prompt]: Epoch 46 / 100: avg data time: 6.47e-02, avg batch time: 0.5127, average train loss: 0.2030
[09/26 11:01:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1695, average loss: 7.0970
[09/26 11:01:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:01:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 11:01:17 visual_prompt]: Epoch 47 / 100: avg data time: 6.57e-02, avg batch time: 0.5147, average train loss: 0.2115
[09/26 11:01:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1693, average loss: 7.0922
[09/26 11:01:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 61.00	
[09/26 11:01:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 11:01:26 visual_prompt]: Epoch 48 / 100: avg data time: 5.10e-02, avg batch time: 0.4995, average train loss: 0.1410
[09/26 11:01:27 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1691, average loss: 7.6256
[09/26 11:01:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.50	
[09/26 11:01:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 11:01:34 visual_prompt]: Epoch 49 / 100: avg data time: 6.27e-02, avg batch time: 0.5106, average train loss: 0.1592
[09/26 11:01:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 7.1839
[09/26 11:01:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 11:01:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 11:01:43 visual_prompt]: Epoch 50 / 100: avg data time: 6.47e-02, avg batch time: 0.5136, average train loss: 0.1886
[09/26 11:01:44 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1695, average loss: 7.8149
[09/26 11:01:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 11:01:44 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 11:01:51 visual_prompt]: Epoch 51 / 100: avg data time: 6.86e-02, avg batch time: 0.5165, average train loss: 0.1695
[09/26 11:01:53 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1693, average loss: 7.7494
[09/26 11:01:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.50	
[09/26 11:01:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 11:02:00 visual_prompt]: Epoch 52 / 100: avg data time: 6.22e-02, avg batch time: 0.5116, average train loss: 0.0917
[09/26 11:02:01 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1696, average loss: 8.2127
[09/26 11:02:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 59.00	
[09/26 11:02:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 11:02:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.90e-02, avg batch time: 0.5081, average train loss: 0.0729
[09/26 11:02:10 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1693, average loss: 8.6865
[09/26 11:02:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 58.00	
[09/26 11:02:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 11:02:17 visual_prompt]: Epoch 54 / 100: avg data time: 6.02e-02, avg batch time: 0.5091, average train loss: 0.0689
[09/26 11:02:18 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1693, average loss: 8.5434
[09/26 11:02:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 60.00	
[09/26 11:02:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 11:02:25 visual_prompt]: Epoch 55 / 100: avg data time: 5.75e-02, avg batch time: 0.5062, average train loss: 0.0396
[09/26 11:02:27 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 9.2790
[09/26 11:02:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.00	
[09/26 11:02:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 11:02:34 visual_prompt]: Epoch 56 / 100: avg data time: 6.36e-02, avg batch time: 0.5130, average train loss: 0.0332
[09/26 11:02:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1694, average loss: 9.3537
[09/26 11:02:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 59.50	
[09/26 11:02:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 11:02:42 visual_prompt]: Epoch 57 / 100: avg data time: 5.91e-02, avg batch time: 0.5092, average train loss: 0.0271
[09/26 11:02:44 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1695, average loss: 9.4274
[09/26 11:02:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 59.00	
[09/26 11:02:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 11:02:51 visual_prompt]: Epoch 58 / 100: avg data time: 6.43e-02, avg batch time: 0.5128, average train loss: 0.0241
[09/26 11:02:52 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1696, average loss: 9.7662
[09/26 11:02:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 11:02:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 11:02:59 visual_prompt]: Epoch 59 / 100: avg data time: 5.77e-02, avg batch time: 0.5061, average train loss: 0.0174
[09/26 11:03:01 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 9.7740
[09/26 11:03:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.50	
[09/26 11:03:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 11:03:08 visual_prompt]: Epoch 60 / 100: avg data time: 6.50e-02, avg batch time: 0.5139, average train loss: 0.0135
[09/26 11:03:09 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 9.4892
[09/26 11:03:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.50	
[09/26 11:03:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 11:03:16 visual_prompt]: Epoch 61 / 100: avg data time: 5.45e-02, avg batch time: 0.5030, average train loss: 0.0139
[09/26 11:03:18 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1695, average loss: 10.6310
[09/26 11:03:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 58.50	
[09/26 11:03:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 11:03:25 visual_prompt]: Epoch 62 / 100: avg data time: 6.05e-02, avg batch time: 0.5106, average train loss: 0.0126
[09/26 11:03:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1695, average loss: 10.4753
[09/26 11:03:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:03:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 11:03:33 visual_prompt]: Epoch 63 / 100: avg data time: 5.84e-02, avg batch time: 0.5084, average train loss: 0.0145
[09/26 11:03:35 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1694, average loss: 10.3461
[09/26 11:03:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 63.00	
[09/26 11:03:35 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 11:03:42 visual_prompt]: Epoch 64 / 100: avg data time: 6.27e-02, avg batch time: 0.5111, average train loss: 0.0078
[09/26 11:03:43 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1692, average loss: 11.0910
[09/26 11:03:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 58.00	
[09/26 11:03:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 11:03:50 visual_prompt]: Epoch 65 / 100: avg data time: 5.47e-02, avg batch time: 0.5032, average train loss: 0.0100
[09/26 11:03:52 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1695, average loss: 10.8352
[09/26 11:03:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.50	
[09/26 11:03:52 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 11:03:58 visual_prompt]: Epoch 66 / 100: avg data time: 5.54e-02, avg batch time: 0.5055, average train loss: 0.0054
[09/26 11:04:00 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1695, average loss: 10.6037
[09/26 11:04:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.50	
[09/26 11:04:00 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 11:04:07 visual_prompt]: Epoch 67 / 100: avg data time: 5.69e-02, avg batch time: 0.5065, average train loss: 0.0039
[09/26 11:04:08 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1698, average loss: 10.4101
[09/26 11:04:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 63.00	
[09/26 11:04:08 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 11:04:15 visual_prompt]: Epoch 68 / 100: avg data time: 6.01e-02, avg batch time: 0.5097, average train loss: 0.0017
[09/26 11:04:17 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1695, average loss: 10.5661
[09/26 11:04:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 63.50	
[09/26 11:04:17 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 11:04:24 visual_prompt]: Epoch 69 / 100: avg data time: 5.58e-02, avg batch time: 0.5068, average train loss: 0.0018
[09/26 11:04:25 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1694, average loss: 10.7981
[09/26 11:04:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.50	
[09/26 11:04:25 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 11:04:32 visual_prompt]: Epoch 70 / 100: avg data time: 5.45e-02, avg batch time: 0.5040, average train loss: 0.0043
[09/26 11:04:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 10.7975
[09/26 11:04:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.50	
[09/26 11:04:33 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 11:04:40 visual_prompt]: Epoch 71 / 100: avg data time: 5.39e-02, avg batch time: 0.5028, average train loss: 0.0038
[09/26 11:04:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 11.2092
[09/26 11:04:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:04:42 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 11:04:49 visual_prompt]: Epoch 72 / 100: avg data time: 5.18e-02, avg batch time: 0.5003, average train loss: 0.0023
[09/26 11:04:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1694, average loss: 10.9522
[09/26 11:04:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 62.00	
[09/26 11:04:50 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 11:04:57 visual_prompt]: Epoch 73 / 100: avg data time: 5.42e-02, avg batch time: 0.5041, average train loss: 0.0012
[09/26 11:04:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1695, average loss: 10.7935
[09/26 11:04:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 11:04:58 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 11:05:05 visual_prompt]: Epoch 74 / 100: avg data time: 6.04e-02, avg batch time: 0.5086, average train loss: 0.0012
[09/26 11:05:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1694, average loss: 10.7856
[09/26 11:05:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 62.00	
[09/26 11:05:07 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 11:05:14 visual_prompt]: Epoch 75 / 100: avg data time: 6.43e-02, avg batch time: 0.5128, average train loss: 0.0010
[09/26 11:05:15 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1693, average loss: 10.8090
[09/26 11:05:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 11:05:15 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 11:05:22 visual_prompt]: Epoch 76 / 100: avg data time: 5.79e-02, avg batch time: 0.5076, average train loss: 0.0005
[09/26 11:05:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1693, average loss: 10.8647
[09/26 11:05:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 11:05:24 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 11:05:31 visual_prompt]: Epoch 77 / 100: avg data time: 6.29e-02, avg batch time: 0.5112, average train loss: 0.0008
[09/26 11:05:33 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 10.9146
[09/26 11:05:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.00	
[09/26 11:05:33 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 11:05:40 visual_prompt]: Epoch 78 / 100: avg data time: 5.96e-02, avg batch time: 0.5090, average train loss: 0.0021
[09/26 11:05:41 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1694, average loss: 10.9718
[09/26 11:05:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 11:05:41 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 11:05:48 visual_prompt]: Epoch 79 / 100: avg data time: 5.96e-02, avg batch time: 0.5099, average train loss: 0.0011
[09/26 11:05:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1690, average loss: 10.9854
[09/26 11:05:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:05:50 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 11:05:57 visual_prompt]: Epoch 80 / 100: avg data time: 5.68e-02, avg batch time: 0.5049, average train loss: 0.0010
[09/26 11:05:58 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1693, average loss: 10.9908
[09/26 11:05:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:05:58 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 11:06:05 visual_prompt]: Epoch 81 / 100: avg data time: 7.28e-02, avg batch time: 0.5209, average train loss: 0.0008
[09/26 11:06:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 11.0076
[09/26 11:06:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:06:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 11:06:14 visual_prompt]: Epoch 82 / 100: avg data time: 4.70e-02, avg batch time: 0.5000, average train loss: 0.0012
[09/26 11:06:15 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1694, average loss: 11.0406
[09/26 11:06:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:06:15 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 11:06:22 visual_prompt]: Epoch 83 / 100: avg data time: 4.95e-02, avg batch time: 0.4994, average train loss: 0.0009
[09/26 11:06:24 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1695, average loss: 11.0742
[09/26 11:06:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:06:24 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 11:06:31 visual_prompt]: Epoch 84 / 100: avg data time: 6.73e-02, avg batch time: 0.5154, average train loss: 0.0010
[09/26 11:06:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1696, average loss: 11.0964
[09/26 11:06:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:06:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 11:06:39 visual_prompt]: Epoch 85 / 100: avg data time: 5.45e-02, avg batch time: 0.5030, average train loss: 0.0010
[09/26 11:06:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 11.1085
[09/26 11:06:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:06:41 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 11:06:47 visual_prompt]: Epoch 86 / 100: avg data time: 5.19e-02, avg batch time: 0.5013, average train loss: 0.0008
[09/26 11:06:49 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 11.1046
[09/26 11:06:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:06:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 11:06:56 visual_prompt]: Epoch 87 / 100: avg data time: 4.97e-02, avg batch time: 0.4999, average train loss: 0.0007
[09/26 11:06:57 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1697, average loss: 11.1123
[09/26 11:06:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:06:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 11:07:04 visual_prompt]: Epoch 88 / 100: avg data time: 6.53e-02, avg batch time: 0.5151, average train loss: 0.0012
[09/26 11:07:06 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1694, average loss: 11.1277
[09/26 11:07:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:07:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 11:07:13 visual_prompt]: Epoch 89 / 100: avg data time: 5.39e-02, avg batch time: 0.5022, average train loss: 0.0008
[09/26 11:07:14 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1696, average loss: 11.1442
[09/26 11:07:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:07:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 11:07:21 visual_prompt]: Epoch 90 / 100: avg data time: 5.16e-02, avg batch time: 0.5004, average train loss: 0.0005
[09/26 11:07:22 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1697, average loss: 11.1544
[09/26 11:07:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:07:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 11:07:29 visual_prompt]: Epoch 91 / 100: avg data time: 4.84e-02, avg batch time: 0.4982, average train loss: 0.0006
[09/26 11:07:31 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1693, average loss: 11.1614
[09/26 11:07:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:07:31 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 11:07:38 visual_prompt]: Epoch 92 / 100: avg data time: 5.49e-02, avg batch time: 0.5035, average train loss: 0.0009
[09/26 11:07:39 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1696, average loss: 11.1701
[09/26 11:07:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 11:07:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 11:07:46 visual_prompt]: Epoch 93 / 100: avg data time: 5.19e-02, avg batch time: 0.5028, average train loss: 0.0006
[09/26 11:07:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1696, average loss: 11.1736
[09/26 11:07:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 11:07:48 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 11:07:55 visual_prompt]: Epoch 94 / 100: avg data time: 7.42e-02, avg batch time: 0.5224, average train loss: 0.0005
[09/26 11:07:56 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1695, average loss: 11.1750
[09/26 11:07:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:07:56 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 11:08:04 visual_prompt]: Epoch 95 / 100: avg data time: 7.89e-02, avg batch time: 0.5270, average train loss: 0.0004
[09/26 11:08:05 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1691, average loss: 11.1758
[09/26 11:08:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:05 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 11:08:12 visual_prompt]: Epoch 96 / 100: avg data time: 7.21e-02, avg batch time: 0.5201, average train loss: 0.0010
[09/26 11:08:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1693, average loss: 11.1727
[09/26 11:08:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:14 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 11:08:21 visual_prompt]: Epoch 97 / 100: avg data time: 6.39e-02, avg batch time: 0.5132, average train loss: 0.0006
[09/26 11:08:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 11.1727
[09/26 11:08:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:22 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 11:08:29 visual_prompt]: Epoch 98 / 100: avg data time: 5.89e-02, avg batch time: 0.5070, average train loss: 0.0005
[09/26 11:08:31 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1694, average loss: 11.1728
[09/26 11:08:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:31 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 11:08:38 visual_prompt]: Epoch 99 / 100: avg data time: 6.21e-02, avg batch time: 0.5114, average train loss: 0.0007
[09/26 11:08:39 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1692, average loss: 11.1731
[09/26 11:08:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:39 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 11:08:46 visual_prompt]: Epoch 100 / 100: avg data time: 5.46e-02, avg batch time: 0.5044, average train loss: 0.0017
[09/26 11:08:48 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1693, average loss: 11.1731
[09/26 11:08:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 11:08:48 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:08:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:08:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:08:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:08:48 visual_prompt]: Training with config:
[09/26 11:08:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:08:48 visual_prompt]: Loading training data...
[09/26 11:08:48 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:08:49 visual_prompt]: Number of images: 800
[09/26 11:08:49 visual_prompt]: Number of classes: 18 / 18
[09/26 11:08:49 visual_prompt]: Loading validation data...
[09/26 11:08:49 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:08:49 visual_prompt]: Number of images: 200
[09/26 11:08:49 visual_prompt]: Number of classes: 18 / 18
[09/26 11:08:49 visual_prompt]: Constructing models...
[09/26 11:08:52 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 11:08:52 visual_prompt]: tuned percent:0.550
[09/26 11:08:52 visual_prompt]: Device used for model: 0
[09/26 11:08:52 visual_prompt]: Setting up Evaluator...
[09/26 11:08:52 visual_prompt]: Setting up Trainer...
[09/26 11:08:52 visual_prompt]: 	Setting up the optimizer...
[09/26 11:08:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:08:59 visual_prompt]: Epoch 1 / 100: avg data time: 6.31e-02, avg batch time: 0.5134, average train loss: 3.2510
[09/26 11:09:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 11:09:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 11:09:01 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 11:09:01 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:09:08 visual_prompt]: Epoch 2 / 100: avg data time: 6.92e-02, avg batch time: 0.5161, average train loss: 3.2800
[09/26 11:09:09 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 3.1595
[09/26 11:09:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 11:09:09 visual_prompt]: Best epoch 2: best metric: 0.085
[09/26 11:09:09 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:09:16 visual_prompt]: Epoch 3 / 100: avg data time: 5.50e-02, avg batch time: 0.5020, average train loss: 2.9961
[09/26 11:09:18 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 2.9647
[09/26 11:09:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 11:09:18 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:09:24 visual_prompt]: Epoch 4 / 100: avg data time: 6.13e-02, avg batch time: 0.5095, average train loss: 2.9473
[09/26 11:09:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 3.0329
[09/26 11:09:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 11:09:26 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:09:33 visual_prompt]: Epoch 5 / 100: avg data time: 6.36e-02, avg batch time: 0.5105, average train loss: 2.9829
[09/26 11:09:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 3.0297
[09/26 11:09:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:09:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:09:41 visual_prompt]: Epoch 6 / 100: avg data time: 6.72e-02, avg batch time: 0.5143, average train loss: 2.9869
[09/26 11:09:43 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1688, average loss: 3.1319
[09/26 11:09:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.50	
[09/26 11:09:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:09:50 visual_prompt]: Epoch 7 / 100: avg data time: 6.44e-02, avg batch time: 0.5130, average train loss: 3.0352
[09/26 11:09:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 2.9895
[09/26 11:09:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:09:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:09:58 visual_prompt]: Epoch 8 / 100: avg data time: 6.10e-02, avg batch time: 0.5089, average train loss: 2.9971
[09/26 11:10:00 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 3.1613
[09/26 11:10:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 11:10:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:10:07 visual_prompt]: Epoch 9 / 100: avg data time: 5.16e-02, avg batch time: 0.4996, average train loss: 3.0751
[09/26 11:10:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 3.1634
[09/26 11:10:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.50	
[09/26 11:10:08 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:10:15 visual_prompt]: Epoch 10 / 100: avg data time: 6.45e-02, avg batch time: 0.5134, average train loss: 3.4593
[09/26 11:10:17 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1693, average loss: 3.4493
[09/26 11:10:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 11:10:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:10:24 visual_prompt]: Epoch 11 / 100: avg data time: 6.00e-02, avg batch time: 0.5084, average train loss: 3.4135
[09/26 11:10:25 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 4.4392
[09/26 11:10:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 11:10:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:10:32 visual_prompt]: Epoch 12 / 100: avg data time: 5.19e-02, avg batch time: 0.5024, average train loss: 6.4880
[09/26 11:10:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1691, average loss: 4.9700
[09/26 11:10:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 11:10:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:10:40 visual_prompt]: Epoch 13 / 100: avg data time: 4.39e-02, avg batch time: 0.4923, average train loss: 6.4546
[09/26 11:10:42 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 6.3379
[09/26 11:10:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 11:10:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:10:49 visual_prompt]: Epoch 14 / 100: avg data time: 5.86e-02, avg batch time: 0.5065, average train loss: 6.9189
[09/26 11:10:50 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1695, average loss: 4.6985
[09/26 11:10:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 11:10:50 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:10:57 visual_prompt]: Epoch 15 / 100: avg data time: 6.58e-02, avg batch time: 0.5139, average train loss: 6.2996
[09/26 11:10:59 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1689, average loss: 7.6329
[09/26 11:10:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 11:10:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:11:06 visual_prompt]: Epoch 16 / 100: avg data time: 5.85e-02, avg batch time: 0.5060, average train loss: 9.8146
[09/26 11:11:07 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1691, average loss: 5.6117
[09/26 11:11:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 11:11:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:11:14 visual_prompt]: Epoch 17 / 100: avg data time: 4.71e-02, avg batch time: 0.4954, average train loss: 5.7426
[09/26 11:11:16 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1691, average loss: 5.1474
[09/26 11:11:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 11:11:16 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:11:22 visual_prompt]: Epoch 18 / 100: avg data time: 6.42e-02, avg batch time: 0.5116, average train loss: 7.5330
[09/26 11:11:24 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1694, average loss: 7.5657
[09/26 11:11:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.50	
[09/26 11:11:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:11:31 visual_prompt]: Epoch 19 / 100: avg data time: 5.12e-02, avg batch time: 0.4996, average train loss: 7.1756
[09/26 11:11:32 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1693, average loss: 5.9268
[09/26 11:11:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 11:11:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:11:39 visual_prompt]: Epoch 20 / 100: avg data time: 5.63e-02, avg batch time: 0.5045, average train loss: 4.7554
[09/26 11:11:41 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1690, average loss: 4.3576
[09/26 11:11:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 11:11:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:11:48 visual_prompt]: Epoch 21 / 100: avg data time: 5.34e-02, avg batch time: 0.5028, average train loss: 4.0653
[09/26 11:11:49 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 4.4238
[09/26 11:11:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 11:11:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:11:56 visual_prompt]: Epoch 22 / 100: avg data time: 6.43e-02, avg batch time: 0.5118, average train loss: 3.4095
[09/26 11:11:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1695, average loss: 3.6415
[09/26 11:11:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 11:11:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:12:05 visual_prompt]: Epoch 23 / 100: avg data time: 6.38e-02, avg batch time: 0.5112, average train loss: 3.4435
[09/26 11:12:07 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1688, average loss: 3.4263
[09/26 11:12:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 11:12:07 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:12:14 visual_prompt]: Epoch 24 / 100: avg data time: 7.45e-02, avg batch time: 0.5215, average train loss: 4.6489
[09/26 11:12:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1689, average loss: 4.6224
[09/26 11:12:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:12:16 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:12:23 visual_prompt]: Epoch 25 / 100: avg data time: 7.15e-02, avg batch time: 0.5181, average train loss: 5.9319
[09/26 11:12:24 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1691, average loss: 4.0037
[09/26 11:12:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 33.00	
[09/26 11:12:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:12:31 visual_prompt]: Epoch 26 / 100: avg data time: 5.68e-02, avg batch time: 0.5041, average train loss: 6.3276
[09/26 11:12:33 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1693, average loss: 7.1064
[09/26 11:12:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 11:12:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:12:40 visual_prompt]: Epoch 27 / 100: avg data time: 6.28e-02, avg batch time: 0.5116, average train loss: 7.7011
[09/26 11:12:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1688, average loss: 6.6853
[09/26 11:12:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 11:12:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:12:48 visual_prompt]: Epoch 28 / 100: avg data time: 7.19e-02, avg batch time: 0.5191, average train loss: 8.9582
[09/26 11:12:50 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1690, average loss: 5.5580
[09/26 11:12:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.00	
[09/26 11:12:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:12:57 visual_prompt]: Epoch 29 / 100: avg data time: 4.87e-02, avg batch time: 0.4965, average train loss: 6.5913
[09/26 11:12:58 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 5.6007
[09/26 11:12:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 11:12:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:13:05 visual_prompt]: Epoch 30 / 100: avg data time: 4.40e-02, avg batch time: 0.4923, average train loss: 5.5613
[09/26 11:13:06 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1693, average loss: 4.4702
[09/26 11:13:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 11:13:06 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:13:13 visual_prompt]: Epoch 31 / 100: avg data time: 6.46e-02, avg batch time: 0.5130, average train loss: 4.6914
[09/26 11:13:15 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1687, average loss: 3.9323
[09/26 11:13:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.00	
[09/26 11:13:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:13:22 visual_prompt]: Epoch 32 / 100: avg data time: 5.26e-02, avg batch time: 0.5007, average train loss: 4.1859
[09/26 11:13:23 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1696, average loss: 3.9012
[09/26 11:13:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 11:13:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:13:30 visual_prompt]: Epoch 33 / 100: avg data time: 6.72e-02, avg batch time: 0.5147, average train loss: 3.6954
[09/26 11:13:32 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1690, average loss: 3.5851
[09/26 11:13:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 11:13:32 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:13:39 visual_prompt]: Epoch 34 / 100: avg data time: 6.76e-02, avg batch time: 0.5154, average train loss: 3.2436
[09/26 11:13:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1693, average loss: 3.1240
[09/26 11:13:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 24.50	
[09/26 11:13:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:13:47 visual_prompt]: Epoch 35 / 100: avg data time: 5.95e-02, avg batch time: 0.5092, average train loss: 3.4394
[09/26 11:13:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1692, average loss: 3.4443
[09/26 11:13:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 11:13:49 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:13:56 visual_prompt]: Epoch 36 / 100: avg data time: 6.05e-02, avg batch time: 0.5090, average train loss: 3.2514
[09/26 11:13:57 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1697, average loss: 3.1128
[09/26 11:13:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 11:13:57 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:14:04 visual_prompt]: Epoch 37 / 100: avg data time: 5.97e-02, avg batch time: 0.5073, average train loss: 3.1379
[09/26 11:14:06 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 3.6631
[09/26 11:14:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 11:14:06 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:14:13 visual_prompt]: Epoch 38 / 100: avg data time: 6.44e-02, avg batch time: 0.5112, average train loss: 3.1856
[09/26 11:14:14 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1689, average loss: 3.0712
[09/26 11:14:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 11:14:14 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:14:21 visual_prompt]: Epoch 39 / 100: avg data time: 6.22e-02, avg batch time: 0.5099, average train loss: 3.0244
[09/26 11:14:23 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1693, average loss: 3.0352
[09/26 11:14:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.00	
[09/26 11:14:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:14:30 visual_prompt]: Epoch 40 / 100: avg data time: 5.85e-02, avg batch time: 0.5073, average train loss: 3.2678
[09/26 11:14:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 3.0317
[09/26 11:14:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 34.00	
[09/26 11:14:32 visual_prompt]: Best epoch 40: best metric: 0.090
[09/26 11:14:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:14:39 visual_prompt]: Epoch 41 / 100: avg data time: 7.27e-02, avg batch time: 0.5201, average train loss: 3.7375
[09/26 11:14:40 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1691, average loss: 3.6853
[09/26 11:14:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 11:14:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:14:47 visual_prompt]: Epoch 42 / 100: avg data time: 6.76e-02, avg batch time: 0.5142, average train loss: 3.5953
[09/26 11:14:49 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 3.2449
[09/26 11:14:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 11:14:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:14:56 visual_prompt]: Epoch 43 / 100: avg data time: 6.29e-02, avg batch time: 0.5100, average train loss: 3.4237
[09/26 11:14:57 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1687, average loss: 3.2450
[09/26 11:14:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 11:14:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:15:04 visual_prompt]: Epoch 44 / 100: avg data time: 6.83e-02, avg batch time: 0.5154, average train loss: 3.3060
[09/26 11:15:06 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1689, average loss: 3.2464
[09/26 11:15:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:15:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:15:13 visual_prompt]: Epoch 45 / 100: avg data time: 7.18e-02, avg batch time: 0.5186, average train loss: 3.2880
[09/26 11:15:15 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.1691, average loss: 3.3666
[09/26 11:15:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 11:15:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:15:22 visual_prompt]: Epoch 46 / 100: avg data time: 6.78e-02, avg batch time: 0.5147, average train loss: 3.2443
[09/26 11:15:23 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 3.9995
[09/26 11:15:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 11:15:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:15:30 visual_prompt]: Epoch 47 / 100: avg data time: 5.67e-02, avg batch time: 0.5039, average train loss: 3.6035
[09/26 11:15:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 3.0374
[09/26 11:15:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 11:15:32 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:15:39 visual_prompt]: Epoch 48 / 100: avg data time: 6.43e-02, avg batch time: 0.5119, average train loss: 3.0491
[09/26 11:15:40 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 3.0237
[09/26 11:15:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.50	
[09/26 11:15:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:15:47 visual_prompt]: Epoch 49 / 100: avg data time: 4.81e-02, avg batch time: 0.4982, average train loss: 3.0351
[09/26 11:15:49 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 3.2612
[09/26 11:15:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 21.50	
[09/26 11:15:49 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:15:56 visual_prompt]: Epoch 50 / 100: avg data time: 5.68e-02, avg batch time: 0.5043, average train loss: 3.1608
[09/26 11:15:57 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1694, average loss: 3.1038
[09/26 11:15:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.00	
[09/26 11:15:57 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:16:04 visual_prompt]: Epoch 51 / 100: avg data time: 5.18e-02, avg batch time: 0.5005, average train loss: 3.4538
[09/26 11:16:06 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1688, average loss: 3.1492
[09/26 11:16:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:16:06 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:16:12 visual_prompt]: Epoch 52 / 100: avg data time: 4.90e-02, avg batch time: 0.4993, average train loss: 3.1510
[09/26 11:16:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 3.1247
[09/26 11:16:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 11:16:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:16:21 visual_prompt]: Epoch 53 / 100: avg data time: 5.14e-02, avg batch time: 0.4998, average train loss: 3.0444
[09/26 11:16:22 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1692, average loss: 3.1154
[09/26 11:16:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 11:16:22 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:16:29 visual_prompt]: Epoch 54 / 100: avg data time: 4.92e-02, avg batch time: 0.4990, average train loss: 3.0041
[09/26 11:16:31 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 2.9840
[09/26 11:16:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:16:31 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:16:38 visual_prompt]: Epoch 55 / 100: avg data time: 4.76e-02, avg batch time: 0.4973, average train loss: 2.9647
[09/26 11:16:39 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1695, average loss: 3.0958
[09/26 11:16:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 11:16:39 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:16:46 visual_prompt]: Epoch 56 / 100: avg data time: 5.60e-02, avg batch time: 0.5039, average train loss: 2.9891
[09/26 11:16:48 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1689, average loss: 2.9441
[09/26 11:16:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 11:16:48 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:16:55 visual_prompt]: Epoch 57 / 100: avg data time: 6.97e-02, avg batch time: 0.5173, average train loss: 3.0406
[09/26 11:16:56 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.1691, average loss: 2.9922
[09/26 11:16:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 11:16:56 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:17:03 visual_prompt]: Epoch 58 / 100: avg data time: 4.86e-02, avg batch time: 0.4973, average train loss: 3.0044
[09/26 11:17:04 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1691, average loss: 2.9545
[09/26 11:17:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:17:04 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:17:11 visual_prompt]: Epoch 59 / 100: avg data time: 5.93e-02, avg batch time: 0.5078, average train loss: 2.9580
[09/26 11:17:13 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 3.1512
[09/26 11:17:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 11:17:13 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:17:20 visual_prompt]: Epoch 60 / 100: avg data time: 6.97e-02, avg batch time: 0.5174, average train loss: 3.0753
[09/26 11:17:21 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1689, average loss: 3.1750
[09/26 11:17:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 11:17:21 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:17:28 visual_prompt]: Epoch 61 / 100: avg data time: 6.22e-02, avg batch time: 0.5096, average train loss: 2.9860
[09/26 11:17:30 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1687, average loss: 2.9715
[09/26 11:17:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 11:17:30 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 11:17:37 visual_prompt]: Epoch 62 / 100: avg data time: 6.15e-02, avg batch time: 0.5102, average train loss: 2.9787
[09/26 11:17:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1689, average loss: 3.0201
[09/26 11:17:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 11:17:38 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 11:17:45 visual_prompt]: Epoch 63 / 100: avg data time: 6.61e-02, avg batch time: 0.5145, average train loss: 2.9595
[09/26 11:17:47 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 3.0243
[09/26 11:17:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 11:17:47 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 11:17:54 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.5060, average train loss: 2.9564
[09/26 11:17:55 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 2.9630
[09/26 11:17:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 11:17:55 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 11:18:02 visual_prompt]: Epoch 65 / 100: avg data time: 4.78e-02, avg batch time: 0.4953, average train loss: 2.9423
[09/26 11:18:04 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1693, average loss: 2.9668
[09/26 11:18:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 11:18:04 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 11:18:11 visual_prompt]: Epoch 66 / 100: avg data time: 5.66e-02, avg batch time: 0.5056, average train loss: 2.9487
[09/26 11:18:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1692, average loss: 2.9471
[09/26 11:18:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 11:18:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 11:18:19 visual_prompt]: Epoch 67 / 100: avg data time: 4.63e-02, avg batch time: 0.4959, average train loss: 2.9281
[09/26 11:18:20 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1693, average loss: 2.9689
[09/26 11:18:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 11:18:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 11:18:27 visual_prompt]: Epoch 68 / 100: avg data time: 6.56e-02, avg batch time: 0.5134, average train loss: 2.9339
[09/26 11:18:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1688, average loss: 2.9464
[09/26 11:18:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 11:18:29 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 11:18:36 visual_prompt]: Epoch 69 / 100: avg data time: 5.04e-02, avg batch time: 0.4987, average train loss: 2.9267
[09/26 11:18:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1688, average loss: 2.9120
[09/26 11:18:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 11:18:37 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 11:18:44 visual_prompt]: Epoch 70 / 100: avg data time: 4.58e-02, avg batch time: 0.4935, average train loss: 2.9251
[09/26 11:18:45 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 2.9391
[09/26 11:18:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 23.50	
[09/26 11:18:45 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 11:18:52 visual_prompt]: Epoch 71 / 100: avg data time: 4.95e-02, avg batch time: 0.4989, average train loss: 2.9242
[09/26 11:18:54 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1691, average loss: 3.0220
[09/26 11:18:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 22.50	
[09/26 11:18:54 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 11:19:00 visual_prompt]: Epoch 72 / 100: avg data time: 4.17e-02, avg batch time: 0.4908, average train loss: 2.9850
[09/26 11:19:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 3.0052
[09/26 11:19:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 11:19:02 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 11:19:09 visual_prompt]: Epoch 73 / 100: avg data time: 5.72e-02, avg batch time: 0.5072, average train loss: 2.9639
[09/26 11:19:10 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1693, average loss: 2.9114
[09/26 11:19:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 11:19:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 11:19:17 visual_prompt]: Epoch 74 / 100: avg data time: 5.42e-02, avg batch time: 0.5040, average train loss: 2.9187
[09/26 11:19:19 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1692, average loss: 2.9414
[09/26 11:19:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 11:19:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 11:19:26 visual_prompt]: Epoch 75 / 100: avg data time: 4.93e-02, avg batch time: 0.4971, average train loss: 2.9193
[09/26 11:19:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1693, average loss: 2.8937
[09/26 11:19:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 11:19:27 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 11:19:34 visual_prompt]: Epoch 76 / 100: avg data time: 5.66e-02, avg batch time: 0.5049, average train loss: 2.9013
[09/26 11:19:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1690, average loss: 2.9132
[09/26 11:19:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.50	
[09/26 11:19:36 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 11:19:42 visual_prompt]: Epoch 77 / 100: avg data time: 4.72e-02, avg batch time: 0.4967, average train loss: 2.9154
[09/26 11:19:44 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1686, average loss: 2.8998
[09/26 11:19:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 11:19:44 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 11:19:51 visual_prompt]: Epoch 78 / 100: avg data time: 5.53e-02, avg batch time: 0.5039, average train loss: 2.9088
[09/26 11:19:52 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1696, average loss: 2.9467
[09/26 11:19:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 11:19:52 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 11:19:59 visual_prompt]: Epoch 79 / 100: avg data time: 5.49e-02, avg batch time: 0.5035, average train loss: 2.9136
[09/26 11:20:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1688, average loss: 2.9073
[09/26 11:20:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 34.50	
[09/26 11:20:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 11:20:07 visual_prompt]: Epoch 80 / 100: avg data time: 5.57e-02, avg batch time: 0.5033, average train loss: 2.9122
[09/26 11:20:09 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1689, average loss: 2.9183
[09/26 11:20:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 11:20:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 11:20:16 visual_prompt]: Epoch 81 / 100: avg data time: 5.16e-02, avg batch time: 0.5002, average train loss: 2.9075
[09/26 11:20:17 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1691, average loss: 2.9140
[09/26 11:20:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 11:20:17 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 11:20:24 visual_prompt]: Epoch 82 / 100: avg data time: 5.06e-02, avg batch time: 0.5003, average train loss: 2.9118
[09/26 11:20:26 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1694, average loss: 2.8988
[09/26 11:20:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 11:20:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 11:20:32 visual_prompt]: Epoch 83 / 100: avg data time: 5.08e-02, avg batch time: 0.5002, average train loss: 2.8976
[09/26 11:20:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 2.9126
[09/26 11:20:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:20:34 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:20:41 visual_prompt]: Epoch 84 / 100: avg data time: 7.05e-02, avg batch time: 0.5186, average train loss: 2.8951
[09/26 11:20:43 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 2.9120
[09/26 11:20:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:20:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:20:50 visual_prompt]: Epoch 85 / 100: avg data time: 7.76e-02, avg batch time: 0.5248, average train loss: 2.8900
[09/26 11:20:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1687, average loss: 2.9079
[09/26 11:20:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:20:52 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:20:59 visual_prompt]: Epoch 86 / 100: avg data time: 6.17e-02, avg batch time: 0.5092, average train loss: 2.8913
[09/26 11:21:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1690, average loss: 2.9160
[09/26 11:21:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 11:21:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:21:07 visual_prompt]: Epoch 87 / 100: avg data time: 5.31e-02, avg batch time: 0.5062, average train loss: 2.8938
[09/26 11:21:09 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 2.9070
[09/26 11:21:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:21:09 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:21:15 visual_prompt]: Epoch 88 / 100: avg data time: 6.16e-02, avg batch time: 0.5090, average train loss: 2.8945
[09/26 11:21:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 2.9025
[09/26 11:21:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 11:21:17 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:21:24 visual_prompt]: Epoch 89 / 100: avg data time: 4.64e-02, avg batch time: 0.4956, average train loss: 2.8905
[09/26 11:21:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 2.9106
[09/26 11:21:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 11:21:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:21:32 visual_prompt]: Epoch 90 / 100: avg data time: 4.55e-02, avg batch time: 0.4951, average train loss: 2.8837
[09/26 11:21:33 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 2.9124
[09/26 11:21:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 11:21:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:21:40 visual_prompt]: Epoch 91 / 100: avg data time: 4.72e-02, avg batch time: 0.4950, average train loss: 2.8879
[09/26 11:21:42 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 2.9095
[09/26 11:21:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 11:21:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:21:49 visual_prompt]: Epoch 92 / 100: avg data time: 4.90e-02, avg batch time: 0.4968, average train loss: 2.8832
[09/26 11:21:50 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1692, average loss: 2.9060
[09/26 11:21:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:21:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:21:57 visual_prompt]: Epoch 93 / 100: avg data time: 5.57e-02, avg batch time: 0.5044, average train loss: 2.8826
[09/26 11:21:58 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1688, average loss: 2.9069
[09/26 11:21:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 11:21:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:22:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.90e-02, avg batch time: 0.5065, average train loss: 2.8826
[09/26 11:22:07 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1689, average loss: 2.9093
[09/26 11:22:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 11:22:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:22:14 visual_prompt]: Epoch 95 / 100: avg data time: 5.98e-02, avg batch time: 0.5068, average train loss: 2.8795
[09/26 11:22:16 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 2.9056
[09/26 11:22:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 11:22:16 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:22:23 visual_prompt]: Epoch 96 / 100: avg data time: 6.32e-02, avg batch time: 0.5098, average train loss: 2.8811
[09/26 11:22:24 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1687, average loss: 2.9070
[09/26 11:22:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:22:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:22:31 visual_prompt]: Epoch 97 / 100: avg data time: 6.15e-02, avg batch time: 0.5093, average train loss: 2.8784
[09/26 11:22:32 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 2.9027
[09/26 11:22:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 11:22:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:22:39 visual_prompt]: Epoch 98 / 100: avg data time: 5.31e-02, avg batch time: 0.5005, average train loss: 2.8770
[09/26 11:22:41 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1687, average loss: 2.9009
[09/26 11:22:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 11:22:41 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:22:48 visual_prompt]: Epoch 99 / 100: avg data time: 6.13e-02, avg batch time: 0.5085, average train loss: 2.8744
[09/26 11:22:49 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1693, average loss: 2.9054
[09/26 11:22:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 11:22:49 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:22:56 visual_prompt]: Epoch 100 / 100: avg data time: 4.31e-02, avg batch time: 0.4925, average train loss: 2.8753
[09/26 11:22:58 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1690, average loss: 2.9045
[09/26 11:22:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 11:22:58 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:22:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:22:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:22:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:22:58 visual_prompt]: Training with config:
[09/26 11:22:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:22:58 visual_prompt]: Loading training data...
[09/26 11:22:58 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:22:59 visual_prompt]: Number of images: 800
[09/26 11:22:59 visual_prompt]: Number of classes: 18 / 18
[09/26 11:22:59 visual_prompt]: Loading validation data...
[09/26 11:22:59 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:22:59 visual_prompt]: Number of images: 200
[09/26 11:22:59 visual_prompt]: Number of classes: 18 / 18
[09/26 11:22:59 visual_prompt]: Constructing models...
[09/26 11:23:02 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 11:23:02 visual_prompt]: tuned percent:0.550
[09/26 11:23:02 visual_prompt]: Device used for model: 0
[09/26 11:23:02 visual_prompt]: Setting up Evaluator...
[09/26 11:23:02 visual_prompt]: Setting up Trainer...
[09/26 11:23:02 visual_prompt]: 	Setting up the optimizer...
[09/26 11:23:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:23:09 visual_prompt]: Epoch 1 / 100: avg data time: 5.12e-02, avg batch time: 0.5019, average train loss: 3.2465
[09/26 11:23:10 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 11:23:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 11:23:10 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 11:23:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:23:17 visual_prompt]: Epoch 2 / 100: avg data time: 7.30e-02, avg batch time: 0.5197, average train loss: 3.2839
[09/26 11:23:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1688, average loss: 3.1860
[09/26 11:23:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:23:19 visual_prompt]: Best epoch 2: best metric: 0.085
[09/26 11:23:19 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:23:26 visual_prompt]: Epoch 3 / 100: avg data time: 6.42e-02, avg batch time: 0.5110, average train loss: 2.9952
[09/26 11:23:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1689, average loss: 2.9551
[09/26 11:23:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 11:23:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:23:34 visual_prompt]: Epoch 4 / 100: avg data time: 7.18e-02, avg batch time: 0.5186, average train loss: 3.0110
[09/26 11:23:36 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 3.0391
[09/26 11:23:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:23:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:23:43 visual_prompt]: Epoch 5 / 100: avg data time: 5.86e-02, avg batch time: 0.5062, average train loss: 2.9963
[09/26 11:23:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 3.0287
[09/26 11:23:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.00	
[09/26 11:23:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:23:51 visual_prompt]: Epoch 6 / 100: avg data time: 5.36e-02, avg batch time: 0.5016, average train loss: 3.0431
[09/26 11:23:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 3.1934
[09/26 11:23:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 2.50	top5: 27.50	
[09/26 11:23:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:24:00 visual_prompt]: Epoch 7 / 100: avg data time: 6.80e-02, avg batch time: 0.5152, average train loss: 3.1089
[09/26 11:24:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 3.0597
[09/26 11:24:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.50	
[09/26 11:24:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:24:08 visual_prompt]: Epoch 8 / 100: avg data time: 5.88e-02, avg batch time: 0.5074, average train loss: 3.1592
[09/26 11:24:10 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 3.1268
[09/26 11:24:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 26.50	
[09/26 11:24:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:24:16 visual_prompt]: Epoch 9 / 100: avg data time: 5.61e-02, avg batch time: 0.5036, average train loss: 3.0875
[09/26 11:24:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 3.0364
[09/26 11:24:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 29.00	
[09/26 11:24:18 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:24:25 visual_prompt]: Epoch 10 / 100: avg data time: 6.45e-02, avg batch time: 0.5115, average train loss: 3.0336
[09/26 11:24:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1687, average loss: 3.0627
[09/26 11:24:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 11:24:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:24:33 visual_prompt]: Epoch 11 / 100: avg data time: 5.42e-02, avg batch time: 0.5035, average train loss: 3.1205
[09/26 11:24:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1690, average loss: 3.1774
[09/26 11:24:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 11:24:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:24:42 visual_prompt]: Epoch 12 / 100: avg data time: 5.85e-02, avg batch time: 0.5065, average train loss: 3.0955
[09/26 11:24:43 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1690, average loss: 3.1814
[09/26 11:24:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 11:24:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:24:50 visual_prompt]: Epoch 13 / 100: avg data time: 5.64e-02, avg batch time: 0.5052, average train loss: 3.1410
[09/26 11:24:52 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.3262, average loss: 3.1651
[09/26 11:24:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 11:24:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:24:59 visual_prompt]: Epoch 14 / 100: avg data time: 6.92e-02, avg batch time: 0.5158, average train loss: 3.1756
[09/26 11:25:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 3.1451
[09/26 11:25:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 11:25:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:25:08 visual_prompt]: Epoch 15 / 100: avg data time: 6.23e-02, avg batch time: 0.5091, average train loss: 3.0663
[09/26 11:25:10 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1688, average loss: 2.9770
[09/26 11:25:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 11:25:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:25:16 visual_prompt]: Epoch 16 / 100: avg data time: 6.33e-02, avg batch time: 0.5118, average train loss: 3.0400
[09/26 11:25:18 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1689, average loss: 3.1128
[09/26 11:25:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 11:25:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:25:25 visual_prompt]: Epoch 17 / 100: avg data time: 6.76e-02, avg batch time: 0.5151, average train loss: 3.0774
[09/26 11:25:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1689, average loss: 3.0298
[09/26 11:25:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 11:25:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:25:34 visual_prompt]: Epoch 18 / 100: avg data time: 7.07e-02, avg batch time: 0.5168, average train loss: 3.0339
[09/26 11:25:36 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1687, average loss: 3.0301
[09/26 11:25:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 11:25:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:25:43 visual_prompt]: Epoch 19 / 100: avg data time: 6.53e-02, avg batch time: 0.5126, average train loss: 3.0697
[09/26 11:25:44 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1688, average loss: 3.0890
[09/26 11:25:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 11:25:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:25:51 visual_prompt]: Epoch 20 / 100: avg data time: 6.67e-02, avg batch time: 0.5137, average train loss: 3.0612
[09/26 11:25:53 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1686, average loss: 3.3704
[09/26 11:25:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 11:25:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:26:00 visual_prompt]: Epoch 21 / 100: avg data time: 6.46e-02, avg batch time: 0.5110, average train loss: 3.2355
[09/26 11:26:01 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1689, average loss: 3.0888
[09/26 11:26:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 11:26:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:26:08 visual_prompt]: Epoch 22 / 100: avg data time: 4.91e-02, avg batch time: 0.4984, average train loss: 3.0752
[09/26 11:26:10 visual_prompt]: Inference (val):avg data time: 5.50e-05, avg batch time: 0.1703, average loss: 3.1526
[09/26 11:26:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 11:26:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:26:17 visual_prompt]: Epoch 23 / 100: avg data time: 6.38e-02, avg batch time: 0.5106, average train loss: 3.1375
[09/26 11:26:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1688, average loss: 3.2073
[09/26 11:26:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.50	
[09/26 11:26:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:26:25 visual_prompt]: Epoch 24 / 100: avg data time: 5.86e-02, avg batch time: 0.5056, average train loss: 3.0743
[09/26 11:26:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1688, average loss: 3.0562
[09/26 11:26:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:26:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:26:34 visual_prompt]: Epoch 25 / 100: avg data time: 6.25e-02, avg batch time: 0.5092, average train loss: 3.0413
[09/26 11:26:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1687, average loss: 3.1601
[09/26 11:26:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 11:26:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:26:42 visual_prompt]: Epoch 26 / 100: avg data time: 6.28e-02, avg batch time: 0.5108, average train loss: 3.0104
[09/26 11:26:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1689, average loss: 3.0027
[09/26 11:26:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 11:26:44 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:26:51 visual_prompt]: Epoch 27 / 100: avg data time: 5.33e-02, avg batch time: 0.5026, average train loss: 3.0212
[09/26 11:26:52 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1690, average loss: 3.1960
[09/26 11:26:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 11:26:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:26:59 visual_prompt]: Epoch 28 / 100: avg data time: 6.67e-02, avg batch time: 0.5140, average train loss: 3.0382
[09/26 11:27:01 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1686, average loss: 2.9558
[09/26 11:27:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 11:27:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:27:08 visual_prompt]: Epoch 29 / 100: avg data time: 6.45e-02, avg batch time: 0.5123, average train loss: 3.0236
[09/26 11:27:10 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1691, average loss: 3.0289
[09/26 11:27:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 25.50	
[09/26 11:27:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:27:17 visual_prompt]: Epoch 30 / 100: avg data time: 6.84e-02, avg batch time: 0.5154, average train loss: 3.0598
[09/26 11:27:18 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1685, average loss: 3.0837
[09/26 11:27:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 11:27:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:27:25 visual_prompt]: Epoch 31 / 100: avg data time: 7.18e-02, avg batch time: 0.5183, average train loss: 3.0187
[09/26 11:27:27 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1686, average loss: 2.9884
[09/26 11:27:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 11:27:27 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:27:34 visual_prompt]: Epoch 32 / 100: avg data time: 7.41e-02, avg batch time: 0.5202, average train loss: 2.9695
[09/26 11:27:36 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1685, average loss: 3.0431
[09/26 11:27:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 11:27:36 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:27:43 visual_prompt]: Epoch 33 / 100: avg data time: 6.57e-02, avg batch time: 0.5125, average train loss: 3.0074
[09/26 11:27:44 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 2.9632
[09/26 11:27:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 11:27:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:27:51 visual_prompt]: Epoch 34 / 100: avg data time: 6.91e-02, avg batch time: 0.5153, average train loss: 3.0063
[09/26 11:27:53 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1685, average loss: 2.9961
[09/26 11:27:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 11:27:53 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:28:00 visual_prompt]: Epoch 35 / 100: avg data time: 5.21e-02, avg batch time: 0.4984, average train loss: 2.9847
[09/26 11:28:01 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1684, average loss: 2.9360
[09/26 11:28:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 11:28:01 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:28:08 visual_prompt]: Epoch 36 / 100: avg data time: 7.44e-02, avg batch time: 0.5206, average train loss: 2.9935
[09/26 11:28:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1682, average loss: 2.9267
[09/26 11:28:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 11:28:10 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:28:17 visual_prompt]: Epoch 37 / 100: avg data time: 6.83e-02, avg batch time: 0.5144, average train loss: 2.9952
[09/26 11:28:18 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1688, average loss: 3.0777
[09/26 11:28:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 11:28:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:28:25 visual_prompt]: Epoch 38 / 100: avg data time: 6.02e-02, avg batch time: 0.5072, average train loss: 2.9720
[09/26 11:28:27 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1686, average loss: 3.0468
[09/26 11:28:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 11:28:27 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:28:34 visual_prompt]: Epoch 39 / 100: avg data time: 5.17e-02, avg batch time: 0.5000, average train loss: 3.0029
[09/26 11:28:35 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1687, average loss: 2.9504
[09/26 11:28:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 11:28:35 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:28:42 visual_prompt]: Epoch 40 / 100: avg data time: 4.64e-02, avg batch time: 0.4941, average train loss: 2.9701
[09/26 11:28:44 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1690, average loss: 3.0129
[09/26 11:28:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 11:28:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:28:50 visual_prompt]: Epoch 41 / 100: avg data time: 4.91e-02, avg batch time: 0.4968, average train loss: 2.9838
[09/26 11:28:52 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 2.9713
[09/26 11:28:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 11:28:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:28:59 visual_prompt]: Epoch 42 / 100: avg data time: 6.19e-02, avg batch time: 0.5084, average train loss: 2.9788
[09/26 11:29:00 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1686, average loss: 2.9949
[09/26 11:29:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 11:29:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:29:07 visual_prompt]: Epoch 43 / 100: avg data time: 4.68e-02, avg batch time: 0.4936, average train loss: 2.9899
[09/26 11:29:09 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1688, average loss: 3.0138
[09/26 11:29:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 11:29:09 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:29:15 visual_prompt]: Epoch 44 / 100: avg data time: 4.91e-02, avg batch time: 0.4956, average train loss: 3.0127
[09/26 11:29:17 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1690, average loss: 3.0165
[09/26 11:29:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 11:29:17 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:29:24 visual_prompt]: Epoch 45 / 100: avg data time: 6.03e-02, avg batch time: 0.5102, average train loss: 2.9959
[09/26 11:29:25 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 2.9652
[09/26 11:29:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 11:29:25 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:29:32 visual_prompt]: Epoch 46 / 100: avg data time: 6.10e-02, avg batch time: 0.5080, average train loss: 2.9630
[09/26 11:29:34 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 3.0063
[09/26 11:29:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 11:29:34 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:29:41 visual_prompt]: Epoch 47 / 100: avg data time: 5.62e-02, avg batch time: 0.5035, average train loss: 3.0051
[09/26 11:29:42 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1687, average loss: 3.0362
[09/26 11:29:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 11:29:42 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:29:49 visual_prompt]: Epoch 48 / 100: avg data time: 6.80e-02, avg batch time: 0.5144, average train loss: 2.9720
[09/26 11:29:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1688, average loss: 2.9748
[09/26 11:29:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 11:29:51 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:29:58 visual_prompt]: Epoch 49 / 100: avg data time: 4.60e-02, avg batch time: 0.4936, average train loss: 2.9838
[09/26 11:29:59 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1686, average loss: 2.9834
[09/26 11:29:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 11:29:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:30:06 visual_prompt]: Epoch 50 / 100: avg data time: 6.32e-02, avg batch time: 0.5102, average train loss: 2.9626
[09/26 11:30:08 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1684, average loss: 2.9628
[09/26 11:30:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 11:30:08 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:30:14 visual_prompt]: Epoch 51 / 100: avg data time: 5.59e-02, avg batch time: 0.5030, average train loss: 2.9570
[09/26 11:30:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 3.0037
[09/26 11:30:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 11:30:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:30:23 visual_prompt]: Epoch 52 / 100: avg data time: 7.49e-02, avg batch time: 0.5224, average train loss: 2.9838
[09/26 11:30:25 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 3.0183
[09/26 11:30:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 11:30:25 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:30:31 visual_prompt]: Epoch 53 / 100: avg data time: 4.38e-02, avg batch time: 0.4929, average train loss: 2.9740
[09/26 11:30:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1686, average loss: 2.9205
[09/26 11:30:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 34.50	
[09/26 11:30:33 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:30:40 visual_prompt]: Epoch 54 / 100: avg data time: 5.55e-02, avg batch time: 0.5029, average train loss: 2.9634
[09/26 11:30:41 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1685, average loss: 2.9589
[09/26 11:30:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 11:30:41 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:30:48 visual_prompt]: Epoch 55 / 100: avg data time: 4.37e-02, avg batch time: 0.4923, average train loss: 2.9692
[09/26 11:30:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 2.9807
[09/26 11:30:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 11:30:49 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:30:56 visual_prompt]: Epoch 56 / 100: avg data time: 5.80e-02, avg batch time: 0.5048, average train loss: 2.9656
[09/26 11:30:58 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1687, average loss: 2.9564
[09/26 11:30:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 11:30:58 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:31:04 visual_prompt]: Epoch 57 / 100: avg data time: 4.84e-02, avg batch time: 0.4977, average train loss: 2.9489
[09/26 11:31:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1686, average loss: 3.0212
[09/26 11:31:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 11:31:06 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:31:13 visual_prompt]: Epoch 58 / 100: avg data time: 5.14e-02, avg batch time: 0.4988, average train loss: 2.9502
[09/26 11:31:14 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1687, average loss: 2.9788
[09/26 11:31:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 11:31:14 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:31:21 visual_prompt]: Epoch 59 / 100: avg data time: 5.18e-02, avg batch time: 0.5000, average train loss: 2.9452
[09/26 11:31:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1689, average loss: 2.9712
[09/26 11:31:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 11:31:23 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:31:29 visual_prompt]: Epoch 60 / 100: avg data time: 5.51e-02, avg batch time: 0.5025, average train loss: 2.9470
[09/26 11:31:31 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 2.9727
[09/26 11:31:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 11:31:31 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:31:38 visual_prompt]: Epoch 61 / 100: avg data time: 5.07e-02, avg batch time: 0.4998, average train loss: 2.9321
[09/26 11:31:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 2.9317
[09/26 11:31:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 11:31:39 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 11:31:46 visual_prompt]: Epoch 62 / 100: avg data time: 6.18e-02, avg batch time: 0.5103, average train loss: 2.9188
[09/26 11:31:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1688, average loss: 2.9805
[09/26 11:31:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 11:31:48 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 11:31:55 visual_prompt]: Epoch 63 / 100: avg data time: 6.51e-02, avg batch time: 0.5136, average train loss: 2.9676
[09/26 11:31:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1688, average loss: 2.9902
[09/26 11:31:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 11:31:57 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 11:32:03 visual_prompt]: Epoch 64 / 100: avg data time: 6.73e-02, avg batch time: 0.5151, average train loss: 2.9473
[09/26 11:32:05 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1694, average loss: 3.0131
[09/26 11:32:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 11:32:05 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 11:32:12 visual_prompt]: Epoch 65 / 100: avg data time: 6.88e-02, avg batch time: 0.5162, average train loss: 2.9266
[09/26 11:32:14 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1699, average loss: 2.9130
[09/26 11:32:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 11:32:14 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 11:32:20 visual_prompt]: Epoch 66 / 100: avg data time: 4.73e-02, avg batch time: 0.4968, average train loss: 2.9599
[09/26 11:32:22 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1688, average loss: 2.9458
[09/26 11:32:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 11:32:22 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 11:32:29 visual_prompt]: Epoch 67 / 100: avg data time: 5.74e-02, avg batch time: 0.5062, average train loss: 2.9271
[09/26 11:32:31 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 2.9599
[09/26 11:32:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.50	
[09/26 11:32:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 11:32:38 visual_prompt]: Epoch 68 / 100: avg data time: 6.62e-02, avg batch time: 0.5145, average train loss: 2.9306
[09/26 11:32:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 2.9751
[09/26 11:32:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 11:32:39 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 11:32:46 visual_prompt]: Epoch 69 / 100: avg data time: 5.85e-02, avg batch time: 0.5065, average train loss: 2.9268
[09/26 11:32:48 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1689, average loss: 2.9171
[09/26 11:32:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 11:32:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 11:32:55 visual_prompt]: Epoch 70 / 100: avg data time: 6.24e-02, avg batch time: 0.5098, average train loss: 2.9228
[09/26 11:32:56 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 2.9491
[09/26 11:32:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 11:32:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 11:33:03 visual_prompt]: Epoch 71 / 100: avg data time: 6.54e-02, avg batch time: 0.5137, average train loss: 2.9266
[09/26 11:33:05 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1687, average loss: 2.9351
[09/26 11:33:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 11:33:05 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 11:33:12 visual_prompt]: Epoch 72 / 100: avg data time: 5.09e-02, avg batch time: 0.5017, average train loss: 2.9169
[09/26 11:33:13 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 2.9358
[09/26 11:33:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 24.50	
[09/26 11:33:13 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 11:33:20 visual_prompt]: Epoch 73 / 100: avg data time: 5.91e-02, avg batch time: 0.5068, average train loss: 2.9262
[09/26 11:33:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1687, average loss: 2.9110
[09/26 11:33:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 11:33:22 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 11:33:29 visual_prompt]: Epoch 74 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 2.9359
[09/26 11:33:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 2.9591
[09/26 11:33:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 11:33:30 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 11:33:37 visual_prompt]: Epoch 75 / 100: avg data time: 5.95e-02, avg batch time: 0.5068, average train loss: 2.9278
[09/26 11:33:39 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1687, average loss: 2.9006
[09/26 11:33:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 11:33:39 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 11:33:46 visual_prompt]: Epoch 76 / 100: avg data time: 5.89e-02, avg batch time: 0.5095, average train loss: 2.9182
[09/26 11:33:47 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1687, average loss: 2.9297
[09/26 11:33:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:33:47 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 11:33:54 visual_prompt]: Epoch 77 / 100: avg data time: 5.72e-02, avg batch time: 0.5054, average train loss: 2.9151
[09/26 11:33:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1685, average loss: 2.8923
[09/26 11:33:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 11:33:56 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 11:34:02 visual_prompt]: Epoch 78 / 100: avg data time: 5.41e-02, avg batch time: 0.5026, average train loss: 2.9045
[09/26 11:34:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 2.9394
[09/26 11:34:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 11:34:04 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 11:34:11 visual_prompt]: Epoch 79 / 100: avg data time: 5.84e-02, avg batch time: 0.5068, average train loss: 2.9030
[09/26 11:34:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1688, average loss: 2.8967
[09/26 11:34:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 11:34:13 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 11:34:19 visual_prompt]: Epoch 80 / 100: avg data time: 5.13e-02, avg batch time: 0.4988, average train loss: 2.9027
[09/26 11:34:21 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 2.9104
[09/26 11:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 11:34:21 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 11:34:28 visual_prompt]: Epoch 81 / 100: avg data time: 6.39e-02, avg batch time: 0.5109, average train loss: 2.8922
[09/26 11:34:29 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1689, average loss: 2.8994
[09/26 11:34:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 29.50	
[09/26 11:34:29 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 11:34:36 visual_prompt]: Epoch 82 / 100: avg data time: 6.45e-02, avg batch time: 0.5125, average train loss: 2.9000
[09/26 11:34:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1689, average loss: 2.9128
[09/26 11:34:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 11:34:38 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 11:34:45 visual_prompt]: Epoch 83 / 100: avg data time: 5.47e-02, avg batch time: 0.5028, average train loss: 2.8937
[09/26 11:34:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1689, average loss: 2.9047
[09/26 11:34:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 11:34:46 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:34:53 visual_prompt]: Epoch 84 / 100: avg data time: 5.46e-02, avg batch time: 0.5041, average train loss: 2.8797
[09/26 11:34:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 2.9138
[09/26 11:34:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.00	
[09/26 11:34:55 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:35:02 visual_prompt]: Epoch 85 / 100: avg data time: 5.42e-02, avg batch time: 0.5028, average train loss: 2.8783
[09/26 11:35:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 2.8900
[09/26 11:35:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 11:35:03 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:35:10 visual_prompt]: Epoch 86 / 100: avg data time: 6.00e-02, avg batch time: 0.5092, average train loss: 2.8737
[09/26 11:35:11 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1691, average loss: 2.8850
[09/26 11:35:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.00	
[09/26 11:35:11 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:35:18 visual_prompt]: Epoch 87 / 100: avg data time: 5.95e-02, avg batch time: 0.5071, average train loss: 2.8771
[09/26 11:35:20 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1687, average loss: 2.9006
[09/26 11:35:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 11:35:20 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:35:27 visual_prompt]: Epoch 88 / 100: avg data time: 5.23e-02, avg batch time: 0.5002, average train loss: 2.8736
[09/26 11:35:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1687, average loss: 2.9034
[09/26 11:35:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 11:35:28 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:35:35 visual_prompt]: Epoch 89 / 100: avg data time: 6.30e-02, avg batch time: 0.5113, average train loss: 2.8693
[09/26 11:35:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 2.9255
[09/26 11:35:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 11:35:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:35:43 visual_prompt]: Epoch 90 / 100: avg data time: 4.64e-02, avg batch time: 0.4964, average train loss: 2.8672
[09/26 11:35:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1689, average loss: 2.8971
[09/26 11:35:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 11:35:45 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:35:52 visual_prompt]: Epoch 91 / 100: avg data time: 6.84e-02, avg batch time: 0.5159, average train loss: 2.8654
[09/26 11:35:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1687, average loss: 2.9041
[09/26 11:35:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 31.00	
[09/26 11:35:54 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:36:00 visual_prompt]: Epoch 92 / 100: avg data time: 5.52e-02, avg batch time: 0.5052, average train loss: 2.8653
[09/26 11:36:02 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1689, average loss: 2.9069
[09/26 11:36:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.00	
[09/26 11:36:02 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:36:09 visual_prompt]: Epoch 93 / 100: avg data time: 6.12e-02, avg batch time: 0.5103, average train loss: 2.8617
[09/26 11:36:11 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1687, average loss: 2.9077
[09/26 11:36:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 30.50	
[09/26 11:36:11 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:36:17 visual_prompt]: Epoch 94 / 100: avg data time: 4.60e-02, avg batch time: 0.4962, average train loss: 2.8596
[09/26 11:36:19 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 2.9327
[09/26 11:36:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 11:36:19 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:36:26 visual_prompt]: Epoch 95 / 100: avg data time: 5.43e-02, avg batch time: 0.5038, average train loss: 2.8630
[09/26 11:36:28 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1689, average loss: 2.9271
[09/26 11:36:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.50	
[09/26 11:36:28 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:36:35 visual_prompt]: Epoch 96 / 100: avg data time: 5.83e-02, avg batch time: 0.5059, average train loss: 2.8579
[09/26 11:36:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 2.9126
[09/26 11:36:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 11:36:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:36:44 visual_prompt]: Epoch 97 / 100: avg data time: 6.42e-02, avg batch time: 0.5123, average train loss: 2.8578
[09/26 11:36:45 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 2.9171
[09/26 11:36:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 11:36:45 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:36:52 visual_prompt]: Epoch 98 / 100: avg data time: 5.30e-02, avg batch time: 0.5015, average train loss: 2.8564
[09/26 11:36:53 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 2.9159
[09/26 11:36:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 11:36:53 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:37:00 visual_prompt]: Epoch 99 / 100: avg data time: 5.60e-02, avg batch time: 0.5041, average train loss: 2.8567
[09/26 11:37:02 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1692, average loss: 2.9206
[09/26 11:37:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:37:02 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:37:09 visual_prompt]: Epoch 100 / 100: avg data time: 6.31e-02, avg batch time: 0.5105, average train loss: 2.8553
[09/26 11:37:11 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1689, average loss: 2.9206
[09/26 11:37:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 11:37:11 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:37:11 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:37:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:37:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:37:11 visual_prompt]: Training with config:
[09/26 11:37:11 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:37:11 visual_prompt]: Loading training data...
[09/26 11:37:11 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:37:12 visual_prompt]: Number of images: 800
[09/26 11:37:12 visual_prompt]: Number of classes: 18 / 18
[09/26 11:37:12 visual_prompt]: Loading validation data...
[09/26 11:37:12 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:37:12 visual_prompt]: Number of images: 200
[09/26 11:37:12 visual_prompt]: Number of classes: 18 / 18
[09/26 11:37:12 visual_prompt]: Constructing models...
[09/26 11:37:15 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 11:37:15 visual_prompt]: tuned percent:0.550
[09/26 11:37:15 visual_prompt]: Device used for model: 0
[09/26 11:37:15 visual_prompt]: Setting up Evaluator...
[09/26 11:37:15 visual_prompt]: Setting up Trainer...
[09/26 11:37:15 visual_prompt]: 	Setting up the optimizer...
[09/26 11:37:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:37:22 visual_prompt]: Epoch 1 / 100: avg data time: 6.02e-02, avg batch time: 0.5065, average train loss: 3.2552
[09/26 11:37:23 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1684, average loss: 3.1895
[09/26 11:37:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 11:37:23 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 11:37:23 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:37:30 visual_prompt]: Epoch 2 / 100: avg data time: 6.32e-02, avg batch time: 0.5105, average train loss: 3.2738
[09/26 11:37:32 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1684, average loss: 3.1871
[09/26 11:37:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 11:37:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:37:39 visual_prompt]: Epoch 3 / 100: avg data time: 5.83e-02, avg batch time: 0.5045, average train loss: 3.1026
[09/26 11:37:40 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1686, average loss: 3.0755
[09/26 11:37:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 11:37:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:37:47 visual_prompt]: Epoch 4 / 100: avg data time: 6.23e-02, avg batch time: 0.5108, average train loss: 3.0698
[09/26 11:37:49 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1690, average loss: 3.0073
[09/26 11:37:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 11:37:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:37:56 visual_prompt]: Epoch 5 / 100: avg data time: 6.17e-02, avg batch time: 0.5103, average train loss: 2.9625
[09/26 11:37:57 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1689, average loss: 3.0060
[09/26 11:37:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 11:37:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:38:04 visual_prompt]: Epoch 6 / 100: avg data time: 5.93e-02, avg batch time: 0.5061, average train loss: 2.9948
[09/26 11:38:06 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 3.0458
[09/26 11:38:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 11:38:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:38:13 visual_prompt]: Epoch 7 / 100: avg data time: 6.76e-02, avg batch time: 0.5145, average train loss: 3.0675
[09/26 11:38:15 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 3.2111
[09/26 11:38:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 11:38:15 visual_prompt]: Best epoch 7: best metric: 0.070
[09/26 11:38:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:38:22 visual_prompt]: Epoch 8 / 100: avg data time: 6.60e-02, avg batch time: 0.5138, average train loss: 3.1601
[09/26 11:38:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1686, average loss: 3.1816
[09/26 11:38:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 11:38:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:38:30 visual_prompt]: Epoch 9 / 100: avg data time: 6.30e-02, avg batch time: 0.5112, average train loss: 3.1643
[09/26 11:38:32 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1690, average loss: 3.2143
[09/26 11:38:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 11:38:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:38:39 visual_prompt]: Epoch 10 / 100: avg data time: 6.05e-02, avg batch time: 0.5079, average train loss: 3.3082
[09/26 11:38:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1687, average loss: 3.2186
[09/26 11:38:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 11:38:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:38:47 visual_prompt]: Epoch 11 / 100: avg data time: 5.42e-02, avg batch time: 0.5021, average train loss: 3.3017
[09/26 11:38:49 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 3.1990
[09/26 11:38:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 11:38:49 visual_prompt]: Best epoch 11: best metric: 0.085
[09/26 11:38:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:38:56 visual_prompt]: Epoch 12 / 100: avg data time: 6.01e-02, avg batch time: 0.5095, average train loss: 3.2364
[09/26 11:38:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1689, average loss: 3.2634
[09/26 11:38:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 11:38:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:39:04 visual_prompt]: Epoch 13 / 100: avg data time: 5.36e-02, avg batch time: 0.5030, average train loss: 3.1335
[09/26 11:39:06 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 3.0337
[09/26 11:39:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 32.00	
[09/26 11:39:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:39:13 visual_prompt]: Epoch 14 / 100: avg data time: 5.80e-02, avg batch time: 0.5063, average train loss: 3.1266
[09/26 11:39:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 3.0469
[09/26 11:39:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 35.00	
[09/26 11:39:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:39:21 visual_prompt]: Epoch 15 / 100: avg data time: 4.54e-02, avg batch time: 0.4963, average train loss: 3.0030
[09/26 11:39:23 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1693, average loss: 3.2715
[09/26 11:39:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 33.50	
[09/26 11:39:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:39:29 visual_prompt]: Epoch 16 / 100: avg data time: 4.57e-02, avg batch time: 0.4954, average train loss: 3.0191
[09/26 11:39:31 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1693, average loss: 2.8964
[09/26 11:39:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 42.00	
[09/26 11:39:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:39:38 visual_prompt]: Epoch 17 / 100: avg data time: 4.79e-02, avg batch time: 0.4970, average train loss: 2.9565
[09/26 11:39:39 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1692, average loss: 2.9184
[09/26 11:39:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 41.00	
[09/26 11:39:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:39:46 visual_prompt]: Epoch 18 / 100: avg data time: 5.34e-02, avg batch time: 0.5013, average train loss: 2.7701
[09/26 11:39:48 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 3.4074
[09/26 11:39:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 11:39:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:39:54 visual_prompt]: Epoch 19 / 100: avg data time: 4.33e-02, avg batch time: 0.4938, average train loss: 3.1851
[09/26 11:39:56 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1688, average loss: 3.1922
[09/26 11:39:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 11:39:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:40:03 visual_prompt]: Epoch 20 / 100: avg data time: 4.28e-02, avg batch time: 0.4923, average train loss: 3.1482
[09/26 11:40:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1687, average loss: 3.4759
[09/26 11:40:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.50	
[09/26 11:40:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:40:11 visual_prompt]: Epoch 21 / 100: avg data time: 4.31e-02, avg batch time: 0.4929, average train loss: 3.1467
[09/26 11:40:12 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 3.0937
[09/26 11:40:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 11:40:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:40:19 visual_prompt]: Epoch 22 / 100: avg data time: 4.83e-02, avg batch time: 0.4972, average train loss: 2.9862
[09/26 11:40:21 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 3.0076
[09/26 11:40:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 38.00	
[09/26 11:40:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:40:28 visual_prompt]: Epoch 23 / 100: avg data time: 4.64e-02, avg batch time: 0.4944, average train loss: 2.8868
[09/26 11:40:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 3.1310
[09/26 11:40:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 32.50	
[09/26 11:40:29 visual_prompt]: Best epoch 23: best metric: 0.095
[09/26 11:40:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:40:36 visual_prompt]: Epoch 24 / 100: avg data time: 6.16e-02, avg batch time: 0.5104, average train loss: 2.8928
[09/26 11:40:38 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 2.9956
[09/26 11:40:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 40.00	
[09/26 11:40:38 visual_prompt]: Best epoch 24: best metric: 0.120
[09/26 11:40:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:40:44 visual_prompt]: Epoch 25 / 100: avg data time: 4.60e-02, avg batch time: 0.4981, average train loss: 2.7789
[09/26 11:40:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 2.9836
[09/26 11:40:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 50.50	
[09/26 11:40:46 visual_prompt]: Best epoch 25: best metric: 0.165
[09/26 11:40:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:40:53 visual_prompt]: Epoch 26 / 100: avg data time: 5.73e-02, avg batch time: 0.5061, average train loss: 2.5765
[09/26 11:40:54 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1691, average loss: 2.7019
[09/26 11:40:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 53.00	
[09/26 11:40:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:41:01 visual_prompt]: Epoch 27 / 100: avg data time: 4.44e-02, avg batch time: 0.4950, average train loss: 2.3926
[09/26 11:41:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1695, average loss: 2.8232
[09/26 11:41:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 56.00	
[09/26 11:41:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:41:10 visual_prompt]: Epoch 28 / 100: avg data time: 6.47e-02, avg batch time: 0.5146, average train loss: 2.3686
[09/26 11:41:11 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1690, average loss: 2.9546
[09/26 11:41:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 50.50	
[09/26 11:41:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:41:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.64e-02, avg batch time: 0.5055, average train loss: 2.3754
[09/26 11:41:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1692, average loss: 2.7375
[09/26 11:41:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 11:41:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:41:27 visual_prompt]: Epoch 30 / 100: avg data time: 6.11e-02, avg batch time: 0.5117, average train loss: 2.1155
[09/26 11:41:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 2.7795
[09/26 11:41:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.00	
[09/26 11:41:28 visual_prompt]: Best epoch 30: best metric: 0.175
[09/26 11:41:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:41:35 visual_prompt]: Epoch 31 / 100: avg data time: 5.75e-02, avg batch time: 0.5074, average train loss: 2.0320
[09/26 11:41:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 2.8250
[09/26 11:41:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 56.50	
[09/26 11:41:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:41:44 visual_prompt]: Epoch 32 / 100: avg data time: 6.11e-02, avg batch time: 0.5110, average train loss: 1.9363
[09/26 11:41:45 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 3.0636
[09/26 11:41:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.50	
[09/26 11:41:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:41:52 visual_prompt]: Epoch 33 / 100: avg data time: 4.66e-02, avg batch time: 0.4948, average train loss: 1.6410
[09/26 11:41:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 3.3785
[09/26 11:41:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.00	
[09/26 11:41:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:42:00 visual_prompt]: Epoch 34 / 100: avg data time: 5.31e-02, avg batch time: 0.5022, average train loss: 1.5385
[09/26 11:42:02 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 2.8488
[09/26 11:42:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 11:42:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:42:09 visual_prompt]: Epoch 35 / 100: avg data time: 6.00e-02, avg batch time: 0.5084, average train loss: 1.2618
[09/26 11:42:11 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1691, average loss: 3.4013
[09/26 11:42:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 11:42:11 visual_prompt]: Best epoch 35: best metric: 0.195
[09/26 11:42:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:42:17 visual_prompt]: Epoch 36 / 100: avg data time: 5.48e-02, avg batch time: 0.5033, average train loss: 1.1349
[09/26 11:42:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1690, average loss: 3.3887
[09/26 11:42:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 11:42:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:42:26 visual_prompt]: Epoch 37 / 100: avg data time: 6.19e-02, avg batch time: 0.5100, average train loss: 1.0198
[09/26 11:42:27 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 4.1542
[09/26 11:42:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 58.50	
[09/26 11:42:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:42:34 visual_prompt]: Epoch 38 / 100: avg data time: 5.85e-02, avg batch time: 0.5082, average train loss: 1.0920
[09/26 11:42:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1693, average loss: 3.2791
[09/26 11:42:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 11:42:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:42:43 visual_prompt]: Epoch 39 / 100: avg data time: 5.96e-02, avg batch time: 0.5090, average train loss: 0.9735
[09/26 11:42:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1695, average loss: 4.2719
[09/26 11:42:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 66.00	
[09/26 11:42:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:42:51 visual_prompt]: Epoch 40 / 100: avg data time: 5.42e-02, avg batch time: 0.5037, average train loss: 0.9050
[09/26 11:42:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1692, average loss: 3.9724
[09/26 11:42:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.50	
[09/26 11:42:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:43:00 visual_prompt]: Epoch 41 / 100: avg data time: 6.06e-02, avg batch time: 0.5100, average train loss: 0.7121
[09/26 11:43:01 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 4.5811
[09/26 11:43:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 11:43:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:43:08 visual_prompt]: Epoch 42 / 100: avg data time: 5.36e-02, avg batch time: 0.5027, average train loss: 0.4730
[09/26 11:43:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1693, average loss: 5.8625
[09/26 11:43:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 66.50	
[09/26 11:43:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:43:16 visual_prompt]: Epoch 43 / 100: avg data time: 4.54e-02, avg batch time: 0.4962, average train loss: 0.6673
[09/26 11:43:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1689, average loss: 4.5782
[09/26 11:43:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.00	
[09/26 11:43:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:43:25 visual_prompt]: Epoch 44 / 100: avg data time: 4.89e-02, avg batch time: 0.5001, average train loss: 0.6783
[09/26 11:43:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1691, average loss: 4.7720
[09/26 11:43:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 62.50	
[09/26 11:43:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:43:33 visual_prompt]: Epoch 45 / 100: avg data time: 4.83e-02, avg batch time: 0.4971, average train loss: 0.4845
[09/26 11:43:34 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1689, average loss: 5.2043
[09/26 11:43:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 68.00	
[09/26 11:43:34 visual_prompt]: Best epoch 45: best metric: 0.215
[09/26 11:43:34 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:43:41 visual_prompt]: Epoch 46 / 100: avg data time: 5.85e-02, avg batch time: 0.5073, average train loss: 0.5022
[09/26 11:43:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1694, average loss: 5.1185
[09/26 11:43:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.50	
[09/26 11:43:43 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:43:50 visual_prompt]: Epoch 47 / 100: avg data time: 5.67e-02, avg batch time: 0.5056, average train loss: 0.3818
[09/26 11:43:51 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1694, average loss: 5.2074
[09/26 11:43:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.50	
[09/26 11:43:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:43:58 visual_prompt]: Epoch 48 / 100: avg data time: 5.88e-02, avg batch time: 0.5071, average train loss: 0.2792
[09/26 11:44:00 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1692, average loss: 5.9061
[09/26 11:44:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 11:44:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:44:07 visual_prompt]: Epoch 49 / 100: avg data time: 6.36e-02, avg batch time: 0.5121, average train loss: 0.2611
[09/26 11:44:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1690, average loss: 6.1774
[09/26 11:44:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 65.50	
[09/26 11:44:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:44:15 visual_prompt]: Epoch 50 / 100: avg data time: 5.68e-02, avg batch time: 0.5064, average train loss: 0.2251
[09/26 11:44:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1694, average loss: 6.7356
[09/26 11:44:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 11:44:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:44:24 visual_prompt]: Epoch 51 / 100: avg data time: 6.01e-02, avg batch time: 0.5093, average train loss: 0.1606
[09/26 11:44:25 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1695, average loss: 6.3189
[09/26 11:44:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.00	
[09/26 11:44:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:44:32 visual_prompt]: Epoch 52 / 100: avg data time: 5.22e-02, avg batch time: 0.5026, average train loss: 0.2403
[09/26 11:44:34 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1697, average loss: 6.7908
[09/26 11:44:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 60.50	
[09/26 11:44:34 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:44:40 visual_prompt]: Epoch 53 / 100: avg data time: 6.13e-02, avg batch time: 0.5102, average train loss: 0.2586
[09/26 11:44:42 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1697, average loss: 5.6883
[09/26 11:44:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 11:44:42 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:44:49 visual_prompt]: Epoch 54 / 100: avg data time: 6.69e-02, avg batch time: 0.5159, average train loss: 0.1447
[09/26 11:44:51 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 6.0748
[09/26 11:44:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.50	
[09/26 11:44:51 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:44:58 visual_prompt]: Epoch 55 / 100: avg data time: 6.28e-02, avg batch time: 0.5126, average train loss: 0.0893
[09/26 11:44:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 6.2998
[09/26 11:44:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 64.50	
[09/26 11:44:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:45:06 visual_prompt]: Epoch 56 / 100: avg data time: 5.85e-02, avg batch time: 0.5086, average train loss: 0.0883
[09/26 11:45:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 6.4566
[09/26 11:45:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 11:45:08 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:45:15 visual_prompt]: Epoch 57 / 100: avg data time: 6.38e-02, avg batch time: 0.5120, average train loss: 0.0424
[09/26 11:45:17 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 6.6202
[09/26 11:45:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 11:45:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:45:23 visual_prompt]: Epoch 58 / 100: avg data time: 5.73e-02, avg batch time: 0.5065, average train loss: 0.0423
[09/26 11:45:25 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 5.9586
[09/26 11:45:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 11:45:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:45:32 visual_prompt]: Epoch 59 / 100: avg data time: 6.05e-02, avg batch time: 0.5118, average train loss: 0.0260
[09/26 11:45:33 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1694, average loss: 5.9720
[09/26 11:45:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 11:45:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:45:40 visual_prompt]: Epoch 60 / 100: avg data time: 5.51e-02, avg batch time: 0.5036, average train loss: 0.0159
[09/26 11:45:42 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1691, average loss: 5.9219
[09/26 11:45:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 62.00	
[09/26 11:45:42 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:45:49 visual_prompt]: Epoch 61 / 100: avg data time: 5.37e-02, avg batch time: 0.5036, average train loss: 0.0152
[09/26 11:45:50 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 5.8743
[09/26 11:45:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 11:45:50 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 11:45:57 visual_prompt]: Epoch 62 / 100: avg data time: 5.94e-02, avg batch time: 0.5087, average train loss: 0.0105
[09/26 11:45:59 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1692, average loss: 5.6651
[09/26 11:45:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 11:45:59 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 11:46:06 visual_prompt]: Epoch 63 / 100: avg data time: 4.52e-02, avg batch time: 0.4961, average train loss: 0.0076
[09/26 11:46:07 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1693, average loss: 5.5933
[09/26 11:46:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.00	
[09/26 11:46:07 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 11:46:14 visual_prompt]: Epoch 64 / 100: avg data time: 5.35e-02, avg batch time: 0.5037, average train loss: 0.0047
[09/26 11:46:16 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1694, average loss: 5.5828
[09/26 11:46:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 11:46:16 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 11:46:22 visual_prompt]: Epoch 65 / 100: avg data time: 5.76e-02, avg batch time: 0.5058, average train loss: 0.0044
[09/26 11:46:24 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 5.5859
[09/26 11:46:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.00	
[09/26 11:46:24 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 11:46:31 visual_prompt]: Epoch 66 / 100: avg data time: 8.04e-02, avg batch time: 0.5287, average train loss: 0.0026
[09/26 11:46:33 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1696, average loss: 5.5453
[09/26 11:46:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 67.50	
[09/26 11:46:33 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 11:46:40 visual_prompt]: Epoch 67 / 100: avg data time: 6.99e-02, avg batch time: 0.5179, average train loss: 0.0030
[09/26 11:46:42 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 5.4867
[09/26 11:46:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.50	
[09/26 11:46:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 11:46:48 visual_prompt]: Epoch 68 / 100: avg data time: 4.09e-02, avg batch time: 0.4904, average train loss: 0.0024
[09/26 11:46:50 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1693, average loss: 5.4635
[09/26 11:46:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.50	
[09/26 11:46:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 11:46:57 visual_prompt]: Epoch 69 / 100: avg data time: 6.31e-02, avg batch time: 0.5124, average train loss: 0.0024
[09/26 11:46:58 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1691, average loss: 5.4267
[09/26 11:46:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.00	
[09/26 11:46:58 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 11:47:05 visual_prompt]: Epoch 70 / 100: avg data time: 7.09e-02, avg batch time: 0.5192, average train loss: 0.0026
[09/26 11:47:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1692, average loss: 5.4033
[09/26 11:47:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:47:07 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 11:47:14 visual_prompt]: Epoch 71 / 100: avg data time: 5.05e-02, avg batch time: 0.5000, average train loss: 0.0024
[09/26 11:47:15 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 5.3929
[09/26 11:47:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 11:47:15 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 11:47:22 visual_prompt]: Epoch 72 / 100: avg data time: 6.97e-02, avg batch time: 0.5180, average train loss: 0.0026
[09/26 11:47:24 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1693, average loss: 5.3771
[09/26 11:47:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 11:47:24 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 11:47:31 visual_prompt]: Epoch 73 / 100: avg data time: 6.00e-02, avg batch time: 0.5085, average train loss: 0.0025
[09/26 11:47:32 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1703, average loss: 5.3520
[09/26 11:47:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.50	
[09/26 11:47:32 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 11:47:39 visual_prompt]: Epoch 74 / 100: avg data time: 5.86e-02, avg batch time: 0.5079, average train loss: 0.0022
[09/26 11:47:41 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 5.3144
[09/26 11:47:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:47:41 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 11:47:47 visual_prompt]: Epoch 75 / 100: avg data time: 5.83e-02, avg batch time: 0.5081, average train loss: 0.0021
[09/26 11:47:49 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 5.2912
[09/26 11:47:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 11:47:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 11:47:56 visual_prompt]: Epoch 76 / 100: avg data time: 6.63e-02, avg batch time: 0.5145, average train loss: 0.0020
[09/26 11:47:57 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1692, average loss: 5.2712
[09/26 11:47:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:47:57 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 11:48:04 visual_prompt]: Epoch 77 / 100: avg data time: 5.32e-02, avg batch time: 0.5020, average train loss: 0.0021
[09/26 11:48:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1692, average loss: 5.2529
[09/26 11:48:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:48:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 11:48:13 visual_prompt]: Epoch 78 / 100: avg data time: 5.72e-02, avg batch time: 0.5055, average train loss: 0.0022
[09/26 11:48:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 5.2373
[09/26 11:48:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.00	
[09/26 11:48:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 11:48:21 visual_prompt]: Epoch 79 / 100: avg data time: 6.27e-02, avg batch time: 0.5120, average train loss: 0.0020
[09/26 11:48:23 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1691, average loss: 5.2210
[09/26 11:48:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 65.50	
[09/26 11:48:23 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 11:48:30 visual_prompt]: Epoch 80 / 100: avg data time: 5.57e-02, avg batch time: 0.5052, average train loss: 0.0023
[09/26 11:48:31 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1694, average loss: 5.2105
[09/26 11:48:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.00	
[09/26 11:48:31 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 11:48:38 visual_prompt]: Epoch 81 / 100: avg data time: 6.12e-02, avg batch time: 0.5094, average train loss: 0.0020
[09/26 11:48:40 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1694, average loss: 5.2044
[09/26 11:48:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:48:40 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 11:48:47 visual_prompt]: Epoch 82 / 100: avg data time: 7.57e-02, avg batch time: 0.5241, average train loss: 0.0022
[09/26 11:48:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 5.1936
[09/26 11:48:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.50	
[09/26 11:48:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 11:48:56 visual_prompt]: Epoch 83 / 100: avg data time: 7.84e-02, avg batch time: 0.5261, average train loss: 0.0021
[09/26 11:48:58 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 5.1805
[09/26 11:48:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 11:48:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:49:05 visual_prompt]: Epoch 84 / 100: avg data time: 6.44e-02, avg batch time: 0.5123, average train loss: 0.0022
[09/26 11:49:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 5.1703
[09/26 11:49:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.50	
[09/26 11:49:06 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:49:13 visual_prompt]: Epoch 85 / 100: avg data time: 6.26e-02, avg batch time: 0.5105, average train loss: 0.0022
[09/26 11:49:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 5.1629
[09/26 11:49:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 11:49:15 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:49:22 visual_prompt]: Epoch 86 / 100: avg data time: 5.71e-02, avg batch time: 0.5057, average train loss: 0.0021
[09/26 11:49:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 5.1560
[09/26 11:49:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 11:49:23 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:49:30 visual_prompt]: Epoch 87 / 100: avg data time: 6.34e-02, avg batch time: 0.5125, average train loss: 0.0021
[09/26 11:49:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 5.1500
[09/26 11:49:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 11:49:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:49:39 visual_prompt]: Epoch 88 / 100: avg data time: 5.83e-02, avg batch time: 0.5082, average train loss: 0.0026
[09/26 11:49:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1693, average loss: 5.1436
[09/26 11:49:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 11:49:40 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:49:47 visual_prompt]: Epoch 89 / 100: avg data time: 5.99e-02, avg batch time: 0.5082, average train loss: 0.0028
[09/26 11:49:49 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1691, average loss: 5.1348
[09/26 11:49:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:49:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:49:56 visual_prompt]: Epoch 90 / 100: avg data time: 5.70e-02, avg batch time: 0.5078, average train loss: 0.0023
[09/26 11:49:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1693, average loss: 5.1301
[09/26 11:49:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:49:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:50:04 visual_prompt]: Epoch 91 / 100: avg data time: 5.01e-02, avg batch time: 0.4982, average train loss: 0.0023
[09/26 11:50:06 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1690, average loss: 5.1289
[09/26 11:50:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:50:12 visual_prompt]: Epoch 92 / 100: avg data time: 4.39e-02, avg batch time: 0.4942, average train loss: 0.0023
[09/26 11:50:14 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 5.1266
[09/26 11:50:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:50:21 visual_prompt]: Epoch 93 / 100: avg data time: 4.22e-02, avg batch time: 0.4931, average train loss: 0.0022
[09/26 11:50:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1695, average loss: 5.1244
[09/26 11:50:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:50:29 visual_prompt]: Epoch 94 / 100: avg data time: 6.64e-02, avg batch time: 0.5146, average train loss: 0.0025
[09/26 11:50:31 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 5.1229
[09/26 11:50:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:50:38 visual_prompt]: Epoch 95 / 100: avg data time: 4.81e-02, avg batch time: 0.4984, average train loss: 0.0026
[09/26 11:50:39 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 5.1225
[09/26 11:50:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:39 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:50:46 visual_prompt]: Epoch 96 / 100: avg data time: 6.28e-02, avg batch time: 0.5111, average train loss: 0.0025
[09/26 11:50:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1691, average loss: 5.1220
[09/26 11:50:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:50:55 visual_prompt]: Epoch 97 / 100: avg data time: 5.47e-02, avg batch time: 0.5041, average train loss: 0.0023
[09/26 11:50:56 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1690, average loss: 5.1217
[09/26 11:50:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:50:56 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:51:03 visual_prompt]: Epoch 98 / 100: avg data time: 7.51e-02, avg batch time: 0.5233, average train loss: 0.0025
[09/26 11:51:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1688, average loss: 5.1215
[09/26 11:51:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:51:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:51:12 visual_prompt]: Epoch 99 / 100: avg data time: 5.65e-02, avg batch time: 0.5051, average train loss: 0.0024
[09/26 11:51:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 5.1215
[09/26 11:51:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:51:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:51:20 visual_prompt]: Epoch 100 / 100: avg data time: 5.06e-02, avg batch time: 0.5004, average train loss: 0.0024
[09/26 11:51:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 5.1215
[09/26 11:51:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:51:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:51:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:51:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:51:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:51:22 visual_prompt]: Training with config:
[09/26 11:51:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:51:22 visual_prompt]: Loading training data...
[09/26 11:51:22 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:51:23 visual_prompt]: Number of images: 800
[09/26 11:51:23 visual_prompt]: Number of classes: 18 / 18
[09/26 11:51:23 visual_prompt]: Loading validation data...
[09/26 11:51:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 11:51:23 visual_prompt]: Number of images: 200
[09/26 11:51:23 visual_prompt]: Number of classes: 18 / 18
[09/26 11:51:23 visual_prompt]: Constructing models...
[09/26 11:51:26 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 11:51:26 visual_prompt]: tuned percent:0.550
[09/26 11:51:26 visual_prompt]: Device used for model: 0
[09/26 11:51:26 visual_prompt]: Setting up Evaluator...
[09/26 11:51:26 visual_prompt]: Setting up Trainer...
[09/26 11:51:26 visual_prompt]: 	Setting up the optimizer...
[09/26 11:51:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:51:33 visual_prompt]: Epoch 1 / 100: avg data time: 4.26e-02, avg batch time: 0.4914, average train loss: 3.2568
[09/26 11:51:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 3.1895
[09/26 11:51:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 11:51:34 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 11:51:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:51:41 visual_prompt]: Epoch 2 / 100: avg data time: 5.14e-02, avg batch time: 0.4988, average train loss: 3.1514
[09/26 11:51:42 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1687, average loss: 3.1586
[09/26 11:51:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 11:51:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:51:49 visual_prompt]: Epoch 3 / 100: avg data time: 5.49e-02, avg batch time: 0.5033, average train loss: 3.0323
[09/26 11:51:51 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1690, average loss: 3.0912
[09/26 11:51:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.00	
[09/26 11:51:51 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 11:51:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:51:57 visual_prompt]: Epoch 4 / 100: avg data time: 4.39e-02, avg batch time: 0.4929, average train loss: 3.0139
[09/26 11:51:59 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1689, average loss: 3.0111
[09/26 11:51:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 11:51:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:52:06 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.5040, average train loss: 2.9975
[09/26 11:52:07 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 3.0732
[09/26 11:52:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 11:52:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:52:14 visual_prompt]: Epoch 6 / 100: avg data time: 5.61e-02, avg batch time: 0.5042, average train loss: 3.1393
[09/26 11:52:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 3.2850
[09/26 11:52:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 11:52:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:52:22 visual_prompt]: Epoch 7 / 100: avg data time: 5.63e-02, avg batch time: 0.5057, average train loss: 3.1252
[09/26 11:52:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 3.0508
[09/26 11:52:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 11:52:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:52:31 visual_prompt]: Epoch 8 / 100: avg data time: 4.63e-02, avg batch time: 0.4990, average train loss: 3.1160
[09/26 11:52:32 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1689, average loss: 3.1092
[09/26 11:52:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 11:52:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:52:39 visual_prompt]: Epoch 9 / 100: avg data time: 5.88e-02, avg batch time: 0.5067, average train loss: 3.1685
[09/26 11:52:40 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 3.1189
[09/26 11:52:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 33.00	
[09/26 11:52:40 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:52:47 visual_prompt]: Epoch 10 / 100: avg data time: 5.16e-02, avg batch time: 0.4996, average train loss: 3.3370
[09/26 11:52:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 3.2071
[09/26 11:52:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 11:52:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:52:56 visual_prompt]: Epoch 11 / 100: avg data time: 5.74e-02, avg batch time: 0.5060, average train loss: 3.3619
[09/26 11:52:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 3.6717
[09/26 11:52:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 11:52:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:53:04 visual_prompt]: Epoch 12 / 100: avg data time: 5.84e-02, avg batch time: 0.5065, average train loss: 3.3102
[09/26 11:53:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1692, average loss: 3.4977
[09/26 11:53:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.00	
[09/26 11:53:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:53:12 visual_prompt]: Epoch 13 / 100: avg data time: 5.64e-02, avg batch time: 0.5056, average train loss: 3.3065
[09/26 11:53:14 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1692, average loss: 3.3312
[09/26 11:53:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 11:53:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:53:21 visual_prompt]: Epoch 14 / 100: avg data time: 5.60e-02, avg batch time: 0.5052, average train loss: 3.1672
[09/26 11:53:22 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 3.0577
[09/26 11:53:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 11:53:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:53:29 visual_prompt]: Epoch 15 / 100: avg data time: 5.45e-02, avg batch time: 0.5042, average train loss: 3.0917
[09/26 11:53:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1693, average loss: 3.1763
[09/26 11:53:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 31.50	
[09/26 11:53:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:53:38 visual_prompt]: Epoch 16 / 100: avg data time: 5.52e-02, avg batch time: 0.5054, average train loss: 3.1119
[09/26 11:53:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 2.9790
[09/26 11:53:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 39.00	
[09/26 11:53:39 visual_prompt]: Best epoch 16: best metric: 0.090
[09/26 11:53:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:53:46 visual_prompt]: Epoch 17 / 100: avg data time: 6.16e-02, avg batch time: 0.5097, average train loss: 2.9980
[09/26 11:53:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1693, average loss: 2.9982
[09/26 11:53:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 35.50	
[09/26 11:53:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:53:54 visual_prompt]: Epoch 18 / 100: avg data time: 5.90e-02, avg batch time: 0.5069, average train loss: 2.7744
[09/26 11:53:56 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1691, average loss: 3.1458
[09/26 11:53:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 44.50	
[09/26 11:53:56 visual_prompt]: Best epoch 18: best metric: 0.100
[09/26 11:53:56 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:54:03 visual_prompt]: Epoch 19 / 100: avg data time: 5.07e-02, avg batch time: 0.5003, average train loss: 2.7679
[09/26 11:54:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 3.1853
[09/26 11:54:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 39.50	
[09/26 11:54:04 visual_prompt]: Best epoch 19: best metric: 0.150
[09/26 11:54:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:54:11 visual_prompt]: Epoch 20 / 100: avg data time: 5.33e-02, avg batch time: 0.5016, average train loss: 2.6683
[09/26 11:54:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1695, average loss: 2.8198
[09/26 11:54:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.00	
[09/26 11:54:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:54:19 visual_prompt]: Epoch 21 / 100: avg data time: 4.82e-02, avg batch time: 0.4974, average train loss: 2.5623
[09/26 11:54:21 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 2.9248
[09/26 11:54:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 48.00	
[09/26 11:54:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:54:27 visual_prompt]: Epoch 22 / 100: avg data time: 5.52e-02, avg batch time: 0.5044, average train loss: 2.3504
[09/26 11:54:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1693, average loss: 3.1174
[09/26 11:54:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 11:54:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:54:36 visual_prompt]: Epoch 23 / 100: avg data time: 6.20e-02, avg batch time: 0.5102, average train loss: 2.5149
[09/26 11:54:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 3.1853
[09/26 11:54:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 55.00	
[09/26 11:54:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:54:44 visual_prompt]: Epoch 24 / 100: avg data time: 4.61e-02, avg batch time: 0.4963, average train loss: 2.2009
[09/26 11:54:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1695, average loss: 2.8349
[09/26 11:54:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 59.50	
[09/26 11:54:46 visual_prompt]: Best epoch 24: best metric: 0.175
[09/26 11:54:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:54:52 visual_prompt]: Epoch 25 / 100: avg data time: 4.50e-02, avg batch time: 0.4982, average train loss: 1.9202
[09/26 11:54:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1691, average loss: 3.1060
[09/26 11:54:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 60.50	
[09/26 11:54:54 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:55:01 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e-02, avg batch time: 0.4998, average train loss: 1.6141
[09/26 11:55:02 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 3.2250
[09/26 11:55:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 64.00	
[09/26 11:55:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:55:09 visual_prompt]: Epoch 27 / 100: avg data time: 5.87e-02, avg batch time: 0.5083, average train loss: 1.4386
[09/26 11:55:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 3.7302
[09/26 11:55:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 64.00	
[09/26 11:55:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:55:18 visual_prompt]: Epoch 28 / 100: avg data time: 6.34e-02, avg batch time: 0.5119, average train loss: 1.4543
[09/26 11:55:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1691, average loss: 3.6923
[09/26 11:55:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.00	
[09/26 11:55:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:55:26 visual_prompt]: Epoch 29 / 100: avg data time: 5.38e-02, avg batch time: 0.5030, average train loss: 1.2616
[09/26 11:55:28 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1692, average loss: 3.3398
[09/26 11:55:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 66.50	
[09/26 11:55:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:55:34 visual_prompt]: Epoch 30 / 100: avg data time: 4.58e-02, avg batch time: 0.4961, average train loss: 1.1158
[09/26 11:55:36 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 4.2293
[09/26 11:55:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 59.00	
[09/26 11:55:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:55:43 visual_prompt]: Epoch 31 / 100: avg data time: 5.53e-02, avg batch time: 0.5036, average train loss: 0.9401
[09/26 11:55:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1694, average loss: 4.1082
[09/26 11:55:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 62.00	
[09/26 11:55:44 visual_prompt]: Best epoch 31: best metric: 0.215
[09/26 11:55:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:55:51 visual_prompt]: Epoch 32 / 100: avg data time: 4.49e-02, avg batch time: 0.4962, average train loss: 0.7828
[09/26 11:55:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1692, average loss: 4.7278
[09/26 11:55:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 64.00	
[09/26 11:55:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:55:59 visual_prompt]: Epoch 33 / 100: avg data time: 5.50e-02, avg batch time: 0.5065, average train loss: 0.7607
[09/26 11:56:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 4.7544
[09/26 11:56:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 62.00	
[09/26 11:56:01 visual_prompt]: Best epoch 33: best metric: 0.220
[09/26 11:56:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:56:08 visual_prompt]: Epoch 34 / 100: avg data time: 5.36e-02, avg batch time: 0.5031, average train loss: 0.5784
[09/26 11:56:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1695, average loss: 5.1910
[09/26 11:56:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 61.50	
[09/26 11:56:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:56:16 visual_prompt]: Epoch 35 / 100: avg data time: 5.62e-02, avg batch time: 0.5060, average train loss: 0.5145
[09/26 11:56:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 6.0757
[09/26 11:56:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 11:56:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:56:24 visual_prompt]: Epoch 36 / 100: avg data time: 6.12e-02, avg batch time: 0.5097, average train loss: 0.5907
[09/26 11:56:26 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 5.3952
[09/26 11:56:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 62.00	
[09/26 11:56:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:56:33 visual_prompt]: Epoch 37 / 100: avg data time: 5.15e-02, avg batch time: 0.5016, average train loss: 0.6697
[09/26 11:56:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1695, average loss: 4.5763
[09/26 11:56:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 62.00	
[09/26 11:56:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:56:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.98e-02, avg batch time: 0.5095, average train loss: 0.3667
[09/26 11:56:42 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1690, average loss: 6.0556
[09/26 11:56:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.00	
[09/26 11:56:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:56:49 visual_prompt]: Epoch 39 / 100: avg data time: 5.74e-02, avg batch time: 0.5073, average train loss: 0.2873
[09/26 11:56:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 6.3504
[09/26 11:56:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 66.00	
[09/26 11:56:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:56:58 visual_prompt]: Epoch 40 / 100: avg data time: 5.33e-02, avg batch time: 0.5036, average train loss: 0.2328
[09/26 11:56:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 6.5511
[09/26 11:56:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.00	
[09/26 11:56:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:57:06 visual_prompt]: Epoch 41 / 100: avg data time: 4.69e-02, avg batch time: 0.4986, average train loss: 0.1649
[09/26 11:57:07 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 7.6536
[09/26 11:57:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.50	
[09/26 11:57:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:57:14 visual_prompt]: Epoch 42 / 100: avg data time: 6.56e-02, avg batch time: 0.5140, average train loss: 0.1820
[09/26 11:57:16 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1693, average loss: 7.1624
[09/26 11:57:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 11:57:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:57:23 visual_prompt]: Epoch 43 / 100: avg data time: 5.75e-02, avg batch time: 0.5079, average train loss: 0.1785
[09/26 11:57:24 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 7.3429
[09/26 11:57:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 65.00	
[09/26 11:57:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:57:31 visual_prompt]: Epoch 44 / 100: avg data time: 5.57e-02, avg batch time: 0.5055, average train loss: 0.1879
[09/26 11:57:33 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 7.8642
[09/26 11:57:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.50	
[09/26 11:57:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:57:40 visual_prompt]: Epoch 45 / 100: avg data time: 4.74e-02, avg batch time: 0.4975, average train loss: 0.1871
[09/26 11:57:41 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1692, average loss: 7.0887
[09/26 11:57:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.00	
[09/26 11:57:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:57:48 visual_prompt]: Epoch 46 / 100: avg data time: 5.29e-02, avg batch time: 0.5013, average train loss: 0.1202
[09/26 11:57:49 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1691, average loss: 7.1635
[09/26 11:57:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 65.00	
[09/26 11:57:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:57:56 visual_prompt]: Epoch 47 / 100: avg data time: 6.27e-02, avg batch time: 0.5119, average train loss: 0.1083
[09/26 11:57:58 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1698, average loss: 7.4509
[09/26 11:57:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.50	
[09/26 11:57:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:58:05 visual_prompt]: Epoch 48 / 100: avg data time: 6.10e-02, avg batch time: 0.5120, average train loss: 0.0539
[09/26 11:58:06 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1693, average loss: 8.1028
[09/26 11:58:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 63.00	
[09/26 11:58:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:58:13 visual_prompt]: Epoch 49 / 100: avg data time: 6.09e-02, avg batch time: 0.5091, average train loss: 0.0406
[09/26 11:58:15 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 7.8764
[09/26 11:58:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 11:58:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:58:21 visual_prompt]: Epoch 50 / 100: avg data time: 4.62e-02, avg batch time: 0.4970, average train loss: 0.0342
[09/26 11:58:23 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1695, average loss: 8.0828
[09/26 11:58:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 66.00	
[09/26 11:58:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:58:30 visual_prompt]: Epoch 51 / 100: avg data time: 4.71e-02, avg batch time: 0.4959, average train loss: 0.0141
[09/26 11:58:31 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1694, average loss: 8.4211
[09/26 11:58:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.00	
[09/26 11:58:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:58:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.83e-02, avg batch time: 0.5067, average train loss: 0.0097
[09/26 11:58:40 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1692, average loss: 8.8610
[09/26 11:58:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.00	
[09/26 11:58:40 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:58:46 visual_prompt]: Epoch 53 / 100: avg data time: 5.72e-02, avg batch time: 0.5066, average train loss: 0.0036
[09/26 11:58:48 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 9.1464
[09/26 11:58:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 67.00	
[09/26 11:58:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:58:55 visual_prompt]: Epoch 54 / 100: avg data time: 5.92e-02, avg batch time: 0.5076, average train loss: 0.0043
[09/26 11:58:56 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1693, average loss: 9.2954
[09/26 11:58:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 65.50	
[09/26 11:58:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:59:03 visual_prompt]: Epoch 55 / 100: avg data time: 5.25e-02, avg batch time: 0.5017, average train loss: 0.0034
[09/26 11:59:05 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1696, average loss: 9.5856
[09/26 11:59:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 11:59:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:59:12 visual_prompt]: Epoch 56 / 100: avg data time: 5.79e-02, avg batch time: 0.5074, average train loss: 0.0050
[09/26 11:59:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1692, average loss: 9.6791
[09/26 11:59:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 11:59:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:59:20 visual_prompt]: Epoch 57 / 100: avg data time: 5.91e-02, avg batch time: 0.5091, average train loss: 0.0037
[09/26 11:59:22 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1694, average loss: 9.8007
[09/26 11:59:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.50	
[09/26 11:59:22 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:59:29 visual_prompt]: Epoch 58 / 100: avg data time: 5.41e-02, avg batch time: 0.5035, average train loss: 0.0043
[09/26 11:59:30 visual_prompt]: Inference (val):avg data time: 5.29e-05, avg batch time: 0.1692, average loss: 9.9239
[09/26 11:59:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 11:59:30 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:59:37 visual_prompt]: Epoch 59 / 100: avg data time: 5.62e-02, avg batch time: 0.5049, average train loss: 0.0025
[09/26 11:59:39 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1695, average loss: 10.1739
[09/26 11:59:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 65.50	
[09/26 11:59:39 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:59:45 visual_prompt]: Epoch 60 / 100: avg data time: 5.05e-02, avg batch time: 0.5010, average train loss: 0.0024
[09/26 11:59:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1693, average loss: 10.1214
[09/26 11:59:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 65.50	
[09/26 11:59:47 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:59:54 visual_prompt]: Epoch 61 / 100: avg data time: 5.83e-02, avg batch time: 0.5075, average train loss: 0.0024
[09/26 11:59:55 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1690, average loss: 9.9348
[09/26 11:59:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 66.50	
[09/26 11:59:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 12:00:02 visual_prompt]: Epoch 62 / 100: avg data time: 5.71e-02, avg batch time: 0.5053, average train loss: 0.0018
[09/26 12:00:04 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1694, average loss: 9.9268
[09/26 12:00:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:00:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 12:00:11 visual_prompt]: Epoch 63 / 100: avg data time: 4.70e-02, avg batch time: 0.4964, average train loss: 0.0012
[09/26 12:00:12 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 9.9599
[09/26 12:00:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.00	
[09/26 12:00:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 12:00:19 visual_prompt]: Epoch 64 / 100: avg data time: 5.03e-02, avg batch time: 0.4990, average train loss: 0.0006
[09/26 12:00:20 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1693, average loss: 9.9688
[09/26 12:00:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.00	
[09/26 12:00:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 12:00:27 visual_prompt]: Epoch 65 / 100: avg data time: 5.21e-02, avg batch time: 0.5014, average train loss: 0.0018
[09/26 12:00:29 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1695, average loss: 9.7949
[09/26 12:00:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.00	
[09/26 12:00:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 12:00:36 visual_prompt]: Epoch 66 / 100: avg data time: 4.51e-02, avg batch time: 0.4948, average train loss: 0.0014
[09/26 12:00:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 9.7720
[09/26 12:00:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.00	
[09/26 12:00:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 12:00:44 visual_prompt]: Epoch 67 / 100: avg data time: 5.18e-02, avg batch time: 0.5013, average train loss: 0.0026
[09/26 12:00:45 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1696, average loss: 9.7323
[09/26 12:00:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 65.00	
[09/26 12:00:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 12:00:52 visual_prompt]: Epoch 68 / 100: avg data time: 5.26e-02, avg batch time: 0.5019, average train loss: 0.0012
[09/26 12:00:54 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 9.7722
[09/26 12:00:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 65.50	
[09/26 12:00:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 12:01:00 visual_prompt]: Epoch 69 / 100: avg data time: 4.75e-02, avg batch time: 0.4974, average train loss: 0.0009
[09/26 12:01:02 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1695, average loss: 9.7886
[09/26 12:01:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 12:01:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 12:01:09 visual_prompt]: Epoch 70 / 100: avg data time: 5.78e-02, avg batch time: 0.5069, average train loss: 0.0014
[09/26 12:01:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 9.8669
[09/26 12:01:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 12:01:10 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 12:01:17 visual_prompt]: Epoch 71 / 100: avg data time: 5.83e-02, avg batch time: 0.5069, average train loss: 0.0009
[09/26 12:01:19 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 9.8809
[09/26 12:01:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.50	
[09/26 12:01:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 12:01:26 visual_prompt]: Epoch 72 / 100: avg data time: 4.63e-02, avg batch time: 0.4983, average train loss: 0.0015
[09/26 12:01:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1695, average loss: 9.9024
[09/26 12:01:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 67.00	
[09/26 12:01:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 12:01:34 visual_prompt]: Epoch 73 / 100: avg data time: 6.47e-02, avg batch time: 0.5143, average train loss: 0.0006
[09/26 12:01:36 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1695, average loss: 9.9054
[09/26 12:01:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.50	
[09/26 12:01:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 12:01:42 visual_prompt]: Epoch 74 / 100: avg data time: 4.81e-02, avg batch time: 0.4980, average train loss: 0.0008
[09/26 12:01:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1692, average loss: 9.9160
[09/26 12:01:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 67.00	
[09/26 12:01:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 12:01:51 visual_prompt]: Epoch 75 / 100: avg data time: 5.19e-02, avg batch time: 0.5018, average train loss: 0.0010
[09/26 12:01:52 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1695, average loss: 9.9251
[09/26 12:01:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 12:01:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 12:01:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.30e-02, avg batch time: 0.5030, average train loss: 0.0007
[09/26 12:02:00 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1694, average loss: 9.9316
[09/26 12:02:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.50	
[09/26 12:02:00 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 12:02:07 visual_prompt]: Epoch 77 / 100: avg data time: 6.06e-02, avg batch time: 0.5099, average train loss: 0.0005
[09/26 12:02:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 9.9332
[09/26 12:02:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.50	
[09/26 12:02:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 12:02:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.50e-02, avg batch time: 0.5048, average train loss: 0.0005
[09/26 12:02:17 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 9.9277
[09/26 12:02:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 12:02:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 12:02:24 visual_prompt]: Epoch 79 / 100: avg data time: 4.91e-02, avg batch time: 0.4991, average train loss: 0.0005
[09/26 12:02:25 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 9.9173
[09/26 12:02:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 12:02:25 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 12:02:32 visual_prompt]: Epoch 80 / 100: avg data time: 4.59e-02, avg batch time: 0.4983, average train loss: 0.0008
[09/26 12:02:34 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1690, average loss: 9.9173
[09/26 12:02:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 67.00	
[09/26 12:02:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 12:02:41 visual_prompt]: Epoch 81 / 100: avg data time: 4.76e-02, avg batch time: 0.4996, average train loss: 0.0004
[09/26 12:02:42 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 9.9168
[09/26 12:02:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:02:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 12:02:49 visual_prompt]: Epoch 82 / 100: avg data time: 5.09e-02, avg batch time: 0.4998, average train loss: 0.0004
[09/26 12:02:50 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1694, average loss: 9.9176
[09/26 12:02:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.50	
[09/26 12:02:50 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 12:02:57 visual_prompt]: Epoch 83 / 100: avg data time: 6.03e-02, avg batch time: 0.5102, average train loss: 0.0008
[09/26 12:02:59 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1694, average loss: 9.9213
[09/26 12:02:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:02:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 12:03:06 visual_prompt]: Epoch 84 / 100: avg data time: 5.98e-02, avg batch time: 0.5100, average train loss: 0.0004
[09/26 12:03:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 9.9230
[09/26 12:03:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:07 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 12:03:14 visual_prompt]: Epoch 85 / 100: avg data time: 5.72e-02, avg batch time: 0.5060, average train loss: 0.0007
[09/26 12:03:16 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1694, average loss: 9.9229
[09/26 12:03:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 12:03:22 visual_prompt]: Epoch 86 / 100: avg data time: 4.69e-02, avg batch time: 0.4987, average train loss: 0.0006
[09/26 12:03:24 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1695, average loss: 9.9218
[09/26 12:03:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 12:03:31 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.5025, average train loss: 0.0004
[09/26 12:03:32 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1692, average loss: 9.9234
[09/26 12:03:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:32 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 12:03:39 visual_prompt]: Epoch 88 / 100: avg data time: 6.02e-02, avg batch time: 0.5095, average train loss: 0.0003
[09/26 12:03:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1694, average loss: 9.9256
[09/26 12:03:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 12:03:47 visual_prompt]: Epoch 89 / 100: avg data time: 4.38e-02, avg batch time: 0.4946, average train loss: 0.0005
[09/26 12:03:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 9.9272
[09/26 12:03:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 12:03:56 visual_prompt]: Epoch 90 / 100: avg data time: 5.67e-02, avg batch time: 0.5064, average train loss: 0.0005
[09/26 12:03:57 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1694, average loss: 9.9279
[09/26 12:03:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:03:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 12:04:04 visual_prompt]: Epoch 91 / 100: avg data time: 6.33e-02, avg batch time: 0.5122, average train loss: 0.0010
[09/26 12:04:06 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 9.9271
[09/26 12:04:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 12:04:13 visual_prompt]: Epoch 92 / 100: avg data time: 5.91e-02, avg batch time: 0.5078, average train loss: 0.0006
[09/26 12:04:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 9.9269
[09/26 12:04:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 12:04:21 visual_prompt]: Epoch 93 / 100: avg data time: 5.90e-02, avg batch time: 0.5080, average train loss: 0.0005
[09/26 12:04:23 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1694, average loss: 9.9272
[09/26 12:04:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 12:04:30 visual_prompt]: Epoch 94 / 100: avg data time: 5.10e-02, avg batch time: 0.5019, average train loss: 0.0005
[09/26 12:04:31 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1698, average loss: 9.9274
[09/26 12:04:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 12:04:38 visual_prompt]: Epoch 95 / 100: avg data time: 5.38e-02, avg batch time: 0.5022, average train loss: 0.0004
[09/26 12:04:39 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 9.9276
[09/26 12:04:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:39 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 12:04:46 visual_prompt]: Epoch 96 / 100: avg data time: 5.58e-02, avg batch time: 0.5041, average train loss: 0.0005
[09/26 12:04:48 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1694, average loss: 9.9277
[09/26 12:04:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 12:04:55 visual_prompt]: Epoch 97 / 100: avg data time: 5.67e-02, avg batch time: 0.5063, average train loss: 0.0009
[09/26 12:04:57 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1697, average loss: 9.9277
[09/26 12:04:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:04:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 12:05:03 visual_prompt]: Epoch 98 / 100: avg data time: 5.75e-02, avg batch time: 0.5056, average train loss: 0.0005
[09/26 12:05:05 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 9.9273
[09/26 12:05:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:05:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 12:05:12 visual_prompt]: Epoch 99 / 100: avg data time: 6.54e-02, avg batch time: 0.5139, average train loss: 0.0013
[09/26 12:05:13 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1695, average loss: 9.9274
[09/26 12:05:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:05:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 12:05:20 visual_prompt]: Epoch 100 / 100: avg data time: 5.22e-02, avg batch time: 0.5014, average train loss: 0.0004
[09/26 12:05:22 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1693, average loss: 9.9275
[09/26 12:05:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 12:05:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:05:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:05:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:05:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:05:22 visual_prompt]: Training with config:
[09/26 12:05:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:05:22 visual_prompt]: Loading training data...
[09/26 12:05:22 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:05:23 visual_prompt]: Number of images: 800
[09/26 12:05:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:05:23 visual_prompt]: Loading validation data...
[09/26 12:05:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:05:23 visual_prompt]: Number of images: 200
[09/26 12:05:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:05:23 visual_prompt]: Constructing models...
[09/26 12:05:26 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 12:05:26 visual_prompt]: tuned percent:0.550
[09/26 12:05:26 visual_prompt]: Device used for model: 0
[09/26 12:05:26 visual_prompt]: Setting up Evaluator...
[09/26 12:05:26 visual_prompt]: Setting up Trainer...
[09/26 12:05:26 visual_prompt]: 	Setting up the optimizer...
[09/26 12:05:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:05:33 visual_prompt]: Epoch 1 / 100: avg data time: 4.74e-02, avg batch time: 0.4960, average train loss: 3.2611
[09/26 12:05:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 3.1895
[09/26 12:05:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 12:05:34 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 12:05:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 12:05:41 visual_prompt]: Epoch 2 / 100: avg data time: 5.18e-02, avg batch time: 0.4991, average train loss: 3.0320
[09/26 12:05:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1687, average loss: 3.0363
[09/26 12:05:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 12:05:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 12:05:49 visual_prompt]: Epoch 3 / 100: avg data time: 5.65e-02, avg batch time: 0.5042, average train loss: 2.9280
[09/26 12:05:51 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 2.9120
[09/26 12:05:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 12:05:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 12:05:58 visual_prompt]: Epoch 4 / 100: avg data time: 6.10e-02, avg batch time: 0.5090, average train loss: 2.9273
[09/26 12:05:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 2.8967
[09/26 12:05:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 12:05:59 visual_prompt]: Best epoch 4: best metric: 0.070
[09/26 12:05:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 12:06:06 visual_prompt]: Epoch 5 / 100: avg data time: 5.54e-02, avg batch time: 0.5036, average train loss: 2.9251
[09/26 12:06:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1690, average loss: 2.9016
[09/26 12:06:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 12:06:08 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 12:06:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 12:06:14 visual_prompt]: Epoch 6 / 100: avg data time: 5.45e-02, avg batch time: 0.5020, average train loss: 2.9302
[09/26 12:06:16 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1685, average loss: 2.9225
[09/26 12:06:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 12:06:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 12:06:23 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.5014, average train loss: 2.9313
[09/26 12:06:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 2.9071
[09/26 12:06:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 12:06:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 12:06:31 visual_prompt]: Epoch 8 / 100: avg data time: 5.94e-02, avg batch time: 0.5070, average train loss: 2.9380
[09/26 12:06:33 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 2.9136
[09/26 12:06:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 12:06:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:06:40 visual_prompt]: Epoch 9 / 100: avg data time: 5.88e-02, avg batch time: 0.5072, average train loss: 2.9471
[09/26 12:06:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 2.9451
[09/26 12:06:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 12:06:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:06:48 visual_prompt]: Epoch 10 / 100: avg data time: 6.18e-02, avg batch time: 0.5117, average train loss: 2.9718
[09/26 12:06:50 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1686, average loss: 3.0066
[09/26 12:06:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 22.50	
[09/26 12:06:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:06:57 visual_prompt]: Epoch 11 / 100: avg data time: 5.80e-02, avg batch time: 0.5047, average train loss: 2.9648
[09/26 12:06:58 visual_prompt]: Inference (val):avg data time: 4.99e-05, avg batch time: 0.1687, average loss: 2.9715
[09/26 12:06:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 12:06:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:07:05 visual_prompt]: Epoch 12 / 100: avg data time: 5.13e-02, avg batch time: 0.4998, average train loss: 2.9825
[09/26 12:07:06 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1693, average loss: 3.0389
[09/26 12:07:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 12:07:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:07:13 visual_prompt]: Epoch 13 / 100: avg data time: 5.75e-02, avg batch time: 0.5043, average train loss: 3.0008
[09/26 12:07:15 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1691, average loss: 2.9689
[09/26 12:07:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 12:07:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:07:22 visual_prompt]: Epoch 14 / 100: avg data time: 5.84e-02, avg batch time: 0.5060, average train loss: 2.9925
[09/26 12:07:23 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1688, average loss: 2.9760
[09/26 12:07:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 12:07:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:07:30 visual_prompt]: Epoch 15 / 100: avg data time: 5.30e-02, avg batch time: 0.5002, average train loss: 2.9701
[09/26 12:07:32 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1692, average loss: 2.9774
[09/26 12:07:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 12:07:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:07:38 visual_prompt]: Epoch 16 / 100: avg data time: 5.61e-02, avg batch time: 0.5036, average train loss: 2.9676
[09/26 12:07:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1688, average loss: 3.0040
[09/26 12:07:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 12:07:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:07:47 visual_prompt]: Epoch 17 / 100: avg data time: 5.27e-02, avg batch time: 0.5003, average train loss: 2.9801
[09/26 12:07:48 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1686, average loss: 2.9363
[09/26 12:07:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 12:07:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:07:55 visual_prompt]: Epoch 18 / 100: avg data time: 4.88e-02, avg batch time: 0.4983, average train loss: 2.9577
[09/26 12:07:57 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1694, average loss: 3.0697
[09/26 12:07:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 12:07:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:08:03 visual_prompt]: Epoch 19 / 100: avg data time: 6.17e-02, avg batch time: 0.5091, average train loss: 2.9604
[09/26 12:08:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1689, average loss: 2.9216
[09/26 12:08:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 12:08:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:08:12 visual_prompt]: Epoch 20 / 100: avg data time: 5.94e-02, avg batch time: 0.5068, average train loss: 2.9472
[09/26 12:08:13 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 2.9718
[09/26 12:08:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 12:08:13 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:08:20 visual_prompt]: Epoch 21 / 100: avg data time: 5.16e-02, avg batch time: 0.5001, average train loss: 2.9613
[09/26 12:08:22 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 2.9074
[09/26 12:08:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 12:08:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:08:29 visual_prompt]: Epoch 22 / 100: avg data time: 5.83e-02, avg batch time: 0.5060, average train loss: 2.9561
[09/26 12:08:30 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1692, average loss: 2.9482
[09/26 12:08:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 12:08:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:08:37 visual_prompt]: Epoch 23 / 100: avg data time: 4.66e-02, avg batch time: 0.4947, average train loss: 2.9618
[09/26 12:08:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1689, average loss: 3.2811
[09/26 12:08:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 12:08:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:08:45 visual_prompt]: Epoch 24 / 100: avg data time: 4.25e-02, avg batch time: 0.4903, average train loss: 3.0068
[09/26 12:08:47 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 2.9488
[09/26 12:08:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 12:08:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:08:53 visual_prompt]: Epoch 25 / 100: avg data time: 4.40e-02, avg batch time: 0.4922, average train loss: 2.9751
[09/26 12:08:55 visual_prompt]: Inference (val):avg data time: 4.22e-05, avg batch time: 0.1693, average loss: 3.0433
[09/26 12:08:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 24.00	
[09/26 12:08:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:09:02 visual_prompt]: Epoch 26 / 100: avg data time: 6.13e-02, avg batch time: 0.5093, average train loss: 2.9523
[09/26 12:09:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1688, average loss: 2.9486
[09/26 12:09:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:09:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:09:10 visual_prompt]: Epoch 27 / 100: avg data time: 6.39e-02, avg batch time: 0.5116, average train loss: 2.9506
[09/26 12:09:12 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1690, average loss: 2.9556
[09/26 12:09:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 12:09:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:09:19 visual_prompt]: Epoch 28 / 100: avg data time: 6.29e-02, avg batch time: 0.5103, average train loss: 2.9961
[09/26 12:09:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1692, average loss: 2.9672
[09/26 12:09:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 12:09:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:09:27 visual_prompt]: Epoch 29 / 100: avg data time: 5.49e-02, avg batch time: 0.5032, average train loss: 3.0050
[09/26 12:09:29 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 2.9640
[09/26 12:09:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 12:09:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:09:36 visual_prompt]: Epoch 30 / 100: avg data time: 6.20e-02, avg batch time: 0.5121, average train loss: 2.9581
[09/26 12:09:37 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 2.9410
[09/26 12:09:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 12:09:37 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:09:44 visual_prompt]: Epoch 31 / 100: avg data time: 4.75e-02, avg batch time: 0.4960, average train loss: 2.9491
[09/26 12:09:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1689, average loss: 3.0008
[09/26 12:09:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 12:09:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:09:52 visual_prompt]: Epoch 32 / 100: avg data time: 5.61e-02, avg batch time: 0.5046, average train loss: 2.9579
[09/26 12:09:54 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1696, average loss: 2.9540
[09/26 12:09:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.00	
[09/26 12:09:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:10:01 visual_prompt]: Epoch 33 / 100: avg data time: 6.86e-02, avg batch time: 0.5158, average train loss: 2.9571
[09/26 12:10:02 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1689, average loss: 2.9903
[09/26 12:10:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 12:10:02 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:10:09 visual_prompt]: Epoch 34 / 100: avg data time: 4.34e-02, avg batch time: 0.4952, average train loss: 2.9526
[09/26 12:10:11 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1695, average loss: 2.9558
[09/26 12:10:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 12:10:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:10:17 visual_prompt]: Epoch 35 / 100: avg data time: 5.35e-02, avg batch time: 0.5013, average train loss: 2.9561
[09/26 12:10:19 visual_prompt]: Inference (val):avg data time: 5.27e-05, avg batch time: 0.1692, average loss: 3.0324
[09/26 12:10:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 12:10:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:10:26 visual_prompt]: Epoch 36 / 100: avg data time: 6.07e-02, avg batch time: 0.5112, average train loss: 2.9605
[09/26 12:10:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1694, average loss: 2.9401
[09/26 12:10:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 12:10:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:10:34 visual_prompt]: Epoch 37 / 100: avg data time: 4.47e-02, avg batch time: 0.4945, average train loss: 2.9905
[09/26 12:10:36 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 2.9838
[09/26 12:10:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 12:10:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:10:43 visual_prompt]: Epoch 38 / 100: avg data time: 5.63e-02, avg batch time: 0.5050, average train loss: 3.0539
[09/26 12:10:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 3.0448
[09/26 12:10:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 12:10:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:10:51 visual_prompt]: Epoch 39 / 100: avg data time: 5.71e-02, avg batch time: 0.5056, average train loss: 3.0861
[09/26 12:10:53 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1689, average loss: 3.0704
[09/26 12:10:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 12:10:53 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:10:59 visual_prompt]: Epoch 40 / 100: avg data time: 5.65e-02, avg batch time: 0.5036, average train loss: 3.0181
[09/26 12:11:01 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 3.1988
[09/26 12:11:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 12:11:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:11:08 visual_prompt]: Epoch 41 / 100: avg data time: 4.39e-02, avg batch time: 0.4947, average train loss: 2.9835
[09/26 12:11:09 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1688, average loss: 3.0097
[09/26 12:11:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 12:11:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:11:16 visual_prompt]: Epoch 42 / 100: avg data time: 5.90e-02, avg batch time: 0.5075, average train loss: 2.9697
[09/26 12:11:18 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1689, average loss: 2.9479
[09/26 12:11:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 12:11:18 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:11:25 visual_prompt]: Epoch 43 / 100: avg data time: 5.67e-02, avg batch time: 0.5046, average train loss: 2.9445
[09/26 12:11:26 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 2.9377
[09/26 12:11:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.00	
[09/26 12:11:26 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:11:33 visual_prompt]: Epoch 44 / 100: avg data time: 6.00e-02, avg batch time: 0.5080, average train loss: 2.9286
[09/26 12:11:35 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1693, average loss: 2.9487
[09/26 12:11:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 12:11:35 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:11:41 visual_prompt]: Epoch 45 / 100: avg data time: 5.83e-02, avg batch time: 0.5069, average train loss: 2.9236
[09/26 12:11:43 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 3.0949
[09/26 12:11:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.00	
[09/26 12:11:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:11:50 visual_prompt]: Epoch 46 / 100: avg data time: 5.21e-02, avg batch time: 0.5015, average train loss: 2.9609
[09/26 12:11:51 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1690, average loss: 2.9623
[09/26 12:11:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 12:11:51 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:11:58 visual_prompt]: Epoch 47 / 100: avg data time: 5.13e-02, avg batch time: 0.5017, average train loss: 2.9505
[09/26 12:12:00 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1698, average loss: 2.9916
[09/26 12:12:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 12:12:00 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:12:06 visual_prompt]: Epoch 48 / 100: avg data time: 5.30e-02, avg batch time: 0.5018, average train loss: 2.9665
[09/26 12:12:08 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1692, average loss: 2.9525
[09/26 12:12:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 12:12:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:12:15 visual_prompt]: Epoch 49 / 100: avg data time: 4.44e-02, avg batch time: 0.4942, average train loss: 2.9423
[09/26 12:12:16 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1689, average loss: 2.9539
[09/26 12:12:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 12:12:16 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:12:23 visual_prompt]: Epoch 50 / 100: avg data time: 4.53e-02, avg batch time: 0.4940, average train loss: 2.9552
[09/26 12:12:25 visual_prompt]: Inference (val):avg data time: 5.91e-05, avg batch time: 0.1698, average loss: 3.0179
[09/26 12:12:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 12:12:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:12:31 visual_prompt]: Epoch 51 / 100: avg data time: 5.57e-02, avg batch time: 0.5037, average train loss: 2.9496
[09/26 12:12:33 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1692, average loss: 2.9387
[09/26 12:12:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 12:12:33 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:12:40 visual_prompt]: Epoch 52 / 100: avg data time: 5.58e-02, avg batch time: 0.5047, average train loss: 2.9392
[09/26 12:12:41 visual_prompt]: Inference (val):avg data time: 4.71e-05, avg batch time: 0.1690, average loss: 2.9539
[09/26 12:12:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 12:12:41 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:12:48 visual_prompt]: Epoch 53 / 100: avg data time: 5.02e-02, avg batch time: 0.4988, average train loss: 2.9386
[09/26 12:12:50 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1695, average loss: 2.9261
[09/26 12:12:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 12:12:50 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:12:56 visual_prompt]: Epoch 54 / 100: avg data time: 4.54e-02, avg batch time: 0.4938, average train loss: 2.9199
[09/26 12:12:58 visual_prompt]: Inference (val):avg data time: 4.64e-05, avg batch time: 0.1690, average loss: 2.9193
[09/26 12:12:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 12:12:58 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:13:05 visual_prompt]: Epoch 55 / 100: avg data time: 4.29e-02, avg batch time: 0.4924, average train loss: 2.9117
[09/26 12:13:06 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 2.9311
[09/26 12:13:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 12:13:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:13:13 visual_prompt]: Epoch 56 / 100: avg data time: 5.26e-02, avg batch time: 0.5021, average train loss: 2.9183
[09/26 12:13:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 2.9434
[09/26 12:13:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 12:13:14 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:13:21 visual_prompt]: Epoch 57 / 100: avg data time: 4.52e-02, avg batch time: 0.4937, average train loss: 2.9286
[09/26 12:13:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 2.9202
[09/26 12:13:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.50	
[09/26 12:13:23 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:13:30 visual_prompt]: Epoch 58 / 100: avg data time: 5.46e-02, avg batch time: 0.5023, average train loss: 2.9387
[09/26 12:13:31 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 2.9077
[09/26 12:13:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 12:13:31 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:13:38 visual_prompt]: Epoch 59 / 100: avg data time: 5.89e-02, avg batch time: 0.5081, average train loss: 2.9166
[09/26 12:13:40 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1691, average loss: 2.9216
[09/26 12:13:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 12:13:40 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:13:47 visual_prompt]: Epoch 60 / 100: avg data time: 5.88e-02, avg batch time: 0.5093, average train loss: 2.9254
[09/26 12:13:48 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1691, average loss: 2.9165
[09/26 12:13:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 12:13:48 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:13:55 visual_prompt]: Epoch 61 / 100: avg data time: 4.50e-02, avg batch time: 0.4962, average train loss: 2.9150
[09/26 12:13:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 2.9184
[09/26 12:13:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 12:13:56 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:14:03 visual_prompt]: Epoch 62 / 100: avg data time: 4.67e-02, avg batch time: 0.4958, average train loss: 2.9080
[09/26 12:14:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 2.9269
[09/26 12:14:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 12:14:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:14:12 visual_prompt]: Epoch 63 / 100: avg data time: 6.28e-02, avg batch time: 0.5104, average train loss: 2.9066
[09/26 12:14:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1688, average loss: 2.9130
[09/26 12:14:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 12:14:13 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:14:20 visual_prompt]: Epoch 64 / 100: avg data time: 5.25e-02, avg batch time: 0.5010, average train loss: 2.8985
[09/26 12:14:21 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 2.9098
[09/26 12:14:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 12:14:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:14:28 visual_prompt]: Epoch 65 / 100: avg data time: 4.26e-02, avg batch time: 0.4920, average train loss: 2.9087
[09/26 12:14:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1687, average loss: 2.9270
[09/26 12:14:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 12:14:30 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:14:36 visual_prompt]: Epoch 66 / 100: avg data time: 4.29e-02, avg batch time: 0.4933, average train loss: 2.9118
[09/26 12:14:38 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1687, average loss: 2.9252
[09/26 12:14:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 12:14:38 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:14:45 visual_prompt]: Epoch 67 / 100: avg data time: 5.30e-02, avg batch time: 0.5013, average train loss: 2.9155
[09/26 12:14:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 2.9300
[09/26 12:14:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 12:14:46 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:14:53 visual_prompt]: Epoch 68 / 100: avg data time: 4.64e-02, avg batch time: 0.4945, average train loss: 2.9018
[09/26 12:14:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1691, average loss: 2.9230
[09/26 12:14:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 12:14:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:15:01 visual_prompt]: Epoch 69 / 100: avg data time: 6.02e-02, avg batch time: 0.5079, average train loss: 2.9082
[09/26 12:15:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 2.9023
[09/26 12:15:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 12:15:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:15:09 visual_prompt]: Epoch 70 / 100: avg data time: 4.77e-02, avg batch time: 0.4968, average train loss: 2.8972
[09/26 12:15:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 2.9047
[09/26 12:15:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 12:15:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:15:18 visual_prompt]: Epoch 71 / 100: avg data time: 5.96e-02, avg batch time: 0.5077, average train loss: 2.8960
[09/26 12:15:19 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1690, average loss: 2.9016
[09/26 12:15:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 12:15:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:15:26 visual_prompt]: Epoch 72 / 100: avg data time: 5.78e-02, avg batch time: 0.5064, average train loss: 2.9021
[09/26 12:15:28 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1690, average loss: 2.9078
[09/26 12:15:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 12:15:28 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:15:35 visual_prompt]: Epoch 73 / 100: avg data time: 5.35e-02, avg batch time: 0.5014, average train loss: 2.8949
[09/26 12:15:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1689, average loss: 2.9086
[09/26 12:15:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:15:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:15:43 visual_prompt]: Epoch 74 / 100: avg data time: 6.38e-02, avg batch time: 0.5116, average train loss: 2.8895
[09/26 12:15:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1683, average loss: 2.9193
[09/26 12:15:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 12:15:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:15:51 visual_prompt]: Epoch 75 / 100: avg data time: 5.59e-02, avg batch time: 0.5036, average train loss: 2.8976
[09/26 12:15:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 2.9037
[09/26 12:15:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 12:15:53 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:16:00 visual_prompt]: Epoch 76 / 100: avg data time: 5.30e-02, avg batch time: 0.5020, average train loss: 2.8926
[09/26 12:16:01 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1687, average loss: 2.9139
[09/26 12:16:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 12:16:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:16:08 visual_prompt]: Epoch 77 / 100: avg data time: 5.32e-02, avg batch time: 0.5006, average train loss: 2.8908
[09/26 12:16:09 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1688, average loss: 2.8988
[09/26 12:16:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 12:16:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:16:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.71e-02, avg batch time: 0.5052, average train loss: 2.8892
[09/26 12:16:18 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1694, average loss: 2.9030
[09/26 12:16:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 12:16:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:16:24 visual_prompt]: Epoch 79 / 100: avg data time: 5.23e-02, avg batch time: 0.4993, average train loss: 2.8885
[09/26 12:16:26 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 2.9108
[09/26 12:16:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 12:16:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:16:33 visual_prompt]: Epoch 80 / 100: avg data time: 6.25e-02, avg batch time: 0.5096, average train loss: 2.8878
[09/26 12:16:35 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1687, average loss: 2.9067
[09/26 12:16:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:16:35 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:16:41 visual_prompt]: Epoch 81 / 100: avg data time: 5.90e-02, avg batch time: 0.5058, average train loss: 2.8856
[09/26 12:16:43 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 2.9089
[09/26 12:16:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:16:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:16:50 visual_prompt]: Epoch 82 / 100: avg data time: 5.57e-02, avg batch time: 0.5047, average train loss: 2.8848
[09/26 12:16:51 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1690, average loss: 2.9077
[09/26 12:16:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 12:16:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:16:58 visual_prompt]: Epoch 83 / 100: avg data time: 4.75e-02, avg batch time: 0.4976, average train loss: 2.8830
[09/26 12:17:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1686, average loss: 2.9035
[09/26 12:17:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:17:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:17:06 visual_prompt]: Epoch 84 / 100: avg data time: 5.62e-02, avg batch time: 0.5039, average train loss: 2.8810
[09/26 12:17:08 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 2.9032
[09/26 12:17:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 12:17:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:17:15 visual_prompt]: Epoch 85 / 100: avg data time: 5.13e-02, avg batch time: 0.4991, average train loss: 2.8828
[09/26 12:17:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1695, average loss: 2.9100
[09/26 12:17:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 12:17:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:17:23 visual_prompt]: Epoch 86 / 100: avg data time: 5.50e-02, avg batch time: 0.5034, average train loss: 2.8868
[09/26 12:17:25 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1695, average loss: 2.9080
[09/26 12:17:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 12:17:25 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:17:31 visual_prompt]: Epoch 87 / 100: avg data time: 4.98e-02, avg batch time: 0.4996, average train loss: 2.8837
[09/26 12:17:33 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1691, average loss: 2.9016
[09/26 12:17:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 12:17:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:17:40 visual_prompt]: Epoch 88 / 100: avg data time: 4.94e-02, avg batch time: 0.4984, average train loss: 2.8801
[09/26 12:17:41 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 2.9030
[09/26 12:17:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 12:17:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:17:48 visual_prompt]: Epoch 89 / 100: avg data time: 5.43e-02, avg batch time: 0.5034, average train loss: 2.8811
[09/26 12:17:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 2.9059
[09/26 12:17:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 12:17:50 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 12:17:56 visual_prompt]: Epoch 90 / 100: avg data time: 4.92e-02, avg batch time: 0.4982, average train loss: 2.8793
[09/26 12:17:58 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1689, average loss: 2.9107
[09/26 12:17:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 12:17:58 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 12:18:05 visual_prompt]: Epoch 91 / 100: avg data time: 5.39e-02, avg batch time: 0.5028, average train loss: 2.8777
[09/26 12:18:06 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1697, average loss: 2.8993
[09/26 12:18:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 28.00	
[09/26 12:18:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 12:18:13 visual_prompt]: Epoch 92 / 100: avg data time: 4.25e-02, avg batch time: 0.4929, average train loss: 2.8680
[09/26 12:18:15 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1690, average loss: 2.9065
[09/26 12:18:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.50	
[09/26 12:18:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 12:18:21 visual_prompt]: Epoch 93 / 100: avg data time: 4.25e-02, avg batch time: 0.4943, average train loss: 2.8807
[09/26 12:18:23 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1694, average loss: 2.9017
[09/26 12:18:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 12:18:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 12:18:30 visual_prompt]: Epoch 94 / 100: avg data time: 5.87e-02, avg batch time: 0.5076, average train loss: 2.8778
[09/26 12:18:31 visual_prompt]: Inference (val):avg data time: 5.30e-05, avg batch time: 0.1691, average loss: 2.9033
[09/26 12:18:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 12:18:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 12:18:38 visual_prompt]: Epoch 95 / 100: avg data time: 5.80e-02, avg batch time: 0.5068, average train loss: 2.8741
[09/26 12:18:40 visual_prompt]: Inference (val):avg data time: 4.73e-05, avg batch time: 0.1695, average loss: 2.8960
[09/26 12:18:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 28.00	
[09/26 12:18:40 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 12:18:47 visual_prompt]: Epoch 96 / 100: avg data time: 5.16e-02, avg batch time: 0.5004, average train loss: 2.8722
[09/26 12:18:48 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 2.9086
[09/26 12:18:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 12:18:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 12:18:55 visual_prompt]: Epoch 97 / 100: avg data time: 5.84e-02, avg batch time: 0.5058, average train loss: 2.8753
[09/26 12:18:57 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1689, average loss: 2.8948
[09/26 12:18:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 12:18:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 12:19:03 visual_prompt]: Epoch 98 / 100: avg data time: 5.56e-02, avg batch time: 0.5041, average train loss: 2.8636
[09/26 12:19:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 2.8965
[09/26 12:19:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 33.50	
[09/26 12:19:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 12:19:12 visual_prompt]: Epoch 99 / 100: avg data time: 5.68e-02, avg batch time: 0.5047, average train loss: 2.8503
[09/26 12:19:13 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1691, average loss: 2.8876
[09/26 12:19:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 12:19:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 12:19:20 visual_prompt]: Epoch 100 / 100: avg data time: 5.21e-02, avg batch time: 0.4998, average train loss: 2.8433
[09/26 12:19:22 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1691, average loss: 2.8816
[09/26 12:19:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 12:19:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:19:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:19:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:19:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:19:22 visual_prompt]: Training with config:
[09/26 12:19:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:19:22 visual_prompt]: Loading training data...
[09/26 12:19:22 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:19:23 visual_prompt]: Number of images: 800
[09/26 12:19:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:19:23 visual_prompt]: Loading validation data...
[09/26 12:19:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:19:23 visual_prompt]: Number of images: 200
[09/26 12:19:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:19:23 visual_prompt]: Constructing models...
[09/26 12:19:26 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 12:19:26 visual_prompt]: tuned percent:0.550
[09/26 12:19:26 visual_prompt]: Device used for model: 0
[09/26 12:19:26 visual_prompt]: Setting up Evaluator...
[09/26 12:19:26 visual_prompt]: Setting up Trainer...
[09/26 12:19:26 visual_prompt]: 	Setting up the optimizer...
[09/26 12:19:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:19:33 visual_prompt]: Epoch 1 / 100: avg data time: 5.61e-02, avg batch time: 0.5057, average train loss: 3.2454
[09/26 12:19:34 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1686, average loss: 3.1895
[09/26 12:19:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 12:19:34 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 12:19:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 12:19:41 visual_prompt]: Epoch 2 / 100: avg data time: 4.55e-02, avg batch time: 0.4934, average train loss: 3.0912
[09/26 12:19:43 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1687, average loss: 3.0312
[09/26 12:19:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 12:19:43 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 12:19:49 visual_prompt]: Epoch 3 / 100: avg data time: 4.42e-02, avg batch time: 0.4950, average train loss: 2.9370
[09/26 12:19:51 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 2.9011
[09/26 12:19:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 12:19:51 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 12:19:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 12:19:58 visual_prompt]: Epoch 4 / 100: avg data time: 5.50e-02, avg batch time: 0.5029, average train loss: 2.9451
[09/26 12:19:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1688, average loss: 2.9189
[09/26 12:19:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 12:19:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 12:20:06 visual_prompt]: Epoch 5 / 100: avg data time: 4.60e-02, avg batch time: 0.4941, average train loss: 2.9614
[09/26 12:20:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1685, average loss: 2.9595
[09/26 12:20:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 12:20:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 12:20:14 visual_prompt]: Epoch 6 / 100: avg data time: 4.93e-02, avg batch time: 0.4981, average train loss: 2.9500
[09/26 12:20:16 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1690, average loss: 2.9805
[09/26 12:20:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 12:20:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 12:20:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.83e-02, avg batch time: 0.4983, average train loss: 2.9716
[09/26 12:20:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1687, average loss: 3.0300
[09/26 12:20:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 21.50	
[09/26 12:20:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 12:20:31 visual_prompt]: Epoch 8 / 100: avg data time: 4.42e-02, avg batch time: 0.4937, average train loss: 2.9922
[09/26 12:20:32 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 3.0223
[09/26 12:20:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 22.50	
[09/26 12:20:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:20:39 visual_prompt]: Epoch 9 / 100: avg data time: 4.67e-02, avg batch time: 0.4955, average train loss: 2.9706
[09/26 12:20:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 3.0200
[09/26 12:20:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 12:20:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:20:47 visual_prompt]: Epoch 10 / 100: avg data time: 4.51e-02, avg batch time: 0.4939, average train loss: 2.9917
[09/26 12:20:49 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 3.0455
[09/26 12:20:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 12:20:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:20:56 visual_prompt]: Epoch 11 / 100: avg data time: 6.02e-02, avg batch time: 0.5082, average train loss: 3.0373
[09/26 12:20:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1692, average loss: 3.0615
[09/26 12:20:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 12:20:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:21:04 visual_prompt]: Epoch 12 / 100: avg data time: 4.63e-02, avg batch time: 0.4960, average train loss: 3.0286
[09/26 12:21:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1694, average loss: 3.0811
[09/26 12:21:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 12:21:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:21:12 visual_prompt]: Epoch 13 / 100: avg data time: 4.72e-02, avg batch time: 0.4972, average train loss: 2.9935
[09/26 12:21:14 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 3.1134
[09/26 12:21:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.00	
[09/26 12:21:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:21:21 visual_prompt]: Epoch 14 / 100: avg data time: 6.05e-02, avg batch time: 0.5084, average train loss: 3.0024
[09/26 12:21:22 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 3.1149
[09/26 12:21:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 12:21:22 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:21:29 visual_prompt]: Epoch 15 / 100: avg data time: 5.07e-02, avg batch time: 0.4987, average train loss: 2.9980
[09/26 12:21:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 3.0371
[09/26 12:21:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 12:21:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:21:37 visual_prompt]: Epoch 16 / 100: avg data time: 4.52e-02, avg batch time: 0.4956, average train loss: 2.9919
[09/26 12:21:39 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.1689, average loss: 2.9600
[09/26 12:21:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 12:21:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:21:45 visual_prompt]: Epoch 17 / 100: avg data time: 5.25e-02, avg batch time: 0.5013, average train loss: 2.9639
[09/26 12:21:47 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 3.0222
[09/26 12:21:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 12:21:47 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:21:54 visual_prompt]: Epoch 18 / 100: avg data time: 5.15e-02, avg batch time: 0.5005, average train loss: 2.9553
[09/26 12:21:55 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1692, average loss: 2.9758
[09/26 12:21:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 12:21:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:22:02 visual_prompt]: Epoch 19 / 100: avg data time: 5.76e-02, avg batch time: 0.5062, average train loss: 2.9531
[09/26 12:22:04 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 2.9690
[09/26 12:22:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 12:22:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:22:10 visual_prompt]: Epoch 20 / 100: avg data time: 4.60e-02, avg batch time: 0.4953, average train loss: 2.9302
[09/26 12:22:12 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1690, average loss: 2.9566
[09/26 12:22:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 29.50	
[09/26 12:22:12 visual_prompt]: Best epoch 20: best metric: 0.105
[09/26 12:22:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:22:19 visual_prompt]: Epoch 21 / 100: avg data time: 5.89e-02, avg batch time: 0.5068, average train loss: 2.9417
[09/26 12:22:20 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 2.9760
[09/26 12:22:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 12:22:20 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:22:27 visual_prompt]: Epoch 22 / 100: avg data time: 6.12e-02, avg batch time: 0.5105, average train loss: 2.9886
[09/26 12:22:29 visual_prompt]: Inference (val):avg data time: 4.40e-05, avg batch time: 0.1689, average loss: 2.9863
[09/26 12:22:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.50	
[09/26 12:22:29 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:22:36 visual_prompt]: Epoch 23 / 100: avg data time: 4.50e-02, avg batch time: 0.4956, average train loss: 2.9249
[09/26 12:22:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1688, average loss: 2.9074
[09/26 12:22:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 35.50	
[09/26 12:22:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:22:44 visual_prompt]: Epoch 24 / 100: avg data time: 6.40e-02, avg batch time: 0.5125, average train loss: 2.9441
[09/26 12:22:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 3.0053
[09/26 12:22:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 12:22:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:22:52 visual_prompt]: Epoch 25 / 100: avg data time: 6.11e-02, avg batch time: 0.5100, average train loss: 2.9243
[09/26 12:22:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1687, average loss: 3.0062
[09/26 12:22:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.00	
[09/26 12:22:54 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:23:01 visual_prompt]: Epoch 26 / 100: avg data time: 5.06e-02, avg batch time: 0.5008, average train loss: 2.9514
[09/26 12:23:02 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 2.9344
[09/26 12:23:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 33.50	
[09/26 12:23:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:23:09 visual_prompt]: Epoch 27 / 100: avg data time: 5.53e-02, avg batch time: 0.5034, average train loss: 2.9265
[09/26 12:23:11 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1693, average loss: 2.9094
[09/26 12:23:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.00	
[09/26 12:23:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:23:18 visual_prompt]: Epoch 28 / 100: avg data time: 5.76e-02, avg batch time: 0.5062, average train loss: 2.9814
[09/26 12:23:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1689, average loss: 3.0513
[09/26 12:23:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 12:23:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:23:26 visual_prompt]: Epoch 29 / 100: avg data time: 4.50e-02, avg batch time: 0.4934, average train loss: 2.9789
[09/26 12:23:28 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1688, average loss: 3.0353
[09/26 12:23:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 12:23:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:23:34 visual_prompt]: Epoch 30 / 100: avg data time: 4.79e-02, avg batch time: 0.4975, average train loss: 2.9676
[09/26 12:23:36 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1688, average loss: 3.0555
[09/26 12:23:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 12:23:36 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:23:43 visual_prompt]: Epoch 31 / 100: avg data time: 4.46e-02, avg batch time: 0.4939, average train loss: 2.9729
[09/26 12:23:44 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 2.9695
[09/26 12:23:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 12:23:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:23:51 visual_prompt]: Epoch 32 / 100: avg data time: 5.48e-02, avg batch time: 0.5034, average train loss: 2.9467
[09/26 12:23:52 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1691, average loss: 2.9367
[09/26 12:23:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 28.00	
[09/26 12:23:52 visual_prompt]: Best epoch 32: best metric: 0.130
[09/26 12:23:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:23:59 visual_prompt]: Epoch 33 / 100: avg data time: 6.10e-02, avg batch time: 0.5099, average train loss: 2.9377
[09/26 12:24:01 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 2.9360
[09/26 12:24:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.00	
[09/26 12:24:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:24:08 visual_prompt]: Epoch 34 / 100: avg data time: 6.18e-02, avg batch time: 0.5104, average train loss: 2.9359
[09/26 12:24:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 3.0076
[09/26 12:24:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 12:24:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:24:16 visual_prompt]: Epoch 35 / 100: avg data time: 5.47e-02, avg batch time: 0.5027, average train loss: 2.8790
[09/26 12:24:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 2.9662
[09/26 12:24:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 32.00	
[09/26 12:24:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:24:24 visual_prompt]: Epoch 36 / 100: avg data time: 5.72e-02, avg batch time: 0.5068, average train loss: 2.8956
[09/26 12:24:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 2.8552
[09/26 12:24:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 40.50	
[09/26 12:24:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:24:33 visual_prompt]: Epoch 37 / 100: avg data time: 4.45e-02, avg batch time: 0.4926, average train loss: 2.7704
[09/26 12:24:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1691, average loss: 2.9703
[09/26 12:24:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 39.50	
[09/26 12:24:34 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:24:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.93e-02, avg batch time: 0.5072, average train loss: 2.7819
[09/26 12:24:42 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1693, average loss: 2.9823
[09/26 12:24:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 41.50	
[09/26 12:24:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:24:49 visual_prompt]: Epoch 39 / 100: avg data time: 5.99e-02, avg batch time: 0.5095, average train loss: 2.8315
[09/26 12:24:51 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 2.9105
[09/26 12:24:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 37.00	
[09/26 12:24:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:24:58 visual_prompt]: Epoch 40 / 100: avg data time: 4.98e-02, avg batch time: 0.5001, average train loss: 2.8608
[09/26 12:24:59 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1693, average loss: 2.7314
[09/26 12:24:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 46.00	
[09/26 12:24:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:25:06 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.5086, average train loss: 2.7233
[09/26 12:25:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 3.0366
[09/26 12:25:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 34.50	
[09/26 12:25:08 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:25:14 visual_prompt]: Epoch 42 / 100: avg data time: 4.93e-02, avg batch time: 0.4997, average train loss: 2.7065
[09/26 12:25:16 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1692, average loss: 2.7935
[09/26 12:25:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 46.50	
[09/26 12:25:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:25:23 visual_prompt]: Epoch 43 / 100: avg data time: 5.42e-02, avg batch time: 0.5040, average train loss: 2.7202
[09/26 12:25:24 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1692, average loss: 3.1804
[09/26 12:25:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 40.00	
[09/26 12:25:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:25:31 visual_prompt]: Epoch 44 / 100: avg data time: 5.44e-02, avg batch time: 0.5040, average train loss: 2.6552
[09/26 12:25:33 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 2.6418
[09/26 12:25:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 52.00	
[09/26 12:25:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:25:39 visual_prompt]: Epoch 45 / 100: avg data time: 5.48e-02, avg batch time: 0.5059, average train loss: 2.6307
[09/26 12:25:41 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1694, average loss: 2.8386
[09/26 12:25:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 52.00	
[09/26 12:25:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:25:48 visual_prompt]: Epoch 46 / 100: avg data time: 5.11e-02, avg batch time: 0.4994, average train loss: 2.5767
[09/26 12:25:49 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1695, average loss: 2.7413
[09/26 12:25:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.00	
[09/26 12:25:49 visual_prompt]: Best epoch 46: best metric: 0.135
[09/26 12:25:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:25:56 visual_prompt]: Epoch 47 / 100: avg data time: 3.94e-02, avg batch time: 0.4892, average train loss: 2.5730
[09/26 12:25:57 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1693, average loss: 2.5198
[09/26 12:25:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 12:25:57 visual_prompt]: Best epoch 47: best metric: 0.170
[09/26 12:25:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:26:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.48e-02, avg batch time: 0.5046, average train loss: 2.5628
[09/26 12:26:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1692, average loss: 2.6491
[09/26 12:26:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 53.00	
[09/26 12:26:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:26:13 visual_prompt]: Epoch 49 / 100: avg data time: 4.45e-02, avg batch time: 0.4953, average train loss: 2.5531
[09/26 12:26:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 2.6118
[09/26 12:26:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 57.00	
[09/26 12:26:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:26:21 visual_prompt]: Epoch 50 / 100: avg data time: 5.53e-02, avg batch time: 0.5050, average train loss: 2.4521
[09/26 12:26:23 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1694, average loss: 2.5559
[09/26 12:26:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.50	
[09/26 12:26:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:26:29 visual_prompt]: Epoch 51 / 100: avg data time: 5.52e-02, avg batch time: 0.5059, average train loss: 2.4346
[09/26 12:26:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1692, average loss: 2.4833
[09/26 12:26:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 69.50	
[09/26 12:26:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:26:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.70e-02, avg batch time: 0.5054, average train loss: 2.3729
[09/26 12:26:39 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1697, average loss: 2.5032
[09/26 12:26:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 12:26:39 visual_prompt]: Best epoch 52: best metric: 0.195
[09/26 12:26:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:26:46 visual_prompt]: Epoch 53 / 100: avg data time: 5.44e-02, avg batch time: 0.5036, average train loss: 2.3585
[09/26 12:26:48 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 2.6034
[09/26 12:26:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.50	
[09/26 12:26:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:26:55 visual_prompt]: Epoch 54 / 100: avg data time: 5.98e-02, avg batch time: 0.5095, average train loss: 2.3633
[09/26 12:26:56 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1690, average loss: 2.5525
[09/26 12:26:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 58.00	
[09/26 12:26:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:27:03 visual_prompt]: Epoch 55 / 100: avg data time: 6.13e-02, avg batch time: 0.5106, average train loss: 2.2149
[09/26 12:27:05 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 2.8961
[09/26 12:27:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 59.00	
[09/26 12:27:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:27:12 visual_prompt]: Epoch 56 / 100: avg data time: 4.91e-02, avg batch time: 0.4986, average train loss: 2.4012
[09/26 12:27:13 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1693, average loss: 2.5991
[09/26 12:27:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 58.50	
[09/26 12:27:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:27:20 visual_prompt]: Epoch 57 / 100: avg data time: 4.93e-02, avg batch time: 0.5001, average train loss: 2.2701
[09/26 12:27:22 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1692, average loss: 2.8242
[09/26 12:27:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.00	
[09/26 12:27:22 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:27:29 visual_prompt]: Epoch 58 / 100: avg data time: 6.22e-02, avg batch time: 0.5105, average train loss: 2.1472
[09/26 12:27:30 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 2.6854
[09/26 12:27:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 57.50	
[09/26 12:27:30 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:27:37 visual_prompt]: Epoch 59 / 100: avg data time: 4.37e-02, avg batch time: 0.4934, average train loss: 2.1590
[09/26 12:27:38 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1692, average loss: 2.6390
[09/26 12:27:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 12:27:38 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:27:45 visual_prompt]: Epoch 60 / 100: avg data time: 5.50e-02, avg batch time: 0.5043, average train loss: 2.0163
[09/26 12:27:47 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1697, average loss: 2.6328
[09/26 12:27:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 61.50	
[09/26 12:27:47 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:27:54 visual_prompt]: Epoch 61 / 100: avg data time: 6.10e-02, avg batch time: 0.5094, average train loss: 1.9851
[09/26 12:27:55 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1693, average loss: 2.8667
[09/26 12:27:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 59.00	
[09/26 12:27:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:28:02 visual_prompt]: Epoch 62 / 100: avg data time: 4.70e-02, avg batch time: 0.4958, average train loss: 1.9230
[09/26 12:28:03 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 2.6009
[09/26 12:28:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 12:28:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:28:10 visual_prompt]: Epoch 63 / 100: avg data time: 5.96e-02, avg batch time: 0.5088, average train loss: 1.8218
[09/26 12:28:12 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1694, average loss: 2.9765
[09/26 12:28:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 56.00	
[09/26 12:28:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:28:19 visual_prompt]: Epoch 64 / 100: avg data time: 4.92e-02, avg batch time: 0.4981, average train loss: 1.9619
[09/26 12:28:20 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1692, average loss: 2.7576
[09/26 12:28:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.50	
[09/26 12:28:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:28:27 visual_prompt]: Epoch 65 / 100: avg data time: 5.38e-02, avg batch time: 0.5032, average train loss: 1.8104
[09/26 12:28:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1692, average loss: 2.8903
[09/26 12:28:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.50	
[09/26 12:28:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:28:36 visual_prompt]: Epoch 66 / 100: avg data time: 5.71e-02, avg batch time: 0.5055, average train loss: 1.7287
[09/26 12:28:37 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 3.0650
[09/26 12:28:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 58.50	
[09/26 12:28:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:28:44 visual_prompt]: Epoch 67 / 100: avg data time: 4.28e-02, avg batch time: 0.4922, average train loss: 1.6485
[09/26 12:28:45 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 3.3034
[09/26 12:28:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 12:28:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:28:52 visual_prompt]: Epoch 68 / 100: avg data time: 3.82e-02, avg batch time: 0.4906, average train loss: 1.5067
[09/26 12:28:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 3.2413
[09/26 12:28:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 60.50	
[09/26 12:28:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:29:00 visual_prompt]: Epoch 69 / 100: avg data time: 5.39e-02, avg batch time: 0.5022, average train loss: 1.4957
[09/26 12:29:02 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1692, average loss: 2.9855
[09/26 12:29:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 69.00	
[09/26 12:29:02 visual_prompt]: Best epoch 69: best metric: 0.220
[09/26 12:29:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:29:09 visual_prompt]: Epoch 70 / 100: avg data time: 5.44e-02, avg batch time: 0.5045, average train loss: 1.2556
[09/26 12:29:11 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1695, average loss: 3.5960
[09/26 12:29:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 12:29:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:29:17 visual_prompt]: Epoch 71 / 100: avg data time: 5.05e-02, avg batch time: 0.5009, average train loss: 1.2297
[09/26 12:29:19 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1692, average loss: 3.6905
[09/26 12:29:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 62.00	
[09/26 12:29:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:29:26 visual_prompt]: Epoch 72 / 100: avg data time: 4.94e-02, avg batch time: 0.4990, average train loss: 1.1128
[09/26 12:29:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 3.5098
[09/26 12:29:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 64.00	
[09/26 12:29:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:29:34 visual_prompt]: Epoch 73 / 100: avg data time: 5.19e-02, avg batch time: 0.5017, average train loss: 1.0238
[09/26 12:29:35 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1696, average loss: 3.2539
[09/26 12:29:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.00	
[09/26 12:29:35 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:29:42 visual_prompt]: Epoch 74 / 100: avg data time: 5.44e-02, avg batch time: 0.5048, average train loss: 0.7862
[09/26 12:29:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 3.3956
[09/26 12:29:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 68.00	
[09/26 12:29:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:29:51 visual_prompt]: Epoch 75 / 100: avg data time: 4.27e-02, avg batch time: 0.4938, average train loss: 0.5841
[09/26 12:29:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1687, average loss: 3.8237
[09/26 12:29:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.00	
[09/26 12:29:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:29:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.38e-02, avg batch time: 0.5026, average train loss: 0.4792
[09/26 12:30:01 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1695, average loss: 3.7438
[09/26 12:30:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 66.00	
[09/26 12:30:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:30:07 visual_prompt]: Epoch 77 / 100: avg data time: 5.60e-02, avg batch time: 0.5044, average train loss: 0.3773
[09/26 12:30:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1690, average loss: 4.0478
[09/26 12:30:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 12:30:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:30:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.28e-02, avg batch time: 0.5019, average train loss: 0.3080
[09/26 12:30:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 3.9643
[09/26 12:30:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 12:30:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:30:24 visual_prompt]: Epoch 79 / 100: avg data time: 5.89e-02, avg batch time: 0.5085, average train loss: 0.2858
[09/26 12:30:26 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 4.0013
[09/26 12:30:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 67.50	
[09/26 12:30:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:30:33 visual_prompt]: Epoch 80 / 100: avg data time: 5.27e-02, avg batch time: 0.5034, average train loss: 0.2126
[09/26 12:30:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 4.1275
[09/26 12:30:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.00	
[09/26 12:30:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:30:41 visual_prompt]: Epoch 81 / 100: avg data time: 5.89e-02, avg batch time: 0.5072, average train loss: 0.1644
[09/26 12:30:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 4.4085
[09/26 12:30:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 12:30:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:30:49 visual_prompt]: Epoch 82 / 100: avg data time: 4.54e-02, avg batch time: 0.4955, average train loss: 0.1449
[09/26 12:30:51 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 4.2640
[09/26 12:30:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 12:30:51 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:30:58 visual_prompt]: Epoch 83 / 100: avg data time: 5.11e-02, avg batch time: 0.5004, average train loss: 0.1132
[09/26 12:30:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 4.2371
[09/26 12:30:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 61.00	
[09/26 12:30:59 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:31:06 visual_prompt]: Epoch 84 / 100: avg data time: 6.21e-02, avg batch time: 0.5107, average train loss: 0.0868
[09/26 12:31:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 4.2999
[09/26 12:31:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 12:31:08 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:31:14 visual_prompt]: Epoch 85 / 100: avg data time: 5.14e-02, avg batch time: 0.5006, average train loss: 0.0698
[09/26 12:31:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 4.3551
[09/26 12:31:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 12:31:16 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:31:23 visual_prompt]: Epoch 86 / 100: avg data time: 5.34e-02, avg batch time: 0.5027, average train loss: 0.0541
[09/26 12:31:24 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1691, average loss: 4.4122
[09/26 12:31:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 64.50	
[09/26 12:31:24 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:31:31 visual_prompt]: Epoch 87 / 100: avg data time: 4.69e-02, avg batch time: 0.4986, average train loss: 0.0463
[09/26 12:31:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 4.4236
[09/26 12:31:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.50	
[09/26 12:31:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:31:39 visual_prompt]: Epoch 88 / 100: avg data time: 6.37e-02, avg batch time: 0.5119, average train loss: 0.0374
[09/26 12:31:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1692, average loss: 4.3976
[09/26 12:31:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 12:31:41 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:31:48 visual_prompt]: Epoch 89 / 100: avg data time: 5.31e-02, avg batch time: 0.5014, average train loss: 0.0327
[09/26 12:31:49 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 4.3854
[09/26 12:31:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.00	
[09/26 12:31:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 12:31:56 visual_prompt]: Epoch 90 / 100: avg data time: 5.78e-02, avg batch time: 0.5077, average train loss: 0.0297
[09/26 12:31:58 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1693, average loss: 4.3907
[09/26 12:31:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 65.00	
[09/26 12:31:58 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 12:32:05 visual_prompt]: Epoch 91 / 100: avg data time: 5.82e-02, avg batch time: 0.5069, average train loss: 0.0294
[09/26 12:32:06 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1693, average loss: 4.4184
[09/26 12:32:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.00	
[09/26 12:32:06 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 12:32:13 visual_prompt]: Epoch 92 / 100: avg data time: 5.89e-02, avg batch time: 0.5071, average train loss: 0.0295
[09/26 12:32:15 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1694, average loss: 4.4417
[09/26 12:32:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.00	
[09/26 12:32:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 12:32:21 visual_prompt]: Epoch 93 / 100: avg data time: 4.62e-02, avg batch time: 0.4967, average train loss: 0.0274
[09/26 12:32:23 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1693, average loss: 4.4634
[09/26 12:32:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.00	
[09/26 12:32:23 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 12:32:30 visual_prompt]: Epoch 94 / 100: avg data time: 5.32e-02, avg batch time: 0.5031, average train loss: 0.0272
[09/26 12:32:31 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1694, average loss: 4.4824
[09/26 12:32:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 12:32:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 12:32:38 visual_prompt]: Epoch 95 / 100: avg data time: 5.68e-02, avg batch time: 0.5062, average train loss: 0.0244
[09/26 12:32:40 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1695, average loss: 4.4923
[09/26 12:32:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 63.50	
[09/26 12:32:40 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 12:32:47 visual_prompt]: Epoch 96 / 100: avg data time: 5.42e-02, avg batch time: 0.5050, average train loss: 0.0254
[09/26 12:32:48 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1695, average loss: 4.4878
[09/26 12:32:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 12:32:48 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 12:32:55 visual_prompt]: Epoch 97 / 100: avg data time: 6.13e-02, avg batch time: 0.5114, average train loss: 0.0244
[09/26 12:32:57 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 4.4839
[09/26 12:32:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 12:32:57 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 12:33:03 visual_prompt]: Epoch 98 / 100: avg data time: 4.52e-02, avg batch time: 0.4942, average train loss: 0.0245
[09/26 12:33:05 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1692, average loss: 4.4828
[09/26 12:33:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 64.00	
[09/26 12:33:05 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 12:33:12 visual_prompt]: Epoch 99 / 100: avg data time: 4.26e-02, avg batch time: 0.4919, average train loss: 0.0251
[09/26 12:33:13 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1692, average loss: 4.4823
[09/26 12:33:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 64.00	
[09/26 12:33:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 12:33:20 visual_prompt]: Epoch 100 / 100: avg data time: 5.86e-02, avg batch time: 0.5078, average train loss: 0.0239
[09/26 12:33:22 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1697, average loss: 4.4822
[09/26 12:33:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 64.00	
[09/26 12:33:22 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:33:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:33:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:33:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:33:22 visual_prompt]: Training with config:
[09/26 12:33:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:33:22 visual_prompt]: Loading training data...
[09/26 12:33:22 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:33:23 visual_prompt]: Number of images: 800
[09/26 12:33:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:33:23 visual_prompt]: Loading validation data...
[09/26 12:33:23 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:33:23 visual_prompt]: Number of images: 200
[09/26 12:33:23 visual_prompt]: Number of classes: 18 / 18
[09/26 12:33:23 visual_prompt]: Constructing models...
[09/26 12:33:26 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 12:33:26 visual_prompt]: tuned percent:0.550
[09/26 12:33:26 visual_prompt]: Device used for model: 0
[09/26 12:33:26 visual_prompt]: Setting up Evaluator...
[09/26 12:33:26 visual_prompt]: Setting up Trainer...
[09/26 12:33:26 visual_prompt]: 	Setting up the optimizer...
[09/26 12:33:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:33:33 visual_prompt]: Epoch 1 / 100: avg data time: 4.30e-02, avg batch time: 0.4944, average train loss: 3.2464
[09/26 12:33:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1690, average loss: 3.1895
[09/26 12:33:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 12:33:34 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 12:33:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 12:33:41 visual_prompt]: Epoch 2 / 100: avg data time: 4.67e-02, avg batch time: 0.4941, average train loss: 3.0126
[09/26 12:33:42 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1687, average loss: 3.0053
[09/26 12:33:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 12:33:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 12:33:49 visual_prompt]: Epoch 3 / 100: avg data time: 5.81e-02, avg batch time: 0.5062, average train loss: 2.9393
[09/26 12:33:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 2.9103
[09/26 12:33:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 12:33:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 12:33:58 visual_prompt]: Epoch 4 / 100: avg data time: 6.11e-02, avg batch time: 0.5093, average train loss: 2.9254
[09/26 12:33:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 2.9625
[09/26 12:33:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 12:33:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 12:34:06 visual_prompt]: Epoch 5 / 100: avg data time: 5.25e-02, avg batch time: 0.5015, average train loss: 2.9535
[09/26 12:34:08 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1688, average loss: 2.9283
[09/26 12:34:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 12:34:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 12:34:14 visual_prompt]: Epoch 6 / 100: avg data time: 5.81e-02, avg batch time: 0.5076, average train loss: 2.9307
[09/26 12:34:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1687, average loss: 3.0082
[09/26 12:34:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 12:34:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 12:34:23 visual_prompt]: Epoch 7 / 100: avg data time: 5.17e-02, avg batch time: 0.5011, average train loss: 2.9538
[09/26 12:34:24 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1687, average loss: 2.9228
[09/26 12:34:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 12:34:24 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 12:34:24 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 12:34:31 visual_prompt]: Epoch 8 / 100: avg data time: 5.76e-02, avg batch time: 0.5064, average train loss: 2.9479
[09/26 12:34:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1689, average loss: 2.9892
[09/26 12:34:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 12:34:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:34:40 visual_prompt]: Epoch 9 / 100: avg data time: 5.02e-02, avg batch time: 0.4995, average train loss: 2.9666
[09/26 12:34:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1688, average loss: 3.0012
[09/26 12:34:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.50	
[09/26 12:34:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:34:48 visual_prompt]: Epoch 10 / 100: avg data time: 5.60e-02, avg batch time: 0.5036, average train loss: 2.9928
[09/26 12:34:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 2.9989
[09/26 12:34:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 33.00	
[09/26 12:34:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:34:56 visual_prompt]: Epoch 11 / 100: avg data time: 6.38e-02, avg batch time: 0.5125, average train loss: 2.9834
[09/26 12:34:58 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1692, average loss: 3.0318
[09/26 12:34:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 12:34:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:35:05 visual_prompt]: Epoch 12 / 100: avg data time: 5.73e-02, avg batch time: 0.5052, average train loss: 2.9897
[09/26 12:35:06 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 3.0266
[09/26 12:35:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.50	
[09/26 12:35:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:35:13 visual_prompt]: Epoch 13 / 100: avg data time: 6.32e-02, avg batch time: 0.5122, average train loss: 2.9080
[09/26 12:35:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 2.9011
[09/26 12:35:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 34.50	
[09/26 12:35:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:35:22 visual_prompt]: Epoch 14 / 100: avg data time: 5.53e-02, avg batch time: 0.5040, average train loss: 2.8595
[09/26 12:35:23 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1693, average loss: 2.8459
[09/26 12:35:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 35.50	
[09/26 12:35:23 visual_prompt]: Best epoch 14: best metric: 0.095
[09/26 12:35:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:35:30 visual_prompt]: Epoch 15 / 100: avg data time: 5.94e-02, avg batch time: 0.5083, average train loss: 2.8322
[09/26 12:35:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 2.8164
[09/26 12:35:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 42.00	
[09/26 12:35:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:35:39 visual_prompt]: Epoch 16 / 100: avg data time: 6.07e-02, avg batch time: 0.5094, average train loss: 2.7247
[09/26 12:35:40 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1690, average loss: 2.7762
[09/26 12:35:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 48.50	
[09/26 12:35:40 visual_prompt]: Best epoch 16: best metric: 0.120
[09/26 12:35:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:35:47 visual_prompt]: Epoch 17 / 100: avg data time: 4.75e-02, avg batch time: 0.4987, average train loss: 2.6224
[09/26 12:35:49 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1690, average loss: 3.1999
[09/26 12:35:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.00	
[09/26 12:35:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:35:55 visual_prompt]: Epoch 18 / 100: avg data time: 5.37e-02, avg batch time: 0.5035, average train loss: 2.6667
[09/26 12:35:57 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1691, average loss: 2.6264
[09/26 12:35:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 52.50	
[09/26 12:35:57 visual_prompt]: Best epoch 18: best metric: 0.165
[09/26 12:35:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:36:04 visual_prompt]: Epoch 19 / 100: avg data time: 5.76e-02, avg batch time: 0.5070, average train loss: 2.4016
[09/26 12:36:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1689, average loss: 2.7975
[09/26 12:36:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 50.00	
[09/26 12:36:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:36:12 visual_prompt]: Epoch 20 / 100: avg data time: 6.11e-02, avg batch time: 0.5103, average train loss: 2.3088
[09/26 12:36:14 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 2.8372
[09/26 12:36:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 53.00	
[09/26 12:36:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:36:21 visual_prompt]: Epoch 21 / 100: avg data time: 5.88e-02, avg batch time: 0.5071, average train loss: 2.1857
[09/26 12:36:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 2.8508
[09/26 12:36:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 61.50	
[09/26 12:36:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:36:29 visual_prompt]: Epoch 22 / 100: avg data time: 5.47e-02, avg batch time: 0.5059, average train loss: 2.0120
[09/26 12:36:31 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1690, average loss: 2.7753
[09/26 12:36:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 58.00	
[09/26 12:36:31 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:36:38 visual_prompt]: Epoch 23 / 100: avg data time: 5.42e-02, avg batch time: 0.5038, average train loss: 1.8833
[09/26 12:36:39 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 2.8641
[09/26 12:36:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.50	
[09/26 12:36:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:36:46 visual_prompt]: Epoch 24 / 100: avg data time: 6.03e-02, avg batch time: 0.5107, average train loss: 1.7735
[09/26 12:36:47 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 2.8980
[09/26 12:36:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.50	
[09/26 12:36:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:36:55 visual_prompt]: Epoch 25 / 100: avg data time: 6.96e-02, avg batch time: 0.5193, average train loss: 1.6581
[09/26 12:36:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1694, average loss: 3.1162
[09/26 12:36:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.00	
[09/26 12:36:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:37:03 visual_prompt]: Epoch 26 / 100: avg data time: 4.44e-02, avg batch time: 0.4942, average train loss: 1.4795
[09/26 12:37:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1695, average loss: 3.3393
[09/26 12:37:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 60.00	
[09/26 12:37:04 visual_prompt]: Best epoch 26: best metric: 0.200
[09/26 12:37:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:37:11 visual_prompt]: Epoch 27 / 100: avg data time: 4.64e-02, avg batch time: 0.4967, average train loss: 1.3575
[09/26 12:37:13 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 3.5507
[09/26 12:37:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 66.50	
[09/26 12:37:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:37:19 visual_prompt]: Epoch 28 / 100: avg data time: 5.65e-02, avg batch time: 0.5054, average train loss: 1.1011
[09/26 12:37:21 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 4.1357
[09/26 12:37:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 12:37:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:37:28 visual_prompt]: Epoch 29 / 100: avg data time: 5.31e-02, avg batch time: 0.5033, average train loss: 1.1939
[09/26 12:37:29 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1692, average loss: 3.7655
[09/26 12:37:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 64.00	
[09/26 12:37:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:37:36 visual_prompt]: Epoch 30 / 100: avg data time: 4.99e-02, avg batch time: 0.5012, average train loss: 1.0547
[09/26 12:37:38 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 3.7104
[09/26 12:37:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 68.00	
[09/26 12:37:38 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:37:45 visual_prompt]: Epoch 31 / 100: avg data time: 6.16e-02, avg batch time: 0.5110, average train loss: 0.8276
[09/26 12:37:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1693, average loss: 4.4939
[09/26 12:37:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 12:37:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:37:53 visual_prompt]: Epoch 32 / 100: avg data time: 5.62e-02, avg batch time: 0.5062, average train loss: 0.7020
[09/26 12:37:55 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 5.0785
[09/26 12:37:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 12:37:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:38:01 visual_prompt]: Epoch 33 / 100: avg data time: 5.63e-02, avg batch time: 0.5058, average train loss: 0.6172
[09/26 12:38:03 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1694, average loss: 4.9890
[09/26 12:38:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 66.00	
[09/26 12:38:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:38:10 visual_prompt]: Epoch 34 / 100: avg data time: 6.22e-02, avg batch time: 0.5109, average train loss: 0.5638
[09/26 12:38:12 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1694, average loss: 4.6576
[09/26 12:38:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.00	
[09/26 12:38:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:38:18 visual_prompt]: Epoch 35 / 100: avg data time: 4.96e-02, avg batch time: 0.4998, average train loss: 0.4768
[09/26 12:38:20 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1694, average loss: 5.1806
[09/26 12:38:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 12:38:20 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:38:27 visual_prompt]: Epoch 36 / 100: avg data time: 6.16e-02, avg batch time: 0.5107, average train loss: 0.2799
[09/26 12:38:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1691, average loss: 5.6535
[09/26 12:38:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 67.50	
[09/26 12:38:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:38:35 visual_prompt]: Epoch 37 / 100: avg data time: 5.81e-02, avg batch time: 0.5073, average train loss: 0.2261
[09/26 12:38:37 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 6.1587
[09/26 12:38:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 12:38:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:38:44 visual_prompt]: Epoch 38 / 100: avg data time: 5.67e-02, avg batch time: 0.5057, average train loss: 0.1701
[09/26 12:38:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 5.9274
[09/26 12:38:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 65.50	
[09/26 12:38:45 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:38:52 visual_prompt]: Epoch 39 / 100: avg data time: 5.31e-02, avg batch time: 0.5031, average train loss: 0.1434
[09/26 12:38:54 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1694, average loss: 5.7488
[09/26 12:38:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 70.00	
[09/26 12:38:54 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:39:01 visual_prompt]: Epoch 40 / 100: avg data time: 6.16e-02, avg batch time: 0.5116, average train loss: 0.1865
[09/26 12:39:02 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1695, average loss: 6.1321
[09/26 12:39:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 12:39:02 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:39:09 visual_prompt]: Epoch 41 / 100: avg data time: 6.51e-02, avg batch time: 0.5134, average train loss: 0.1029
[09/26 12:39:11 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1693, average loss: 6.1053
[09/26 12:39:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 64.00	
[09/26 12:39:11 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:39:17 visual_prompt]: Epoch 42 / 100: avg data time: 5.43e-02, avg batch time: 0.5050, average train loss: 0.1016
[09/26 12:39:19 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1692, average loss: 6.2820
[09/26 12:39:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.00	
[09/26 12:39:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:39:26 visual_prompt]: Epoch 43 / 100: avg data time: 4.34e-02, avg batch time: 0.4928, average train loss: 0.0915
[09/26 12:39:27 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1694, average loss: 5.8624
[09/26 12:39:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 70.00	
[09/26 12:39:27 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:39:34 visual_prompt]: Epoch 44 / 100: avg data time: 6.04e-02, avg batch time: 0.5094, average train loss: 0.0695
[09/26 12:39:36 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1691, average loss: 6.1530
[09/26 12:39:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 64.00	
[09/26 12:39:36 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:39:43 visual_prompt]: Epoch 45 / 100: avg data time: 5.93e-02, avg batch time: 0.5077, average train loss: 0.0547
[09/26 12:39:44 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1695, average loss: 5.7794
[09/26 12:39:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 65.00	
[09/26 12:39:44 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:39:51 visual_prompt]: Epoch 46 / 100: avg data time: 5.77e-02, avg batch time: 0.5074, average train loss: 0.0335
[09/26 12:39:53 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1693, average loss: 5.9516
[09/26 12:39:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 66.00	
[09/26 12:39:53 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:39:59 visual_prompt]: Epoch 47 / 100: avg data time: 5.86e-02, avg batch time: 0.5092, average train loss: 0.0510
[09/26 12:40:01 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1691, average loss: 5.8170
[09/26 12:40:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.50	
[09/26 12:40:01 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:40:08 visual_prompt]: Epoch 48 / 100: avg data time: 5.13e-02, avg batch time: 0.5015, average train loss: 0.0386
[09/26 12:40:09 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 6.0364
[09/26 12:40:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.00	
[09/26 12:40:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:40:16 visual_prompt]: Epoch 49 / 100: avg data time: 5.50e-02, avg batch time: 0.5042, average train loss: 0.0328
[09/26 12:40:18 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1695, average loss: 5.9991
[09/26 12:40:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 67.50	
[09/26 12:40:18 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:40:25 visual_prompt]: Epoch 50 / 100: avg data time: 5.88e-02, avg batch time: 0.5093, average train loss: 0.0146
[09/26 12:40:26 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 5.8433
[09/26 12:40:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 66.00	
[09/26 12:40:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:40:33 visual_prompt]: Epoch 51 / 100: avg data time: 4.41e-02, avg batch time: 0.4946, average train loss: 0.0116
[09/26 12:40:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1694, average loss: 5.8387
[09/26 12:40:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 67.00	
[09/26 12:40:35 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:40:41 visual_prompt]: Epoch 52 / 100: avg data time: 4.63e-02, avg batch time: 0.4969, average train loss: 0.0066
[09/26 12:40:43 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1693, average loss: 5.8307
[09/26 12:40:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 69.00	
[09/26 12:40:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:40:50 visual_prompt]: Epoch 53 / 100: avg data time: 5.30e-02, avg batch time: 0.5029, average train loss: 0.0064
[09/26 12:40:51 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 5.8457
[09/26 12:40:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 12:40:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:40:58 visual_prompt]: Epoch 54 / 100: avg data time: 4.38e-02, avg batch time: 0.4952, average train loss: 0.0046
[09/26 12:41:00 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1697, average loss: 5.8677
[09/26 12:41:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.00	
[09/26 12:41:00 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:41:06 visual_prompt]: Epoch 55 / 100: avg data time: 4.55e-02, avg batch time: 0.4945, average train loss: 0.0043
[09/26 12:41:08 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1697, average loss: 5.8568
[09/26 12:41:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.50	
[09/26 12:41:08 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:41:15 visual_prompt]: Epoch 56 / 100: avg data time: 4.29e-02, avg batch time: 0.4929, average train loss: 0.0038
[09/26 12:41:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1693, average loss: 5.8348
[09/26 12:41:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 68.00	
[09/26 12:41:16 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:41:23 visual_prompt]: Epoch 57 / 100: avg data time: 3.94e-02, avg batch time: 0.4893, average train loss: 0.0041
[09/26 12:41:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1692, average loss: 5.8026
[09/26 12:41:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 68.00	
[09/26 12:41:24 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:41:31 visual_prompt]: Epoch 58 / 100: avg data time: 5.66e-02, avg batch time: 0.5070, average train loss: 0.0036
[09/26 12:41:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1692, average loss: 5.7540
[09/26 12:41:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 68.00	
[09/26 12:41:33 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:41:40 visual_prompt]: Epoch 59 / 100: avg data time: 4.89e-02, avg batch time: 0.4985, average train loss: 0.0036
[09/26 12:41:41 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1695, average loss: 5.7189
[09/26 12:41:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 68.00	
[09/26 12:41:41 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:41:48 visual_prompt]: Epoch 60 / 100: avg data time: 5.47e-02, avg batch time: 0.5050, average train loss: 0.0034
[09/26 12:41:49 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1694, average loss: 5.6973
[09/26 12:41:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 68.00	
[09/26 12:41:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:41:56 visual_prompt]: Epoch 61 / 100: avg data time: 4.41e-02, avg batch time: 0.4932, average train loss: 0.0035
[09/26 12:41:58 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1692, average loss: 5.6822
[09/26 12:41:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 68.00	
[09/26 12:41:58 visual_prompt]: Best epoch 61: best metric: 0.205
[09/26 12:41:58 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:42:04 visual_prompt]: Epoch 62 / 100: avg data time: 4.65e-02, avg batch time: 0.4972, average train loss: 0.0035
[09/26 12:42:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1698, average loss: 5.6618
[09/26 12:42:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 67.50	
[09/26 12:42:06 visual_prompt]: Best epoch 62: best metric: 0.210
[09/26 12:42:06 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:42:13 visual_prompt]: Epoch 63 / 100: avg data time: 5.43e-02, avg batch time: 0.5048, average train loss: 0.0030
[09/26 12:42:14 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1693, average loss: 5.6479
[09/26 12:42:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 67.50	
[09/26 12:42:14 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:42:21 visual_prompt]: Epoch 64 / 100: avg data time: 4.73e-02, avg batch time: 0.4973, average train loss: 0.0036
[09/26 12:42:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1695, average loss: 5.6512
[09/26 12:42:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 67.50	
[09/26 12:42:22 visual_prompt]: Best epoch 64: best metric: 0.215
[09/26 12:42:22 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:42:29 visual_prompt]: Epoch 65 / 100: avg data time: 4.62e-02, avg batch time: 0.4959, average train loss: 0.0030
[09/26 12:42:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1691, average loss: 5.6383
[09/26 12:42:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 67.00	
[09/26 12:42:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:42:38 visual_prompt]: Epoch 66 / 100: avg data time: 4.94e-02, avg batch time: 0.4990, average train loss: 0.0037
[09/26 12:42:39 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1690, average loss: 5.6232
[09/26 12:42:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 66.50	
[09/26 12:42:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:42:46 visual_prompt]: Epoch 67 / 100: avg data time: 6.02e-02, avg batch time: 0.5093, average train loss: 0.0032
[09/26 12:42:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1694, average loss: 5.6155
[09/26 12:42:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:42:48 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:42:54 visual_prompt]: Epoch 68 / 100: avg data time: 6.12e-02, avg batch time: 0.5107, average train loss: 0.0031
[09/26 12:42:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 5.6128
[09/26 12:42:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.50	
[09/26 12:42:56 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:43:03 visual_prompt]: Epoch 69 / 100: avg data time: 4.50e-02, avg batch time: 0.4963, average train loss: 0.0032
[09/26 12:43:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1696, average loss: 5.5985
[09/26 12:43:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 12:43:04 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:43:11 visual_prompt]: Epoch 70 / 100: avg data time: 5.96e-02, avg batch time: 0.5092, average train loss: 0.0034
[09/26 12:43:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1694, average loss: 5.6052
[09/26 12:43:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 67.00	
[09/26 12:43:13 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:43:19 visual_prompt]: Epoch 71 / 100: avg data time: 5.36e-02, avg batch time: 0.5036, average train loss: 0.0031
[09/26 12:43:21 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1691, average loss: 5.6048
[09/26 12:43:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:43:21 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:43:28 visual_prompt]: Epoch 72 / 100: avg data time: 4.27e-02, avg batch time: 0.4944, average train loss: 0.0031
[09/26 12:43:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 5.5858
[09/26 12:43:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:43:29 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:43:36 visual_prompt]: Epoch 73 / 100: avg data time: 4.32e-02, avg batch time: 0.4931, average train loss: 0.0032
[09/26 12:43:37 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1695, average loss: 5.5764
[09/26 12:43:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 67.00	
[09/26 12:43:37 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:43:44 visual_prompt]: Epoch 74 / 100: avg data time: 4.88e-02, avg batch time: 0.4986, average train loss: 0.0032
[09/26 12:43:46 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 5.5688
[09/26 12:43:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:43:46 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:43:53 visual_prompt]: Epoch 75 / 100: avg data time: 5.37e-02, avg batch time: 0.5036, average train loss: 0.0034
[09/26 12:43:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 5.5709
[09/26 12:43:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.50	
[09/26 12:43:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:44:01 visual_prompt]: Epoch 76 / 100: avg data time: 6.19e-02, avg batch time: 0.5107, average train loss: 0.0030
[09/26 12:44:03 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1694, average loss: 5.5711
[09/26 12:44:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 12:44:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:44:09 visual_prompt]: Epoch 77 / 100: avg data time: 6.06e-02, avg batch time: 0.5094, average train loss: 0.0029
[09/26 12:44:11 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1692, average loss: 5.5594
[09/26 12:44:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 67.00	
[09/26 12:44:11 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:44:18 visual_prompt]: Epoch 78 / 100: avg data time: 5.68e-02, avg batch time: 0.5058, average train loss: 0.0030
[09/26 12:44:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1694, average loss: 5.5535
[09/26 12:44:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:44:20 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:44:26 visual_prompt]: Epoch 79 / 100: avg data time: 6.46e-02, avg batch time: 0.5140, average train loss: 0.0030
[09/26 12:44:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 5.5509
[09/26 12:44:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:44:28 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:44:35 visual_prompt]: Epoch 80 / 100: avg data time: 6.17e-02, avg batch time: 0.5118, average train loss: 0.0028
[09/26 12:44:36 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 5.5428
[09/26 12:44:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:44:36 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:44:43 visual_prompt]: Epoch 81 / 100: avg data time: 5.49e-02, avg batch time: 0.5044, average train loss: 0.0031
[09/26 12:44:45 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1694, average loss: 5.5355
[09/26 12:44:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:44:45 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:44:52 visual_prompt]: Epoch 82 / 100: avg data time: 6.28e-02, avg batch time: 0.5119, average train loss: 0.0029
[09/26 12:44:53 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1694, average loss: 5.5305
[09/26 12:44:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 12:44:53 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:45:00 visual_prompt]: Epoch 83 / 100: avg data time: 6.91e-02, avg batch time: 0.5174, average train loss: 0.0031
[09/26 12:45:02 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1696, average loss: 5.5288
[09/26 12:45:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:45:02 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:45:09 visual_prompt]: Epoch 84 / 100: avg data time: 5.89e-02, avg batch time: 0.5077, average train loss: 0.0029
[09/26 12:45:10 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1694, average loss: 5.5243
[09/26 12:45:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:45:10 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:45:17 visual_prompt]: Epoch 85 / 100: avg data time: 5.80e-02, avg batch time: 0.5067, average train loss: 0.0030
[09/26 12:45:19 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1693, average loss: 5.5203
[09/26 12:45:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 12:45:19 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:45:26 visual_prompt]: Epoch 86 / 100: avg data time: 5.73e-02, avg batch time: 0.5056, average train loss: 0.0030
[09/26 12:45:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1694, average loss: 5.5163
[09/26 12:45:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 12:45:27 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:45:34 visual_prompt]: Epoch 87 / 100: avg data time: 5.53e-02, avg batch time: 0.5040, average train loss: 0.0031
[09/26 12:45:36 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 5.5148
[09/26 12:45:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 12:45:36 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:45:42 visual_prompt]: Epoch 88 / 100: avg data time: 5.12e-02, avg batch time: 0.5009, average train loss: 0.0030
[09/26 12:45:44 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1694, average loss: 5.5097
[09/26 12:45:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 12:45:44 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:45:51 visual_prompt]: Epoch 89 / 100: avg data time: 5.91e-02, avg batch time: 0.5090, average train loss: 0.0030
[09/26 12:45:52 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1693, average loss: 5.5090
[09/26 12:45:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:45:52 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 12:45:59 visual_prompt]: Epoch 90 / 100: avg data time: 5.55e-02, avg batch time: 0.5046, average train loss: 0.0029
[09/26 12:46:01 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1694, average loss: 5.5083
[09/26 12:46:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:01 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 12:46:08 visual_prompt]: Epoch 91 / 100: avg data time: 4.73e-02, avg batch time: 0.4974, average train loss: 0.0031
[09/26 12:46:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 5.5072
[09/26 12:46:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:09 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 12:46:16 visual_prompt]: Epoch 92 / 100: avg data time: 6.10e-02, avg batch time: 0.5109, average train loss: 0.0028
[09/26 12:46:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 5.5063
[09/26 12:46:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:18 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 12:46:24 visual_prompt]: Epoch 93 / 100: avg data time: 4.57e-02, avg batch time: 0.4970, average train loss: 0.0027
[09/26 12:46:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1695, average loss: 5.5060
[09/26 12:46:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:26 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 12:46:33 visual_prompt]: Epoch 94 / 100: avg data time: 5.24e-02, avg batch time: 0.5025, average train loss: 0.0030
[09/26 12:46:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 5.5057
[09/26 12:46:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:34 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 12:46:41 visual_prompt]: Epoch 95 / 100: avg data time: 4.69e-02, avg batch time: 0.4970, average train loss: 0.0030
[09/26 12:46:43 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 5.5058
[09/26 12:46:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:43 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 12:46:49 visual_prompt]: Epoch 96 / 100: avg data time: 4.31e-02, avg batch time: 0.4941, average train loss: 0.0026
[09/26 12:46:51 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 5.5057
[09/26 12:46:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:51 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 12:46:58 visual_prompt]: Epoch 97 / 100: avg data time: 5.26e-02, avg batch time: 0.5019, average train loss: 0.0032
[09/26 12:46:59 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1697, average loss: 5.5055
[09/26 12:46:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:46:59 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 12:47:06 visual_prompt]: Epoch 98 / 100: avg data time: 5.33e-02, avg batch time: 0.5028, average train loss: 0.0029
[09/26 12:47:08 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 5.5053
[09/26 12:47:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:47:08 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 12:47:14 visual_prompt]: Epoch 99 / 100: avg data time: 4.98e-02, avg batch time: 0.4995, average train loss: 0.0030
[09/26 12:47:16 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1694, average loss: 5.5053
[09/26 12:47:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:47:16 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 12:47:23 visual_prompt]: Epoch 100 / 100: avg data time: 5.35e-02, avg batch time: 0.5025, average train loss: 0.0030
[09/26 12:47:24 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 5.5052
[09/26 12:47:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 12:47:24 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:47:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:47:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:47:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:47:24 visual_prompt]: Training with config:
[09/26 12:47:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:47:24 visual_prompt]: Loading training data...
[09/26 12:47:24 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:47:26 visual_prompt]: Number of images: 800
[09/26 12:47:26 visual_prompt]: Number of classes: 18 / 18
[09/26 12:47:26 visual_prompt]: Loading validation data...
[09/26 12:47:26 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 12:47:26 visual_prompt]: Number of images: 200
[09/26 12:47:26 visual_prompt]: Number of classes: 18 / 18
[09/26 12:47:26 visual_prompt]: Constructing models...
[09/26 12:47:29 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 12:47:29 visual_prompt]: tuned percent:0.550
[09/26 12:47:29 visual_prompt]: Device used for model: 0
[09/26 12:47:29 visual_prompt]: Setting up Evaluator...
[09/26 12:47:29 visual_prompt]: Setting up Trainer...
[09/26 12:47:29 visual_prompt]: 	Setting up the optimizer...
[09/26 12:47:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:47:36 visual_prompt]: Epoch 1 / 100: avg data time: 5.94e-02, avg batch time: 0.5135, average train loss: 3.2523
[09/26 12:47:38 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 12:47:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 12:47:38 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 12:47:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 12:47:44 visual_prompt]: Epoch 2 / 100: avg data time: 5.62e-02, avg batch time: 0.5044, average train loss: 3.0295
[09/26 12:47:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1685, average loss: 2.9896
[09/26 12:47:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 12:47:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 12:47:53 visual_prompt]: Epoch 3 / 100: avg data time: 5.03e-02, avg batch time: 0.4990, average train loss: 2.9582
[09/26 12:47:54 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1688, average loss: 2.9276
[09/26 12:47:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 12:47:54 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 12:47:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 12:48:01 visual_prompt]: Epoch 4 / 100: avg data time: 5.09e-02, avg batch time: 0.4981, average train loss: 2.9467
[09/26 12:48:03 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1689, average loss: 2.9709
[09/26 12:48:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.50	
[09/26 12:48:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 12:48:09 visual_prompt]: Epoch 5 / 100: avg data time: 5.65e-02, avg batch time: 0.5049, average train loss: 2.9671
[09/26 12:48:11 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1686, average loss: 2.9723
[09/26 12:48:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 12:48:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 12:48:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.35e-02, avg batch time: 0.5014, average train loss: 2.9560
[09/26 12:48:19 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1690, average loss: 3.0332
[09/26 12:48:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 12:48:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 12:48:26 visual_prompt]: Epoch 7 / 100: avg data time: 5.70e-02, avg batch time: 0.5052, average train loss: 3.0084
[09/26 12:48:28 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1690, average loss: 2.9869
[09/26 12:48:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 12:48:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 12:48:35 visual_prompt]: Epoch 8 / 100: avg data time: 4.87e-02, avg batch time: 0.4984, average train loss: 3.0121
[09/26 12:48:36 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 3.0444
[09/26 12:48:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 12:48:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:48:43 visual_prompt]: Epoch 9 / 100: avg data time: 5.34e-02, avg batch time: 0.5022, average train loss: 3.0339
[09/26 12:48:44 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1692, average loss: 3.2120
[09/26 12:48:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 12:48:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:48:51 visual_prompt]: Epoch 10 / 100: avg data time: 4.64e-02, avg batch time: 0.4949, average train loss: 3.0404
[09/26 12:48:53 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1687, average loss: 2.9102
[09/26 12:48:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 12:48:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:49:00 visual_prompt]: Epoch 11 / 100: avg data time: 5.77e-02, avg batch time: 0.5067, average train loss: 2.9760
[09/26 12:49:01 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 2.9801
[09/26 12:49:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 12:49:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:49:08 visual_prompt]: Epoch 12 / 100: avg data time: 5.90e-02, avg batch time: 0.5071, average train loss: 2.9093
[09/26 12:49:10 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1690, average loss: 2.8863
[09/26 12:49:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 36.50	
[09/26 12:49:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:49:17 visual_prompt]: Epoch 13 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 2.9550
[09/26 12:49:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 2.9277
[09/26 12:49:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 33.00	
[09/26 12:49:18 visual_prompt]: Best epoch 13: best metric: 0.100
[09/26 12:49:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:49:25 visual_prompt]: Epoch 14 / 100: avg data time: 5.47e-02, avg batch time: 0.5030, average train loss: 2.9093
[09/26 12:49:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 2.9204
[09/26 12:49:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 12:49:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:49:33 visual_prompt]: Epoch 15 / 100: avg data time: 5.69e-02, avg batch time: 0.5052, average train loss: 2.8893
[09/26 12:49:35 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1692, average loss: 2.9714
[09/26 12:49:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 31.50	
[09/26 12:49:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:49:42 visual_prompt]: Epoch 16 / 100: avg data time: 4.40e-02, avg batch time: 0.4951, average train loss: 2.8795
[09/26 12:49:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 2.9216
[09/26 12:49:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 43.50	
[09/26 12:49:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:49:50 visual_prompt]: Epoch 17 / 100: avg data time: 5.36e-02, avg batch time: 0.5037, average train loss: 2.8880
[09/26 12:49:52 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1690, average loss: 2.9053
[09/26 12:49:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 38.00	
[09/26 12:49:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:49:58 visual_prompt]: Epoch 18 / 100: avg data time: 5.08e-02, avg batch time: 0.5000, average train loss: 2.7776
[09/26 12:50:00 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1693, average loss: 2.8284
[09/26 12:50:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 48.00	
[09/26 12:50:00 visual_prompt]: Best epoch 18: best metric: 0.150
[09/26 12:50:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:50:07 visual_prompt]: Epoch 19 / 100: avg data time: 4.61e-02, avg batch time: 0.4968, average train loss: 2.7243
[09/26 12:50:08 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1689, average loss: 2.6803
[09/26 12:50:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 50.00	
[09/26 12:50:08 visual_prompt]: Best epoch 19: best metric: 0.175
[09/26 12:50:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:50:15 visual_prompt]: Epoch 20 / 100: avg data time: 6.05e-02, avg batch time: 0.5114, average train loss: 2.5061
[09/26 12:50:17 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1688, average loss: 2.7090
[09/26 12:50:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 51.00	
[09/26 12:50:17 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:50:23 visual_prompt]: Epoch 21 / 100: avg data time: 4.61e-02, avg batch time: 0.4966, average train loss: 2.4049
[09/26 12:50:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1694, average loss: 2.7390
[09/26 12:50:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 58.00	
[09/26 12:50:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:50:32 visual_prompt]: Epoch 22 / 100: avg data time: 5.67e-02, avg batch time: 0.5061, average train loss: 2.2933
[09/26 12:50:34 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1692, average loss: 2.6440
[09/26 12:50:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 63.50	
[09/26 12:50:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:50:40 visual_prompt]: Epoch 23 / 100: avg data time: 6.31e-02, avg batch time: 0.5127, average train loss: 2.1173
[09/26 12:50:42 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1689, average loss: 2.7459
[09/26 12:50:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 12:50:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:50:49 visual_prompt]: Epoch 24 / 100: avg data time: 6.15e-02, avg batch time: 0.5098, average train loss: 2.1098
[09/26 12:50:51 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1695, average loss: 2.7999
[09/26 12:50:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 62.50	
[09/26 12:50:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:50:57 visual_prompt]: Epoch 25 / 100: avg data time: 5.72e-02, avg batch time: 0.5058, average train loss: 1.8508
[09/26 12:50:59 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1692, average loss: 2.8717
[09/26 12:50:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.00	
[09/26 12:50:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:51:06 visual_prompt]: Epoch 26 / 100: avg data time: 5.62e-02, avg batch time: 0.5048, average train loss: 1.6799
[09/26 12:51:07 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1694, average loss: 3.0777
[09/26 12:51:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 61.50	
[09/26 12:51:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:51:14 visual_prompt]: Epoch 27 / 100: avg data time: 5.04e-02, avg batch time: 0.5009, average train loss: 1.6743
[09/26 12:51:16 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1694, average loss: 3.1000
[09/26 12:51:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 66.50	
[09/26 12:51:16 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:51:23 visual_prompt]: Epoch 28 / 100: avg data time: 6.29e-02, avg batch time: 0.5121, average train loss: 1.4115
[09/26 12:51:24 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 3.3682
[09/26 12:51:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 67.50	
[09/26 12:51:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:51:31 visual_prompt]: Epoch 29 / 100: avg data time: 5.88e-02, avg batch time: 0.5084, average train loss: 1.3445
[09/26 12:51:33 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 3.8550
[09/26 12:51:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 61.00	
[09/26 12:51:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:51:39 visual_prompt]: Epoch 30 / 100: avg data time: 5.74e-02, avg batch time: 0.5066, average train loss: 1.4486
[09/26 12:51:41 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1691, average loss: 3.6249
[09/26 12:51:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 61.50	
[09/26 12:51:41 visual_prompt]: Best epoch 30: best metric: 0.195
[09/26 12:51:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:51:48 visual_prompt]: Epoch 31 / 100: avg data time: 6.17e-02, avg batch time: 0.5101, average train loss: 1.2783
[09/26 12:51:49 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1692, average loss: 3.4391
[09/26 12:51:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.00	
[09/26 12:51:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:51:56 visual_prompt]: Epoch 32 / 100: avg data time: 6.07e-02, avg batch time: 0.5100, average train loss: 1.0055
[09/26 12:51:58 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1693, average loss: 4.0578
[09/26 12:51:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 66.50	
[09/26 12:51:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:52:05 visual_prompt]: Epoch 33 / 100: avg data time: 6.12e-02, avg batch time: 0.5106, average train loss: 0.7667
[09/26 12:52:06 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 4.9583
[09/26 12:52:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.50	
[09/26 12:52:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:52:13 visual_prompt]: Epoch 34 / 100: avg data time: 5.19e-02, avg batch time: 0.5015, average train loss: 0.8779
[09/26 12:52:15 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1690, average loss: 4.6891
[09/26 12:52:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 63.50	
[09/26 12:52:15 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:52:22 visual_prompt]: Epoch 35 / 100: avg data time: 5.64e-02, avg batch time: 0.5055, average train loss: 0.8344
[09/26 12:52:23 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1692, average loss: 5.2562
[09/26 12:52:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 59.50	
[09/26 12:52:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:52:30 visual_prompt]: Epoch 36 / 100: avg data time: 5.59e-02, avg batch time: 0.5048, average train loss: 0.7950
[09/26 12:52:32 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1692, average loss: 4.9184
[09/26 12:52:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 63.50	
[09/26 12:52:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:52:38 visual_prompt]: Epoch 37 / 100: avg data time: 4.61e-02, avg batch time: 0.4967, average train loss: 0.6175
[09/26 12:52:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1693, average loss: 5.1990
[09/26 12:52:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.50	
[09/26 12:52:40 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:52:47 visual_prompt]: Epoch 38 / 100: avg data time: 5.79e-02, avg batch time: 0.5067, average train loss: 0.4291
[09/26 12:52:48 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1693, average loss: 6.3261
[09/26 12:52:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.50	
[09/26 12:52:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:52:55 visual_prompt]: Epoch 39 / 100: avg data time: 5.47e-02, avg batch time: 0.5037, average train loss: 0.4000
[09/26 12:52:57 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1690, average loss: 6.6302
[09/26 12:52:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 12:52:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:53:04 visual_prompt]: Epoch 40 / 100: avg data time: 5.35e-02, avg batch time: 0.5032, average train loss: 0.3350
[09/26 12:53:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1692, average loss: 6.8658
[09/26 12:53:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 12:53:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:53:12 visual_prompt]: Epoch 41 / 100: avg data time: 6.48e-02, avg batch time: 0.5136, average train loss: 0.3749
[09/26 12:53:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1692, average loss: 6.5798
[09/26 12:53:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.50	
[09/26 12:53:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:53:20 visual_prompt]: Epoch 42 / 100: avg data time: 4.67e-02, avg batch time: 0.4980, average train loss: 0.3663
[09/26 12:53:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1688, average loss: 6.2758
[09/26 12:53:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.50	
[09/26 12:53:22 visual_prompt]: Best epoch 42: best metric: 0.215
[09/26 12:53:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:53:29 visual_prompt]: Epoch 43 / 100: avg data time: 5.81e-02, avg batch time: 0.5077, average train loss: 0.2153
[09/26 12:53:30 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1695, average loss: 7.3289
[09/26 12:53:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 12:53:30 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:53:37 visual_prompt]: Epoch 44 / 100: avg data time: 5.32e-02, avg batch time: 0.5019, average train loss: 0.1120
[09/26 12:53:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 7.4357
[09/26 12:53:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 69.00	
[09/26 12:53:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:53:46 visual_prompt]: Epoch 45 / 100: avg data time: 6.12e-02, avg batch time: 0.5105, average train loss: 0.0981
[09/26 12:53:47 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1699, average loss: 7.8852
[09/26 12:53:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.50	
[09/26 12:53:47 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:53:54 visual_prompt]: Epoch 46 / 100: avg data time: 5.59e-02, avg batch time: 0.5064, average train loss: 0.1070
[09/26 12:53:56 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1694, average loss: 7.4429
[09/26 12:53:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.50	
[09/26 12:53:56 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:54:03 visual_prompt]: Epoch 47 / 100: avg data time: 5.57e-02, avg batch time: 0.5055, average train loss: 0.1220
[09/26 12:54:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 7.5825
[09/26 12:54:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.50	
[09/26 12:54:04 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:54:11 visual_prompt]: Epoch 48 / 100: avg data time: 6.12e-02, avg batch time: 0.5096, average train loss: 0.1011
[09/26 12:54:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1694, average loss: 7.7781
[09/26 12:54:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 64.00	
[09/26 12:54:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:54:19 visual_prompt]: Epoch 49 / 100: avg data time: 4.57e-02, avg batch time: 0.4962, average train loss: 0.0817
[09/26 12:54:21 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 7.2590
[09/26 12:54:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 12:54:21 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:54:28 visual_prompt]: Epoch 50 / 100: avg data time: 5.56e-02, avg batch time: 0.5046, average train loss: 0.0506
[09/26 12:54:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1697, average loss: 7.5031
[09/26 12:54:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.50	
[09/26 12:54:29 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:54:36 visual_prompt]: Epoch 51 / 100: avg data time: 6.05e-02, avg batch time: 0.5090, average train loss: 0.0413
[09/26 12:54:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 7.5212
[09/26 12:54:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.50	
[09/26 12:54:38 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:54:45 visual_prompt]: Epoch 52 / 100: avg data time: 5.72e-02, avg batch time: 0.5066, average train loss: 0.0274
[09/26 12:54:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 7.6875
[09/26 12:54:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.00	
[09/26 12:54:46 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:54:53 visual_prompt]: Epoch 53 / 100: avg data time: 6.05e-02, avg batch time: 0.5107, average train loss: 0.0126
[09/26 12:54:55 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 7.8361
[09/26 12:54:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.50	
[09/26 12:54:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:55:01 visual_prompt]: Epoch 54 / 100: avg data time: 5.07e-02, avg batch time: 0.5001, average train loss: 0.0181
[09/26 12:55:03 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1695, average loss: 7.8638
[09/26 12:55:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 12:55:03 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:55:10 visual_prompt]: Epoch 55 / 100: avg data time: 4.71e-02, avg batch time: 0.4980, average train loss: 0.0062
[09/26 12:55:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 7.6388
[09/26 12:55:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 66.00	
[09/26 12:55:11 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:55:18 visual_prompt]: Epoch 56 / 100: avg data time: 4.81e-02, avg batch time: 0.4989, average train loss: 0.0153
[09/26 12:55:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 7.9907
[09/26 12:55:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 12:55:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:55:26 visual_prompt]: Epoch 57 / 100: avg data time: 5.55e-02, avg batch time: 0.5060, average train loss: 0.0069
[09/26 12:55:28 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1694, average loss: 7.9591
[09/26 12:55:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 65.00	
[09/26 12:55:28 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:55:35 visual_prompt]: Epoch 58 / 100: avg data time: 4.66e-02, avg batch time: 0.4952, average train loss: 0.0038
[09/26 12:55:36 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1692, average loss: 7.8246
[09/26 12:55:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 12:55:36 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:55:43 visual_prompt]: Epoch 59 / 100: avg data time: 5.63e-02, avg batch time: 0.5067, average train loss: 0.0029
[09/26 12:55:45 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1701, average loss: 7.8106
[09/26 12:55:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 12:55:45 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:55:52 visual_prompt]: Epoch 60 / 100: avg data time: 5.93e-02, avg batch time: 0.5088, average train loss: 0.0040
[09/26 12:55:53 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 7.8225
[09/26 12:55:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.00	
[09/26 12:55:53 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:56:00 visual_prompt]: Epoch 61 / 100: avg data time: 6.19e-02, avg batch time: 0.5112, average train loss: 0.0033
[09/26 12:56:02 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1696, average loss: 7.8584
[09/26 12:56:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 12:56:02 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:56:08 visual_prompt]: Epoch 62 / 100: avg data time: 5.88e-02, avg batch time: 0.5073, average train loss: 0.0028
[09/26 12:56:10 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1694, average loss: 7.8908
[09/26 12:56:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 12:56:10 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:56:17 visual_prompt]: Epoch 63 / 100: avg data time: 6.81e-02, avg batch time: 0.5170, average train loss: 0.0021
[09/26 12:56:19 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1695, average loss: 7.9142
[09/26 12:56:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 64.50	
[09/26 12:56:19 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:56:26 visual_prompt]: Epoch 64 / 100: avg data time: 4.99e-02, avg batch time: 0.4996, average train loss: 0.0024
[09/26 12:56:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 7.9116
[09/26 12:56:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 12:56:27 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:56:34 visual_prompt]: Epoch 65 / 100: avg data time: 6.48e-02, avg batch time: 0.5137, average train loss: 0.0021
[09/26 12:56:36 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1694, average loss: 7.9054
[09/26 12:56:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 12:56:36 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:56:43 visual_prompt]: Epoch 66 / 100: avg data time: 6.29e-02, avg batch time: 0.5121, average train loss: 0.0022
[09/26 12:56:44 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1696, average loss: 7.9052
[09/26 12:56:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 12:56:44 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:56:51 visual_prompt]: Epoch 67 / 100: avg data time: 6.11e-02, avg batch time: 0.5105, average train loss: 0.0022
[09/26 12:56:53 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1694, average loss: 7.8993
[09/26 12:56:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 12:56:53 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:57:00 visual_prompt]: Epoch 68 / 100: avg data time: 5.89e-02, avg batch time: 0.5082, average train loss: 0.0020
[09/26 12:57:01 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1697, average loss: 7.8952
[09/26 12:57:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 12:57:01 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:57:08 visual_prompt]: Epoch 69 / 100: avg data time: 5.94e-02, avg batch time: 0.5079, average train loss: 0.0020
[09/26 12:57:10 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 7.8924
[09/26 12:57:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 12:57:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:57:17 visual_prompt]: Epoch 70 / 100: avg data time: 6.01e-02, avg batch time: 0.5088, average train loss: 0.0018
[09/26 12:57:18 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 7.8975
[09/26 12:57:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 12:57:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:57:25 visual_prompt]: Epoch 71 / 100: avg data time: 4.18e-02, avg batch time: 0.4928, average train loss: 0.0023
[09/26 12:57:26 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1694, average loss: 7.8976
[09/26 12:57:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 12:57:26 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:57:33 visual_prompt]: Epoch 72 / 100: avg data time: 4.20e-02, avg batch time: 0.4914, average train loss: 0.0018
[09/26 12:57:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1691, average loss: 7.8751
[09/26 12:57:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 12:57:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:57:41 visual_prompt]: Epoch 73 / 100: avg data time: 4.74e-02, avg batch time: 0.4984, average train loss: 0.0019
[09/26 12:57:43 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1695, average loss: 7.8743
[09/26 12:57:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.00	
[09/26 12:57:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:57:50 visual_prompt]: Epoch 74 / 100: avg data time: 4.27e-02, avg batch time: 0.4922, average train loss: 0.0019
[09/26 12:57:51 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 7.8882
[09/26 12:57:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 12:57:51 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:57:58 visual_prompt]: Epoch 75 / 100: avg data time: 5.09e-02, avg batch time: 0.5007, average train loss: 0.0022
[09/26 12:58:00 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 7.8976
[09/26 12:58:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 12:58:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:58:06 visual_prompt]: Epoch 76 / 100: avg data time: 4.24e-02, avg batch time: 0.4964, average train loss: 0.0016
[09/26 12:58:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 7.9028
[09/26 12:58:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.00	
[09/26 12:58:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:58:15 visual_prompt]: Epoch 77 / 100: avg data time: 4.93e-02, avg batch time: 0.4989, average train loss: 0.0020
[09/26 12:58:16 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1695, average loss: 7.9062
[09/26 12:58:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 12:58:16 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:58:23 visual_prompt]: Epoch 78 / 100: avg data time: 5.30e-02, avg batch time: 0.5049, average train loss: 0.0016
[09/26 12:58:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1692, average loss: 7.9127
[09/26 12:58:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 12:58:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:58:32 visual_prompt]: Epoch 79 / 100: avg data time: 6.01e-02, avg batch time: 0.5101, average train loss: 0.0016
[09/26 12:58:33 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 7.9226
[09/26 12:58:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.00	
[09/26 12:58:33 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:58:40 visual_prompt]: Epoch 80 / 100: avg data time: 5.33e-02, avg batch time: 0.5021, average train loss: 0.0018
[09/26 12:58:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1694, average loss: 7.9334
[09/26 12:58:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 12:58:41 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:58:48 visual_prompt]: Epoch 81 / 100: avg data time: 5.96e-02, avg batch time: 0.5085, average train loss: 0.0023
[09/26 12:58:50 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 7.9212
[09/26 12:58:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 12:58:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:58:57 visual_prompt]: Epoch 82 / 100: avg data time: 5.85e-02, avg batch time: 0.5079, average train loss: 0.0016
[09/26 12:58:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1692, average loss: 7.9184
[09/26 12:58:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 12:58:58 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:59:05 visual_prompt]: Epoch 83 / 100: avg data time: 5.93e-02, avg batch time: 0.5079, average train loss: 0.0023
[09/26 12:59:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 7.9238
[09/26 12:59:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 12:59:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:59:13 visual_prompt]: Epoch 84 / 100: avg data time: 4.81e-02, avg batch time: 0.4998, average train loss: 0.0015
[09/26 12:59:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 7.9257
[09/26 12:59:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 12:59:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:59:22 visual_prompt]: Epoch 85 / 100: avg data time: 5.45e-02, avg batch time: 0.5057, average train loss: 0.0024
[09/26 12:59:23 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1690, average loss: 7.9263
[09/26 12:59:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 12:59:23 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:59:30 visual_prompt]: Epoch 86 / 100: avg data time: 4.66e-02, avg batch time: 0.4997, average train loss: 0.0023
[09/26 12:59:32 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1693, average loss: 7.9315
[09/26 12:59:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 12:59:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:59:39 visual_prompt]: Epoch 87 / 100: avg data time: 6.03e-02, avg batch time: 0.5099, average train loss: 0.0014
[09/26 12:59:40 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 7.9342
[09/26 12:59:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 12:59:40 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:59:47 visual_prompt]: Epoch 88 / 100: avg data time: 6.17e-02, avg batch time: 0.5108, average train loss: 0.0018
[09/26 12:59:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1689, average loss: 7.9358
[09/26 12:59:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 12:59:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:59:55 visual_prompt]: Epoch 89 / 100: avg data time: 4.56e-02, avg batch time: 0.4965, average train loss: 0.0016
[09/26 12:59:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1697, average loss: 7.9356
[09/26 12:59:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 12:59:57 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 13:00:04 visual_prompt]: Epoch 90 / 100: avg data time: 4.63e-02, avg batch time: 0.4960, average train loss: 0.0013
[09/26 13:00:05 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1696, average loss: 7.9362
[09/26 13:00:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:05 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 13:00:12 visual_prompt]: Epoch 91 / 100: avg data time: 4.62e-02, avg batch time: 0.4974, average train loss: 0.0016
[09/26 13:00:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1694, average loss: 7.9375
[09/26 13:00:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:13 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 13:00:20 visual_prompt]: Epoch 92 / 100: avg data time: 4.60e-02, avg batch time: 0.4958, average train loss: 0.0017
[09/26 13:00:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1697, average loss: 7.9372
[09/26 13:00:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:22 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 13:00:28 visual_prompt]: Epoch 93 / 100: avg data time: 4.35e-02, avg batch time: 0.4924, average train loss: 0.0016
[09/26 13:00:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1696, average loss: 7.9372
[09/26 13:00:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:30 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 13:00:37 visual_prompt]: Epoch 94 / 100: avg data time: 4.30e-02, avg batch time: 0.4946, average train loss: 0.0016
[09/26 13:00:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1696, average loss: 7.9372
[09/26 13:00:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:38 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 13:00:45 visual_prompt]: Epoch 95 / 100: avg data time: 5.96e-02, avg batch time: 0.5089, average train loss: 0.0020
[09/26 13:00:47 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1695, average loss: 7.9373
[09/26 13:00:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 13:00:53 visual_prompt]: Epoch 96 / 100: avg data time: 4.74e-02, avg batch time: 0.4985, average train loss: 0.0018
[09/26 13:00:55 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1693, average loss: 7.9376
[09/26 13:00:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:00:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 13:01:02 visual_prompt]: Epoch 97 / 100: avg data time: 5.65e-02, avg batch time: 0.5052, average train loss: 0.0013
[09/26 13:01:03 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.1692, average loss: 7.9378
[09/26 13:01:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:01:03 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 13:01:10 visual_prompt]: Epoch 98 / 100: avg data time: 6.11e-02, avg batch time: 0.5102, average train loss: 0.0015
[09/26 13:01:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1690, average loss: 7.9378
[09/26 13:01:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:01:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 13:01:18 visual_prompt]: Epoch 99 / 100: avg data time: 5.26e-02, avg batch time: 0.5021, average train loss: 0.0013
[09/26 13:01:20 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 7.9378
[09/26 13:01:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:01:20 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 13:01:27 visual_prompt]: Epoch 100 / 100: avg data time: 4.98e-02, avg batch time: 0.5012, average train loss: 0.0015
[09/26 13:01:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1694, average loss: 7.9378
[09/26 13:01:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 13:01:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:01:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:01:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:01:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:01:28 visual_prompt]: Training with config:
[09/26 13:01:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:01:28 visual_prompt]: Loading training data...
[09/26 13:01:28 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:01:30 visual_prompt]: Number of images: 800
[09/26 13:01:30 visual_prompt]: Number of classes: 18 / 18
[09/26 13:01:30 visual_prompt]: Loading validation data...
[09/26 13:01:30 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:01:30 visual_prompt]: Number of images: 200
[09/26 13:01:30 visual_prompt]: Number of classes: 18 / 18
[09/26 13:01:30 visual_prompt]: Constructing models...
[09/26 13:01:32 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 13:01:32 visual_prompt]: tuned percent:0.550
[09/26 13:01:33 visual_prompt]: Device used for model: 0
[09/26 13:01:33 visual_prompt]: Setting up Evaluator...
[09/26 13:01:33 visual_prompt]: Setting up Trainer...
[09/26 13:01:33 visual_prompt]: 	Setting up the optimizer...
[09/26 13:01:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:01:40 visual_prompt]: Epoch 1 / 100: avg data time: 5.84e-02, avg batch time: 0.5089, average train loss: 3.2470
[09/26 13:01:41 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 13:01:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 13:01:41 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 13:01:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 13:01:48 visual_prompt]: Epoch 2 / 100: avg data time: 5.58e-02, avg batch time: 0.5038, average train loss: 2.9824
[09/26 13:01:49 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1689, average loss: 2.9560
[09/26 13:01:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.50	
[09/26 13:01:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 13:01:56 visual_prompt]: Epoch 3 / 100: avg data time: 5.55e-02, avg batch time: 0.5027, average train loss: 2.9087
[09/26 13:01:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1685, average loss: 2.9013
[09/26 13:01:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 13:01:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 13:02:05 visual_prompt]: Epoch 4 / 100: avg data time: 5.92e-02, avg batch time: 0.5083, average train loss: 2.9114
[09/26 13:02:06 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1685, average loss: 2.9292
[09/26 13:02:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 13:02:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 13:02:13 visual_prompt]: Epoch 5 / 100: avg data time: 5.31e-02, avg batch time: 0.5015, average train loss: 2.9297
[09/26 13:02:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1688, average loss: 2.9175
[09/26 13:02:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 13:02:15 visual_prompt]: Best epoch 5: best metric: 0.085
[09/26 13:02:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 13:02:22 visual_prompt]: Epoch 6 / 100: avg data time: 6.10e-02, avg batch time: 0.5086, average train loss: 2.9095
[09/26 13:02:23 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 2.9021
[09/26 13:02:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 13:02:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 13:02:30 visual_prompt]: Epoch 7 / 100: avg data time: 5.08e-02, avg batch time: 0.4991, average train loss: 2.9202
[09/26 13:02:31 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 2.9457
[09/26 13:02:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 13:02:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 13:02:38 visual_prompt]: Epoch 8 / 100: avg data time: 5.27e-02, avg batch time: 0.5006, average train loss: 2.9376
[09/26 13:02:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 2.9071
[09/26 13:02:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 13:02:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 13:02:46 visual_prompt]: Epoch 9 / 100: avg data time: 4.72e-02, avg batch time: 0.4977, average train loss: 2.9202
[09/26 13:02:48 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1690, average loss: 2.9420
[09/26 13:02:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.00	
[09/26 13:02:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 13:02:55 visual_prompt]: Epoch 10 / 100: avg data time: 5.49e-02, avg batch time: 0.5021, average train loss: 2.9265
[09/26 13:02:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 2.9451
[09/26 13:02:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 13:02:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 13:03:03 visual_prompt]: Epoch 11 / 100: avg data time: 5.71e-02, avg batch time: 0.5064, average train loss: 2.9268
[09/26 13:03:05 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1687, average loss: 2.8996
[09/26 13:03:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 13:03:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 13:03:11 visual_prompt]: Epoch 12 / 100: avg data time: 5.57e-02, avg batch time: 0.5034, average train loss: 2.9291
[09/26 13:03:13 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1687, average loss: 3.1022
[09/26 13:03:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 13:03:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 13:03:20 visual_prompt]: Epoch 13 / 100: avg data time: 6.57e-02, avg batch time: 0.5143, average train loss: 2.9460
[09/26 13:03:21 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1687, average loss: 2.8981
[09/26 13:03:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 13:03:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 13:03:28 visual_prompt]: Epoch 14 / 100: avg data time: 5.44e-02, avg batch time: 0.5023, average train loss: 2.9388
[09/26 13:03:30 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1687, average loss: 2.9518
[09/26 13:03:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 13:03:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 13:03:37 visual_prompt]: Epoch 15 / 100: avg data time: 6.50e-02, avg batch time: 0.5130, average train loss: 2.9280
[09/26 13:03:38 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1686, average loss: 2.9455
[09/26 13:03:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 13:03:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 13:03:45 visual_prompt]: Epoch 16 / 100: avg data time: 5.81e-02, avg batch time: 0.5054, average train loss: 2.9380
[09/26 13:03:47 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1691, average loss: 2.9398
[09/26 13:03:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 13:03:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 13:03:54 visual_prompt]: Epoch 17 / 100: avg data time: 5.80e-02, avg batch time: 0.5054, average train loss: 2.9055
[09/26 13:03:55 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 2.9199
[09/26 13:03:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:03:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 13:04:02 visual_prompt]: Epoch 18 / 100: avg data time: 6.44e-02, avg batch time: 0.5119, average train loss: 2.9366
[09/26 13:04:04 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1694, average loss: 2.9564
[09/26 13:04:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 13:04:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 13:04:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.48e-02, avg batch time: 0.5069, average train loss: 2.9522
[09/26 13:04:12 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1692, average loss: 2.9887
[09/26 13:04:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 13:04:12 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 13:04:19 visual_prompt]: Epoch 20 / 100: avg data time: 5.46e-02, avg batch time: 0.5027, average train loss: 2.9491
[09/26 13:04:21 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1690, average loss: 2.9372
[09/26 13:04:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.00	
[09/26 13:04:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 13:04:27 visual_prompt]: Epoch 21 / 100: avg data time: 5.09e-02, avg batch time: 0.5015, average train loss: 2.9506
[09/26 13:04:29 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 2.9307
[09/26 13:04:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 13:04:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 13:04:36 visual_prompt]: Epoch 22 / 100: avg data time: 4.72e-02, avg batch time: 0.4989, average train loss: 2.9186
[09/26 13:04:37 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1693, average loss: 2.9271
[09/26 13:04:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 13:04:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 13:04:44 visual_prompt]: Epoch 23 / 100: avg data time: 4.79e-02, avg batch time: 0.4963, average train loss: 2.9325
[09/26 13:04:46 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1690, average loss: 2.9487
[09/26 13:04:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 13:04:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 13:04:52 visual_prompt]: Epoch 24 / 100: avg data time: 4.96e-02, avg batch time: 0.4964, average train loss: 2.9359
[09/26 13:04:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1687, average loss: 2.9144
[09/26 13:04:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.50	
[09/26 13:04:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 13:05:01 visual_prompt]: Epoch 25 / 100: avg data time: 5.41e-02, avg batch time: 0.5022, average train loss: 2.9161
[09/26 13:05:02 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1689, average loss: 2.9248
[09/26 13:05:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 13:05:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 13:05:09 visual_prompt]: Epoch 26 / 100: avg data time: 5.25e-02, avg batch time: 0.5004, average train loss: 2.9097
[09/26 13:05:11 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1689, average loss: 2.9481
[09/26 13:05:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 23.00	
[09/26 13:05:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 13:05:17 visual_prompt]: Epoch 27 / 100: avg data time: 5.49e-02, avg batch time: 0.5047, average train loss: 2.9170
[09/26 13:05:19 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1693, average loss: 2.9187
[09/26 13:05:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 13:05:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 13:05:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.56e-02, avg batch time: 0.5027, average train loss: 2.8995
[09/26 13:05:27 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1686, average loss: 2.9334
[09/26 13:05:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 13:05:27 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 13:05:34 visual_prompt]: Epoch 29 / 100: avg data time: 5.53e-02, avg batch time: 0.5023, average train loss: 2.9216
[09/26 13:05:36 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1687, average loss: 2.9164
[09/26 13:05:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 13:05:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 13:05:43 visual_prompt]: Epoch 30 / 100: avg data time: 6.11e-02, avg batch time: 0.5083, average train loss: 2.9087
[09/26 13:05:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 2.9056
[09/26 13:05:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 13:05:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 13:05:51 visual_prompt]: Epoch 31 / 100: avg data time: 5.23e-02, avg batch time: 0.5011, average train loss: 2.9030
[09/26 13:05:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1684, average loss: 2.9087
[09/26 13:05:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 13:05:52 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 13:05:59 visual_prompt]: Epoch 32 / 100: avg data time: 4.73e-02, avg batch time: 0.4951, average train loss: 2.9151
[09/26 13:06:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1687, average loss: 2.9335
[09/26 13:06:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 13:06:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 13:06:07 visual_prompt]: Epoch 33 / 100: avg data time: 4.68e-02, avg batch time: 0.4973, average train loss: 2.9274
[09/26 13:06:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1685, average loss: 2.9041
[09/26 13:06:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 28.50	
[09/26 13:06:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:06:16 visual_prompt]: Epoch 34 / 100: avg data time: 5.95e-02, avg batch time: 0.5083, average train loss: 2.9117
[09/26 13:06:17 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1687, average loss: 2.9379
[09/26 13:06:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 13:06:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:06:24 visual_prompt]: Epoch 35 / 100: avg data time: 5.44e-02, avg batch time: 0.5032, average train loss: 2.9093
[09/26 13:06:26 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 2.9092
[09/26 13:06:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:06:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:06:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.47e-02, avg batch time: 0.5026, average train loss: 2.9119
[09/26 13:06:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 2.9166
[09/26 13:06:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 13:06:34 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:06:41 visual_prompt]: Epoch 37 / 100: avg data time: 5.77e-02, avg batch time: 0.5067, average train loss: 2.9059
[09/26 13:06:42 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1689, average loss: 2.8999
[09/26 13:06:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 13:06:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:06:49 visual_prompt]: Epoch 38 / 100: avg data time: 5.77e-02, avg batch time: 0.5063, average train loss: 2.9112
[09/26 13:06:51 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1687, average loss: 2.9212
[09/26 13:06:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 13:06:51 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:06:58 visual_prompt]: Epoch 39 / 100: avg data time: 5.31e-02, avg batch time: 0.5036, average train loss: 2.9002
[09/26 13:06:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 2.9097
[09/26 13:06:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 13:06:59 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:07:06 visual_prompt]: Epoch 40 / 100: avg data time: 6.24e-02, avg batch time: 0.5111, average train loss: 2.9129
[09/26 13:07:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 2.9012
[09/26 13:07:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 13:07:08 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:07:14 visual_prompt]: Epoch 41 / 100: avg data time: 5.21e-02, avg batch time: 0.5011, average train loss: 2.9075
[09/26 13:07:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1689, average loss: 2.9149
[09/26 13:07:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 13:07:16 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:07:23 visual_prompt]: Epoch 42 / 100: avg data time: 4.59e-02, avg batch time: 0.4950, average train loss: 2.9159
[09/26 13:07:24 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 2.9134
[09/26 13:07:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 13:07:24 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:07:31 visual_prompt]: Epoch 43 / 100: avg data time: 5.58e-02, avg batch time: 0.5048, average train loss: 2.9059
[09/26 13:07:33 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 2.9196
[09/26 13:07:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 13:07:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:07:40 visual_prompt]: Epoch 44 / 100: avg data time: 5.35e-02, avg batch time: 0.5022, average train loss: 2.9092
[09/26 13:07:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 2.9159
[09/26 13:07:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 13:07:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:07:48 visual_prompt]: Epoch 45 / 100: avg data time: 5.43e-02, avg batch time: 0.5029, average train loss: 2.9050
[09/26 13:07:49 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1689, average loss: 2.9074
[09/26 13:07:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 13:07:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:07:56 visual_prompt]: Epoch 46 / 100: avg data time: 5.95e-02, avg batch time: 0.5085, average train loss: 2.9037
[09/26 13:07:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1685, average loss: 2.9127
[09/26 13:07:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 23.00	
[09/26 13:07:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:08:05 visual_prompt]: Epoch 47 / 100: avg data time: 5.98e-02, avg batch time: 0.5079, average train loss: 2.9036
[09/26 13:08:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 2.9132
[09/26 13:08:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 13:08:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:08:13 visual_prompt]: Epoch 48 / 100: avg data time: 5.14e-02, avg batch time: 0.4993, average train loss: 2.9074
[09/26 13:08:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1687, average loss: 2.9248
[09/26 13:08:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 13:08:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:08:21 visual_prompt]: Epoch 49 / 100: avg data time: 5.58e-02, avg batch time: 0.5037, average train loss: 2.8995
[09/26 13:08:23 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 2.9119
[09/26 13:08:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 13:08:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:08:30 visual_prompt]: Epoch 50 / 100: avg data time: 5.73e-02, avg batch time: 0.5074, average train loss: 2.8983
[09/26 13:08:31 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1693, average loss: 2.9033
[09/26 13:08:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 13:08:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:08:38 visual_prompt]: Epoch 51 / 100: avg data time: 6.39e-02, avg batch time: 0.5117, average train loss: 2.8981
[09/26 13:08:40 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1692, average loss: 2.9101
[09/26 13:08:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 13:08:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:08:47 visual_prompt]: Epoch 52 / 100: avg data time: 5.38e-02, avg batch time: 0.5017, average train loss: 2.8953
[09/26 13:08:48 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 2.9127
[09/26 13:08:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 13:08:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:08:55 visual_prompt]: Epoch 53 / 100: avg data time: 5.51e-02, avg batch time: 0.5036, average train loss: 2.8999
[09/26 13:08:57 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1693, average loss: 2.9116
[09/26 13:08:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 13:08:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:09:03 visual_prompt]: Epoch 54 / 100: avg data time: 5.64e-02, avg batch time: 0.5042, average train loss: 2.9005
[09/26 13:09:05 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1690, average loss: 2.9220
[09/26 13:09:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.50	
[09/26 13:09:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:09:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.03e-02, avg batch time: 0.5091, average train loss: 2.8982
[09/26 13:09:13 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1690, average loss: 2.9005
[09/26 13:09:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 13:09:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:09:20 visual_prompt]: Epoch 56 / 100: avg data time: 6.11e-02, avg batch time: 0.5081, average train loss: 2.8924
[09/26 13:09:22 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1685, average loss: 2.9223
[09/26 13:09:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 13:09:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:09:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.83e-02, avg batch time: 0.5059, average train loss: 2.8940
[09/26 13:09:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 2.9020
[09/26 13:09:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 13:09:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:09:37 visual_prompt]: Epoch 58 / 100: avg data time: 5.64e-02, avg batch time: 0.5038, average train loss: 2.8933
[09/26 13:09:39 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1689, average loss: 2.9084
[09/26 13:09:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 13:09:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:09:46 visual_prompt]: Epoch 59 / 100: avg data time: 6.12e-02, avg batch time: 0.5102, average train loss: 2.8909
[09/26 13:09:47 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 2.9145
[09/26 13:09:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 13:09:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:09:54 visual_prompt]: Epoch 60 / 100: avg data time: 5.85e-02, avg batch time: 0.5070, average train loss: 2.8900
[09/26 13:09:56 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1691, average loss: 2.9042
[09/26 13:09:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 27.00	
[09/26 13:09:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:10:02 visual_prompt]: Epoch 61 / 100: avg data time: 5.25e-02, avg batch time: 0.5001, average train loss: 2.8918
[09/26 13:10:04 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 2.9016
[09/26 13:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 13:10:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:10:11 visual_prompt]: Epoch 62 / 100: avg data time: 5.20e-02, avg batch time: 0.4999, average train loss: 2.8966
[09/26 13:10:12 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1691, average loss: 2.9031
[09/26 13:10:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 13:10:12 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:10:19 visual_prompt]: Epoch 63 / 100: avg data time: 5.94e-02, avg batch time: 0.5079, average train loss: 2.8931
[09/26 13:10:21 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 2.9053
[09/26 13:10:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 13:10:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:10:28 visual_prompt]: Epoch 64 / 100: avg data time: 5.92e-02, avg batch time: 0.5080, average train loss: 2.8913
[09/26 13:10:29 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1693, average loss: 2.9027
[09/26 13:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 13:10:29 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:10:36 visual_prompt]: Epoch 65 / 100: avg data time: 5.80e-02, avg batch time: 0.5057, average train loss: 2.8921
[09/26 13:10:38 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1690, average loss: 2.9125
[09/26 13:10:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.50	
[09/26 13:10:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:10:44 visual_prompt]: Epoch 66 / 100: avg data time: 4.56e-02, avg batch time: 0.4937, average train loss: 2.8941
[09/26 13:10:46 visual_prompt]: Inference (val):avg data time: 4.74e-05, avg batch time: 0.1690, average loss: 2.9132
[09/26 13:10:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 13:10:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:10:53 visual_prompt]: Epoch 67 / 100: avg data time: 5.72e-02, avg batch time: 0.5042, average train loss: 2.8929
[09/26 13:10:54 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1688, average loss: 2.9042
[09/26 13:10:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 13:10:54 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:11:01 visual_prompt]: Epoch 68 / 100: avg data time: 5.65e-02, avg batch time: 0.5049, average train loss: 2.8884
[09/26 13:11:03 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1692, average loss: 2.9054
[09/26 13:11:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 13:11:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:11:10 visual_prompt]: Epoch 69 / 100: avg data time: 5.49e-02, avg batch time: 0.5042, average train loss: 2.8880
[09/26 13:11:11 visual_prompt]: Inference (val):avg data time: 5.56e-05, avg batch time: 0.1689, average loss: 2.9060
[09/26 13:11:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 13:11:11 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:11:18 visual_prompt]: Epoch 70 / 100: avg data time: 5.55e-02, avg batch time: 0.5036, average train loss: 2.8870
[09/26 13:11:19 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1688, average loss: 2.9115
[09/26 13:11:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 13:11:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:11:26 visual_prompt]: Epoch 71 / 100: avg data time: 4.33e-02, avg batch time: 0.4911, average train loss: 2.8877
[09/26 13:11:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1686, average loss: 2.9136
[09/26 13:11:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 13:11:28 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:11:35 visual_prompt]: Epoch 72 / 100: avg data time: 5.11e-02, avg batch time: 0.4986, average train loss: 2.8876
[09/26 13:11:36 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1687, average loss: 2.9004
[09/26 13:11:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:11:36 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:11:43 visual_prompt]: Epoch 73 / 100: avg data time: 5.03e-02, avg batch time: 0.4986, average train loss: 2.8864
[09/26 13:11:44 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 2.9056
[09/26 13:11:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:11:44 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:11:51 visual_prompt]: Epoch 74 / 100: avg data time: 5.32e-02, avg batch time: 0.5018, average train loss: 2.8939
[09/26 13:11:53 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1689, average loss: 2.9137
[09/26 13:11:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 13:11:53 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:11:59 visual_prompt]: Epoch 75 / 100: avg data time: 4.25e-02, avg batch time: 0.4916, average train loss: 2.8905
[09/26 13:12:01 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 2.8976
[09/26 13:12:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 13:12:01 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:12:08 visual_prompt]: Epoch 76 / 100: avg data time: 5.62e-02, avg batch time: 0.5053, average train loss: 2.8937
[09/26 13:12:09 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1687, average loss: 2.9134
[09/26 13:12:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:12:09 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:12:16 visual_prompt]: Epoch 77 / 100: avg data time: 4.95e-02, avg batch time: 0.4978, average train loss: 2.8921
[09/26 13:12:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1692, average loss: 2.9109
[09/26 13:12:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:12:18 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:12:25 visual_prompt]: Epoch 78 / 100: avg data time: 5.71e-02, avg batch time: 0.5056, average train loss: 2.8915
[09/26 13:12:26 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1691, average loss: 2.9085
[09/26 13:12:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 13:12:26 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:12:33 visual_prompt]: Epoch 79 / 100: avg data time: 4.89e-02, avg batch time: 0.4976, average train loss: 2.8916
[09/26 13:12:34 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 2.9057
[09/26 13:12:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 13:12:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:12:41 visual_prompt]: Epoch 80 / 100: avg data time: 4.47e-02, avg batch time: 0.4939, average train loss: 2.8860
[09/26 13:12:43 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 2.9119
[09/26 13:12:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 13:12:43 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:12:49 visual_prompt]: Epoch 81 / 100: avg data time: 5.38e-02, avg batch time: 0.5031, average train loss: 2.8869
[09/26 13:12:51 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1688, average loss: 2.9027
[09/26 13:12:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 13:12:51 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:12:58 visual_prompt]: Epoch 82 / 100: avg data time: 4.30e-02, avg batch time: 0.4945, average train loss: 2.8816
[09/26 13:12:59 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 2.9020
[09/26 13:12:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 31.00	
[09/26 13:12:59 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:13:06 visual_prompt]: Epoch 83 / 100: avg data time: 4.33e-02, avg batch time: 0.4947, average train loss: 2.8799
[09/26 13:13:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 2.9102
[09/26 13:13:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 28.50	
[09/26 13:13:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:13:14 visual_prompt]: Epoch 84 / 100: avg data time: 4.44e-02, avg batch time: 0.4927, average train loss: 2.8795
[09/26 13:13:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 2.9034
[09/26 13:13:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.00	
[09/26 13:13:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:13:22 visual_prompt]: Epoch 85 / 100: avg data time: 4.46e-02, avg batch time: 0.4958, average train loss: 2.8767
[09/26 13:13:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 2.9218
[09/26 13:13:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 13:13:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:13:30 visual_prompt]: Epoch 86 / 100: avg data time: 4.84e-02, avg batch time: 0.4974, average train loss: 2.8835
[09/26 13:13:32 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 2.8996
[09/26 13:13:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 13:13:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:13:39 visual_prompt]: Epoch 87 / 100: avg data time: 5.44e-02, avg batch time: 0.5034, average train loss: 2.8779
[09/26 13:13:40 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1689, average loss: 2.9034
[09/26 13:13:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 13:13:40 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:13:47 visual_prompt]: Epoch 88 / 100: avg data time: 5.86e-02, avg batch time: 0.5066, average train loss: 2.8746
[09/26 13:13:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 2.9051
[09/26 13:13:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 13:13:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:13:56 visual_prompt]: Epoch 89 / 100: avg data time: 5.75e-02, avg batch time: 0.5057, average train loss: 2.8718
[09/26 13:13:57 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 2.9070
[09/26 13:13:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 13:13:57 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:14:04 visual_prompt]: Epoch 90 / 100: avg data time: 5.60e-02, avg batch time: 0.5039, average train loss: 2.8703
[09/26 13:14:05 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1700, average loss: 2.9111
[09/26 13:14:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 13:14:05 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:14:12 visual_prompt]: Epoch 91 / 100: avg data time: 4.53e-02, avg batch time: 0.4941, average train loss: 2.8684
[09/26 13:14:14 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 2.9105
[09/26 13:14:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 13:14:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:14:21 visual_prompt]: Epoch 92 / 100: avg data time: 4.86e-02, avg batch time: 0.4996, average train loss: 2.8650
[09/26 13:14:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 2.9120
[09/26 13:14:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 13:14:22 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:14:29 visual_prompt]: Epoch 93 / 100: avg data time: 5.94e-02, avg batch time: 0.5074, average train loss: 2.8637
[09/26 13:14:31 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1687, average loss: 2.9134
[09/26 13:14:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 13:14:31 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:14:37 visual_prompt]: Epoch 94 / 100: avg data time: 4.85e-02, avg batch time: 0.4982, average train loss: 2.8600
[09/26 13:14:39 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1689, average loss: 2.9083
[09/26 13:14:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 13:14:39 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:14:46 visual_prompt]: Epoch 95 / 100: avg data time: 6.04e-02, avg batch time: 0.5086, average train loss: 2.8614
[09/26 13:14:47 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1693, average loss: 2.9049
[09/26 13:14:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 13:14:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:14:54 visual_prompt]: Epoch 96 / 100: avg data time: 6.18e-02, avg batch time: 0.5105, average train loss: 2.8555
[09/26 13:14:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1692, average loss: 2.9096
[09/26 13:14:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 27.50	
[09/26 13:14:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:15:02 visual_prompt]: Epoch 97 / 100: avg data time: 5.67e-02, avg batch time: 0.5047, average train loss: 2.8536
[09/26 13:15:04 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1693, average loss: 2.9056
[09/26 13:15:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.50	
[09/26 13:15:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:15:11 visual_prompt]: Epoch 98 / 100: avg data time: 4.40e-02, avg batch time: 0.4937, average train loss: 2.8474
[09/26 13:15:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 2.9125
[09/26 13:15:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 13:15:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:15:19 visual_prompt]: Epoch 99 / 100: avg data time: 5.83e-02, avg batch time: 0.5077, average train loss: 2.8406
[09/26 13:15:21 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 2.9080
[09/26 13:15:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.50	
[09/26 13:15:21 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:15:27 visual_prompt]: Epoch 100 / 100: avg data time: 5.15e-02, avg batch time: 0.5027, average train loss: 2.8381
[09/26 13:15:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1692, average loss: 2.9071
[09/26 13:15:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 13:15:29 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:15:29 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:15:29 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:15:29 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:15:29 visual_prompt]: Training with config:
[09/26 13:15:29 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:15:29 visual_prompt]: Loading training data...
[09/26 13:15:29 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:15:30 visual_prompt]: Number of images: 800
[09/26 13:15:30 visual_prompt]: Number of classes: 18 / 18
[09/26 13:15:30 visual_prompt]: Loading validation data...
[09/26 13:15:30 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:15:31 visual_prompt]: Number of images: 200
[09/26 13:15:31 visual_prompt]: Number of classes: 18 / 18
[09/26 13:15:31 visual_prompt]: Constructing models...
[09/26 13:15:33 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 13:15:33 visual_prompt]: tuned percent:0.550
[09/26 13:15:33 visual_prompt]: Device used for model: 0
[09/26 13:15:33 visual_prompt]: Setting up Evaluator...
[09/26 13:15:33 visual_prompt]: Setting up Trainer...
[09/26 13:15:33 visual_prompt]: 	Setting up the optimizer...
[09/26 13:15:33 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:15:40 visual_prompt]: Epoch 1 / 100: avg data time: 5.00e-02, avg batch time: 0.4992, average train loss: 3.2469
[09/26 13:15:42 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1684, average loss: 3.1895
[09/26 13:15:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 13:15:42 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 13:15:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 13:15:48 visual_prompt]: Epoch 2 / 100: avg data time: 5.92e-02, avg batch time: 0.5071, average train loss: 2.9883
[09/26 13:15:50 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1690, average loss: 2.9604
[09/26 13:15:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.00	
[09/26 13:15:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 13:15:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.30e-02, avg batch time: 0.4906, average train loss: 2.9181
[09/26 13:15:58 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1691, average loss: 2.9348
[09/26 13:15:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 13:15:58 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 13:16:05 visual_prompt]: Epoch 4 / 100: avg data time: 5.53e-02, avg batch time: 0.5024, average train loss: 2.9187
[09/26 13:16:07 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1688, average loss: 2.9228
[09/26 13:16:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 13:16:07 visual_prompt]: Best epoch 4: best metric: 0.085
[09/26 13:16:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 13:16:14 visual_prompt]: Epoch 5 / 100: avg data time: 5.78e-02, avg batch time: 0.5070, average train loss: 2.9114
[09/26 13:16:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1689, average loss: 2.9510
[09/26 13:16:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 13:16:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 13:16:22 visual_prompt]: Epoch 6 / 100: avg data time: 5.09e-02, avg batch time: 0.5000, average train loss: 2.9055
[09/26 13:16:23 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1689, average loss: 2.9295
[09/26 13:16:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 13:16:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 13:16:30 visual_prompt]: Epoch 7 / 100: avg data time: 4.55e-02, avg batch time: 0.4935, average train loss: 2.9215
[09/26 13:16:32 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1688, average loss: 2.9496
[09/26 13:16:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.00	
[09/26 13:16:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 13:16:38 visual_prompt]: Epoch 8 / 100: avg data time: 4.33e-02, avg batch time: 0.4921, average train loss: 2.8890
[09/26 13:16:40 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1686, average loss: 2.8976
[09/26 13:16:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 29.00	
[09/26 13:16:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 13:16:47 visual_prompt]: Epoch 9 / 100: avg data time: 5.94e-02, avg batch time: 0.5082, average train loss: 2.9103
[09/26 13:16:48 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1693, average loss: 2.9364
[09/26 13:16:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.00	
[09/26 13:16:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 13:16:55 visual_prompt]: Epoch 10 / 100: avg data time: 6.34e-02, avg batch time: 0.5120, average train loss: 2.8817
[09/26 13:16:57 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1688, average loss: 2.9582
[09/26 13:16:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 13:16:57 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 13:17:04 visual_prompt]: Epoch 11 / 100: avg data time: 5.55e-02, avg batch time: 0.5037, average train loss: 2.8710
[09/26 13:17:05 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1688, average loss: 2.9181
[09/26 13:17:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 33.50	
[09/26 13:17:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 13:17:12 visual_prompt]: Epoch 12 / 100: avg data time: 5.77e-02, avg batch time: 0.5065, average train loss: 2.8486
[09/26 13:17:14 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1688, average loss: 2.8881
[09/26 13:17:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 34.50	
[09/26 13:17:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 13:17:20 visual_prompt]: Epoch 13 / 100: avg data time: 5.71e-02, avg batch time: 0.5055, average train loss: 2.7895
[09/26 13:17:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 2.9316
[09/26 13:17:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 39.50	
[09/26 13:17:22 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 13:17:29 visual_prompt]: Epoch 14 / 100: avg data time: 5.87e-02, avg batch time: 0.5072, average train loss: 2.7711
[09/26 13:17:30 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 2.9464
[09/26 13:17:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 35.50	
[09/26 13:17:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 13:17:37 visual_prompt]: Epoch 15 / 100: avg data time: 5.65e-02, avg batch time: 0.5041, average train loss: 2.7291
[09/26 13:17:39 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 2.8230
[09/26 13:17:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 42.00	
[09/26 13:17:39 visual_prompt]: Best epoch 15: best metric: 0.100
[09/26 13:17:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 13:17:46 visual_prompt]: Epoch 16 / 100: avg data time: 6.05e-02, avg batch time: 0.5081, average train loss: 2.6863
[09/26 13:17:47 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 2.7155
[09/26 13:17:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 43.00	
[09/26 13:17:47 visual_prompt]: Best epoch 16: best metric: 0.105
[09/26 13:17:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 13:17:54 visual_prompt]: Epoch 17 / 100: avg data time: 6.09e-02, avg batch time: 0.5087, average train loss: 2.6255
[09/26 13:17:56 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1693, average loss: 2.6486
[09/26 13:17:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 57.00	
[09/26 13:17:56 visual_prompt]: Best epoch 17: best metric: 0.115
[09/26 13:17:56 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 13:18:03 visual_prompt]: Epoch 18 / 100: avg data time: 5.50e-02, avg batch time: 0.5045, average train loss: 2.4587
[09/26 13:18:04 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1689, average loss: 4.1446
[09/26 13:18:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.50	
[09/26 13:18:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 13:18:11 visual_prompt]: Epoch 19 / 100: avg data time: 5.62e-02, avg batch time: 0.5050, average train loss: 2.9867
[09/26 13:18:13 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1692, average loss: 2.8323
[09/26 13:18:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 37.00	
[09/26 13:18:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 13:18:19 visual_prompt]: Epoch 20 / 100: avg data time: 5.99e-02, avg batch time: 0.5084, average train loss: 2.7316
[09/26 13:18:21 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1689, average loss: 2.6209
[09/26 13:18:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 54.50	
[09/26 13:18:21 visual_prompt]: Best epoch 20: best metric: 0.125
[09/26 13:18:21 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 13:18:28 visual_prompt]: Epoch 21 / 100: avg data time: 6.02e-02, avg batch time: 0.5079, average train loss: 2.5290
[09/26 13:18:30 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1686, average loss: 2.7855
[09/26 13:18:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 55.00	
[09/26 13:18:30 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 13:18:36 visual_prompt]: Epoch 22 / 100: avg data time: 5.54e-02, avg batch time: 0.5042, average train loss: 2.3803
[09/26 13:18:38 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1691, average loss: 2.7543
[09/26 13:18:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 13:18:38 visual_prompt]: Best epoch 22: best metric: 0.150
[09/26 13:18:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 13:18:45 visual_prompt]: Epoch 23 / 100: avg data time: 5.85e-02, avg batch time: 0.5082, average train loss: 2.2918
[09/26 13:18:46 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1688, average loss: 2.6148
[09/26 13:18:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 58.00	
[09/26 13:18:46 visual_prompt]: Best epoch 23: best metric: 0.165
[09/26 13:18:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 13:18:53 visual_prompt]: Epoch 24 / 100: avg data time: 4.44e-02, avg batch time: 0.4958, average train loss: 2.3619
[09/26 13:18:55 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 2.6745
[09/26 13:18:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.00	
[09/26 13:18:55 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 13:19:01 visual_prompt]: Epoch 25 / 100: avg data time: 4.33e-02, avg batch time: 0.4928, average train loss: 2.7777
[09/26 13:19:03 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1686, average loss: 2.9826
[09/26 13:19:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 13:19:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 13:19:10 visual_prompt]: Epoch 26 / 100: avg data time: 4.81e-02, avg batch time: 0.4978, average train loss: 2.9675
[09/26 13:19:11 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1687, average loss: 2.9231
[09/26 13:19:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 13:19:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 13:19:18 visual_prompt]: Epoch 27 / 100: avg data time: 5.96e-02, avg batch time: 0.5068, average train loss: 2.9631
[09/26 13:19:20 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 2.9361
[09/26 13:19:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 13:19:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 13:19:27 visual_prompt]: Epoch 28 / 100: avg data time: 4.60e-02, avg batch time: 0.4939, average train loss: 2.9647
[09/26 13:19:28 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1687, average loss: 2.9651
[09/26 13:19:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 28.50	
[09/26 13:19:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 13:19:35 visual_prompt]: Epoch 29 / 100: avg data time: 5.63e-02, avg batch time: 0.5040, average train loss: 2.9626
[09/26 13:19:37 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.1692, average loss: 2.9470
[09/26 13:19:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 13:19:37 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 13:19:44 visual_prompt]: Epoch 30 / 100: avg data time: 6.11e-02, avg batch time: 0.5088, average train loss: 2.9652
[09/26 13:19:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1688, average loss: 2.9807
[09/26 13:19:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 13:19:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 13:19:52 visual_prompt]: Epoch 31 / 100: avg data time: 4.34e-02, avg batch time: 0.4933, average train loss: 2.9130
[09/26 13:19:53 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1694, average loss: 3.2039
[09/26 13:19:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.00	
[09/26 13:19:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 13:20:00 visual_prompt]: Epoch 32 / 100: avg data time: 5.41e-02, avg batch time: 0.5022, average train loss: 2.8910
[09/26 13:20:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1688, average loss: 2.8728
[09/26 13:20:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 34.50	
[09/26 13:20:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 13:20:08 visual_prompt]: Epoch 33 / 100: avg data time: 4.96e-02, avg batch time: 0.4985, average train loss: 2.6815
[09/26 13:20:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1687, average loss: 2.8558
[09/26 13:20:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 37.50	
[09/26 13:20:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:20:17 visual_prompt]: Epoch 34 / 100: avg data time: 5.93e-02, avg batch time: 0.5080, average train loss: 2.7164
[09/26 13:20:18 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 2.9021
[09/26 13:20:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 13:20:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:20:25 visual_prompt]: Epoch 35 / 100: avg data time: 5.46e-02, avg batch time: 0.5029, average train loss: 2.8894
[09/26 13:20:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 2.9538
[09/26 13:20:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 13:20:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:20:33 visual_prompt]: Epoch 36 / 100: avg data time: 4.24e-02, avg batch time: 0.4907, average train loss: 2.9158
[09/26 13:20:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 2.8891
[09/26 13:20:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.00	
[09/26 13:20:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:20:42 visual_prompt]: Epoch 37 / 100: avg data time: 4.29e-02, avg batch time: 0.4912, average train loss: 2.9213
[09/26 13:20:43 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1690, average loss: 2.9230
[09/26 13:20:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 13:20:43 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:20:50 visual_prompt]: Epoch 38 / 100: avg data time: 5.43e-02, avg batch time: 0.5034, average train loss: 2.9216
[09/26 13:20:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 2.9521
[09/26 13:20:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 32.50	
[09/26 13:20:52 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:20:58 visual_prompt]: Epoch 39 / 100: avg data time: 5.23e-02, avg batch time: 0.5008, average train loss: 2.9061
[09/26 13:21:00 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 2.8659
[09/26 13:21:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 34.50	
[09/26 13:21:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:21:07 visual_prompt]: Epoch 40 / 100: avg data time: 6.06e-02, avg batch time: 0.5087, average train loss: 2.8860
[09/26 13:21:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1689, average loss: 2.9269
[09/26 13:21:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 31.50	
[09/26 13:21:08 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:21:15 visual_prompt]: Epoch 41 / 100: avg data time: 5.63e-02, avg batch time: 0.5045, average train loss: 2.8206
[09/26 13:21:17 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1688, average loss: 2.7249
[09/26 13:21:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 47.00	
[09/26 13:21:17 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:21:24 visual_prompt]: Epoch 42 / 100: avg data time: 6.12e-02, avg batch time: 0.5102, average train loss: 2.6197
[09/26 13:21:25 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1693, average loss: 2.4869
[09/26 13:21:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.00	
[09/26 13:21:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:21:32 visual_prompt]: Epoch 43 / 100: avg data time: 5.48e-02, avg batch time: 0.5032, average train loss: 2.3902
[09/26 13:21:33 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 2.5554
[09/26 13:21:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 59.50	
[09/26 13:21:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:21:40 visual_prompt]: Epoch 44 / 100: avg data time: 5.45e-02, avg batch time: 0.5034, average train loss: 2.2696
[09/26 13:21:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 2.6387
[09/26 13:21:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 13:21:42 visual_prompt]: Best epoch 44: best metric: 0.190
[09/26 13:21:42 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:21:49 visual_prompt]: Epoch 45 / 100: avg data time: 5.40e-02, avg batch time: 0.5026, average train loss: 2.1590
[09/26 13:21:50 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 2.7572
[09/26 13:21:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 13:21:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:21:57 visual_prompt]: Epoch 46 / 100: avg data time: 4.41e-02, avg batch time: 0.4938, average train loss: 2.0051
[09/26 13:21:58 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 2.6187
[09/26 13:21:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.50	
[09/26 13:21:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:22:05 visual_prompt]: Epoch 47 / 100: avg data time: 4.24e-02, avg batch time: 0.4937, average train loss: 1.7886
[09/26 13:22:07 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 3.0006
[09/26 13:22:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 57.50	
[09/26 13:22:07 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:22:13 visual_prompt]: Epoch 48 / 100: avg data time: 5.28e-02, avg batch time: 0.5027, average train loss: 1.6685
[09/26 13:22:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 2.8218
[09/26 13:22:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.50	
[09/26 13:22:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:22:22 visual_prompt]: Epoch 49 / 100: avg data time: 4.27e-02, avg batch time: 0.4947, average train loss: 1.3870
[09/26 13:22:23 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 2.8595
[09/26 13:22:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.00	
[09/26 13:22:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:22:30 visual_prompt]: Epoch 50 / 100: avg data time: 5.22e-02, avg batch time: 0.5010, average train loss: 1.1182
[09/26 13:22:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 2.9522
[09/26 13:22:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 13:22:32 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:22:39 visual_prompt]: Epoch 51 / 100: avg data time: 6.30e-02, avg batch time: 0.5126, average train loss: 0.8782
[09/26 13:22:40 visual_prompt]: Inference (val):avg data time: 5.19e-05, avg batch time: 0.1691, average loss: 3.1405
[09/26 13:22:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 13:22:40 visual_prompt]: Best epoch 51: best metric: 0.205
[09/26 13:22:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:22:47 visual_prompt]: Epoch 52 / 100: avg data time: 4.57e-02, avg batch time: 0.4955, average train loss: 0.7761
[09/26 13:22:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 3.1263
[09/26 13:22:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.50	
[09/26 13:22:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:22:55 visual_prompt]: Epoch 53 / 100: avg data time: 6.16e-02, avg batch time: 0.5099, average train loss: 0.6046
[09/26 13:22:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1689, average loss: 3.5976
[09/26 13:22:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 13:22:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:23:04 visual_prompt]: Epoch 54 / 100: avg data time: 5.88e-02, avg batch time: 0.5071, average train loss: 0.4125
[09/26 13:23:05 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1692, average loss: 3.3930
[09/26 13:23:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 13:23:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:23:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.15e-02, avg batch time: 0.5098, average train loss: 0.3017
[09/26 13:23:14 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1690, average loss: 3.4383
[09/26 13:23:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 67.50	
[09/26 13:23:14 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:23:21 visual_prompt]: Epoch 56 / 100: avg data time: 5.79e-02, avg batch time: 0.5061, average train loss: 0.2248
[09/26 13:23:22 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1693, average loss: 3.4897
[09/26 13:23:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 68.50	
[09/26 13:23:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:23:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.58e-02, avg batch time: 0.5045, average train loss: 0.1528
[09/26 13:23:31 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1691, average loss: 3.4659
[09/26 13:23:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 67.00	
[09/26 13:23:31 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:23:38 visual_prompt]: Epoch 58 / 100: avg data time: 5.91e-02, avg batch time: 0.5072, average train loss: 0.1120
[09/26 13:23:39 visual_prompt]: Inference (val):avg data time: 4.72e-05, avg batch time: 0.1690, average loss: 3.7138
[09/26 13:23:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 66.50	
[09/26 13:23:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:23:46 visual_prompt]: Epoch 59 / 100: avg data time: 5.96e-02, avg batch time: 0.5078, average train loss: 0.0776
[09/26 13:23:48 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1689, average loss: 3.8585
[09/26 13:23:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 65.50	
[09/26 13:23:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:23:54 visual_prompt]: Epoch 60 / 100: avg data time: 5.20e-02, avg batch time: 0.5022, average train loss: 0.0649
[09/26 13:23:56 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1692, average loss: 3.8141
[09/26 13:23:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 67.50	
[09/26 13:23:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:24:03 visual_prompt]: Epoch 61 / 100: avg data time: 5.33e-02, avg batch time: 0.5041, average train loss: 0.0551
[09/26 13:24:04 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1692, average loss: 3.7175
[09/26 13:24:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 13:24:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:24:11 visual_prompt]: Epoch 62 / 100: avg data time: 5.64e-02, avg batch time: 0.5059, average train loss: 0.0466
[09/26 13:24:13 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1689, average loss: 3.8197
[09/26 13:24:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 13:24:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:24:20 visual_prompt]: Epoch 63 / 100: avg data time: 5.09e-02, avg batch time: 0.4999, average train loss: 0.0443
[09/26 13:24:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 3.9043
[09/26 13:24:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 13:24:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:24:28 visual_prompt]: Epoch 64 / 100: avg data time: 5.79e-02, avg batch time: 0.5073, average train loss: 0.0384
[09/26 13:24:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1691, average loss: 3.8831
[09/26 13:24:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.00	
[09/26 13:24:30 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:24:37 visual_prompt]: Epoch 65 / 100: avg data time: 5.94e-02, avg batch time: 0.5094, average train loss: 0.0369
[09/26 13:24:38 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1693, average loss: 3.8857
[09/26 13:24:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 66.50	
[09/26 13:24:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:24:45 visual_prompt]: Epoch 66 / 100: avg data time: 6.37e-02, avg batch time: 0.5118, average train loss: 0.0315
[09/26 13:24:47 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1692, average loss: 3.9712
[09/26 13:24:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 13:24:47 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:24:54 visual_prompt]: Epoch 67 / 100: avg data time: 6.08e-02, avg batch time: 0.5216, average train loss: 0.0291
[09/26 13:24:55 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1689, average loss: 3.9510
[09/26 13:24:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 66.50	
[09/26 13:24:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:25:02 visual_prompt]: Epoch 68 / 100: avg data time: 6.16e-02, avg batch time: 0.5095, average train loss: 0.0254
[09/26 13:25:04 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1691, average loss: 4.0335
[09/26 13:25:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 65.50	
[09/26 13:25:04 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:25:11 visual_prompt]: Epoch 69 / 100: avg data time: 4.37e-02, avg batch time: 0.4920, average train loss: 0.0232
[09/26 13:25:12 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1695, average loss: 4.0323
[09/26 13:25:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 66.00	
[09/26 13:25:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:25:19 visual_prompt]: Epoch 70 / 100: avg data time: 6.04e-02, avg batch time: 0.5083, average train loss: 0.0239
[09/26 13:25:21 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1699, average loss: 3.9474
[09/26 13:25:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.00	
[09/26 13:25:21 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:25:28 visual_prompt]: Epoch 71 / 100: avg data time: 5.95e-02, avg batch time: 0.5088, average train loss: 0.0227
[09/26 13:25:29 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1689, average loss: 4.0865
[09/26 13:25:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 13:25:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:25:36 visual_prompt]: Epoch 72 / 100: avg data time: 5.16e-02, avg batch time: 0.5013, average train loss: 0.0258
[09/26 13:25:38 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1692, average loss: 4.0306
[09/26 13:25:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.00	
[09/26 13:25:38 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:25:44 visual_prompt]: Epoch 73 / 100: avg data time: 5.45e-02, avg batch time: 0.5028, average train loss: 0.0323
[09/26 13:25:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1690, average loss: 3.9610
[09/26 13:25:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:25:46 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:25:53 visual_prompt]: Epoch 74 / 100: avg data time: 6.01e-02, avg batch time: 0.5084, average train loss: 0.0302
[09/26 13:25:54 visual_prompt]: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1690, average loss: 4.0506
[09/26 13:25:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.00	
[09/26 13:25:54 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:26:01 visual_prompt]: Epoch 75 / 100: avg data time: 5.75e-02, avg batch time: 0.5072, average train loss: 0.0253
[09/26 13:26:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 4.0221
[09/26 13:26:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 13:26:03 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:26:09 visual_prompt]: Epoch 76 / 100: avg data time: 4.44e-02, avg batch time: 0.4952, average train loss: 0.0219
[09/26 13:26:11 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1690, average loss: 4.0179
[09/26 13:26:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 62.50	
[09/26 13:26:11 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:26:18 visual_prompt]: Epoch 77 / 100: avg data time: 5.47e-02, avg batch time: 0.5043, average train loss: 0.0195
[09/26 13:26:19 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 4.1024
[09/26 13:26:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 62.50	
[09/26 13:26:19 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:26:26 visual_prompt]: Epoch 78 / 100: avg data time: 5.38e-02, avg batch time: 0.5026, average train loss: 0.0181
[09/26 13:26:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1688, average loss: 4.1531
[09/26 13:26:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.00	
[09/26 13:26:28 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:26:35 visual_prompt]: Epoch 79 / 100: avg data time: 5.97e-02, avg batch time: 0.5093, average train loss: 0.0162
[09/26 13:26:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 4.1450
[09/26 13:26:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.00	
[09/26 13:26:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:26:43 visual_prompt]: Epoch 80 / 100: avg data time: 5.85e-02, avg batch time: 0.5078, average train loss: 0.0157
[09/26 13:26:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 4.1544
[09/26 13:26:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 62.50	
[09/26 13:26:44 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:26:51 visual_prompt]: Epoch 81 / 100: avg data time: 6.08e-02, avg batch time: 0.5099, average train loss: 0.0154
[09/26 13:26:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 4.1379
[09/26 13:26:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.50	
[09/26 13:26:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:27:00 visual_prompt]: Epoch 82 / 100: avg data time: 6.25e-02, avg batch time: 0.5109, average train loss: 0.0158
[09/26 13:27:01 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 4.1261
[09/26 13:27:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 13:27:01 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:27:08 visual_prompt]: Epoch 83 / 100: avg data time: 5.51e-02, avg batch time: 0.5038, average train loss: 0.0142
[09/26 13:27:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1689, average loss: 4.1676
[09/26 13:27:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 13:27:10 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:27:17 visual_prompt]: Epoch 84 / 100: avg data time: 6.03e-02, avg batch time: 0.5087, average train loss: 0.0146
[09/26 13:27:18 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1692, average loss: 4.1540
[09/26 13:27:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.00	
[09/26 13:27:18 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:27:25 visual_prompt]: Epoch 85 / 100: avg data time: 6.07e-02, avg batch time: 0.5089, average train loss: 0.0134
[09/26 13:27:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 4.1645
[09/26 13:27:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.50	
[09/26 13:27:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:27:33 visual_prompt]: Epoch 86 / 100: avg data time: 4.34e-02, avg batch time: 0.4929, average train loss: 0.0131
[09/26 13:27:35 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1689, average loss: 4.1705
[09/26 13:27:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 13:27:35 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:27:42 visual_prompt]: Epoch 87 / 100: avg data time: 5.36e-02, avg batch time: 0.5039, average train loss: 0.0135
[09/26 13:27:43 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1689, average loss: 4.1905
[09/26 13:27:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.50	
[09/26 13:27:43 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:27:50 visual_prompt]: Epoch 88 / 100: avg data time: 5.24e-02, avg batch time: 0.5020, average train loss: 0.0131
[09/26 13:27:52 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 4.2038
[09/26 13:27:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.50	
[09/26 13:27:52 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:27:58 visual_prompt]: Epoch 89 / 100: avg data time: 5.46e-02, avg batch time: 0.5029, average train loss: 0.0124
[09/26 13:28:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 4.2020
[09/26 13:28:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.50	
[09/26 13:28:00 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:28:07 visual_prompt]: Epoch 90 / 100: avg data time: 5.90e-02, avg batch time: 0.5072, average train loss: 0.0134
[09/26 13:28:08 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 4.1940
[09/26 13:28:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.50	
[09/26 13:28:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:28:15 visual_prompt]: Epoch 91 / 100: avg data time: 5.94e-02, avg batch time: 0.5088, average train loss: 0.0126
[09/26 13:28:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 4.1962
[09/26 13:28:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.50	
[09/26 13:28:17 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:28:23 visual_prompt]: Epoch 92 / 100: avg data time: 5.49e-02, avg batch time: 0.5053, average train loss: 0.0123
[09/26 13:28:25 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1689, average loss: 4.2047
[09/26 13:28:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.50	
[09/26 13:28:25 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:28:32 visual_prompt]: Epoch 93 / 100: avg data time: 5.34e-02, avg batch time: 0.5027, average train loss: 0.0131
[09/26 13:28:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1690, average loss: 4.1901
[09/26 13:28:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.50	
[09/26 13:28:33 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:28:40 visual_prompt]: Epoch 94 / 100: avg data time: 4.65e-02, avg batch time: 0.4966, average train loss: 0.0126
[09/26 13:28:42 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1690, average loss: 4.1666
[09/26 13:28:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 13:28:42 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:28:49 visual_prompt]: Epoch 95 / 100: avg data time: 6.59e-02, avg batch time: 0.5148, average train loss: 0.0117
[09/26 13:28:50 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1689, average loss: 4.1674
[09/26 13:28:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 13:28:50 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:28:57 visual_prompt]: Epoch 96 / 100: avg data time: 5.24e-02, avg batch time: 0.5006, average train loss: 0.0126
[09/26 13:28:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 4.1699
[09/26 13:28:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 13:28:59 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:29:05 visual_prompt]: Epoch 97 / 100: avg data time: 5.59e-02, avg batch time: 0.5051, average train loss: 0.0123
[09/26 13:29:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 4.1716
[09/26 13:29:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 13:29:07 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:29:14 visual_prompt]: Epoch 98 / 100: avg data time: 5.75e-02, avg batch time: 0.5067, average train loss: 0.0121
[09/26 13:29:15 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1689, average loss: 4.1722
[09/26 13:29:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 13:29:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:29:22 visual_prompt]: Epoch 99 / 100: avg data time: 4.62e-02, avg batch time: 0.4952, average train loss: 0.0116
[09/26 13:29:24 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 4.1729
[09/26 13:29:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 13:29:24 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:29:31 visual_prompt]: Epoch 100 / 100: avg data time: 5.91e-02, avg batch time: 0.5073, average train loss: 0.0125
[09/26 13:29:32 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 4.1733
[09/26 13:29:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 64.00	
[09/26 13:29:32 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:29:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:29:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:29:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:29:32 visual_prompt]: Training with config:
[09/26 13:29:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:29:32 visual_prompt]: Loading training data...
[09/26 13:29:32 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:29:33 visual_prompt]: Number of images: 800
[09/26 13:29:33 visual_prompt]: Number of classes: 18 / 18
[09/26 13:29:33 visual_prompt]: Loading validation data...
[09/26 13:29:33 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:29:34 visual_prompt]: Number of images: 200
[09/26 13:29:34 visual_prompt]: Number of classes: 18 / 18
[09/26 13:29:34 visual_prompt]: Constructing models...
[09/26 13:29:36 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 13:29:36 visual_prompt]: tuned percent:0.550
[09/26 13:29:36 visual_prompt]: Device used for model: 0
[09/26 13:29:36 visual_prompt]: Setting up Evaluator...
[09/26 13:29:36 visual_prompt]: Setting up Trainer...
[09/26 13:29:36 visual_prompt]: 	Setting up the optimizer...
[09/26 13:29:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:29:43 visual_prompt]: Epoch 1 / 100: avg data time: 6.21e-02, avg batch time: 0.5094, average train loss: 3.2575
[09/26 13:29:45 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 13:29:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 13:29:45 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 13:29:45 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 13:29:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.30e-02, avg batch time: 0.5013, average train loss: 2.9901
[09/26 13:29:53 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.1684, average loss: 2.9693
[09/26 13:29:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.50	
[09/26 13:29:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 13:30:00 visual_prompt]: Epoch 3 / 100: avg data time: 4.21e-02, avg batch time: 0.4900, average train loss: 2.9226
[09/26 13:30:01 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1686, average loss: 2.9106
[09/26 13:30:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 13:30:01 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 13:30:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 13:30:08 visual_prompt]: Epoch 4 / 100: avg data time: 4.16e-02, avg batch time: 0.4900, average train loss: 2.9152
[09/26 13:30:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1686, average loss: 2.9093
[09/26 13:30:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.00	
[09/26 13:30:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 13:30:16 visual_prompt]: Epoch 5 / 100: avg data time: 4.43e-02, avg batch time: 0.4950, average train loss: 2.9259
[09/26 13:30:18 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1685, average loss: 2.9600
[09/26 13:30:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 13:30:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 13:30:25 visual_prompt]: Epoch 6 / 100: avg data time: 5.98e-02, avg batch time: 0.5084, average train loss: 2.9356
[09/26 13:30:26 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 2.9236
[09/26 13:30:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 13:30:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 13:30:33 visual_prompt]: Epoch 7 / 100: avg data time: 5.72e-02, avg batch time: 0.5065, average train loss: 2.9199
[09/26 13:30:35 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1688, average loss: 2.9716
[09/26 13:30:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 13:30:35 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 13:30:42 visual_prompt]: Epoch 8 / 100: avg data time: 6.07e-02, avg batch time: 0.5089, average train loss: 2.9347
[09/26 13:30:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 3.0115
[09/26 13:30:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.00	
[09/26 13:30:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 13:30:50 visual_prompt]: Epoch 9 / 100: avg data time: 4.46e-02, avg batch time: 0.4939, average train loss: 2.9486
[09/26 13:30:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1687, average loss: 2.9469
[09/26 13:30:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.50	
[09/26 13:30:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 13:30:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.43e-02, avg batch time: 0.4937, average train loss: 2.9361
[09/26 13:31:00 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1687, average loss: 2.9321
[09/26 13:31:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 13:31:00 visual_prompt]: Best epoch 10: best metric: 0.085
[09/26 13:31:00 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 13:31:06 visual_prompt]: Epoch 11 / 100: avg data time: 4.99e-02, avg batch time: 0.4997, average train loss: 2.8968
[09/26 13:31:08 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 2.9098
[09/26 13:31:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 13:31:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 13:31:15 visual_prompt]: Epoch 12 / 100: avg data time: 4.48e-02, avg batch time: 0.4933, average train loss: 2.9070
[09/26 13:31:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 2.9968
[09/26 13:31:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 13:31:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 13:31:23 visual_prompt]: Epoch 13 / 100: avg data time: 4.40e-02, avg batch time: 0.4938, average train loss: 2.8941
[09/26 13:31:24 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1687, average loss: 2.8762
[09/26 13:31:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 35.50	
[09/26 13:31:24 visual_prompt]: Best epoch 13: best metric: 0.100
[09/26 13:31:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 13:31:31 visual_prompt]: Epoch 14 / 100: avg data time: 5.91e-02, avg batch time: 0.5066, average train loss: 2.8458
[09/26 13:31:33 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 2.9014
[09/26 13:31:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 41.00	
[09/26 13:31:33 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 13:31:40 visual_prompt]: Epoch 15 / 100: avg data time: 6.13e-02, avg batch time: 0.5096, average train loss: 2.7801
[09/26 13:31:41 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1687, average loss: 2.8934
[09/26 13:31:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 35.50	
[09/26 13:31:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 13:31:48 visual_prompt]: Epoch 16 / 100: avg data time: 6.08e-02, avg batch time: 0.5085, average train loss: 2.7414
[09/26 13:31:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1690, average loss: 2.8557
[09/26 13:31:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 41.00	
[09/26 13:31:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 13:31:57 visual_prompt]: Epoch 17 / 100: avg data time: 6.29e-02, avg batch time: 0.5112, average train loss: 2.7485
[09/26 13:31:58 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1693, average loss: 2.8463
[09/26 13:31:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 41.50	
[09/26 13:31:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 13:32:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.42e-02, avg batch time: 0.5033, average train loss: 2.6556
[09/26 13:32:07 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1693, average loss: 2.8385
[09/26 13:32:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.00	
[09/26 13:32:07 visual_prompt]: Best epoch 18: best metric: 0.120
[09/26 13:32:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 13:32:14 visual_prompt]: Epoch 19 / 100: avg data time: 5.80e-02, avg batch time: 0.5058, average train loss: 2.5451
[09/26 13:32:15 visual_prompt]: Inference (val):avg data time: 5.35e-05, avg batch time: 0.1691, average loss: 2.7007
[09/26 13:32:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 48.50	
[09/26 13:32:15 visual_prompt]: Best epoch 19: best metric: 0.145
[09/26 13:32:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 13:32:22 visual_prompt]: Epoch 20 / 100: avg data time: 6.00e-02, avg batch time: 0.5098, average train loss: 2.3011
[09/26 13:32:24 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1693, average loss: 2.7092
[09/26 13:32:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 60.00	
[09/26 13:32:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 13:32:31 visual_prompt]: Epoch 21 / 100: avg data time: 4.84e-02, avg batch time: 0.4982, average train loss: 2.1499
[09/26 13:32:32 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1691, average loss: 2.7612
[09/26 13:32:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.00	
[09/26 13:32:32 visual_prompt]: Best epoch 21: best metric: 0.180
[09/26 13:32:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 13:32:39 visual_prompt]: Epoch 22 / 100: avg data time: 5.27e-02, avg batch time: 0.5013, average train loss: 2.1596
[09/26 13:32:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 2.7014
[09/26 13:32:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 13:32:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 13:32:47 visual_prompt]: Epoch 23 / 100: avg data time: 5.38e-02, avg batch time: 0.5035, average train loss: 1.8775
[09/26 13:32:49 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1691, average loss: 3.1669
[09/26 13:32:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 53.00	
[09/26 13:32:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 13:32:56 visual_prompt]: Epoch 24 / 100: avg data time: 5.08e-02, avg batch time: 0.4993, average train loss: 1.8418
[09/26 13:32:57 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1691, average loss: 3.1184
[09/26 13:32:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 60.50	
[09/26 13:32:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 13:33:04 visual_prompt]: Epoch 25 / 100: avg data time: 4.18e-02, avg batch time: 0.4916, average train loss: 1.8164
[09/26 13:33:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 2.8102
[09/26 13:33:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 63.00	
[09/26 13:33:06 visual_prompt]: Best epoch 25: best metric: 0.195
[09/26 13:33:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 13:33:13 visual_prompt]: Epoch 26 / 100: avg data time: 5.15e-02, avg batch time: 0.5007, average train loss: 1.6426
[09/26 13:33:14 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 3.3780
[09/26 13:33:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 58.50	
[09/26 13:33:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 13:33:21 visual_prompt]: Epoch 27 / 100: avg data time: 5.63e-02, avg batch time: 0.5042, average train loss: 1.5201
[09/26 13:33:23 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1688, average loss: 3.3938
[09/26 13:33:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.00	
[09/26 13:33:23 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 13:33:29 visual_prompt]: Epoch 28 / 100: avg data time: 5.89e-02, avg batch time: 0.5080, average train loss: 1.3343
[09/26 13:33:31 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 3.6007
[09/26 13:33:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.00	
[09/26 13:33:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 13:33:38 visual_prompt]: Epoch 29 / 100: avg data time: 4.49e-02, avg batch time: 0.4958, average train loss: 1.1706
[09/26 13:33:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 3.7556
[09/26 13:33:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 13:33:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 13:33:46 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e-02, avg batch time: 0.5049, average train loss: 1.1833
[09/26 13:33:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 3.6894
[09/26 13:33:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.00	
[09/26 13:33:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 13:33:54 visual_prompt]: Epoch 31 / 100: avg data time: 4.55e-02, avg batch time: 0.4955, average train loss: 0.9851
[09/26 13:33:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 4.6568
[09/26 13:33:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 66.50	
[09/26 13:33:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 13:34:03 visual_prompt]: Epoch 32 / 100: avg data time: 5.60e-02, avg batch time: 0.5044, average train loss: 0.9820
[09/26 13:34:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 4.1823
[09/26 13:34:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.50	
[09/26 13:34:04 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 13:34:11 visual_prompt]: Epoch 33 / 100: avg data time: 4.65e-02, avg batch time: 0.4961, average train loss: 0.7614
[09/26 13:34:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 4.2931
[09/26 13:34:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.00	
[09/26 13:34:13 visual_prompt]: Best epoch 33: best metric: 0.200
[09/26 13:34:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:34:19 visual_prompt]: Epoch 34 / 100: avg data time: 4.55e-02, avg batch time: 0.4942, average train loss: 0.6678
[09/26 13:34:21 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 4.8287
[09/26 13:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 13:34:21 visual_prompt]: Best epoch 34: best metric: 0.205
[09/26 13:34:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:34:28 visual_prompt]: Epoch 35 / 100: avg data time: 4.98e-02, avg batch time: 0.4988, average train loss: 0.5335
[09/26 13:34:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 5.0130
[09/26 13:34:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 68.00	
[09/26 13:34:29 visual_prompt]: Best epoch 35: best metric: 0.225
[09/26 13:34:29 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:34:36 visual_prompt]: Epoch 36 / 100: avg data time: 5.94e-02, avg batch time: 0.5080, average train loss: 0.4833
[09/26 13:34:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 5.4154
[09/26 13:34:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 70.00	
[09/26 13:34:38 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:34:45 visual_prompt]: Epoch 37 / 100: avg data time: 6.19e-02, avg batch time: 0.5110, average train loss: 0.4569
[09/26 13:34:46 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1693, average loss: 5.1834
[09/26 13:34:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.50	
[09/26 13:34:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:34:53 visual_prompt]: Epoch 38 / 100: avg data time: 4.40e-02, avg batch time: 0.4935, average train loss: 0.4279
[09/26 13:34:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 5.8363
[09/26 13:34:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 61.00	
[09/26 13:34:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:35:01 visual_prompt]: Epoch 39 / 100: avg data time: 4.31e-02, avg batch time: 0.4924, average train loss: 0.3710
[09/26 13:35:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 5.6358
[09/26 13:35:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 66.00	
[09/26 13:35:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:35:09 visual_prompt]: Epoch 40 / 100: avg data time: 5.98e-02, avg batch time: 0.5080, average train loss: 0.3065
[09/26 13:35:11 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1692, average loss: 6.2601
[09/26 13:35:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.00	
[09/26 13:35:11 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:35:18 visual_prompt]: Epoch 41 / 100: avg data time: 5.64e-02, avg batch time: 0.5060, average train loss: 0.3502
[09/26 13:35:19 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 5.8008
[09/26 13:35:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.50	
[09/26 13:35:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:35:26 visual_prompt]: Epoch 42 / 100: avg data time: 4.58e-02, avg batch time: 0.4965, average train loss: 0.3350
[09/26 13:35:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 5.7480
[09/26 13:35:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 67.00	
[09/26 13:35:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:35:35 visual_prompt]: Epoch 43 / 100: avg data time: 6.00e-02, avg batch time: 0.5080, average train loss: 0.2449
[09/26 13:35:36 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 5.4048
[09/26 13:35:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.50	
[09/26 13:35:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:35:43 visual_prompt]: Epoch 44 / 100: avg data time: 6.24e-02, avg batch time: 0.5128, average train loss: 0.1572
[09/26 13:35:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 6.0836
[09/26 13:35:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 68.50	
[09/26 13:35:45 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:35:52 visual_prompt]: Epoch 45 / 100: avg data time: 5.85e-02, avg batch time: 0.5092, average train loss: 0.1212
[09/26 13:35:53 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1689, average loss: 5.4978
[09/26 13:35:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 71.50	
[09/26 13:35:53 visual_prompt]: Best epoch 45: best metric: 0.230
[09/26 13:35:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:36:00 visual_prompt]: Epoch 46 / 100: avg data time: 4.67e-02, avg batch time: 0.4976, average train loss: 0.0729
[09/26 13:36:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1692, average loss: 5.6664
[09/26 13:36:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.50	
[09/26 13:36:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:36:08 visual_prompt]: Epoch 47 / 100: avg data time: 6.61e-02, avg batch time: 0.5144, average train loss: 0.0558
[09/26 13:36:10 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1693, average loss: 5.5247
[09/26 13:36:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.50	
[09/26 13:36:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:36:17 visual_prompt]: Epoch 48 / 100: avg data time: 5.73e-02, avg batch time: 0.5059, average train loss: 0.0382
[09/26 13:36:19 visual_prompt]: Inference (val):avg data time: 5.61e-04, avg batch time: 0.2433, average loss: 5.7682
[09/26 13:36:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 69.00	
[09/26 13:36:19 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:36:26 visual_prompt]: Epoch 49 / 100: avg data time: 6.08e-02, avg batch time: 0.5105, average train loss: 0.0293
[09/26 13:36:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 5.7063
[09/26 13:36:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 68.00	
[09/26 13:36:27 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:36:34 visual_prompt]: Epoch 50 / 100: avg data time: 5.56e-02, avg batch time: 0.5036, average train loss: 0.0235
[09/26 13:36:36 visual_prompt]: Inference (val):avg data time: 4.20e-05, avg batch time: 0.1701, average loss: 5.8815
[09/26 13:36:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.00	
[09/26 13:36:36 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:36:42 visual_prompt]: Epoch 51 / 100: avg data time: 5.74e-02, avg batch time: 0.5059, average train loss: 0.0178
[09/26 13:36:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 5.9104
[09/26 13:36:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 68.00	
[09/26 13:36:44 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:36:51 visual_prompt]: Epoch 52 / 100: avg data time: 5.16e-02, avg batch time: 0.5004, average train loss: 0.0171
[09/26 13:36:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1692, average loss: 6.0812
[09/26 13:36:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.00	
[09/26 13:36:52 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:36:59 visual_prompt]: Epoch 53 / 100: avg data time: 4.78e-02, avg batch time: 0.4968, average train loss: 0.0187
[09/26 13:37:01 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1693, average loss: 6.0882
[09/26 13:37:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 67.00	
[09/26 13:37:01 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:37:08 visual_prompt]: Epoch 54 / 100: avg data time: 5.97e-02, avg batch time: 0.5077, average train loss: 0.0307
[09/26 13:37:09 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1689, average loss: 6.0763
[09/26 13:37:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 67.50	
[09/26 13:37:09 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:37:16 visual_prompt]: Epoch 55 / 100: avg data time: 4.70e-02, avg batch time: 0.4971, average train loss: 0.0178
[09/26 13:37:17 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1695, average loss: 6.0712
[09/26 13:37:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 67.50	
[09/26 13:37:17 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:37:24 visual_prompt]: Epoch 56 / 100: avg data time: 5.31e-02, avg batch time: 0.5018, average train loss: 0.0117
[09/26 13:37:26 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1691, average loss: 5.9371
[09/26 13:37:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 67.50	
[09/26 13:37:26 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:37:33 visual_prompt]: Epoch 57 / 100: avg data time: 6.25e-02, avg batch time: 0.5105, average train loss: 0.0085
[09/26 13:37:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1687, average loss: 6.0655
[09/26 13:37:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 68.00	
[09/26 13:37:34 visual_prompt]: Best epoch 57: best metric: 0.235
[09/26 13:37:34 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:37:41 visual_prompt]: Epoch 58 / 100: avg data time: 4.21e-02, avg batch time: 0.4919, average train loss: 0.0085
[09/26 13:37:43 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 6.0655
[09/26 13:37:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 68.50	
[09/26 13:37:43 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:37:49 visual_prompt]: Epoch 59 / 100: avg data time: 5.44e-02, avg batch time: 0.5042, average train loss: 0.0084
[09/26 13:37:51 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1697, average loss: 6.0316
[09/26 13:37:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 67.00	
[09/26 13:37:51 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:37:58 visual_prompt]: Epoch 60 / 100: avg data time: 5.25e-02, avg batch time: 0.5029, average train loss: 0.0074
[09/26 13:37:59 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1690, average loss: 6.0484
[09/26 13:37:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 67.50	
[09/26 13:37:59 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:38:06 visual_prompt]: Epoch 61 / 100: avg data time: 4.96e-02, avg batch time: 0.4993, average train loss: 0.0070
[09/26 13:38:08 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1692, average loss: 6.0540
[09/26 13:38:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 68.50	
[09/26 13:38:08 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:38:15 visual_prompt]: Epoch 62 / 100: avg data time: 6.49e-02, avg batch time: 0.5132, average train loss: 0.0057
[09/26 13:38:16 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 6.0820
[09/26 13:38:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 68.00	
[09/26 13:38:16 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:38:23 visual_prompt]: Epoch 63 / 100: avg data time: 5.63e-02, avg batch time: 0.5051, average train loss: 0.0060
[09/26 13:38:25 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1692, average loss: 6.1081
[09/26 13:38:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 68.00	
[09/26 13:38:25 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:38:32 visual_prompt]: Epoch 64 / 100: avg data time: 5.77e-02, avg batch time: 0.5060, average train loss: 0.0057
[09/26 13:38:33 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1689, average loss: 6.0259
[09/26 13:38:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 67.50	
[09/26 13:38:33 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:38:40 visual_prompt]: Epoch 65 / 100: avg data time: 5.78e-02, avg batch time: 0.5060, average train loss: 0.0049
[09/26 13:38:42 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 6.0196
[09/26 13:38:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 67.50	
[09/26 13:38:42 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:38:48 visual_prompt]: Epoch 66 / 100: avg data time: 4.43e-02, avg batch time: 0.4950, average train loss: 0.0048
[09/26 13:38:50 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1692, average loss: 6.0272
[09/26 13:38:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 68.50	
[09/26 13:38:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:38:57 visual_prompt]: Epoch 67 / 100: avg data time: 4.59e-02, avg batch time: 0.4945, average train loss: 0.0049
[09/26 13:38:58 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1689, average loss: 6.0334
[09/26 13:38:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:38:58 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:39:05 visual_prompt]: Epoch 68 / 100: avg data time: 4.73e-02, avg batch time: 0.4963, average train loss: 0.0049
[09/26 13:39:07 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1695, average loss: 6.0193
[09/26 13:39:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.50	
[09/26 13:39:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:39:14 visual_prompt]: Epoch 69 / 100: avg data time: 5.89e-02, avg batch time: 0.5091, average train loss: 0.0043
[09/26 13:39:15 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1690, average loss: 6.0246
[09/26 13:39:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:39:15 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:39:22 visual_prompt]: Epoch 70 / 100: avg data time: 5.66e-02, avg batch time: 0.5047, average train loss: 0.0041
[09/26 13:39:24 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1693, average loss: 6.0285
[09/26 13:39:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:39:24 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:39:30 visual_prompt]: Epoch 71 / 100: avg data time: 4.38e-02, avg batch time: 0.4932, average train loss: 0.0049
[09/26 13:39:32 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 6.0159
[09/26 13:39:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.50	
[09/26 13:39:32 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:39:38 visual_prompt]: Epoch 72 / 100: avg data time: 4.41e-02, avg batch time: 0.4948, average train loss: 0.0046
[09/26 13:39:40 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 6.0193
[09/26 13:39:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 69.00	
[09/26 13:39:40 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:39:47 visual_prompt]: Epoch 73 / 100: avg data time: 4.51e-02, avg batch time: 0.4970, average train loss: 0.0042
[09/26 13:39:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1686, average loss: 6.0160
[09/26 13:39:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 68.50	
[09/26 13:39:48 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:39:55 visual_prompt]: Epoch 74 / 100: avg data time: 4.98e-02, avg batch time: 0.4984, average train loss: 0.0041
[09/26 13:39:57 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1693, average loss: 6.0124
[09/26 13:39:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:39:57 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:40:03 visual_prompt]: Epoch 75 / 100: avg data time: 4.21e-02, avg batch time: 0.4940, average train loss: 0.0044
[09/26 13:40:05 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1699, average loss: 6.0179
[09/26 13:40:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 69.00	
[09/26 13:40:05 visual_prompt]: Best epoch 75: best metric: 0.240
[09/26 13:40:05 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:40:12 visual_prompt]: Epoch 76 / 100: avg data time: 4.56e-02, avg batch time: 0.4939, average train loss: 0.0047
[09/26 13:40:13 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1689, average loss: 6.0264
[09/26 13:40:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.50	top5: 69.00	
[09/26 13:40:13 visual_prompt]: Best epoch 76: best metric: 0.245
[09/26 13:40:13 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:40:20 visual_prompt]: Epoch 77 / 100: avg data time: 4.43e-02, avg batch time: 0.4964, average train loss: 0.0043
[09/26 13:40:22 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1694, average loss: 6.0318
[09/26 13:40:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 69.00	
[09/26 13:40:22 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:40:28 visual_prompt]: Epoch 78 / 100: avg data time: 5.46e-02, avg batch time: 0.5055, average train loss: 0.0044
[09/26 13:40:30 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1693, average loss: 6.0313
[09/26 13:40:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 69.00	
[09/26 13:40:30 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:40:37 visual_prompt]: Epoch 79 / 100: avg data time: 5.47e-02, avg batch time: 0.5039, average train loss: 0.0039
[09/26 13:40:38 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1693, average loss: 6.0269
[09/26 13:40:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 69.00	
[09/26 13:40:38 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:40:45 visual_prompt]: Epoch 80 / 100: avg data time: 5.76e-02, avg batch time: 0.5058, average train loss: 0.0037
[09/26 13:40:47 visual_prompt]: Inference (val):avg data time: 6.14e-05, avg batch time: 0.1695, average loss: 6.0223
[09/26 13:40:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 69.00	
[09/26 13:40:47 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:40:54 visual_prompt]: Epoch 81 / 100: avg data time: 5.44e-02, avg batch time: 0.5052, average train loss: 0.0044
[09/26 13:40:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1689, average loss: 6.0114
[09/26 13:40:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 69.00	
[09/26 13:40:55 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:41:02 visual_prompt]: Epoch 82 / 100: avg data time: 4.55e-02, avg batch time: 0.4959, average train loss: 0.0037
[09/26 13:41:04 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1694, average loss: 6.0077
[09/26 13:41:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 69.50	
[09/26 13:41:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:41:10 visual_prompt]: Epoch 83 / 100: avg data time: 4.17e-02, avg batch time: 0.4917, average train loss: 0.0043
[09/26 13:41:12 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 6.0096
[09/26 13:41:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.50	
[09/26 13:41:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:41:19 visual_prompt]: Epoch 84 / 100: avg data time: 5.41e-02, avg batch time: 0.5034, average train loss: 0.0043
[09/26 13:41:20 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 6.0107
[09/26 13:41:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.50	
[09/26 13:41:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:41:27 visual_prompt]: Epoch 85 / 100: avg data time: 4.66e-02, avg batch time: 0.4963, average train loss: 0.0040
[09/26 13:41:28 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1689, average loss: 6.0092
[09/26 13:41:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:41:28 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:41:35 visual_prompt]: Epoch 86 / 100: avg data time: 4.44e-02, avg batch time: 0.4935, average train loss: 0.0034
[09/26 13:41:37 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1693, average loss: 6.0094
[09/26 13:41:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:41:37 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:41:43 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.5021, average train loss: 0.0034
[09/26 13:41:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1689, average loss: 6.0114
[09/26 13:41:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 68.50	
[09/26 13:41:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:41:52 visual_prompt]: Epoch 88 / 100: avg data time: 4.86e-02, avg batch time: 0.4997, average train loss: 0.0037
[09/26 13:41:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 6.0115
[09/26 13:41:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:41:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:42:00 visual_prompt]: Epoch 89 / 100: avg data time: 4.95e-02, avg batch time: 0.5001, average train loss: 0.0038
[09/26 13:42:02 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1694, average loss: 6.0120
[09/26 13:42:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:42:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:42:08 visual_prompt]: Epoch 90 / 100: avg data time: 4.20e-02, avg batch time: 0.4927, average train loss: 0.0035
[09/26 13:42:10 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1688, average loss: 6.0135
[09/26 13:42:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:42:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:42:17 visual_prompt]: Epoch 91 / 100: avg data time: 4.49e-02, avg batch time: 0.4951, average train loss: 0.0037
[09/26 13:42:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 6.0141
[09/26 13:42:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:42:18 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:42:25 visual_prompt]: Epoch 92 / 100: avg data time: 5.63e-02, avg batch time: 0.5057, average train loss: 0.0040
[09/26 13:42:26 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1689, average loss: 6.0147
[09/26 13:42:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 13:42:26 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:42:33 visual_prompt]: Epoch 93 / 100: avg data time: 5.64e-02, avg batch time: 0.5058, average train loss: 0.0035
[09/26 13:42:35 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.1696, average loss: 6.0152
[09/26 13:42:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:42:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:42:42 visual_prompt]: Epoch 94 / 100: avg data time: 5.24e-02, avg batch time: 0.5010, average train loss: 0.0044
[09/26 13:42:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1694, average loss: 6.0159
[09/26 13:42:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:42:43 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:42:50 visual_prompt]: Epoch 95 / 100: avg data time: 4.81e-02, avg batch time: 0.4984, average train loss: 0.0037
[09/26 13:42:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1696, average loss: 6.0164
[09/26 13:42:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:42:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:42:58 visual_prompt]: Epoch 96 / 100: avg data time: 6.06e-02, avg batch time: 0.5091, average train loss: 0.0038
[09/26 13:43:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 6.0162
[09/26 13:43:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:43:00 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:43:07 visual_prompt]: Epoch 97 / 100: avg data time: 4.51e-02, avg batch time: 0.4954, average train loss: 0.0040
[09/26 13:43:08 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 6.0160
[09/26 13:43:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:43:08 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:43:15 visual_prompt]: Epoch 98 / 100: avg data time: 5.18e-02, avg batch time: 0.5009, average train loss: 0.0039
[09/26 13:43:16 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1689, average loss: 6.0158
[09/26 13:43:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:43:16 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:43:23 visual_prompt]: Epoch 99 / 100: avg data time: 4.64e-02, avg batch time: 0.4958, average train loss: 0.0037
[09/26 13:43:25 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1688, average loss: 6.0157
[09/26 13:43:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:43:25 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:43:31 visual_prompt]: Epoch 100 / 100: avg data time: 4.38e-02, avg batch time: 0.4968, average train loss: 0.0038
[09/26 13:43:33 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1690, average loss: 6.0157
[09/26 13:43:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 69.00	
[09/26 13:43:33 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:43:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:43:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:43:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:43:33 visual_prompt]: Training with config:
[09/26 13:43:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:43:33 visual_prompt]: Loading training data...
[09/26 13:43:33 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:43:34 visual_prompt]: Number of images: 800
[09/26 13:43:34 visual_prompt]: Number of classes: 18 / 18
[09/26 13:43:34 visual_prompt]: Loading validation data...
[09/26 13:43:34 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:43:34 visual_prompt]: Number of images: 200
[09/26 13:43:34 visual_prompt]: Number of classes: 18 / 18
[09/26 13:43:34 visual_prompt]: Constructing models...
[09/26 13:43:37 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 13:43:37 visual_prompt]: tuned percent:0.550
[09/26 13:43:37 visual_prompt]: Device used for model: 0
[09/26 13:43:37 visual_prompt]: Setting up Evaluator...
[09/26 13:43:37 visual_prompt]: Setting up Trainer...
[09/26 13:43:37 visual_prompt]: 	Setting up the optimizer...
[09/26 13:43:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:43:44 visual_prompt]: Epoch 1 / 100: avg data time: 6.06e-02, avg batch time: 0.5092, average train loss: 3.2557
[09/26 13:43:46 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1688, average loss: 3.1895
[09/26 13:43:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 13:43:46 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 13:43:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 13:43:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.02e-02, avg batch time: 0.4978, average train loss: 3.0094
[09/26 13:43:54 visual_prompt]: Inference (val):avg data time: 4.78e-05, avg batch time: 0.1687, average loss: 2.9514
[09/26 13:43:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.50	
[09/26 13:43:54 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 13:44:01 visual_prompt]: Epoch 3 / 100: avg data time: 5.92e-02, avg batch time: 0.5061, average train loss: 2.9258
[09/26 13:44:02 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1687, average loss: 2.9662
[09/26 13:44:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 29.50	
[09/26 13:44:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 13:44:09 visual_prompt]: Epoch 4 / 100: avg data time: 5.90e-02, avg batch time: 0.5069, average train loss: 2.9429
[09/26 13:44:11 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1689, average loss: 2.9332
[09/26 13:44:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 21.50	
[09/26 13:44:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 13:44:18 visual_prompt]: Epoch 5 / 100: avg data time: 5.16e-02, avg batch time: 0.4993, average train loss: 2.9225
[09/26 13:44:19 visual_prompt]: Inference (val):avg data time: 4.61e-05, avg batch time: 0.1689, average loss: 2.9029
[09/26 13:44:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 33.00	
[09/26 13:44:19 visual_prompt]: Best epoch 5: best metric: 0.080
[09/26 13:44:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 13:44:26 visual_prompt]: Epoch 6 / 100: avg data time: 5.88e-02, avg batch time: 0.5071, average train loss: 2.9195
[09/26 13:44:28 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1689, average loss: 2.9382
[09/26 13:44:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 13:44:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 13:44:35 visual_prompt]: Epoch 7 / 100: avg data time: 5.59e-02, avg batch time: 0.5041, average train loss: 2.9324
[09/26 13:44:36 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1689, average loss: 2.9848
[09/26 13:44:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.50	
[09/26 13:44:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 13:44:43 visual_prompt]: Epoch 8 / 100: avg data time: 5.35e-02, avg batch time: 0.5015, average train loss: 2.9399
[09/26 13:44:45 visual_prompt]: Inference (val):avg data time: 5.25e-05, avg batch time: 0.1687, average loss: 2.9761
[09/26 13:44:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 13:44:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 13:44:51 visual_prompt]: Epoch 9 / 100: avg data time: 5.76e-02, avg batch time: 0.5048, average train loss: 2.9475
[09/26 13:44:53 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1688, average loss: 2.9687
[09/26 13:44:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 13:44:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 13:45:00 visual_prompt]: Epoch 10 / 100: avg data time: 5.89e-02, avg batch time: 0.5076, average train loss: 2.9148
[09/26 13:45:01 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1688, average loss: 2.9647
[09/26 13:45:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 30.00	
[09/26 13:45:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 13:45:08 visual_prompt]: Epoch 11 / 100: avg data time: 5.67e-02, avg batch time: 0.5047, average train loss: 2.9205
[09/26 13:45:10 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1691, average loss: 2.9034
[09/26 13:45:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 33.00	
[09/26 13:45:10 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 13:45:17 visual_prompt]: Epoch 12 / 100: avg data time: 6.14e-02, avg batch time: 0.5100, average train loss: 2.9145
[09/26 13:45:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 2.9728
[09/26 13:45:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.00	
[09/26 13:45:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 13:45:25 visual_prompt]: Epoch 13 / 100: avg data time: 5.85e-02, avg batch time: 0.5067, average train loss: 2.8829
[09/26 13:45:27 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1690, average loss: 2.9143
[09/26 13:45:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 38.00	
[09/26 13:45:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 13:45:34 visual_prompt]: Epoch 14 / 100: avg data time: 5.80e-02, avg batch time: 0.5055, average train loss: 2.8256
[09/26 13:45:35 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1691, average loss: 2.7928
[09/26 13:45:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 38.50	
[09/26 13:45:35 visual_prompt]: Best epoch 14: best metric: 0.105
[09/26 13:45:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 13:45:42 visual_prompt]: Epoch 15 / 100: avg data time: 5.60e-02, avg batch time: 0.5038, average train loss: 2.7240
[09/26 13:45:43 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1694, average loss: 3.1617
[09/26 13:45:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 41.50	
[09/26 13:45:43 visual_prompt]: Best epoch 15: best metric: 0.110
[09/26 13:45:43 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 13:45:50 visual_prompt]: Epoch 16 / 100: avg data time: 6.43e-02, avg batch time: 0.5121, average train loss: 2.7662
[09/26 13:45:52 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1687, average loss: 2.8078
[09/26 13:45:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 46.50	
[09/26 13:45:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 13:45:59 visual_prompt]: Epoch 17 / 100: avg data time: 6.26e-02, avg batch time: 0.5116, average train loss: 2.6219
[09/26 13:46:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1688, average loss: 2.8992
[09/26 13:46:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 42.00	
[09/26 13:46:00 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 13:46:07 visual_prompt]: Epoch 18 / 100: avg data time: 5.71e-02, avg batch time: 0.5068, average train loss: 2.5136
[09/26 13:46:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 3.0551
[09/26 13:46:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 42.00	
[09/26 13:46:09 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 13:46:16 visual_prompt]: Epoch 19 / 100: avg data time: 5.04e-02, avg batch time: 0.5000, average train loss: 2.4923
[09/26 13:46:17 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 2.8347
[09/26 13:46:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 13:46:17 visual_prompt]: Best epoch 19: best metric: 0.130
[09/26 13:46:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 13:46:24 visual_prompt]: Epoch 20 / 100: avg data time: 5.92e-02, avg batch time: 0.5070, average train loss: 2.2817
[09/26 13:46:26 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1692, average loss: 2.8576
[09/26 13:46:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 53.50	
[09/26 13:46:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 13:46:33 visual_prompt]: Epoch 21 / 100: avg data time: 5.94e-02, avg batch time: 0.5104, average train loss: 2.2288
[09/26 13:46:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1688, average loss: 2.9827
[09/26 13:46:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 53.50	
[09/26 13:46:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 13:46:41 visual_prompt]: Epoch 22 / 100: avg data time: 5.10e-02, avg batch time: 0.5009, average train loss: 2.1101
[09/26 13:46:43 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 2.8191
[09/26 13:46:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.50	
[09/26 13:46:43 visual_prompt]: Best epoch 22: best metric: 0.160
[09/26 13:46:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 13:46:49 visual_prompt]: Epoch 23 / 100: avg data time: 6.05e-02, avg batch time: 0.5085, average train loss: 1.9469
[09/26 13:46:51 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 2.9844
[09/26 13:46:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.50	
[09/26 13:46:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 13:46:58 visual_prompt]: Epoch 24 / 100: avg data time: 5.49e-02, avg batch time: 0.5036, average train loss: 1.6988
[09/26 13:46:59 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1690, average loss: 3.0421
[09/26 13:46:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.00	
[09/26 13:46:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 13:47:06 visual_prompt]: Epoch 25 / 100: avg data time: 5.51e-02, avg batch time: 0.5042, average train loss: 1.5430
[09/26 13:47:08 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1688, average loss: 3.6327
[09/26 13:47:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.50	
[09/26 13:47:08 visual_prompt]: Best epoch 25: best metric: 0.175
[09/26 13:47:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 13:47:15 visual_prompt]: Epoch 26 / 100: avg data time: 4.83e-02, avg batch time: 0.4974, average train loss: 1.3771
[09/26 13:47:16 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1690, average loss: 3.7025
[09/26 13:47:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 58.00	
[09/26 13:47:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 13:47:23 visual_prompt]: Epoch 27 / 100: avg data time: 6.01e-02, avg batch time: 0.5092, average train loss: 1.2381
[09/26 13:47:25 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1692, average loss: 4.2960
[09/26 13:47:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 13:47:25 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 13:47:32 visual_prompt]: Epoch 28 / 100: avg data time: 4.69e-02, avg batch time: 0.4980, average train loss: 1.1344
[09/26 13:47:33 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1692, average loss: 4.4812
[09/26 13:47:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.00	
[09/26 13:47:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 13:47:40 visual_prompt]: Epoch 29 / 100: avg data time: 5.15e-02, avg batch time: 0.4995, average train loss: 0.9801
[09/26 13:47:42 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 4.2557
[09/26 13:47:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 59.50	
[09/26 13:47:42 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 13:47:48 visual_prompt]: Epoch 30 / 100: avg data time: 5.26e-02, avg batch time: 0.5033, average train loss: 0.8358
[09/26 13:47:50 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1690, average loss: 4.4496
[09/26 13:47:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 57.00	
[09/26 13:47:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 13:47:57 visual_prompt]: Epoch 31 / 100: avg data time: 4.56e-02, avg batch time: 0.4970, average train loss: 0.6890
[09/26 13:47:58 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1699, average loss: 5.0602
[09/26 13:47:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.50	
[09/26 13:47:58 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 13:48:05 visual_prompt]: Epoch 32 / 100: avg data time: 5.90e-02, avg batch time: 0.5072, average train loss: 0.5177
[09/26 13:48:07 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1688, average loss: 5.4567
[09/26 13:48:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 60.00	
[09/26 13:48:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 13:48:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.08e-02, avg batch time: 0.4893, average train loss: 0.5552
[09/26 13:48:15 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1692, average loss: 5.2898
[09/26 13:48:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 60.50	
[09/26 13:48:15 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:48:22 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e-02, avg batch time: 0.5046, average train loss: 0.6637
[09/26 13:48:24 visual_prompt]: Inference (val):avg data time: 4.90e-05, avg batch time: 0.1692, average loss: 5.0329
[09/26 13:48:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 59.00	
[09/26 13:48:24 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:48:30 visual_prompt]: Epoch 35 / 100: avg data time: 5.65e-02, avg batch time: 0.5047, average train loss: 0.4718
[09/26 13:48:32 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1701, average loss: 5.2398
[09/26 13:48:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 13:48:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:48:39 visual_prompt]: Epoch 36 / 100: avg data time: 4.46e-02, avg batch time: 0.4938, average train loss: 0.3534
[09/26 13:48:40 visual_prompt]: Inference (val):avg data time: 4.92e-05, avg batch time: 0.1694, average loss: 5.7445
[09/26 13:48:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 13:48:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:48:47 visual_prompt]: Epoch 37 / 100: avg data time: 4.52e-02, avg batch time: 0.4947, average train loss: 0.1983
[09/26 13:48:49 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 6.1844
[09/26 13:48:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 57.50	
[09/26 13:48:49 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:48:55 visual_prompt]: Epoch 38 / 100: avg data time: 5.04e-02, avg batch time: 0.5002, average train loss: 0.1833
[09/26 13:48:57 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1693, average loss: 6.4897
[09/26 13:48:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 60.50	
[09/26 13:48:57 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:49:04 visual_prompt]: Epoch 39 / 100: avg data time: 4.88e-02, avg batch time: 0.4984, average train loss: 0.1432
[09/26 13:49:05 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 6.6225
[09/26 13:49:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 61.50	
[09/26 13:49:05 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:49:12 visual_prompt]: Epoch 40 / 100: avg data time: 4.68e-02, avg batch time: 0.4970, average train loss: 0.0981
[09/26 13:49:14 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1694, average loss: 6.8547
[09/26 13:49:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.00	
[09/26 13:49:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:49:20 visual_prompt]: Epoch 41 / 100: avg data time: 4.71e-02, avg batch time: 0.4962, average train loss: 0.0904
[09/26 13:49:22 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1690, average loss: 7.2539
[09/26 13:49:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 54.50	
[09/26 13:49:22 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:49:29 visual_prompt]: Epoch 42 / 100: avg data time: 5.51e-02, avg batch time: 0.5037, average train loss: 0.0922
[09/26 13:49:30 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1691, average loss: 7.2296
[09/26 13:49:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 61.50	
[09/26 13:49:30 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:49:37 visual_prompt]: Epoch 43 / 100: avg data time: 5.76e-02, avg batch time: 0.5066, average train loss: 0.0874
[09/26 13:49:39 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 6.8526
[09/26 13:49:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 58.00	
[09/26 13:49:39 visual_prompt]: Best epoch 43: best metric: 0.190
[09/26 13:49:39 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:49:46 visual_prompt]: Epoch 44 / 100: avg data time: 6.17e-02, avg batch time: 0.5108, average train loss: 0.0871
[09/26 13:49:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1691, average loss: 7.0105
[09/26 13:49:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 58.00	
[09/26 13:49:47 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:49:54 visual_prompt]: Epoch 45 / 100: avg data time: 5.69e-02, avg batch time: 0.5055, average train loss: 0.0621
[09/26 13:49:56 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1689, average loss: 6.9471
[09/26 13:49:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.00	
[09/26 13:49:56 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:50:02 visual_prompt]: Epoch 46 / 100: avg data time: 5.98e-02, avg batch time: 0.5080, average train loss: 0.0530
[09/26 13:50:04 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1694, average loss: 6.7789
[09/26 13:50:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 13:50:04 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:50:11 visual_prompt]: Epoch 47 / 100: avg data time: 4.97e-02, avg batch time: 0.5005, average train loss: 0.0412
[09/26 13:50:12 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1690, average loss: 6.7942
[09/26 13:50:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 13:50:12 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:50:19 visual_prompt]: Epoch 48 / 100: avg data time: 4.51e-02, avg batch time: 0.4948, average train loss: 0.0205
[09/26 13:50:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 6.9704
[09/26 13:50:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 58.50	
[09/26 13:50:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:50:28 visual_prompt]: Epoch 49 / 100: avg data time: 5.18e-02, avg batch time: 0.5002, average train loss: 0.0140
[09/26 13:50:29 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1696, average loss: 6.9322
[09/26 13:50:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.50	
[09/26 13:50:29 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:50:36 visual_prompt]: Epoch 50 / 100: avg data time: 5.23e-02, avg batch time: 0.5018, average train loss: 0.0104
[09/26 13:50:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 6.9142
[09/26 13:50:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.00	
[09/26 13:50:38 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:50:44 visual_prompt]: Epoch 51 / 100: avg data time: 5.00e-02, avg batch time: 0.4989, average train loss: 0.0082
[09/26 13:50:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 6.9345
[09/26 13:50:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 61.50	
[09/26 13:50:46 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:50:53 visual_prompt]: Epoch 52 / 100: avg data time: 4.52e-02, avg batch time: 0.4953, average train loss: 0.0076
[09/26 13:50:54 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 6.9100
[09/26 13:50:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 62.00	
[09/26 13:50:54 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:51:01 visual_prompt]: Epoch 53 / 100: avg data time: 6.13e-02, avg batch time: 0.5110, average train loss: 0.0067
[09/26 13:51:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 6.9377
[09/26 13:51:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 62.50	
[09/26 13:51:03 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:51:10 visual_prompt]: Epoch 54 / 100: avg data time: 4.81e-02, avg batch time: 0.4998, average train loss: 0.0056
[09/26 13:51:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 6.9322
[09/26 13:51:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.50	
[09/26 13:51:11 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:51:18 visual_prompt]: Epoch 55 / 100: avg data time: 5.79e-02, avg batch time: 0.5071, average train loss: 0.0052
[09/26 13:51:20 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1687, average loss: 6.9993
[09/26 13:51:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.00	
[09/26 13:51:20 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:51:26 visual_prompt]: Epoch 56 / 100: avg data time: 5.94e-02, avg batch time: 0.5087, average train loss: 0.0051
[09/26 13:51:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 7.0205
[09/26 13:51:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 13:51:28 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:51:35 visual_prompt]: Epoch 57 / 100: avg data time: 5.75e-02, avg batch time: 0.5058, average train loss: 0.0036
[09/26 13:51:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 7.0343
[09/26 13:51:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.50	
[09/26 13:51:36 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:51:43 visual_prompt]: Epoch 58 / 100: avg data time: 5.88e-02, avg batch time: 0.5072, average train loss: 0.0039
[09/26 13:51:45 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1692, average loss: 7.0501
[09/26 13:51:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 60.50	
[09/26 13:51:45 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:51:52 visual_prompt]: Epoch 59 / 100: avg data time: 5.49e-02, avg batch time: 0.5044, average train loss: 0.0036
[09/26 13:51:53 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1693, average loss: 7.0649
[09/26 13:51:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.00	
[09/26 13:51:53 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:52:00 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.5060, average train loss: 0.0042
[09/26 13:52:02 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1690, average loss: 7.0642
[09/26 13:52:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 60.50	
[09/26 13:52:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:52:09 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.5080, average train loss: 0.0038
[09/26 13:52:10 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.1692, average loss: 7.0841
[09/26 13:52:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 60.50	
[09/26 13:52:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:52:17 visual_prompt]: Epoch 62 / 100: avg data time: 5.82e-02, avg batch time: 0.5082, average train loss: 0.0034
[09/26 13:52:19 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 7.1012
[09/26 13:52:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 13:52:19 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:52:25 visual_prompt]: Epoch 63 / 100: avg data time: 4.97e-02, avg batch time: 0.5003, average train loss: 0.0027
[09/26 13:52:27 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1691, average loss: 7.1185
[09/26 13:52:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 13:52:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:52:34 visual_prompt]: Epoch 64 / 100: avg data time: 6.33e-02, avg batch time: 0.5118, average train loss: 0.0032
[09/26 13:52:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 7.1197
[09/26 13:52:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:52:35 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:52:42 visual_prompt]: Epoch 65 / 100: avg data time: 4.82e-02, avg batch time: 0.4980, average train loss: 0.0027
[09/26 13:52:44 visual_prompt]: Inference (val):avg data time: 4.53e-05, avg batch time: 0.1691, average loss: 7.1198
[09/26 13:52:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:52:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:52:51 visual_prompt]: Epoch 66 / 100: avg data time: 6.39e-02, avg batch time: 0.5124, average train loss: 0.0027
[09/26 13:52:52 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 7.1187
[09/26 13:52:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:52:52 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:52:59 visual_prompt]: Epoch 67 / 100: avg data time: 5.73e-02, avg batch time: 0.5064, average train loss: 0.0028
[09/26 13:53:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1693, average loss: 7.1353
[09/26 13:53:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:53:08 visual_prompt]: Epoch 68 / 100: avg data time: 5.62e-02, avg batch time: 0.5064, average train loss: 0.0027
[09/26 13:53:09 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1694, average loss: 7.1529
[09/26 13:53:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 13:53:09 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:53:16 visual_prompt]: Epoch 69 / 100: avg data time: 5.68e-02, avg batch time: 0.5054, average train loss: 0.0028
[09/26 13:53:18 visual_prompt]: Inference (val):avg data time: 4.92e-05, avg batch time: 0.1690, average loss: 7.1623
[09/26 13:53:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:18 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:53:25 visual_prompt]: Epoch 70 / 100: avg data time: 6.02e-02, avg batch time: 0.5080, average train loss: 0.0034
[09/26 13:53:26 visual_prompt]: Inference (val):avg data time: 5.26e-05, avg batch time: 0.1692, average loss: 7.1391
[09/26 13:53:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:26 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:53:33 visual_prompt]: Epoch 71 / 100: avg data time: 5.42e-02, avg batch time: 0.5024, average train loss: 0.0027
[09/26 13:53:35 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1691, average loss: 7.1313
[09/26 13:53:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:53:41 visual_prompt]: Epoch 72 / 100: avg data time: 5.76e-02, avg batch time: 0.5070, average train loss: 0.0033
[09/26 13:53:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1689, average loss: 7.1292
[09/26 13:53:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:43 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:53:50 visual_prompt]: Epoch 73 / 100: avg data time: 5.48e-02, avg batch time: 0.5047, average train loss: 0.0022
[09/26 13:53:51 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1693, average loss: 7.1309
[09/26 13:53:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:53:51 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:53:58 visual_prompt]: Epoch 74 / 100: avg data time: 5.88e-02, avg batch time: 0.5091, average train loss: 0.0025
[09/26 13:54:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1691, average loss: 7.1303
[09/26 13:54:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.50	
[09/26 13:54:00 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:54:07 visual_prompt]: Epoch 75 / 100: avg data time: 5.40e-02, avg batch time: 0.5027, average train loss: 0.0030
[09/26 13:54:08 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1687, average loss: 7.1238
[09/26 13:54:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 61.50	
[09/26 13:54:08 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:54:15 visual_prompt]: Epoch 76 / 100: avg data time: 5.76e-02, avg batch time: 0.5058, average train loss: 0.0029
[09/26 13:54:17 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1688, average loss: 7.1146
[09/26 13:54:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 62.00	
[09/26 13:54:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:54:24 visual_prompt]: Epoch 77 / 100: avg data time: 5.74e-02, avg batch time: 0.5070, average train loss: 0.0022
[09/26 13:54:25 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1687, average loss: 7.1226
[09/26 13:54:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 61.50	
[09/26 13:54:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:54:32 visual_prompt]: Epoch 78 / 100: avg data time: 5.27e-02, avg batch time: 0.5018, average train loss: 0.0024
[09/26 13:54:34 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1689, average loss: 7.1318
[09/26 13:54:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.00	
[09/26 13:54:34 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:54:40 visual_prompt]: Epoch 79 / 100: avg data time: 6.51e-02, avg batch time: 0.5134, average train loss: 0.0022
[09/26 13:54:42 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1695, average loss: 7.1389
[09/26 13:54:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.50	
[09/26 13:54:42 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:54:49 visual_prompt]: Epoch 80 / 100: avg data time: 6.30e-02, avg batch time: 0.5123, average train loss: 0.0022
[09/26 13:54:50 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 7.1429
[09/26 13:54:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 61.50	
[09/26 13:54:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:54:57 visual_prompt]: Epoch 81 / 100: avg data time: 6.28e-02, avg batch time: 0.5109, average train loss: 0.0022
[09/26 13:54:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1691, average loss: 7.1451
[09/26 13:54:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 13:54:59 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:55:06 visual_prompt]: Epoch 82 / 100: avg data time: 5.79e-02, avg batch time: 0.5060, average train loss: 0.0023
[09/26 13:55:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1691, average loss: 7.1475
[09/26 13:55:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 13:55:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:55:14 visual_prompt]: Epoch 83 / 100: avg data time: 5.63e-02, avg batch time: 0.5044, average train loss: 0.0025
[09/26 13:55:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 7.1521
[09/26 13:55:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 13:55:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:55:22 visual_prompt]: Epoch 84 / 100: avg data time: 4.48e-02, avg batch time: 0.4953, average train loss: 0.0026
[09/26 13:55:24 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1690, average loss: 7.1535
[09/26 13:55:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 13:55:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:55:31 visual_prompt]: Epoch 85 / 100: avg data time: 5.83e-02, avg batch time: 0.5066, average train loss: 0.0026
[09/26 13:55:32 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 7.1570
[09/26 13:55:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:55:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:55:39 visual_prompt]: Epoch 86 / 100: avg data time: 6.00e-02, avg batch time: 0.5088, average train loss: 0.0024
[09/26 13:55:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 7.1638
[09/26 13:55:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:55:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:55:48 visual_prompt]: Epoch 87 / 100: avg data time: 6.63e-02, avg batch time: 0.5147, average train loss: 0.0021
[09/26 13:55:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1692, average loss: 7.1669
[09/26 13:55:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:55:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:55:56 visual_prompt]: Epoch 88 / 100: avg data time: 4.70e-02, avg batch time: 0.4972, average train loss: 0.0023
[09/26 13:55:58 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1691, average loss: 7.1683
[09/26 13:55:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:55:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:56:04 visual_prompt]: Epoch 89 / 100: avg data time: 4.55e-02, avg batch time: 0.4960, average train loss: 0.0023
[09/26 13:56:06 visual_prompt]: Inference (val):avg data time: 5.53e-05, avg batch time: 0.1699, average loss: 7.1703
[09/26 13:56:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:56:13 visual_prompt]: Epoch 90 / 100: avg data time: 5.79e-02, avg batch time: 0.5081, average train loss: 0.0026
[09/26 13:56:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 7.1733
[09/26 13:56:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:56:21 visual_prompt]: Epoch 91 / 100: avg data time: 4.68e-02, avg batch time: 0.4963, average train loss: 0.0025
[09/26 13:56:23 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 7.1735
[09/26 13:56:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:56:30 visual_prompt]: Epoch 92 / 100: avg data time: 5.90e-02, avg batch time: 0.5074, average train loss: 0.0020
[09/26 13:56:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 7.1737
[09/26 13:56:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:56:38 visual_prompt]: Epoch 93 / 100: avg data time: 5.76e-02, avg batch time: 0.5083, average train loss: 0.0022
[09/26 13:56:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 7.1748
[09/26 13:56:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:56:46 visual_prompt]: Epoch 94 / 100: avg data time: 5.95e-02, avg batch time: 0.5089, average train loss: 0.0023
[09/26 13:56:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 7.1750
[09/26 13:56:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:56:55 visual_prompt]: Epoch 95 / 100: avg data time: 6.05e-02, avg batch time: 0.5097, average train loss: 0.0023
[09/26 13:56:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1693, average loss: 7.1754
[09/26 13:56:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:56:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:57:03 visual_prompt]: Epoch 96 / 100: avg data time: 5.90e-02, avg batch time: 0.5083, average train loss: 0.0022
[09/26 13:57:05 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1690, average loss: 7.1756
[09/26 13:57:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:57:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:57:12 visual_prompt]: Epoch 97 / 100: avg data time: 4.75e-02, avg batch time: 0.4964, average train loss: 0.0022
[09/26 13:57:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 7.1757
[09/26 13:57:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:57:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:57:20 visual_prompt]: Epoch 98 / 100: avg data time: 5.64e-02, avg batch time: 0.5060, average train loss: 0.0034
[09/26 13:57:22 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1694, average loss: 7.1758
[09/26 13:57:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:57:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:57:28 visual_prompt]: Epoch 99 / 100: avg data time: 5.49e-02, avg batch time: 0.5037, average train loss: 0.0019
[09/26 13:57:30 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 7.1757
[09/26 13:57:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:57:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:57:37 visual_prompt]: Epoch 100 / 100: avg data time: 5.11e-02, avg batch time: 0.5016, average train loss: 0.0022
[09/26 13:57:38 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1696, average loss: 7.1757
[09/26 13:57:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.00	
[09/26 13:57:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:57:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:57:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:57:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:57:38 visual_prompt]: Training with config:
[09/26 13:57:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:57:38 visual_prompt]: Loading training data...
[09/26 13:57:38 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:57:39 visual_prompt]: Number of images: 800
[09/26 13:57:39 visual_prompt]: Number of classes: 18 / 18
[09/26 13:57:39 visual_prompt]: Loading validation data...
[09/26 13:57:39 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 13:57:40 visual_prompt]: Number of images: 200
[09/26 13:57:40 visual_prompt]: Number of classes: 18 / 18
[09/26 13:57:40 visual_prompt]: Constructing models...
[09/26 13:57:42 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 13:57:42 visual_prompt]: tuned percent:0.550
[09/26 13:57:42 visual_prompt]: Device used for model: 0
[09/26 13:57:42 visual_prompt]: Setting up Evaluator...
[09/26 13:57:42 visual_prompt]: Setting up Trainer...
[09/26 13:57:42 visual_prompt]: 	Setting up the optimizer...
[09/26 13:57:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:57:49 visual_prompt]: Epoch 1 / 100: avg data time: 5.75e-02, avg batch time: 0.5042, average train loss: 3.2557
[09/26 13:57:51 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1683, average loss: 3.1895
[09/26 13:57:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 13:57:51 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 13:57:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 13:57:58 visual_prompt]: Epoch 2 / 100: avg data time: 6.06e-02, avg batch time: 0.5083, average train loss: 2.9742
[09/26 13:57:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1683, average loss: 2.9463
[09/26 13:57:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 13:57:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 13:58:06 visual_prompt]: Epoch 3 / 100: avg data time: 4.44e-02, avg batch time: 0.4940, average train loss: 2.9037
[09/26 13:58:08 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 3.0259
[09/26 13:58:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 13:58:08 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 13:58:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 13:58:14 visual_prompt]: Epoch 4 / 100: avg data time: 4.71e-02, avg batch time: 0.4956, average train loss: 2.9372
[09/26 13:58:16 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 2.9271
[09/26 13:58:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 13:58:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 13:58:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.59e-02, avg batch time: 0.5033, average train loss: 2.9265
[09/26 13:58:24 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 2.9170
[09/26 13:58:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 13:58:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 13:58:31 visual_prompt]: Epoch 6 / 100: avg data time: 5.33e-02, avg batch time: 0.5022, average train loss: 2.9171
[09/26 13:58:33 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1689, average loss: 2.9132
[09/26 13:58:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 13:58:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 13:58:39 visual_prompt]: Epoch 7 / 100: avg data time: 5.59e-02, avg batch time: 0.5050, average train loss: 2.9171
[09/26 13:58:41 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1687, average loss: 2.9003
[09/26 13:58:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 13:58:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 13:58:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.34e-02, avg batch time: 0.5020, average train loss: 2.9075
[09/26 13:58:49 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1690, average loss: 2.9185
[09/26 13:58:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 13:58:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 13:58:56 visual_prompt]: Epoch 9 / 100: avg data time: 6.19e-02, avg batch time: 0.5101, average train loss: 2.9070
[09/26 13:58:58 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 2.9014
[09/26 13:58:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 27.00	
[09/26 13:58:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 13:59:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.47e-02, avg batch time: 0.5032, average train loss: 2.9085
[09/26 13:59:06 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 2.9145
[09/26 13:59:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 13:59:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 13:59:13 visual_prompt]: Epoch 11 / 100: avg data time: 6.07e-02, avg batch time: 0.5095, average train loss: 2.9034
[09/26 13:59:15 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1693, average loss: 2.9019
[09/26 13:59:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 13:59:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 13:59:22 visual_prompt]: Epoch 12 / 100: avg data time: 6.23e-02, avg batch time: 0.5100, average train loss: 2.8844
[09/26 13:59:23 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1689, average loss: 2.9051
[09/26 13:59:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 33.00	
[09/26 13:59:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 13:59:30 visual_prompt]: Epoch 13 / 100: avg data time: 4.45e-02, avg batch time: 0.4950, average train loss: 2.8997
[09/26 13:59:32 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1691, average loss: 2.9305
[09/26 13:59:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 13:59:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 13:59:38 visual_prompt]: Epoch 14 / 100: avg data time: 5.59e-02, avg batch time: 0.5039, average train loss: 2.8965
[09/26 13:59:40 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1688, average loss: 2.9068
[09/26 13:59:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 32.00	
[09/26 13:59:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 13:59:47 visual_prompt]: Epoch 15 / 100: avg data time: 5.67e-02, avg batch time: 0.5042, average train loss: 2.8959
[09/26 13:59:48 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1689, average loss: 2.8994
[09/26 13:59:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 26.50	
[09/26 13:59:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 13:59:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.87e-02, avg batch time: 0.5078, average train loss: 2.8991
[09/26 13:59:57 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1689, average loss: 2.9080
[09/26 13:59:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 13:59:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 14:00:04 visual_prompt]: Epoch 17 / 100: avg data time: 5.77e-02, avg batch time: 0.5050, average train loss: 2.9061
[09/26 14:00:05 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 2.9132
[09/26 14:00:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 27.00	
[09/26 14:00:05 visual_prompt]: Best epoch 17: best metric: 0.105
[09/26 14:00:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 14:00:12 visual_prompt]: Epoch 18 / 100: avg data time: 4.30e-02, avg batch time: 0.4937, average train loss: 2.9016
[09/26 14:00:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1686, average loss: 2.9044
[09/26 14:00:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 14:00:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 14:00:20 visual_prompt]: Epoch 19 / 100: avg data time: 4.48e-02, avg batch time: 0.4933, average train loss: 2.9085
[09/26 14:00:22 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1690, average loss: 2.8988
[09/26 14:00:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.00	
[09/26 14:00:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 14:00:29 visual_prompt]: Epoch 20 / 100: avg data time: 5.46e-02, avg batch time: 0.5030, average train loss: 2.8991
[09/26 14:00:30 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1686, average loss: 2.9024
[09/26 14:00:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.50	
[09/26 14:00:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 14:00:37 visual_prompt]: Epoch 21 / 100: avg data time: 4.35e-02, avg batch time: 0.4917, average train loss: 2.9096
[09/26 14:00:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1688, average loss: 2.9057
[09/26 14:00:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 14:00:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 14:00:45 visual_prompt]: Epoch 22 / 100: avg data time: 5.72e-02, avg batch time: 0.5052, average train loss: 2.8994
[09/26 14:00:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1688, average loss: 2.9221
[09/26 14:00:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 25.00	
[09/26 14:00:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 14:00:54 visual_prompt]: Epoch 23 / 100: avg data time: 5.33e-02, avg batch time: 0.5011, average train loss: 2.9143
[09/26 14:00:55 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 2.9106
[09/26 14:00:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 14:00:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 14:01:02 visual_prompt]: Epoch 24 / 100: avg data time: 5.38e-02, avg batch time: 0.5018, average train loss: 2.9063
[09/26 14:01:04 visual_prompt]: Inference (val):avg data time: 4.94e-05, avg batch time: 0.1690, average loss: 2.9153
[09/26 14:01:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 14:01:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 14:01:11 visual_prompt]: Epoch 25 / 100: avg data time: 4.78e-02, avg batch time: 0.4950, average train loss: 2.9081
[09/26 14:01:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1684, average loss: 2.9038
[09/26 14:01:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 29.00	
[09/26 14:01:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 14:01:19 visual_prompt]: Epoch 26 / 100: avg data time: 6.18e-02, avg batch time: 0.5084, average train loss: 2.8971
[09/26 14:01:21 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1686, average loss: 2.9166
[09/26 14:01:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 14:01:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 14:01:27 visual_prompt]: Epoch 27 / 100: avg data time: 4.21e-02, avg batch time: 0.4890, average train loss: 2.9057
[09/26 14:01:29 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 2.9148
[09/26 14:01:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:01:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 14:01:36 visual_prompt]: Epoch 28 / 100: avg data time: 4.45e-02, avg batch time: 0.4927, average train loss: 2.9047
[09/26 14:01:37 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1685, average loss: 2.9070
[09/26 14:01:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 14:01:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 14:01:44 visual_prompt]: Epoch 29 / 100: avg data time: 4.37e-02, avg batch time: 0.4920, average train loss: 2.8953
[09/26 14:01:45 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1685, average loss: 2.9196
[09/26 14:01:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 14:01:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 14:01:52 visual_prompt]: Epoch 30 / 100: avg data time: 4.37e-02, avg batch time: 0.4905, average train loss: 2.9076
[09/26 14:01:53 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1685, average loss: 2.9129
[09/26 14:01:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 14:01:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 14:02:00 visual_prompt]: Epoch 31 / 100: avg data time: 4.32e-02, avg batch time: 0.4901, average train loss: 2.9002
[09/26 14:02:02 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1683, average loss: 2.9021
[09/26 14:02:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 14:02:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 14:02:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.42e-02, avg batch time: 0.5015, average train loss: 2.8944
[09/26 14:02:10 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1687, average loss: 2.9085
[09/26 14:02:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 14:02:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 14:02:17 visual_prompt]: Epoch 33 / 100: avg data time: 6.11e-02, avg batch time: 0.5088, average train loss: 2.8961
[09/26 14:02:19 visual_prompt]: Inference (val):avg data time: 4.29e-05, avg batch time: 0.1687, average loss: 2.9523
[09/26 14:02:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 23.50	
[09/26 14:02:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 14:02:25 visual_prompt]: Epoch 34 / 100: avg data time: 5.94e-02, avg batch time: 0.5076, average train loss: 2.9025
[09/26 14:02:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 2.9056
[09/26 14:02:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 29.00	
[09/26 14:02:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 14:02:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.65e-02, avg batch time: 0.4966, average train loss: 2.9013
[09/26 14:02:35 visual_prompt]: Inference (val):avg data time: 5.02e-05, avg batch time: 0.1689, average loss: 2.9081
[09/26 14:02:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 14:02:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 14:02:42 visual_prompt]: Epoch 36 / 100: avg data time: 5.82e-02, avg batch time: 0.5082, average train loss: 2.8928
[09/26 14:02:44 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1687, average loss: 2.9067
[09/26 14:02:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 14:02:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 14:02:50 visual_prompt]: Epoch 37 / 100: avg data time: 4.84e-02, avg batch time: 0.4990, average train loss: 2.8995
[09/26 14:02:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 2.9095
[09/26 14:02:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 14:02:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 14:02:59 visual_prompt]: Epoch 38 / 100: avg data time: 5.80e-02, avg batch time: 0.5070, average train loss: 2.8983
[09/26 14:03:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 2.9155
[09/26 14:03:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:03:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 14:03:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.86e-02, avg batch time: 0.5067, average train loss: 2.8958
[09/26 14:03:09 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1685, average loss: 2.9127
[09/26 14:03:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 14:03:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 14:03:16 visual_prompt]: Epoch 40 / 100: avg data time: 6.03e-02, avg batch time: 0.5080, average train loss: 2.8898
[09/26 14:03:17 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1684, average loss: 2.9015
[09/26 14:03:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 14:03:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 14:03:24 visual_prompt]: Epoch 41 / 100: avg data time: 6.12e-02, avg batch time: 0.5081, average train loss: 2.8949
[09/26 14:03:26 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1686, average loss: 2.9025
[09/26 14:03:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 14:03:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 14:03:33 visual_prompt]: Epoch 42 / 100: avg data time: 5.72e-02, avg batch time: 0.5044, average train loss: 2.8917
[09/26 14:03:34 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1685, average loss: 2.9080
[09/26 14:03:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:03:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 14:03:41 visual_prompt]: Epoch 43 / 100: avg data time: 4.84e-02, avg batch time: 0.4965, average train loss: 2.8989
[09/26 14:03:42 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1686, average loss: 2.9133
[09/26 14:03:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 26.50	
[09/26 14:03:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 14:03:49 visual_prompt]: Epoch 44 / 100: avg data time: 5.90e-02, avg batch time: 0.5068, average train loss: 2.8943
[09/26 14:03:51 visual_prompt]: Inference (val):avg data time: 4.34e-05, avg batch time: 0.1725, average loss: 2.9037
[09/26 14:03:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 14:03:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 14:03:58 visual_prompt]: Epoch 45 / 100: avg data time: 5.85e-02, avg batch time: 0.5053, average train loss: 2.8942
[09/26 14:04:00 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1686, average loss: 2.9088
[09/26 14:04:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 14:04:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 14:04:06 visual_prompt]: Epoch 46 / 100: avg data time: 5.32e-02, avg batch time: 0.5001, average train loss: 2.8956
[09/26 14:04:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 2.9294
[09/26 14:04:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 14:04:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 14:04:15 visual_prompt]: Epoch 47 / 100: avg data time: 6.31e-02, avg batch time: 0.5101, average train loss: 2.9014
[09/26 14:04:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1686, average loss: 2.9109
[09/26 14:04:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 14:04:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 14:04:23 visual_prompt]: Epoch 48 / 100: avg data time: 5.75e-02, avg batch time: 0.5054, average train loss: 2.8934
[09/26 14:04:25 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 2.9095
[09/26 14:04:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 14:04:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 14:04:32 visual_prompt]: Epoch 49 / 100: avg data time: 5.71e-02, avg batch time: 0.5042, average train loss: 2.8880
[09/26 14:04:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 2.9089
[09/26 14:04:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:04:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 14:04:40 visual_prompt]: Epoch 50 / 100: avg data time: 5.95e-02, avg batch time: 0.5075, average train loss: 2.8936
[09/26 14:04:42 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1692, average loss: 2.9090
[09/26 14:04:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 14:04:42 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 14:04:49 visual_prompt]: Epoch 51 / 100: avg data time: 5.87e-02, avg batch time: 0.5084, average train loss: 2.8996
[09/26 14:04:50 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 2.9026
[09/26 14:04:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 14:04:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 14:04:57 visual_prompt]: Epoch 52 / 100: avg data time: 4.77e-02, avg batch time: 0.4983, average train loss: 2.8984
[09/26 14:04:59 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1689, average loss: 2.9212
[09/26 14:04:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 14:04:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 14:05:05 visual_prompt]: Epoch 53 / 100: avg data time: 4.39e-02, avg batch time: 0.4926, average train loss: 2.9100
[09/26 14:05:07 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1692, average loss: 2.9102
[09/26 14:05:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 14:05:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 14:05:14 visual_prompt]: Epoch 54 / 100: avg data time: 6.19e-02, avg batch time: 0.5103, average train loss: 2.8946
[09/26 14:05:15 visual_prompt]: Inference (val):avg data time: 4.35e-05, avg batch time: 0.1690, average loss: 2.9087
[09/26 14:05:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 14:05:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 14:05:22 visual_prompt]: Epoch 55 / 100: avg data time: 4.99e-02, avg batch time: 0.4967, average train loss: 2.8959
[09/26 14:05:24 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1687, average loss: 2.9139
[09/26 14:05:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 14:05:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 14:05:30 visual_prompt]: Epoch 56 / 100: avg data time: 4.90e-02, avg batch time: 0.4974, average train loss: 2.8968
[09/26 14:05:32 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1690, average loss: 2.9076
[09/26 14:05:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 14:05:32 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 14:05:39 visual_prompt]: Epoch 57 / 100: avg data time: 5.46e-02, avg batch time: 0.5033, average train loss: 2.8878
[09/26 14:05:40 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1687, average loss: 2.9128
[09/26 14:05:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.00	
[09/26 14:05:40 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 14:05:47 visual_prompt]: Epoch 58 / 100: avg data time: 5.39e-02, avg batch time: 0.5024, average train loss: 2.8880
[09/26 14:05:48 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 2.9019
[09/26 14:05:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:05:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:05:55 visual_prompt]: Epoch 59 / 100: avg data time: 6.39e-02, avg batch time: 0.5116, average train loss: 2.8861
[09/26 14:05:57 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1688, average loss: 2.9058
[09/26 14:05:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 14:05:57 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:06:04 visual_prompt]: Epoch 60 / 100: avg data time: 4.68e-02, avg batch time: 0.4971, average train loss: 2.8885
[09/26 14:06:05 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1687, average loss: 2.9086
[09/26 14:06:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 28.50	
[09/26 14:06:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:06:12 visual_prompt]: Epoch 61 / 100: avg data time: 5.96e-02, avg batch time: 0.5073, average train loss: 2.8855
[09/26 14:06:14 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1690, average loss: 2.9110
[09/26 14:06:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 14:06:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:06:21 visual_prompt]: Epoch 62 / 100: avg data time: 5.45e-02, avg batch time: 0.5029, average train loss: 2.8841
[09/26 14:06:22 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1689, average loss: 2.9054
[09/26 14:06:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:06:22 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:06:29 visual_prompt]: Epoch 63 / 100: avg data time: 6.33e-02, avg batch time: 0.5109, average train loss: 2.8883
[09/26 14:06:31 visual_prompt]: Inference (val):avg data time: 5.02e-05, avg batch time: 0.1687, average loss: 2.9147
[09/26 14:06:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.50	
[09/26 14:06:31 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:06:38 visual_prompt]: Epoch 64 / 100: avg data time: 6.23e-02, avg batch time: 0.5366, average train loss: 2.8883
[09/26 14:06:40 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1689, average loss: 2.9059
[09/26 14:06:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.50	
[09/26 14:06:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:06:46 visual_prompt]: Epoch 65 / 100: avg data time: 4.05e-02, avg batch time: 0.4884, average train loss: 2.8845
[09/26 14:06:48 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1688, average loss: 2.9086
[09/26 14:06:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 27.00	
[09/26 14:06:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:06:55 visual_prompt]: Epoch 66 / 100: avg data time: 5.92e-02, avg batch time: 0.5068, average train loss: 2.8856
[09/26 14:06:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1687, average loss: 2.9015
[09/26 14:06:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 14:06:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:07:03 visual_prompt]: Epoch 67 / 100: avg data time: 4.42e-02, avg batch time: 0.4940, average train loss: 2.8791
[09/26 14:07:05 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1687, average loss: 2.9085
[09/26 14:07:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 14:07:05 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:07:11 visual_prompt]: Epoch 68 / 100: avg data time: 4.76e-02, avg batch time: 0.4954, average train loss: 2.8873
[09/26 14:07:13 visual_prompt]: Inference (val):avg data time: 4.81e-05, avg batch time: 0.1687, average loss: 2.8996
[09/26 14:07:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:07:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:07:20 visual_prompt]: Epoch 69 / 100: avg data time: 5.48e-02, avg batch time: 0.5020, average train loss: 2.8872
[09/26 14:07:21 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1689, average loss: 2.9078
[09/26 14:07:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:07:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:07:28 visual_prompt]: Epoch 70 / 100: avg data time: 5.66e-02, avg batch time: 0.5046, average train loss: 2.8808
[09/26 14:07:30 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1686, average loss: 2.8996
[09/26 14:07:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 30.00	
[09/26 14:07:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:07:36 visual_prompt]: Epoch 71 / 100: avg data time: 4.44e-02, avg batch time: 0.4940, average train loss: 2.8800
[09/26 14:07:38 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1683, average loss: 2.8972
[09/26 14:07:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.00	
[09/26 14:07:38 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:07:45 visual_prompt]: Epoch 72 / 100: avg data time: 5.62e-02, avg batch time: 0.5039, average train loss: 2.8764
[09/26 14:07:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1688, average loss: 2.9078
[09/26 14:07:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.50	
[09/26 14:07:46 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:07:53 visual_prompt]: Epoch 73 / 100: avg data time: 4.49e-02, avg batch time: 0.4946, average train loss: 2.8796
[09/26 14:07:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1689, average loss: 2.9017
[09/26 14:07:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 14:07:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:08:02 visual_prompt]: Epoch 74 / 100: avg data time: 5.83e-02, avg batch time: 0.5055, average train loss: 2.8829
[09/26 14:08:03 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1688, average loss: 2.9061
[09/26 14:08:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 14:08:03 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:08:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.64e-02, avg batch time: 0.5035, average train loss: 2.8795
[09/26 14:08:12 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1688, average loss: 2.9024
[09/26 14:08:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 29.50	
[09/26 14:08:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:08:18 visual_prompt]: Epoch 76 / 100: avg data time: 4.56e-02, avg batch time: 0.4943, average train loss: 2.8835
[09/26 14:08:20 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 2.9002
[09/26 14:08:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 14:08:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:08:27 visual_prompt]: Epoch 77 / 100: avg data time: 4.62e-02, avg batch time: 0.4953, average train loss: 2.8775
[09/26 14:08:28 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1690, average loss: 2.9147
[09/26 14:08:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 14:08:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:08:35 visual_prompt]: Epoch 78 / 100: avg data time: 4.53e-02, avg batch time: 0.4947, average train loss: 2.8734
[09/26 14:08:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1688, average loss: 2.8992
[09/26 14:08:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 14:08:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:08:43 visual_prompt]: Epoch 79 / 100: avg data time: 5.32e-02, avg batch time: 0.5014, average train loss: 2.8767
[09/26 14:08:45 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1693, average loss: 2.9042
[09/26 14:08:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 30.00	
[09/26 14:08:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:08:52 visual_prompt]: Epoch 80 / 100: avg data time: 4.53e-02, avg batch time: 0.4931, average train loss: 2.8843
[09/26 14:08:53 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1689, average loss: 2.9096
[09/26 14:08:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:08:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:09:00 visual_prompt]: Epoch 81 / 100: avg data time: 4.35e-02, avg batch time: 0.4919, average train loss: 2.8843
[09/26 14:09:01 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1689, average loss: 2.9080
[09/26 14:09:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:09:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:09:08 visual_prompt]: Epoch 82 / 100: avg data time: 5.07e-02, avg batch time: 0.5011, average train loss: 2.8842
[09/26 14:09:10 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1687, average loss: 2.9036
[09/26 14:09:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:09:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:09:16 visual_prompt]: Epoch 83 / 100: avg data time: 4.37e-02, avg batch time: 0.4954, average train loss: 2.8834
[09/26 14:09:18 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1685, average loss: 2.8979
[09/26 14:09:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 14:09:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:09:25 visual_prompt]: Epoch 84 / 100: avg data time: 4.59e-02, avg batch time: 0.4944, average train loss: 2.8818
[09/26 14:09:26 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 2.9055
[09/26 14:09:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:09:26 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:09:33 visual_prompt]: Epoch 85 / 100: avg data time: 4.46e-02, avg batch time: 0.4958, average train loss: 2.8924
[09/26 14:09:35 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1687, average loss: 2.9025
[09/26 14:09:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.00	
[09/26 14:09:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:09:41 visual_prompt]: Epoch 86 / 100: avg data time: 5.79e-02, avg batch time: 0.5050, average train loss: 2.8830
[09/26 14:09:43 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1685, average loss: 2.9045
[09/26 14:09:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 29.50	
[09/26 14:09:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:09:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.30e-02, avg batch time: 0.5007, average train loss: 2.8794
[09/26 14:09:51 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1686, average loss: 2.9241
[09/26 14:09:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 14:09:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:09:58 visual_prompt]: Epoch 88 / 100: avg data time: 6.47e-02, avg batch time: 0.5129, average train loss: 2.8833
[09/26 14:10:00 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1686, average loss: 2.9004
[09/26 14:10:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:10:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:10:06 visual_prompt]: Epoch 89 / 100: avg data time: 4.36e-02, avg batch time: 0.4924, average train loss: 2.8804
[09/26 14:10:08 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1687, average loss: 2.9045
[09/26 14:10:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 14:10:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:10:15 visual_prompt]: Epoch 90 / 100: avg data time: 5.18e-02, avg batch time: 0.4992, average train loss: 2.8801
[09/26 14:10:16 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1685, average loss: 2.9065
[09/26 14:10:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 27.00	
[09/26 14:10:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:10:23 visual_prompt]: Epoch 91 / 100: avg data time: 5.22e-02, avg batch time: 0.5006, average train loss: 2.8790
[09/26 14:10:25 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1687, average loss: 2.9049
[09/26 14:10:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 14:10:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:10:32 visual_prompt]: Epoch 92 / 100: avg data time: 6.42e-02, avg batch time: 0.5122, average train loss: 2.8798
[09/26 14:10:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1684, average loss: 2.9056
[09/26 14:10:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 27.00	
[09/26 14:10:33 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:10:40 visual_prompt]: Epoch 93 / 100: avg data time: 5.31e-02, avg batch time: 0.5014, average train loss: 2.8792
[09/26 14:10:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1684, average loss: 2.9042
[09/26 14:10:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.00	
[09/26 14:10:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:10:48 visual_prompt]: Epoch 94 / 100: avg data time: 4.49e-02, avg batch time: 0.4932, average train loss: 2.8778
[09/26 14:10:49 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1685, average loss: 2.9028
[09/26 14:10:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 14:10:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:10:56 visual_prompt]: Epoch 95 / 100: avg data time: 4.37e-02, avg batch time: 0.4954, average train loss: 2.8762
[09/26 14:10:58 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1689, average loss: 2.9009
[09/26 14:10:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 29.50	
[09/26 14:10:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:11:04 visual_prompt]: Epoch 96 / 100: avg data time: 4.30e-02, avg batch time: 0.4929, average train loss: 2.8750
[09/26 14:11:06 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1685, average loss: 2.9011
[09/26 14:11:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 14:11:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:11:13 visual_prompt]: Epoch 97 / 100: avg data time: 6.39e-02, avg batch time: 0.5112, average train loss: 2.8744
[09/26 14:11:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1685, average loss: 2.9012
[09/26 14:11:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 14:11:14 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:11:21 visual_prompt]: Epoch 98 / 100: avg data time: 5.25e-02, avg batch time: 0.5003, average train loss: 2.8730
[09/26 14:11:23 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1687, average loss: 2.9011
[09/26 14:11:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 14:11:23 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:11:29 visual_prompt]: Epoch 99 / 100: avg data time: 4.54e-02, avg batch time: 0.4938, average train loss: 2.8723
[09/26 14:11:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1687, average loss: 2.9010
[09/26 14:11:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 14:11:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:11:38 visual_prompt]: Epoch 100 / 100: avg data time: 5.21e-02, avg batch time: 0.5014, average train loss: 2.8716
[09/26 14:11:39 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1686, average loss: 2.9011
[09/26 14:11:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 14:11:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:11:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:11:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:11:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:11:39 visual_prompt]: Training with config:
[09/26 14:11:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:11:39 visual_prompt]: Loading training data...
[09/26 14:11:39 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:11:41 visual_prompt]: Number of images: 800
[09/26 14:11:41 visual_prompt]: Number of classes: 18 / 18
[09/26 14:11:41 visual_prompt]: Loading validation data...
[09/26 14:11:41 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:11:41 visual_prompt]: Number of images: 200
[09/26 14:11:41 visual_prompt]: Number of classes: 18 / 18
[09/26 14:11:41 visual_prompt]: Constructing models...
[09/26 14:11:43 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 14:11:43 visual_prompt]: tuned percent:0.550
[09/26 14:11:44 visual_prompt]: Device used for model: 0
[09/26 14:11:44 visual_prompt]: Setting up Evaluator...
[09/26 14:11:44 visual_prompt]: Setting up Trainer...
[09/26 14:11:44 visual_prompt]: 	Setting up the optimizer...
[09/26 14:11:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:11:50 visual_prompt]: Epoch 1 / 100: avg data time: 5.75e-02, avg batch time: 0.5057, average train loss: 3.2517
[09/26 14:11:52 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 14:11:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 14:11:52 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 14:11:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 14:11:59 visual_prompt]: Epoch 2 / 100: avg data time: 5.95e-02, avg batch time: 0.5062, average train loss: 2.9733
[09/26 14:12:00 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1684, average loss: 2.9333
[09/26 14:12:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 14:12:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 14:12:07 visual_prompt]: Epoch 3 / 100: avg data time: 5.78e-02, avg batch time: 0.5046, average train loss: 2.9133
[09/26 14:12:09 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1686, average loss: 2.9818
[09/26 14:12:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 14:12:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 14:12:16 visual_prompt]: Epoch 4 / 100: avg data time: 6.51e-02, avg batch time: 0.5121, average train loss: 2.9019
[09/26 14:12:17 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1686, average loss: 2.9097
[09/26 14:12:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 28.50	
[09/26 14:12:17 visual_prompt]: Best epoch 4: best metric: 0.075
[09/26 14:12:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 14:12:24 visual_prompt]: Epoch 5 / 100: avg data time: 5.37e-02, avg batch time: 0.5019, average train loss: 2.9053
[09/26 14:12:26 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1689, average loss: 2.9260
[09/26 14:12:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 24.50	
[09/26 14:12:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 14:12:33 visual_prompt]: Epoch 6 / 100: avg data time: 5.62e-02, avg batch time: 0.5046, average train loss: 2.9231
[09/26 14:12:34 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.1687, average loss: 2.9566
[09/26 14:12:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.50	
[09/26 14:12:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 14:12:41 visual_prompt]: Epoch 7 / 100: avg data time: 5.47e-02, avg batch time: 0.5040, average train loss: 2.9112
[09/26 14:12:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1688, average loss: 2.9137
[09/26 14:12:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 14:12:42 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 14:12:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 14:12:49 visual_prompt]: Epoch 8 / 100: avg data time: 5.56e-02, avg batch time: 0.5040, average train loss: 2.9225
[09/26 14:12:51 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 2.9056
[09/26 14:12:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 31.50	
[09/26 14:12:51 visual_prompt]: Best epoch 8: best metric: 0.095
[09/26 14:12:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 14:12:58 visual_prompt]: Epoch 9 / 100: avg data time: 6.36e-02, avg batch time: 0.5121, average train loss: 2.9030
[09/26 14:12:59 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 2.9287
[09/26 14:12:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 14:12:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 14:13:06 visual_prompt]: Epoch 10 / 100: avg data time: 5.82e-02, avg batch time: 0.5065, average train loss: 2.9273
[09/26 14:13:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1692, average loss: 2.9647
[09/26 14:13:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 27.00	
[09/26 14:13:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 14:13:14 visual_prompt]: Epoch 11 / 100: avg data time: 5.56e-02, avg batch time: 0.5043, average train loss: 2.9304
[09/26 14:13:16 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 2.9385
[09/26 14:13:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.50	
[09/26 14:13:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 14:13:23 visual_prompt]: Epoch 12 / 100: avg data time: 6.29e-02, avg batch time: 0.5112, average train loss: 2.9136
[09/26 14:13:24 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 2.9262
[09/26 14:13:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 28.50	
[09/26 14:13:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 14:13:31 visual_prompt]: Epoch 13 / 100: avg data time: 5.41e-02, avg batch time: 0.5027, average train loss: 2.9072
[09/26 14:13:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1687, average loss: 2.9075
[09/26 14:13:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.50	
[09/26 14:13:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 14:13:40 visual_prompt]: Epoch 14 / 100: avg data time: 4.35e-02, avg batch time: 0.4935, average train loss: 2.8787
[09/26 14:13:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1687, average loss: 2.8981
[09/26 14:13:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 35.00	
[09/26 14:13:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 14:13:48 visual_prompt]: Epoch 15 / 100: avg data time: 4.58e-02, avg batch time: 0.4951, average train loss: 2.8439
[09/26 14:13:49 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1688, average loss: 2.9958
[09/26 14:13:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 14:13:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 14:13:56 visual_prompt]: Epoch 16 / 100: avg data time: 5.30e-02, avg batch time: 0.5012, average train loss: 2.8341
[09/26 14:13:58 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1688, average loss: 2.8311
[09/26 14:13:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 38.50	
[09/26 14:13:58 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 14:14:05 visual_prompt]: Epoch 17 / 100: avg data time: 6.01e-02, avg batch time: 0.5084, average train loss: 2.7962
[09/26 14:14:06 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1690, average loss: 2.8483
[09/26 14:14:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 39.50	
[09/26 14:14:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 14:14:13 visual_prompt]: Epoch 18 / 100: avg data time: 6.13e-02, avg batch time: 0.5093, average train loss: 2.7407
[09/26 14:14:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1690, average loss: 2.8770
[09/26 14:14:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 42.50	
[09/26 14:14:15 visual_prompt]: Best epoch 18: best metric: 0.100
[09/26 14:14:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 14:14:22 visual_prompt]: Epoch 19 / 100: avg data time: 5.31e-02, avg batch time: 0.5014, average train loss: 2.6585
[09/26 14:14:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1685, average loss: 2.8745
[09/26 14:14:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 41.50	
[09/26 14:14:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 14:14:30 visual_prompt]: Epoch 20 / 100: avg data time: 5.95e-02, avg batch time: 0.5075, average train loss: 2.6330
[09/26 14:14:32 visual_prompt]: Inference (val):avg data time: 4.50e-05, avg batch time: 0.1688, average loss: 2.9824
[09/26 14:14:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 37.50	
[09/26 14:14:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 14:14:39 visual_prompt]: Epoch 21 / 100: avg data time: 6.62e-02, avg batch time: 0.5139, average train loss: 2.6010
[09/26 14:14:40 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1688, average loss: 3.1981
[09/26 14:14:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 35.00	
[09/26 14:14:40 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 14:14:47 visual_prompt]: Epoch 22 / 100: avg data time: 6.05e-02, avg batch time: 0.5092, average train loss: 2.7515
[09/26 14:14:49 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1698, average loss: 2.8268
[09/26 14:14:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 40.50	
[09/26 14:14:49 visual_prompt]: Best epoch 22: best metric: 0.125
[09/26 14:14:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 14:14:55 visual_prompt]: Epoch 23 / 100: avg data time: 6.09e-02, avg batch time: 0.5088, average train loss: 2.5653
[09/26 14:14:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1694, average loss: 2.7517
[09/26 14:14:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 14:14:57 visual_prompt]: Best epoch 23: best metric: 0.145
[09/26 14:14:57 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 14:15:04 visual_prompt]: Epoch 24 / 100: avg data time: 5.09e-02, avg batch time: 0.4999, average train loss: 2.4413
[09/26 14:15:05 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1691, average loss: 2.6618
[09/26 14:15:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 58.00	
[09/26 14:15:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 14:15:12 visual_prompt]: Epoch 25 / 100: avg data time: 5.52e-02, avg batch time: 0.5044, average train loss: 2.3426
[09/26 14:15:14 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 2.7201
[09/26 14:15:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 14:15:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 14:15:21 visual_prompt]: Epoch 26 / 100: avg data time: 5.18e-02, avg batch time: 0.5012, average train loss: 2.2051
[09/26 14:15:22 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1689, average loss: 2.5841
[09/26 14:15:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 65.50	
[09/26 14:15:22 visual_prompt]: Best epoch 26: best metric: 0.155
[09/26 14:15:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 14:15:29 visual_prompt]: Epoch 27 / 100: avg data time: 5.78e-02, avg batch time: 0.5068, average train loss: 2.0359
[09/26 14:15:31 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1693, average loss: 2.5569
[09/26 14:15:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 64.50	
[09/26 14:15:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 14:15:38 visual_prompt]: Epoch 28 / 100: avg data time: 6.21e-02, avg batch time: 0.5111, average train loss: 2.0404
[09/26 14:15:39 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1690, average loss: 2.8647
[09/26 14:15:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 57.50	
[09/26 14:15:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 14:15:46 visual_prompt]: Epoch 29 / 100: avg data time: 5.76e-02, avg batch time: 0.5064, average train loss: 1.9827
[09/26 14:15:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1690, average loss: 2.7532
[09/26 14:15:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 69.50	
[09/26 14:15:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 14:15:54 visual_prompt]: Epoch 30 / 100: avg data time: 4.47e-02, avg batch time: 0.4955, average train loss: 1.7994
[09/26 14:15:56 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1691, average loss: 2.8699
[09/26 14:15:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 63.00	
[09/26 14:15:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 14:16:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.99e-02, avg batch time: 0.5083, average train loss: 1.7223
[09/26 14:16:04 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 2.7335
[09/26 14:16:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 69.00	
[09/26 14:16:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 14:16:11 visual_prompt]: Epoch 32 / 100: avg data time: 4.69e-02, avg batch time: 0.4959, average train loss: 1.4675
[09/26 14:16:13 visual_prompt]: Inference (val):avg data time: 5.44e-05, avg batch time: 0.1691, average loss: 3.2568
[09/26 14:16:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.00	
[09/26 14:16:13 visual_prompt]: Best epoch 32: best metric: 0.185
[09/26 14:16:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 14:16:20 visual_prompt]: Epoch 33 / 100: avg data time: 5.75e-02, avg batch time: 0.5058, average train loss: 1.4030
[09/26 14:16:21 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1692, average loss: 3.4032
[09/26 14:16:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 70.50	
[09/26 14:16:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 14:16:28 visual_prompt]: Epoch 34 / 100: avg data time: 5.60e-02, avg batch time: 0.5051, average train loss: 1.4112
[09/26 14:16:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1690, average loss: 3.1954
[09/26 14:16:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 69.00	
[09/26 14:16:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 14:16:36 visual_prompt]: Epoch 35 / 100: avg data time: 4.61e-02, avg batch time: 0.4987, average train loss: 1.2218
[09/26 14:16:38 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1691, average loss: 3.4726
[09/26 14:16:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 14:16:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 14:16:45 visual_prompt]: Epoch 36 / 100: avg data time: 5.49e-02, avg batch time: 0.5034, average train loss: 1.0163
[09/26 14:16:46 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 3.5457
[09/26 14:16:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.50	
[09/26 14:16:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 14:16:53 visual_prompt]: Epoch 37 / 100: avg data time: 4.96e-02, avg batch time: 0.4986, average train loss: 0.8957
[09/26 14:16:55 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1692, average loss: 3.7617
[09/26 14:16:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 64.00	
[09/26 14:16:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 14:17:01 visual_prompt]: Epoch 38 / 100: avg data time: 4.32e-02, avg batch time: 0.4932, average train loss: 0.8232
[09/26 14:17:03 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 3.7660
[09/26 14:17:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 66.00	
[09/26 14:17:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 14:17:10 visual_prompt]: Epoch 39 / 100: avg data time: 4.25e-02, avg batch time: 0.4944, average train loss: 0.7889
[09/26 14:17:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 3.7991
[09/26 14:17:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 14:17:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 14:17:18 visual_prompt]: Epoch 40 / 100: avg data time: 5.20e-02, avg batch time: 0.5020, average train loss: 0.7648
[09/26 14:17:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 3.8146
[09/26 14:17:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 58.00	
[09/26 14:17:20 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 14:17:26 visual_prompt]: Epoch 41 / 100: avg data time: 4.45e-02, avg batch time: 0.4939, average train loss: 0.6434
[09/26 14:17:28 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 3.7520
[09/26 14:17:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 64.00	
[09/26 14:17:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 14:17:35 visual_prompt]: Epoch 42 / 100: avg data time: 5.86e-02, avg batch time: 0.5069, average train loss: 0.5045
[09/26 14:17:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1694, average loss: 3.7357
[09/26 14:17:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 69.50	
[09/26 14:17:36 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 14:17:43 visual_prompt]: Epoch 43 / 100: avg data time: 4.72e-02, avg batch time: 0.4973, average train loss: 0.4204
[09/26 14:17:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 3.7437
[09/26 14:17:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.50	
[09/26 14:17:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 14:17:51 visual_prompt]: Epoch 44 / 100: avg data time: 5.51e-02, avg batch time: 0.5042, average train loss: 0.3115
[09/26 14:17:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1693, average loss: 3.7805
[09/26 14:17:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 67.00	
[09/26 14:17:53 visual_prompt]: Best epoch 44: best metric: 0.195
[09/26 14:17:53 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 14:18:00 visual_prompt]: Epoch 45 / 100: avg data time: 5.50e-02, avg batch time: 0.5046, average train loss: 0.2542
[09/26 14:18:01 visual_prompt]: Inference (val):avg data time: 3.97e-05, avg batch time: 0.1689, average loss: 3.9280
[09/26 14:18:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.50	
[09/26 14:18:01 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 14:18:08 visual_prompt]: Epoch 46 / 100: avg data time: 6.00e-02, avg batch time: 0.5100, average train loss: 0.2145
[09/26 14:18:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 4.0385
[09/26 14:18:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 69.50	
[09/26 14:18:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 14:18:16 visual_prompt]: Epoch 47 / 100: avg data time: 6.03e-02, avg batch time: 0.5100, average train loss: 0.1669
[09/26 14:18:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1690, average loss: 4.0461
[09/26 14:18:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.50	
[09/26 14:18:18 visual_prompt]: Best epoch 47: best metric: 0.200
[09/26 14:18:18 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 14:18:25 visual_prompt]: Epoch 48 / 100: avg data time: 6.08e-02, avg batch time: 0.5097, average train loss: 0.1186
[09/26 14:18:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 3.9285
[09/26 14:18:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 14:18:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 14:18:33 visual_prompt]: Epoch 49 / 100: avg data time: 6.36e-02, avg batch time: 0.5137, average train loss: 0.0980
[09/26 14:18:35 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1689, average loss: 3.8864
[09/26 14:18:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 68.00	
[09/26 14:18:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 14:18:42 visual_prompt]: Epoch 50 / 100: avg data time: 4.45e-02, avg batch time: 0.4941, average train loss: 0.0622
[09/26 14:18:43 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 4.0497
[09/26 14:18:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 14:18:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 14:18:50 visual_prompt]: Epoch 51 / 100: avg data time: 6.08e-02, avg batch time: 0.5108, average train loss: 0.0592
[09/26 14:18:52 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1688, average loss: 4.1604
[09/26 14:18:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 14:18:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 14:18:59 visual_prompt]: Epoch 52 / 100: avg data time: 6.12e-02, avg batch time: 0.5095, average train loss: 0.0630
[09/26 14:19:01 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1694, average loss: 4.1983
[09/26 14:19:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.50	
[09/26 14:19:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 14:19:08 visual_prompt]: Epoch 53 / 100: avg data time: 6.08e-02, avg batch time: 0.5097, average train loss: 0.0523
[09/26 14:19:09 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1688, average loss: 4.2911
[09/26 14:19:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 65.00	
[09/26 14:19:09 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 14:19:16 visual_prompt]: Epoch 54 / 100: avg data time: 5.66e-02, avg batch time: 0.5048, average train loss: 0.0444
[09/26 14:19:17 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1689, average loss: 4.0430
[09/26 14:19:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 14:19:17 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 14:19:24 visual_prompt]: Epoch 55 / 100: avg data time: 6.06e-02, avg batch time: 0.5092, average train loss: 0.0331
[09/26 14:19:26 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1693, average loss: 4.1204
[09/26 14:19:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.00	
[09/26 14:19:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 14:19:33 visual_prompt]: Epoch 56 / 100: avg data time: 5.89e-02, avg batch time: 0.5077, average train loss: 0.0251
[09/26 14:19:34 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 4.1081
[09/26 14:19:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 65.00	
[09/26 14:19:35 visual_prompt]: Best epoch 56: best metric: 0.205
[09/26 14:19:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 14:19:41 visual_prompt]: Epoch 57 / 100: avg data time: 5.44e-02, avg batch time: 0.5026, average train loss: 0.0194
[09/26 14:19:43 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1691, average loss: 4.0931
[09/26 14:19:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 64.00	
[09/26 14:19:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 14:19:50 visual_prompt]: Epoch 58 / 100: avg data time: 4.66e-02, avg batch time: 0.4974, average train loss: 0.0181
[09/26 14:19:51 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1692, average loss: 4.0708
[09/26 14:19:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 66.00	
[09/26 14:19:51 visual_prompt]: Best epoch 58: best metric: 0.220
[09/26 14:19:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:19:58 visual_prompt]: Epoch 59 / 100: avg data time: 5.70e-02, avg batch time: 0.5049, average train loss: 0.0175
[09/26 14:19:59 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1691, average loss: 4.1105
[09/26 14:19:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 14:19:59 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:20:06 visual_prompt]: Epoch 60 / 100: avg data time: 5.83e-02, avg batch time: 0.5068, average train loss: 0.0168
[09/26 14:20:08 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1694, average loss: 4.0869
[09/26 14:20:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 65.50	
[09/26 14:20:08 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:20:15 visual_prompt]: Epoch 61 / 100: avg data time: 5.37e-02, avg batch time: 0.5028, average train loss: 0.0147
[09/26 14:20:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1694, average loss: 4.0786
[09/26 14:20:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 65.50	
[09/26 14:20:16 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:20:23 visual_prompt]: Epoch 62 / 100: avg data time: 5.82e-02, avg batch time: 0.5065, average train loss: 0.0147
[09/26 14:20:25 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1692, average loss: 4.0882
[09/26 14:20:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 66.00	
[09/26 14:20:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:20:32 visual_prompt]: Epoch 63 / 100: avg data time: 6.16e-02, avg batch time: 0.5099, average train loss: 0.0152
[09/26 14:20:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1692, average loss: 4.0654
[09/26 14:20:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.50	
[09/26 14:20:33 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:20:40 visual_prompt]: Epoch 64 / 100: avg data time: 5.75e-02, avg batch time: 0.5065, average train loss: 0.0144
[09/26 14:20:42 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 4.0380
[09/26 14:20:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.00	
[09/26 14:20:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:20:48 visual_prompt]: Epoch 65 / 100: avg data time: 6.07e-02, avg batch time: 0.5093, average train loss: 0.0139
[09/26 14:20:50 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 4.0246
[09/26 14:20:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 65.50	
[09/26 14:20:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:20:57 visual_prompt]: Epoch 66 / 100: avg data time: 5.79e-02, avg batch time: 0.5059, average train loss: 0.0132
[09/26 14:20:59 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 4.0349
[09/26 14:20:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 66.50	
[09/26 14:20:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:21:05 visual_prompt]: Epoch 67 / 100: avg data time: 4.37e-02, avg batch time: 0.4939, average train loss: 0.0121
[09/26 14:21:07 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 4.0462
[09/26 14:21:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.00	
[09/26 14:21:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:21:14 visual_prompt]: Epoch 68 / 100: avg data time: 6.07e-02, avg batch time: 0.5105, average train loss: 0.0123
[09/26 14:21:15 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1691, average loss: 4.0475
[09/26 14:21:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 14:21:15 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:21:22 visual_prompt]: Epoch 69 / 100: avg data time: 5.46e-02, avg batch time: 0.5028, average train loss: 0.0128
[09/26 14:21:24 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1694, average loss: 4.0429
[09/26 14:21:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 14:21:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:21:30 visual_prompt]: Epoch 70 / 100: avg data time: 5.51e-02, avg batch time: 0.5049, average train loss: 0.0128
[09/26 14:21:32 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1693, average loss: 4.0161
[09/26 14:21:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 64.00	
[09/26 14:21:32 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:21:39 visual_prompt]: Epoch 71 / 100: avg data time: 4.41e-02, avg batch time: 0.4962, average train loss: 0.0124
[09/26 14:21:40 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1692, average loss: 3.9876
[09/26 14:21:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 64.00	
[09/26 14:21:40 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:21:47 visual_prompt]: Epoch 72 / 100: avg data time: 4.40e-02, avg batch time: 0.4945, average train loss: 0.0122
[09/26 14:21:49 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1695, average loss: 4.0051
[09/26 14:21:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 65.50	
[09/26 14:21:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:21:55 visual_prompt]: Epoch 73 / 100: avg data time: 5.20e-02, avg batch time: 0.5004, average train loss: 0.0115
[09/26 14:21:57 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1693, average loss: 4.0217
[09/26 14:21:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 65.50	
[09/26 14:21:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:22:04 visual_prompt]: Epoch 74 / 100: avg data time: 5.65e-02, avg batch time: 0.5048, average train loss: 0.0118
[09/26 14:22:05 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1691, average loss: 4.0086
[09/26 14:22:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 65.50	
[09/26 14:22:05 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:22:12 visual_prompt]: Epoch 75 / 100: avg data time: 6.30e-02, avg batch time: 0.5120, average train loss: 0.0115
[09/26 14:22:14 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1695, average loss: 4.0058
[09/26 14:22:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 66.00	
[09/26 14:22:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:22:21 visual_prompt]: Epoch 76 / 100: avg data time: 6.27e-02, avg batch time: 0.5115, average train loss: 0.0115
[09/26 14:22:22 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1691, average loss: 4.0110
[09/26 14:22:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.50	
[09/26 14:22:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:22:29 visual_prompt]: Epoch 77 / 100: avg data time: 6.18e-02, avg batch time: 0.5100, average train loss: 0.0112
[09/26 14:22:31 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1693, average loss: 4.0090
[09/26 14:22:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.00	
[09/26 14:22:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:22:38 visual_prompt]: Epoch 78 / 100: avg data time: 5.72e-02, avg batch time: 0.5079, average train loss: 0.0106
[09/26 14:22:39 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1692, average loss: 4.0096
[09/26 14:22:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 66.00	
[09/26 14:22:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:22:46 visual_prompt]: Epoch 79 / 100: avg data time: 5.68e-02, avg batch time: 0.5052, average train loss: 0.0110
[09/26 14:22:48 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 4.0105
[09/26 14:22:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 65.00	
[09/26 14:22:48 visual_prompt]: Best epoch 79: best metric: 0.225
[09/26 14:22:48 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:22:55 visual_prompt]: Epoch 80 / 100: avg data time: 6.34e-02, avg batch time: 0.5120, average train loss: 0.0105
[09/26 14:22:56 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1691, average loss: 4.0119
[09/26 14:22:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 65.00	
[09/26 14:22:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:23:03 visual_prompt]: Epoch 81 / 100: avg data time: 5.46e-02, avg batch time: 0.5027, average train loss: 0.0101
[09/26 14:23:05 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 4.0120
[09/26 14:23:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 64.50	
[09/26 14:23:05 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:23:11 visual_prompt]: Epoch 82 / 100: avg data time: 4.64e-02, avg batch time: 0.4959, average train loss: 0.0104
[09/26 14:23:13 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 4.0146
[09/26 14:23:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:23:13 visual_prompt]: Best epoch 82: best metric: 0.230
[09/26 14:23:13 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:23:19 visual_prompt]: Epoch 83 / 100: avg data time: 4.45e-02, avg batch time: 0.4939, average train loss: 0.0112
[09/26 14:23:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 4.0156
[09/26 14:23:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:23:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:23:28 visual_prompt]: Epoch 84 / 100: avg data time: 5.25e-02, avg batch time: 0.5024, average train loss: 0.0112
[09/26 14:23:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 4.0247
[09/26 14:23:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.00	
[09/26 14:23:29 visual_prompt]: Best epoch 84: best metric: 0.235
[09/26 14:23:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:23:36 visual_prompt]: Epoch 85 / 100: avg data time: 4.24e-02, avg batch time: 0.4916, average train loss: 0.0101
[09/26 14:23:37 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 4.0292
[09/26 14:23:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.00	
[09/26 14:23:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:23:44 visual_prompt]: Epoch 86 / 100: avg data time: 4.94e-02, avg batch time: 0.4980, average train loss: 0.0102
[09/26 14:23:46 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1688, average loss: 4.0307
[09/26 14:23:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.00	
[09/26 14:23:46 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:23:53 visual_prompt]: Epoch 87 / 100: avg data time: 4.49e-02, avg batch time: 0.4962, average train loss: 0.0103
[09/26 14:23:54 visual_prompt]: Inference (val):avg data time: 4.44e-05, avg batch time: 0.1691, average loss: 4.0281
[09/26 14:23:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.00	
[09/26 14:23:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:24:01 visual_prompt]: Epoch 88 / 100: avg data time: 6.03e-02, avg batch time: 0.5093, average train loss: 0.0103
[09/26 14:24:02 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 4.0272
[09/26 14:24:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.00	
[09/26 14:24:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:24:09 visual_prompt]: Epoch 89 / 100: avg data time: 5.38e-02, avg batch time: 0.5042, average train loss: 0.0105
[09/26 14:24:11 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1693, average loss: 4.0243
[09/26 14:24:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 64.50	
[09/26 14:24:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:24:18 visual_prompt]: Epoch 90 / 100: avg data time: 4.67e-02, avg batch time: 0.4951, average train loss: 0.0103
[09/26 14:24:19 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 4.0204
[09/26 14:24:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:24:19 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:24:26 visual_prompt]: Epoch 91 / 100: avg data time: 4.36e-02, avg batch time: 0.4935, average train loss: 0.0099
[09/26 14:24:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1688, average loss: 4.0210
[09/26 14:24:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:24:27 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:24:34 visual_prompt]: Epoch 92 / 100: avg data time: 4.74e-02, avg batch time: 0.4967, average train loss: 0.0100
[09/26 14:24:36 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1692, average loss: 4.0229
[09/26 14:24:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:24:36 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:24:43 visual_prompt]: Epoch 93 / 100: avg data time: 5.24e-02, avg batch time: 0.5016, average train loss: 0.0101
[09/26 14:24:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1688, average loss: 4.0240
[09/26 14:24:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:24:44 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:24:51 visual_prompt]: Epoch 94 / 100: avg data time: 4.30e-02, avg batch time: 0.4925, average train loss: 0.0102
[09/26 14:24:52 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 4.0243
[09/26 14:24:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:24:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:24:59 visual_prompt]: Epoch 95 / 100: avg data time: 5.19e-02, avg batch time: 0.5022, average train loss: 0.0097
[09/26 14:25:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 4.0239
[09/26 14:25:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.50	
[09/26 14:25:01 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:25:07 visual_prompt]: Epoch 96 / 100: avg data time: 4.33e-02, avg batch time: 0.4923, average train loss: 0.0103
[09/26 14:25:09 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1692, average loss: 4.0233
[09/26 14:25:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:25:09 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:25:16 visual_prompt]: Epoch 97 / 100: avg data time: 5.11e-02, avg batch time: 0.5010, average train loss: 0.0108
[09/26 14:25:17 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1695, average loss: 4.0233
[09/26 14:25:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:25:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:25:24 visual_prompt]: Epoch 98 / 100: avg data time: 4.48e-02, avg batch time: 0.4954, average train loss: 0.0103
[09/26 14:25:26 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1692, average loss: 4.0233
[09/26 14:25:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:25:26 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:25:33 visual_prompt]: Epoch 99 / 100: avg data time: 5.48e-02, avg batch time: 0.5037, average train loss: 0.0100
[09/26 14:25:34 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1694, average loss: 4.0234
[09/26 14:25:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:25:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:25:41 visual_prompt]: Epoch 100 / 100: avg data time: 5.00e-02, avg batch time: 0.4994, average train loss: 0.0101
[09/26 14:25:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1689, average loss: 4.0234
[09/26 14:25:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.00	top5: 64.00	
[09/26 14:25:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:25:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:25:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:25:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:25:42 visual_prompt]: Training with config:
[09/26 14:25:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:25:42 visual_prompt]: Loading training data...
[09/26 14:25:42 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:25:44 visual_prompt]: Number of images: 800
[09/26 14:25:44 visual_prompt]: Number of classes: 18 / 18
[09/26 14:25:44 visual_prompt]: Loading validation data...
[09/26 14:25:44 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:25:44 visual_prompt]: Number of images: 200
[09/26 14:25:44 visual_prompt]: Number of classes: 18 / 18
[09/26 14:25:44 visual_prompt]: Constructing models...
[09/26 14:25:46 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 14:25:46 visual_prompt]: tuned percent:0.550
[09/26 14:25:47 visual_prompt]: Device used for model: 0
[09/26 14:25:47 visual_prompt]: Setting up Evaluator...
[09/26 14:25:47 visual_prompt]: Setting up Trainer...
[09/26 14:25:47 visual_prompt]: 	Setting up the optimizer...
[09/26 14:25:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:25:53 visual_prompt]: Epoch 1 / 100: avg data time: 6.27e-02, avg batch time: 0.5111, average train loss: 3.2531
[09/26 14:25:55 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1687, average loss: 3.1895
[09/26 14:25:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 14:25:55 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 14:25:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 14:26:02 visual_prompt]: Epoch 2 / 100: avg data time: 5.65e-02, avg batch time: 0.5033, average train loss: 2.9994
[09/26 14:26:03 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1687, average loss: 2.9123
[09/26 14:26:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 14:26:03 visual_prompt]: Best epoch 2: best metric: 0.070
[09/26 14:26:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 14:26:10 visual_prompt]: Epoch 3 / 100: avg data time: 6.00e-02, avg batch time: 0.5076, average train loss: 2.9284
[09/26 14:26:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1686, average loss: 2.9403
[09/26 14:26:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 25.00	
[09/26 14:26:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 14:26:19 visual_prompt]: Epoch 4 / 100: avg data time: 6.20e-02, avg batch time: 0.5091, average train loss: 2.9130
[09/26 14:26:20 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1686, average loss: 2.9241
[09/26 14:26:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 29.00	
[09/26 14:26:20 visual_prompt]: Best epoch 4: best metric: 0.085
[09/26 14:26:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 14:26:27 visual_prompt]: Epoch 5 / 100: avg data time: 5.49e-02, avg batch time: 0.5034, average train loss: 2.9123
[09/26 14:26:29 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1688, average loss: 2.9136
[09/26 14:26:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.00	
[09/26 14:26:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 14:26:35 visual_prompt]: Epoch 6 / 100: avg data time: 4.33e-02, avg batch time: 0.4928, average train loss: 2.9150
[09/26 14:26:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1685, average loss: 2.9280
[09/26 14:26:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 14:26:37 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 14:26:44 visual_prompt]: Epoch 7 / 100: avg data time: 5.33e-02, avg batch time: 0.5018, average train loss: 2.8960
[09/26 14:26:45 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1689, average loss: 2.9406
[09/26 14:26:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 24.00	
[09/26 14:26:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 14:26:52 visual_prompt]: Epoch 8 / 100: avg data time: 6.42e-02, avg batch time: 0.5117, average train loss: 2.8926
[09/26 14:26:54 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 2.9782
[09/26 14:26:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 23.00	
[09/26 14:26:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 14:27:00 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e-02, avg batch time: 0.4986, average train loss: 2.8948
[09/26 14:27:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1687, average loss: 2.9140
[09/26 14:27:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 14:27:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 14:27:09 visual_prompt]: Epoch 10 / 100: avg data time: 5.32e-02, avg batch time: 0.5015, average train loss: 2.9048
[09/26 14:27:10 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1687, average loss: 2.9056
[09/26 14:27:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 14:27:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 14:27:17 visual_prompt]: Epoch 11 / 100: avg data time: 5.83e-02, avg batch time: 0.5069, average train loss: 2.9187
[09/26 14:27:19 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 2.9671
[09/26 14:27:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 14:27:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 14:27:26 visual_prompt]: Epoch 12 / 100: avg data time: 6.20e-02, avg batch time: 0.5102, average train loss: 2.8873
[09/26 14:27:27 visual_prompt]: Inference (val):avg data time: 4.47e-05, avg batch time: 0.1688, average loss: 2.8729
[09/26 14:27:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 35.00	
[09/26 14:27:27 visual_prompt]: Best epoch 12: best metric: 0.095
[09/26 14:27:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 14:27:34 visual_prompt]: Epoch 13 / 100: avg data time: 6.22e-02, avg batch time: 0.5102, average train loss: 2.8438
[09/26 14:27:36 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 2.8605
[09/26 14:27:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 38.00	
[09/26 14:27:36 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 14:27:43 visual_prompt]: Epoch 14 / 100: avg data time: 5.98e-02, avg batch time: 0.5084, average train loss: 2.7632
[09/26 14:27:44 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1690, average loss: 2.8525
[09/26 14:27:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 39.00	
[09/26 14:27:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 14:27:51 visual_prompt]: Epoch 15 / 100: avg data time: 5.94e-02, avg batch time: 0.5072, average train loss: 2.7052
[09/26 14:27:53 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1696, average loss: 2.8124
[09/26 14:27:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 43.50	
[09/26 14:27:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 14:27:59 visual_prompt]: Epoch 16 / 100: avg data time: 4.77e-02, avg batch time: 0.4971, average train loss: 2.6563
[09/26 14:28:01 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1692, average loss: 2.7583
[09/26 14:28:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 45.50	
[09/26 14:28:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 14:28:08 visual_prompt]: Epoch 17 / 100: avg data time: 5.49e-02, avg batch time: 0.5038, average train loss: 2.6162
[09/26 14:28:09 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 2.8079
[09/26 14:28:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.00	
[09/26 14:28:09 visual_prompt]: Best epoch 17: best metric: 0.120
[09/26 14:28:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 14:28:16 visual_prompt]: Epoch 18 / 100: avg data time: 6.04e-02, avg batch time: 0.5091, average train loss: 2.5185
[09/26 14:28:18 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1693, average loss: 2.8886
[09/26 14:28:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 47.50	
[09/26 14:28:18 visual_prompt]: Best epoch 18: best metric: 0.130
[09/26 14:28:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 14:28:25 visual_prompt]: Epoch 19 / 100: avg data time: 5.90e-02, avg batch time: 0.5092, average train loss: 2.4261
[09/26 14:28:26 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1698, average loss: 3.3888
[09/26 14:28:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 37.50	
[09/26 14:28:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 14:28:33 visual_prompt]: Epoch 20 / 100: avg data time: 5.75e-02, avg batch time: 0.5069, average train loss: 2.3539
[09/26 14:28:35 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1691, average loss: 3.1218
[09/26 14:28:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 52.50	
[09/26 14:28:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 14:28:42 visual_prompt]: Epoch 21 / 100: avg data time: 5.65e-02, avg batch time: 0.5041, average train loss: 2.2536
[09/26 14:28:43 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1694, average loss: 2.9256
[09/26 14:28:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 56.50	
[09/26 14:28:43 visual_prompt]: Best epoch 21: best metric: 0.155
[09/26 14:28:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 14:28:50 visual_prompt]: Epoch 22 / 100: avg data time: 5.10e-02, avg batch time: 0.5006, average train loss: 2.0977
[09/26 14:28:52 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 2.8524
[09/26 14:28:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.50	
[09/26 14:28:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 14:28:58 visual_prompt]: Epoch 23 / 100: avg data time: 6.01e-02, avg batch time: 0.5086, average train loss: 1.9447
[09/26 14:29:00 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 3.0729
[09/26 14:29:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 58.00	
[09/26 14:29:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 14:29:07 visual_prompt]: Epoch 24 / 100: avg data time: 5.34e-02, avg batch time: 0.5015, average train loss: 1.8035
[09/26 14:29:08 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1690, average loss: 3.1642
[09/26 14:29:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.00	
[09/26 14:29:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 14:29:15 visual_prompt]: Epoch 25 / 100: avg data time: 5.53e-02, avg batch time: 0.5035, average train loss: 1.6539
[09/26 14:29:17 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1691, average loss: 3.0582
[09/26 14:29:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 64.50	
[09/26 14:29:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 14:29:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.98e-02, avg batch time: 0.5077, average train loss: 1.5130
[09/26 14:29:25 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1691, average loss: 3.5533
[09/26 14:29:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.50	
[09/26 14:29:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 14:29:32 visual_prompt]: Epoch 27 / 100: avg data time: 6.52e-02, avg batch time: 0.5132, average train loss: 1.3699
[09/26 14:29:34 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 3.2455
[09/26 14:29:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.00	
[09/26 14:29:34 visual_prompt]: Best epoch 27: best metric: 0.170
[09/26 14:29:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 14:29:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.77e-02, avg batch time: 0.5058, average train loss: 1.2971
[09/26 14:29:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1700, average loss: 3.6889
[09/26 14:29:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 61.00	
[09/26 14:29:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 14:29:49 visual_prompt]: Epoch 29 / 100: avg data time: 5.76e-02, avg batch time: 0.5061, average train loss: 1.0960
[09/26 14:29:51 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1691, average loss: 3.6989
[09/26 14:29:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 63.00	
[09/26 14:29:51 visual_prompt]: Best epoch 29: best metric: 0.220
[09/26 14:29:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 14:29:58 visual_prompt]: Epoch 30 / 100: avg data time: 5.57e-02, avg batch time: 0.5048, average train loss: 1.0155
[09/26 14:29:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1688, average loss: 4.3077
[09/26 14:29:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.00	
[09/26 14:29:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 14:30:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.48e-02, avg batch time: 0.4940, average train loss: 0.9729
[09/26 14:30:07 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 3.9010
[09/26 14:30:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.50	
[09/26 14:30:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 14:30:14 visual_prompt]: Epoch 32 / 100: avg data time: 5.39e-02, avg batch time: 0.5038, average train loss: 0.8119
[09/26 14:30:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1689, average loss: 4.5165
[09/26 14:30:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.00	
[09/26 14:30:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 14:30:23 visual_prompt]: Epoch 33 / 100: avg data time: 4.28e-02, avg batch time: 0.4930, average train loss: 0.6894
[09/26 14:30:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1687, average loss: 4.7784
[09/26 14:30:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 55.00	
[09/26 14:30:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 14:30:31 visual_prompt]: Epoch 34 / 100: avg data time: 4.62e-02, avg batch time: 0.4986, average train loss: 0.5337
[09/26 14:30:32 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1690, average loss: 5.2174
[09/26 14:30:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 60.50	
[09/26 14:30:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 14:30:39 visual_prompt]: Epoch 35 / 100: avg data time: 5.45e-02, avg batch time: 0.5040, average train loss: 0.4862
[09/26 14:30:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 5.4092
[09/26 14:30:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 58.00	
[09/26 14:30:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 14:30:48 visual_prompt]: Epoch 36 / 100: avg data time: 5.27e-02, avg batch time: 0.5008, average train loss: 0.3785
[09/26 14:30:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 5.5767
[09/26 14:30:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 58.50	
[09/26 14:30:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 14:30:56 visual_prompt]: Epoch 37 / 100: avg data time: 4.49e-02, avg batch time: 0.4949, average train loss: 0.3621
[09/26 14:30:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1689, average loss: 5.6629
[09/26 14:30:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 14:30:58 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 14:31:04 visual_prompt]: Epoch 38 / 100: avg data time: 5.59e-02, avg batch time: 0.5055, average train loss: 0.3570
[09/26 14:31:06 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 5.4357
[09/26 14:31:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 64.00	
[09/26 14:31:06 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 14:31:13 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e-02, avg batch time: 0.5055, average train loss: 0.2830
[09/26 14:31:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 5.9654
[09/26 14:31:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.00	
[09/26 14:31:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 14:31:21 visual_prompt]: Epoch 40 / 100: avg data time: 5.52e-02, avg batch time: 0.5044, average train loss: 0.2516
[09/26 14:31:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1693, average loss: 6.1688
[09/26 14:31:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 57.50	
[09/26 14:31:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 14:31:30 visual_prompt]: Epoch 41 / 100: avg data time: 5.71e-02, avg batch time: 0.5053, average train loss: 0.1964
[09/26 14:31:31 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1692, average loss: 6.1037
[09/26 14:31:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 57.50	
[09/26 14:31:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 14:31:38 visual_prompt]: Epoch 42 / 100: avg data time: 4.42e-02, avg batch time: 0.4940, average train loss: 0.1845
[09/26 14:31:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 6.0446
[09/26 14:31:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.00	
[09/26 14:31:39 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 14:31:46 visual_prompt]: Epoch 43 / 100: avg data time: 5.95e-02, avg batch time: 0.5081, average train loss: 0.1552
[09/26 14:31:48 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1691, average loss: 6.1658
[09/26 14:31:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 59.00	
[09/26 14:31:48 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 14:31:55 visual_prompt]: Epoch 44 / 100: avg data time: 4.97e-02, avg batch time: 0.4982, average train loss: 0.1279
[09/26 14:31:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 6.1658
[09/26 14:31:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 61.00	
[09/26 14:31:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 14:32:03 visual_prompt]: Epoch 45 / 100: avg data time: 4.67e-02, avg batch time: 0.4981, average train loss: 0.0909
[09/26 14:32:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1688, average loss: 5.8857
[09/26 14:32:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 63.50	
[09/26 14:32:04 visual_prompt]: Best epoch 45: best metric: 0.225
[09/26 14:32:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 14:32:11 visual_prompt]: Epoch 46 / 100: avg data time: 4.32e-02, avg batch time: 0.4941, average train loss: 0.0686
[09/26 14:32:13 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 6.0641
[09/26 14:32:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 64.00	
[09/26 14:32:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 14:32:19 visual_prompt]: Epoch 47 / 100: avg data time: 5.48e-02, avg batch time: 0.5043, average train loss: 0.0527
[09/26 14:32:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 6.1436
[09/26 14:32:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 14:32:21 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 14:32:28 visual_prompt]: Epoch 48 / 100: avg data time: 6.12e-02, avg batch time: 0.5100, average train loss: 0.0333
[09/26 14:32:29 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 6.1658
[09/26 14:32:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:32:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 14:32:36 visual_prompt]: Epoch 49 / 100: avg data time: 5.81e-02, avg batch time: 0.5077, average train loss: 0.0232
[09/26 14:32:38 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1692, average loss: 6.1793
[09/26 14:32:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.50	
[09/26 14:32:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 14:32:45 visual_prompt]: Epoch 50 / 100: avg data time: 5.57e-02, avg batch time: 0.5046, average train loss: 0.0155
[09/26 14:32:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 6.2188
[09/26 14:32:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.50	
[09/26 14:32:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 14:32:53 visual_prompt]: Epoch 51 / 100: avg data time: 5.88e-02, avg batch time: 0.5081, average train loss: 0.0114
[09/26 14:32:55 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 6.2915
[09/26 14:32:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:32:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 14:33:02 visual_prompt]: Epoch 52 / 100: avg data time: 6.70e-02, avg batch time: 0.5152, average train loss: 0.0106
[09/26 14:33:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 6.2665
[09/26 14:33:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 59.50	
[09/26 14:33:03 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 14:33:10 visual_prompt]: Epoch 53 / 100: avg data time: 5.87e-02, avg batch time: 0.5083, average train loss: 0.0093
[09/26 14:33:12 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 6.2715
[09/26 14:33:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 14:33:12 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 14:33:19 visual_prompt]: Epoch 54 / 100: avg data time: 5.29e-02, avg batch time: 0.5011, average train loss: 0.0088
[09/26 14:33:20 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1690, average loss: 6.3112
[09/26 14:33:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 14:33:20 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 14:33:27 visual_prompt]: Epoch 55 / 100: avg data time: 5.75e-02, avg batch time: 0.5057, average train loss: 0.0074
[09/26 14:33:29 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 6.3119
[09/26 14:33:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 59.00	
[09/26 14:33:29 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 14:33:36 visual_prompt]: Epoch 56 / 100: avg data time: 6.05e-02, avg batch time: 0.5084, average train loss: 0.0074
[09/26 14:33:37 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1693, average loss: 6.3228
[09/26 14:33:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 59.50	
[09/26 14:33:37 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 14:33:44 visual_prompt]: Epoch 57 / 100: avg data time: 5.33e-02, avg batch time: 0.5034, average train loss: 0.0059
[09/26 14:33:45 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1691, average loss: 6.3084
[09/26 14:33:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 59.00	
[09/26 14:33:45 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 14:33:52 visual_prompt]: Epoch 58 / 100: avg data time: 5.55e-02, avg batch time: 0.5037, average train loss: 0.0067
[09/26 14:33:54 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1691, average loss: 6.3105
[09/26 14:33:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:33:54 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:34:01 visual_prompt]: Epoch 59 / 100: avg data time: 5.70e-02, avg batch time: 0.5050, average train loss: 0.0055
[09/26 14:34:02 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1691, average loss: 6.3367
[09/26 14:34:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 58.50	
[09/26 14:34:02 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:34:09 visual_prompt]: Epoch 60 / 100: avg data time: 5.33e-02, avg batch time: 0.5011, average train loss: 0.0054
[09/26 14:34:11 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1692, average loss: 6.3683
[09/26 14:34:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 58.00	
[09/26 14:34:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:34:18 visual_prompt]: Epoch 61 / 100: avg data time: 6.44e-02, avg batch time: 0.5125, average train loss: 0.0052
[09/26 14:34:19 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1687, average loss: 6.3761
[09/26 14:34:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.00	
[09/26 14:34:19 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:34:26 visual_prompt]: Epoch 62 / 100: avg data time: 5.60e-02, avg batch time: 0.5046, average train loss: 0.0058
[09/26 14:34:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1687, average loss: 6.3802
[09/26 14:34:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 58.50	
[09/26 14:34:28 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:34:35 visual_prompt]: Epoch 63 / 100: avg data time: 5.56e-02, avg batch time: 0.5045, average train loss: 0.0058
[09/26 14:34:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 6.3828
[09/26 14:34:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 59.00	
[09/26 14:34:36 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:34:43 visual_prompt]: Epoch 64 / 100: avg data time: 6.19e-02, avg batch time: 0.5108, average train loss: 0.0052
[09/26 14:34:45 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1688, average loss: 6.3819
[09/26 14:34:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.50	
[09/26 14:34:45 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:34:52 visual_prompt]: Epoch 65 / 100: avg data time: 6.47e-02, avg batch time: 0.5135, average train loss: 0.0055
[09/26 14:34:53 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 6.3731
[09/26 14:34:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.00	
[09/26 14:34:53 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:35:00 visual_prompt]: Epoch 66 / 100: avg data time: 5.52e-02, avg batch time: 0.5033, average train loss: 0.0049
[09/26 14:35:02 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 6.3679
[09/26 14:35:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.50	
[09/26 14:35:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:35:09 visual_prompt]: Epoch 67 / 100: avg data time: 5.97e-02, avg batch time: 0.5087, average train loss: 0.0043
[09/26 14:35:10 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1692, average loss: 6.3708
[09/26 14:35:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 59.50	
[09/26 14:35:10 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:35:17 visual_prompt]: Epoch 68 / 100: avg data time: 5.13e-02, avg batch time: 0.5018, average train loss: 0.0046
[09/26 14:35:19 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1689, average loss: 6.3842
[09/26 14:35:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.50	
[09/26 14:35:19 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:35:26 visual_prompt]: Epoch 69 / 100: avg data time: 5.89e-02, avg batch time: 0.5080, average train loss: 0.0049
[09/26 14:35:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1688, average loss: 6.3955
[09/26 14:35:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 14:35:27 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:35:34 visual_prompt]: Epoch 70 / 100: avg data time: 5.22e-02, avg batch time: 0.5005, average train loss: 0.0047
[09/26 14:35:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1686, average loss: 6.4135
[09/26 14:35:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 14:35:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:35:43 visual_prompt]: Epoch 71 / 100: avg data time: 5.92e-02, avg batch time: 0.5084, average train loss: 0.0042
[09/26 14:35:44 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 6.4269
[09/26 14:35:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 14:35:44 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:35:51 visual_prompt]: Epoch 72 / 100: avg data time: 4.39e-02, avg batch time: 0.4934, average train loss: 0.0045
[09/26 14:35:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 6.4393
[09/26 14:35:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 58.50	
[09/26 14:35:52 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:35:59 visual_prompt]: Epoch 73 / 100: avg data time: 5.81e-02, avg batch time: 0.5075, average train loss: 0.0047
[09/26 14:36:01 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1690, average loss: 6.4416
[09/26 14:36:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 58.50	
[09/26 14:36:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:36:08 visual_prompt]: Epoch 74 / 100: avg data time: 5.71e-02, avg batch time: 0.5070, average train loss: 0.0040
[09/26 14:36:09 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1692, average loss: 6.4407
[09/26 14:36:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:36:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:36:16 visual_prompt]: Epoch 75 / 100: avg data time: 5.52e-02, avg batch time: 0.5035, average train loss: 0.0039
[09/26 14:36:18 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1691, average loss: 6.4369
[09/26 14:36:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:36:18 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:36:24 visual_prompt]: Epoch 76 / 100: avg data time: 4.54e-02, avg batch time: 0.4937, average train loss: 0.0041
[09/26 14:36:26 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 6.4373
[09/26 14:36:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:36:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:36:33 visual_prompt]: Epoch 77 / 100: avg data time: 5.04e-02, avg batch time: 0.5018, average train loss: 0.0045
[09/26 14:36:34 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 6.4365
[09/26 14:36:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:36:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:36:41 visual_prompt]: Epoch 78 / 100: avg data time: 5.80e-02, avg batch time: 0.5070, average train loss: 0.0040
[09/26 14:36:43 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1692, average loss: 6.4366
[09/26 14:36:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:36:43 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:36:50 visual_prompt]: Epoch 79 / 100: avg data time: 5.95e-02, avg batch time: 0.5083, average train loss: 0.0045
[09/26 14:36:51 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1691, average loss: 6.4350
[09/26 14:36:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:36:51 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:36:58 visual_prompt]: Epoch 80 / 100: avg data time: 4.55e-02, avg batch time: 0.4950, average train loss: 0.0039
[09/26 14:36:59 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 6.4305
[09/26 14:36:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:36:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:37:06 visual_prompt]: Epoch 81 / 100: avg data time: 5.29e-02, avg batch time: 0.5029, average train loss: 0.0040
[09/26 14:37:08 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1690, average loss: 6.4318
[09/26 14:37:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:37:08 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:37:15 visual_prompt]: Epoch 82 / 100: avg data time: 5.95e-02, avg batch time: 0.5078, average train loss: 0.0036
[09/26 14:37:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 6.4328
[09/26 14:37:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.50	
[09/26 14:37:16 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:37:23 visual_prompt]: Epoch 83 / 100: avg data time: 6.09e-02, avg batch time: 0.5091, average train loss: 0.0040
[09/26 14:37:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 6.4349
[09/26 14:37:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:37:25 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:37:31 visual_prompt]: Epoch 84 / 100: avg data time: 5.38e-02, avg batch time: 0.5024, average train loss: 0.0038
[09/26 14:37:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 6.4369
[09/26 14:37:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:37:33 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:37:40 visual_prompt]: Epoch 85 / 100: avg data time: 4.36e-02, avg batch time: 0.4943, average train loss: 0.0039
[09/26 14:37:41 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1692, average loss: 6.4384
[09/26 14:37:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:37:41 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:37:48 visual_prompt]: Epoch 86 / 100: avg data time: 4.36e-02, avg batch time: 0.4950, average train loss: 0.0038
[09/26 14:37:49 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1692, average loss: 6.4396
[09/26 14:37:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 59.00	
[09/26 14:37:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:37:56 visual_prompt]: Epoch 87 / 100: avg data time: 4.42e-02, avg batch time: 0.4935, average train loss: 0.0038
[09/26 14:37:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1686, average loss: 6.4415
[09/26 14:37:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:37:58 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:38:04 visual_prompt]: Epoch 88 / 100: avg data time: 4.41e-02, avg batch time: 0.4948, average train loss: 0.0040
[09/26 14:38:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 6.4413
[09/26 14:38:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:38:13 visual_prompt]: Epoch 89 / 100: avg data time: 4.52e-02, avg batch time: 0.4973, average train loss: 0.0043
[09/26 14:38:14 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1688, average loss: 6.4411
[09/26 14:38:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:38:21 visual_prompt]: Epoch 90 / 100: avg data time: 5.66e-02, avg batch time: 0.5059, average train loss: 0.0043
[09/26 14:38:22 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 6.4421
[09/26 14:38:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:38:29 visual_prompt]: Epoch 91 / 100: avg data time: 5.60e-02, avg batch time: 0.5057, average train loss: 0.0042
[09/26 14:38:31 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1692, average loss: 6.4418
[09/26 14:38:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:31 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:38:38 visual_prompt]: Epoch 92 / 100: avg data time: 5.80e-02, avg batch time: 0.5071, average train loss: 0.0034
[09/26 14:38:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1689, average loss: 6.4418
[09/26 14:38:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:38:46 visual_prompt]: Epoch 93 / 100: avg data time: 5.16e-02, avg batch time: 0.5010, average train loss: 0.0036
[09/26 14:38:48 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 6.4425
[09/26 14:38:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:48 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:38:54 visual_prompt]: Epoch 94 / 100: avg data time: 5.44e-02, avg batch time: 0.5032, average train loss: 0.0036
[09/26 14:38:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 6.4430
[09/26 14:38:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:38:56 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:39:03 visual_prompt]: Epoch 95 / 100: avg data time: 5.42e-02, avg batch time: 0.5031, average train loss: 0.0035
[09/26 14:39:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1692, average loss: 6.4432
[09/26 14:39:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:04 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:39:11 visual_prompt]: Epoch 96 / 100: avg data time: 5.29e-02, avg batch time: 0.5027, average train loss: 0.0045
[09/26 14:39:13 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 6.4432
[09/26 14:39:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:13 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:39:19 visual_prompt]: Epoch 97 / 100: avg data time: 4.21e-02, avg batch time: 0.4929, average train loss: 0.0037
[09/26 14:39:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 6.4432
[09/26 14:39:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:39:28 visual_prompt]: Epoch 98 / 100: avg data time: 4.48e-02, avg batch time: 0.4953, average train loss: 0.0036
[09/26 14:39:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 6.4432
[09/26 14:39:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:39:36 visual_prompt]: Epoch 99 / 100: avg data time: 5.42e-02, avg batch time: 0.5045, average train loss: 0.0038
[09/26 14:39:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 6.4433
[09/26 14:39:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:37 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:39:44 visual_prompt]: Epoch 100 / 100: avg data time: 4.26e-02, avg batch time: 0.4935, average train loss: 0.0040
[09/26 14:39:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1690, average loss: 6.4433
[09/26 14:39:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 58.50	
[09/26 14:39:46 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:39:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:39:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:39:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:39:46 visual_prompt]: Training with config:
[09/26 14:39:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:39:46 visual_prompt]: Loading training data...
[09/26 14:39:46 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:39:47 visual_prompt]: Number of images: 800
[09/26 14:39:47 visual_prompt]: Number of classes: 18 / 18
[09/26 14:39:47 visual_prompt]: Loading validation data...
[09/26 14:39:47 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:39:47 visual_prompt]: Number of images: 200
[09/26 14:39:47 visual_prompt]: Number of classes: 18 / 18
[09/26 14:39:47 visual_prompt]: Constructing models...
[09/26 14:39:50 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 14:39:50 visual_prompt]: tuned percent:0.550
[09/26 14:39:50 visual_prompt]: Device used for model: 0
[09/26 14:39:50 visual_prompt]: Setting up Evaluator...
[09/26 14:39:50 visual_prompt]: Setting up Trainer...
[09/26 14:39:50 visual_prompt]: 	Setting up the optimizer...
[09/26 14:39:50 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:39:57 visual_prompt]: Epoch 1 / 100: avg data time: 6.44e-02, avg batch time: 0.5120, average train loss: 3.2615
[09/26 14:39:58 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 14:39:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 14:39:58 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 14:39:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 14:40:05 visual_prompt]: Epoch 2 / 100: avg data time: 5.87e-02, avg batch time: 0.5067, average train loss: 2.9872
[09/26 14:40:07 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1689, average loss: 2.9340
[09/26 14:40:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.50	
[09/26 14:40:07 visual_prompt]: Best epoch 2: best metric: 0.070
[09/26 14:40:07 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 14:40:13 visual_prompt]: Epoch 3 / 100: avg data time: 4.70e-02, avg batch time: 0.4955, average train loss: 2.9308
[09/26 14:40:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1686, average loss: 2.9309
[09/26 14:40:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 14:40:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 14:40:22 visual_prompt]: Epoch 4 / 100: avg data time: 6.12e-02, avg batch time: 0.5086, average train loss: 2.9167
[09/26 14:40:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 2.9001
[09/26 14:40:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 14:40:23 visual_prompt]: Best epoch 4: best metric: 0.085
[09/26 14:40:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 14:40:30 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.5044, average train loss: 2.9029
[09/26 14:40:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1688, average loss: 2.9170
[09/26 14:40:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 29.50	
[09/26 14:40:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 14:40:39 visual_prompt]: Epoch 6 / 100: avg data time: 5.49e-02, avg batch time: 0.5037, average train loss: 2.8973
[09/26 14:40:40 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 2.9328
[09/26 14:40:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 14:40:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 14:40:47 visual_prompt]: Epoch 7 / 100: avg data time: 6.26e-02, avg batch time: 0.5101, average train loss: 2.8919
[09/26 14:40:49 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1684, average loss: 2.9508
[09/26 14:40:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 28.50	
[09/26 14:40:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 14:40:55 visual_prompt]: Epoch 8 / 100: avg data time: 4.40e-02, avg batch time: 0.4940, average train loss: 2.8929
[09/26 14:40:57 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1686, average loss: 2.9013
[09/26 14:40:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 14:40:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 14:41:04 visual_prompt]: Epoch 9 / 100: avg data time: 6.30e-02, avg batch time: 0.5113, average train loss: 2.8680
[09/26 14:41:06 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1692, average loss: 2.9048
[09/26 14:41:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 35.00	
[09/26 14:41:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 14:41:12 visual_prompt]: Epoch 10 / 100: avg data time: 6.24e-02, avg batch time: 0.5099, average train loss: 2.9606
[09/26 14:41:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 2.9535
[09/26 14:41:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 29.50	
[09/26 14:41:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 14:41:21 visual_prompt]: Epoch 11 / 100: avg data time: 5.07e-02, avg batch time: 0.5003, average train loss: 2.9629
[09/26 14:41:22 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 2.9605
[09/26 14:41:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 14:41:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 14:41:29 visual_prompt]: Epoch 12 / 100: avg data time: 5.49e-02, avg batch time: 0.5044, average train loss: 2.9610
[09/26 14:41:31 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1688, average loss: 2.9472
[09/26 14:41:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.00	
[09/26 14:41:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 14:41:38 visual_prompt]: Epoch 13 / 100: avg data time: 6.11e-02, avg batch time: 0.5094, average train loss: 2.9453
[09/26 14:41:39 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 2.9665
[09/26 14:41:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 27.50	
[09/26 14:41:39 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 14:41:46 visual_prompt]: Epoch 14 / 100: avg data time: 5.25e-02, avg batch time: 0.5002, average train loss: 2.9312
[09/26 14:41:48 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1688, average loss: 2.9312
[09/26 14:41:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 14:41:48 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 14:41:54 visual_prompt]: Epoch 15 / 100: avg data time: 5.65e-02, avg batch time: 0.5041, average train loss: 2.9070
[09/26 14:41:56 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1690, average loss: 2.9321
[09/26 14:41:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.50	
[09/26 14:41:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 14:42:03 visual_prompt]: Epoch 16 / 100: avg data time: 5.62e-02, avg batch time: 0.5040, average train loss: 2.9100
[09/26 14:42:04 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 2.9601
[09/26 14:42:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 14:42:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 14:42:11 visual_prompt]: Epoch 17 / 100: avg data time: 5.54e-02, avg batch time: 0.5036, average train loss: 2.8876
[09/26 14:42:13 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1687, average loss: 2.9242
[09/26 14:42:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 29.00	
[09/26 14:42:13 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 14:42:20 visual_prompt]: Epoch 18 / 100: avg data time: 4.77e-02, avg batch time: 0.4979, average train loss: 2.8965
[09/26 14:42:21 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1689, average loss: 2.9166
[09/26 14:42:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 30.00	
[09/26 14:42:21 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 14:42:28 visual_prompt]: Epoch 19 / 100: avg data time: 6.26e-02, avg batch time: 0.5106, average train loss: 2.8764
[09/26 14:42:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 2.8917
[09/26 14:42:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 28.50	
[09/26 14:42:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 14:42:37 visual_prompt]: Epoch 20 / 100: avg data time: 6.05e-02, avg batch time: 0.5083, average train loss: 2.8577
[09/26 14:42:38 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1686, average loss: 2.8493
[09/26 14:42:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 38.00	
[09/26 14:42:38 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 14:42:45 visual_prompt]: Epoch 21 / 100: avg data time: 5.94e-02, avg batch time: 0.5079, average train loss: 2.8098
[09/26 14:42:47 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 2.9143
[09/26 14:42:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 37.50	
[09/26 14:42:47 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 14:42:54 visual_prompt]: Epoch 22 / 100: avg data time: 6.18e-02, avg batch time: 0.5095, average train loss: 2.7589
[09/26 14:42:55 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1693, average loss: 2.8375
[09/26 14:42:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 39.00	
[09/26 14:42:55 visual_prompt]: Best epoch 22: best metric: 0.095
[09/26 14:42:55 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 14:43:02 visual_prompt]: Epoch 23 / 100: avg data time: 6.11e-02, avg batch time: 0.5087, average train loss: 2.7050
[09/26 14:43:04 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 2.8400
[09/26 14:43:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 38.00	
[09/26 14:43:04 visual_prompt]: Best epoch 23: best metric: 0.100
[09/26 14:43:04 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 14:43:11 visual_prompt]: Epoch 24 / 100: avg data time: 5.73e-02, avg batch time: 0.5056, average train loss: 2.7031
[09/26 14:43:12 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1690, average loss: 2.8315
[09/26 14:43:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 39.00	
[09/26 14:43:12 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 14:43:19 visual_prompt]: Epoch 25 / 100: avg data time: 5.60e-02, avg batch time: 0.5039, average train loss: 2.6482
[09/26 14:43:21 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1688, average loss: 2.8383
[09/26 14:43:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 39.50	
[09/26 14:43:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 14:43:27 visual_prompt]: Epoch 26 / 100: avg data time: 4.57e-02, avg batch time: 0.4948, average train loss: 2.5889
[09/26 14:43:29 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1691, average loss: 2.7862
[09/26 14:43:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 44.50	
[09/26 14:43:29 visual_prompt]: Best epoch 26: best metric: 0.115
[09/26 14:43:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 14:43:36 visual_prompt]: Epoch 27 / 100: avg data time: 5.41e-02, avg batch time: 0.5023, average train loss: 2.4744
[09/26 14:43:37 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.1688, average loss: 2.8335
[09/26 14:43:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.00	
[09/26 14:43:37 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 14:43:44 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e-02, avg batch time: 0.5052, average train loss: 2.4324
[09/26 14:43:46 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1693, average loss: 2.7047
[09/26 14:43:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.00	
[09/26 14:43:46 visual_prompt]: Best epoch 28: best metric: 0.140
[09/26 14:43:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 14:43:53 visual_prompt]: Epoch 29 / 100: avg data time: 5.80e-02, avg batch time: 0.5059, average train loss: 2.3477
[09/26 14:43:54 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 2.7485
[09/26 14:43:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 54.50	
[09/26 14:43:54 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 14:44:01 visual_prompt]: Epoch 30 / 100: avg data time: 6.12e-02, avg batch time: 0.5093, average train loss: 2.2311
[09/26 14:44:03 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1691, average loss: 2.9373
[09/26 14:44:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 52.00	
[09/26 14:44:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 14:44:09 visual_prompt]: Epoch 31 / 100: avg data time: 5.56e-02, avg batch time: 0.5041, average train loss: 2.1413
[09/26 14:44:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 2.8242
[09/26 14:44:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.00	
[09/26 14:44:11 visual_prompt]: Best epoch 31: best metric: 0.175
[09/26 14:44:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 14:44:18 visual_prompt]: Epoch 32 / 100: avg data time: 5.53e-02, avg batch time: 0.5040, average train loss: 2.0607
[09/26 14:44:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 2.8257
[09/26 14:44:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.00	
[09/26 14:44:19 visual_prompt]: Best epoch 32: best metric: 0.180
[09/26 14:44:19 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 14:44:26 visual_prompt]: Epoch 33 / 100: avg data time: 5.96e-02, avg batch time: 0.5086, average train loss: 1.9118
[09/26 14:44:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1694, average loss: 2.8883
[09/26 14:44:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 56.50	
[09/26 14:44:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 14:44:35 visual_prompt]: Epoch 34 / 100: avg data time: 5.81e-02, avg batch time: 0.5076, average train loss: 1.8276
[09/26 14:44:36 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 3.0030
[09/26 14:44:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 59.50	
[09/26 14:44:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 14:44:43 visual_prompt]: Epoch 35 / 100: avg data time: 5.44e-02, avg batch time: 0.5029, average train loss: 1.6395
[09/26 14:44:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1690, average loss: 3.1296
[09/26 14:44:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.50	
[09/26 14:44:45 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 14:44:52 visual_prompt]: Epoch 36 / 100: avg data time: 4.49e-02, avg batch time: 0.4951, average train loss: 1.4681
[09/26 14:44:53 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 3.4244
[09/26 14:44:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 65.50	
[09/26 14:44:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 14:45:00 visual_prompt]: Epoch 37 / 100: avg data time: 5.71e-02, avg batch time: 0.5066, average train loss: 1.3449
[09/26 14:45:02 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 4.0598
[09/26 14:45:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 56.50	
[09/26 14:45:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 14:45:08 visual_prompt]: Epoch 38 / 100: avg data time: 5.77e-02, avg batch time: 0.5058, average train loss: 1.3981
[09/26 14:45:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1691, average loss: 3.5653
[09/26 14:45:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 58.00	
[09/26 14:45:10 visual_prompt]: Best epoch 38: best metric: 0.185
[09/26 14:45:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 14:45:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.84e-02, avg batch time: 0.5070, average train loss: 1.2056
[09/26 14:45:18 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 3.8400
[09/26 14:45:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 62.00	
[09/26 14:45:18 visual_prompt]: Best epoch 39: best metric: 0.190
[09/26 14:45:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 14:45:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.08e-02, avg batch time: 0.4900, average train loss: 1.0955
[09/26 14:45:27 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1689, average loss: 4.0650
[09/26 14:45:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 64.50	
[09/26 14:45:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 14:45:34 visual_prompt]: Epoch 41 / 100: avg data time: 5.83e-02, avg batch time: 0.5086, average train loss: 0.9376
[09/26 14:45:35 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 4.2579
[09/26 14:45:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.50	
[09/26 14:45:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 14:45:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.58e-02, avg batch time: 0.5055, average train loss: 0.8426
[09/26 14:45:44 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1690, average loss: 4.3057
[09/26 14:45:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.50	
[09/26 14:45:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 14:45:51 visual_prompt]: Epoch 43 / 100: avg data time: 6.50e-02, avg batch time: 0.5137, average train loss: 0.6912
[09/26 14:45:52 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1689, average loss: 4.7256
[09/26 14:45:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 62.50	
[09/26 14:45:52 visual_prompt]: Best epoch 43: best metric: 0.205
[09/26 14:45:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 14:45:59 visual_prompt]: Epoch 44 / 100: avg data time: 5.38e-02, avg batch time: 0.5031, average train loss: 0.5569
[09/26 14:46:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 4.6484
[09/26 14:46:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 64.50	
[09/26 14:46:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 14:46:07 visual_prompt]: Epoch 45 / 100: avg data time: 5.60e-02, avg batch time: 0.5042, average train loss: 0.4967
[09/26 14:46:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1692, average loss: 5.3553
[09/26 14:46:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 62.50	
[09/26 14:46:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 14:46:16 visual_prompt]: Epoch 46 / 100: avg data time: 5.15e-02, avg batch time: 0.5013, average train loss: 0.4514
[09/26 14:46:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1689, average loss: 5.2216
[09/26 14:46:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 14:46:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 14:46:24 visual_prompt]: Epoch 47 / 100: avg data time: 6.29e-02, avg batch time: 0.5123, average train loss: 0.4818
[09/26 14:46:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 5.3768
[09/26 14:46:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 59.50	
[09/26 14:46:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 14:46:33 visual_prompt]: Epoch 48 / 100: avg data time: 5.87e-02, avg batch time: 0.5067, average train loss: 0.3423
[09/26 14:46:34 visual_prompt]: Inference (val):avg data time: 4.04e-05, avg batch time: 0.1693, average loss: 5.4690
[09/26 14:46:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 58.00	
[09/26 14:46:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 14:46:41 visual_prompt]: Epoch 49 / 100: avg data time: 5.93e-02, avg batch time: 0.5087, average train loss: 0.2594
[09/26 14:46:42 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1694, average loss: 5.5081
[09/26 14:46:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 62.00	
[09/26 14:46:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 14:46:49 visual_prompt]: Epoch 50 / 100: avg data time: 5.30e-02, avg batch time: 0.5024, average train loss: 0.1953
[09/26 14:46:51 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1687, average loss: 5.3906
[09/26 14:46:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 60.50	
[09/26 14:46:51 visual_prompt]: Best epoch 50: best metric: 0.225
[09/26 14:46:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 14:46:58 visual_prompt]: Epoch 51 / 100: avg data time: 5.77e-02, avg batch time: 0.5061, average train loss: 0.1678
[09/26 14:46:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 5.6397
[09/26 14:46:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 61.00	
[09/26 14:46:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 14:47:06 visual_prompt]: Epoch 52 / 100: avg data time: 5.50e-02, avg batch time: 0.5037, average train loss: 0.1075
[09/26 14:47:08 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 5.6482
[09/26 14:47:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 64.50	
[09/26 14:47:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 14:47:15 visual_prompt]: Epoch 53 / 100: avg data time: 6.08e-02, avg batch time: 0.5106, average train loss: 0.0833
[09/26 14:47:16 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1692, average loss: 5.7622
[09/26 14:47:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 14:47:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 14:47:23 visual_prompt]: Epoch 54 / 100: avg data time: 6.22e-02, avg batch time: 0.5106, average train loss: 0.0707
[09/26 14:47:25 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 5.8166
[09/26 14:47:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.50	
[09/26 14:47:25 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 14:47:32 visual_prompt]: Epoch 55 / 100: avg data time: 6.66e-02, avg batch time: 0.5148, average train loss: 0.0534
[09/26 14:47:33 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 5.8452
[09/26 14:47:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.00	
[09/26 14:47:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 14:47:40 visual_prompt]: Epoch 56 / 100: avg data time: 5.34e-02, avg batch time: 0.5021, average train loss: 0.0545
[09/26 14:47:42 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1692, average loss: 5.9476
[09/26 14:47:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.50	
[09/26 14:47:42 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 14:47:48 visual_prompt]: Epoch 57 / 100: avg data time: 5.11e-02, avg batch time: 0.4994, average train loss: 0.0346
[09/26 14:47:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 6.1228
[09/26 14:47:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.50	
[09/26 14:47:50 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 14:47:57 visual_prompt]: Epoch 58 / 100: avg data time: 4.56e-02, avg batch time: 0.4939, average train loss: 0.0251
[09/26 14:47:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1689, average loss: 5.9050
[09/26 14:47:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.00	
[09/26 14:47:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:48:05 visual_prompt]: Epoch 59 / 100: avg data time: 5.77e-02, avg batch time: 0.5080, average train loss: 0.0216
[09/26 14:48:07 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.1693, average loss: 6.1084
[09/26 14:48:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 62.50	
[09/26 14:48:07 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:48:14 visual_prompt]: Epoch 60 / 100: avg data time: 5.41e-02, avg batch time: 0.5030, average train loss: 0.0150
[09/26 14:48:15 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1692, average loss: 6.1306
[09/26 14:48:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 63.50	
[09/26 14:48:15 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:48:22 visual_prompt]: Epoch 61 / 100: avg data time: 6.30e-02, avg batch time: 0.5119, average train loss: 0.0137
[09/26 14:48:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 6.0017
[09/26 14:48:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 14:48:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:48:30 visual_prompt]: Epoch 62 / 100: avg data time: 5.17e-02, avg batch time: 0.5006, average train loss: 0.0124
[09/26 14:48:32 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1691, average loss: 6.0587
[09/26 14:48:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 66.00	
[09/26 14:48:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:48:39 visual_prompt]: Epoch 63 / 100: avg data time: 5.91e-02, avg batch time: 0.5069, average train loss: 0.0113
[09/26 14:48:41 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1691, average loss: 6.1480
[09/26 14:48:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 14:48:41 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:48:47 visual_prompt]: Epoch 64 / 100: avg data time: 5.96e-02, avg batch time: 0.5075, average train loss: 0.0099
[09/26 14:48:49 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1688, average loss: 6.1857
[09/26 14:48:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 14:48:49 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:48:56 visual_prompt]: Epoch 65 / 100: avg data time: 5.70e-02, avg batch time: 0.5057, average train loss: 0.0089
[09/26 14:48:57 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1693, average loss: 6.2221
[09/26 14:48:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.50	
[09/26 14:48:57 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:49:04 visual_prompt]: Epoch 66 / 100: avg data time: 6.20e-02, avg batch time: 0.5100, average train loss: 0.0104
[09/26 14:49:06 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1690, average loss: 6.2028
[09/26 14:49:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.00	
[09/26 14:49:06 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:49:13 visual_prompt]: Epoch 67 / 100: avg data time: 6.09e-02, avg batch time: 0.5113, average train loss: 0.0091
[09/26 14:49:15 visual_prompt]: Inference (val):avg data time: 4.65e-05, avg batch time: 0.1691, average loss: 6.1969
[09/26 14:49:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.50	
[09/26 14:49:15 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:49:21 visual_prompt]: Epoch 68 / 100: avg data time: 5.89e-02, avg batch time: 0.5069, average train loss: 0.0084
[09/26 14:49:23 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1691, average loss: 6.2431
[09/26 14:49:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 14:49:23 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:49:30 visual_prompt]: Epoch 69 / 100: avg data time: 5.92e-02, avg batch time: 0.5074, average train loss: 0.0088
[09/26 14:49:31 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1690, average loss: 6.2536
[09/26 14:49:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:49:31 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:49:38 visual_prompt]: Epoch 70 / 100: avg data time: 5.66e-02, avg batch time: 0.5048, average train loss: 0.0073
[09/26 14:49:40 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1691, average loss: 6.2554
[09/26 14:49:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 14:49:40 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:49:47 visual_prompt]: Epoch 71 / 100: avg data time: 4.60e-02, avg batch time: 0.4976, average train loss: 0.0073
[09/26 14:49:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1692, average loss: 6.2884
[09/26 14:49:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 14:49:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:49:55 visual_prompt]: Epoch 72 / 100: avg data time: 5.56e-02, avg batch time: 0.5046, average train loss: 0.0061
[09/26 14:49:57 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 6.3127
[09/26 14:49:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:49:57 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:50:04 visual_prompt]: Epoch 73 / 100: avg data time: 5.44e-02, avg batch time: 0.5031, average train loss: 0.0060
[09/26 14:50:05 visual_prompt]: Inference (val):avg data time: 4.52e-05, avg batch time: 0.1693, average loss: 6.3261
[09/26 14:50:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.50	
[09/26 14:50:05 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:50:12 visual_prompt]: Epoch 74 / 100: avg data time: 5.55e-02, avg batch time: 0.5037, average train loss: 0.0075
[09/26 14:50:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 6.3366
[09/26 14:50:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.00	
[09/26 14:50:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:50:21 visual_prompt]: Epoch 75 / 100: avg data time: 5.69e-02, avg batch time: 0.5064, average train loss: 0.0062
[09/26 14:50:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 6.3283
[09/26 14:50:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.00	
[09/26 14:50:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:50:29 visual_prompt]: Epoch 76 / 100: avg data time: 5.03e-02, avg batch time: 0.4992, average train loss: 0.0056
[09/26 14:50:31 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 6.3340
[09/26 14:50:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 14:50:31 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:50:37 visual_prompt]: Epoch 77 / 100: avg data time: 4.50e-02, avg batch time: 0.4941, average train loss: 0.0059
[09/26 14:50:39 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1694, average loss: 6.3338
[09/26 14:50:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:50:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:50:46 visual_prompt]: Epoch 78 / 100: avg data time: 4.78e-02, avg batch time: 0.4978, average train loss: 0.0057
[09/26 14:50:47 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1692, average loss: 6.3260
[09/26 14:50:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 63.00	
[09/26 14:50:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:50:54 visual_prompt]: Epoch 79 / 100: avg data time: 5.89e-02, avg batch time: 0.5083, average train loss: 0.0050
[09/26 14:50:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 6.3274
[09/26 14:50:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.00	
[09/26 14:50:56 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:51:03 visual_prompt]: Epoch 80 / 100: avg data time: 6.14e-02, avg batch time: 0.5099, average train loss: 0.0052
[09/26 14:51:04 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 6.3395
[09/26 14:51:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.00	
[09/26 14:51:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:51:11 visual_prompt]: Epoch 81 / 100: avg data time: 4.23e-02, avg batch time: 0.4922, average train loss: 0.0055
[09/26 14:51:12 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1690, average loss: 6.3426
[09/26 14:51:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 63.00	
[09/26 14:51:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:51:19 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.5074, average train loss: 0.0055
[09/26 14:51:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 6.3447
[09/26 14:51:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 63.00	
[09/26 14:51:21 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:51:28 visual_prompt]: Epoch 83 / 100: avg data time: 4.79e-02, avg batch time: 0.4973, average train loss: 0.0065
[09/26 14:51:29 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 6.3514
[09/26 14:51:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 63.50	
[09/26 14:51:29 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:51:36 visual_prompt]: Epoch 84 / 100: avg data time: 5.55e-02, avg batch time: 0.5056, average train loss: 0.0050
[09/26 14:51:37 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1688, average loss: 6.3581
[09/26 14:51:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:51:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:51:44 visual_prompt]: Epoch 85 / 100: avg data time: 4.55e-02, avg batch time: 0.4966, average train loss: 0.0061
[09/26 14:51:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 6.3574
[09/26 14:51:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.00	
[09/26 14:51:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:51:53 visual_prompt]: Epoch 86 / 100: avg data time: 4.69e-02, avg batch time: 0.4975, average train loss: 0.0060
[09/26 14:51:54 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1689, average loss: 6.3421
[09/26 14:51:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.00	
[09/26 14:51:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:52:01 visual_prompt]: Epoch 87 / 100: avg data time: 4.14e-02, avg batch time: 0.4926, average train loss: 0.0047
[09/26 14:52:02 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1692, average loss: 6.3394
[09/26 14:52:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.50	
[09/26 14:52:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:52:09 visual_prompt]: Epoch 88 / 100: avg data time: 4.70e-02, avg batch time: 0.4981, average train loss: 0.0055
[09/26 14:52:11 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 6.3420
[09/26 14:52:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 64.50	
[09/26 14:52:11 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:52:17 visual_prompt]: Epoch 89 / 100: avg data time: 4.83e-02, avg batch time: 0.4974, average train loss: 0.0045
[09/26 14:52:19 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1689, average loss: 6.3438
[09/26 14:52:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:52:19 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:52:26 visual_prompt]: Epoch 90 / 100: avg data time: 5.12e-02, avg batch time: 0.5011, average train loss: 0.0047
[09/26 14:52:27 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1693, average loss: 6.3456
[09/26 14:52:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:52:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:52:34 visual_prompt]: Epoch 91 / 100: avg data time: 5.30e-02, avg batch time: 0.5029, average train loss: 0.0057
[09/26 14:52:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 6.3484
[09/26 14:52:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:52:36 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:52:42 visual_prompt]: Epoch 92 / 100: avg data time: 6.09e-02, avg batch time: 0.5097, average train loss: 0.0047
[09/26 14:52:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 6.3497
[09/26 14:52:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:52:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:52:51 visual_prompt]: Epoch 93 / 100: avg data time: 5.68e-02, avg batch time: 0.5054, average train loss: 0.0046
[09/26 14:52:52 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1692, average loss: 6.3508
[09/26 14:52:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:52:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:52:59 visual_prompt]: Epoch 94 / 100: avg data time: 4.18e-02, avg batch time: 0.4903, average train loss: 0.0045
[09/26 14:53:01 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1691, average loss: 6.3518
[09/26 14:53:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:01 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:53:08 visual_prompt]: Epoch 95 / 100: avg data time: 6.13e-02, avg batch time: 0.5112, average train loss: 0.0053
[09/26 14:53:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1692, average loss: 6.3532
[09/26 14:53:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:53:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.79e-02, avg batch time: 0.5074, average train loss: 0.0050
[09/26 14:53:17 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 6.3528
[09/26 14:53:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:53:24 visual_prompt]: Epoch 97 / 100: avg data time: 4.37e-02, avg batch time: 0.4937, average train loss: 0.0058
[09/26 14:53:26 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1692, average loss: 6.3529
[09/26 14:53:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:53:32 visual_prompt]: Epoch 98 / 100: avg data time: 4.46e-02, avg batch time: 0.4960, average train loss: 0.0043
[09/26 14:53:34 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 6.3531
[09/26 14:53:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:34 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:53:41 visual_prompt]: Epoch 99 / 100: avg data time: 5.51e-02, avg batch time: 0.5037, average train loss: 0.0053
[09/26 14:53:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 6.3532
[09/26 14:53:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:53:49 visual_prompt]: Epoch 100 / 100: avg data time: 5.86e-02, avg batch time: 0.5077, average train loss: 0.0051
[09/26 14:53:51 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1695, average loss: 6.3532
[09/26 14:53:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.00	
[09/26 14:53:51 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:53:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:53:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:53:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:53:51 visual_prompt]: Training with config:
[09/26 14:53:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:53:51 visual_prompt]: Loading training data...
[09/26 14:53:51 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:53:52 visual_prompt]: Number of images: 800
[09/26 14:53:52 visual_prompt]: Number of classes: 18 / 18
[09/26 14:53:52 visual_prompt]: Loading validation data...
[09/26 14:53:52 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 14:53:52 visual_prompt]: Number of images: 200
[09/26 14:53:52 visual_prompt]: Number of classes: 18 / 18
[09/26 14:53:52 visual_prompt]: Constructing models...
[09/26 14:53:55 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 14:53:55 visual_prompt]: tuned percent:0.550
[09/26 14:53:55 visual_prompt]: Device used for model: 0
[09/26 14:53:55 visual_prompt]: Setting up Evaluator...
[09/26 14:53:55 visual_prompt]: Setting up Trainer...
[09/26 14:53:55 visual_prompt]: 	Setting up the optimizer...
[09/26 14:53:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:54:02 visual_prompt]: Epoch 1 / 100: avg data time: 4.45e-02, avg batch time: 0.4952, average train loss: 3.2466
[09/26 14:54:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1686, average loss: 3.1895
[09/26 14:54:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 14:54:03 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 14:54:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 14:54:10 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e-02, avg batch time: 0.4984, average train loss: 3.0214
[09/26 14:54:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1687, average loss: 2.9229
[09/26 14:54:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 33.00	
[09/26 14:54:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 14:54:18 visual_prompt]: Epoch 3 / 100: avg data time: 4.43e-02, avg batch time: 0.4936, average train loss: 2.9208
[09/26 14:54:19 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1686, average loss: 2.9223
[09/26 14:54:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 27.50	
[09/26 14:54:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 14:54:26 visual_prompt]: Epoch 4 / 100: avg data time: 4.87e-02, avg batch time: 0.4963, average train loss: 2.9109
[09/26 14:54:28 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1687, average loss: 2.9141
[09/26 14:54:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 28.00	
[09/26 14:54:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 14:54:34 visual_prompt]: Epoch 5 / 100: avg data time: 5.16e-02, avg batch time: 0.5002, average train loss: 2.9153
[09/26 14:54:36 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 2.9276
[09/26 14:54:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.00	
[09/26 14:54:36 visual_prompt]: Best epoch 5: best metric: 0.070
[09/26 14:54:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 14:54:43 visual_prompt]: Epoch 6 / 100: avg data time: 6.03e-02, avg batch time: 0.5095, average train loss: 2.8999
[09/26 14:54:44 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 2.9029
[09/26 14:54:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 27.50	
[09/26 14:54:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 14:54:51 visual_prompt]: Epoch 7 / 100: avg data time: 6.18e-02, avg batch time: 0.5110, average train loss: 2.9122
[09/26 14:54:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 2.9057
[09/26 14:54:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 31.00	
[09/26 14:54:53 visual_prompt]: Best epoch 7: best metric: 0.085
[09/26 14:54:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 14:55:00 visual_prompt]: Epoch 8 / 100: avg data time: 5.41e-02, avg batch time: 0.5037, average train loss: 2.8903
[09/26 14:55:01 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1684, average loss: 2.9277
[09/26 14:55:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 27.50	
[09/26 14:55:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 14:55:08 visual_prompt]: Epoch 9 / 100: avg data time: 5.76e-02, avg batch time: 0.5064, average train loss: 2.8872
[09/26 14:55:10 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1688, average loss: 2.8974
[09/26 14:55:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.50	
[09/26 14:55:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 14:55:17 visual_prompt]: Epoch 10 / 100: avg data time: 6.21e-02, avg batch time: 0.5105, average train loss: 2.8798
[09/26 14:55:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 2.9397
[09/26 14:55:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 26.00	
[09/26 14:55:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 14:55:25 visual_prompt]: Epoch 11 / 100: avg data time: 5.87e-02, avg batch time: 0.5063, average train loss: 2.8890
[09/26 14:55:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1689, average loss: 2.9351
[09/26 14:55:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 25.50	
[09/26 14:55:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 14:55:34 visual_prompt]: Epoch 12 / 100: avg data time: 6.51e-02, avg batch time: 0.5136, average train loss: 2.8606
[09/26 14:55:35 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1695, average loss: 2.8923
[09/26 14:55:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 34.50	
[09/26 14:55:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 14:55:42 visual_prompt]: Epoch 13 / 100: avg data time: 5.25e-02, avg batch time: 0.5043, average train loss: 2.8533
[09/26 14:55:44 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1688, average loss: 2.9083
[09/26 14:55:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 14:55:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 14:55:51 visual_prompt]: Epoch 14 / 100: avg data time: 6.56e-02, avg batch time: 0.5133, average train loss: 2.8395
[09/26 14:55:52 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1693, average loss: 2.9419
[09/26 14:55:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 30.00	
[09/26 14:55:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 14:55:59 visual_prompt]: Epoch 15 / 100: avg data time: 5.86e-02, avg batch time: 0.5064, average train loss: 2.8172
[09/26 14:56:01 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 2.8202
[09/26 14:56:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 38.00	
[09/26 14:56:01 visual_prompt]: Best epoch 15: best metric: 0.100
[09/26 14:56:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 14:56:08 visual_prompt]: Epoch 16 / 100: avg data time: 6.02e-02, avg batch time: 0.5090, average train loss: 2.7758
[09/26 14:56:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1687, average loss: 3.0283
[09/26 14:56:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 33.00	
[09/26 14:56:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 14:56:16 visual_prompt]: Epoch 17 / 100: avg data time: 5.53e-02, avg batch time: 0.5043, average train loss: 2.7848
[09/26 14:56:17 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1695, average loss: 2.7892
[09/26 14:56:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 40.00	
[09/26 14:56:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 14:56:24 visual_prompt]: Epoch 18 / 100: avg data time: 5.65e-02, avg batch time: 0.5069, average train loss: 2.7237
[09/26 14:56:26 visual_prompt]: Inference (val):avg data time: 4.66e-05, avg batch time: 0.1687, average loss: 2.7270
[09/26 14:56:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 43.00	
[09/26 14:56:26 visual_prompt]: Best epoch 18: best metric: 0.110
[09/26 14:56:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 14:56:33 visual_prompt]: Epoch 19 / 100: avg data time: 5.69e-02, avg batch time: 0.5060, average train loss: 2.6754
[09/26 14:56:34 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 2.7643
[09/26 14:56:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 43.50	
[09/26 14:56:34 visual_prompt]: Best epoch 19: best metric: 0.130
[09/26 14:56:34 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 14:56:41 visual_prompt]: Epoch 20 / 100: avg data time: 6.26e-02, avg batch time: 0.5120, average train loss: 2.7425
[09/26 14:56:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1688, average loss: 2.8962
[09/26 14:56:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 36.50	
[09/26 14:56:43 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 14:56:50 visual_prompt]: Epoch 21 / 100: avg data time: 5.56e-02, avg batch time: 0.5039, average train loss: 2.7317
[09/26 14:56:51 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 2.8479
[09/26 14:56:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 39.00	
[09/26 14:56:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 14:56:58 visual_prompt]: Epoch 22 / 100: avg data time: 5.47e-02, avg batch time: 0.5046, average train loss: 2.6364
[09/26 14:57:00 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 2.7822
[09/26 14:57:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 43.00	
[09/26 14:57:00 visual_prompt]: Best epoch 22: best metric: 0.145
[09/26 14:57:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 14:57:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.84e-02, avg batch time: 0.5064, average train loss: 2.6166
[09/26 14:57:08 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1689, average loss: 2.7026
[09/26 14:57:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 48.50	
[09/26 14:57:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 14:57:15 visual_prompt]: Epoch 24 / 100: avg data time: 5.90e-02, avg batch time: 0.5085, average train loss: 2.6020
[09/26 14:57:17 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1688, average loss: 2.6805
[09/26 14:57:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.50	
[09/26 14:57:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 14:57:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.16e-02, avg batch time: 0.5012, average train loss: 2.6018
[09/26 14:57:25 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1690, average loss: 2.9149
[09/26 14:57:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 37.50	
[09/26 14:57:25 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 14:57:32 visual_prompt]: Epoch 26 / 100: avg data time: 4.85e-02, avg batch time: 0.4977, average train loss: 2.6869
[09/26 14:57:33 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1695, average loss: 2.5926
[09/26 14:57:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 56.00	
[09/26 14:57:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 14:57:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.94e-02, avg batch time: 0.5076, average train loss: 2.5802
[09/26 14:57:42 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1691, average loss: 2.6765
[09/26 14:57:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 55.00	
[09/26 14:57:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 14:57:49 visual_prompt]: Epoch 28 / 100: avg data time: 6.36e-02, avg batch time: 0.5120, average train loss: 2.6164
[09/26 14:57:50 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1694, average loss: 2.6109
[09/26 14:57:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 54.00	
[09/26 14:57:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 14:57:57 visual_prompt]: Epoch 29 / 100: avg data time: 4.37e-02, avg batch time: 0.4933, average train loss: 2.4220
[09/26 14:57:59 visual_prompt]: Inference (val):avg data time: 5.52e-05, avg batch time: 0.1691, average loss: 2.5021
[09/26 14:57:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 63.00	
[09/26 14:57:59 visual_prompt]: Best epoch 29: best metric: 0.160
[09/26 14:57:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 14:58:06 visual_prompt]: Epoch 30 / 100: avg data time: 4.41e-02, avg batch time: 0.4939, average train loss: 2.2744
[09/26 14:58:07 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1691, average loss: 2.6711
[09/26 14:58:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 14:58:07 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 14:58:14 visual_prompt]: Epoch 31 / 100: avg data time: 4.25e-02, avg batch time: 0.4926, average train loss: 2.2409
[09/26 14:58:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 2.4479
[09/26 14:58:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 14:58:15 visual_prompt]: Best epoch 31: best metric: 0.170
[09/26 14:58:15 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 14:58:22 visual_prompt]: Epoch 32 / 100: avg data time: 3.97e-02, avg batch time: 0.4897, average train loss: 2.1591
[09/26 14:58:24 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1692, average loss: 2.5458
[09/26 14:58:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 61.00	
[09/26 14:58:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 14:58:31 visual_prompt]: Epoch 33 / 100: avg data time: 5.96e-02, avg batch time: 0.5081, average train loss: 2.0656
[09/26 14:58:32 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1689, average loss: 2.6128
[09/26 14:58:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 14:58:32 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 14:58:39 visual_prompt]: Epoch 34 / 100: avg data time: 5.54e-02, avg batch time: 0.5036, average train loss: 1.9463
[09/26 14:58:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 2.5798
[09/26 14:58:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 62.50	
[09/26 14:58:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 14:58:47 visual_prompt]: Epoch 35 / 100: avg data time: 5.45e-02, avg batch time: 0.5029, average train loss: 1.8430
[09/26 14:58:49 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1694, average loss: 2.8455
[09/26 14:58:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 50.00	
[09/26 14:58:49 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 14:58:56 visual_prompt]: Epoch 36 / 100: avg data time: 4.31e-02, avg batch time: 0.4947, average train loss: 1.9185
[09/26 14:58:57 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1697, average loss: 2.5904
[09/26 14:58:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 14:58:57 visual_prompt]: Best epoch 36: best metric: 0.180
[09/26 14:58:57 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 14:59:04 visual_prompt]: Epoch 37 / 100: avg data time: 5.63e-02, avg batch time: 0.5058, average train loss: 1.7508
[09/26 14:59:06 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1688, average loss: 2.5921
[09/26 14:59:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 66.00	
[09/26 14:59:06 visual_prompt]: Best epoch 37: best metric: 0.185
[09/26 14:59:06 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 14:59:13 visual_prompt]: Epoch 38 / 100: avg data time: 5.17e-02, avg batch time: 0.5021, average train loss: 1.6490
[09/26 14:59:14 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 2.7494
[09/26 14:59:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 61.50	
[09/26 14:59:14 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 14:59:21 visual_prompt]: Epoch 39 / 100: avg data time: 5.33e-02, avg batch time: 0.5026, average train loss: 1.5922
[09/26 14:59:22 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1691, average loss: 2.6509
[09/26 14:59:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 69.50	
[09/26 14:59:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 14:59:29 visual_prompt]: Epoch 40 / 100: avg data time: 6.16e-02, avg batch time: 0.5100, average train loss: 1.7108
[09/26 14:59:31 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 2.6314
[09/26 14:59:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.50	
[09/26 14:59:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 14:59:38 visual_prompt]: Epoch 41 / 100: avg data time: 4.89e-02, avg batch time: 0.4981, average train loss: 1.6358
[09/26 14:59:39 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1688, average loss: 2.4778
[09/26 14:59:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 72.50	
[09/26 14:59:39 visual_prompt]: Best epoch 41: best metric: 0.200
[09/26 14:59:39 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 14:59:46 visual_prompt]: Epoch 42 / 100: avg data time: 4.37e-02, avg batch time: 0.4952, average train loss: 1.4128
[09/26 14:59:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 2.6862
[09/26 14:59:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 66.50	
[09/26 14:59:47 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 14:59:54 visual_prompt]: Epoch 43 / 100: avg data time: 6.15e-02, avg batch time: 0.5108, average train loss: 1.3997
[09/26 14:59:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 2.6231
[09/26 14:59:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 64.50	
[09/26 14:59:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 15:00:03 visual_prompt]: Epoch 44 / 100: avg data time: 5.85e-02, avg batch time: 0.5076, average train loss: 1.1840
[09/26 15:00:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 2.8340
[09/26 15:00:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.00	
[09/26 15:00:04 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 15:00:11 visual_prompt]: Epoch 45 / 100: avg data time: 5.55e-02, avg batch time: 0.5041, average train loss: 1.1451
[09/26 15:00:13 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1690, average loss: 2.7662
[09/26 15:00:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 65.50	
[09/26 15:00:13 visual_prompt]: Best epoch 45: best metric: 0.225
[09/26 15:00:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 15:00:20 visual_prompt]: Epoch 46 / 100: avg data time: 5.73e-02, avg batch time: 0.5063, average train loss: 0.9931
[09/26 15:00:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 2.8069
[09/26 15:00:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 67.00	
[09/26 15:00:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 15:00:28 visual_prompt]: Epoch 47 / 100: avg data time: 4.38e-02, avg batch time: 0.4947, average train loss: 0.9495
[09/26 15:00:29 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1692, average loss: 2.9490
[09/26 15:00:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.00	
[09/26 15:00:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 15:00:36 visual_prompt]: Epoch 48 / 100: avg data time: 5.12e-02, avg batch time: 0.5001, average train loss: 0.8848
[09/26 15:00:38 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1692, average loss: 3.0027
[09/26 15:00:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 61.50	
[09/26 15:00:38 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 15:00:45 visual_prompt]: Epoch 49 / 100: avg data time: 4.24e-02, avg batch time: 0.4925, average train loss: 0.8981
[09/26 15:00:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 2.9552
[09/26 15:00:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.50	
[09/26 15:00:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 15:00:53 visual_prompt]: Epoch 50 / 100: avg data time: 5.97e-02, avg batch time: 0.5084, average train loss: 0.8257
[09/26 15:00:54 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1694, average loss: 2.8992
[09/26 15:00:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 68.00	
[09/26 15:00:54 visual_prompt]: Best epoch 50: best metric: 0.235
[09/26 15:00:54 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 15:01:01 visual_prompt]: Epoch 51 / 100: avg data time: 5.45e-02, avg batch time: 0.5036, average train loss: 0.8110
[09/26 15:01:03 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 2.8619
[09/26 15:01:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 66.00	
[09/26 15:01:03 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 15:01:10 visual_prompt]: Epoch 52 / 100: avg data time: 5.53e-02, avg batch time: 0.5056, average train loss: 0.7797
[09/26 15:01:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1692, average loss: 3.0686
[09/26 15:01:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 65.50	
[09/26 15:01:11 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 15:01:18 visual_prompt]: Epoch 53 / 100: avg data time: 6.11e-02, avg batch time: 0.5099, average train loss: 0.7038
[09/26 15:01:19 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1690, average loss: 3.0057
[09/26 15:01:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 67.00	
[09/26 15:01:19 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 15:01:26 visual_prompt]: Epoch 54 / 100: avg data time: 6.78e-02, avg batch time: 0.5163, average train loss: 0.6450
[09/26 15:01:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 3.0268
[09/26 15:01:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 63.50	
[09/26 15:01:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 15:01:35 visual_prompt]: Epoch 55 / 100: avg data time: 6.06e-02, avg batch time: 0.5103, average train loss: 0.5269
[09/26 15:01:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1695, average loss: 3.0659
[09/26 15:01:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 70.00	
[09/26 15:01:36 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 15:01:43 visual_prompt]: Epoch 56 / 100: avg data time: 4.74e-02, avg batch time: 0.4969, average train loss: 0.4778
[09/26 15:01:45 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 3.2592
[09/26 15:01:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 65.50	
[09/26 15:01:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 15:01:52 visual_prompt]: Epoch 57 / 100: avg data time: 5.91e-02, avg batch time: 0.5083, average train loss: 0.4281
[09/26 15:01:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 3.2224
[09/26 15:01:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 62.50	
[09/26 15:01:53 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 15:02:00 visual_prompt]: Epoch 58 / 100: avg data time: 5.29e-02, avg batch time: 0.5022, average train loss: 0.4232
[09/26 15:02:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 3.1989
[09/26 15:02:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 63.50	
[09/26 15:02:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 15:02:08 visual_prompt]: Epoch 59 / 100: avg data time: 6.33e-02, avg batch time: 0.5119, average train loss: 0.3775
[09/26 15:02:10 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1694, average loss: 3.1243
[09/26 15:02:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 27.00	top5: 66.50	
[09/26 15:02:10 visual_prompt]: Best epoch 59: best metric: 0.270
[09/26 15:02:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 15:02:17 visual_prompt]: Epoch 60 / 100: avg data time: 6.00e-02, avg batch time: 0.5088, average train loss: 0.3986
[09/26 15:02:18 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1695, average loss: 3.0646
[09/26 15:02:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 23.50	top5: 66.50	
[09/26 15:02:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 15:02:25 visual_prompt]: Epoch 61 / 100: avg data time: 5.17e-02, avg batch time: 0.5013, average train loss: 0.4127
[09/26 15:02:27 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1688, average loss: 3.0982
[09/26 15:02:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 66.50	
[09/26 15:02:27 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 15:02:34 visual_prompt]: Epoch 62 / 100: avg data time: 5.68e-02, avg batch time: 0.5053, average train loss: 0.4195
[09/26 15:02:35 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.1197
[09/26 15:02:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 67.50	
[09/26 15:02:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 15:02:42 visual_prompt]: Epoch 63 / 100: avg data time: 5.38e-02, avg batch time: 0.5026, average train loss: 0.4278
[09/26 15:02:44 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 3.1372
[09/26 15:02:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 68.50	
[09/26 15:02:44 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 15:02:50 visual_prompt]: Epoch 64 / 100: avg data time: 6.21e-02, avg batch time: 0.5102, average train loss: 0.3760
[09/26 15:02:52 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1693, average loss: 3.0838
[09/26 15:02:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 68.50	
[09/26 15:02:52 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 15:02:59 visual_prompt]: Epoch 65 / 100: avg data time: 6.19e-02, avg batch time: 0.5100, average train loss: 0.3388
[09/26 15:03:00 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 3.3000
[09/26 15:03:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 64.00	
[09/26 15:03:00 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 15:03:07 visual_prompt]: Epoch 66 / 100: avg data time: 5.17e-02, avg batch time: 0.5000, average train loss: 0.2920
[09/26 15:03:09 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1693, average loss: 3.2490
[09/26 15:03:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 15:03:09 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 15:03:16 visual_prompt]: Epoch 67 / 100: avg data time: 5.47e-02, avg batch time: 0.5033, average train loss: 0.2220
[09/26 15:03:17 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1688, average loss: 3.2009
[09/26 15:03:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 15:03:17 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 15:03:24 visual_prompt]: Epoch 68 / 100: avg data time: 4.74e-02, avg batch time: 0.4961, average train loss: 0.1696
[09/26 15:03:25 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1694, average loss: 3.4344
[09/26 15:03:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 64.50	
[09/26 15:03:25 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 15:03:32 visual_prompt]: Epoch 69 / 100: avg data time: 5.13e-02, avg batch time: 0.4996, average train loss: 0.1356
[09/26 15:03:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1694, average loss: 3.3895
[09/26 15:03:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 65.50	
[09/26 15:03:34 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 15:03:41 visual_prompt]: Epoch 70 / 100: avg data time: 4.72e-02, avg batch time: 0.4987, average train loss: 0.1166
[09/26 15:03:42 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1689, average loss: 3.3289
[09/26 15:03:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.00	
[09/26 15:03:42 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 15:03:49 visual_prompt]: Epoch 71 / 100: avg data time: 4.83e-02, avg batch time: 0.4992, average train loss: 0.1051
[09/26 15:03:50 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1689, average loss: 3.3950
[09/26 15:03:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.50	
[09/26 15:03:50 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 15:03:57 visual_prompt]: Epoch 72 / 100: avg data time: 5.71e-02, avg batch time: 0.5055, average train loss: 0.0851
[09/26 15:03:59 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1694, average loss: 3.4034
[09/26 15:03:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 64.00	
[09/26 15:03:59 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 15:04:06 visual_prompt]: Epoch 73 / 100: avg data time: 6.26e-02, avg batch time: 0.5107, average train loss: 0.0746
[09/26 15:04:07 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1693, average loss: 3.4005
[09/26 15:04:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 65.50	
[09/26 15:04:07 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 15:04:14 visual_prompt]: Epoch 74 / 100: avg data time: 6.21e-02, avg batch time: 0.5099, average train loss: 0.0640
[09/26 15:04:16 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.3426
[09/26 15:04:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 65.00	
[09/26 15:04:16 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 15:04:23 visual_prompt]: Epoch 75 / 100: avg data time: 5.89e-02, avg batch time: 0.5083, average train loss: 0.0596
[09/26 15:04:24 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 3.2933
[09/26 15:04:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 66.00	
[09/26 15:04:24 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 15:04:31 visual_prompt]: Epoch 76 / 100: avg data time: 5.87e-02, avg batch time: 0.5069, average train loss: 0.0552
[09/26 15:04:33 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1688, average loss: 3.3284
[09/26 15:04:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 66.00	
[09/26 15:04:33 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 15:04:40 visual_prompt]: Epoch 77 / 100: avg data time: 5.87e-02, avg batch time: 0.5078, average train loss: 0.0517
[09/26 15:04:41 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1693, average loss: 3.3205
[09/26 15:04:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 67.50	
[09/26 15:04:41 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 15:04:48 visual_prompt]: Epoch 78 / 100: avg data time: 6.03e-02, avg batch time: 0.5087, average train loss: 0.0504
[09/26 15:04:50 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 3.3203
[09/26 15:04:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 68.00	
[09/26 15:04:50 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 15:04:57 visual_prompt]: Epoch 79 / 100: avg data time: 6.43e-02, avg batch time: 0.5132, average train loss: 0.0491
[09/26 15:04:58 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1693, average loss: 3.3399
[09/26 15:04:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 68.50	
[09/26 15:04:58 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 15:05:05 visual_prompt]: Epoch 80 / 100: avg data time: 5.81e-02, avg batch time: 0.5061, average train loss: 0.0483
[09/26 15:05:07 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1691, average loss: 3.3417
[09/26 15:05:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 69.00	
[09/26 15:05:07 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 15:05:13 visual_prompt]: Epoch 81 / 100: avg data time: 4.36e-02, avg batch time: 0.4941, average train loss: 0.0471
[09/26 15:05:15 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1691, average loss: 3.3454
[09/26 15:05:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.50	top5: 68.00	
[09/26 15:05:15 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:05:22 visual_prompt]: Epoch 82 / 100: avg data time: 4.37e-02, avg batch time: 0.4935, average train loss: 0.0471
[09/26 15:05:23 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1690, average loss: 3.3343
[09/26 15:05:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 67.50	
[09/26 15:05:23 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:05:30 visual_prompt]: Epoch 83 / 100: avg data time: 4.49e-02, avg batch time: 0.4948, average train loss: 0.0462
[09/26 15:05:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.3177
[09/26 15:05:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 21.00	top5: 68.50	
[09/26 15:05:31 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:05:38 visual_prompt]: Epoch 84 / 100: avg data time: 5.40e-02, avg batch time: 0.5033, average train loss: 0.0465
[09/26 15:05:40 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 3.3152
[09/26 15:05:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:05:40 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:05:47 visual_prompt]: Epoch 85 / 100: avg data time: 5.18e-02, avg batch time: 0.5007, average train loss: 0.0463
[09/26 15:05:48 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 3.3331
[09/26 15:05:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.50	top5: 68.50	
[09/26 15:05:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:05:55 visual_prompt]: Epoch 86 / 100: avg data time: 5.74e-02, avg batch time: 0.5053, average train loss: 0.0456
[09/26 15:05:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 3.3198
[09/26 15:05:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 15:05:57 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:06:04 visual_prompt]: Epoch 87 / 100: avg data time: 6.05e-02, avg batch time: 0.5096, average train loss: 0.0449
[09/26 15:06:05 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1692, average loss: 3.3185
[09/26 15:06:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 68.00	
[09/26 15:06:05 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:06:12 visual_prompt]: Epoch 88 / 100: avg data time: 6.00e-02, avg batch time: 0.5091, average train loss: 0.0447
[09/26 15:06:14 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1694, average loss: 3.3174
[09/26 15:06:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 24.00	top5: 68.50	
[09/26 15:06:14 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:06:21 visual_prompt]: Epoch 89 / 100: avg data time: 5.86e-02, avg batch time: 0.5073, average train loss: 0.0447
[09/26 15:06:22 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 3.3293
[09/26 15:06:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 67.00	
[09/26 15:06:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:06:29 visual_prompt]: Epoch 90 / 100: avg data time: 5.26e-02, avg batch time: 0.5011, average train loss: 0.0449
[09/26 15:06:31 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1692, average loss: 3.3226
[09/26 15:06:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.00	
[09/26 15:06:31 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:06:37 visual_prompt]: Epoch 91 / 100: avg data time: 4.57e-02, avg batch time: 0.4965, average train loss: 0.0441
[09/26 15:06:39 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 3.3214
[09/26 15:06:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 69.00	
[09/26 15:06:39 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:06:46 visual_prompt]: Epoch 92 / 100: avg data time: 4.43e-02, avg batch time: 0.4941, average train loss: 0.0442
[09/26 15:06:47 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1691, average loss: 3.3224
[09/26 15:06:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 15:06:47 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:06:54 visual_prompt]: Epoch 93 / 100: avg data time: 4.40e-02, avg batch time: 0.4933, average train loss: 0.0444
[09/26 15:06:55 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1694, average loss: 3.3228
[09/26 15:06:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:06:55 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:07:02 visual_prompt]: Epoch 94 / 100: avg data time: 4.45e-02, avg batch time: 0.4941, average train loss: 0.0441
[09/26 15:07:04 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1694, average loss: 3.3230
[09/26 15:07:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 69.00	
[09/26 15:07:04 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:07:11 visual_prompt]: Epoch 95 / 100: avg data time: 5.71e-02, avg batch time: 0.5053, average train loss: 0.0441
[09/26 15:07:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 3.3239
[09/26 15:07:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 69.00	
[09/26 15:07:12 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:07:19 visual_prompt]: Epoch 96 / 100: avg data time: 4.50e-02, avg batch time: 0.4964, average train loss: 0.0436
[09/26 15:07:20 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1697, average loss: 3.3264
[09/26 15:07:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.50	top5: 68.50	
[09/26 15:07:20 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:07:27 visual_prompt]: Epoch 97 / 100: avg data time: 5.71e-02, avg batch time: 0.5052, average train loss: 0.0443
[09/26 15:07:29 visual_prompt]: Inference (val):avg data time: 4.43e-05, avg batch time: 0.1692, average loss: 3.3270
[09/26 15:07:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:07:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:07:36 visual_prompt]: Epoch 98 / 100: avg data time: 5.99e-02, avg batch time: 0.5082, average train loss: 0.0437
[09/26 15:07:37 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 3.3267
[09/26 15:07:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:07:37 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:07:44 visual_prompt]: Epoch 99 / 100: avg data time: 5.58e-02, avg batch time: 0.5040, average train loss: 0.0441
[09/26 15:07:46 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.1691, average loss: 3.3267
[09/26 15:07:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:07:46 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:07:53 visual_prompt]: Epoch 100 / 100: avg data time: 5.76e-02, avg batch time: 0.5060, average train loss: 0.0438
[09/26 15:07:54 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1692, average loss: 3.3265
[09/26 15:07:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 22.00	top5: 68.50	
[09/26 15:07:54 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:07:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:07:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:07:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:07:54 visual_prompt]: Training with config:
[09/26 15:07:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:07:54 visual_prompt]: Loading training data...
[09/26 15:07:54 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:07:55 visual_prompt]: Number of images: 800
[09/26 15:07:55 visual_prompt]: Number of classes: 18 / 18
[09/26 15:07:55 visual_prompt]: Loading validation data...
[09/26 15:07:55 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:07:56 visual_prompt]: Number of images: 200
[09/26 15:07:56 visual_prompt]: Number of classes: 18 / 18
[09/26 15:07:56 visual_prompt]: Constructing models...
[09/26 15:07:58 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 15:07:58 visual_prompt]: tuned percent:0.550
[09/26 15:07:58 visual_prompt]: Device used for model: 0
[09/26 15:07:58 visual_prompt]: Setting up Evaluator...
[09/26 15:07:58 visual_prompt]: Setting up Trainer...
[09/26 15:07:58 visual_prompt]: 	Setting up the optimizer...
[09/26 15:07:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:08:05 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e-02, avg batch time: 0.4985, average train loss: 3.2489
[09/26 15:08:07 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1684, average loss: 3.1895
[09/26 15:08:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 15:08:07 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 15:08:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:08:13 visual_prompt]: Epoch 2 / 100: avg data time: 5.45e-02, avg batch time: 0.5038, average train loss: 2.9965
[09/26 15:08:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1687, average loss: 2.9631
[09/26 15:08:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 25.50	
[09/26 15:08:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:08:22 visual_prompt]: Epoch 3 / 100: avg data time: 5.11e-02, avg batch time: 0.4989, average train loss: 2.9298
[09/26 15:08:23 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1687, average loss: 2.9154
[09/26 15:08:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 28.00	
[09/26 15:08:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 15:08:30 visual_prompt]: Epoch 4 / 100: avg data time: 5.68e-02, avg batch time: 0.5044, average train loss: 2.9111
[09/26 15:08:32 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1686, average loss: 2.9182
[09/26 15:08:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.00	
[09/26 15:08:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:08:38 visual_prompt]: Epoch 5 / 100: avg data time: 5.63e-02, avg batch time: 0.5040, average train loss: 2.8974
[09/26 15:08:40 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1684, average loss: 2.9412
[09/26 15:08:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 25.50	
[09/26 15:08:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 15:08:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.90e-02, avg batch time: 0.5063, average train loss: 2.8867
[09/26 15:08:48 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1687, average loss: 2.9061
[09/26 15:08:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 15:08:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 15:08:55 visual_prompt]: Epoch 7 / 100: avg data time: 6.30e-02, avg batch time: 0.5104, average train loss: 2.8958
[09/26 15:08:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 2.9099
[09/26 15:08:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 31.00	
[09/26 15:08:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 15:09:03 visual_prompt]: Epoch 8 / 100: avg data time: 4.57e-02, avg batch time: 0.4951, average train loss: 2.8861
[09/26 15:09:05 visual_prompt]: Inference (val):avg data time: 5.23e-05, avg batch time: 0.1720, average loss: 2.9123
[09/26 15:09:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.00	
[09/26 15:09:05 visual_prompt]: Best epoch 8: best metric: 0.080
[09/26 15:09:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 15:09:12 visual_prompt]: Epoch 9 / 100: avg data time: 5.90e-02, avg batch time: 0.5088, average train loss: 2.8944
[09/26 15:09:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1686, average loss: 2.8978
[09/26 15:09:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.00	
[09/26 15:09:13 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 15:09:20 visual_prompt]: Epoch 10 / 100: avg data time: 5.46e-02, avg batch time: 0.5038, average train loss: 2.8612
[09/26 15:09:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1689, average loss: 2.9197
[09/26 15:09:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.50	
[09/26 15:09:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 15:09:29 visual_prompt]: Epoch 11 / 100: avg data time: 6.16e-02, avg batch time: 0.5096, average train loss: 2.8925
[09/26 15:09:30 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 2.9381
[09/26 15:09:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 26.50	
[09/26 15:09:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 15:09:37 visual_prompt]: Epoch 12 / 100: avg data time: 5.72e-02, avg batch time: 0.5047, average train loss: 2.8556
[09/26 15:09:39 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1688, average loss: 2.8656
[09/26 15:09:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.50	
[09/26 15:09:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 15:09:46 visual_prompt]: Epoch 13 / 100: avg data time: 5.94e-02, avg batch time: 0.5089, average train loss: 2.8340
[09/26 15:09:47 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1689, average loss: 2.8383
[09/26 15:09:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 39.00	
[09/26 15:09:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 15:09:54 visual_prompt]: Epoch 14 / 100: avg data time: 6.09e-02, avg batch time: 0.5097, average train loss: 2.7960
[09/26 15:09:56 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1688, average loss: 2.8668
[09/26 15:09:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 36.00	
[09/26 15:09:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 15:10:02 visual_prompt]: Epoch 15 / 100: avg data time: 6.10e-02, avg batch time: 0.5097, average train loss: 2.7574
[09/26 15:10:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1690, average loss: 2.8178
[09/26 15:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 40.50	
[09/26 15:10:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 15:10:11 visual_prompt]: Epoch 16 / 100: avg data time: 5.69e-02, avg batch time: 0.5059, average train loss: 2.6812
[09/26 15:10:12 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 2.8818
[09/26 15:10:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.50	
[09/26 15:10:12 visual_prompt]: Best epoch 16: best metric: 0.105
[09/26 15:10:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 15:10:19 visual_prompt]: Epoch 17 / 100: avg data time: 6.52e-02, avg batch time: 0.5129, average train loss: 2.6267
[09/26 15:10:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 2.8125
[09/26 15:10:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 41.50	
[09/26 15:10:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 15:10:28 visual_prompt]: Epoch 18 / 100: avg data time: 6.05e-02, avg batch time: 0.5090, average train loss: 2.5555
[09/26 15:10:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 2.8772
[09/26 15:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 39.00	
[09/26 15:10:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 15:10:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.61e-02, avg batch time: 0.5048, average train loss: 2.5576
[09/26 15:10:38 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1693, average loss: 2.7080
[09/26 15:10:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 15:10:38 visual_prompt]: Best epoch 19: best metric: 0.135
[09/26 15:10:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 15:10:45 visual_prompt]: Epoch 20 / 100: avg data time: 6.46e-02, avg batch time: 0.5133, average train loss: 2.4523
[09/26 15:10:46 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1691, average loss: 2.8865
[09/26 15:10:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 45.50	
[09/26 15:10:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 15:10:53 visual_prompt]: Epoch 21 / 100: avg data time: 5.89e-02, avg batch time: 0.5086, average train loss: 2.4268
[09/26 15:10:55 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1689, average loss: 2.8099
[09/26 15:10:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 47.50	
[09/26 15:10:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 15:11:01 visual_prompt]: Epoch 22 / 100: avg data time: 5.20e-02, avg batch time: 0.5005, average train loss: 2.2807
[09/26 15:11:03 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1692, average loss: 2.9301
[09/26 15:11:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 50.00	
[09/26 15:11:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 15:11:10 visual_prompt]: Epoch 23 / 100: avg data time: 6.10e-02, avg batch time: 0.5093, average train loss: 2.1785
[09/26 15:11:11 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1689, average loss: 2.8767
[09/26 15:11:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.00	
[09/26 15:11:11 visual_prompt]: Best epoch 23: best metric: 0.160
[09/26 15:11:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 15:11:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.77e-02, avg batch time: 0.4976, average train loss: 2.0691
[09/26 15:11:20 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 3.0368
[09/26 15:11:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.50	
[09/26 15:11:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 15:11:27 visual_prompt]: Epoch 25 / 100: avg data time: 5.52e-02, avg batch time: 0.5045, average train loss: 2.0896
[09/26 15:11:28 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1692, average loss: 2.8303
[09/26 15:11:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 55.50	
[09/26 15:11:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 15:11:35 visual_prompt]: Epoch 26 / 100: avg data time: 4.82e-02, avg batch time: 0.4982, average train loss: 1.8263
[09/26 15:11:36 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.1083
[09/26 15:11:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:11:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 15:11:43 visual_prompt]: Epoch 27 / 100: avg data time: 4.59e-02, avg batch time: 0.4949, average train loss: 1.6792
[09/26 15:11:45 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1693, average loss: 3.1617
[09/26 15:11:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 55.50	
[09/26 15:11:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 15:11:52 visual_prompt]: Epoch 28 / 100: avg data time: 5.51e-02, avg batch time: 0.5032, average train loss: 1.4673
[09/26 15:11:53 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1689, average loss: 3.2101
[09/26 15:11:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 59.50	
[09/26 15:11:53 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 15:12:00 visual_prompt]: Epoch 29 / 100: avg data time: 4.72e-02, avg batch time: 0.4959, average train loss: 1.3251
[09/26 15:12:01 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1691, average loss: 3.6557
[09/26 15:12:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 53.50	
[09/26 15:12:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 15:12:08 visual_prompt]: Epoch 30 / 100: avg data time: 5.74e-02, avg batch time: 0.5061, average train loss: 1.1742
[09/26 15:12:10 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1692, average loss: 3.6201
[09/26 15:12:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 57.00	
[09/26 15:12:10 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 15:12:17 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e-02, avg batch time: 0.5051, average train loss: 1.0743
[09/26 15:12:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 3.9714
[09/26 15:12:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 60.00	
[09/26 15:12:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 15:12:25 visual_prompt]: Epoch 32 / 100: avg data time: 6.00e-02, avg batch time: 0.5097, average train loss: 1.0277
[09/26 15:12:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 3.7869
[09/26 15:12:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 57.50	
[09/26 15:12:27 visual_prompt]: Best epoch 32: best metric: 0.180
[09/26 15:12:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 15:12:34 visual_prompt]: Epoch 33 / 100: avg data time: 5.94e-02, avg batch time: 0.5086, average train loss: 0.8100
[09/26 15:12:35 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1692, average loss: 3.8207
[09/26 15:12:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 61.50	
[09/26 15:12:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 15:12:42 visual_prompt]: Epoch 34 / 100: avg data time: 5.80e-02, avg batch time: 0.5060, average train loss: 0.7052
[09/26 15:12:44 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1691, average loss: 3.9692
[09/26 15:12:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.00	
[09/26 15:12:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 15:12:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.93e-02, avg batch time: 0.5073, average train loss: 0.5402
[09/26 15:12:52 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1688, average loss: 4.0684
[09/26 15:12:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 15:12:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 15:12:59 visual_prompt]: Epoch 36 / 100: avg data time: 5.45e-02, avg batch time: 0.5032, average train loss: 0.4902
[09/26 15:13:00 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1692, average loss: 4.1682
[09/26 15:13:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.50	
[09/26 15:13:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 15:13:07 visual_prompt]: Epoch 37 / 100: avg data time: 4.35e-02, avg batch time: 0.4940, average train loss: 0.4096
[09/26 15:13:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1690, average loss: 4.2787
[09/26 15:13:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 62.00	
[09/26 15:13:09 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 15:13:16 visual_prompt]: Epoch 38 / 100: avg data time: 4.61e-02, avg batch time: 0.4955, average train loss: 0.3120
[09/26 15:13:17 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1693, average loss: 4.0843
[09/26 15:13:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 63.50	
[09/26 15:13:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 15:13:24 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e-02, avg batch time: 0.5057, average train loss: 0.2395
[09/26 15:13:25 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1692, average loss: 4.3047
[09/26 15:13:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 59.00	
[09/26 15:13:25 visual_prompt]: Best epoch 39: best metric: 0.185
[09/26 15:13:25 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 15:13:32 visual_prompt]: Epoch 40 / 100: avg data time: 4.66e-02, avg batch time: 0.4953, average train loss: 0.1635
[09/26 15:13:34 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1688, average loss: 4.2476
[09/26 15:13:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.50	
[09/26 15:13:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 15:13:40 visual_prompt]: Epoch 41 / 100: avg data time: 5.10e-02, avg batch time: 0.5003, average train loss: 0.1261
[09/26 15:13:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1693, average loss: 4.2370
[09/26 15:13:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 62.00	
[09/26 15:13:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 15:13:49 visual_prompt]: Epoch 42 / 100: avg data time: 4.62e-02, avg batch time: 0.4967, average train loss: 0.1189
[09/26 15:13:50 visual_prompt]: Inference (val):avg data time: 5.18e-05, avg batch time: 0.1694, average loss: 4.2843
[09/26 15:13:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 63.50	
[09/26 15:13:50 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 15:13:57 visual_prompt]: Epoch 43 / 100: avg data time: 6.10e-02, avg batch time: 0.5104, average train loss: 0.0913
[09/26 15:13:59 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1694, average loss: 4.4645
[09/26 15:13:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 60.50	
[09/26 15:13:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 15:14:06 visual_prompt]: Epoch 44 / 100: avg data time: 4.22e-02, avg batch time: 0.4952, average train loss: 0.0715
[09/26 15:14:07 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1689, average loss: 4.3582
[09/26 15:14:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 60.00	
[09/26 15:14:07 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 15:14:14 visual_prompt]: Epoch 45 / 100: avg data time: 5.34e-02, avg batch time: 0.5020, average train loss: 0.0627
[09/26 15:14:15 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 4.3296
[09/26 15:14:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.50	
[09/26 15:14:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 15:14:22 visual_prompt]: Epoch 46 / 100: avg data time: 5.49e-02, avg batch time: 0.5045, average train loss: 0.0521
[09/26 15:14:24 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 4.4558
[09/26 15:14:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 61.50	
[09/26 15:14:24 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 15:14:31 visual_prompt]: Epoch 47 / 100: avg data time: 5.66e-02, avg batch time: 0.5070, average train loss: 0.0389
[09/26 15:14:32 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 4.4221
[09/26 15:14:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 62.00	
[09/26 15:14:32 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 15:14:39 visual_prompt]: Epoch 48 / 100: avg data time: 4.96e-02, avg batch time: 0.4996, average train loss: 0.0275
[09/26 15:14:41 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1693, average loss: 4.4415
[09/26 15:14:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.00	
[09/26 15:14:41 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 15:14:48 visual_prompt]: Epoch 49 / 100: avg data time: 5.07e-02, avg batch time: 0.5007, average train loss: 0.0256
[09/26 15:14:49 visual_prompt]: Inference (val):avg data time: 4.45e-05, avg batch time: 0.1690, average loss: 4.4328
[09/26 15:14:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 60.50	
[09/26 15:14:49 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 15:14:56 visual_prompt]: Epoch 50 / 100: avg data time: 4.37e-02, avg batch time: 0.4926, average train loss: 0.0218
[09/26 15:14:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 4.4723
[09/26 15:14:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 62.00	
[09/26 15:14:57 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 15:15:04 visual_prompt]: Epoch 51 / 100: avg data time: 5.31e-02, avg batch time: 0.5016, average train loss: 0.0205
[09/26 15:15:06 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1691, average loss: 4.4678
[09/26 15:15:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 62.00	
[09/26 15:15:06 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 15:15:13 visual_prompt]: Epoch 52 / 100: avg data time: 4.19e-02, avg batch time: 0.4910, average train loss: 0.0175
[09/26 15:15:14 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 4.4586
[09/26 15:15:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.00	
[09/26 15:15:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 15:15:21 visual_prompt]: Epoch 53 / 100: avg data time: 5.64e-02, avg batch time: 0.5055, average train loss: 0.0165
[09/26 15:15:22 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1698, average loss: 4.5044
[09/26 15:15:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 61.50	
[09/26 15:15:22 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 15:15:29 visual_prompt]: Epoch 54 / 100: avg data time: 4.82e-02, avg batch time: 0.4971, average train loss: 0.0160
[09/26 15:15:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 4.4926
[09/26 15:15:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.00	
[09/26 15:15:31 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 15:15:38 visual_prompt]: Epoch 55 / 100: avg data time: 6.08e-02, avg batch time: 0.5109, average train loss: 0.0152
[09/26 15:15:39 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1692, average loss: 4.4526
[09/26 15:15:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 61.00	
[09/26 15:15:39 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 15:15:46 visual_prompt]: Epoch 56 / 100: avg data time: 4.43e-02, avg batch time: 0.4941, average train loss: 0.0136
[09/26 15:15:47 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 4.4740
[09/26 15:15:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 63.00	
[09/26 15:15:47 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 15:15:54 visual_prompt]: Epoch 57 / 100: avg data time: 4.39e-02, avg batch time: 0.4938, average train loss: 0.0125
[09/26 15:15:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 4.4876
[09/26 15:15:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.50	
[09/26 15:15:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 15:16:02 visual_prompt]: Epoch 58 / 100: avg data time: 5.62e-02, avg batch time: 0.5050, average train loss: 0.0136
[09/26 15:16:04 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 4.4878
[09/26 15:16:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.00	
[09/26 15:16:04 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 15:16:11 visual_prompt]: Epoch 59 / 100: avg data time: 4.73e-02, avg batch time: 0.4974, average train loss: 0.0153
[09/26 15:16:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 4.5460
[09/26 15:16:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 62.00	
[09/26 15:16:12 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 15:16:19 visual_prompt]: Epoch 60 / 100: avg data time: 4.26e-02, avg batch time: 0.4915, average train loss: 0.0165
[09/26 15:16:20 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 4.4335
[09/26 15:16:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 60.00	
[09/26 15:16:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 15:16:27 visual_prompt]: Epoch 61 / 100: avg data time: 5.59e-02, avg batch time: 0.5055, average train loss: 0.0130
[09/26 15:16:29 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1690, average loss: 4.4332
[09/26 15:16:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 61.00	
[09/26 15:16:29 visual_prompt]: Best epoch 61: best metric: 0.195
[09/26 15:16:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 15:16:36 visual_prompt]: Epoch 62 / 100: avg data time: 5.69e-02, avg batch time: 0.5065, average train loss: 0.0128
[09/26 15:16:37 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1694, average loss: 4.4644
[09/26 15:16:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 61.50	
[09/26 15:16:37 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 15:16:44 visual_prompt]: Epoch 63 / 100: avg data time: 5.69e-02, avg batch time: 0.5074, average train loss: 0.0122
[09/26 15:16:46 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 4.4465
[09/26 15:16:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.50	top5: 60.50	
[09/26 15:16:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 15:16:53 visual_prompt]: Epoch 64 / 100: avg data time: 5.14e-02, avg batch time: 0.5006, average train loss: 0.0121
[09/26 15:16:54 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1689, average loss: 4.4579
[09/26 15:16:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 19.00	top5: 61.50	
[09/26 15:16:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 15:17:01 visual_prompt]: Epoch 65 / 100: avg data time: 4.35e-02, avg batch time: 0.4937, average train loss: 0.0107
[09/26 15:17:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 4.4743
[09/26 15:17:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 60.00	
[09/26 15:17:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 15:17:09 visual_prompt]: Epoch 66 / 100: avg data time: 4.77e-02, avg batch time: 0.4989, average train loss: 0.0107
[09/26 15:17:11 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1688, average loss: 4.4555
[09/26 15:17:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.50	
[09/26 15:17:11 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 15:17:17 visual_prompt]: Epoch 67 / 100: avg data time: 4.19e-02, avg batch time: 0.4917, average train loss: 0.0112
[09/26 15:17:19 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 4.4341
[09/26 15:17:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.50	
[09/26 15:17:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 15:17:26 visual_prompt]: Epoch 68 / 100: avg data time: 5.43e-02, avg batch time: 0.5029, average train loss: 0.0106
[09/26 15:17:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1696, average loss: 4.4389
[09/26 15:17:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.00	
[09/26 15:17:27 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 15:17:34 visual_prompt]: Epoch 69 / 100: avg data time: 5.58e-02, avg batch time: 0.5050, average train loss: 0.0108
[09/26 15:17:36 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 4.4249
[09/26 15:17:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.00	
[09/26 15:17:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 15:17:43 visual_prompt]: Epoch 70 / 100: avg data time: 5.72e-02, avg batch time: 0.5056, average train loss: 0.0099
[09/26 15:17:44 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1693, average loss: 4.4465
[09/26 15:17:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 60.50	
[09/26 15:17:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 15:17:51 visual_prompt]: Epoch 71 / 100: avg data time: 5.76e-02, avg batch time: 0.5067, average train loss: 0.0111
[09/26 15:17:52 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 4.4636
[09/26 15:17:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 60.00	
[09/26 15:17:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 15:17:59 visual_prompt]: Epoch 72 / 100: avg data time: 6.37e-02, avg batch time: 0.5120, average train loss: 0.0099
[09/26 15:18:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 4.4437
[09/26 15:18:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.00	
[09/26 15:18:01 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 15:18:08 visual_prompt]: Epoch 73 / 100: avg data time: 5.55e-02, avg batch time: 0.5044, average train loss: 0.0098
[09/26 15:18:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 4.4393
[09/26 15:18:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 61.00	
[09/26 15:18:09 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 15:18:16 visual_prompt]: Epoch 74 / 100: avg data time: 5.63e-02, avg batch time: 0.5053, average train loss: 0.0097
[09/26 15:18:18 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 4.4336
[09/26 15:18:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.00	
[09/26 15:18:18 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 15:18:25 visual_prompt]: Epoch 75 / 100: avg data time: 4.85e-02, avg batch time: 0.5001, average train loss: 0.0095
[09/26 15:18:26 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1689, average loss: 4.4455
[09/26 15:18:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.00	
[09/26 15:18:26 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 15:18:33 visual_prompt]: Epoch 76 / 100: avg data time: 6.18e-02, avg batch time: 0.5101, average train loss: 0.0095
[09/26 15:18:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 4.4530
[09/26 15:18:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:18:35 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 15:18:41 visual_prompt]: Epoch 77 / 100: avg data time: 4.97e-02, avg batch time: 0.5000, average train loss: 0.0108
[09/26 15:18:43 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1689, average loss: 4.4516
[09/26 15:18:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:18:43 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 15:18:50 visual_prompt]: Epoch 78 / 100: avg data time: 5.42e-02, avg batch time: 0.5041, average train loss: 0.0095
[09/26 15:18:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1690, average loss: 4.4563
[09/26 15:18:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.50	
[09/26 15:18:51 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 15:18:58 visual_prompt]: Epoch 79 / 100: avg data time: 6.12e-02, avg batch time: 0.5104, average train loss: 0.0092
[09/26 15:19:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 4.4468
[09/26 15:19:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 61.00	
[09/26 15:19:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 15:19:07 visual_prompt]: Epoch 80 / 100: avg data time: 6.12e-02, avg batch time: 0.5105, average train loss: 0.0101
[09/26 15:19:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 4.4426
[09/26 15:19:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 60.50	
[09/26 15:19:08 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 15:19:15 visual_prompt]: Epoch 81 / 100: avg data time: 5.91e-02, avg batch time: 0.5095, average train loss: 0.0094
[09/26 15:19:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1693, average loss: 4.4442
[09/26 15:19:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.50	
[09/26 15:19:17 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:19:24 visual_prompt]: Epoch 82 / 100: avg data time: 5.35e-02, avg batch time: 0.5016, average train loss: 0.0099
[09/26 15:19:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1692, average loss: 4.4473
[09/26 15:19:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.50	
[09/26 15:19:25 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:19:32 visual_prompt]: Epoch 83 / 100: avg data time: 5.86e-02, avg batch time: 0.5067, average train loss: 0.0096
[09/26 15:19:34 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1690, average loss: 4.4557
[09/26 15:19:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.50	
[09/26 15:19:34 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:19:40 visual_prompt]: Epoch 84 / 100: avg data time: 5.82e-02, avg batch time: 0.5064, average train loss: 0.0095
[09/26 15:19:42 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 4.4620
[09/26 15:19:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 61.00	
[09/26 15:19:42 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:19:49 visual_prompt]: Epoch 85 / 100: avg data time: 5.94e-02, avg batch time: 0.5082, average train loss: 0.0096
[09/26 15:19:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1693, average loss: 4.4616
[09/26 15:19:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 60.50	
[09/26 15:19:50 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:19:57 visual_prompt]: Epoch 86 / 100: avg data time: 4.58e-02, avg batch time: 0.4965, average train loss: 0.0091
[09/26 15:19:59 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1691, average loss: 4.4546
[09/26 15:19:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:19:59 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:20:06 visual_prompt]: Epoch 87 / 100: avg data time: 5.85e-02, avg batch time: 0.5081, average train loss: 0.0098
[09/26 15:20:07 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1691, average loss: 4.4540
[09/26 15:20:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:07 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:20:14 visual_prompt]: Epoch 88 / 100: avg data time: 5.67e-02, avg batch time: 0.5056, average train loss: 0.0092
[09/26 15:20:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 4.4522
[09/26 15:20:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:20:22 visual_prompt]: Epoch 89 / 100: avg data time: 4.73e-02, avg batch time: 0.4966, average train loss: 0.0095
[09/26 15:20:24 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1690, average loss: 4.4493
[09/26 15:20:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:24 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:20:31 visual_prompt]: Epoch 90 / 100: avg data time: 6.46e-02, avg batch time: 0.5124, average train loss: 0.0089
[09/26 15:20:33 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1690, average loss: 4.4449
[09/26 15:20:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:20:39 visual_prompt]: Epoch 91 / 100: avg data time: 5.47e-02, avg batch time: 0.5037, average train loss: 0.0094
[09/26 15:20:41 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.1688, average loss: 4.4411
[09/26 15:20:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:20:48 visual_prompt]: Epoch 92 / 100: avg data time: 5.64e-02, avg batch time: 0.5045, average train loss: 0.0093
[09/26 15:20:49 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1691, average loss: 4.4391
[09/26 15:20:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:49 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:20:56 visual_prompt]: Epoch 93 / 100: avg data time: 5.84e-02, avg batch time: 0.5084, average train loss: 0.0093
[09/26 15:20:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1693, average loss: 4.4396
[09/26 15:20:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:20:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:21:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.87e-02, avg batch time: 0.5077, average train loss: 0.0094
[09/26 15:21:06 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1693, average loss: 4.4402
[09/26 15:21:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:06 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:21:13 visual_prompt]: Epoch 95 / 100: avg data time: 5.77e-02, avg batch time: 0.5065, average train loss: 0.0095
[09/26 15:21:15 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1688, average loss: 4.4404
[09/26 15:21:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:21:22 visual_prompt]: Epoch 96 / 100: avg data time: 6.42e-02, avg batch time: 0.5139, average train loss: 0.0089
[09/26 15:21:23 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1691, average loss: 4.4403
[09/26 15:21:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:23 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:21:30 visual_prompt]: Epoch 97 / 100: avg data time: 5.69e-02, avg batch time: 0.5058, average train loss: 0.0090
[09/26 15:21:32 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1691, average loss: 4.4403
[09/26 15:21:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:21:39 visual_prompt]: Epoch 98 / 100: avg data time: 6.32e-02, avg batch time: 0.5113, average train loss: 0.0093
[09/26 15:21:40 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 4.4403
[09/26 15:21:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:21:47 visual_prompt]: Epoch 99 / 100: avg data time: 5.86e-02, avg batch time: 0.5086, average train loss: 0.0095
[09/26 15:21:49 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1688, average loss: 4.4403
[09/26 15:21:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:49 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:21:55 visual_prompt]: Epoch 100 / 100: avg data time: 6.23e-02, avg batch time: 0.5103, average train loss: 0.0092
[09/26 15:21:57 visual_prompt]: Inference (val):avg data time: 4.14e-05, avg batch time: 0.1691, average loss: 4.4403
[09/26 15:21:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 60.50	
[09/26 15:21:57 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:21:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:21:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:21:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:21:57 visual_prompt]: Training with config:
[09/26 15:21:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:21:57 visual_prompt]: Loading training data...
[09/26 15:21:57 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:21:58 visual_prompt]: Number of images: 800
[09/26 15:21:58 visual_prompt]: Number of classes: 18 / 18
[09/26 15:21:58 visual_prompt]: Loading validation data...
[09/26 15:21:58 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:21:59 visual_prompt]: Number of images: 200
[09/26 15:21:59 visual_prompt]: Number of classes: 18 / 18
[09/26 15:21:59 visual_prompt]: Constructing models...
[09/26 15:22:01 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 15:22:01 visual_prompt]: tuned percent:0.550
[09/26 15:22:01 visual_prompt]: Device used for model: 0
[09/26 15:22:01 visual_prompt]: Setting up Evaluator...
[09/26 15:22:01 visual_prompt]: Setting up Trainer...
[09/26 15:22:01 visual_prompt]: 	Setting up the optimizer...
[09/26 15:22:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:22:08 visual_prompt]: Epoch 1 / 100: avg data time: 5.35e-02, avg batch time: 0.5012, average train loss: 3.2562
[09/26 15:22:10 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1686, average loss: 3.1895
[09/26 15:22:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 15:22:10 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 15:22:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:22:16 visual_prompt]: Epoch 2 / 100: avg data time: 5.23e-02, avg batch time: 0.4993, average train loss: 2.9668
[09/26 15:22:18 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1685, average loss: 2.9692
[09/26 15:22:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 24.00	
[09/26 15:22:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:22:25 visual_prompt]: Epoch 3 / 100: avg data time: 4.32e-02, avg batch time: 0.4931, average train loss: 2.9177
[09/26 15:22:26 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1686, average loss: 2.9353
[09/26 15:22:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 29.50	
[09/26 15:22:26 visual_prompt]: Best epoch 3: best metric: 0.075
[09/26 15:22:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 15:22:33 visual_prompt]: Epoch 4 / 100: avg data time: 4.38e-02, avg batch time: 0.4940, average train loss: 2.9255
[09/26 15:22:34 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 2.9305
[09/26 15:22:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 26.00	
[09/26 15:22:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:22:41 visual_prompt]: Epoch 5 / 100: avg data time: 4.52e-02, avg batch time: 0.4946, average train loss: 2.9261
[09/26 15:22:43 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1690, average loss: 2.9204
[09/26 15:22:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 15:22:43 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 15:22:50 visual_prompt]: Epoch 6 / 100: avg data time: 5.43e-02, avg batch time: 0.5029, average train loss: 2.9211
[09/26 15:22:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 2.9181
[09/26 15:22:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 27.50	
[09/26 15:22:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 15:22:58 visual_prompt]: Epoch 7 / 100: avg data time: 4.51e-02, avg batch time: 0.4945, average train loss: 2.8974
[09/26 15:23:00 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1693, average loss: 2.9930
[09/26 15:23:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 24.00	
[09/26 15:23:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 15:23:06 visual_prompt]: Epoch 8 / 100: avg data time: 5.58e-02, avg batch time: 0.5035, average train loss: 2.8963
[09/26 15:23:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1696, average loss: 2.9254
[09/26 15:23:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.50	
[09/26 15:23:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 15:23:15 visual_prompt]: Epoch 9 / 100: avg data time: 6.47e-02, avg batch time: 0.5133, average train loss: 2.8790
[09/26 15:23:16 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1688, average loss: 2.9255
[09/26 15:23:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.00	
[09/26 15:23:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 15:23:23 visual_prompt]: Epoch 10 / 100: avg data time: 4.32e-02, avg batch time: 0.4928, average train loss: 2.8894
[09/26 15:23:25 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1687, average loss: 2.9268
[09/26 15:23:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.00	
[09/26 15:23:25 visual_prompt]: Best epoch 10: best metric: 0.080
[09/26 15:23:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 15:23:31 visual_prompt]: Epoch 11 / 100: avg data time: 4.38e-02, avg batch time: 0.4937, average train loss: 2.8933
[09/26 15:23:33 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1685, average loss: 2.9249
[09/26 15:23:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 28.00	
[09/26 15:23:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 15:23:40 visual_prompt]: Epoch 12 / 100: avg data time: 5.15e-02, avg batch time: 0.5002, average train loss: 2.8934
[09/26 15:23:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 2.9446
[09/26 15:23:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 27.50	
[09/26 15:23:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 15:23:48 visual_prompt]: Epoch 13 / 100: avg data time: 5.83e-02, avg batch time: 0.5073, average train loss: 2.8544
[09/26 15:23:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 3.1717
[09/26 15:23:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 25.00	
[09/26 15:23:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 15:23:56 visual_prompt]: Epoch 14 / 100: avg data time: 4.33e-02, avg batch time: 0.4927, average train loss: 2.8752
[09/26 15:23:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 2.9386
[09/26 15:23:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 15:23:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 15:24:05 visual_prompt]: Epoch 15 / 100: avg data time: 4.81e-02, avg batch time: 0.4980, average train loss: 2.8560
[09/26 15:24:06 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1688, average loss: 2.9630
[09/26 15:24:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 15:24:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 15:24:13 visual_prompt]: Epoch 16 / 100: avg data time: 4.85e-02, avg batch time: 0.4973, average train loss: 2.8766
[09/26 15:24:15 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 2.8797
[09/26 15:24:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 35.00	
[09/26 15:24:15 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 15:24:21 visual_prompt]: Epoch 17 / 100: avg data time: 4.46e-02, avg batch time: 0.4926, average train loss: 2.8425
[09/26 15:24:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1692, average loss: 2.8527
[09/26 15:24:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 41.00	
[09/26 15:24:23 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 15:24:30 visual_prompt]: Epoch 18 / 100: avg data time: 5.20e-02, avg batch time: 0.5013, average train loss: 2.8186
[09/26 15:24:31 visual_prompt]: Inference (val):avg data time: 5.32e-05, avg batch time: 0.1691, average loss: 2.8499
[09/26 15:24:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 39.00	
[09/26 15:24:31 visual_prompt]: Best epoch 18: best metric: 0.095
[09/26 15:24:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 15:24:38 visual_prompt]: Epoch 19 / 100: avg data time: 5.41e-02, avg batch time: 0.5035, average train loss: 2.7583
[09/26 15:24:40 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1695, average loss: 2.8758
[09/26 15:24:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 37.50	
[09/26 15:24:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 15:24:46 visual_prompt]: Epoch 20 / 100: avg data time: 5.45e-02, avg batch time: 0.5041, average train loss: 2.6804
[09/26 15:24:48 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1689, average loss: 2.9021
[09/26 15:24:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 41.00	
[09/26 15:24:48 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 15:24:55 visual_prompt]: Epoch 21 / 100: avg data time: 5.93e-02, avg batch time: 0.5085, average train loss: 2.6110
[09/26 15:24:56 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1695, average loss: 2.8981
[09/26 15:24:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.50	
[09/26 15:24:56 visual_prompt]: Best epoch 21: best metric: 0.105
[09/26 15:24:56 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 15:25:03 visual_prompt]: Epoch 22 / 100: avg data time: 6.05e-02, avg batch time: 0.5099, average train loss: 2.5283
[09/26 15:25:05 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 2.8828
[09/26 15:25:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 45.50	
[09/26 15:25:05 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 15:25:12 visual_prompt]: Epoch 23 / 100: avg data time: 6.07e-02, avg batch time: 0.5098, average train loss: 2.4979
[09/26 15:25:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1689, average loss: 2.8853
[09/26 15:25:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 47.50	
[09/26 15:25:13 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 15:25:20 visual_prompt]: Epoch 24 / 100: avg data time: 5.31e-02, avg batch time: 0.5033, average train loss: 2.3872
[09/26 15:25:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1693, average loss: 3.0376
[09/26 15:25:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 42.50	
[09/26 15:25:22 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 15:25:29 visual_prompt]: Epoch 25 / 100: avg data time: 5.92e-02, avg batch time: 0.5076, average train loss: 2.2567
[09/26 15:25:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 3.1791
[09/26 15:25:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.50	
[09/26 15:25:30 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 15:25:37 visual_prompt]: Epoch 26 / 100: avg data time: 4.52e-02, avg batch time: 0.4986, average train loss: 2.0885
[09/26 15:25:38 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 3.2626
[09/26 15:25:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 41.50	
[09/26 15:25:38 visual_prompt]: Best epoch 26: best metric: 0.120
[09/26 15:25:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 15:25:45 visual_prompt]: Epoch 27 / 100: avg data time: 6.21e-02, avg batch time: 0.5116, average train loss: 2.1384
[09/26 15:25:47 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 3.3146
[09/26 15:25:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 47.00	
[09/26 15:25:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 15:25:54 visual_prompt]: Epoch 28 / 100: avg data time: 5.80e-02, avg batch time: 0.5078, average train loss: 1.9999
[09/26 15:25:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1688, average loss: 3.0759
[09/26 15:25:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 49.50	
[09/26 15:25:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 15:26:02 visual_prompt]: Epoch 29 / 100: avg data time: 4.58e-02, avg batch time: 0.4950, average train loss: 1.9251
[09/26 15:26:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1689, average loss: 3.3494
[09/26 15:26:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.00	
[09/26 15:26:04 visual_prompt]: Best epoch 29: best metric: 0.135
[09/26 15:26:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 15:26:11 visual_prompt]: Epoch 30 / 100: avg data time: 4.90e-02, avg batch time: 0.4988, average train loss: 1.6262
[09/26 15:26:12 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1691, average loss: 3.9782
[09/26 15:26:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 47.50	
[09/26 15:26:12 visual_prompt]: Best epoch 30: best metric: 0.145
[09/26 15:26:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 15:26:19 visual_prompt]: Epoch 31 / 100: avg data time: 4.53e-02, avg batch time: 0.4973, average train loss: 1.4984
[09/26 15:26:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 4.0550
[09/26 15:26:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 46.50	
[09/26 15:26:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 15:26:27 visual_prompt]: Epoch 32 / 100: avg data time: 5.80e-02, avg batch time: 0.5068, average train loss: 1.3834
[09/26 15:26:29 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1689, average loss: 3.7175
[09/26 15:26:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 20.00	top5: 47.00	
[09/26 15:26:29 visual_prompt]: Best epoch 32: best metric: 0.200
[09/26 15:26:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 15:26:36 visual_prompt]: Epoch 33 / 100: avg data time: 4.87e-02, avg batch time: 0.4988, average train loss: 1.2826
[09/26 15:26:37 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1688, average loss: 4.3011
[09/26 15:26:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 49.00	
[09/26 15:26:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 15:26:44 visual_prompt]: Epoch 34 / 100: avg data time: 6.01e-02, avg batch time: 0.5092, average train loss: 1.1512
[09/26 15:26:46 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1693, average loss: 3.9480
[09/26 15:26:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:26:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 15:26:53 visual_prompt]: Epoch 35 / 100: avg data time: 6.47e-02, avg batch time: 0.5138, average train loss: 0.9873
[09/26 15:26:54 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1691, average loss: 4.2979
[09/26 15:26:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.50	
[09/26 15:26:54 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 15:27:01 visual_prompt]: Epoch 36 / 100: avg data time: 6.39e-02, avg batch time: 0.5119, average train loss: 0.7418
[09/26 15:27:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1692, average loss: 4.4766
[09/26 15:27:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 15:27:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 15:27:10 visual_prompt]: Epoch 37 / 100: avg data time: 5.64e-02, avg batch time: 0.5049, average train loss: 0.6120
[09/26 15:27:11 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1694, average loss: 4.9255
[09/26 15:27:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 55.00	
[09/26 15:27:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 15:27:18 visual_prompt]: Epoch 38 / 100: avg data time: 6.16e-02, avg batch time: 0.5099, average train loss: 0.5515
[09/26 15:27:20 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1690, average loss: 4.8354
[09/26 15:27:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.00	
[09/26 15:27:20 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 15:27:26 visual_prompt]: Epoch 39 / 100: avg data time: 4.36e-02, avg batch time: 0.4950, average train loss: 0.4370
[09/26 15:27:28 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1691, average loss: 4.8890
[09/26 15:27:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 53.50	
[09/26 15:27:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 15:27:35 visual_prompt]: Epoch 40 / 100: avg data time: 5.99e-02, avg batch time: 0.5099, average train loss: 0.4182
[09/26 15:27:36 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 5.2990
[09/26 15:27:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.50	
[09/26 15:27:36 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 15:27:43 visual_prompt]: Epoch 41 / 100: avg data time: 5.69e-02, avg batch time: 0.5058, average train loss: 0.3586
[09/26 15:27:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1690, average loss: 5.2255
[09/26 15:27:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 15:27:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 15:27:52 visual_prompt]: Epoch 42 / 100: avg data time: 4.54e-02, avg batch time: 0.4954, average train loss: 0.3010
[09/26 15:27:53 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 5.3372
[09/26 15:27:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 50.50	
[09/26 15:27:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 15:28:00 visual_prompt]: Epoch 43 / 100: avg data time: 6.15e-02, avg batch time: 0.5094, average train loss: 0.2315
[09/26 15:28:02 visual_prompt]: Inference (val):avg data time: 4.85e-05, avg batch time: 0.1690, average loss: 5.2500
[09/26 15:28:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 51.50	
[09/26 15:28:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 15:28:09 visual_prompt]: Epoch 44 / 100: avg data time: 6.33e-02, avg batch time: 0.5112, average train loss: 0.1515
[09/26 15:28:10 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 5.3253
[09/26 15:28:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 56.50	
[09/26 15:28:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 15:28:17 visual_prompt]: Epoch 45 / 100: avg data time: 5.80e-02, avg batch time: 0.5073, average train loss: 0.1050
[09/26 15:28:19 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1690, average loss: 5.6216
[09/26 15:28:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 52.00	
[09/26 15:28:19 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 15:28:26 visual_prompt]: Epoch 46 / 100: avg data time: 5.61e-02, avg batch time: 0.5052, average train loss: 0.0817
[09/26 15:28:27 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1689, average loss: 5.5426
[09/26 15:28:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 54.50	
[09/26 15:28:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 15:28:34 visual_prompt]: Epoch 47 / 100: avg data time: 5.44e-02, avg batch time: 0.5025, average train loss: 0.0630
[09/26 15:28:36 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1695, average loss: 5.5329
[09/26 15:28:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.00	
[09/26 15:28:36 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 15:28:42 visual_prompt]: Epoch 48 / 100: avg data time: 5.61e-02, avg batch time: 0.5052, average train loss: 0.0466
[09/26 15:28:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1695, average loss: 5.5805
[09/26 15:28:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 52.50	
[09/26 15:28:44 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 15:28:51 visual_prompt]: Epoch 49 / 100: avg data time: 4.72e-02, avg batch time: 0.4953, average train loss: 0.0293
[09/26 15:28:52 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1692, average loss: 5.5439
[09/26 15:28:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 53.50	
[09/26 15:28:52 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 15:28:59 visual_prompt]: Epoch 50 / 100: avg data time: 5.82e-02, avg batch time: 0.5068, average train loss: 0.0237
[09/26 15:29:01 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1694, average loss: 5.4836
[09/26 15:29:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.00	
[09/26 15:29:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 15:29:08 visual_prompt]: Epoch 51 / 100: avg data time: 6.03e-02, avg batch time: 0.5098, average train loss: 0.0228
[09/26 15:29:09 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1688, average loss: 5.5565
[09/26 15:29:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 54.50	
[09/26 15:29:09 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 15:29:16 visual_prompt]: Epoch 52 / 100: avg data time: 5.88e-02, avg batch time: 0.5067, average train loss: 0.0159
[09/26 15:29:18 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1691, average loss: 5.6791
[09/26 15:29:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.00	
[09/26 15:29:18 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 15:29:25 visual_prompt]: Epoch 53 / 100: avg data time: 5.47e-02, avg batch time: 0.5030, average train loss: 0.0157
[09/26 15:29:26 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 5.6511
[09/26 15:29:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 15:29:26 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 15:29:33 visual_prompt]: Epoch 54 / 100: avg data time: 5.73e-02, avg batch time: 0.5055, average train loss: 0.0145
[09/26 15:29:35 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1692, average loss: 5.6264
[09/26 15:29:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 56.50	
[09/26 15:29:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 15:29:41 visual_prompt]: Epoch 55 / 100: avg data time: 5.96e-02, avg batch time: 0.5087, average train loss: 0.0182
[09/26 15:29:43 visual_prompt]: Inference (val):avg data time: 5.72e-05, avg batch time: 0.1701, average loss: 5.6201
[09/26 15:29:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 57.50	
[09/26 15:29:43 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 15:29:50 visual_prompt]: Epoch 56 / 100: avg data time: 5.64e-02, avg batch time: 0.5061, average train loss: 0.0139
[09/26 15:29:52 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1689, average loss: 5.6956
[09/26 15:29:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 56.50	
[09/26 15:29:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 15:29:58 visual_prompt]: Epoch 57 / 100: avg data time: 4.20e-02, avg batch time: 0.4907, average train loss: 0.0127
[09/26 15:30:00 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1691, average loss: 5.7406
[09/26 15:30:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 15:30:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 15:30:07 visual_prompt]: Epoch 58 / 100: avg data time: 4.72e-02, avg batch time: 0.4985, average train loss: 0.0114
[09/26 15:30:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1691, average loss: 5.7577
[09/26 15:30:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.00	
[09/26 15:30:08 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 15:30:15 visual_prompt]: Epoch 59 / 100: avg data time: 4.84e-02, avg batch time: 0.4979, average train loss: 0.0107
[09/26 15:30:17 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1687, average loss: 5.7419
[09/26 15:30:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 55.00	
[09/26 15:30:17 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 15:30:23 visual_prompt]: Epoch 60 / 100: avg data time: 4.43e-02, avg batch time: 0.4961, average train loss: 0.0107
[09/26 15:30:25 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 5.7196
[09/26 15:30:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.50	
[09/26 15:30:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 15:30:32 visual_prompt]: Epoch 61 / 100: avg data time: 5.68e-02, avg batch time: 0.5061, average train loss: 0.0088
[09/26 15:30:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1688, average loss: 5.7056
[09/26 15:30:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.50	
[09/26 15:30:33 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 15:30:40 visual_prompt]: Epoch 62 / 100: avg data time: 4.98e-02, avg batch time: 0.4984, average train loss: 0.0084
[09/26 15:30:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1688, average loss: 5.7038
[09/26 15:30:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.50	
[09/26 15:30:42 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 15:30:48 visual_prompt]: Epoch 63 / 100: avg data time: 4.86e-02, avg batch time: 0.4984, average train loss: 0.0086
[09/26 15:30:50 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1694, average loss: 5.7174
[09/26 15:30:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:30:50 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 15:30:57 visual_prompt]: Epoch 64 / 100: avg data time: 5.55e-02, avg batch time: 0.5037, average train loss: 0.0080
[09/26 15:30:58 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1688, average loss: 5.7269
[09/26 15:30:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.00	
[09/26 15:30:58 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 15:31:05 visual_prompt]: Epoch 65 / 100: avg data time: 4.60e-02, avg batch time: 0.4962, average train loss: 0.0081
[09/26 15:31:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 5.7558
[09/26 15:31:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 54.50	
[09/26 15:31:07 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 15:31:14 visual_prompt]: Epoch 66 / 100: avg data time: 5.59e-02, avg batch time: 0.5045, average train loss: 0.0083
[09/26 15:31:15 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1692, average loss: 5.7564
[09/26 15:31:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 55.00	
[09/26 15:31:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 15:31:22 visual_prompt]: Epoch 67 / 100: avg data time: 5.90e-02, avg batch time: 0.5088, average train loss: 0.0075
[09/26 15:31:24 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1693, average loss: 5.7396
[09/26 15:31:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 54.50	
[09/26 15:31:24 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 15:31:30 visual_prompt]: Epoch 68 / 100: avg data time: 5.42e-02, avg batch time: 0.5044, average train loss: 0.0068
[09/26 15:31:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 5.7464
[09/26 15:31:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 54.50	
[09/26 15:31:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 15:31:39 visual_prompt]: Epoch 69 / 100: avg data time: 5.13e-02, avg batch time: 0.5012, average train loss: 0.0067
[09/26 15:31:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 5.7521
[09/26 15:31:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:31:40 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 15:31:47 visual_prompt]: Epoch 70 / 100: avg data time: 5.61e-02, avg batch time: 0.5053, average train loss: 0.0067
[09/26 15:31:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1694, average loss: 5.7584
[09/26 15:31:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 53.50	
[09/26 15:31:49 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 15:31:56 visual_prompt]: Epoch 71 / 100: avg data time: 5.69e-02, avg batch time: 0.5056, average train loss: 0.0067
[09/26 15:31:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 5.7573
[09/26 15:31:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:31:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 15:32:04 visual_prompt]: Epoch 72 / 100: avg data time: 5.29e-02, avg batch time: 0.5029, average train loss: 0.0058
[09/26 15:32:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 5.7507
[09/26 15:32:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 54.00	
[09/26 15:32:06 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 15:32:12 visual_prompt]: Epoch 73 / 100: avg data time: 4.32e-02, avg batch time: 0.4933, average train loss: 0.0059
[09/26 15:32:14 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1690, average loss: 5.7480
[09/26 15:32:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:32:14 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 15:32:21 visual_prompt]: Epoch 74 / 100: avg data time: 5.58e-02, avg batch time: 0.5052, average train loss: 0.0059
[09/26 15:32:22 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1687, average loss: 5.7543
[09/26 15:32:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 55.00	
[09/26 15:32:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 15:32:29 visual_prompt]: Epoch 75 / 100: avg data time: 5.70e-02, avg batch time: 0.5064, average train loss: 0.0056
[09/26 15:32:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1689, average loss: 5.7631
[09/26 15:32:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 55.00	
[09/26 15:32:31 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 15:32:38 visual_prompt]: Epoch 76 / 100: avg data time: 5.93e-02, avg batch time: 0.5096, average train loss: 0.0060
[09/26 15:32:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1689, average loss: 5.7668
[09/26 15:32:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:32:39 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 15:32:46 visual_prompt]: Epoch 77 / 100: avg data time: 5.43e-02, avg batch time: 0.5047, average train loss: 0.0061
[09/26 15:32:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 5.7634
[09/26 15:32:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:32:48 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 15:32:54 visual_prompt]: Epoch 78 / 100: avg data time: 5.00e-02, avg batch time: 0.5008, average train loss: 0.0055
[09/26 15:32:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 5.7624
[09/26 15:32:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:32:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 15:33:03 visual_prompt]: Epoch 79 / 100: avg data time: 5.94e-02, avg batch time: 0.5087, average train loss: 0.0060
[09/26 15:33:04 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1692, average loss: 5.7614
[09/26 15:33:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 54.50	
[09/26 15:33:04 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 15:33:11 visual_prompt]: Epoch 80 / 100: avg data time: 6.32e-02, avg batch time: 0.5120, average train loss: 0.0057
[09/26 15:33:13 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1692, average loss: 5.7587
[09/26 15:33:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 54.50	
[09/26 15:33:13 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 15:33:20 visual_prompt]: Epoch 81 / 100: avg data time: 6.59e-02, avg batch time: 0.5142, average train loss: 0.0062
[09/26 15:33:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 5.7605
[09/26 15:33:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 55.00	
[09/26 15:33:22 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:33:28 visual_prompt]: Epoch 82 / 100: avg data time: 5.63e-02, avg batch time: 0.5057, average train loss: 0.0058
[09/26 15:33:30 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 5.7642
[09/26 15:33:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.00	
[09/26 15:33:30 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:33:37 visual_prompt]: Epoch 83 / 100: avg data time: 4.34e-02, avg batch time: 0.4929, average train loss: 0.0059
[09/26 15:33:38 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 5.7664
[09/26 15:33:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 55.00	
[09/26 15:33:38 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:33:45 visual_prompt]: Epoch 84 / 100: avg data time: 4.77e-02, avg batch time: 0.4979, average train loss: 0.0056
[09/26 15:33:47 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 5.7677
[09/26 15:33:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 55.00	
[09/26 15:33:47 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:33:54 visual_prompt]: Epoch 85 / 100: avg data time: 5.81e-02, avg batch time: 0.5062, average train loss: 0.0054
[09/26 15:33:55 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1689, average loss: 5.7677
[09/26 15:33:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.00	
[09/26 15:33:55 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:34:02 visual_prompt]: Epoch 86 / 100: avg data time: 6.14e-02, avg batch time: 0.5099, average train loss: 0.0053
[09/26 15:34:04 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1692, average loss: 5.7648
[09/26 15:34:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:04 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:34:10 visual_prompt]: Epoch 87 / 100: avg data time: 5.87e-02, avg batch time: 0.5070, average train loss: 0.0055
[09/26 15:34:12 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1689, average loss: 5.7655
[09/26 15:34:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:12 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:34:19 visual_prompt]: Epoch 88 / 100: avg data time: 6.77e-02, avg batch time: 0.5161, average train loss: 0.0053
[09/26 15:34:21 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 5.7662
[09/26 15:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:21 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:34:28 visual_prompt]: Epoch 89 / 100: avg data time: 5.94e-02, avg batch time: 0.5099, average train loss: 0.0059
[09/26 15:34:29 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 5.7664
[09/26 15:34:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:29 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:34:36 visual_prompt]: Epoch 90 / 100: avg data time: 4.74e-02, avg batch time: 0.4964, average train loss: 0.0055
[09/26 15:34:37 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 5.7683
[09/26 15:34:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:37 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:34:44 visual_prompt]: Epoch 91 / 100: avg data time: 5.29e-02, avg batch time: 0.5025, average train loss: 0.0047
[09/26 15:34:46 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1690, average loss: 5.7687
[09/26 15:34:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:46 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:34:53 visual_prompt]: Epoch 92 / 100: avg data time: 5.86e-02, avg batch time: 0.5075, average train loss: 0.0046
[09/26 15:34:54 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1691, average loss: 5.7683
[09/26 15:34:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:34:54 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:35:01 visual_prompt]: Epoch 93 / 100: avg data time: 6.23e-02, avg batch time: 0.5113, average train loss: 0.0054
[09/26 15:35:03 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1689, average loss: 5.7683
[09/26 15:35:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:35:10 visual_prompt]: Epoch 94 / 100: avg data time: 6.04e-02, avg batch time: 0.5104, average train loss: 0.0058
[09/26 15:35:11 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 5.7685
[09/26 15:35:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:11 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:35:18 visual_prompt]: Epoch 95 / 100: avg data time: 4.89e-02, avg batch time: 0.4996, average train loss: 0.0053
[09/26 15:35:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 5.7686
[09/26 15:35:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:20 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:35:27 visual_prompt]: Epoch 96 / 100: avg data time: 5.98e-02, avg batch time: 0.5088, average train loss: 0.0056
[09/26 15:35:28 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 5.7687
[09/26 15:35:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:28 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:35:35 visual_prompt]: Epoch 97 / 100: avg data time: 5.88e-02, avg batch time: 0.5078, average train loss: 0.0059
[09/26 15:35:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 5.7686
[09/26 15:35:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:37 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:35:43 visual_prompt]: Epoch 98 / 100: avg data time: 5.74e-02, avg batch time: 0.5062, average train loss: 0.0052
[09/26 15:35:45 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1689, average loss: 5.7686
[09/26 15:35:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:45 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:35:52 visual_prompt]: Epoch 99 / 100: avg data time: 5.27e-02, avg batch time: 0.5030, average train loss: 0.0050
[09/26 15:35:53 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 5.7686
[09/26 15:35:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:35:53 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:36:00 visual_prompt]: Epoch 100 / 100: avg data time: 6.73e-02, avg batch time: 0.5150, average train loss: 0.0051
[09/26 15:36:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1692, average loss: 5.7686
[09/26 15:36:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.50	
[09/26 15:36:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:36:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:36:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:36:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:36:02 visual_prompt]: Training with config:
[09/26 15:36:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:36:02 visual_prompt]: Loading training data...
[09/26 15:36:02 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:36:04 visual_prompt]: Number of images: 800
[09/26 15:36:04 visual_prompt]: Number of classes: 18 / 18
[09/26 15:36:04 visual_prompt]: Loading validation data...
[09/26 15:36:04 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:36:04 visual_prompt]: Number of images: 200
[09/26 15:36:04 visual_prompt]: Number of classes: 18 / 18
[09/26 15:36:04 visual_prompt]: Constructing models...
[09/26 15:36:06 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 15:36:06 visual_prompt]: tuned percent:0.550
[09/26 15:36:06 visual_prompt]: Device used for model: 0
[09/26 15:36:06 visual_prompt]: Setting up Evaluator...
[09/26 15:36:06 visual_prompt]: Setting up Trainer...
[09/26 15:36:06 visual_prompt]: 	Setting up the optimizer...
[09/26 15:36:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:36:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e-02, avg batch time: 0.4981, average train loss: 3.2577
[09/26 15:36:15 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1683, average loss: 3.1895
[09/26 15:36:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 15:36:15 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 15:36:15 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:36:21 visual_prompt]: Epoch 2 / 100: avg data time: 4.21e-02, avg batch time: 0.4899, average train loss: 2.9978
[09/26 15:36:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1683, average loss: 2.9460
[09/26 15:36:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 15:36:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:36:30 visual_prompt]: Epoch 3 / 100: avg data time: 4.61e-02, avg batch time: 0.4941, average train loss: 2.9288
[09/26 15:36:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 2.9185
[09/26 15:36:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 28.50	
[09/26 15:36:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 15:36:38 visual_prompt]: Epoch 4 / 100: avg data time: 4.03e-02, avg batch time: 0.4899, average train loss: 2.8959
[09/26 15:36:39 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1688, average loss: 2.9370
[09/26 15:36:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.00	top5: 30.00	
[09/26 15:36:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:36:46 visual_prompt]: Epoch 5 / 100: avg data time: 4.24e-02, avg batch time: 0.4924, average train loss: 2.9085
[09/26 15:36:48 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1687, average loss: 2.9194
[09/26 15:36:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 28.00	
[09/26 15:36:48 visual_prompt]: Best epoch 5: best metric: 0.075
[09/26 15:36:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 15:36:55 visual_prompt]: Epoch 6 / 100: avg data time: 5.65e-02, avg batch time: 0.5051, average train loss: 2.8999
[09/26 15:36:56 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 2.9127
[09/26 15:36:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 15:36:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 15:37:03 visual_prompt]: Epoch 7 / 100: avg data time: 4.77e-02, avg batch time: 0.4965, average train loss: 2.8918
[09/26 15:37:04 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1690, average loss: 2.9544
[09/26 15:37:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 2.50	top5: 28.00	
[09/26 15:37:04 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 15:37:11 visual_prompt]: Epoch 8 / 100: avg data time: 4.55e-02, avg batch time: 0.4949, average train loss: 2.8777
[09/26 15:37:13 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 2.8971
[09/26 15:37:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 15:37:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 15:37:20 visual_prompt]: Epoch 9 / 100: avg data time: 5.81e-02, avg batch time: 0.5068, average train loss: 2.8332
[09/26 15:37:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 3.1125
[09/26 15:37:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 15:37:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 15:37:28 visual_prompt]: Epoch 10 / 100: avg data time: 4.85e-02, avg batch time: 0.4964, average train loss: 2.8408
[09/26 15:37:29 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1689, average loss: 3.0573
[09/26 15:37:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.00	top5: 24.50	
[09/26 15:37:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 15:37:36 visual_prompt]: Epoch 11 / 100: avg data time: 5.07e-02, avg batch time: 0.5001, average train loss: 2.8697
[09/26 15:37:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 2.8777
[09/26 15:37:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 34.00	
[09/26 15:37:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 15:37:45 visual_prompt]: Epoch 12 / 100: avg data time: 4.46e-02, avg batch time: 0.4927, average train loss: 2.8014
[09/26 15:37:46 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 2.9206
[09/26 15:37:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 35.00	
[09/26 15:37:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 15:37:53 visual_prompt]: Epoch 13 / 100: avg data time: 4.56e-02, avg batch time: 0.4948, average train loss: 2.7570
[09/26 15:37:54 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 3.3097
[09/26 15:37:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 31.50	
[09/26 15:37:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 15:38:01 visual_prompt]: Epoch 14 / 100: avg data time: 6.18e-02, avg batch time: 0.5102, average train loss: 2.7099
[09/26 15:38:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1690, average loss: 2.9236
[09/26 15:38:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 37.00	
[09/26 15:38:03 visual_prompt]: Best epoch 14: best metric: 0.110
[09/26 15:38:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 15:38:10 visual_prompt]: Epoch 15 / 100: avg data time: 4.64e-02, avg batch time: 0.4972, average train loss: 2.5799
[09/26 15:38:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 2.8664
[09/26 15:38:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 41.50	
[09/26 15:38:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 15:38:18 visual_prompt]: Epoch 16 / 100: avg data time: 4.52e-02, avg batch time: 0.4940, average train loss: 2.4721
[09/26 15:38:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 2.9145
[09/26 15:38:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 43.50	
[09/26 15:38:19 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 15:38:26 visual_prompt]: Epoch 17 / 100: avg data time: 5.15e-02, avg batch time: 0.5005, average train loss: 2.4962
[09/26 15:38:28 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1691, average loss: 2.7775
[09/26 15:38:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 50.50	
[09/26 15:38:28 visual_prompt]: Best epoch 17: best metric: 0.120
[09/26 15:38:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 15:38:34 visual_prompt]: Epoch 18 / 100: avg data time: 4.54e-02, avg batch time: 0.4941, average train loss: 2.3491
[09/26 15:38:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1688, average loss: 2.9203
[09/26 15:38:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 45.50	
[09/26 15:38:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 15:38:43 visual_prompt]: Epoch 19 / 100: avg data time: 4.29e-02, avg batch time: 0.4918, average train loss: 2.2006
[09/26 15:38:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 2.8868
[09/26 15:38:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 50.00	
[09/26 15:38:44 visual_prompt]: Best epoch 19: best metric: 0.125
[09/26 15:38:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 15:38:51 visual_prompt]: Epoch 20 / 100: avg data time: 5.21e-02, avg batch time: 0.5034, average train loss: 2.1354
[09/26 15:38:53 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 3.1526
[09/26 15:38:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 44.50	
[09/26 15:38:53 visual_prompt]: Best epoch 20: best metric: 0.145
[09/26 15:38:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 15:39:00 visual_prompt]: Epoch 21 / 100: avg data time: 5.81e-02, avg batch time: 0.5072, average train loss: 1.9690
[09/26 15:39:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1692, average loss: 3.5628
[09/26 15:39:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.50	
[09/26 15:39:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 15:39:08 visual_prompt]: Epoch 22 / 100: avg data time: 4.70e-02, avg batch time: 0.4971, average train loss: 1.8417
[09/26 15:39:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 3.2567
[09/26 15:39:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 47.00	
[09/26 15:39:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 15:39:16 visual_prompt]: Epoch 23 / 100: avg data time: 5.36e-02, avg batch time: 0.5031, average train loss: 1.6578
[09/26 15:39:18 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1687, average loss: 3.5038
[09/26 15:39:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 47.50	
[09/26 15:39:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 15:39:25 visual_prompt]: Epoch 24 / 100: avg data time: 5.09e-02, avg batch time: 0.5001, average train loss: 1.3954
[09/26 15:39:26 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1690, average loss: 3.8491
[09/26 15:39:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 46.00	
[09/26 15:39:26 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 15:39:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.59e-02, avg batch time: 0.5043, average train loss: 1.3481
[09/26 15:39:35 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1687, average loss: 4.2239
[09/26 15:39:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 50.50	
[09/26 15:39:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 15:39:41 visual_prompt]: Epoch 26 / 100: avg data time: 4.46e-02, avg batch time: 0.4962, average train loss: 1.1869
[09/26 15:39:43 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1689, average loss: 4.4885
[09/26 15:39:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 45.50	
[09/26 15:39:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 15:39:50 visual_prompt]: Epoch 27 / 100: avg data time: 5.43e-02, avg batch time: 0.5039, average train loss: 0.9834
[09/26 15:39:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 4.1545
[09/26 15:39:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 15:39:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 15:39:58 visual_prompt]: Epoch 28 / 100: avg data time: 6.39e-02, avg batch time: 0.5132, average train loss: 0.8640
[09/26 15:40:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1690, average loss: 4.0725
[09/26 15:40:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 49.50	
[09/26 15:40:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 15:40:07 visual_prompt]: Epoch 29 / 100: avg data time: 5.44e-02, avg batch time: 0.5046, average train loss: 0.7034
[09/26 15:40:08 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 4.6510
[09/26 15:40:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 49.50	
[09/26 15:40:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 15:40:15 visual_prompt]: Epoch 30 / 100: avg data time: 4.56e-02, avg batch time: 0.4951, average train loss: 0.5917
[09/26 15:40:16 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1692, average loss: 4.8913
[09/26 15:40:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 50.00	
[09/26 15:40:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 15:40:23 visual_prompt]: Epoch 31 / 100: avg data time: 5.60e-02, avg batch time: 0.5042, average train loss: 0.5336
[09/26 15:40:25 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1691, average loss: 4.7994
[09/26 15:40:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 49.50	
[09/26 15:40:25 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 15:40:32 visual_prompt]: Epoch 32 / 100: avg data time: 4.33e-02, avg batch time: 0.4936, average train loss: 0.4280
[09/26 15:40:33 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1691, average loss: 5.1135
[09/26 15:40:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 46.50	
[09/26 15:40:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 15:40:40 visual_prompt]: Epoch 33 / 100: avg data time: 5.71e-02, avg batch time: 0.5053, average train loss: 0.3754
[09/26 15:40:42 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 4.8554
[09/26 15:40:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 52.50	
[09/26 15:40:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 15:40:48 visual_prompt]: Epoch 34 / 100: avg data time: 5.37e-02, avg batch time: 0.5017, average train loss: 0.2427
[09/26 15:40:50 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 4.8499
[09/26 15:40:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 51.00	
[09/26 15:40:50 visual_prompt]: Best epoch 34: best metric: 0.155
[09/26 15:40:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 15:40:57 visual_prompt]: Epoch 35 / 100: avg data time: 5.78e-02, avg batch time: 0.5060, average train loss: 0.1833
[09/26 15:40:59 visual_prompt]: Inference (val):avg data time: 4.72e-05, avg batch time: 0.1691, average loss: 5.2002
[09/26 15:40:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 51.50	
[09/26 15:40:59 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 15:41:06 visual_prompt]: Epoch 36 / 100: avg data time: 6.49e-02, avg batch time: 0.5136, average train loss: 0.1595
[09/26 15:41:07 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1692, average loss: 5.0253
[09/26 15:41:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 52.00	
[09/26 15:41:07 visual_prompt]: Best epoch 36: best metric: 0.185
[09/26 15:41:07 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 15:41:14 visual_prompt]: Epoch 37 / 100: avg data time: 4.72e-02, avg batch time: 0.4971, average train loss: 0.1143
[09/26 15:41:15 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1692, average loss: 5.3769
[09/26 15:41:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 51.00	
[09/26 15:41:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 15:41:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.26e-02, avg batch time: 0.5018, average train loss: 0.1318
[09/26 15:41:24 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 5.0586
[09/26 15:41:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 55.00	
[09/26 15:41:24 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 15:41:31 visual_prompt]: Epoch 39 / 100: avg data time: 5.48e-02, avg batch time: 0.5042, average train loss: 0.0843
[09/26 15:41:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1693, average loss: 5.3495
[09/26 15:41:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 15:41:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 15:41:39 visual_prompt]: Epoch 40 / 100: avg data time: 5.83e-02, avg batch time: 0.5068, average train loss: 0.0697
[09/26 15:41:41 visual_prompt]: Inference (val):avg data time: 5.17e-05, avg batch time: 0.1692, average loss: 5.1723
[09/26 15:41:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.50	
[09/26 15:41:41 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 15:41:47 visual_prompt]: Epoch 41 / 100: avg data time: 5.24e-02, avg batch time: 0.5038, average train loss: 0.0565
[09/26 15:41:49 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1692, average loss: 5.3522
[09/26 15:41:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 52.50	
[09/26 15:41:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 15:41:56 visual_prompt]: Epoch 42 / 100: avg data time: 4.08e-02, avg batch time: 0.4908, average train loss: 0.0425
[09/26 15:41:57 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1691, average loss: 5.4045
[09/26 15:41:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 49.50	
[09/26 15:41:57 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 15:42:04 visual_prompt]: Epoch 43 / 100: avg data time: 5.88e-02, avg batch time: 0.5074, average train loss: 0.0416
[09/26 15:42:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1692, average loss: 5.4934
[09/26 15:42:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 53.00	
[09/26 15:42:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 15:42:12 visual_prompt]: Epoch 44 / 100: avg data time: 5.51e-02, avg batch time: 0.5040, average train loss: 0.0390
[09/26 15:42:14 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1694, average loss: 5.5365
[09/26 15:42:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.50	
[09/26 15:42:14 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 15:42:21 visual_prompt]: Epoch 45 / 100: avg data time: 5.96e-02, avg batch time: 0.5077, average train loss: 0.0284
[09/26 15:42:22 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 5.5294
[09/26 15:42:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.00	
[09/26 15:42:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 15:42:29 visual_prompt]: Epoch 46 / 100: avg data time: 5.75e-02, avg batch time: 0.5055, average train loss: 0.0196
[09/26 15:42:31 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 5.4648
[09/26 15:42:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:42:31 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 15:42:38 visual_prompt]: Epoch 47 / 100: avg data time: 5.69e-02, avg batch time: 0.5059, average train loss: 0.0138
[09/26 15:42:39 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 5.4667
[09/26 15:42:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.50	
[09/26 15:42:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 15:42:46 visual_prompt]: Epoch 48 / 100: avg data time: 5.93e-02, avg batch time: 0.5081, average train loss: 0.0126
[09/26 15:42:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 5.5023
[09/26 15:42:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 52.50	
[09/26 15:42:48 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 15:42:55 visual_prompt]: Epoch 49 / 100: avg data time: 6.40e-02, avg batch time: 0.5119, average train loss: 0.0106
[09/26 15:42:56 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1692, average loss: 5.5237
[09/26 15:42:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 52.50	
[09/26 15:42:56 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 15:43:03 visual_prompt]: Epoch 50 / 100: avg data time: 5.83e-02, avg batch time: 0.5067, average train loss: 0.0089
[09/26 15:43:05 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1690, average loss: 5.5249
[09/26 15:43:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 52.00	
[09/26 15:43:05 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 15:43:12 visual_prompt]: Epoch 51 / 100: avg data time: 5.77e-02, avg batch time: 0.5077, average train loss: 0.0086
[09/26 15:43:13 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1691, average loss: 5.5566
[09/26 15:43:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.50	
[09/26 15:43:13 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 15:43:20 visual_prompt]: Epoch 52 / 100: avg data time: 5.91e-02, avg batch time: 0.5075, average train loss: 0.0074
[09/26 15:43:22 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1692, average loss: 5.5728
[09/26 15:43:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 53.00	
[09/26 15:43:22 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 15:43:29 visual_prompt]: Epoch 53 / 100: avg data time: 4.92e-02, avg batch time: 0.4976, average train loss: 0.0082
[09/26 15:43:30 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1694, average loss: 5.5506
[09/26 15:43:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:43:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 15:43:37 visual_prompt]: Epoch 54 / 100: avg data time: 5.77e-02, avg batch time: 0.5056, average train loss: 0.0075
[09/26 15:43:39 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1689, average loss: 5.5231
[09/26 15:43:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.50	
[09/26 15:43:39 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 15:43:46 visual_prompt]: Epoch 55 / 100: avg data time: 6.04e-02, avg batch time: 0.5084, average train loss: 0.0064
[09/26 15:43:47 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1692, average loss: 5.4978
[09/26 15:43:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.00	
[09/26 15:43:47 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 15:43:54 visual_prompt]: Epoch 56 / 100: avg data time: 5.64e-02, avg batch time: 0.5055, average train loss: 0.0061
[09/26 15:43:56 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1696, average loss: 5.4983
[09/26 15:43:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:43:56 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 15:44:03 visual_prompt]: Epoch 57 / 100: avg data time: 6.23e-02, avg batch time: 0.5108, average train loss: 0.0057
[09/26 15:44:04 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1689, average loss: 5.5068
[09/26 15:44:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.50	
[09/26 15:44:04 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 15:44:11 visual_prompt]: Epoch 58 / 100: avg data time: 4.87e-02, avg batch time: 0.4974, average train loss: 0.0059
[09/26 15:44:13 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1686, average loss: 5.5232
[09/26 15:44:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.50	
[09/26 15:44:13 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 15:44:19 visual_prompt]: Epoch 59 / 100: avg data time: 4.52e-02, avg batch time: 0.4954, average train loss: 0.0062
[09/26 15:44:21 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 5.5462
[09/26 15:44:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.50	
[09/26 15:44:21 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 15:44:28 visual_prompt]: Epoch 60 / 100: avg data time: 6.19e-02, avg batch time: 0.5098, average train loss: 0.0058
[09/26 15:44:29 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1688, average loss: 5.5503
[09/26 15:44:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.00	
[09/26 15:44:29 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 15:44:36 visual_prompt]: Epoch 61 / 100: avg data time: 6.08e-02, avg batch time: 0.5098, average train loss: 0.0058
[09/26 15:44:38 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1691, average loss: 5.5500
[09/26 15:44:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.50	
[09/26 15:44:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 15:44:45 visual_prompt]: Epoch 62 / 100: avg data time: 6.46e-02, avg batch time: 0.5140, average train loss: 0.0055
[09/26 15:44:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 5.5556
[09/26 15:44:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 53.50	
[09/26 15:44:46 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 15:44:53 visual_prompt]: Epoch 63 / 100: avg data time: 4.27e-02, avg batch time: 0.4921, average train loss: 0.0047
[09/26 15:44:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 5.5636
[09/26 15:44:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.50	
[09/26 15:44:54 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 15:45:01 visual_prompt]: Epoch 64 / 100: avg data time: 4.52e-02, avg batch time: 0.4934, average train loss: 0.0045
[09/26 15:45:03 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1689, average loss: 5.5602
[09/26 15:45:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.00	
[09/26 15:45:03 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 15:45:10 visual_prompt]: Epoch 65 / 100: avg data time: 5.40e-02, avg batch time: 0.5027, average train loss: 0.0048
[09/26 15:45:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 5.5698
[09/26 15:45:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.00	
[09/26 15:45:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 15:45:18 visual_prompt]: Epoch 66 / 100: avg data time: 5.65e-02, avg batch time: 0.5056, average train loss: 0.0051
[09/26 15:45:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1687, average loss: 5.5688
[09/26 15:45:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.00	
[09/26 15:45:20 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 15:45:26 visual_prompt]: Epoch 67 / 100: avg data time: 4.61e-02, avg batch time: 0.4973, average train loss: 0.0044
[09/26 15:45:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1692, average loss: 5.5656
[09/26 15:45:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.00	
[09/26 15:45:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 15:45:35 visual_prompt]: Epoch 68 / 100: avg data time: 6.04e-02, avg batch time: 0.5085, average train loss: 0.0047
[09/26 15:45:36 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 5.5662
[09/26 15:45:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.50	
[09/26 15:45:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 15:45:43 visual_prompt]: Epoch 69 / 100: avg data time: 5.56e-02, avg batch time: 0.5041, average train loss: 0.0049
[09/26 15:45:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 5.5741
[09/26 15:45:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 53.00	
[09/26 15:45:45 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 15:45:52 visual_prompt]: Epoch 70 / 100: avg data time: 6.08e-02, avg batch time: 0.5097, average train loss: 0.0045
[09/26 15:45:53 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 5.5807
[09/26 15:45:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 53.00	
[09/26 15:45:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 15:46:00 visual_prompt]: Epoch 71 / 100: avg data time: 5.96e-02, avg batch time: 0.5100, average train loss: 0.0048
[09/26 15:46:02 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1690, average loss: 5.5886
[09/26 15:46:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.50	
[09/26 15:46:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 15:46:09 visual_prompt]: Epoch 72 / 100: avg data time: 5.92e-02, avg batch time: 0.5072, average train loss: 0.0043
[09/26 15:46:10 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 5.5980
[09/26 15:46:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.50	
[09/26 15:46:10 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 15:46:17 visual_prompt]: Epoch 73 / 100: avg data time: 5.91e-02, avg batch time: 0.5083, average train loss: 0.0049
[09/26 15:46:19 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1693, average loss: 5.5969
[09/26 15:46:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:46:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 15:46:25 visual_prompt]: Epoch 74 / 100: avg data time: 4.48e-02, avg batch time: 0.4946, average train loss: 0.0041
[09/26 15:46:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 5.5933
[09/26 15:46:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.00	
[09/26 15:46:27 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 15:46:34 visual_prompt]: Epoch 75 / 100: avg data time: 5.87e-02, avg batch time: 0.5077, average train loss: 0.0050
[09/26 15:46:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 5.5939
[09/26 15:46:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.50	
[09/26 15:46:35 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 15:46:42 visual_prompt]: Epoch 76 / 100: avg data time: 5.80e-02, avg batch time: 0.5062, average train loss: 0.0043
[09/26 15:46:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 5.5985
[09/26 15:46:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.50	
[09/26 15:46:44 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 15:46:51 visual_prompt]: Epoch 77 / 100: avg data time: 5.16e-02, avg batch time: 0.5012, average train loss: 0.0046
[09/26 15:46:52 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1688, average loss: 5.5978
[09/26 15:46:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.50	
[09/26 15:46:52 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 15:46:59 visual_prompt]: Epoch 78 / 100: avg data time: 5.99e-02, avg batch time: 0.5084, average train loss: 0.0040
[09/26 15:47:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1687, average loss: 5.5961
[09/26 15:47:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.50	
[09/26 15:47:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 15:47:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.95e-02, avg batch time: 0.5086, average train loss: 0.0040
[09/26 15:47:09 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1691, average loss: 5.5981
[09/26 15:47:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.00	
[09/26 15:47:09 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 15:47:16 visual_prompt]: Epoch 80 / 100: avg data time: 6.04e-02, avg batch time: 0.5105, average train loss: 0.0050
[09/26 15:47:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1691, average loss: 5.5998
[09/26 15:47:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:47:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 15:47:25 visual_prompt]: Epoch 81 / 100: avg data time: 6.15e-02, avg batch time: 0.5103, average train loss: 0.0037
[09/26 15:47:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1689, average loss: 5.6017
[09/26 15:47:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.50	
[09/26 15:47:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:47:33 visual_prompt]: Epoch 82 / 100: avg data time: 5.27e-02, avg batch time: 0.5013, average train loss: 0.0052
[09/26 15:47:34 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1693, average loss: 5.6024
[09/26 15:47:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 54.50	
[09/26 15:47:34 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:47:41 visual_prompt]: Epoch 83 / 100: avg data time: 6.41e-02, avg batch time: 0.5128, average train loss: 0.0039
[09/26 15:47:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1687, average loss: 5.6024
[09/26 15:47:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 54.50	
[09/26 15:47:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:47:50 visual_prompt]: Epoch 84 / 100: avg data time: 5.77e-02, avg batch time: 0.5065, average train loss: 0.0039
[09/26 15:47:51 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1688, average loss: 5.6022
[09/26 15:47:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.00	
[09/26 15:47:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:47:58 visual_prompt]: Epoch 85 / 100: avg data time: 5.78e-02, avg batch time: 0.5067, average train loss: 0.0045
[09/26 15:48:00 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1690, average loss: 5.6036
[09/26 15:48:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 15:48:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:48:07 visual_prompt]: Epoch 86 / 100: avg data time: 6.02e-02, avg batch time: 0.5092, average train loss: 0.0041
[09/26 15:48:08 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 5.6066
[09/26 15:48:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 53.50	
[09/26 15:48:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:48:15 visual_prompt]: Epoch 87 / 100: avg data time: 5.74e-02, avg batch time: 0.5079, average train loss: 0.0039
[09/26 15:48:17 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1693, average loss: 5.6066
[09/26 15:48:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:48:17 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:48:24 visual_prompt]: Epoch 88 / 100: avg data time: 5.60e-02, avg batch time: 0.5049, average train loss: 0.0047
[09/26 15:48:25 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1691, average loss: 5.6059
[09/26 15:48:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 53.50	
[09/26 15:48:25 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:48:32 visual_prompt]: Epoch 89 / 100: avg data time: 5.73e-02, avg batch time: 0.5059, average train loss: 0.0043
[09/26 15:48:33 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1694, average loss: 5.6063
[09/26 15:48:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:48:33 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:48:40 visual_prompt]: Epoch 90 / 100: avg data time: 5.83e-02, avg batch time: 0.5079, average train loss: 0.0044
[09/26 15:48:42 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1689, average loss: 5.6072
[09/26 15:48:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:48:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:48:49 visual_prompt]: Epoch 91 / 100: avg data time: 5.43e-02, avg batch time: 0.5033, average train loss: 0.0039
[09/26 15:48:50 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1691, average loss: 5.6078
[09/26 15:48:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:48:50 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:48:57 visual_prompt]: Epoch 92 / 100: avg data time: 5.26e-02, avg batch time: 0.5017, average train loss: 0.0042
[09/26 15:48:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 5.6091
[09/26 15:48:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:48:59 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:49:05 visual_prompt]: Epoch 93 / 100: avg data time: 5.14e-02, avg batch time: 0.4997, average train loss: 0.0041
[09/26 15:49:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1689, average loss: 5.6096
[09/26 15:49:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:07 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:49:14 visual_prompt]: Epoch 94 / 100: avg data time: 5.92e-02, avg batch time: 0.5088, average train loss: 0.0040
[09/26 15:49:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1690, average loss: 5.6097
[09/26 15:49:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:16 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:49:22 visual_prompt]: Epoch 95 / 100: avg data time: 5.84e-02, avg batch time: 0.5071, average train loss: 0.0037
[09/26 15:49:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1686, average loss: 5.6095
[09/26 15:49:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:24 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:49:31 visual_prompt]: Epoch 96 / 100: avg data time: 5.65e-02, avg batch time: 0.5062, average train loss: 0.0040
[09/26 15:49:32 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 5.6094
[09/26 15:49:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:32 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:49:39 visual_prompt]: Epoch 97 / 100: avg data time: 5.70e-02, avg batch time: 0.5068, average train loss: 0.0043
[09/26 15:49:41 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1687, average loss: 5.6095
[09/26 15:49:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:41 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:49:48 visual_prompt]: Epoch 98 / 100: avg data time: 6.53e-02, avg batch time: 0.5143, average train loss: 0.0039
[09/26 15:49:49 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1691, average loss: 5.6095
[09/26 15:49:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:49 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:49:56 visual_prompt]: Epoch 99 / 100: avg data time: 5.87e-02, avg batch time: 0.5075, average train loss: 0.0041
[09/26 15:49:58 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 5.6095
[09/26 15:49:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:49:58 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:50:05 visual_prompt]: Epoch 100 / 100: avg data time: 6.07e-02, avg batch time: 0.5088, average train loss: 0.0042
[09/26 15:50:06 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 5.6095
[09/26 15:50:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.50	
[09/26 15:50:06 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:50:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:50:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:50:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:50:06 visual_prompt]: Training with config:
[09/26 15:50:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:50:06 visual_prompt]: Loading training data...
[09/26 15:50:06 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:50:07 visual_prompt]: Number of images: 800
[09/26 15:50:07 visual_prompt]: Number of classes: 18 / 18
[09/26 15:50:07 visual_prompt]: Loading validation data...
[09/26 15:50:07 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 15:50:08 visual_prompt]: Number of images: 200
[09/26 15:50:08 visual_prompt]: Number of classes: 18 / 18
[09/26 15:50:08 visual_prompt]: Constructing models...
[09/26 15:50:10 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 15:50:10 visual_prompt]: tuned percent:0.550
[09/26 15:50:10 visual_prompt]: Device used for model: 0
[09/26 15:50:10 visual_prompt]: Setting up Evaluator...
[09/26 15:50:10 visual_prompt]: Setting up Trainer...
[09/26 15:50:10 visual_prompt]: 	Setting up the optimizer...
[09/26 15:50:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:50:17 visual_prompt]: Epoch 1 / 100: avg data time: 4.51e-02, avg batch time: 0.4927, average train loss: 3.2506
[09/26 15:50:19 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 15:50:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 15:50:19 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 15:50:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 15:50:25 visual_prompt]: Epoch 2 / 100: avg data time: 5.81e-02, avg batch time: 0.5062, average train loss: 3.0344
[09/26 15:50:27 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1682, average loss: 2.9677
[09/26 15:50:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 26.50	
[09/26 15:50:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:50:34 visual_prompt]: Epoch 3 / 100: avg data time: 5.83e-02, avg batch time: 0.5056, average train loss: 2.9291
[09/26 15:50:36 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1685, average loss: 2.9199
[09/26 15:50:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.00	
[09/26 15:50:36 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 15:50:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 15:50:42 visual_prompt]: Epoch 4 / 100: avg data time: 6.54e-02, avg batch time: 0.5125, average train loss: 2.9086
[09/26 15:50:44 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1684, average loss: 2.9056
[09/26 15:50:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.50	
[09/26 15:50:44 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:50:51 visual_prompt]: Epoch 5 / 100: avg data time: 5.90e-02, avg batch time: 0.5072, average train loss: 2.8848
[09/26 15:50:52 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1686, average loss: 2.9220
[09/26 15:50:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 15:50:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 15:50:59 visual_prompt]: Epoch 6 / 100: avg data time: 4.75e-02, avg batch time: 0.4967, average train loss: 2.8901
[09/26 15:51:01 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 2.9336
[09/26 15:51:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 15:51:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 15:51:08 visual_prompt]: Epoch 7 / 100: avg data time: 5.72e-02, avg batch time: 0.5047, average train loss: 2.8882
[09/26 15:51:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1690, average loss: 2.9252
[09/26 15:51:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.00	
[09/26 15:51:09 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 15:51:16 visual_prompt]: Epoch 8 / 100: avg data time: 5.63e-02, avg batch time: 0.5037, average train loss: 2.8629
[09/26 15:51:17 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 2.9096
[09/26 15:51:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 32.00	
[09/26 15:51:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:51:24 visual_prompt]: Epoch 9 / 100: avg data time: 4.64e-02, avg batch time: 0.4947, average train loss: 2.8593
[09/26 15:51:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1688, average loss: 2.8975
[09/26 15:51:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 32.00	
[09/26 15:51:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 15:51:32 visual_prompt]: Epoch 10 / 100: avg data time: 4.11e-02, avg batch time: 0.4911, average train loss: 2.8327
[09/26 15:51:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1690, average loss: 2.9420
[09/26 15:51:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 32.00	
[09/26 15:51:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 15:51:41 visual_prompt]: Epoch 11 / 100: avg data time: 4.36e-02, avg batch time: 0.4925, average train loss: 2.8318
[09/26 15:51:42 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 2.9085
[09/26 15:51:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 31.00	
[09/26 15:51:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 15:51:49 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e-02, avg batch time: 0.4945, average train loss: 2.7873
[09/26 15:51:50 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1688, average loss: 2.8208
[09/26 15:51:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 39.00	
[09/26 15:51:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 15:51:57 visual_prompt]: Epoch 13 / 100: avg data time: 5.24e-02, avg batch time: 0.5012, average train loss: 2.7442
[09/26 15:51:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 2.9692
[09/26 15:51:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 28.50	
[09/26 15:51:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 15:52:05 visual_prompt]: Epoch 14 / 100: avg data time: 4.41e-02, avg batch time: 0.4940, average train loss: 2.7647
[09/26 15:52:07 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 2.9317
[09/26 15:52:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 34.00	
[09/26 15:52:07 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 15:52:14 visual_prompt]: Epoch 15 / 100: avg data time: 4.66e-02, avg batch time: 0.4971, average train loss: 2.6838
[09/26 15:52:15 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1688, average loss: 2.7982
[09/26 15:52:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 43.00	
[09/26 15:52:15 visual_prompt]: Best epoch 15: best metric: 0.100
[09/26 15:52:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 15:52:22 visual_prompt]: Epoch 16 / 100: avg data time: 5.84e-02, avg batch time: 0.5099, average train loss: 2.6519
[09/26 15:52:24 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1688, average loss: 2.8383
[09/26 15:52:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 38.50	
[09/26 15:52:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 15:52:31 visual_prompt]: Epoch 17 / 100: avg data time: 5.84e-02, avg batch time: 0.5078, average train loss: 2.5740
[09/26 15:52:32 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1690, average loss: 2.8071
[09/26 15:52:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 47.00	
[09/26 15:52:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 15:52:39 visual_prompt]: Epoch 18 / 100: avg data time: 4.51e-02, avg batch time: 0.4951, average train loss: 2.4243
[09/26 15:52:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1691, average loss: 2.7975
[09/26 15:52:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 45.50	
[09/26 15:52:40 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 15:52:47 visual_prompt]: Epoch 19 / 100: avg data time: 6.53e-02, avg batch time: 0.5134, average train loss: 2.2970
[09/26 15:52:49 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1690, average loss: 3.0635
[09/26 15:52:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 45.00	
[09/26 15:52:49 visual_prompt]: Best epoch 19: best metric: 0.105
[09/26 15:52:49 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 15:52:56 visual_prompt]: Epoch 20 / 100: avg data time: 5.46e-02, avg batch time: 0.5030, average train loss: 2.3004
[09/26 15:52:57 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1692, average loss: 2.8911
[09/26 15:52:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 48.00	
[09/26 15:52:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 15:53:04 visual_prompt]: Epoch 21 / 100: avg data time: 6.30e-02, avg batch time: 0.5112, average train loss: 2.1644
[09/26 15:53:06 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 3.0698
[09/26 15:53:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 46.50	
[09/26 15:53:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 15:53:13 visual_prompt]: Epoch 22 / 100: avg data time: 4.72e-02, avg batch time: 0.4966, average train loss: 2.0271
[09/26 15:53:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1692, average loss: 3.1652
[09/26 15:53:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 47.00	
[09/26 15:53:14 visual_prompt]: Best epoch 22: best metric: 0.135
[09/26 15:53:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 15:53:21 visual_prompt]: Epoch 23 / 100: avg data time: 4.58e-02, avg batch time: 0.4981, average train loss: 2.0198
[09/26 15:53:22 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1689, average loss: 3.0147
[09/26 15:53:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 49.00	
[09/26 15:53:22 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 15:53:29 visual_prompt]: Epoch 24 / 100: avg data time: 4.86e-02, avg batch time: 0.4998, average train loss: 1.8081
[09/26 15:53:31 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1687, average loss: 2.9875
[09/26 15:53:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 51.00	
[09/26 15:53:31 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 15:53:37 visual_prompt]: Epoch 25 / 100: avg data time: 4.60e-02, avg batch time: 0.4964, average train loss: 1.5548
[09/26 15:53:39 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 2.9335
[09/26 15:53:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 57.00	
[09/26 15:53:39 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 15:53:46 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e-02, avg batch time: 0.4985, average train loss: 1.3862
[09/26 15:53:47 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1690, average loss: 2.9899
[09/26 15:53:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 52.50	
[09/26 15:53:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 15:53:54 visual_prompt]: Epoch 27 / 100: avg data time: 5.55e-02, avg batch time: 0.5045, average train loss: 1.3181
[09/26 15:53:56 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1690, average loss: 3.1884
[09/26 15:53:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 46.50	
[09/26 15:53:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 15:54:03 visual_prompt]: Epoch 28 / 100: avg data time: 5.49e-02, avg batch time: 0.5036, average train loss: 1.1838
[09/26 15:54:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1693, average loss: 2.9844
[09/26 15:54:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 57.50	
[09/26 15:54:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 15:54:11 visual_prompt]: Epoch 29 / 100: avg data time: 4.73e-02, avg batch time: 0.4964, average train loss: 1.0601
[09/26 15:54:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 3.1546
[09/26 15:54:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 53.00	
[09/26 15:54:12 visual_prompt]: Best epoch 29: best metric: 0.155
[09/26 15:54:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 15:54:19 visual_prompt]: Epoch 30 / 100: avg data time: 4.93e-02, avg batch time: 0.5008, average train loss: 0.9922
[09/26 15:54:21 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1692, average loss: 3.1346
[09/26 15:54:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 53.00	
[09/26 15:54:21 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 15:54:28 visual_prompt]: Epoch 31 / 100: avg data time: 4.64e-02, avg batch time: 0.4971, average train loss: 0.9530
[09/26 15:54:29 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 3.0001
[09/26 15:54:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.50	
[09/26 15:54:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 15:54:36 visual_prompt]: Epoch 32 / 100: avg data time: 4.48e-02, avg batch time: 0.4952, average train loss: 0.8725
[09/26 15:54:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1690, average loss: 3.0689
[09/26 15:54:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 57.50	
[09/26 15:54:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 15:54:44 visual_prompt]: Epoch 33 / 100: avg data time: 5.67e-02, avg batch time: 0.5063, average train loss: 0.6828
[09/26 15:54:46 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 3.1163
[09/26 15:54:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 62.50	
[09/26 15:54:46 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 15:54:53 visual_prompt]: Epoch 34 / 100: avg data time: 6.42e-02, avg batch time: 0.5141, average train loss: 0.5540
[09/26 15:54:54 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 3.2012
[09/26 15:54:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 15:54:54 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 15:55:01 visual_prompt]: Epoch 35 / 100: avg data time: 6.41e-02, avg batch time: 0.5126, average train loss: 0.4915
[09/26 15:55:03 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 3.4475
[09/26 15:55:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 52.50	
[09/26 15:55:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 15:55:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.64e-02, avg batch time: 0.5063, average train loss: 0.4351
[09/26 15:55:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1692, average loss: 3.2195
[09/26 15:55:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 61.00	
[09/26 15:55:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 15:55:18 visual_prompt]: Epoch 37 / 100: avg data time: 5.48e-02, avg batch time: 0.5054, average train loss: 0.4324
[09/26 15:55:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1688, average loss: 3.4017
[09/26 15:55:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 56.50	
[09/26 15:55:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 15:55:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.14e-02, avg batch time: 0.5001, average train loss: 0.3729
[09/26 15:55:28 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 3.3393
[09/26 15:55:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 58.50	
[09/26 15:55:28 visual_prompt]: Best epoch 38: best metric: 0.160
[09/26 15:55:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 15:55:35 visual_prompt]: Epoch 39 / 100: avg data time: 5.92e-02, avg batch time: 0.5073, average train loss: 0.3551
[09/26 15:55:36 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 3.6573
[09/26 15:55:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 54.00	
[09/26 15:55:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 15:55:43 visual_prompt]: Epoch 40 / 100: avg data time: 5.56e-02, avg batch time: 0.5051, average train loss: 0.2932
[09/26 15:55:45 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 3.5915
[09/26 15:55:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 55.00	
[09/26 15:55:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 15:55:51 visual_prompt]: Epoch 41 / 100: avg data time: 5.30e-02, avg batch time: 0.5032, average train loss: 0.3387
[09/26 15:55:53 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1692, average loss: 3.4578
[09/26 15:55:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 55.00	
[09/26 15:55:53 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 15:56:00 visual_prompt]: Epoch 42 / 100: avg data time: 5.81e-02, avg batch time: 0.5062, average train loss: 0.3442
[09/26 15:56:02 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1690, average loss: 3.3693
[09/26 15:56:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 58.00	
[09/26 15:56:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 15:56:08 visual_prompt]: Epoch 43 / 100: avg data time: 5.73e-02, avg batch time: 0.5060, average train loss: 0.3087
[09/26 15:56:10 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1693, average loss: 3.3226
[09/26 15:56:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 59.00	
[09/26 15:56:10 visual_prompt]: Best epoch 43: best metric: 0.165
[09/26 15:56:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 15:56:17 visual_prompt]: Epoch 44 / 100: avg data time: 5.94e-02, avg batch time: 0.5084, average train loss: 0.2823
[09/26 15:56:18 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1692, average loss: 3.2959
[09/26 15:56:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 56.00	
[09/26 15:56:18 visual_prompt]: Best epoch 44: best metric: 0.170
[09/26 15:56:18 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 15:56:25 visual_prompt]: Epoch 45 / 100: avg data time: 5.78e-02, avg batch time: 0.5073, average train loss: 0.2582
[09/26 15:56:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 3.4374
[09/26 15:56:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 52.00	
[09/26 15:56:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 15:56:34 visual_prompt]: Epoch 46 / 100: avg data time: 5.98e-02, avg batch time: 0.5086, average train loss: 0.2778
[09/26 15:56:36 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1692, average loss: 3.3684
[09/26 15:56:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 56.50	
[09/26 15:56:36 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 15:56:42 visual_prompt]: Epoch 47 / 100: avg data time: 5.72e-02, avg batch time: 0.5060, average train loss: 0.2394
[09/26 15:56:44 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 3.4942
[09/26 15:56:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 54.00	
[09/26 15:56:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 15:56:51 visual_prompt]: Epoch 48 / 100: avg data time: 6.00e-02, avg batch time: 0.5085, average train loss: 0.2643
[09/26 15:56:52 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1691, average loss: 3.5397
[09/26 15:56:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 53.00	
[09/26 15:56:52 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 15:56:59 visual_prompt]: Epoch 49 / 100: avg data time: 6.44e-02, avg batch time: 0.5124, average train loss: 0.2927
[09/26 15:57:01 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1692, average loss: 3.3659
[09/26 15:57:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 55.50	
[09/26 15:57:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 15:57:08 visual_prompt]: Epoch 50 / 100: avg data time: 5.52e-02, avg batch time: 0.5039, average train loss: 0.2812
[09/26 15:57:09 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1693, average loss: 3.5068
[09/26 15:57:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 53.50	
[09/26 15:57:09 visual_prompt]: Best epoch 50: best metric: 0.175
[09/26 15:57:09 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 15:57:16 visual_prompt]: Epoch 51 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 0.3685
[09/26 15:57:18 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1693, average loss: 3.5455
[09/26 15:57:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 52.00	
[09/26 15:57:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 15:57:25 visual_prompt]: Epoch 52 / 100: avg data time: 4.84e-02, avg batch time: 0.4982, average train loss: 0.3082
[09/26 15:57:26 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 3.5362
[09/26 15:57:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 54.00	
[09/26 15:57:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 15:57:33 visual_prompt]: Epoch 53 / 100: avg data time: 4.26e-02, avg batch time: 0.4929, average train loss: 0.2963
[09/26 15:57:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1689, average loss: 3.2796
[09/26 15:57:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 59.50	
[09/26 15:57:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 15:57:41 visual_prompt]: Epoch 54 / 100: avg data time: 5.39e-02, avg batch time: 0.5019, average train loss: 0.2495
[09/26 15:57:43 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1692, average loss: 3.3509
[09/26 15:57:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 15:57:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 15:57:50 visual_prompt]: Epoch 55 / 100: avg data time: 4.26e-02, avg batch time: 0.4915, average train loss: 0.1901
[09/26 15:57:51 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1692, average loss: 3.4045
[09/26 15:57:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.50	top5: 53.00	
[09/26 15:57:51 visual_prompt]: Best epoch 55: best metric: 0.185
[09/26 15:57:51 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 15:57:58 visual_prompt]: Epoch 56 / 100: avg data time: 4.64e-02, avg batch time: 0.4956, average train loss: 0.1409
[09/26 15:58:00 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1692, average loss: 3.6520
[09/26 15:58:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 52.50	
[09/26 15:58:00 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 15:58:07 visual_prompt]: Epoch 57 / 100: avg data time: 6.06e-02, avg batch time: 0.5098, average train loss: 0.1156
[09/26 15:58:08 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1693, average loss: 3.3797
[09/26 15:58:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 56.00	
[09/26 15:58:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 15:58:15 visual_prompt]: Epoch 58 / 100: avg data time: 5.09e-02, avg batch time: 0.5013, average train loss: 0.0908
[09/26 15:58:17 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1690, average loss: 3.4864
[09/26 15:58:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 55.00	
[09/26 15:58:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 15:58:23 visual_prompt]: Epoch 59 / 100: avg data time: 6.01e-02, avg batch time: 0.5089, average train loss: 0.0679
[09/26 15:58:25 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 3.4376
[09/26 15:58:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 55.50	
[09/26 15:58:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 15:58:32 visual_prompt]: Epoch 60 / 100: avg data time: 5.99e-02, avg batch time: 0.5086, average train loss: 0.0547
[09/26 15:58:33 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1693, average loss: 3.5158
[09/26 15:58:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.00	
[09/26 15:58:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 15:58:40 visual_prompt]: Epoch 61 / 100: avg data time: 6.02e-02, avg batch time: 0.5093, average train loss: 0.0486
[09/26 15:58:42 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 3.4717
[09/26 15:58:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.00	
[09/26 15:58:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 15:58:49 visual_prompt]: Epoch 62 / 100: avg data time: 4.92e-02, avg batch time: 0.4986, average train loss: 0.0448
[09/26 15:58:50 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1691, average loss: 3.4362
[09/26 15:58:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.00	
[09/26 15:58:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 15:58:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.26e-02, avg batch time: 0.5013, average train loss: 0.0433
[09/26 15:58:59 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1690, average loss: 3.4513
[09/26 15:58:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 52.00	
[09/26 15:58:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 15:59:06 visual_prompt]: Epoch 64 / 100: avg data time: 6.28e-02, avg batch time: 0.5113, average train loss: 0.0433
[09/26 15:59:07 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 3.4684
[09/26 15:59:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.00	
[09/26 15:59:07 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 15:59:14 visual_prompt]: Epoch 65 / 100: avg data time: 5.72e-02, avg batch time: 0.5056, average train loss: 0.0418
[09/26 15:59:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 3.4564
[09/26 15:59:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 54.00	
[09/26 15:59:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 15:59:22 visual_prompt]: Epoch 66 / 100: avg data time: 4.28e-02, avg batch time: 0.4914, average train loss: 0.0418
[09/26 15:59:24 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1689, average loss: 3.4650
[09/26 15:59:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.50	
[09/26 15:59:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 15:59:31 visual_prompt]: Epoch 67 / 100: avg data time: 4.82e-02, avg batch time: 0.4973, average train loss: 0.0414
[09/26 15:59:32 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 3.4588
[09/26 15:59:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 54.50	
[09/26 15:59:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 15:59:39 visual_prompt]: Epoch 68 / 100: avg data time: 5.38e-02, avg batch time: 0.5019, average train loss: 0.0416
[09/26 15:59:40 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 3.4726
[09/26 15:59:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 56.50	
[09/26 15:59:40 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 15:59:47 visual_prompt]: Epoch 69 / 100: avg data time: 5.90e-02, avg batch time: 0.5074, average train loss: 0.0407
[09/26 15:59:49 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 3.4810
[09/26 15:59:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 55.00	
[09/26 15:59:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 15:59:56 visual_prompt]: Epoch 70 / 100: avg data time: 5.47e-02, avg batch time: 0.5034, average train loss: 0.0403
[09/26 15:59:57 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1688, average loss: 3.4615
[09/26 15:59:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 56.50	
[09/26 15:59:57 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 16:00:04 visual_prompt]: Epoch 71 / 100: avg data time: 5.75e-02, avg batch time: 0.5066, average train loss: 0.0401
[09/26 16:00:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1689, average loss: 3.4530
[09/26 16:00:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.50	
[09/26 16:00:06 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 16:00:13 visual_prompt]: Epoch 72 / 100: avg data time: 5.99e-02, avg batch time: 0.5080, average train loss: 0.0396
[09/26 16:00:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 3.4540
[09/26 16:00:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.50	
[09/26 16:00:14 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 16:00:21 visual_prompt]: Epoch 73 / 100: avg data time: 6.00e-02, avg batch time: 0.5090, average train loss: 0.0395
[09/26 16:00:22 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1692, average loss: 3.4338
[09/26 16:00:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 55.50	
[09/26 16:00:22 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 16:00:29 visual_prompt]: Epoch 74 / 100: avg data time: 6.12e-02, avg batch time: 0.5097, average train loss: 0.0393
[09/26 16:00:31 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 3.4172
[09/26 16:00:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.00	
[09/26 16:00:31 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 16:00:38 visual_prompt]: Epoch 75 / 100: avg data time: 5.34e-02, avg batch time: 0.5019, average train loss: 0.0399
[09/26 16:00:39 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1689, average loss: 3.4332
[09/26 16:00:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.00	
[09/26 16:00:39 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 16:00:46 visual_prompt]: Epoch 76 / 100: avg data time: 5.25e-02, avg batch time: 0.5016, average train loss: 0.0389
[09/26 16:00:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1692, average loss: 3.4284
[09/26 16:00:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 54.00	
[09/26 16:00:48 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 16:00:54 visual_prompt]: Epoch 77 / 100: avg data time: 5.98e-02, avg batch time: 0.5085, average train loss: 0.0388
[09/26 16:00:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 3.4142
[09/26 16:00:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 54.00	
[09/26 16:00:56 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 16:01:03 visual_prompt]: Epoch 78 / 100: avg data time: 5.12e-02, avg batch time: 0.5014, average train loss: 0.0391
[09/26 16:01:04 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1692, average loss: 3.4252
[09/26 16:01:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 56.50	
[09/26 16:01:04 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 16:01:11 visual_prompt]: Epoch 79 / 100: avg data time: 4.65e-02, avg batch time: 0.4964, average train loss: 0.0387
[09/26 16:01:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1690, average loss: 3.4267
[09/26 16:01:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.00	
[09/26 16:01:13 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 16:01:19 visual_prompt]: Epoch 80 / 100: avg data time: 5.67e-02, avg batch time: 0.5062, average train loss: 0.0389
[09/26 16:01:21 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1693, average loss: 3.4236
[09/26 16:01:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 55.50	
[09/26 16:01:21 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 16:01:28 visual_prompt]: Epoch 81 / 100: avg data time: 6.47e-02, avg batch time: 0.5139, average train loss: 0.0387
[09/26 16:01:29 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1693, average loss: 3.4138
[09/26 16:01:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 56.50	
[09/26 16:01:29 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 16:01:36 visual_prompt]: Epoch 82 / 100: avg data time: 6.57e-02, avg batch time: 0.5149, average train loss: 0.0390
[09/26 16:01:38 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1693, average loss: 3.4146
[09/26 16:01:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.00	
[09/26 16:01:38 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 16:01:45 visual_prompt]: Epoch 83 / 100: avg data time: 5.67e-02, avg batch time: 0.5049, average train loss: 0.0387
[09/26 16:01:46 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1690, average loss: 3.4259
[09/26 16:01:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.00	
[09/26 16:01:46 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 16:01:53 visual_prompt]: Epoch 84 / 100: avg data time: 5.73e-02, avg batch time: 0.5065, average train loss: 0.0381
[09/26 16:01:55 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1691, average loss: 3.4146
[09/26 16:01:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 55.00	
[09/26 16:01:55 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 16:02:02 visual_prompt]: Epoch 85 / 100: avg data time: 5.89e-02, avg batch time: 0.5085, average train loss: 0.0383
[09/26 16:02:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 3.4034
[09/26 16:02:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.00	
[09/26 16:02:03 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 16:02:10 visual_prompt]: Epoch 86 / 100: avg data time: 5.19e-02, avg batch time: 0.5018, average train loss: 0.0380
[09/26 16:02:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 3.4091
[09/26 16:02:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.00	
[09/26 16:02:11 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 16:02:18 visual_prompt]: Epoch 87 / 100: avg data time: 5.73e-02, avg batch time: 0.5056, average train loss: 0.0381
[09/26 16:02:20 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1687, average loss: 3.4096
[09/26 16:02:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.50	
[09/26 16:02:20 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 16:02:27 visual_prompt]: Epoch 88 / 100: avg data time: 6.28e-02, avg batch time: 0.5114, average train loss: 0.0379
[09/26 16:02:28 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1687, average loss: 3.4114
[09/26 16:02:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 55.50	
[09/26 16:02:29 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 16:02:35 visual_prompt]: Epoch 89 / 100: avg data time: 5.46e-02, avg batch time: 0.5027, average train loss: 0.0381
[09/26 16:02:37 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1691, average loss: 3.4154
[09/26 16:02:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:02:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 16:02:44 visual_prompt]: Epoch 90 / 100: avg data time: 6.06e-02, avg batch time: 0.5097, average train loss: 0.0387
[09/26 16:02:45 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1689, average loss: 3.4122
[09/26 16:02:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:02:45 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 16:02:52 visual_prompt]: Epoch 91 / 100: avg data time: 5.25e-02, avg batch time: 0.5013, average train loss: 0.0379
[09/26 16:02:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 3.4116
[09/26 16:02:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:02:54 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 16:03:00 visual_prompt]: Epoch 92 / 100: avg data time: 5.64e-02, avg batch time: 0.5048, average train loss: 0.0383
[09/26 16:03:02 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 3.4113
[09/26 16:03:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:03:02 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 16:03:09 visual_prompt]: Epoch 93 / 100: avg data time: 5.95e-02, avg batch time: 0.5103, average train loss: 0.0379
[09/26 16:03:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 3.4116
[09/26 16:03:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:03:11 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 16:03:17 visual_prompt]: Epoch 94 / 100: avg data time: 5.04e-02, avg batch time: 0.4983, average train loss: 0.0378
[09/26 16:03:19 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1686, average loss: 3.4098
[09/26 16:03:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:03:19 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 16:03:26 visual_prompt]: Epoch 95 / 100: avg data time: 5.69e-02, avg batch time: 0.5056, average train loss: 0.0376
[09/26 16:03:27 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1689, average loss: 3.4090
[09/26 16:03:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 56.50	
[09/26 16:03:27 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 16:03:34 visual_prompt]: Epoch 96 / 100: avg data time: 5.87e-02, avg batch time: 0.5068, average train loss: 0.0378
[09/26 16:03:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1691, average loss: 3.4084
[09/26 16:03:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:03:36 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 16:03:43 visual_prompt]: Epoch 97 / 100: avg data time: 5.83e-02, avg batch time: 0.5063, average train loss: 0.0373
[09/26 16:03:44 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1691, average loss: 3.4085
[09/26 16:03:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:03:44 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 16:03:51 visual_prompt]: Epoch 98 / 100: avg data time: 6.01e-02, avg batch time: 0.5089, average train loss: 0.0382
[09/26 16:03:53 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1687, average loss: 3.4081
[09/26 16:03:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:03:53 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 16:03:59 visual_prompt]: Epoch 99 / 100: avg data time: 5.06e-02, avg batch time: 0.5006, average train loss: 0.0375
[09/26 16:04:01 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1689, average loss: 3.4080
[09/26 16:04:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:04:01 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 16:04:08 visual_prompt]: Epoch 100 / 100: avg data time: 5.49e-02, avg batch time: 0.5030, average train loss: 0.0378
[09/26 16:04:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1691, average loss: 3.4080
[09/26 16:04:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 18.00	top5: 56.50	
[09/26 16:04:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 16:04:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 16:04:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 16:04:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 16:04:09 visual_prompt]: Training with config:
[09/26 16:04:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 16:04:09 visual_prompt]: Loading training data...
[09/26 16:04:09 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:04:11 visual_prompt]: Number of images: 800
[09/26 16:04:11 visual_prompt]: Number of classes: 18 / 18
[09/26 16:04:11 visual_prompt]: Loading validation data...
[09/26 16:04:11 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:04:11 visual_prompt]: Number of images: 200
[09/26 16:04:11 visual_prompt]: Number of classes: 18 / 18
[09/26 16:04:11 visual_prompt]: Constructing models...
[09/26 16:04:13 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 16:04:13 visual_prompt]: tuned percent:0.550
[09/26 16:04:14 visual_prompt]: Device used for model: 0
[09/26 16:04:14 visual_prompt]: Setting up Evaluator...
[09/26 16:04:14 visual_prompt]: Setting up Trainer...
[09/26 16:04:14 visual_prompt]: 	Setting up the optimizer...
[09/26 16:04:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 16:04:20 visual_prompt]: Epoch 1 / 100: avg data time: 4.49e-02, avg batch time: 0.4929, average train loss: 3.2547
[09/26 16:04:22 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 16:04:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 16:04:22 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 16:04:22 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 16:04:29 visual_prompt]: Epoch 2 / 100: avg data time: 6.17e-02, avg batch time: 0.5093, average train loss: 2.9992
[09/26 16:04:30 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1685, average loss: 2.9463
[09/26 16:04:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 28.00	
[09/26 16:04:30 visual_prompt]: Best epoch 2: best metric: 0.080
[09/26 16:04:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 16:04:37 visual_prompt]: Epoch 3 / 100: avg data time: 5.32e-02, avg batch time: 0.5012, average train loss: 2.9448
[09/26 16:04:39 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1687, average loss: 2.9308
[09/26 16:04:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 28.50	
[09/26 16:04:39 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 16:04:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 16:04:46 visual_prompt]: Epoch 4 / 100: avg data time: 5.87e-02, avg batch time: 0.5058, average train loss: 2.9263
[09/26 16:04:47 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1686, average loss: 2.9271
[09/26 16:04:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 27.50	
[09/26 16:04:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 16:04:54 visual_prompt]: Epoch 5 / 100: avg data time: 5.46e-02, avg batch time: 0.5026, average train loss: 2.8983
[09/26 16:04:56 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1689, average loss: 2.8931
[09/26 16:04:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 31.00	
[09/26 16:04:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 16:05:02 visual_prompt]: Epoch 6 / 100: avg data time: 4.24e-02, avg batch time: 0.4934, average train loss: 2.8890
[09/26 16:05:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1687, average loss: 2.9101
[09/26 16:05:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 29.50	
[09/26 16:05:04 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 16:05:11 visual_prompt]: Epoch 7 / 100: avg data time: 5.25e-02, avg batch time: 0.5014, average train loss: 2.8948
[09/26 16:05:12 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1688, average loss: 2.9284
[09/26 16:05:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 30.00	
[09/26 16:05:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 16:05:19 visual_prompt]: Epoch 8 / 100: avg data time: 5.14e-02, avg batch time: 0.4996, average train loss: 2.8725
[09/26 16:05:21 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1691, average loss: 2.9101
[09/26 16:05:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.50	
[09/26 16:05:21 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 16:05:27 visual_prompt]: Epoch 9 / 100: avg data time: 4.50e-02, avg batch time: 0.4942, average train loss: 2.8627
[09/26 16:05:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 2.9168
[09/26 16:05:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 28.50	
[09/26 16:05:29 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 16:05:36 visual_prompt]: Epoch 10 / 100: avg data time: 4.46e-02, avg batch time: 0.4951, average train loss: 2.8437
[09/26 16:05:37 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1697, average loss: 2.9383
[09/26 16:05:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 31.00	
[09/26 16:05:37 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 16:05:44 visual_prompt]: Epoch 11 / 100: avg data time: 4.22e-02, avg batch time: 0.4922, average train loss: 2.8374
[09/26 16:05:45 visual_prompt]: Inference (val):avg data time: 6.27e-05, avg batch time: 0.1691, average loss: 2.8308
[09/26 16:05:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 37.00	
[09/26 16:05:45 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 16:05:52 visual_prompt]: Epoch 12 / 100: avg data time: 4.63e-02, avg batch time: 0.4957, average train loss: 2.7868
[09/26 16:05:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1690, average loss: 2.8848
[09/26 16:05:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 33.50	
[09/26 16:05:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 16:06:01 visual_prompt]: Epoch 13 / 100: avg data time: 4.49e-02, avg batch time: 0.4959, average train loss: 2.7453
[09/26 16:06:02 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1690, average loss: 2.8298
[09/26 16:06:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 38.50	
[09/26 16:06:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 16:06:09 visual_prompt]: Epoch 14 / 100: avg data time: 4.98e-02, avg batch time: 0.4984, average train loss: 2.7153
[09/26 16:06:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 2.8665
[09/26 16:06:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 35.00	
[09/26 16:06:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 16:06:17 visual_prompt]: Epoch 15 / 100: avg data time: 4.20e-02, avg batch time: 0.4911, average train loss: 2.6280
[09/26 16:06:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1689, average loss: 2.8470
[09/26 16:06:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 40.50	
[09/26 16:06:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 16:06:25 visual_prompt]: Epoch 16 / 100: avg data time: 5.09e-02, avg batch time: 0.5002, average train loss: 2.5958
[09/26 16:06:27 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1690, average loss: 2.8289
[09/26 16:06:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 43.00	
[09/26 16:06:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 16:06:34 visual_prompt]: Epoch 17 / 100: avg data time: 5.83e-02, avg batch time: 0.5065, average train loss: 2.4789
[09/26 16:06:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 2.8471
[09/26 16:06:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 43.00	
[09/26 16:06:35 visual_prompt]: Best epoch 17: best metric: 0.090
[09/26 16:06:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 16:06:42 visual_prompt]: Epoch 18 / 100: avg data time: 4.77e-02, avg batch time: 0.4975, average train loss: 2.3831
[09/26 16:06:44 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1686, average loss: 2.9764
[09/26 16:06:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 43.00	
[09/26 16:06:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 16:06:50 visual_prompt]: Epoch 19 / 100: avg data time: 4.28e-02, avg batch time: 0.4942, average train loss: 2.2948
[09/26 16:06:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1689, average loss: 3.1099
[09/26 16:06:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 42.00	
[09/26 16:06:52 visual_prompt]: Best epoch 19: best metric: 0.095
[09/26 16:06:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 16:06:59 visual_prompt]: Epoch 20 / 100: avg data time: 4.29e-02, avg batch time: 0.4933, average train loss: 2.2260
[09/26 16:07:00 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 2.8236
[09/26 16:07:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 43.00	
[09/26 16:07:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 16:07:07 visual_prompt]: Epoch 21 / 100: avg data time: 5.88e-02, avg batch time: 0.5083, average train loss: 2.0860
[09/26 16:07:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1690, average loss: 3.0112
[09/26 16:07:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 43.50	
[09/26 16:07:09 visual_prompt]: Best epoch 21: best metric: 0.115
[09/26 16:07:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 16:07:15 visual_prompt]: Epoch 22 / 100: avg data time: 5.24e-02, avg batch time: 0.5029, average train loss: 1.9979
[09/26 16:07:17 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1690, average loss: 3.2534
[09/26 16:07:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 42.50	
[09/26 16:07:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 16:07:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.27e-02, avg batch time: 0.5018, average train loss: 1.7749
[09/26 16:07:25 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 3.3185
[09/26 16:07:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 46.00	
[09/26 16:07:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 16:07:32 visual_prompt]: Epoch 24 / 100: avg data time: 4.45e-02, avg batch time: 0.4942, average train loss: 1.6652
[09/26 16:07:34 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1689, average loss: 3.2788
[09/26 16:07:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 50.50	
[09/26 16:07:34 visual_prompt]: Best epoch 24: best metric: 0.125
[09/26 16:07:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 16:07:40 visual_prompt]: Epoch 25 / 100: avg data time: 4.38e-02, avg batch time: 0.4936, average train loss: 1.4618
[09/26 16:07:42 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1689, average loss: 3.5787
[09/26 16:07:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 45.00	
[09/26 16:07:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 16:07:48 visual_prompt]: Epoch 26 / 100: avg data time: 4.38e-02, avg batch time: 0.4925, average train loss: 1.3417
[09/26 16:07:50 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1686, average loss: 3.6942
[09/26 16:07:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 45.00	
[09/26 16:07:50 visual_prompt]: Best epoch 26: best metric: 0.160
[09/26 16:07:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 16:07:57 visual_prompt]: Epoch 27 / 100: avg data time: 4.80e-02, avg batch time: 0.4984, average train loss: 1.1605
[09/26 16:07:58 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1692, average loss: 3.9328
[09/26 16:07:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 44.50	
[09/26 16:07:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 16:08:05 visual_prompt]: Epoch 28 / 100: avg data time: 5.41e-02, avg batch time: 0.5026, average train loss: 0.9842
[09/26 16:08:07 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1691, average loss: 3.9232
[09/26 16:08:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 53.50	
[09/26 16:08:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 16:08:13 visual_prompt]: Epoch 29 / 100: avg data time: 4.58e-02, avg batch time: 0.4972, average train loss: 0.7989
[09/26 16:08:15 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 4.1640
[09/26 16:08:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 48.00	
[09/26 16:08:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 16:08:22 visual_prompt]: Epoch 30 / 100: avg data time: 5.74e-02, avg batch time: 0.5067, average train loss: 0.6590
[09/26 16:08:23 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1693, average loss: 4.2845
[09/26 16:08:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 51.00	
[09/26 16:08:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 16:08:30 visual_prompt]: Epoch 31 / 100: avg data time: 5.91e-02, avg batch time: 0.5075, average train loss: 0.5368
[09/26 16:08:32 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1688, average loss: 4.4479
[09/26 16:08:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 50.50	
[09/26 16:08:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 16:08:39 visual_prompt]: Epoch 32 / 100: avg data time: 5.59e-02, avg batch time: 0.5304, average train loss: 0.4944
[09/26 16:08:40 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1689, average loss: 4.3440
[09/26 16:08:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 16:08:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 16:08:47 visual_prompt]: Epoch 33 / 100: avg data time: 6.09e-02, avg batch time: 0.5102, average train loss: 0.4200
[09/26 16:08:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 4.6181
[09/26 16:08:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:08:49 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 16:08:56 visual_prompt]: Epoch 34 / 100: avg data time: 5.35e-02, avg batch time: 0.5038, average train loss: 0.3399
[09/26 16:08:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1692, average loss: 4.4849
[09/26 16:08:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 47.50	
[09/26 16:08:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 16:09:04 visual_prompt]: Epoch 35 / 100: avg data time: 5.83e-02, avg batch time: 0.5065, average train loss: 0.2404
[09/26 16:09:06 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 4.3992
[09/26 16:09:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 51.50	
[09/26 16:09:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 16:09:13 visual_prompt]: Epoch 36 / 100: avg data time: 4.55e-02, avg batch time: 0.4963, average train loss: 0.1656
[09/26 16:09:14 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1688, average loss: 4.4867
[09/26 16:09:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 16:09:14 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 16:09:21 visual_prompt]: Epoch 37 / 100: avg data time: 4.36e-02, avg batch time: 0.4933, average train loss: 0.1404
[09/26 16:09:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1688, average loss: 4.4498
[09/26 16:09:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 53.50	
[09/26 16:09:22 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 16:09:29 visual_prompt]: Epoch 38 / 100: avg data time: 5.03e-02, avg batch time: 0.4993, average train loss: 0.0925
[09/26 16:09:31 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1689, average loss: 4.5642
[09/26 16:09:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 50.00	
[09/26 16:09:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 16:09:37 visual_prompt]: Epoch 39 / 100: avg data time: 4.50e-02, avg batch time: 0.4942, average train loss: 0.0658
[09/26 16:09:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1688, average loss: 4.4422
[09/26 16:09:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 51.00	
[09/26 16:09:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 16:09:46 visual_prompt]: Epoch 40 / 100: avg data time: 4.85e-02, avg batch time: 0.4993, average train loss: 0.0489
[09/26 16:09:47 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1689, average loss: 4.5447
[09/26 16:09:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 50.00	
[09/26 16:09:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 16:09:54 visual_prompt]: Epoch 41 / 100: avg data time: 4.46e-02, avg batch time: 0.4951, average train loss: 0.0355
[09/26 16:09:56 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 4.4949
[09/26 16:09:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 51.00	
[09/26 16:09:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 16:10:02 visual_prompt]: Epoch 42 / 100: avg data time: 5.20e-02, avg batch time: 0.5008, average train loss: 0.0329
[09/26 16:10:04 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1691, average loss: 4.5574
[09/26 16:10:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.50	
[09/26 16:10:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 16:10:11 visual_prompt]: Epoch 43 / 100: avg data time: 6.23e-02, avg batch time: 0.5107, average train loss: 0.0270
[09/26 16:10:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1690, average loss: 4.6236
[09/26 16:10:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 48.00	
[09/26 16:10:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 16:10:19 visual_prompt]: Epoch 44 / 100: avg data time: 5.80e-02, avg batch time: 0.5068, average train loss: 0.0258
[09/26 16:10:21 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1690, average loss: 4.6180
[09/26 16:10:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.00	
[09/26 16:10:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 16:10:28 visual_prompt]: Epoch 45 / 100: avg data time: 4.66e-02, avg batch time: 0.4950, average train loss: 0.0210
[09/26 16:10:29 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1691, average loss: 4.6766
[09/26 16:10:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:10:29 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 16:10:36 visual_prompt]: Epoch 46 / 100: avg data time: 4.89e-02, avg batch time: 0.4980, average train loss: 0.0190
[09/26 16:10:38 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1690, average loss: 4.6938
[09/26 16:10:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:10:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 16:10:44 visual_prompt]: Epoch 47 / 100: avg data time: 5.25e-02, avg batch time: 0.5009, average train loss: 0.0206
[09/26 16:10:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1692, average loss: 4.6401
[09/26 16:10:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 50.50	
[09/26 16:10:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 16:10:53 visual_prompt]: Epoch 48 / 100: avg data time: 6.09e-02, avg batch time: 0.5106, average train loss: 0.0202
[09/26 16:10:54 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1690, average loss: 4.6602
[09/26 16:10:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 48.50	
[09/26 16:10:54 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 16:11:01 visual_prompt]: Epoch 49 / 100: avg data time: 6.26e-02, avg batch time: 0.5111, average train loss: 0.0168
[09/26 16:11:03 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1691, average loss: 4.7176
[09/26 16:11:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.00	
[09/26 16:11:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 16:11:10 visual_prompt]: Epoch 50 / 100: avg data time: 6.23e-02, avg batch time: 0.5102, average train loss: 0.0168
[09/26 16:11:11 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1688, average loss: 4.7134
[09/26 16:11:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.50	
[09/26 16:11:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 16:11:18 visual_prompt]: Epoch 51 / 100: avg data time: 4.56e-02, avg batch time: 0.4956, average train loss: 0.0167
[09/26 16:11:20 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1691, average loss: 4.7538
[09/26 16:11:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:11:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 16:11:27 visual_prompt]: Epoch 52 / 100: avg data time: 5.17e-02, avg batch time: 0.4998, average train loss: 0.0148
[09/26 16:11:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 4.7733
[09/26 16:11:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:11:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 16:11:35 visual_prompt]: Epoch 53 / 100: avg data time: 5.60e-02, avg batch time: 0.5056, average train loss: 0.0144
[09/26 16:11:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 4.7623
[09/26 16:11:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 47.50	
[09/26 16:11:37 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 16:11:44 visual_prompt]: Epoch 54 / 100: avg data time: 6.23e-02, avg batch time: 0.5110, average train loss: 0.0139
[09/26 16:11:45 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1696, average loss: 4.7456
[09/26 16:11:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 46.50	
[09/26 16:11:45 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 16:11:52 visual_prompt]: Epoch 55 / 100: avg data time: 6.00e-02, avg batch time: 0.5077, average train loss: 0.0145
[09/26 16:11:54 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1689, average loss: 4.7761
[09/26 16:11:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.50	
[09/26 16:11:54 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 16:12:01 visual_prompt]: Epoch 56 / 100: avg data time: 6.31e-02, avg batch time: 0.5110, average train loss: 0.0123
[09/26 16:12:02 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1693, average loss: 4.7647
[09/26 16:12:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 47.50	
[09/26 16:12:02 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 16:12:09 visual_prompt]: Epoch 57 / 100: avg data time: 5.74e-02, avg batch time: 0.5057, average train loss: 0.0123
[09/26 16:12:11 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1692, average loss: 4.7677
[09/26 16:12:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 47.50	
[09/26 16:12:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 16:12:17 visual_prompt]: Epoch 58 / 100: avg data time: 5.67e-02, avg batch time: 0.5065, average train loss: 0.0123
[09/26 16:12:19 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1690, average loss: 4.7771
[09/26 16:12:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 46.50	
[09/26 16:12:19 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 16:12:26 visual_prompt]: Epoch 59 / 100: avg data time: 5.62e-02, avg batch time: 0.5055, average train loss: 0.0120
[09/26 16:12:27 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1690, average loss: 4.7716
[09/26 16:12:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 46.00	
[09/26 16:12:27 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 16:12:34 visual_prompt]: Epoch 60 / 100: avg data time: 5.39e-02, avg batch time: 0.5030, average train loss: 0.0115
[09/26 16:12:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1690, average loss: 4.7534
[09/26 16:12:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 47.00	
[09/26 16:12:36 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 16:12:43 visual_prompt]: Epoch 61 / 100: avg data time: 5.12e-02, avg batch time: 0.5004, average train loss: 0.0119
[09/26 16:12:44 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1694, average loss: 4.7533
[09/26 16:12:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:12:44 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 16:12:51 visual_prompt]: Epoch 62 / 100: avg data time: 5.99e-02, avg batch time: 0.5087, average train loss: 0.0123
[09/26 16:12:53 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1688, average loss: 4.7568
[09/26 16:12:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 48.00	
[09/26 16:12:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 16:13:00 visual_prompt]: Epoch 63 / 100: avg data time: 5.81e-02, avg batch time: 0.5071, average train loss: 0.0115
[09/26 16:13:01 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1692, average loss: 4.7813
[09/26 16:13:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.50	
[09/26 16:13:01 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 16:13:08 visual_prompt]: Epoch 64 / 100: avg data time: 5.29e-02, avg batch time: 0.5023, average train loss: 0.0111
[09/26 16:13:10 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1691, average loss: 4.7719
[09/26 16:13:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.50	
[09/26 16:13:10 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 16:13:17 visual_prompt]: Epoch 65 / 100: avg data time: 5.72e-02, avg batch time: 0.5053, average train loss: 0.0113
[09/26 16:13:18 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1693, average loss: 4.7430
[09/26 16:13:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 47.50	
[09/26 16:13:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 16:13:25 visual_prompt]: Epoch 66 / 100: avg data time: 6.31e-02, avg batch time: 0.5111, average train loss: 0.0107
[09/26 16:13:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1688, average loss: 4.7472
[09/26 16:13:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 47.00	
[09/26 16:13:27 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 16:13:33 visual_prompt]: Epoch 67 / 100: avg data time: 6.03e-02, avg batch time: 0.5084, average train loss: 0.0111
[09/26 16:13:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1692, average loss: 4.7688
[09/26 16:13:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 47.50	
[09/26 16:13:35 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 16:13:42 visual_prompt]: Epoch 68 / 100: avg data time: 5.32e-02, avg batch time: 0.5036, average train loss: 0.0104
[09/26 16:13:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1688, average loss: 4.7787
[09/26 16:13:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 47.50	
[09/26 16:13:43 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 16:13:50 visual_prompt]: Epoch 69 / 100: avg data time: 5.43e-02, avg batch time: 0.5034, average train loss: 0.0106
[09/26 16:13:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1690, average loss: 4.7895
[09/26 16:13:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 47.50	
[09/26 16:13:52 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 16:13:59 visual_prompt]: Epoch 70 / 100: avg data time: 6.03e-02, avg batch time: 0.5104, average train loss: 0.0109
[09/26 16:14:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1691, average loss: 4.7743
[09/26 16:14:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 48.00	
[09/26 16:14:00 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 16:14:07 visual_prompt]: Epoch 71 / 100: avg data time: 5.52e-02, avg batch time: 0.5043, average train loss: 0.0099
[09/26 16:14:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1691, average loss: 4.7724
[09/26 16:14:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 48.50	
[09/26 16:14:09 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 16:14:16 visual_prompt]: Epoch 72 / 100: avg data time: 6.07e-02, avg batch time: 0.5099, average train loss: 0.0105
[09/26 16:14:17 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1692, average loss: 4.7753
[09/26 16:14:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 47.50	
[09/26 16:14:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 16:14:24 visual_prompt]: Epoch 73 / 100: avg data time: 5.56e-02, avg batch time: 0.5056, average train loss: 0.0105
[09/26 16:14:25 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1692, average loss: 4.7638
[09/26 16:14:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:14:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 16:14:32 visual_prompt]: Epoch 74 / 100: avg data time: 6.14e-02, avg batch time: 0.5095, average train loss: 0.0112
[09/26 16:14:34 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 4.7631
[09/26 16:14:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:14:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 16:14:41 visual_prompt]: Epoch 75 / 100: avg data time: 6.02e-02, avg batch time: 0.5092, average train loss: 0.0105
[09/26 16:14:42 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1692, average loss: 4.7597
[09/26 16:14:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:14:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 16:14:49 visual_prompt]: Epoch 76 / 100: avg data time: 5.69e-02, avg batch time: 0.5059, average train loss: 0.0098
[09/26 16:14:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 4.7505
[09/26 16:14:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:14:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 16:14:58 visual_prompt]: Epoch 77 / 100: avg data time: 5.86e-02, avg batch time: 0.5080, average train loss: 0.0098
[09/26 16:14:59 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1691, average loss: 4.7502
[09/26 16:14:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:14:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 16:15:06 visual_prompt]: Epoch 78 / 100: avg data time: 5.59e-02, avg batch time: 0.5048, average train loss: 0.0095
[09/26 16:15:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1689, average loss: 4.7543
[09/26 16:15:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:15:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 16:15:14 visual_prompt]: Epoch 79 / 100: avg data time: 4.97e-02, avg batch time: 0.4998, average train loss: 0.0092
[09/26 16:15:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1692, average loss: 4.7559
[09/26 16:15:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:15:16 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 16:15:23 visual_prompt]: Epoch 80 / 100: avg data time: 5.51e-02, avg batch time: 0.5036, average train loss: 0.0099
[09/26 16:15:24 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 4.7602
[09/26 16:15:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:15:24 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 16:15:31 visual_prompt]: Epoch 81 / 100: avg data time: 4.52e-02, avg batch time: 0.4944, average train loss: 0.0096
[09/26 16:15:32 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1690, average loss: 4.7614
[09/26 16:15:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:15:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 16:15:39 visual_prompt]: Epoch 82 / 100: avg data time: 4.48e-02, avg batch time: 0.4962, average train loss: 0.0099
[09/26 16:15:41 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1690, average loss: 4.7629
[09/26 16:15:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:15:41 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 16:15:47 visual_prompt]: Epoch 83 / 100: avg data time: 5.42e-02, avg batch time: 0.5039, average train loss: 0.0095
[09/26 16:15:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 4.7605
[09/26 16:15:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:15:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 16:15:56 visual_prompt]: Epoch 84 / 100: avg data time: 4.66e-02, avg batch time: 0.4963, average train loss: 0.0092
[09/26 16:15:57 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 4.7605
[09/26 16:15:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:15:57 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 16:16:04 visual_prompt]: Epoch 85 / 100: avg data time: 5.30e-02, avg batch time: 0.5013, average train loss: 0.0097
[09/26 16:16:06 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1689, average loss: 4.7626
[09/26 16:16:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:16:06 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 16:16:12 visual_prompt]: Epoch 86 / 100: avg data time: 4.36e-02, avg batch time: 0.4937, average train loss: 0.0096
[09/26 16:16:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 4.7630
[09/26 16:16:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:16:14 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 16:16:21 visual_prompt]: Epoch 87 / 100: avg data time: 4.58e-02, avg batch time: 0.4972, average train loss: 0.0088
[09/26 16:16:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1691, average loss: 4.7644
[09/26 16:16:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:16:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 16:16:29 visual_prompt]: Epoch 88 / 100: avg data time: 6.18e-02, avg batch time: 0.5109, average train loss: 0.0095
[09/26 16:16:31 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1691, average loss: 4.7643
[09/26 16:16:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:16:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 16:16:37 visual_prompt]: Epoch 89 / 100: avg data time: 4.54e-02, avg batch time: 0.4974, average train loss: 0.0095
[09/26 16:16:39 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 4.7651
[09/26 16:16:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:16:39 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 16:16:46 visual_prompt]: Epoch 90 / 100: avg data time: 6.02e-02, avg batch time: 0.5099, average train loss: 0.0098
[09/26 16:16:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 4.7647
[09/26 16:16:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:16:47 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 16:16:54 visual_prompt]: Epoch 91 / 100: avg data time: 5.53e-02, avg batch time: 0.5041, average train loss: 0.0093
[09/26 16:16:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 4.7654
[09/26 16:16:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:16:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 16:17:02 visual_prompt]: Epoch 92 / 100: avg data time: 5.24e-02, avg batch time: 0.5024, average train loss: 0.0097
[09/26 16:17:04 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1695, average loss: 4.7660
[09/26 16:17:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:17:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 16:17:11 visual_prompt]: Epoch 93 / 100: avg data time: 5.01e-02, avg batch time: 0.4999, average train loss: 0.0096
[09/26 16:17:12 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1690, average loss: 4.7661
[09/26 16:17:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 16:17:19 visual_prompt]: Epoch 94 / 100: avg data time: 4.72e-02, avg batch time: 0.4964, average train loss: 0.0104
[09/26 16:17:21 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1693, average loss: 4.7658
[09/26 16:17:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 16:17:27 visual_prompt]: Epoch 95 / 100: avg data time: 5.60e-02, avg batch time: 0.5054, average train loss: 0.0096
[09/26 16:17:29 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 4.7652
[09/26 16:17:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:29 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 16:17:36 visual_prompt]: Epoch 96 / 100: avg data time: 5.51e-02, avg batch time: 0.5035, average train loss: 0.0099
[09/26 16:17:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 4.7653
[09/26 16:17:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 16:17:44 visual_prompt]: Epoch 97 / 100: avg data time: 5.34e-02, avg batch time: 0.5027, average train loss: 0.0098
[09/26 16:17:46 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1693, average loss: 4.7653
[09/26 16:17:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 16:17:53 visual_prompt]: Epoch 98 / 100: avg data time: 5.11e-02, avg batch time: 0.5023, average train loss: 0.0092
[09/26 16:17:54 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 4.7651
[09/26 16:17:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:17:54 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 16:18:01 visual_prompt]: Epoch 99 / 100: avg data time: 4.49e-02, avg batch time: 0.4955, average train loss: 0.0095
[09/26 16:18:02 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1692, average loss: 4.7650
[09/26 16:18:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:18:02 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 16:18:09 visual_prompt]: Epoch 100 / 100: avg data time: 5.73e-02, avg batch time: 0.5054, average train loss: 0.0096
[09/26 16:18:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1693, average loss: 4.7650
[09/26 16:18:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:18:11 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 16:18:11 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 16:18:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 16:18:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 16:18:11 visual_prompt]: Training with config:
[09/26 16:18:11 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 16:18:11 visual_prompt]: Loading training data...
[09/26 16:18:11 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:18:12 visual_prompt]: Number of images: 800
[09/26 16:18:12 visual_prompt]: Number of classes: 18 / 18
[09/26 16:18:12 visual_prompt]: Loading validation data...
[09/26 16:18:12 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:18:12 visual_prompt]: Number of images: 200
[09/26 16:18:12 visual_prompt]: Number of classes: 18 / 18
[09/26 16:18:12 visual_prompt]: Constructing models...
[09/26 16:18:15 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 16:18:15 visual_prompt]: tuned percent:0.550
[09/26 16:18:15 visual_prompt]: Device used for model: 0
[09/26 16:18:15 visual_prompt]: Setting up Evaluator...
[09/26 16:18:15 visual_prompt]: Setting up Trainer...
[09/26 16:18:15 visual_prompt]: 	Setting up the optimizer...
[09/26 16:18:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 16:18:22 visual_prompt]: Epoch 1 / 100: avg data time: 6.56e-02, avg batch time: 0.5136, average train loss: 3.2569
[09/26 16:18:24 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1689, average loss: 3.1895
[09/26 16:18:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 16:18:24 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 16:18:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 16:18:30 visual_prompt]: Epoch 2 / 100: avg data time: 5.83e-02, avg batch time: 0.5067, average train loss: 2.9960
[09/26 16:18:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1688, average loss: 2.9539
[09/26 16:18:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.00	
[09/26 16:18:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 16:18:39 visual_prompt]: Epoch 3 / 100: avg data time: 6.10e-02, avg batch time: 0.5091, average train loss: 2.9290
[09/26 16:18:41 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1689, average loss: 2.9308
[09/26 16:18:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 25.50	
[09/26 16:18:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 16:18:47 visual_prompt]: Epoch 4 / 100: avg data time: 5.90e-02, avg batch time: 0.5062, average train loss: 2.9264
[09/26 16:18:49 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1686, average loss: 2.9318
[09/26 16:18:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 26.50	
[09/26 16:18:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 16:18:56 visual_prompt]: Epoch 5 / 100: avg data time: 5.11e-02, avg batch time: 0.5013, average train loss: 2.9007
[09/26 16:18:57 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1688, average loss: 2.8962
[09/26 16:18:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 30.50	
[09/26 16:18:57 visual_prompt]: Best epoch 5: best metric: 0.075
[09/26 16:18:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 16:19:04 visual_prompt]: Epoch 6 / 100: avg data time: 5.48e-02, avg batch time: 0.5039, average train loss: 2.8776
[09/26 16:19:06 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1687, average loss: 2.9712
[09/26 16:19:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 25.00	
[09/26 16:19:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 16:19:13 visual_prompt]: Epoch 7 / 100: avg data time: 4.61e-02, avg batch time: 0.4947, average train loss: 2.8951
[09/26 16:19:14 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 2.9298
[09/26 16:19:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 32.50	
[09/26 16:19:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 16:19:21 visual_prompt]: Epoch 8 / 100: avg data time: 5.75e-02, avg batch time: 0.5067, average train loss: 2.8918
[09/26 16:19:23 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.1687, average loss: 2.9088
[09/26 16:19:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 29.00	
[09/26 16:19:23 visual_prompt]: Best epoch 8: best metric: 0.090
[09/26 16:19:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 16:19:29 visual_prompt]: Epoch 9 / 100: avg data time: 4.56e-02, avg batch time: 0.4949, average train loss: 2.8627
[09/26 16:19:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1691, average loss: 2.9530
[09/26 16:19:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 4.50	top5: 30.00	
[09/26 16:19:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 16:19:38 visual_prompt]: Epoch 10 / 100: avg data time: 6.22e-02, avg batch time: 0.5115, average train loss: 2.8543
[09/26 16:19:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1691, average loss: 2.9041
[09/26 16:19:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 16:19:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 16:19:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.35e-02, avg batch time: 0.5021, average train loss: 2.8363
[09/26 16:19:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 3.0025
[09/26 16:19:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.50	
[09/26 16:19:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 16:19:55 visual_prompt]: Epoch 12 / 100: avg data time: 6.14e-02, avg batch time: 0.5103, average train loss: 2.7922
[09/26 16:19:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1690, average loss: 3.0463
[09/26 16:19:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 30.50	
[09/26 16:19:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 16:20:03 visual_prompt]: Epoch 13 / 100: avg data time: 5.53e-02, avg batch time: 0.5038, average train loss: 2.7168
[09/26 16:20:04 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1693, average loss: 2.9897
[09/26 16:20:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 34.00	
[09/26 16:20:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 16:20:11 visual_prompt]: Epoch 14 / 100: avg data time: 4.75e-02, avg batch time: 0.4959, average train loss: 2.6391
[09/26 16:20:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 2.8971
[09/26 16:20:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 41.00	
[09/26 16:20:13 visual_prompt]: Best epoch 14: best metric: 0.105
[09/26 16:20:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 16:20:19 visual_prompt]: Epoch 15 / 100: avg data time: 4.54e-02, avg batch time: 0.4951, average train loss: 2.6074
[09/26 16:20:21 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1695, average loss: 2.9703
[09/26 16:20:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 37.00	
[09/26 16:20:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 16:20:28 visual_prompt]: Epoch 16 / 100: avg data time: 6.10e-02, avg batch time: 0.5100, average train loss: 2.5824
[09/26 16:20:30 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1692, average loss: 2.7987
[09/26 16:20:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.50	top5: 40.00	
[09/26 16:20:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 16:20:36 visual_prompt]: Epoch 17 / 100: avg data time: 6.05e-02, avg batch time: 0.5102, average train loss: 2.4411
[09/26 16:20:38 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1692, average loss: 3.0396
[09/26 16:20:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 40.50	
[09/26 16:20:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 16:20:45 visual_prompt]: Epoch 18 / 100: avg data time: 6.22e-02, avg batch time: 0.5100, average train loss: 2.3562
[09/26 16:20:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 2.9885
[09/26 16:20:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 46.50	
[09/26 16:20:46 visual_prompt]: Best epoch 18: best metric: 0.120
[09/26 16:20:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 16:20:53 visual_prompt]: Epoch 19 / 100: avg data time: 6.19e-02, avg batch time: 0.5105, average train loss: 2.2142
[09/26 16:20:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1688, average loss: 2.9222
[09/26 16:20:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 52.00	
[09/26 16:20:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 16:21:02 visual_prompt]: Epoch 20 / 100: avg data time: 4.78e-02, avg batch time: 0.5000, average train loss: 2.1259
[09/26 16:21:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 3.0072
[09/26 16:21:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 47.00	
[09/26 16:21:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 16:21:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.29e-02, avg batch time: 0.5033, average train loss: 2.0541
[09/26 16:21:12 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 3.4647
[09/26 16:21:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 47.00	
[09/26 16:21:12 visual_prompt]: Best epoch 21: best metric: 0.125
[09/26 16:21:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 16:21:18 visual_prompt]: Epoch 22 / 100: avg data time: 5.68e-02, avg batch time: 0.5068, average train loss: 1.7991
[09/26 16:21:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 3.2499
[09/26 16:21:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 44.50	
[09/26 16:21:20 visual_prompt]: Best epoch 22: best metric: 0.130
[09/26 16:21:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 16:21:27 visual_prompt]: Epoch 23 / 100: avg data time: 5.67e-02, avg batch time: 0.5048, average train loss: 1.7018
[09/26 16:21:28 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1688, average loss: 3.4136
[09/26 16:21:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 48.00	
[09/26 16:21:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 16:21:35 visual_prompt]: Epoch 24 / 100: avg data time: 5.59e-02, avg batch time: 0.5036, average train loss: 1.5313
[09/26 16:21:37 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1692, average loss: 3.7439
[09/26 16:21:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 45.00	
[09/26 16:21:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 16:21:44 visual_prompt]: Epoch 25 / 100: avg data time: 5.89e-02, avg batch time: 0.5069, average train loss: 1.3466
[09/26 16:21:45 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1693, average loss: 3.8063
[09/26 16:21:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 47.50	
[09/26 16:21:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 16:21:52 visual_prompt]: Epoch 26 / 100: avg data time: 5.85e-02, avg batch time: 0.5063, average train loss: 1.2139
[09/26 16:21:54 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1691, average loss: 3.9518
[09/26 16:21:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 51.50	
[09/26 16:21:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 16:22:00 visual_prompt]: Epoch 27 / 100: avg data time: 4.65e-02, avg batch time: 0.4979, average train loss: 1.0803
[09/26 16:22:02 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 3.9966
[09/26 16:22:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 16:22:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 16:22:09 visual_prompt]: Epoch 28 / 100: avg data time: 6.16e-02, avg batch time: 0.5095, average train loss: 0.9073
[09/26 16:22:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1691, average loss: 4.3060
[09/26 16:22:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:22:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 16:22:17 visual_prompt]: Epoch 29 / 100: avg data time: 4.77e-02, avg batch time: 0.4963, average train loss: 0.7616
[09/26 16:22:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1689, average loss: 4.6111
[09/26 16:22:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 48.00	
[09/26 16:22:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 16:22:26 visual_prompt]: Epoch 30 / 100: avg data time: 6.38e-02, avg batch time: 0.5116, average train loss: 0.6908
[09/26 16:22:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1692, average loss: 4.5140
[09/26 16:22:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 44.00	
[09/26 16:22:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 16:22:34 visual_prompt]: Epoch 31 / 100: avg data time: 5.32e-02, avg batch time: 0.5027, average train loss: 0.4989
[09/26 16:22:35 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 4.3972
[09/26 16:22:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 55.00	
[09/26 16:22:35 visual_prompt]: Best epoch 31: best metric: 0.145
[09/26 16:22:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 16:22:42 visual_prompt]: Epoch 32 / 100: avg data time: 4.70e-02, avg batch time: 0.4970, average train loss: 0.4420
[09/26 16:22:44 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1693, average loss: 4.9844
[09/26 16:22:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 50.00	
[09/26 16:22:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 16:22:51 visual_prompt]: Epoch 33 / 100: avg data time: 6.46e-02, avg batch time: 0.5129, average train loss: 0.3408
[09/26 16:22:52 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1690, average loss: 4.9644
[09/26 16:22:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 49.50	
[09/26 16:22:52 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 16:22:59 visual_prompt]: Epoch 34 / 100: avg data time: 4.98e-02, avg batch time: 0.5012, average train loss: 0.3201
[09/26 16:23:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1690, average loss: 4.9961
[09/26 16:23:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 49.50	
[09/26 16:23:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 16:23:08 visual_prompt]: Epoch 35 / 100: avg data time: 6.22e-02, avg batch time: 0.5103, average train loss: 0.2590
[09/26 16:23:09 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1689, average loss: 4.9545
[09/26 16:23:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 50.00	
[09/26 16:23:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 16:23:16 visual_prompt]: Epoch 36 / 100: avg data time: 5.41e-02, avg batch time: 0.5017, average train loss: 0.1659
[09/26 16:23:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1688, average loss: 4.9307
[09/26 16:23:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 54.00	
[09/26 16:23:18 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 16:23:25 visual_prompt]: Epoch 37 / 100: avg data time: 5.60e-02, avg batch time: 0.5048, average train loss: 0.1222
[09/26 16:23:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1692, average loss: 4.9301
[09/26 16:23:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 47.50	
[09/26 16:23:26 visual_prompt]: Best epoch 37: best metric: 0.150
[09/26 16:23:26 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 16:23:33 visual_prompt]: Epoch 38 / 100: avg data time: 5.26e-02, avg batch time: 0.5016, average train loss: 0.0961
[09/26 16:23:35 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1690, average loss: 4.8885
[09/26 16:23:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 16:23:35 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 16:23:41 visual_prompt]: Epoch 39 / 100: avg data time: 4.62e-02, avg batch time: 0.4956, average train loss: 0.0670
[09/26 16:23:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1693, average loss: 5.0001
[09/26 16:23:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.50	top5: 50.50	
[09/26 16:23:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 16:23:50 visual_prompt]: Epoch 40 / 100: avg data time: 5.74e-02, avg batch time: 0.5066, average train loss: 0.0492
[09/26 16:23:51 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1690, average loss: 5.0446
[09/26 16:23:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 48.50	
[09/26 16:23:51 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 16:23:58 visual_prompt]: Epoch 41 / 100: avg data time: 5.57e-02, avg batch time: 0.5037, average train loss: 0.0369
[09/26 16:24:00 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1687, average loss: 5.0400
[09/26 16:24:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 47.50	
[09/26 16:24:00 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 16:24:07 visual_prompt]: Epoch 42 / 100: avg data time: 4.42e-02, avg batch time: 0.4932, average train loss: 0.0287
[09/26 16:24:08 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1691, average loss: 5.1191
[09/26 16:24:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 48.50	
[09/26 16:24:08 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 16:24:15 visual_prompt]: Epoch 43 / 100: avg data time: 4.74e-02, avg batch time: 0.4972, average train loss: 0.0213
[09/26 16:24:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 5.2061
[09/26 16:24:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 51.00	
[09/26 16:24:16 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 16:24:23 visual_prompt]: Epoch 44 / 100: avg data time: 4.74e-02, avg batch time: 0.4963, average train loss: 0.0197
[09/26 16:24:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1694, average loss: 5.2381
[09/26 16:24:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 51.00	
[09/26 16:24:25 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 16:24:31 visual_prompt]: Epoch 45 / 100: avg data time: 5.68e-02, avg batch time: 0.5046, average train loss: 0.0209
[09/26 16:24:33 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1692, average loss: 5.2116
[09/26 16:24:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 50.50	
[09/26 16:24:33 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 16:24:40 visual_prompt]: Epoch 46 / 100: avg data time: 6.32e-02, avg batch time: 0.5109, average train loss: 0.0166
[09/26 16:24:41 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1687, average loss: 5.1824
[09/26 16:24:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 50.00	
[09/26 16:24:41 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 16:24:48 visual_prompt]: Epoch 47 / 100: avg data time: 4.53e-02, avg batch time: 0.4971, average train loss: 0.0161
[09/26 16:24:50 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1691, average loss: 5.2268
[09/26 16:24:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 50.00	
[09/26 16:24:50 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 16:24:57 visual_prompt]: Epoch 48 / 100: avg data time: 4.55e-02, avg batch time: 0.4945, average train loss: 0.0123
[09/26 16:24:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1691, average loss: 5.2750
[09/26 16:24:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:24:58 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 16:25:05 visual_prompt]: Epoch 49 / 100: avg data time: 4.44e-02, avg batch time: 0.4939, average train loss: 0.0131
[09/26 16:25:06 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1690, average loss: 5.2842
[09/26 16:25:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 51.00	
[09/26 16:25:06 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 16:25:13 visual_prompt]: Epoch 50 / 100: avg data time: 4.64e-02, avg batch time: 0.4978, average train loss: 0.0118
[09/26 16:25:15 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1689, average loss: 5.2444
[09/26 16:25:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 51.00	
[09/26 16:25:15 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 16:25:22 visual_prompt]: Epoch 51 / 100: avg data time: 5.47e-02, avg batch time: 0.5030, average train loss: 0.0101
[09/26 16:25:23 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1690, average loss: 5.2425
[09/26 16:25:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 54.00	
[09/26 16:25:23 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 16:25:30 visual_prompt]: Epoch 52 / 100: avg data time: 5.90e-02, avg batch time: 0.5078, average train loss: 0.0114
[09/26 16:25:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1689, average loss: 5.2564
[09/26 16:25:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.00	
[09/26 16:25:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 16:25:39 visual_prompt]: Epoch 53 / 100: avg data time: 6.13e-02, avg batch time: 0.5097, average train loss: 0.0113
[09/26 16:25:40 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 5.2372
[09/26 16:25:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 53.00	
[09/26 16:25:40 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 16:25:47 visual_prompt]: Epoch 54 / 100: avg data time: 5.06e-02, avg batch time: 0.4998, average train loss: 0.0096
[09/26 16:25:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 5.2295
[09/26 16:25:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 50.50	
[09/26 16:25:48 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 16:25:55 visual_prompt]: Epoch 55 / 100: avg data time: 5.98e-02, avg batch time: 0.5085, average train loss: 0.0096
[09/26 16:25:57 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1690, average loss: 5.2617
[09/26 16:25:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.50	
[09/26 16:25:57 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 16:26:04 visual_prompt]: Epoch 56 / 100: avg data time: 5.15e-02, avg batch time: 0.5004, average train loss: 0.0100
[09/26 16:26:05 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1695, average loss: 5.3017
[09/26 16:26:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 51.50	
[09/26 16:26:05 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 16:26:12 visual_prompt]: Epoch 57 / 100: avg data time: 4.47e-02, avg batch time: 0.4936, average train loss: 0.0089
[09/26 16:26:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1692, average loss: 5.3122
[09/26 16:26:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.50	
[09/26 16:26:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 16:26:20 visual_prompt]: Epoch 58 / 100: avg data time: 6.14e-02, avg batch time: 0.5099, average train loss: 0.0094
[09/26 16:26:22 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1691, average loss: 5.3076
[09/26 16:26:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 52.00	
[09/26 16:26:22 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 16:26:29 visual_prompt]: Epoch 59 / 100: avg data time: 5.06e-02, avg batch time: 0.5005, average train loss: 0.0084
[09/26 16:26:30 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1693, average loss: 5.3260
[09/26 16:26:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 52.50	
[09/26 16:26:30 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 16:26:37 visual_prompt]: Epoch 60 / 100: avg data time: 5.32e-02, avg batch time: 0.5019, average train loss: 0.0078
[09/26 16:26:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1688, average loss: 5.3318
[09/26 16:26:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 53.00	
[09/26 16:26:39 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 16:26:46 visual_prompt]: Epoch 61 / 100: avg data time: 5.77e-02, avg batch time: 0.5064, average train loss: 0.0088
[09/26 16:26:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 5.3179
[09/26 16:26:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 53.00	
[09/26 16:26:47 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 16:26:54 visual_prompt]: Epoch 62 / 100: avg data time: 5.66e-02, avg batch time: 0.5044, average train loss: 0.0085
[09/26 16:26:55 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 5.3101
[09/26 16:26:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 53.50	
[09/26 16:26:55 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 16:27:02 visual_prompt]: Epoch 63 / 100: avg data time: 4.56e-02, avg batch time: 0.4962, average train loss: 0.0092
[09/26 16:27:04 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1692, average loss: 5.2961
[09/26 16:27:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 16:27:04 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 16:27:11 visual_prompt]: Epoch 64 / 100: avg data time: 4.97e-02, avg batch time: 0.4979, average train loss: 0.0075
[09/26 16:27:12 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1691, average loss: 5.2939
[09/26 16:27:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 16:27:12 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 16:27:19 visual_prompt]: Epoch 65 / 100: avg data time: 4.71e-02, avg batch time: 0.4962, average train loss: 0.0082
[09/26 16:27:20 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 5.2915
[09/26 16:27:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 16:27:20 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 16:27:27 visual_prompt]: Epoch 66 / 100: avg data time: 5.74e-02, avg batch time: 0.5051, average train loss: 0.0079
[09/26 16:27:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1688, average loss: 5.2922
[09/26 16:27:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 55.50	
[09/26 16:27:29 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 16:27:36 visual_prompt]: Epoch 67 / 100: avg data time: 6.32e-02, avg batch time: 0.5120, average train loss: 0.0075
[09/26 16:27:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1690, average loss: 5.2918
[09/26 16:27:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:27:37 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 16:27:44 visual_prompt]: Epoch 68 / 100: avg data time: 5.74e-02, avg batch time: 0.5068, average train loss: 0.0070
[09/26 16:27:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1690, average loss: 5.2858
[09/26 16:27:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:27:46 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 16:27:52 visual_prompt]: Epoch 69 / 100: avg data time: 4.29e-02, avg batch time: 0.4927, average train loss: 0.0074
[09/26 16:27:54 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1690, average loss: 5.2727
[09/26 16:27:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.50	
[09/26 16:27:54 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 16:28:01 visual_prompt]: Epoch 70 / 100: avg data time: 5.15e-02, avg batch time: 0.5029, average train loss: 0.0080
[09/26 16:28:02 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1689, average loss: 5.2792
[09/26 16:28:02 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.50	
[09/26 16:28:02 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 16:28:09 visual_prompt]: Epoch 71 / 100: avg data time: 5.43e-02, avg batch time: 0.5032, average train loss: 0.0084
[09/26 16:28:11 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1688, average loss: 5.2950
[09/26 16:28:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.50	
[09/26 16:28:11 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 16:28:17 visual_prompt]: Epoch 72 / 100: avg data time: 4.67e-02, avg batch time: 0.4970, average train loss: 0.0065
[09/26 16:28:19 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1691, average loss: 5.3021
[09/26 16:28:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 56.00	
[09/26 16:28:19 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 16:28:26 visual_prompt]: Epoch 73 / 100: avg data time: 4.60e-02, avg batch time: 0.4972, average train loss: 0.0077
[09/26 16:28:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1693, average loss: 5.3325
[09/26 16:28:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:28:27 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 16:28:34 visual_prompt]: Epoch 74 / 100: avg data time: 4.65e-02, avg batch time: 0.4944, average train loss: 0.0075
[09/26 16:28:36 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1692, average loss: 5.3341
[09/26 16:28:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.50	
[09/26 16:28:36 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 16:28:42 visual_prompt]: Epoch 75 / 100: avg data time: 4.79e-02, avg batch time: 0.4972, average train loss: 0.0058
[09/26 16:28:44 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1689, average loss: 5.3317
[09/26 16:28:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 54.00	
[09/26 16:28:44 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 16:28:51 visual_prompt]: Epoch 76 / 100: avg data time: 5.01e-02, avg batch time: 0.4996, average train loss: 0.0065
[09/26 16:28:52 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1691, average loss: 5.3317
[09/26 16:28:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:28:52 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 16:28:59 visual_prompt]: Epoch 77 / 100: avg data time: 5.46e-02, avg batch time: 0.5037, average train loss: 0.0079
[09/26 16:29:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 5.3319
[09/26 16:29:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.50	
[09/26 16:29:01 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 16:29:07 visual_prompt]: Epoch 78 / 100: avg data time: 4.65e-02, avg batch time: 0.4968, average train loss: 0.0066
[09/26 16:29:09 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1691, average loss: 5.3327
[09/26 16:29:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.00	
[09/26 16:29:09 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 16:29:16 visual_prompt]: Epoch 79 / 100: avg data time: 4.78e-02, avg batch time: 0.4967, average train loss: 0.0079
[09/26 16:29:17 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1692, average loss: 5.3282
[09/26 16:29:17 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.50	
[09/26 16:29:17 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 16:29:24 visual_prompt]: Epoch 80 / 100: avg data time: 4.34e-02, avg batch time: 0.4935, average train loss: 0.0060
[09/26 16:29:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 5.3288
[09/26 16:29:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 55.00	
[09/26 16:29:26 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 16:29:32 visual_prompt]: Epoch 81 / 100: avg data time: 4.77e-02, avg batch time: 0.4968, average train loss: 0.0071
[09/26 16:29:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1692, average loss: 5.3296
[09/26 16:29:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 55.00	
[09/26 16:29:34 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 16:29:41 visual_prompt]: Epoch 82 / 100: avg data time: 5.12e-02, avg batch time: 0.5007, average train loss: 0.0065
[09/26 16:29:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 5.3313
[09/26 16:29:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:29:42 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 16:29:49 visual_prompt]: Epoch 83 / 100: avg data time: 5.55e-02, avg batch time: 0.5035, average train loss: 0.0061
[09/26 16:29:50 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1691, average loss: 5.3333
[09/26 16:29:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:29:50 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 16:29:57 visual_prompt]: Epoch 84 / 100: avg data time: 5.16e-02, avg batch time: 0.4996, average train loss: 0.0059
[09/26 16:29:59 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 5.3342
[09/26 16:29:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:29:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 16:30:05 visual_prompt]: Epoch 85 / 100: avg data time: 4.48e-02, avg batch time: 0.4961, average train loss: 0.0063
[09/26 16:30:07 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1691, average loss: 5.3333
[09/26 16:30:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:30:07 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 16:30:14 visual_prompt]: Epoch 86 / 100: avg data time: 4.67e-02, avg batch time: 0.4971, average train loss: 0.0061
[09/26 16:30:15 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1689, average loss: 5.3283
[09/26 16:30:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:30:15 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 16:30:22 visual_prompt]: Epoch 87 / 100: avg data time: 6.05e-02, avg batch time: 0.5116, average train loss: 0.0055
[09/26 16:30:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1687, average loss: 5.3289
[09/26 16:30:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:30:24 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 16:30:31 visual_prompt]: Epoch 88 / 100: avg data time: 4.63e-02, avg batch time: 0.4982, average train loss: 0.0062
[09/26 16:30:32 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1691, average loss: 5.3299
[09/26 16:30:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.00	
[09/26 16:30:32 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 16:30:39 visual_prompt]: Epoch 89 / 100: avg data time: 4.33e-02, avg batch time: 0.4956, average train loss: 0.0068
[09/26 16:30:40 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1688, average loss: 5.3317
[09/26 16:30:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:30:40 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 16:30:47 visual_prompt]: Epoch 90 / 100: avg data time: 4.93e-02, avg batch time: 0.4986, average train loss: 0.0061
[09/26 16:30:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1692, average loss: 5.3332
[09/26 16:30:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:30:49 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 16:30:56 visual_prompt]: Epoch 91 / 100: avg data time: 4.97e-02, avg batch time: 0.4992, average train loss: 0.0065
[09/26 16:30:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1690, average loss: 5.3347
[09/26 16:30:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:30:57 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 16:31:04 visual_prompt]: Epoch 92 / 100: avg data time: 5.62e-02, avg batch time: 0.5052, average train loss: 0.0065
[09/26 16:31:05 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1689, average loss: 5.3359
[09/26 16:31:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:05 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 16:31:12 visual_prompt]: Epoch 93 / 100: avg data time: 4.59e-02, avg batch time: 0.4938, average train loss: 0.0066
[09/26 16:31:14 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1689, average loss: 5.3364
[09/26 16:31:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:14 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 16:31:20 visual_prompt]: Epoch 94 / 100: avg data time: 5.13e-02, avg batch time: 0.4988, average train loss: 0.0061
[09/26 16:31:22 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1693, average loss: 5.3364
[09/26 16:31:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:22 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 16:31:29 visual_prompt]: Epoch 95 / 100: avg data time: 4.82e-02, avg batch time: 0.4968, average train loss: 0.0057
[09/26 16:31:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1687, average loss: 5.3367
[09/26 16:31:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 16:31:37 visual_prompt]: Epoch 96 / 100: avg data time: 4.75e-02, avg batch time: 0.4975, average train loss: 0.0080
[09/26 16:31:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 5.3374
[09/26 16:31:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:39 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 16:31:45 visual_prompt]: Epoch 97 / 100: avg data time: 5.86e-02, avg batch time: 0.5074, average train loss: 0.0066
[09/26 16:31:47 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1691, average loss: 5.3375
[09/26 16:31:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:47 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 16:31:54 visual_prompt]: Epoch 98 / 100: avg data time: 4.68e-02, avg batch time: 0.4956, average train loss: 0.0067
[09/26 16:31:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 5.3377
[09/26 16:31:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:31:55 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 16:32:02 visual_prompt]: Epoch 99 / 100: avg data time: 6.18e-02, avg batch time: 0.5104, average train loss: 0.0060
[09/26 16:32:04 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1690, average loss: 5.3377
[09/26 16:32:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:32:04 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 16:32:11 visual_prompt]: Epoch 100 / 100: avg data time: 6.38e-02, avg batch time: 0.5116, average train loss: 0.0055
[09/26 16:32:12 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1693, average loss: 5.3378
[09/26 16:32:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 55.50	
[09/26 16:32:12 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 16:32:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 16:32:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATA.NUMBER_CLASSES', '18', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 16:32:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 16:32:12 visual_prompt]: Training with config:
[09/26 16:32:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-smallnorb(predicted_attribute="label_azimuth")/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-smallnorb(predicted_attribute="label_azimuth")', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 18, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 16:32:12 visual_prompt]: Loading training data...
[09/26 16:32:12 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split train[:800], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:32:13 visual_prompt]: Number of images: 800
[09/26 16:32:13 visual_prompt]: Number of classes: 18 / 18
[09/26 16:32:13 visual_prompt]: Loading validation data...
[09/26 16:32:13 visual_prompt]: Constructing vtab-smallnorb(predicted_attribute="label_azimuth") dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/smallnorb/2.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset smallnorb (visual_prompt_tuning/data_path/smallnorb/2.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset smallnorb for split test[:200], from visual_prompt_tuning/data_path/smallnorb/2.0.0
[09/26 16:32:14 visual_prompt]: Number of images: 200
[09/26 16:32:14 visual_prompt]: Number of classes: 18 / 18
[09/26 16:32:14 visual_prompt]: Constructing models...
[09/26 16:32:16 visual_prompt]: Total Parameters: 86273298	 Gradient Parameters: 474642
[09/26 16:32:16 visual_prompt]: tuned percent:0.550
[09/26 16:32:16 visual_prompt]: Device used for model: 0
[09/26 16:32:16 visual_prompt]: Setting up Evaluator...
[09/26 16:32:16 visual_prompt]: Setting up Trainer...
[09/26 16:32:16 visual_prompt]: 	Setting up the optimizer...
[09/26 16:32:16 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 16:32:23 visual_prompt]: Epoch 1 / 100: avg data time: 5.40e-02, avg batch time: 0.5014, average train loss: 3.2486
[09/26 16:32:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1685, average loss: 3.1895
[09/26 16:32:25 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.00	top5: 34.00	
[09/26 16:32:25 visual_prompt]: Best epoch 1: best metric: 0.060
[09/26 16:32:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 16:32:31 visual_prompt]: Epoch 2 / 100: avg data time: 4.77e-02, avg batch time: 0.4946, average train loss: 3.0062
[09/26 16:32:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1684, average loss: 2.9511
[09/26 16:32:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.00	top5: 23.00	
[09/26 16:32:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 16:32:40 visual_prompt]: Epoch 3 / 100: avg data time: 5.25e-02, avg batch time: 0.5001, average train loss: 2.9230
[09/26 16:32:41 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1690, average loss: 2.9025
[09/26 16:32:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 30.00	
[09/26 16:32:41 visual_prompt]: Best epoch 3: best metric: 0.080
[09/26 16:32:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 16:32:48 visual_prompt]: Epoch 4 / 100: avg data time: 4.82e-02, avg batch time: 0.4960, average train loss: 2.9112
[09/26 16:32:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1687, average loss: 2.9318
[09/26 16:32:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 28.00	
[09/26 16:32:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 16:32:56 visual_prompt]: Epoch 5 / 100: avg data time: 5.30e-02, avg batch time: 0.5014, average train loss: 2.9010
[09/26 16:32:58 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1688, average loss: 2.8976
[09/26 16:32:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 6.50	top5: 29.00	
[09/26 16:32:58 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 16:33:04 visual_prompt]: Epoch 6 / 100: avg data time: 4.83e-02, avg batch time: 0.4986, average train loss: 2.9172
[09/26 16:33:06 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1686, average loss: 2.9572
[09/26 16:33:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 28.50	
[09/26 16:33:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 16:33:13 visual_prompt]: Epoch 7 / 100: avg data time: 4.58e-02, avg batch time: 0.4944, average train loss: 2.9084
[09/26 16:33:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1687, average loss: 2.9059
[09/26 16:33:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 3.50	top5: 30.00	
[09/26 16:33:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 16:33:21 visual_prompt]: Epoch 8 / 100: avg data time: 4.46e-02, avg batch time: 0.4955, average train loss: 2.8880
[09/26 16:33:23 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1686, average loss: 2.8947
[09/26 16:33:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 7.00	top5: 31.00	
[09/26 16:33:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 16:33:29 visual_prompt]: Epoch 9 / 100: avg data time: 4.44e-02, avg batch time: 0.4923, average train loss: 2.8917
[09/26 16:33:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1691, average loss: 2.9148
[09/26 16:33:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 30.00	
[09/26 16:33:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 16:33:38 visual_prompt]: Epoch 10 / 100: avg data time: 5.42e-02, avg batch time: 0.5018, average train loss: 2.8762
[09/26 16:33:39 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1692, average loss: 2.9018
[09/26 16:33:39 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 32.50	
[09/26 16:33:39 visual_prompt]: Best epoch 10: best metric: 0.085
[09/26 16:33:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 16:33:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.37e-02, avg batch time: 0.5021, average train loss: 2.8749
[09/26 16:33:48 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 2.9232
[09/26 16:33:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.50	top5: 27.50	
[09/26 16:33:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 16:33:54 visual_prompt]: Epoch 12 / 100: avg data time: 4.77e-02, avg batch time: 0.4973, average train loss: 2.8548
[09/26 16:33:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1686, average loss: 2.9499
[09/26 16:33:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 26.50	
[09/26 16:33:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 16:34:03 visual_prompt]: Epoch 13 / 100: avg data time: 4.68e-02, avg batch time: 0.4963, average train loss: 2.8348
[09/26 16:34:04 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1691, average loss: 2.9030
[09/26 16:34:04 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 5.50	top5: 32.50	
[09/26 16:34:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 16:34:11 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e-02, avg batch time: 0.4986, average train loss: 2.7842
[09/26 16:34:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1687, average loss: 2.9318
[09/26 16:34:12 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 31.00	
[09/26 16:34:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 16:34:19 visual_prompt]: Epoch 15 / 100: avg data time: 5.75e-02, avg batch time: 0.5049, average train loss: 2.7546
[09/26 16:34:21 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1688, average loss: 2.8758
[09/26 16:34:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 38.50	
[09/26 16:34:21 visual_prompt]: Best epoch 15: best metric: 0.090
[09/26 16:34:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 16:34:28 visual_prompt]: Epoch 16 / 100: avg data time: 5.76e-02, avg batch time: 0.5051, average train loss: 2.6750
[09/26 16:34:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1689, average loss: 2.8895
[09/26 16:34:29 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.00	top5: 41.50	
[09/26 16:34:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 16:34:36 visual_prompt]: Epoch 17 / 100: avg data time: 4.92e-02, avg batch time: 0.4979, average train loss: 2.5997
[09/26 16:34:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1688, average loss: 2.7995
[09/26 16:34:37 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 10.00	top5: 45.00	
[09/26 16:34:37 visual_prompt]: Best epoch 17: best metric: 0.100
[09/26 16:34:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 16:34:44 visual_prompt]: Epoch 18 / 100: avg data time: 4.65e-02, avg batch time: 0.4953, average train loss: 2.5379
[09/26 16:34:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1692, average loss: 2.9028
[09/26 16:34:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 43.00	
[09/26 16:34:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 16:34:53 visual_prompt]: Epoch 19 / 100: avg data time: 6.27e-02, avg batch time: 0.5104, average train loss: 2.4990
[09/26 16:34:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1690, average loss: 2.8104
[09/26 16:34:54 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 8.00	top5: 47.50	
[09/26 16:34:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 16:35:01 visual_prompt]: Epoch 20 / 100: avg data time: 4.81e-02, avg batch time: 0.4980, average train loss: 2.3784
[09/26 16:35:03 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1691, average loss: 2.9133
[09/26 16:35:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 9.50	top5: 49.50	
[09/26 16:35:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 16:35:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.97e-02, avg batch time: 0.5073, average train loss: 2.2237
[09/26 16:35:11 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1686, average loss: 3.1847
[09/26 16:35:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.00	
[09/26 16:35:11 visual_prompt]: Best epoch 21: best metric: 0.130
[09/26 16:35:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 16:35:18 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e-02, avg batch time: 0.4974, average train loss: 2.0970
[09/26 16:35:19 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1687, average loss: 3.4764
[09/26 16:35:19 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 44.50	
[09/26 16:35:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 16:35:26 visual_prompt]: Epoch 23 / 100: avg data time: 5.25e-02, avg batch time: 0.5012, average train loss: 2.0517
[09/26 16:35:28 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1690, average loss: 3.1086
[09/26 16:35:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 43.50	
[09/26 16:35:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 16:35:34 visual_prompt]: Epoch 24 / 100: avg data time: 5.00e-02, avg batch time: 0.4986, average train loss: 1.9137
[09/26 16:35:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1693, average loss: 3.2314
[09/26 16:35:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.00	
[09/26 16:35:36 visual_prompt]: Best epoch 24: best metric: 0.140
[09/26 16:35:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 16:35:43 visual_prompt]: Epoch 25 / 100: avg data time: 4.79e-02, avg batch time: 0.4986, average train loss: 1.7141
[09/26 16:35:44 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1691, average loss: 3.6422
[09/26 16:35:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 52.00	
[09/26 16:35:44 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 16:35:51 visual_prompt]: Epoch 26 / 100: avg data time: 5.44e-02, avg batch time: 0.5047, average train loss: 1.5198
[09/26 16:35:53 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1686, average loss: 3.7795
[09/26 16:35:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.00	top5: 48.50	
[09/26 16:35:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 16:35:59 visual_prompt]: Epoch 27 / 100: avg data time: 5.04e-02, avg batch time: 0.4984, average train loss: 1.3687
[09/26 16:36:01 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1688, average loss: 3.8017
[09/26 16:36:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 50.00	
[09/26 16:36:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 16:36:08 visual_prompt]: Epoch 28 / 100: avg data time: 4.84e-02, avg batch time: 0.4987, average train loss: 1.2495
[09/26 16:36:09 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1690, average loss: 3.8912
[09/26 16:36:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:36:09 visual_prompt]: Best epoch 28: best metric: 0.160
[09/26 16:36:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 16:36:16 visual_prompt]: Epoch 29 / 100: avg data time: 5.06e-02, avg batch time: 0.5004, average train loss: 1.1747
[09/26 16:36:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1693, average loss: 4.1534
[09/26 16:36:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 46.50	
[09/26 16:36:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 16:36:24 visual_prompt]: Epoch 30 / 100: avg data time: 5.56e-02, avg batch time: 0.5042, average train loss: 0.9526
[09/26 16:36:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1684, average loss: 4.4846
[09/26 16:36:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 45.50	
[09/26 16:36:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 16:36:33 visual_prompt]: Epoch 31 / 100: avg data time: 6.50e-02, avg batch time: 0.5129, average train loss: 0.8041
[09/26 16:36:34 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 4.2842
[09/26 16:36:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 46.00	
[09/26 16:36:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 16:36:41 visual_prompt]: Epoch 32 / 100: avg data time: 6.08e-02, avg batch time: 0.5087, average train loss: 0.7440
[09/26 16:36:43 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1690, average loss: 4.5262
[09/26 16:36:43 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.50	top5: 44.50	
[09/26 16:36:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 16:36:50 visual_prompt]: Epoch 33 / 100: avg data time: 6.36e-02, avg batch time: 0.5131, average train loss: 0.5719
[09/26 16:36:51 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1689, average loss: 4.5568
[09/26 16:36:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 49.50	
[09/26 16:36:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 16:36:58 visual_prompt]: Epoch 34 / 100: avg data time: 4.99e-02, avg batch time: 0.5005, average train loss: 0.5012
[09/26 16:37:00 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1690, average loss: 4.8019
[09/26 16:37:00 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 11.50	top5: 49.00	
[09/26 16:37:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 16:37:06 visual_prompt]: Epoch 35 / 100: avg data time: 4.46e-02, avg batch time: 0.4930, average train loss: 0.3606
[09/26 16:37:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1688, average loss: 4.7907
[09/26 16:37:08 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 47.00	
[09/26 16:37:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 16:37:15 visual_prompt]: Epoch 36 / 100: avg data time: 4.27e-02, avg batch time: 0.4905, average train loss: 0.3039
[09/26 16:37:16 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1691, average loss: 4.8146
[09/26 16:37:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 50.00	
[09/26 16:37:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 16:37:23 visual_prompt]: Epoch 37 / 100: avg data time: 5.49e-02, avg batch time: 0.5045, average train loss: 0.2952
[09/26 16:37:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1687, average loss: 4.9553
[09/26 16:37:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 46.50	
[09/26 16:37:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 16:37:31 visual_prompt]: Epoch 38 / 100: avg data time: 4.73e-02, avg batch time: 0.4953, average train loss: 0.1911
[09/26 16:37:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1690, average loss: 5.0474
[09/26 16:37:33 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.00	top5: 54.00	
[09/26 16:37:33 visual_prompt]: Best epoch 38: best metric: 0.170
[09/26 16:37:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 16:37:40 visual_prompt]: Epoch 39 / 100: avg data time: 5.46e-02, avg batch time: 0.5031, average train loss: 0.1775
[09/26 16:37:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1690, average loss: 4.9439
[09/26 16:37:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 53.00	
[09/26 16:37:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 16:37:48 visual_prompt]: Epoch 40 / 100: avg data time: 5.72e-02, avg batch time: 0.5051, average train loss: 0.1230
[09/26 16:37:50 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1688, average loss: 4.9709
[09/26 16:37:50 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 52.00	
[09/26 16:37:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 16:37:56 visual_prompt]: Epoch 41 / 100: avg data time: 5.44e-02, avg batch time: 0.5033, average train loss: 0.1015
[09/26 16:37:58 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1691, average loss: 4.9649
[09/26 16:37:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 12.00	top5: 54.50	
[09/26 16:37:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 16:38:05 visual_prompt]: Epoch 42 / 100: avg data time: 5.41e-02, avg batch time: 0.5028, average train loss: 0.0636
[09/26 16:38:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1690, average loss: 4.9373
[09/26 16:38:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.50	top5: 53.00	
[09/26 16:38:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 16:38:13 visual_prompt]: Epoch 43 / 100: avg data time: 4.76e-02, avg batch time: 0.4960, average train loss: 0.0467
[09/26 16:38:15 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1686, average loss: 4.9249
[09/26 16:38:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 17.50	top5: 53.50	
[09/26 16:38:15 visual_prompt]: Best epoch 43: best metric: 0.175
[09/26 16:38:15 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 16:38:21 visual_prompt]: Epoch 44 / 100: avg data time: 4.39e-02, avg batch time: 0.4942, average train loss: 0.0349
[09/26 16:38:23 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1689, average loss: 5.0737
[09/26 16:38:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.00	
[09/26 16:38:23 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 16:38:30 visual_prompt]: Epoch 45 / 100: avg data time: 4.13e-02, avg batch time: 0.4918, average train loss: 0.0358
[09/26 16:38:31 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1689, average loss: 5.1631
[09/26 16:38:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 48.50	
[09/26 16:38:31 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 16:38:38 visual_prompt]: Epoch 46 / 100: avg data time: 6.20e-02, avg batch time: 0.5094, average train loss: 0.0366
[09/26 16:38:40 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1693, average loss: 5.1896
[09/26 16:38:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 50.00	
[09/26 16:38:40 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 16:38:47 visual_prompt]: Epoch 47 / 100: avg data time: 5.50e-02, avg batch time: 0.5026, average train loss: 0.0251
[09/26 16:38:48 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1691, average loss: 5.1909
[09/26 16:38:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 48.50	
[09/26 16:38:48 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 16:38:55 visual_prompt]: Epoch 48 / 100: avg data time: 5.54e-02, avg batch time: 0.5026, average train loss: 0.0206
[09/26 16:38:57 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1691, average loss: 5.1678
[09/26 16:38:57 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:38:57 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 16:39:04 visual_prompt]: Epoch 49 / 100: avg data time: 6.45e-02, avg batch time: 0.5121, average train loss: 0.0196
[09/26 16:39:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1691, average loss: 5.1761
[09/26 16:39:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 51.00	
[09/26 16:39:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 16:39:12 visual_prompt]: Epoch 50 / 100: avg data time: 6.06e-02, avg batch time: 0.5088, average train loss: 0.0146
[09/26 16:39:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1691, average loss: 5.1981
[09/26 16:39:14 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.00	
[09/26 16:39:14 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 16:39:20 visual_prompt]: Epoch 51 / 100: avg data time: 4.41e-02, avg batch time: 0.4927, average train loss: 0.0137
[09/26 16:39:22 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1691, average loss: 5.2075
[09/26 16:39:22 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:39:22 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 16:39:29 visual_prompt]: Epoch 52 / 100: avg data time: 5.16e-02, avg batch time: 0.4997, average train loss: 0.0134
[09/26 16:39:30 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1689, average loss: 5.1747
[09/26 16:39:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:39:30 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 16:39:37 visual_prompt]: Epoch 53 / 100: avg data time: 4.98e-02, avg batch time: 0.4980, average train loss: 0.0131
[09/26 16:39:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1688, average loss: 5.1473
[09/26 16:39:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 50.00	
[09/26 16:39:38 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 16:39:45 visual_prompt]: Epoch 54 / 100: avg data time: 4.79e-02, avg batch time: 0.4954, average train loss: 0.0126
[09/26 16:39:47 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1688, average loss: 5.1765
[09/26 16:39:47 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:39:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 16:39:53 visual_prompt]: Epoch 55 / 100: avg data time: 4.86e-02, avg batch time: 0.4980, average train loss: 0.0109
[09/26 16:39:55 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1692, average loss: 5.1979
[09/26 16:39:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.50	
[09/26 16:39:55 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 16:40:02 visual_prompt]: Epoch 56 / 100: avg data time: 4.38e-02, avg batch time: 0.4940, average train loss: 0.0117
[09/26 16:40:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1691, average loss: 5.2137
[09/26 16:40:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:40:03 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 16:40:10 visual_prompt]: Epoch 57 / 100: avg data time: 5.07e-02, avg batch time: 0.4997, average train loss: 0.0112
[09/26 16:40:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1687, average loss: 5.2284
[09/26 16:40:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 50.50	
[09/26 16:40:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 16:40:18 visual_prompt]: Epoch 58 / 100: avg data time: 4.52e-02, avg batch time: 0.4945, average train loss: 0.0106
[09/26 16:40:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1689, average loss: 5.2484
[09/26 16:40:20 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 50.00	
[09/26 16:40:20 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 16:40:26 visual_prompt]: Epoch 59 / 100: avg data time: 5.14e-02, avg batch time: 0.4996, average train loss: 0.0102
[09/26 16:40:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 5.2520
[09/26 16:40:28 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.50	
[09/26 16:40:28 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 16:40:35 visual_prompt]: Epoch 60 / 100: avg data time: 4.62e-02, avg batch time: 0.4952, average train loss: 0.0090
[09/26 16:40:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 5.2482
[09/26 16:40:36 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 50.50	
[09/26 16:40:36 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 16:40:43 visual_prompt]: Epoch 61 / 100: avg data time: 5.60e-02, avg batch time: 0.5041, average train loss: 0.0098
[09/26 16:40:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1693, average loss: 5.2662
[09/26 16:40:45 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 49.50	
[09/26 16:40:45 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 16:40:51 visual_prompt]: Epoch 62 / 100: avg data time: 4.34e-02, avg batch time: 0.4924, average train loss: 0.0096
[09/26 16:40:53 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1688, average loss: 5.3135
[09/26 16:40:53 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 49.50	
[09/26 16:40:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 16:41:00 visual_prompt]: Epoch 63 / 100: avg data time: 4.61e-02, avg batch time: 0.4950, average train loss: 0.0141
[09/26 16:41:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 5.3097
[09/26 16:41:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:41:01 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 16:41:08 visual_prompt]: Epoch 64 / 100: avg data time: 6.64e-02, avg batch time: 0.5152, average train loss: 0.0089
[09/26 16:41:10 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1687, average loss: 5.3256
[09/26 16:41:10 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.50	
[09/26 16:41:10 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 16:41:17 visual_prompt]: Epoch 65 / 100: avg data time: 5.87e-02, avg batch time: 0.5072, average train loss: 0.0087
[09/26 16:41:18 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1688, average loss: 5.3236
[09/26 16:41:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.50	
[09/26 16:41:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 16:41:25 visual_prompt]: Epoch 66 / 100: avg data time: 6.92e-02, avg batch time: 0.5165, average train loss: 0.0075
[09/26 16:41:27 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1686, average loss: 5.3186
[09/26 16:41:27 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.00	top5: 49.00	
[09/26 16:41:27 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 16:41:34 visual_prompt]: Epoch 67 / 100: avg data time: 4.80e-02, avg batch time: 0.4976, average train loss: 0.0092
[09/26 16:41:35 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1686, average loss: 5.3307
[09/26 16:41:35 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 48.50	
[09/26 16:41:35 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 16:41:42 visual_prompt]: Epoch 68 / 100: avg data time: 7.09e-02, avg batch time: 0.5182, average train loss: 0.0080
[09/26 16:41:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1691, average loss: 5.3373
[09/26 16:41:44 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 13.50	top5: 49.00	
[09/26 16:41:44 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 16:41:51 visual_prompt]: Epoch 69 / 100: avg data time: 4.85e-02, avg batch time: 0.4976, average train loss: 0.0082
[09/26 16:41:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1693, average loss: 5.3395
[09/26 16:41:52 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.00	
[09/26 16:41:52 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 16:41:59 visual_prompt]: Epoch 70 / 100: avg data time: 6.64e-02, avg batch time: 0.5140, average train loss: 0.0080
[09/26 16:42:01 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1687, average loss: 5.3334
[09/26 16:42:01 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.50	
[09/26 16:42:01 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 16:42:08 visual_prompt]: Epoch 71 / 100: avg data time: 4.44e-02, avg batch time: 0.4968, average train loss: 0.0072
[09/26 16:42:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1688, average loss: 5.3265
[09/26 16:42:09 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.00	top5: 49.50	
[09/26 16:42:09 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 16:42:16 visual_prompt]: Epoch 72 / 100: avg data time: 5.60e-02, avg batch time: 0.5031, average train loss: 0.0073
[09/26 16:42:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1690, average loss: 5.3271
[09/26 16:42:18 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 49.50	
[09/26 16:42:18 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 16:42:24 visual_prompt]: Epoch 73 / 100: avg data time: 4.39e-02, avg batch time: 0.4939, average train loss: 0.0070
[09/26 16:42:26 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1689, average loss: 5.3267
[09/26 16:42:26 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.00	
[09/26 16:42:26 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 16:42:33 visual_prompt]: Epoch 74 / 100: avg data time: 4.57e-02, avg batch time: 0.4941, average train loss: 0.0077
[09/26 16:42:34 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1690, average loss: 5.3251
[09/26 16:42:34 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 49.50	
[09/26 16:42:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 16:42:41 visual_prompt]: Epoch 75 / 100: avg data time: 4.32e-02, avg batch time: 0.4921, average train loss: 0.0071
[09/26 16:42:42 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1690, average loss: 5.3270
[09/26 16:42:42 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 49.50	
[09/26 16:42:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 16:42:49 visual_prompt]: Epoch 76 / 100: avg data time: 5.02e-02, avg batch time: 0.4989, average train loss: 0.0067
[09/26 16:42:51 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1693, average loss: 5.3294
[09/26 16:42:51 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 49.50	
[09/26 16:42:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 16:42:57 visual_prompt]: Epoch 77 / 100: avg data time: 5.06e-02, avg batch time: 0.4980, average train loss: 0.0068
[09/26 16:42:59 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1687, average loss: 5.3338
[09/26 16:42:59 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 49.50	
[09/26 16:42:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 16:43:06 visual_prompt]: Epoch 78 / 100: avg data time: 4.41e-02, avg batch time: 0.4963, average train loss: 0.0066
[09/26 16:43:07 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1687, average loss: 5.3382
[09/26 16:43:07 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 49.50	
[09/26 16:43:07 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 16:43:14 visual_prompt]: Epoch 79 / 100: avg data time: 5.58e-02, avg batch time: 0.5035, average train loss: 0.0064
[09/26 16:43:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 5.3401
[09/26 16:43:16 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 14.50	top5: 50.00	
[09/26 16:43:16 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 16:43:22 visual_prompt]: Epoch 80 / 100: avg data time: 4.66e-02, avg batch time: 0.4958, average train loss: 0.0065
[09/26 16:43:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1690, average loss: 5.3448
[09/26 16:43:24 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:43:24 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 16:43:31 visual_prompt]: Epoch 81 / 100: avg data time: 5.18e-02, avg batch time: 0.4993, average train loss: 0.0075
[09/26 16:43:32 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1688, average loss: 5.3456
[09/26 16:43:32 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 50.00	
[09/26 16:43:32 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 16:43:39 visual_prompt]: Epoch 82 / 100: avg data time: 5.65e-02, avg batch time: 0.5064, average train loss: 0.0069
[09/26 16:43:41 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1687, average loss: 5.3412
[09/26 16:43:41 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.00	top5: 50.00	
[09/26 16:43:41 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 16:43:48 visual_prompt]: Epoch 83 / 100: avg data time: 6.98e-02, avg batch time: 0.5181, average train loss: 0.0066
[09/26 16:43:49 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1688, average loss: 5.3422
[09/26 16:43:49 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 50.00	
[09/26 16:43:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 16:43:56 visual_prompt]: Epoch 84 / 100: avg data time: 6.33e-02, avg batch time: 0.5127, average train loss: 0.0067
[09/26 16:43:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1690, average loss: 5.3440
[09/26 16:43:58 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:43:58 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 16:44:05 visual_prompt]: Epoch 85 / 100: avg data time: 5.58e-02, avg batch time: 0.5037, average train loss: 0.0068
[09/26 16:44:06 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1688, average loss: 5.3442
[09/26 16:44:06 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:44:06 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 16:44:13 visual_prompt]: Epoch 86 / 100: avg data time: 4.77e-02, avg batch time: 0.4971, average train loss: 0.0065
[09/26 16:44:15 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1689, average loss: 5.3441
[09/26 16:44:15 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:44:15 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 16:44:21 visual_prompt]: Epoch 87 / 100: avg data time: 4.97e-02, avg batch time: 0.4973, average train loss: 0.0072
[09/26 16:44:23 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1687, average loss: 5.3460
[09/26 16:44:23 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:44:23 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 16:44:30 visual_prompt]: Epoch 88 / 100: avg data time: 6.36e-02, avg batch time: 0.5120, average train loss: 0.0064
[09/26 16:44:31 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1688, average loss: 5.3478
[09/26 16:44:31 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:44:31 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 16:44:38 visual_prompt]: Epoch 89 / 100: avg data time: 4.33e-02, avg batch time: 0.4923, average train loss: 0.0061
[09/26 16:44:40 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1696, average loss: 5.3474
[09/26 16:44:40 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:44:40 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 16:44:46 visual_prompt]: Epoch 90 / 100: avg data time: 4.88e-02, avg batch time: 0.4969, average train loss: 0.0061
[09/26 16:44:48 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1688, average loss: 5.3469
[09/26 16:44:48 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:44:48 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 16:44:55 visual_prompt]: Epoch 91 / 100: avg data time: 5.37e-02, avg batch time: 0.5032, average train loss: 0.0065
[09/26 16:44:56 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1689, average loss: 5.3463
[09/26 16:44:56 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:44:56 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 16:45:03 visual_prompt]: Epoch 92 / 100: avg data time: 4.90e-02, avg batch time: 0.4982, average train loss: 0.0065
[09/26 16:45:05 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1691, average loss: 5.3467
[09/26 16:45:05 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:45:05 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 16:45:11 visual_prompt]: Epoch 93 / 100: avg data time: 4.87e-02, avg batch time: 0.4982, average train loss: 0.0070
[09/26 16:45:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1690, average loss: 5.3461
[09/26 16:45:13 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 16.00	top5: 49.50	
[09/26 16:45:13 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 16:45:20 visual_prompt]: Epoch 94 / 100: avg data time: 5.06e-02, avg batch time: 0.5007, average train loss: 0.0068
[09/26 16:45:21 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1689, average loss: 5.3460
[09/26 16:45:21 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:45:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 16:45:28 visual_prompt]: Epoch 95 / 100: avg data time: 4.58e-02, avg batch time: 0.4960, average train loss: 0.0058
[09/26 16:45:30 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1690, average loss: 5.3462
[09/26 16:45:30 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:45:30 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 16:45:36 visual_prompt]: Epoch 96 / 100: avg data time: 5.78e-02, avg batch time: 0.5056, average train loss: 0.0062
[09/26 16:45:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1688, average loss: 5.3463
[09/26 16:45:38 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:45:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 16:45:45 visual_prompt]: Epoch 97 / 100: avg data time: 5.32e-02, avg batch time: 0.5015, average train loss: 0.0074
[09/26 16:45:46 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1689, average loss: 5.3465
[09/26 16:45:46 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:45:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 16:45:53 visual_prompt]: Epoch 98 / 100: avg data time: 4.48e-02, avg batch time: 0.4932, average train loss: 0.0061
[09/26 16:45:55 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1690, average loss: 5.3465
[09/26 16:45:55 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:45:55 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 16:46:02 visual_prompt]: Epoch 99 / 100: avg data time: 5.93e-02, avg batch time: 0.5076, average train loss: 0.0066
[09/26 16:46:03 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 5.3465
[09/26 16:46:03 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
[09/26 16:46:03 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 16:46:10 visual_prompt]: Epoch 100 / 100: avg data time: 5.71e-02, avg batch time: 0.5059, average train loss: 0.0069
[09/26 16:46:11 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1689, average loss: 5.3465
[09/26 16:46:11 visual_prompt]: Classification results with val_vtab-smallnorb(predicted_attribute="label_azimuth"): top1: 15.50	top5: 49.50	
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 289, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 284, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 113, in train
    seed(cfg)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 136, in seed
    torch.manual_seed(SEED)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/torch/random.py", line 36, in manual_seed
    seed = int(seed)
           ^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'tuple'
