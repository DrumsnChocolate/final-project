/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:50:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 06:50:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 06:50:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 06:50:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 06:50:38 visual_prompt]: Training with config:
[09/26 06:50:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 06:50:38 visual_prompt]: Loading training data...
2023-09-26 06:50:38.315294: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-26 06:50:38.361692: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-26 06:50:39.596911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/26 06:50:41 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 06:50:43 visual_prompt]: Number of images: 800
[09/26 06:50:43 visual_prompt]: Number of classes: 45 / 45
[09/26 06:50:43 visual_prompt]: Loading validation data...
[09/26 06:50:43 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 06:50:43 visual_prompt]: Number of images: 200
[09/26 06:50:43 visual_prompt]: Number of classes: 45 / 45
[09/26 06:50:43 visual_prompt]: Constructing models...
[09/26 06:50:46 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 06:50:46 visual_prompt]: tuned percent:0.574
[09/26 06:50:48 visual_prompt]: Device used for model: 0
[09/26 06:50:48 visual_prompt]: Setting up Evaluator...
[09/26 06:50:48 visual_prompt]: Setting up Trainer...
[09/26 06:50:48 visual_prompt]: 	Setting up the optimizer...
[09/26 06:50:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 06:50:59 visual_prompt]: Epoch 1 / 100: avg data time: 1.93e-01, avg batch time: 0.8083, average train loss: 3.8991
[09/26 06:51:00 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1647, average loss: 3.9529
[09/26 06:51:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 06:51:00 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 06:51:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 06:51:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.79e-02, avg batch time: 0.4869, average train loss: 9.5951
[09/26 06:51:08 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1650, average loss: 7.0470
[09/26 06:51:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.00	
[09/26 06:51:08 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 06:51:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 06:51:15 visual_prompt]: Epoch 3 / 100: avg data time: 5.67e-02, avg batch time: 0.4945, average train loss: 11.1870
[09/26 06:51:17 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1649, average loss: 13.2081
[09/26 06:51:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 13.00	
[09/26 06:51:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 06:51:23 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4906, average train loss: 20.6100
[09/26 06:51:25 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1650, average loss: 37.7268
[09/26 06:51:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 06:51:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 06:51:31 visual_prompt]: Epoch 5 / 100: avg data time: 5.21e-02, avg batch time: 0.4910, average train loss: 42.4231
[09/26 06:51:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1657, average loss: 66.4486
[09/26 06:51:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 06:51:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 06:51:39 visual_prompt]: Epoch 6 / 100: avg data time: 5.98e-02, avg batch time: 0.5004, average train loss: 78.8609
[09/26 06:51:41 visual_prompt]: Inference (val):avg data time: 1.68e-05, avg batch time: 0.1658, average loss: 79.2867
[09/26 06:51:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 06:51:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 06:51:48 visual_prompt]: Epoch 7 / 100: avg data time: 5.26e-02, avg batch time: 0.4933, average train loss: 95.7286
[09/26 06:51:49 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1661, average loss: 126.3348
[09/26 06:51:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 06:51:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 06:51:56 visual_prompt]: Epoch 8 / 100: avg data time: 5.05e-02, avg batch time: 0.4938, average train loss: 126.1468
[09/26 06:51:57 visual_prompt]: Inference (val):avg data time: 1.56e-05, avg batch time: 0.1669, average loss: 133.5156
[09/26 06:51:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 06:51:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 06:52:04 visual_prompt]: Epoch 9 / 100: avg data time: 5.66e-02, avg batch time: 0.5000, average train loss: 150.5552
[09/26 06:52:05 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1667, average loss: 168.3409
[09/26 06:52:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 06:52:05 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 06:52:12 visual_prompt]: Epoch 10 / 100: avg data time: 5.29e-02, avg batch time: 0.4960, average train loss: 156.8270
[09/26 06:52:14 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1670, average loss: 163.7919
[09/26 06:52:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 9.50	
[09/26 06:52:14 visual_prompt]: Best epoch 10: best metric: 0.050
[09/26 06:52:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 06:52:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.23e-02, avg batch time: 0.4887, average train loss: 186.0308
[09/26 06:52:22 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1671, average loss: 236.8657
[09/26 06:52:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 06:52:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 06:52:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.66e-02, avg batch time: 0.4906, average train loss: 214.8171
[09/26 06:52:30 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1671, average loss: 222.7809
[09/26 06:52:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 06:52:30 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 06:52:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.78e-02, avg batch time: 0.5022, average train loss: 203.5163
[09/26 06:52:38 visual_prompt]: Inference (val):avg data time: 1.53e-05, avg batch time: 0.1676, average loss: 215.3922
[09/26 06:52:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 06:52:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 06:52:45 visual_prompt]: Epoch 14 / 100: avg data time: 5.55e-02, avg batch time: 0.5009, average train loss: 214.2895
[09/26 06:52:46 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1675, average loss: 242.2290
[09/26 06:52:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 06:52:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 06:52:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.31e-02, avg batch time: 0.4979, average train loss: 257.6968
[09/26 06:52:54 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1676, average loss: 238.4450
[09/26 06:52:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 06:52:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 06:53:01 visual_prompt]: Epoch 16 / 100: avg data time: 4.19e-02, avg batch time: 0.4880, average train loss: 231.9290
[09/26 06:53:02 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1676, average loss: 274.1115
[09/26 06:53:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 06:53:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 06:53:09 visual_prompt]: Epoch 17 / 100: avg data time: 5.65e-02, avg batch time: 0.5013, average train loss: 243.0406
[09/26 06:53:11 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1677, average loss: 245.9425
[09/26 06:53:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 06:53:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 06:53:17 visual_prompt]: Epoch 18 / 100: avg data time: 4.08e-02, avg batch time: 0.4862, average train loss: 281.2258
[09/26 06:53:19 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1672, average loss: 294.3539
[09/26 06:53:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 06:53:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 06:53:25 visual_prompt]: Epoch 19 / 100: avg data time: 4.61e-02, avg batch time: 0.4919, average train loss: 272.2808
[09/26 06:53:27 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1675, average loss: 266.5568
[09/26 06:53:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 16.50	
[09/26 06:53:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 06:53:33 visual_prompt]: Epoch 20 / 100: avg data time: 5.30e-02, avg batch time: 0.4971, average train loss: 295.4923
[09/26 06:53:35 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1673, average loss: 271.4530
[09/26 06:53:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 06:53:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 06:53:42 visual_prompt]: Epoch 21 / 100: avg data time: 6.08e-02, avg batch time: 0.5068, average train loss: 276.8858
[09/26 06:53:43 visual_prompt]: Inference (val):avg data time: 1.58e-05, avg batch time: 0.1671, average loss: 257.3498
[09/26 06:53:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 06:53:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 06:53:50 visual_prompt]: Epoch 22 / 100: avg data time: 4.05e-02, avg batch time: 0.4893, average train loss: 275.5852
[09/26 06:53:51 visual_prompt]: Inference (val):avg data time: 1.61e-05, avg batch time: 0.1671, average loss: 267.8026
[09/26 06:53:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 06:53:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 06:53:58 visual_prompt]: Epoch 23 / 100: avg data time: 5.43e-02, avg batch time: 0.4983, average train loss: 244.6671
[09/26 06:53:59 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1673, average loss: 203.8301
[09/26 06:53:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 06:53:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 06:54:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.27e-02, avg batch time: 0.4880, average train loss: 206.5444
[09/26 06:54:07 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1675, average loss: 224.7812
[09/26 06:54:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.00	
[09/26 06:54:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 06:54:14 visual_prompt]: Epoch 25 / 100: avg data time: 5.94e-02, avg batch time: 0.5031, average train loss: 237.2993
[09/26 06:54:16 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1672, average loss: 231.5695
[09/26 06:54:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 06:54:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 06:54:22 visual_prompt]: Epoch 26 / 100: avg data time: 5.42e-02, avg batch time: 0.4983, average train loss: 211.2640
[09/26 06:54:24 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1671, average loss: 221.3976
[09/26 06:54:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 06:54:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 06:54:31 visual_prompt]: Epoch 27 / 100: avg data time: 5.80e-02, avg batch time: 0.5034, average train loss: 200.2467
[09/26 06:54:32 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1670, average loss: 214.4321
[09/26 06:54:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 06:54:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 06:54:39 visual_prompt]: Epoch 28 / 100: avg data time: 5.50e-02, avg batch time: 0.4984, average train loss: 209.6002
[09/26 06:54:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1670, average loss: 211.9013
[09/26 06:54:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 06:54:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 06:54:47 visual_prompt]: Epoch 29 / 100: avg data time: 5.73e-02, avg batch time: 0.5007, average train loss: 213.9017
[09/26 06:54:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1672, average loss: 240.6980
[09/26 06:54:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 06:54:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 06:54:55 visual_prompt]: Epoch 30 / 100: avg data time: 4.36e-02, avg batch time: 0.4889, average train loss: 237.4509
[09/26 06:54:57 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1671, average loss: 273.7103
[09/26 06:54:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.50	
[09/26 06:54:57 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 06:55:03 visual_prompt]: Epoch 31 / 100: avg data time: 5.56e-02, avg batch time: 0.5000, average train loss: 276.5845
[09/26 06:55:05 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1670, average loss: 279.2131
[09/26 06:55:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.00	
[09/26 06:55:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 06:55:12 visual_prompt]: Epoch 32 / 100: avg data time: 5.25e-02, avg batch time: 0.4956, average train loss: 262.8170
[09/26 06:55:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1668, average loss: 252.7684
[09/26 06:55:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 8.50	
[09/26 06:55:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 06:55:20 visual_prompt]: Epoch 33 / 100: avg data time: 4.79e-02, avg batch time: 0.4918, average train loss: 206.0119
[09/26 06:55:21 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1669, average loss: 182.5786
[09/26 06:55:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 06:55:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 06:55:28 visual_prompt]: Epoch 34 / 100: avg data time: 5.23e-02, avg batch time: 0.4954, average train loss: 202.3056
[09/26 06:55:29 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1667, average loss: 207.8643
[09/26 06:55:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 06:55:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 06:55:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.58e-02, avg batch time: 0.4989, average train loss: 235.3391
[09/26 06:55:38 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1668, average loss: 219.6662
[09/26 06:55:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 06:55:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 06:55:44 visual_prompt]: Epoch 36 / 100: avg data time: 5.73e-02, avg batch time: 0.5005, average train loss: 203.1106
[09/26 06:55:46 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1672, average loss: 201.5565
[09/26 06:55:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 06:55:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 06:55:53 visual_prompt]: Epoch 37 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 224.2233
[09/26 06:55:54 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1669, average loss: 225.4855
[09/26 06:55:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 06:55:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 06:56:01 visual_prompt]: Epoch 38 / 100: avg data time: 4.54e-02, avg batch time: 0.4898, average train loss: 215.4373
[09/26 06:56:02 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1666, average loss: 157.1888
[09/26 06:56:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 06:56:02 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 06:56:09 visual_prompt]: Epoch 39 / 100: avg data time: 6.22e-02, avg batch time: 0.5049, average train loss: 183.9919
[09/26 06:56:10 visual_prompt]: Inference (val):avg data time: 1.50e-05, avg batch time: 0.1666, average loss: 187.8777
[09/26 06:56:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 06:56:10 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 06:56:17 visual_prompt]: Epoch 40 / 100: avg data time: 5.75e-02, avg batch time: 0.5026, average train loss: 198.6354
[09/26 06:56:19 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1666, average loss: 167.8881
[09/26 06:56:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 06:56:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 06:56:25 visual_prompt]: Epoch 41 / 100: avg data time: 5.88e-02, avg batch time: 0.5020, average train loss: 143.5484
[09/26 06:56:27 visual_prompt]: Inference (val):avg data time: 1.57e-05, avg batch time: 0.1668, average loss: 144.8481
[09/26 06:56:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 06:56:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 06:56:34 visual_prompt]: Epoch 42 / 100: avg data time: 5.42e-02, avg batch time: 0.4969, average train loss: 169.9615
[09/26 06:56:35 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1666, average loss: 179.8675
[09/26 06:56:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 06:56:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 06:56:42 visual_prompt]: Epoch 43 / 100: avg data time: 5.74e-02, avg batch time: 0.5004, average train loss: 201.8468
[09/26 06:56:43 visual_prompt]: Inference (val):avg data time: 1.57e-05, avg batch time: 0.1666, average loss: 180.5777
[09/26 06:56:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 06:56:43 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 06:56:50 visual_prompt]: Epoch 44 / 100: avg data time: 5.63e-02, avg batch time: 0.4999, average train loss: 193.9975
[09/26 06:56:51 visual_prompt]: Inference (val):avg data time: 1.48e-05, avg batch time: 0.1665, average loss: 200.4487
[09/26 06:56:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 06:56:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 06:56:58 visual_prompt]: Epoch 45 / 100: avg data time: 5.36e-02, avg batch time: 0.4957, average train loss: 193.5644
[09/26 06:57:00 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1665, average loss: 187.7394
[09/26 06:57:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 06:57:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 06:57:06 visual_prompt]: Epoch 46 / 100: avg data time: 5.23e-02, avg batch time: 0.4958, average train loss: 164.3668
[09/26 06:57:08 visual_prompt]: Inference (val):avg data time: 1.46e-05, avg batch time: 0.1667, average loss: 141.6850
[09/26 06:57:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 6.50	
[09/26 06:57:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 06:57:14 visual_prompt]: Epoch 47 / 100: avg data time: 4.13e-02, avg batch time: 0.4866, average train loss: 143.3754
[09/26 06:57:16 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1666, average loss: 137.7285
[09/26 06:57:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 06:57:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 06:57:22 visual_prompt]: Epoch 48 / 100: avg data time: 5.52e-02, avg batch time: 0.4981, average train loss: 154.5518
[09/26 06:57:24 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1665, average loss: 196.4379
[09/26 06:57:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 06:57:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 06:57:31 visual_prompt]: Epoch 49 / 100: avg data time: 5.69e-02, avg batch time: 0.5002, average train loss: 161.9058
[09/26 06:57:32 visual_prompt]: Inference (val):avg data time: 1.77e-05, avg batch time: 0.1667, average loss: 214.5729
[09/26 06:57:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 06:57:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 06:57:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.35e-02, avg batch time: 0.4960, average train loss: 147.6848
[09/26 06:57:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1669, average loss: 151.6995
[09/26 06:57:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 06:57:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 06:57:47 visual_prompt]: Epoch 51 / 100: avg data time: 4.10e-02, avg batch time: 0.4855, average train loss: 141.2705
[09/26 06:57:48 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1666, average loss: 158.0850
[09/26 06:57:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 06:57:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 06:57:55 visual_prompt]: Epoch 52 / 100: avg data time: 5.52e-02, avg batch time: 0.4985, average train loss: 140.4451
[09/26 06:57:57 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 122.7358
[09/26 06:57:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 06:57:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 06:58:03 visual_prompt]: Epoch 53 / 100: avg data time: 5.26e-02, avg batch time: 0.4950, average train loss: 134.7521
[09/26 06:58:05 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 129.9445
[09/26 06:58:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 06:58:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 06:58:11 visual_prompt]: Epoch 54 / 100: avg data time: 5.32e-02, avg batch time: 0.4960, average train loss: 126.0317
[09/26 06:58:13 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 159.0688
[09/26 06:58:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 06:58:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 06:58:20 visual_prompt]: Epoch 55 / 100: avg data time: 5.70e-02, avg batch time: 0.4995, average train loss: 137.6919
[09/26 06:58:21 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 113.9979
[09/26 06:58:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 06:58:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 06:58:28 visual_prompt]: Epoch 56 / 100: avg data time: 5.62e-02, avg batch time: 0.4987, average train loss: 111.3586
[09/26 06:58:29 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 80.4350
[09/26 06:58:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 06:58:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 06:58:36 visual_prompt]: Epoch 57 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 106.9286
[09/26 06:58:37 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 117.0324
[09/26 06:58:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 06:58:37 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 06:58:44 visual_prompt]: Epoch 58 / 100: avg data time: 4.58e-02, avg batch time: 0.4892, average train loss: 115.4286
[09/26 06:58:46 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1664, average loss: 101.7632
[09/26 06:58:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.50	
[09/26 06:58:46 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 06:58:52 visual_prompt]: Epoch 59 / 100: avg data time: 6.21e-02, avg batch time: 0.5043, average train loss: 108.6594
[09/26 06:58:54 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1663, average loss: 87.7817
[09/26 06:58:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 06:58:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 06:59:01 visual_prompt]: Epoch 60 / 100: avg data time: 6.05e-02, avg batch time: 0.5033, average train loss: 98.2995
[09/26 06:59:02 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 88.6371
[09/26 06:59:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 06:59:02 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 06:59:09 visual_prompt]: Epoch 61 / 100: avg data time: 5.32e-02, avg batch time: 0.4964, average train loss: 83.3167
[09/26 06:59:10 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1665, average loss: 78.8115
[09/26 06:59:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 06:59:10 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 06:59:17 visual_prompt]: Epoch 62 / 100: avg data time: 4.22e-02, avg batch time: 0.4852, average train loss: 80.1839
[09/26 06:59:18 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 80.2518
[09/26 06:59:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 17.00	
[09/26 06:59:18 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 06:59:25 visual_prompt]: Epoch 63 / 100: avg data time: 4.53e-02, avg batch time: 0.4895, average train loss: 82.5216
[09/26 06:59:26 visual_prompt]: Inference (val):avg data time: 1.56e-05, avg batch time: 0.1662, average loss: 81.7900
[09/26 06:59:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 06:59:26 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 06:59:33 visual_prompt]: Epoch 64 / 100: avg data time: 4.83e-02, avg batch time: 0.4907, average train loss: 81.0235
[09/26 06:59:34 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1666, average loss: 99.9397
[09/26 06:59:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 7.50	
[09/26 06:59:34 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 06:59:41 visual_prompt]: Epoch 65 / 100: avg data time: 5.79e-02, avg batch time: 0.4995, average train loss: 87.0707
[09/26 06:59:42 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1662, average loss: 72.5154
[09/26 06:59:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 13.00	
[09/26 06:59:42 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 06:59:49 visual_prompt]: Epoch 66 / 100: avg data time: 4.64e-02, avg batch time: 0.4884, average train loss: 101.7286
[09/26 06:59:50 visual_prompt]: Inference (val):avg data time: 1.68e-05, avg batch time: 0.1661, average loss: 70.3947
[09/26 06:59:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.00	
[09/26 06:59:50 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 06:59:57 visual_prompt]: Epoch 67 / 100: avg data time: 5.62e-02, avg batch time: 0.4983, average train loss: 78.6601
[09/26 06:59:59 visual_prompt]: Inference (val):avg data time: 1.53e-05, avg batch time: 0.1661, average loss: 72.6307
[09/26 06:59:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 06:59:59 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:00:05 visual_prompt]: Epoch 68 / 100: avg data time: 4.76e-02, avg batch time: 0.4913, average train loss: 75.6227
[09/26 07:00:07 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1660, average loss: 73.8021
[09/26 07:00:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.00	
[09/26 07:00:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:00:13 visual_prompt]: Epoch 69 / 100: avg data time: 4.66e-02, avg batch time: 0.4881, average train loss: 73.3098
[09/26 07:00:15 visual_prompt]: Inference (val):avg data time: 1.57e-05, avg batch time: 0.1663, average loss: 70.0658
[09/26 07:00:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 07:00:15 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:00:21 visual_prompt]: Epoch 70 / 100: avg data time: 5.26e-02, avg batch time: 0.4937, average train loss: 67.4785
[09/26 07:00:23 visual_prompt]: Inference (val):avg data time: 1.55e-05, avg batch time: 0.1662, average loss: 57.4867
[09/26 07:00:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:00:23 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:00:30 visual_prompt]: Epoch 71 / 100: avg data time: 5.04e-02, avg batch time: 0.4935, average train loss: 57.0995
[09/26 07:00:31 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1661, average loss: 69.7558
[09/26 07:00:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 07:00:31 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:00:38 visual_prompt]: Epoch 72 / 100: avg data time: 5.55e-02, avg batch time: 0.4980, average train loss: 58.0504
[09/26 07:00:39 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1664, average loss: 62.0381
[09/26 07:00:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:00:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:00:46 visual_prompt]: Epoch 73 / 100: avg data time: 4.48e-02, avg batch time: 0.4875, average train loss: 57.3866
[09/26 07:00:47 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 46.4724
[09/26 07:00:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 07:00:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:00:54 visual_prompt]: Epoch 74 / 100: avg data time: 5.83e-02, avg batch time: 0.5009, average train loss: 51.4913
[09/26 07:00:55 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 50.2147
[09/26 07:00:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:00:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:01:02 visual_prompt]: Epoch 75 / 100: avg data time: 4.40e-02, avg batch time: 0.4872, average train loss: 42.5809
[09/26 07:01:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 41.3712
[09/26 07:01:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 11.00	
[09/26 07:01:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:01:10 visual_prompt]: Epoch 76 / 100: avg data time: 5.73e-02, avg batch time: 0.4994, average train loss: 39.2851
[09/26 07:01:12 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1661, average loss: 40.1204
[09/26 07:01:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:01:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:01:18 visual_prompt]: Epoch 77 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 34.0548
[09/26 07:01:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 30.8365
[09/26 07:01:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:01:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:01:27 visual_prompt]: Epoch 78 / 100: avg data time: 5.42e-02, avg batch time: 0.4968, average train loss: 25.3155
[09/26 07:01:28 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 28.1714
[09/26 07:01:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:01:28 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:01:35 visual_prompt]: Epoch 79 / 100: avg data time: 5.32e-02, avg batch time: 0.4955, average train loss: 25.0928
[09/26 07:01:36 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 21.5313
[09/26 07:01:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:01:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:01:43 visual_prompt]: Epoch 80 / 100: avg data time: 5.55e-02, avg batch time: 0.4969, average train loss: 16.9563
[09/26 07:01:45 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 16.4458
[09/26 07:01:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 11.50	
[09/26 07:01:45 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:01:51 visual_prompt]: Epoch 81 / 100: avg data time: 5.12e-02, avg batch time: 0.4923, average train loss: 13.7049
[09/26 07:01:53 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1659, average loss: 13.6430
[09/26 07:01:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 15.00	
[09/26 07:01:53 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:01:59 visual_prompt]: Epoch 82 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 11.0137
[09/26 07:02:01 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1660, average loss: 9.6415
[09/26 07:02:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 07:02:01 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:02:07 visual_prompt]: Epoch 83 / 100: avg data time: 3.77e-02, avg batch time: 0.4824, average train loss: 10.4400
[09/26 07:02:09 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1664, average loss: 12.0074
[09/26 07:02:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 6.50	
[09/26 07:02:09 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:02:15 visual_prompt]: Epoch 84 / 100: avg data time: 4.81e-02, avg batch time: 0.4911, average train loss: 9.1756
[09/26 07:02:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 5.9361
[09/26 07:02:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.00	
[09/26 07:02:17 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:02:24 visual_prompt]: Epoch 85 / 100: avg data time: 5.62e-02, avg batch time: 0.4980, average train loss: 6.4586
[09/26 07:02:25 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1661, average loss: 7.4663
[09/26 07:02:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 07:02:25 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:02:32 visual_prompt]: Epoch 86 / 100: avg data time: 5.26e-02, avg batch time: 0.4952, average train loss: 7.1318
[09/26 07:02:33 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1660, average loss: 5.3266
[09/26 07:02:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 07:02:33 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:02:40 visual_prompt]: Epoch 87 / 100: avg data time: 5.83e-02, avg batch time: 0.5012, average train loss: 5.3960
[09/26 07:02:41 visual_prompt]: Inference (val):avg data time: 1.64e-05, avg batch time: 0.1659, average loss: 4.7151
[09/26 07:02:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:02:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:02:48 visual_prompt]: Epoch 88 / 100: avg data time: 5.60e-02, avg batch time: 0.4977, average train loss: 4.6424
[09/26 07:02:49 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1658, average loss: 4.6453
[09/26 07:02:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 07:02:49 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:02:56 visual_prompt]: Epoch 89 / 100: avg data time: 5.02e-02, avg batch time: 0.4912, average train loss: 4.6047
[09/26 07:02:58 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1659, average loss: 4.2370
[09/26 07:02:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 07:02:58 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:03:04 visual_prompt]: Epoch 90 / 100: avg data time: 5.97e-02, avg batch time: 0.5003, average train loss: 4.3164
[09/26 07:03:06 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1658, average loss: 4.1995
[09/26 07:03:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 07:03:06 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:03:12 visual_prompt]: Epoch 91 / 100: avg data time: 4.66e-02, avg batch time: 0.4886, average train loss: 4.1719
[09/26 07:03:14 visual_prompt]: Inference (val):avg data time: 1.51e-05, avg batch time: 0.1658, average loss: 4.2197
[09/26 07:03:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:03:14 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:03:20 visual_prompt]: Epoch 92 / 100: avg data time: 5.57e-02, avg batch time: 0.4969, average train loss: 4.1978
[09/26 07:03:22 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1662, average loss: 4.1157
[09/26 07:03:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 6.00	
[09/26 07:03:22 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:03:29 visual_prompt]: Epoch 93 / 100: avg data time: 5.80e-02, avg batch time: 0.4997, average train loss: 4.0524
[09/26 07:03:30 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1658, average loss: 3.8831
[09/26 07:03:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:03:30 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:03:37 visual_prompt]: Epoch 94 / 100: avg data time: 4.37e-02, avg batch time: 0.4854, average train loss: 3.8830
[09/26 07:03:38 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1661, average loss: 3.9088
[09/26 07:03:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:03:38 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:03:45 visual_prompt]: Epoch 95 / 100: avg data time: 5.63e-02, avg batch time: 0.4981, average train loss: 3.8750
[09/26 07:03:46 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1661, average loss: 3.8599
[09/26 07:03:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:03:46 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:03:53 visual_prompt]: Epoch 96 / 100: avg data time: 5.01e-02, avg batch time: 0.4929, average train loss: 3.8392
[09/26 07:03:54 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1658, average loss: 3.8444
[09/26 07:03:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:03:54 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:04:01 visual_prompt]: Epoch 97 / 100: avg data time: 5.46e-02, avg batch time: 0.4968, average train loss: 3.8580
[09/26 07:04:02 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1661, average loss: 3.8644
[09/26 07:04:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 10.00	
[09/26 07:04:02 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:04:09 visual_prompt]: Epoch 98 / 100: avg data time: 6.15e-02, avg batch time: 0.5029, average train loss: 3.8430
[09/26 07:04:11 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1661, average loss: 3.8881
[09/26 07:04:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 07:04:11 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:04:17 visual_prompt]: Epoch 99 / 100: avg data time: 4.81e-02, avg batch time: 0.4911, average train loss: 3.8509
[09/26 07:04:19 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 3.8493
[09/26 07:04:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:04:19 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:04:25 visual_prompt]: Epoch 100 / 100: avg data time: 4.63e-02, avg batch time: 0.4898, average train loss: 3.8015
[09/26 07:04:27 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 3.8205
[09/26 07:04:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:04:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:04:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:04:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:04:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:04:27 visual_prompt]: Training with config:
[09/26 07:04:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:04:27 visual_prompt]: Loading training data...
[09/26 07:04:27 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:04:28 visual_prompt]: Number of images: 800
[09/26 07:04:28 visual_prompt]: Number of classes: 45 / 45
[09/26 07:04:28 visual_prompt]: Loading validation data...
[09/26 07:04:28 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:04:28 visual_prompt]: Number of images: 200
[09/26 07:04:28 visual_prompt]: Number of classes: 45 / 45
[09/26 07:04:28 visual_prompt]: Constructing models...
[09/26 07:04:31 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 07:04:31 visual_prompt]: tuned percent:0.574
[09/26 07:04:31 visual_prompt]: Device used for model: 0
[09/26 07:04:31 visual_prompt]: Setting up Evaluator...
[09/26 07:04:31 visual_prompt]: Setting up Trainer...
[09/26 07:04:31 visual_prompt]: 	Setting up the optimizer...
[09/26 07:04:31 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:04:38 visual_prompt]: Epoch 1 / 100: avg data time: 5.24e-02, avg batch time: 0.4935, average train loss: 3.9006
[09/26 07:04:39 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 07:04:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 07:04:39 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 07:04:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:04:46 visual_prompt]: Epoch 2 / 100: avg data time: 5.79e-02, avg batch time: 0.4982, average train loss: 6.5091
[09/26 07:04:47 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1652, average loss: 32.4508
[09/26 07:04:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 07:04:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:04:54 visual_prompt]: Epoch 3 / 100: avg data time: 5.40e-02, avg batch time: 0.4933, average train loss: 21.3886
[09/26 07:04:56 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1652, average loss: 23.9876
[09/26 07:04:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:04:56 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:05:02 visual_prompt]: Epoch 4 / 100: avg data time: 4.58e-02, avg batch time: 0.4880, average train loss: 23.4332
[09/26 07:05:04 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1656, average loss: 36.2658
[09/26 07:05:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.00	
[09/26 07:05:04 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 07:05:04 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:05:11 visual_prompt]: Epoch 5 / 100: avg data time: 5.69e-02, avg batch time: 0.4987, average train loss: 55.9284
[09/26 07:05:12 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1656, average loss: 56.0104
[09/26 07:05:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:05:12 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:05:19 visual_prompt]: Epoch 6 / 100: avg data time: 5.81e-02, avg batch time: 0.4988, average train loss: 77.7165
[09/26 07:05:20 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1659, average loss: 94.7580
[09/26 07:05:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:05:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:05:27 visual_prompt]: Epoch 7 / 100: avg data time: 5.28e-02, avg batch time: 0.4937, average train loss: 110.8914
[09/26 07:05:28 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1656, average loss: 117.0038
[09/26 07:05:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:05:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:05:35 visual_prompt]: Epoch 8 / 100: avg data time: 5.52e-02, avg batch time: 0.4971, average train loss: 172.1536
[09/26 07:05:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 145.2319
[09/26 07:05:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 7.00	
[09/26 07:05:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:05:44 visual_prompt]: Epoch 9 / 100: avg data time: 6.12e-02, avg batch time: 0.5022, average train loss: 182.2645
[09/26 07:05:45 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1659, average loss: 189.3044
[09/26 07:05:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 07:05:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:05:52 visual_prompt]: Epoch 10 / 100: avg data time: 4.74e-02, avg batch time: 0.4891, average train loss: 240.8894
[09/26 07:05:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 195.3541
[09/26 07:05:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:05:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:06:00 visual_prompt]: Epoch 11 / 100: avg data time: 6.13e-02, avg batch time: 0.5020, average train loss: 216.3986
[09/26 07:06:02 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1659, average loss: 226.3526
[09/26 07:06:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 07:06:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:06:08 visual_prompt]: Epoch 12 / 100: avg data time: 5.68e-02, avg batch time: 0.4980, average train loss: 216.5900
[09/26 07:06:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1659, average loss: 182.8966
[09/26 07:06:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:06:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:06:16 visual_prompt]: Epoch 13 / 100: avg data time: 4.68e-02, avg batch time: 0.4888, average train loss: 199.1861
[09/26 07:06:18 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 214.0321
[09/26 07:06:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.50	
[09/26 07:06:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:06:25 visual_prompt]: Epoch 14 / 100: avg data time: 5.57e-02, avg batch time: 0.4965, average train loss: 241.9266
[09/26 07:06:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 190.3868
[09/26 07:06:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 07:06:26 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:06:33 visual_prompt]: Epoch 15 / 100: avg data time: 5.50e-02, avg batch time: 0.4969, average train loss: 213.0292
[09/26 07:06:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 213.4402
[09/26 07:06:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:06:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:06:41 visual_prompt]: Epoch 16 / 100: avg data time: 5.51e-02, avg batch time: 0.4955, average train loss: 220.2544
[09/26 07:06:43 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 141.1913
[09/26 07:06:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 07:06:43 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:06:49 visual_prompt]: Epoch 17 / 100: avg data time: 5.63e-02, avg batch time: 0.4977, average train loss: 231.9115
[09/26 07:06:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 248.3877
[09/26 07:06:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:06:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:06:58 visual_prompt]: Epoch 18 / 100: avg data time: 5.81e-02, avg batch time: 0.4987, average train loss: 267.3090
[09/26 07:06:59 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 267.9152
[09/26 07:06:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 07:06:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:07:06 visual_prompt]: Epoch 19 / 100: avg data time: 6.00e-02, avg batch time: 0.5006, average train loss: 232.8887
[09/26 07:07:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 237.9412
[09/26 07:07:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:07:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:07:14 visual_prompt]: Epoch 20 / 100: avg data time: 4.41e-02, avg batch time: 0.4862, average train loss: 284.0927
[09/26 07:07:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 239.4948
[09/26 07:07:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 07:07:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:07:22 visual_prompt]: Epoch 21 / 100: avg data time: 6.00e-02, avg batch time: 0.5013, average train loss: 230.7080
[09/26 07:07:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 224.7817
[09/26 07:07:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 07:07:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:07:31 visual_prompt]: Epoch 22 / 100: avg data time: 4.48e-02, avg batch time: 0.4884, average train loss: 232.5439
[09/26 07:07:32 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 245.9155
[09/26 07:07:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 07:07:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:07:39 visual_prompt]: Epoch 23 / 100: avg data time: 4.71e-02, avg batch time: 0.4889, average train loss: 211.7659
[09/26 07:07:40 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1660, average loss: 185.9644
[09/26 07:07:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 07:07:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:07:47 visual_prompt]: Epoch 24 / 100: avg data time: 5.95e-02, avg batch time: 0.5010, average train loss: 228.9205
[09/26 07:07:49 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1659, average loss: 211.7114
[09/26 07:07:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 07:07:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:07:55 visual_prompt]: Epoch 25 / 100: avg data time: 4.93e-02, avg batch time: 0.4916, average train loss: 233.2842
[09/26 07:07:57 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 195.8490
[09/26 07:07:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 07:07:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:08:03 visual_prompt]: Epoch 26 / 100: avg data time: 4.23e-02, avg batch time: 0.4838, average train loss: 229.1293
[09/26 07:08:05 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1658, average loss: 265.2779
[09/26 07:08:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 07:08:05 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:08:12 visual_prompt]: Epoch 27 / 100: avg data time: 5.83e-02, avg batch time: 0.4993, average train loss: 252.3920
[09/26 07:08:13 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 231.4666
[09/26 07:08:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.00	
[09/26 07:08:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:08:20 visual_prompt]: Epoch 28 / 100: avg data time: 6.02e-02, avg batch time: 0.5007, average train loss: 247.0583
[09/26 07:08:22 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 231.2594
[09/26 07:08:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.50	
[09/26 07:08:22 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:08:28 visual_prompt]: Epoch 29 / 100: avg data time: 5.57e-02, avg batch time: 0.4963, average train loss: 259.0084
[09/26 07:08:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 206.5629
[09/26 07:08:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 07:08:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:08:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.63e-02, avg batch time: 0.4979, average train loss: 234.6125
[09/26 07:08:38 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 248.2231
[09/26 07:08:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 07:08:38 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:08:45 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e-02, avg batch time: 0.4936, average train loss: 225.6749
[09/26 07:08:46 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1659, average loss: 190.4942
[09/26 07:08:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.00	
[09/26 07:08:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:08:53 visual_prompt]: Epoch 32 / 100: avg data time: 5.57e-02, avg batch time: 0.4980, average train loss: 193.5334
[09/26 07:08:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 189.8609
[09/26 07:08:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:08:55 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:09:01 visual_prompt]: Epoch 33 / 100: avg data time: 5.55e-02, avg batch time: 0.4967, average train loss: 208.9367
[09/26 07:09:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1656, average loss: 220.4656
[09/26 07:09:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 07:09:03 visual_prompt]: Best epoch 33: best metric: 0.035
[09/26 07:09:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:09:10 visual_prompt]: Epoch 34 / 100: avg data time: 4.10e-02, avg batch time: 0.4830, average train loss: 240.6646
[09/26 07:09:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 193.1293
[09/26 07:09:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:09:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:09:18 visual_prompt]: Epoch 35 / 100: avg data time: 4.96e-02, avg batch time: 0.4906, average train loss: 213.6697
[09/26 07:09:19 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 221.0215
[09/26 07:09:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 8.50	
[09/26 07:09:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:09:26 visual_prompt]: Epoch 36 / 100: avg data time: 4.77e-02, avg batch time: 0.4901, average train loss: 220.7175
[09/26 07:09:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 202.6450
[09/26 07:09:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 07:09:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:09:34 visual_prompt]: Epoch 37 / 100: avg data time: 5.71e-02, avg batch time: 0.4972, average train loss: 219.5998
[09/26 07:09:36 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1658, average loss: 229.7348
[09/26 07:09:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:09:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:09:42 visual_prompt]: Epoch 38 / 100: avg data time: 4.96e-02, avg batch time: 0.4920, average train loss: 236.1674
[09/26 07:09:44 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1657, average loss: 218.6507
[09/26 07:09:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 07:09:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:09:51 visual_prompt]: Epoch 39 / 100: avg data time: 6.01e-02, avg batch time: 0.5018, average train loss: 199.2123
[09/26 07:09:52 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1659, average loss: 176.9000
[09/26 07:09:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 07:09:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:09:59 visual_prompt]: Epoch 40 / 100: avg data time: 5.99e-02, avg batch time: 0.5007, average train loss: 173.3676
[09/26 07:10:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1656, average loss: 158.4433
[09/26 07:10:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:10:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:10:07 visual_prompt]: Epoch 41 / 100: avg data time: 5.33e-02, avg batch time: 0.4954, average train loss: 184.9522
[09/26 07:10:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 180.3386
[09/26 07:10:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 07:10:09 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:10:16 visual_prompt]: Epoch 42 / 100: avg data time: 5.09e-02, avg batch time: 0.4928, average train loss: 222.1928
[09/26 07:10:17 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1660, average loss: 217.4460
[09/26 07:10:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 07:10:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:10:24 visual_prompt]: Epoch 43 / 100: avg data time: 4.58e-02, avg batch time: 0.4870, average train loss: 187.5297
[09/26 07:10:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 238.9077
[09/26 07:10:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 07:10:25 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:10:32 visual_prompt]: Epoch 44 / 100: avg data time: 4.89e-02, avg batch time: 0.4914, average train loss: 211.5376
[09/26 07:10:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 216.7432
[09/26 07:10:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:10:33 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:10:40 visual_prompt]: Epoch 45 / 100: avg data time: 5.28e-02, avg batch time: 0.4950, average train loss: 223.9797
[09/26 07:10:42 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1658, average loss: 198.9406
[09/26 07:10:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 07:10:42 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 07:10:48 visual_prompt]: Epoch 46 / 100: avg data time: 6.04e-02, avg batch time: 0.5011, average train loss: 160.9793
[09/26 07:10:50 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1657, average loss: 181.2839
[09/26 07:10:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 07:10:50 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 07:10:57 visual_prompt]: Epoch 47 / 100: avg data time: 5.68e-02, avg batch time: 0.4972, average train loss: 164.2999
[09/26 07:10:58 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1659, average loss: 166.4442
[09/26 07:10:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:10:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 07:11:05 visual_prompt]: Epoch 48 / 100: avg data time: 4.95e-02, avg batch time: 0.4918, average train loss: 176.4122
[09/26 07:11:06 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1658, average loss: 123.4900
[09/26 07:11:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.50	
[09/26 07:11:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 07:11:13 visual_prompt]: Epoch 49 / 100: avg data time: 4.65e-02, avg batch time: 0.4893, average train loss: 173.9710
[09/26 07:11:15 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1657, average loss: 152.4603
[09/26 07:11:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 13.50	
[09/26 07:11:15 visual_prompt]: Best epoch 49: best metric: 0.055
[09/26 07:11:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 07:11:21 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e-02, avg batch time: 0.4889, average train loss: 129.9667
[09/26 07:11:23 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1658, average loss: 133.0688
[09/26 07:11:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:11:23 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 07:11:30 visual_prompt]: Epoch 51 / 100: avg data time: 5.96e-02, avg batch time: 0.5006, average train loss: 130.0475
[09/26 07:11:31 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1653, average loss: 275.7577
[09/26 07:11:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:11:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 07:11:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.82e-02, avg batch time: 0.5000, average train loss: 157.8720
[09/26 07:11:39 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1659, average loss: 149.6089
[09/26 07:11:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:11:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 07:11:46 visual_prompt]: Epoch 53 / 100: avg data time: 5.71e-02, avg batch time: 0.4987, average train loss: 146.4091
[09/26 07:11:48 visual_prompt]: Inference (val):avg data time: 1.50e-05, avg batch time: 0.1659, average loss: 139.5944
[09/26 07:11:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:11:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 07:11:54 visual_prompt]: Epoch 54 / 100: avg data time: 5.73e-02, avg batch time: 0.4986, average train loss: 135.9700
[09/26 07:11:56 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1658, average loss: 129.2532
[09/26 07:11:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:11:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 07:12:03 visual_prompt]: Epoch 55 / 100: avg data time: 5.17e-02, avg batch time: 0.4929, average train loss: 159.1031
[09/26 07:12:04 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1656, average loss: 174.8252
[09/26 07:12:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 07:12:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 07:12:11 visual_prompt]: Epoch 56 / 100: avg data time: 5.87e-02, avg batch time: 0.5003, average train loss: 192.9697
[09/26 07:12:12 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1654, average loss: 216.2142
[09/26 07:12:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 07:12:12 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 07:12:19 visual_prompt]: Epoch 57 / 100: avg data time: 5.71e-02, avg batch time: 0.4974, average train loss: 128.4792
[09/26 07:12:21 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1655, average loss: 113.6402
[09/26 07:12:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 07:12:21 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 07:12:27 visual_prompt]: Epoch 58 / 100: avg data time: 5.05e-02, avg batch time: 0.4910, average train loss: 128.6217
[09/26 07:12:29 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1659, average loss: 110.1608
[09/26 07:12:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 07:12:29 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 07:12:36 visual_prompt]: Epoch 59 / 100: avg data time: 5.97e-02, avg batch time: 0.5017, average train loss: 131.9137
[09/26 07:12:37 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1658, average loss: 111.0330
[09/26 07:12:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:12:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 07:12:44 visual_prompt]: Epoch 60 / 100: avg data time: 4.47e-02, avg batch time: 0.4864, average train loss: 110.2588
[09/26 07:12:45 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1656, average loss: 103.5375
[09/26 07:12:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.50	
[09/26 07:12:45 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 07:12:52 visual_prompt]: Epoch 61 / 100: avg data time: 5.72e-02, avg batch time: 0.4974, average train loss: 103.3077
[09/26 07:12:54 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1658, average loss: 91.0762
[09/26 07:12:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:12:54 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 07:13:00 visual_prompt]: Epoch 62 / 100: avg data time: 5.40e-02, avg batch time: 0.4947, average train loss: 102.5669
[09/26 07:13:02 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1657, average loss: 78.1746
[09/26 07:13:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 07:13:02 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 07:13:09 visual_prompt]: Epoch 63 / 100: avg data time: 5.73e-02, avg batch time: 0.4977, average train loss: 114.5621
[09/26 07:13:10 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1653, average loss: 87.5580
[09/26 07:13:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 07:13:10 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 07:13:17 visual_prompt]: Epoch 64 / 100: avg data time: 5.95e-02, avg batch time: 0.5001, average train loss: 111.0913
[09/26 07:13:18 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1656, average loss: 119.5154
[09/26 07:13:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.50	
[09/26 07:13:18 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 07:13:25 visual_prompt]: Epoch 65 / 100: avg data time: 6.14e-02, avg batch time: 0.5016, average train loss: 110.3822
[09/26 07:13:27 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1657, average loss: 111.7336
[09/26 07:13:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:13:27 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 07:13:33 visual_prompt]: Epoch 66 / 100: avg data time: 4.10e-02, avg batch time: 0.4848, average train loss: 90.5399
[09/26 07:13:35 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1653, average loss: 118.5220
[09/26 07:13:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:13:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 07:13:42 visual_prompt]: Epoch 67 / 100: avg data time: 5.70e-02, avg batch time: 0.4973, average train loss: 98.9818
[09/26 07:13:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1654, average loss: 94.3856
[09/26 07:13:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:13:43 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:13:50 visual_prompt]: Epoch 68 / 100: avg data time: 5.29e-02, avg batch time: 0.4939, average train loss: 80.0429
[09/26 07:13:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1656, average loss: 57.4855
[09/26 07:13:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 07:13:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:13:58 visual_prompt]: Epoch 69 / 100: avg data time: 5.67e-02, avg batch time: 0.4975, average train loss: 53.1806
[09/26 07:14:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 53.6701
[09/26 07:14:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 15.50	
[09/26 07:14:00 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:14:06 visual_prompt]: Epoch 70 / 100: avg data time: 5.76e-02, avg batch time: 0.4975, average train loss: 55.0470
[09/26 07:14:08 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 71.9952
[09/26 07:14:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:14:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:14:15 visual_prompt]: Epoch 71 / 100: avg data time: 5.39e-02, avg batch time: 0.4947, average train loss: 64.7793
[09/26 07:14:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1656, average loss: 59.5754
[09/26 07:14:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.50	
[09/26 07:14:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:14:23 visual_prompt]: Epoch 72 / 100: avg data time: 5.55e-02, avg batch time: 0.4952, average train loss: 64.9725
[09/26 07:14:24 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1656, average loss: 56.9970
[09/26 07:14:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:14:24 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:14:31 visual_prompt]: Epoch 73 / 100: avg data time: 4.34e-02, avg batch time: 0.4849, average train loss: 61.5211
[09/26 07:14:33 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1654, average loss: 43.0327
[09/26 07:14:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.50	
[09/26 07:14:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:14:39 visual_prompt]: Epoch 74 / 100: avg data time: 5.09e-02, avg batch time: 0.4923, average train loss: 47.4611
[09/26 07:14:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1656, average loss: 52.4882
[09/26 07:14:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 07:14:41 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:14:47 visual_prompt]: Epoch 75 / 100: avg data time: 4.59e-02, avg batch time: 0.4855, average train loss: 45.7532
[09/26 07:14:49 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1656, average loss: 40.6001
[09/26 07:14:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 07:14:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:14:56 visual_prompt]: Epoch 76 / 100: avg data time: 5.49e-02, avg batch time: 0.4946, average train loss: 34.9439
[09/26 07:14:57 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1656, average loss: 33.2470
[09/26 07:14:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 07:14:57 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:15:04 visual_prompt]: Epoch 77 / 100: avg data time: 5.93e-02, avg batch time: 0.5011, average train loss: 26.6180
[09/26 07:15:05 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1653, average loss: 23.0426
[09/26 07:15:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 07:15:06 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:15:12 visual_prompt]: Epoch 78 / 100: avg data time: 5.97e-02, avg batch time: 0.5011, average train loss: 33.8788
[09/26 07:15:14 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1656, average loss: 44.8437
[09/26 07:15:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 07:15:14 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:15:21 visual_prompt]: Epoch 79 / 100: avg data time: 5.90e-02, avg batch time: 0.5005, average train loss: 50.7264
[09/26 07:15:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 53.9372
[09/26 07:15:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 07:15:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:15:29 visual_prompt]: Epoch 80 / 100: avg data time: 5.17e-02, avg batch time: 0.4921, average train loss: 48.8125
[09/26 07:15:30 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1658, average loss: 38.6785
[09/26 07:15:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 16.00	
[09/26 07:15:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:15:37 visual_prompt]: Epoch 81 / 100: avg data time: 4.16e-02, avg batch time: 0.4845, average train loss: 37.6380
[09/26 07:15:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1654, average loss: 46.5653
[09/26 07:15:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 07:15:39 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:15:45 visual_prompt]: Epoch 82 / 100: avg data time: 5.12e-02, avg batch time: 0.4905, average train loss: 25.3466
[09/26 07:15:47 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1656, average loss: 17.1621
[09/26 07:15:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 07:15:47 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:15:53 visual_prompt]: Epoch 83 / 100: avg data time: 5.30e-02, avg batch time: 0.4944, average train loss: 20.5189
[09/26 07:15:55 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1653, average loss: 14.4239
[09/26 07:15:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:15:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:16:02 visual_prompt]: Epoch 84 / 100: avg data time: 4.57e-02, avg batch time: 0.4863, average train loss: 13.2337
[09/26 07:16:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 7.6182
[09/26 07:16:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:16:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:16:10 visual_prompt]: Epoch 85 / 100: avg data time: 5.19e-02, avg batch time: 0.4942, average train loss: 6.2521
[09/26 07:16:11 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1656, average loss: 5.4525
[09/26 07:16:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:16:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:16:18 visual_prompt]: Epoch 86 / 100: avg data time: 5.56e-02, avg batch time: 0.4960, average train loss: 4.8662
[09/26 07:16:20 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1655, average loss: 4.5230
[09/26 07:16:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:16:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:16:26 visual_prompt]: Epoch 87 / 100: avg data time: 5.56e-02, avg batch time: 0.4966, average train loss: 4.3611
[09/26 07:16:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 4.3576
[09/26 07:16:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 07:16:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:16:34 visual_prompt]: Epoch 88 / 100: avg data time: 5.57e-02, avg batch time: 0.4976, average train loss: 4.1433
[09/26 07:16:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 4.1947
[09/26 07:16:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 07:16:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:16:43 visual_prompt]: Epoch 89 / 100: avg data time: 5.75e-02, avg batch time: 0.4978, average train loss: 4.0857
[09/26 07:16:44 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 3.9569
[09/26 07:16:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 07:16:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:16:51 visual_prompt]: Epoch 90 / 100: avg data time: 5.54e-02, avg batch time: 0.4960, average train loss: 4.0782
[09/26 07:16:52 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1656, average loss: 4.0049
[09/26 07:16:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 07:16:52 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:16:59 visual_prompt]: Epoch 91 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 4.0217
[09/26 07:17:01 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1656, average loss: 3.9696
[09/26 07:17:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 07:17:01 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:17:07 visual_prompt]: Epoch 92 / 100: avg data time: 5.48e-02, avg batch time: 0.4974, average train loss: 3.9411
[09/26 07:17:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 3.9056
[09/26 07:17:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 07:17:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:17:16 visual_prompt]: Epoch 93 / 100: avg data time: 5.99e-02, avg batch time: 0.5030, average train loss: 3.9023
[09/26 07:17:17 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1658, average loss: 3.8142
[09/26 07:17:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 07:17:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:17:24 visual_prompt]: Epoch 94 / 100: avg data time: 5.43e-02, avg batch time: 0.4970, average train loss: 3.9514
[09/26 07:17:25 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1657, average loss: 3.9011
[09/26 07:17:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:17:25 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:17:32 visual_prompt]: Epoch 95 / 100: avg data time: 5.18e-02, avg batch time: 0.4935, average train loss: 3.8332
[09/26 07:17:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 3.8233
[09/26 07:17:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:17:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:17:40 visual_prompt]: Epoch 96 / 100: avg data time: 5.56e-02, avg batch time: 0.4972, average train loss: 3.8180
[09/26 07:17:42 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1659, average loss: 3.7905
[09/26 07:17:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:17:42 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:17:49 visual_prompt]: Epoch 97 / 100: avg data time: 5.54e-02, avg batch time: 0.4972, average train loss: 3.7184
[09/26 07:17:50 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 3.6981
[09/26 07:17:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 18.00	
[09/26 07:17:50 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:17:57 visual_prompt]: Epoch 98 / 100: avg data time: 4.78e-02, avg batch time: 0.4902, average train loss: 3.6588
[09/26 07:17:58 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 3.6512
[09/26 07:17:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 22.50	
[09/26 07:17:58 visual_prompt]: Best epoch 98: best metric: 0.070
[09/26 07:17:58 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:18:05 visual_prompt]: Epoch 99 / 100: avg data time: 5.88e-02, avg batch time: 0.5001, average train loss: 3.5894
[09/26 07:18:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 3.6548
[09/26 07:18:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 18.00	
[09/26 07:18:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:18:13 visual_prompt]: Epoch 100 / 100: avg data time: 5.75e-02, avg batch time: 0.4993, average train loss: 3.5537
[09/26 07:18:15 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 3.5572
[09/26 07:18:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 21.50	
[09/26 07:18:15 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:18:15 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:18:15 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:18:15 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:18:15 visual_prompt]: Training with config:
[09/26 07:18:15 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:18:15 visual_prompt]: Loading training data...
[09/26 07:18:15 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:18:16 visual_prompt]: Number of images: 800
[09/26 07:18:16 visual_prompt]: Number of classes: 45 / 45
[09/26 07:18:16 visual_prompt]: Loading validation data...
[09/26 07:18:16 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:18:16 visual_prompt]: Number of images: 200
[09/26 07:18:16 visual_prompt]: Number of classes: 45 / 45
[09/26 07:18:16 visual_prompt]: Constructing models...
[09/26 07:18:19 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 07:18:19 visual_prompt]: tuned percent:0.574
[09/26 07:18:19 visual_prompt]: Device used for model: 0
[09/26 07:18:19 visual_prompt]: Setting up Evaluator...
[09/26 07:18:19 visual_prompt]: Setting up Trainer...
[09/26 07:18:19 visual_prompt]: 	Setting up the optimizer...
[09/26 07:18:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:18:26 visual_prompt]: Epoch 1 / 100: avg data time: 5.89e-02, avg batch time: 0.4998, average train loss: 3.8942
[09/26 07:18:27 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 07:18:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 07:18:27 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 07:18:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:18:34 visual_prompt]: Epoch 2 / 100: avg data time: 5.84e-02, avg batch time: 0.4992, average train loss: 5.0417
[09/26 07:18:35 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1656, average loss: 4.9273
[09/26 07:18:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 07:18:35 visual_prompt]: Best epoch 2: best metric: 0.035
[09/26 07:18:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:18:42 visual_prompt]: Epoch 3 / 100: avg data time: 5.60e-02, avg batch time: 0.4975, average train loss: 7.9307
[09/26 07:18:44 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1656, average loss: 12.2689
[09/26 07:18:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 07:18:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:18:50 visual_prompt]: Epoch 4 / 100: avg data time: 5.53e-02, avg batch time: 0.4963, average train loss: 19.6080
[09/26 07:18:52 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1659, average loss: 40.3696
[09/26 07:18:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:18:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:18:59 visual_prompt]: Epoch 5 / 100: avg data time: 6.25e-02, avg batch time: 0.5027, average train loss: 74.6668
[09/26 07:19:00 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1655, average loss: 108.4134
[09/26 07:19:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:19:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:19:07 visual_prompt]: Epoch 6 / 100: avg data time: 5.60e-02, avg batch time: 0.4963, average train loss: 219.0775
[09/26 07:19:08 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1656, average loss: 217.1293
[09/26 07:19:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 07:19:08 visual_prompt]: Best epoch 6: best metric: 0.040
[09/26 07:19:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:19:15 visual_prompt]: Epoch 7 / 100: avg data time: 4.74e-02, avg batch time: 0.4880, average train loss: 322.7960
[09/26 07:19:17 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1657, average loss: 294.6943
[09/26 07:19:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 15.50	
[09/26 07:19:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:19:23 visual_prompt]: Epoch 8 / 100: avg data time: 5.78e-02, avg batch time: 0.4985, average train loss: 346.0878
[09/26 07:19:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 364.9058
[09/26 07:19:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.00	
[09/26 07:19:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:19:32 visual_prompt]: Epoch 9 / 100: avg data time: 6.02e-02, avg batch time: 0.5004, average train loss: 340.4553
[09/26 07:19:33 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1658, average loss: 374.7805
[09/26 07:19:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 07:19:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:19:40 visual_prompt]: Epoch 10 / 100: avg data time: 5.06e-02, avg batch time: 0.4931, average train loss: 425.6157
[09/26 07:19:41 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1659, average loss: 474.8573
[09/26 07:19:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 07:19:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:19:48 visual_prompt]: Epoch 11 / 100: avg data time: 4.15e-02, avg batch time: 0.4850, average train loss: 468.6693
[09/26 07:19:49 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1655, average loss: 334.4933
[09/26 07:19:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:19:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:19:56 visual_prompt]: Epoch 12 / 100: avg data time: 5.81e-02, avg batch time: 0.4984, average train loss: 218.0632
[09/26 07:19:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 222.8980
[09/26 07:19:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:19:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:20:04 visual_prompt]: Epoch 13 / 100: avg data time: 5.90e-02, avg batch time: 0.4994, average train loss: 339.9934
[09/26 07:20:06 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1657, average loss: 335.5208
[09/26 07:20:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 07:20:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:20:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.42e-02, avg batch time: 0.4858, average train loss: 390.7494
[09/26 07:20:14 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 381.0379
[09/26 07:20:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 07:20:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:20:21 visual_prompt]: Epoch 15 / 100: avg data time: 5.66e-02, avg batch time: 0.4973, average train loss: 344.1368
[09/26 07:20:22 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1657, average loss: 335.5978
[09/26 07:20:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 07:20:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:20:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.28e-02, avg batch time: 0.4930, average train loss: 241.5921
[09/26 07:20:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1659, average loss: 134.6561
[09/26 07:20:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 07:20:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:20:37 visual_prompt]: Epoch 17 / 100: avg data time: 6.49e-02, avg batch time: 0.5053, average train loss: 285.4011
[09/26 07:20:39 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1656, average loss: 426.2946
[09/26 07:20:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:20:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:20:46 visual_prompt]: Epoch 18 / 100: avg data time: 5.73e-02, avg batch time: 0.4977, average train loss: 332.1348
[09/26 07:20:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1657, average loss: 302.2090
[09/26 07:20:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:20:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:20:54 visual_prompt]: Epoch 19 / 100: avg data time: 5.56e-02, avg batch time: 0.4977, average train loss: 309.1893
[09/26 07:20:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 271.5565
[09/26 07:20:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:20:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:21:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.17e-02, avg batch time: 0.4927, average train loss: 345.8163
[09/26 07:21:04 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 396.7921
[09/26 07:21:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 9.50	
[09/26 07:21:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:21:11 visual_prompt]: Epoch 21 / 100: avg data time: 6.55e-02, avg batch time: 0.5068, average train loss: 372.2103
[09/26 07:21:12 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1659, average loss: 266.3186
[09/26 07:21:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:21:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:21:19 visual_prompt]: Epoch 22 / 100: avg data time: 4.48e-02, avg batch time: 0.4877, average train loss: 299.0694
[09/26 07:21:20 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1660, average loss: 309.7129
[09/26 07:21:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 07:21:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:21:27 visual_prompt]: Epoch 23 / 100: avg data time: 5.74e-02, avg batch time: 0.4980, average train loss: 245.7591
[09/26 07:21:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 215.2691
[09/26 07:21:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.50	
[09/26 07:21:28 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:21:35 visual_prompt]: Epoch 24 / 100: avg data time: 4.98e-02, avg batch time: 0.4916, average train loss: 253.2000
[09/26 07:21:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 281.6484
[09/26 07:21:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 07:21:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:21:43 visual_prompt]: Epoch 25 / 100: avg data time: 5.46e-02, avg batch time: 0.4959, average train loss: 242.3986
[09/26 07:21:45 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1659, average loss: 216.4711
[09/26 07:21:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 07:21:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:21:52 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.4992, average train loss: 262.1896
[09/26 07:21:53 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1658, average loss: 211.0005
[09/26 07:21:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.50	
[09/26 07:21:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:22:00 visual_prompt]: Epoch 27 / 100: avg data time: 4.14e-02, avg batch time: 0.4858, average train loss: 243.8771
[09/26 07:22:01 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 264.4316
[09/26 07:22:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:22:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:22:08 visual_prompt]: Epoch 28 / 100: avg data time: 5.04e-02, avg batch time: 0.4917, average train loss: 261.2067
[09/26 07:22:10 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1660, average loss: 253.3306
[09/26 07:22:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 16.50	
[09/26 07:22:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:22:16 visual_prompt]: Epoch 29 / 100: avg data time: 5.48e-02, avg batch time: 0.4963, average train loss: 272.3055
[09/26 07:22:18 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 323.4366
[09/26 07:22:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 07:22:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:22:24 visual_prompt]: Epoch 30 / 100: avg data time: 5.13e-02, avg batch time: 0.4925, average train loss: 278.1634
[09/26 07:22:26 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 244.6063
[09/26 07:22:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 07:22:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:22:33 visual_prompt]: Epoch 31 / 100: avg data time: 5.40e-02, avg batch time: 0.4950, average train loss: 223.6331
[09/26 07:22:34 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 174.3289
[09/26 07:22:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 15.00	
[09/26 07:22:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:22:41 visual_prompt]: Epoch 32 / 100: avg data time: 5.96e-02, avg batch time: 0.5003, average train loss: 243.1212
[09/26 07:22:43 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1657, average loss: 310.2335
[09/26 07:22:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 12.00	
[09/26 07:22:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:22:49 visual_prompt]: Epoch 33 / 100: avg data time: 4.37e-02, avg batch time: 0.4866, average train loss: 295.0388
[09/26 07:22:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 300.5599
[09/26 07:22:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:22:51 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:22:57 visual_prompt]: Epoch 34 / 100: avg data time: 5.01e-02, avg batch time: 0.4927, average train loss: 288.6515
[09/26 07:22:59 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 278.4171
[09/26 07:22:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:22:59 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:23:06 visual_prompt]: Epoch 35 / 100: avg data time: 4.36e-02, avg batch time: 0.4868, average train loss: 227.9129
[09/26 07:23:07 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 274.5501
[09/26 07:23:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 07:23:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:23:14 visual_prompt]: Epoch 36 / 100: avg data time: 5.26e-02, avg batch time: 0.4945, average train loss: 247.2867
[09/26 07:23:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 313.9291
[09/26 07:23:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.50	
[09/26 07:23:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:23:22 visual_prompt]: Epoch 37 / 100: avg data time: 5.55e-02, avg batch time: 0.4982, average train loss: 210.2749
[09/26 07:23:24 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 195.5551
[09/26 07:23:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 07:23:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:23:30 visual_prompt]: Epoch 38 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 272.1737
[09/26 07:23:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 216.0398
[09/26 07:23:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 07:23:32 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:23:39 visual_prompt]: Epoch 39 / 100: avg data time: 4.67e-02, avg batch time: 0.4886, average train loss: 260.6247
[09/26 07:23:40 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 240.1962
[09/26 07:23:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:23:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:23:47 visual_prompt]: Epoch 40 / 100: avg data time: 5.92e-02, avg batch time: 0.5001, average train loss: 234.9996
[09/26 07:23:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 191.1676
[09/26 07:23:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:23:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:23:55 visual_prompt]: Epoch 41 / 100: avg data time: 5.63e-02, avg batch time: 0.4971, average train loss: 184.6289
[09/26 07:23:57 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1658, average loss: 196.2542
[09/26 07:23:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 07:23:57 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:24:03 visual_prompt]: Epoch 42 / 100: avg data time: 5.84e-02, avg batch time: 0.4998, average train loss: 167.0970
[09/26 07:24:05 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 155.9762
[09/26 07:24:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:24:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:24:12 visual_prompt]: Epoch 43 / 100: avg data time: 5.82e-02, avg batch time: 0.4995, average train loss: 166.5111
[09/26 07:24:13 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 187.3088
[09/26 07:24:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 07:24:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:24:20 visual_prompt]: Epoch 44 / 100: avg data time: 4.46e-02, avg batch time: 0.4885, average train loss: 200.6196
[09/26 07:24:22 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 224.0899
[09/26 07:24:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 13.50	
[09/26 07:24:22 visual_prompt]: Best epoch 44: best metric: 0.050
[09/26 07:24:22 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:24:28 visual_prompt]: Epoch 45 / 100: avg data time: 5.65e-02, avg batch time: 0.4981, average train loss: 235.3813
[09/26 07:24:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 233.6266
[09/26 07:24:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:24:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 07:24:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 189.4751
[09/26 07:24:38 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1663, average loss: 185.7880
[09/26 07:24:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:24:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 07:24:45 visual_prompt]: Epoch 47 / 100: avg data time: 5.68e-02, avg batch time: 0.4991, average train loss: 173.7184
[09/26 07:24:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 202.0347
[09/26 07:24:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 07:24:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 07:24:53 visual_prompt]: Epoch 48 / 100: avg data time: 4.78e-02, avg batch time: 0.4914, average train loss: 136.0167
[09/26 07:24:55 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1658, average loss: 201.6381
[09/26 07:24:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 07:24:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 07:25:01 visual_prompt]: Epoch 49 / 100: avg data time: 5.52e-02, avg batch time: 0.4973, average train loss: 168.9680
[09/26 07:25:03 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 140.0186
[09/26 07:25:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:25:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 07:25:10 visual_prompt]: Epoch 50 / 100: avg data time: 6.45e-02, avg batch time: 0.5052, average train loss: 174.0706
[09/26 07:25:11 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1658, average loss: 158.8900
[09/26 07:25:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:25:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 07:25:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.46e-02, avg batch time: 0.4963, average train loss: 135.5084
[09/26 07:25:19 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 166.5172
[09/26 07:25:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 07:25:19 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 07:25:26 visual_prompt]: Epoch 52 / 100: avg data time: 5.47e-02, avg batch time: 0.4956, average train loss: 173.6467
[09/26 07:25:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 141.6420
[09/26 07:25:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 07:25:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 07:25:34 visual_prompt]: Epoch 53 / 100: avg data time: 6.14e-02, avg batch time: 0.5018, average train loss: 144.2961
[09/26 07:25:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 158.1554
[09/26 07:25:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 10.00	
[09/26 07:25:36 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 07:25:43 visual_prompt]: Epoch 54 / 100: avg data time: 4.63e-02, avg batch time: 0.4896, average train loss: 149.8211
[09/26 07:25:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 140.5308
[09/26 07:25:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 07:25:44 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 07:25:51 visual_prompt]: Epoch 55 / 100: avg data time: 5.08e-02, avg batch time: 0.4933, average train loss: 176.5489
[09/26 07:25:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1659, average loss: 155.3329
[09/26 07:25:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 07:25:52 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 07:25:59 visual_prompt]: Epoch 56 / 100: avg data time: 5.84e-02, avg batch time: 0.4997, average train loss: 134.2150
[09/26 07:26:01 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1659, average loss: 120.9915
[09/26 07:26:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:26:01 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 07:26:07 visual_prompt]: Epoch 57 / 100: avg data time: 5.50e-02, avg batch time: 0.4962, average train loss: 114.9906
[09/26 07:26:09 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1660, average loss: 101.1039
[09/26 07:26:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:26:09 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 07:26:15 visual_prompt]: Epoch 58 / 100: avg data time: 4.84e-02, avg batch time: 0.4908, average train loss: 109.6481
[09/26 07:26:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1658, average loss: 121.9169
[09/26 07:26:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 07:26:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 07:26:24 visual_prompt]: Epoch 59 / 100: avg data time: 4.51e-02, avg batch time: 0.4870, average train loss: 103.4985
[09/26 07:26:25 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 103.3093
[09/26 07:26:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 12.00	
[09/26 07:26:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 07:26:32 visual_prompt]: Epoch 60 / 100: avg data time: 4.76e-02, avg batch time: 0.4900, average train loss: 111.1688
[09/26 07:26:33 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 111.0013
[09/26 07:26:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:26:33 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 07:26:40 visual_prompt]: Epoch 61 / 100: avg data time: 5.92e-02, avg batch time: 0.5018, average train loss: 100.0955
[09/26 07:26:41 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 118.9825
[09/26 07:26:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:26:41 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 07:26:48 visual_prompt]: Epoch 62 / 100: avg data time: 5.72e-02, avg batch time: 0.4991, average train loss: 88.8137
[09/26 07:26:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 96.9118
[09/26 07:26:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 8.50	
[09/26 07:26:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 07:26:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.45e-02, avg batch time: 0.4965, average train loss: 88.5129
[09/26 07:26:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 120.1141
[09/26 07:26:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 07:26:58 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 07:27:05 visual_prompt]: Epoch 64 / 100: avg data time: 5.98e-02, avg batch time: 0.5022, average train loss: 94.8605
[09/26 07:27:06 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 98.2646
[09/26 07:27:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:27:06 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 07:27:13 visual_prompt]: Epoch 65 / 100: avg data time: 5.19e-02, avg batch time: 0.4935, average train loss: 120.2579
[09/26 07:27:15 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 128.0404
[09/26 07:27:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:27:15 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 07:27:21 visual_prompt]: Epoch 66 / 100: avg data time: 5.53e-02, avg batch time: 0.4961, average train loss: 100.3740
[09/26 07:27:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 82.8953
[09/26 07:27:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:27:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 07:27:29 visual_prompt]: Epoch 67 / 100: avg data time: 5.57e-02, avg batch time: 0.4973, average train loss: 81.8387
[09/26 07:27:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1660, average loss: 79.1997
[09/26 07:27:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 07:27:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:27:38 visual_prompt]: Epoch 68 / 100: avg data time: 5.79e-02, avg batch time: 0.4993, average train loss: 78.9503
[09/26 07:27:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 73.5011
[09/26 07:27:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 15.50	
[09/26 07:27:39 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:27:46 visual_prompt]: Epoch 69 / 100: avg data time: 4.63e-02, avg batch time: 0.4886, average train loss: 74.4049
[09/26 07:27:48 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 61.4599
[09/26 07:27:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:27:48 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:27:54 visual_prompt]: Epoch 70 / 100: avg data time: 4.73e-02, avg batch time: 0.4903, average train loss: 64.1422
[09/26 07:27:56 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 76.9986
[09/26 07:27:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 07:27:56 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:28:02 visual_prompt]: Epoch 71 / 100: avg data time: 4.59e-02, avg batch time: 0.4886, average train loss: 70.7432
[09/26 07:28:04 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1660, average loss: 60.8545
[09/26 07:28:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.00	
[09/26 07:28:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:28:11 visual_prompt]: Epoch 72 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 54.3710
[09/26 07:28:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1659, average loss: 61.6098
[09/26 07:28:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:28:12 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:28:19 visual_prompt]: Epoch 73 / 100: avg data time: 6.07e-02, avg batch time: 0.5021, average train loss: 58.2855
[09/26 07:28:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 42.6176
[09/26 07:28:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 13.50	
[09/26 07:28:20 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:28:27 visual_prompt]: Epoch 74 / 100: avg data time: 5.79e-02, avg batch time: 0.5006, average train loss: 36.5908
[09/26 07:28:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1658, average loss: 29.8762
[09/26 07:28:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:28:29 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:28:36 visual_prompt]: Epoch 75 / 100: avg data time: 5.74e-02, avg batch time: 0.4976, average train loss: 26.7763
[09/26 07:28:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 24.9946
[09/26 07:28:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:28:37 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:28:44 visual_prompt]: Epoch 76 / 100: avg data time: 5.37e-02, avg batch time: 0.4953, average train loss: 23.5252
[09/26 07:28:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 17.7829
[09/26 07:28:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:28:45 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:28:52 visual_prompt]: Epoch 77 / 100: avg data time: 5.14e-02, avg batch time: 0.4931, average train loss: 16.6936
[09/26 07:28:54 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 11.2257
[09/26 07:28:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 13.00	
[09/26 07:28:54 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:29:00 visual_prompt]: Epoch 78 / 100: avg data time: 5.50e-02, avg batch time: 0.4964, average train loss: 11.2280
[09/26 07:29:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 7.1929
[09/26 07:29:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 07:29:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:29:08 visual_prompt]: Epoch 79 / 100: avg data time: 4.77e-02, avg batch time: 0.4895, average train loss: 6.7168
[09/26 07:29:10 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 5.5135
[09/26 07:29:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 10.00	
[09/26 07:29:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:29:17 visual_prompt]: Epoch 80 / 100: avg data time: 6.28e-02, avg batch time: 0.5031, average train loss: 5.1240
[09/26 07:29:18 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 4.7672
[09/26 07:29:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:29:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:29:25 visual_prompt]: Epoch 81 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 4.5674
[09/26 07:29:26 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1657, average loss: 4.3633
[09/26 07:29:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 07:29:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:29:33 visual_prompt]: Epoch 82 / 100: avg data time: 5.55e-02, avg batch time: 0.4959, average train loss: 4.2289
[09/26 07:29:35 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1659, average loss: 4.2611
[09/26 07:29:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.50	
[09/26 07:29:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:29:41 visual_prompt]: Epoch 83 / 100: avg data time: 5.33e-02, avg batch time: 0.4942, average train loss: 4.1016
[09/26 07:29:43 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 4.0799
[09/26 07:29:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 19.50	
[09/26 07:29:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:29:50 visual_prompt]: Epoch 84 / 100: avg data time: 4.78e-02, avg batch time: 0.4914, average train loss: 4.0043
[09/26 07:29:51 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 3.9481
[09/26 07:29:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 18.00	
[09/26 07:29:51 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:29:58 visual_prompt]: Epoch 85 / 100: avg data time: 5.77e-02, avg batch time: 0.4984, average train loss: 3.9085
[09/26 07:29:59 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1657, average loss: 3.9013
[09/26 07:29:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 15.50	
[09/26 07:29:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:30:06 visual_prompt]: Epoch 86 / 100: avg data time: 4.88e-02, avg batch time: 0.4901, average train loss: 3.8428
[09/26 07:30:08 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1660, average loss: 3.8510
[09/26 07:30:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 19.50	
[09/26 07:30:08 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:30:14 visual_prompt]: Epoch 87 / 100: avg data time: 5.65e-02, avg batch time: 0.4984, average train loss: 3.7095
[09/26 07:30:16 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1658, average loss: 3.7315
[09/26 07:30:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 25.50	
[09/26 07:30:16 visual_prompt]: Best epoch 87: best metric: 0.055
[09/26 07:30:16 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:30:23 visual_prompt]: Epoch 88 / 100: avg data time: 5.53e-02, avg batch time: 0.4967, average train loss: 3.5804
[09/26 07:30:24 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 3.6522
[09/26 07:30:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 21.50	
[09/26 07:30:24 visual_prompt]: Best epoch 88: best metric: 0.095
[09/26 07:30:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:30:31 visual_prompt]: Epoch 89 / 100: avg data time: 5.55e-02, avg batch time: 0.4968, average train loss: 3.5337
[09/26 07:30:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 3.5640
[09/26 07:30:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 28.00	
[09/26 07:30:32 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:30:39 visual_prompt]: Epoch 90 / 100: avg data time: 5.55e-02, avg batch time: 0.4985, average train loss: 3.4546
[09/26 07:30:41 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1659, average loss: 3.4370
[09/26 07:30:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 37.50	
[09/26 07:30:41 visual_prompt]: Best epoch 90: best metric: 0.130
[09/26 07:30:41 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:30:47 visual_prompt]: Epoch 91 / 100: avg data time: 5.26e-02, avg batch time: 0.4944, average train loss: 3.3954
[09/26 07:30:49 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1658, average loss: 3.4617
[09/26 07:30:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 30.00	
[09/26 07:30:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:30:56 visual_prompt]: Epoch 92 / 100: avg data time: 5.71e-02, avg batch time: 0.4980, average train loss: 3.3180
[09/26 07:30:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 3.2761
[09/26 07:30:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 43.00	
[09/26 07:30:57 visual_prompt]: Best epoch 92: best metric: 0.175
[09/26 07:30:57 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:31:04 visual_prompt]: Epoch 93 / 100: avg data time: 5.50e-02, avg batch time: 0.4961, average train loss: 3.2107
[09/26 07:31:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 3.3288
[09/26 07:31:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 39.00	
[09/26 07:31:05 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:31:12 visual_prompt]: Epoch 94 / 100: avg data time: 5.87e-02, avg batch time: 0.5010, average train loss: 3.1395
[09/26 07:31:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 3.2131
[09/26 07:31:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 43.50	
[09/26 07:31:14 visual_prompt]: Best epoch 94: best metric: 0.180
[09/26 07:31:14 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:31:20 visual_prompt]: Epoch 95 / 100: avg data time: 6.00e-02, avg batch time: 0.5010, average train loss: 3.0864
[09/26 07:31:22 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1658, average loss: 3.1853
[09/26 07:31:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 45.50	
[09/26 07:31:22 visual_prompt]: Best epoch 95: best metric: 0.225
[09/26 07:31:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:31:29 visual_prompt]: Epoch 96 / 100: avg data time: 5.71e-02, avg batch time: 0.4995, average train loss: 3.0430
[09/26 07:31:30 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1659, average loss: 3.1683
[09/26 07:31:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 44.00	
[09/26 07:31:30 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:31:37 visual_prompt]: Epoch 97 / 100: avg data time: 6.09e-02, avg batch time: 0.5014, average train loss: 2.9927
[09/26 07:31:39 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 3.1187
[09/26 07:31:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 48.00	
[09/26 07:31:39 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:31:45 visual_prompt]: Epoch 98 / 100: avg data time: 5.77e-02, avg batch time: 0.4983, average train loss: 2.9749
[09/26 07:31:47 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1658, average loss: 3.1213
[09/26 07:31:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 49.50	
[09/26 07:31:47 visual_prompt]: Best epoch 98: best metric: 0.240
[09/26 07:31:47 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:31:54 visual_prompt]: Epoch 99 / 100: avg data time: 5.68e-02, avg batch time: 0.4974, average train loss: 2.9467
[09/26 07:31:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 3.1106
[09/26 07:31:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 49.00	
[09/26 07:31:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:32:02 visual_prompt]: Epoch 100 / 100: avg data time: 4.78e-02, avg batch time: 0.4909, average train loss: 2.9604
[09/26 07:32:03 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1659, average loss: 3.1121
[09/26 07:32:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 48.50	
[09/26 07:32:03 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:32:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:32:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:32:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:32:03 visual_prompt]: Training with config:
[09/26 07:32:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr50.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:32:03 visual_prompt]: Loading training data...
[09/26 07:32:03 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:32:05 visual_prompt]: Number of images: 800
[09/26 07:32:05 visual_prompt]: Number of classes: 45 / 45
[09/26 07:32:05 visual_prompt]: Loading validation data...
[09/26 07:32:05 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:32:05 visual_prompt]: Number of images: 200
[09/26 07:32:05 visual_prompt]: Number of classes: 45 / 45
[09/26 07:32:05 visual_prompt]: Constructing models...
[09/26 07:32:07 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 07:32:07 visual_prompt]: tuned percent:0.574
[09/26 07:32:07 visual_prompt]: Device used for model: 0
[09/26 07:32:07 visual_prompt]: Setting up Evaluator...
[09/26 07:32:07 visual_prompt]: Setting up Trainer...
[09/26 07:32:07 visual_prompt]: 	Setting up the optimizer...
[09/26 07:32:07 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:32:14 visual_prompt]: Epoch 1 / 100: avg data time: 6.27e-02, avg batch time: 0.5032, average train loss: 3.8871
[09/26 07:32:16 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1653, average loss: 3.9529
[09/26 07:32:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 07:32:16 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 07:32:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[09/26 07:32:23 visual_prompt]: Epoch 2 / 100: avg data time: 6.33e-02, avg batch time: 0.5027, average train loss: 5.4646
[09/26 07:32:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1654, average loss: 5.9144
[09/26 07:32:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:32:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[09/26 07:32:31 visual_prompt]: Epoch 3 / 100: avg data time: 4.64e-02, avg batch time: 0.4885, average train loss: 7.5243
[09/26 07:32:32 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1654, average loss: 6.9666
[09/26 07:32:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 14.00	
[09/26 07:32:32 visual_prompt]: Best epoch 3: best metric: 0.040
[09/26 07:32:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[09/26 07:32:39 visual_prompt]: Epoch 4 / 100: avg data time: 4.83e-02, avg batch time: 0.4901, average train loss: 16.2301
[09/26 07:32:40 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1653, average loss: 24.1138
[09/26 07:32:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 07:32:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[09/26 07:32:47 visual_prompt]: Epoch 5 / 100: avg data time: 4.95e-02, avg batch time: 0.4915, average train loss: 29.4871
[09/26 07:32:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1654, average loss: 36.0871
[09/26 07:32:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 07:32:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[09/26 07:32:56 visual_prompt]: Epoch 6 / 100: avg data time: 6.60e-02, avg batch time: 0.5057, average train loss: 49.5117
[09/26 07:32:57 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1655, average loss: 75.9579
[09/26 07:32:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 07:32:57 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[09/26 07:33:04 visual_prompt]: Epoch 7 / 100: avg data time: 5.69e-02, avg batch time: 0.4967, average train loss: 92.3750
[09/26 07:33:05 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1652, average loss: 104.8326
[09/26 07:33:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 07:33:05 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[09/26 07:33:12 visual_prompt]: Epoch 8 / 100: avg data time: 5.49e-02, avg batch time: 0.4948, average train loss: 161.3302
[09/26 07:33:14 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1653, average loss: 149.1542
[09/26 07:33:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:33:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[09/26 07:33:20 visual_prompt]: Epoch 9 / 100: avg data time: 5.74e-02, avg batch time: 0.4984, average train loss: 183.4445
[09/26 07:33:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1653, average loss: 186.4801
[09/26 07:33:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:33:22 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[09/26 07:33:29 visual_prompt]: Epoch 10 / 100: avg data time: 5.57e-02, avg batch time: 0.4955, average train loss: 210.5693
[09/26 07:33:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1655, average loss: 257.1790
[09/26 07:33:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 07:33:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[09/26 07:33:37 visual_prompt]: Epoch 11 / 100: avg data time: 6.12e-02, avg batch time: 0.5007, average train loss: 234.9600
[09/26 07:33:39 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1666, average loss: 301.2236
[09/26 07:33:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 07:33:39 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[09/26 07:33:45 visual_prompt]: Epoch 12 / 100: avg data time: 5.39e-02, avg batch time: 0.4934, average train loss: 313.9710
[09/26 07:33:47 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1656, average loss: 330.2080
[09/26 07:33:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:33:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[09/26 07:33:54 visual_prompt]: Epoch 13 / 100: avg data time: 5.75e-02, avg batch time: 0.4986, average train loss: 295.3059
[09/26 07:33:55 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1655, average loss: 319.1963
[09/26 07:33:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 6.50	
[09/26 07:33:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[09/26 07:34:02 visual_prompt]: Epoch 14 / 100: avg data time: 4.66e-02, avg batch time: 0.4887, average train loss: 292.1904
[09/26 07:34:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1657, average loss: 256.4421
[09/26 07:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 07:34:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[09/26 07:34:10 visual_prompt]: Epoch 15 / 100: avg data time: 5.43e-02, avg batch time: 0.4953, average train loss: 262.9574
[09/26 07:34:11 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 273.3489
[09/26 07:34:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:34:11 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[09/26 07:34:18 visual_prompt]: Epoch 16 / 100: avg data time: 5.60e-02, avg batch time: 0.4978, average train loss: 234.2062
[09/26 07:34:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 245.1521
[09/26 07:34:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:34:20 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[09/26 07:34:27 visual_prompt]: Epoch 17 / 100: avg data time: 5.66e-02, avg batch time: 0.4966, average train loss: 205.3242
[09/26 07:34:28 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1657, average loss: 179.3397
[09/26 07:34:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 07:34:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[09/26 07:34:35 visual_prompt]: Epoch 18 / 100: avg data time: 5.73e-02, avg batch time: 0.4972, average train loss: 162.0318
[09/26 07:34:36 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1657, average loss: 173.3789
[09/26 07:34:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:34:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[09/26 07:34:43 visual_prompt]: Epoch 19 / 100: avg data time: 6.23e-02, avg batch time: 0.5021, average train loss: 172.8427
[09/26 07:34:45 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1658, average loss: 192.2192
[09/26 07:34:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:34:45 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[09/26 07:34:52 visual_prompt]: Epoch 20 / 100: avg data time: 6.19e-02, avg batch time: 0.5022, average train loss: 181.6990
[09/26 07:34:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1655, average loss: 177.0819
[09/26 07:34:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:34:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[09/26 07:35:00 visual_prompt]: Epoch 21 / 100: avg data time: 5.72e-02, avg batch time: 0.4977, average train loss: 173.1770
[09/26 07:35:01 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1656, average loss: 161.7053
[09/26 07:35:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.50	
[09/26 07:35:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[09/26 07:35:08 visual_prompt]: Epoch 22 / 100: avg data time: 5.60e-02, avg batch time: 0.4972, average train loss: 147.1547
[09/26 07:35:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1658, average loss: 124.7250
[09/26 07:35:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 07:35:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[09/26 07:35:16 visual_prompt]: Epoch 23 / 100: avg data time: 5.57e-02, avg batch time: 0.4965, average train loss: 123.0745
[09/26 07:35:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 131.8453
[09/26 07:35:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:35:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[09/26 07:35:25 visual_prompt]: Epoch 24 / 100: avg data time: 5.16e-02, avg batch time: 0.4925, average train loss: 116.0896
[09/26 07:35:26 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1656, average loss: 107.5559
[09/26 07:35:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.00	
[09/26 07:35:26 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[09/26 07:35:33 visual_prompt]: Epoch 25 / 100: avg data time: 4.99e-02, avg batch time: 0.4915, average train loss: 107.8466
[09/26 07:35:35 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 97.6857
[09/26 07:35:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:35:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[09/26 07:35:41 visual_prompt]: Epoch 26 / 100: avg data time: 5.40e-02, avg batch time: 0.4946, average train loss: 100.7848
[09/26 07:35:43 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 91.1591
[09/26 07:35:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:35:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[09/26 07:35:50 visual_prompt]: Epoch 27 / 100: avg data time: 5.27e-02, avg batch time: 0.4940, average train loss: 93.8053
[09/26 07:35:51 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1656, average loss: 90.8038
[09/26 07:35:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:35:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[09/26 07:35:58 visual_prompt]: Epoch 28 / 100: avg data time: 6.14e-02, avg batch time: 0.5019, average train loss: 88.6311
[09/26 07:36:00 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1656, average loss: 74.8473
[09/26 07:36:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 16.50	
[09/26 07:36:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[09/26 07:36:06 visual_prompt]: Epoch 29 / 100: avg data time: 5.69e-02, avg batch time: 0.4997, average train loss: 94.1889
[09/26 07:36:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1657, average loss: 97.3269
[09/26 07:36:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 07:36:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[09/26 07:36:15 visual_prompt]: Epoch 30 / 100: avg data time: 4.76e-02, avg batch time: 0.4885, average train loss: 88.0944
[09/26 07:36:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1659, average loss: 77.9735
[09/26 07:36:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 07:36:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[09/26 07:36:23 visual_prompt]: Epoch 31 / 100: avg data time: 5.68e-02, avg batch time: 0.4974, average train loss: 77.9019
[09/26 07:36:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 80.0735
[09/26 07:36:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 18.00	
[09/26 07:36:24 visual_prompt]: Best epoch 31: best metric: 0.055
[09/26 07:36:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[09/26 07:36:31 visual_prompt]: Epoch 32 / 100: avg data time: 5.59e-02, avg batch time: 0.4965, average train loss: 84.9473
[09/26 07:36:33 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 86.0528
[09/26 07:36:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 11.00	
[09/26 07:36:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[09/26 07:36:39 visual_prompt]: Epoch 33 / 100: avg data time: 5.78e-02, avg batch time: 0.4991, average train loss: 73.2259
[09/26 07:36:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 68.9726
[09/26 07:36:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 13.50	
[09/26 07:36:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[09/26 07:36:48 visual_prompt]: Epoch 34 / 100: avg data time: 5.75e-02, avg batch time: 0.4994, average train loss: 61.2883
[09/26 07:36:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1659, average loss: 53.0544
[09/26 07:36:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 17.50	
[09/26 07:36:49 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[09/26 07:36:56 visual_prompt]: Epoch 35 / 100: avg data time: 5.58e-02, avg batch time: 0.4975, average train loss: 45.6395
[09/26 07:36:57 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1661, average loss: 46.4124
[09/26 07:36:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 18.50	
[09/26 07:36:57 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[09/26 07:37:04 visual_prompt]: Epoch 36 / 100: avg data time: 6.27e-02, avg batch time: 0.5035, average train loss: 47.3444
[09/26 07:37:06 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1660, average loss: 42.2970
[09/26 07:37:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 14.00	
[09/26 07:37:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[09/26 07:37:13 visual_prompt]: Epoch 37 / 100: avg data time: 4.80e-02, avg batch time: 0.4896, average train loss: 52.0605
[09/26 07:37:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1658, average loss: 52.5392
[09/26 07:37:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 16.50	
[09/26 07:37:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[09/26 07:37:21 visual_prompt]: Epoch 38 / 100: avg data time: 5.81e-02, avg batch time: 0.4988, average train loss: 44.9594
[09/26 07:37:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1660, average loss: 43.4401
[09/26 07:37:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 16.50	
[09/26 07:37:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[09/26 07:37:29 visual_prompt]: Epoch 39 / 100: avg data time: 5.21e-02, avg batch time: 0.4946, average train loss: 34.1586
[09/26 07:37:31 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1658, average loss: 32.5971
[09/26 07:37:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.00	top5: 23.00	
[09/26 07:37:31 visual_prompt]: Best epoch 39: best metric: 0.100
[09/26 07:37:31 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[09/26 07:37:37 visual_prompt]: Epoch 40 / 100: avg data time: 5.15e-02, avg batch time: 0.4931, average train loss: 34.3698
[09/26 07:37:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1660, average loss: 34.7166
[09/26 07:37:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 15.50	
[09/26 07:37:39 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[09/26 07:37:46 visual_prompt]: Epoch 41 / 100: avg data time: 5.81e-02, avg batch time: 0.4991, average train loss: 29.8863
[09/26 07:37:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 37.4757
[09/26 07:37:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 18.00	
[09/26 07:37:47 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[09/26 07:37:54 visual_prompt]: Epoch 42 / 100: avg data time: 5.23e-02, avg batch time: 0.4944, average train loss: 29.7673
[09/26 07:37:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1659, average loss: 25.3892
[09/26 07:37:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 23.50	
[09/26 07:37:56 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[09/26 07:38:02 visual_prompt]: Epoch 43 / 100: avg data time: 5.36e-02, avg batch time: 0.4955, average train loss: 19.1042
[09/26 07:38:04 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 19.8265
[09/26 07:38:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 21.50	
[09/26 07:38:04 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[09/26 07:38:11 visual_prompt]: Epoch 44 / 100: avg data time: 6.52e-02, avg batch time: 0.5069, average train loss: 16.6196
[09/26 07:38:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1659, average loss: 21.5480
[09/26 07:38:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 24.50	
[09/26 07:38:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[09/26 07:38:19 visual_prompt]: Epoch 45 / 100: avg data time: 4.62e-02, avg batch time: 0.4887, average train loss: 13.8086
[09/26 07:38:20 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 19.5956
[09/26 07:38:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 32.00	
[09/26 07:38:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[09/26 07:38:27 visual_prompt]: Epoch 46 / 100: avg data time: 5.24e-02, avg batch time: 0.4937, average train loss: 13.5803
[09/26 07:38:29 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1659, average loss: 13.3954
[09/26 07:38:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 32.50	
[09/26 07:38:29 visual_prompt]: Best epoch 46: best metric: 0.140
[09/26 07:38:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[09/26 07:38:35 visual_prompt]: Epoch 47 / 100: avg data time: 5.56e-02, avg batch time: 0.4969, average train loss: 10.5852
[09/26 07:38:37 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1659, average loss: 12.4419
[09/26 07:38:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.50	top5: 32.50	
[09/26 07:38:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[09/26 07:38:44 visual_prompt]: Epoch 48 / 100: avg data time: 5.17e-02, avg batch time: 0.4950, average train loss: 12.5283
[09/26 07:38:45 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1659, average loss: 13.6538
[09/26 07:38:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.50	top5: 31.50	
[09/26 07:38:45 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[09/26 07:38:52 visual_prompt]: Epoch 49 / 100: avg data time: 5.95e-02, avg batch time: 0.5001, average train loss: 9.5280
[09/26 07:38:54 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 12.2163
[09/26 07:38:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 35.50	
[09/26 07:38:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[09/26 07:39:00 visual_prompt]: Epoch 50 / 100: avg data time: 5.34e-02, avg batch time: 0.4960, average train loss: 8.0649
[09/26 07:39:02 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1658, average loss: 12.3925
[09/26 07:39:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.00	top5: 35.00	
[09/26 07:39:02 visual_prompt]: Best epoch 50: best metric: 0.170
[09/26 07:39:02 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[09/26 07:39:09 visual_prompt]: Epoch 51 / 100: avg data time: 6.12e-02, avg batch time: 0.5022, average train loss: 8.9276
[09/26 07:39:10 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1658, average loss: 12.1870
[09/26 07:39:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 26.50	
[09/26 07:39:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[09/26 07:39:17 visual_prompt]: Epoch 52 / 100: avg data time: 4.60e-02, avg batch time: 0.4899, average train loss: 6.7071
[09/26 07:39:18 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1659, average loss: 10.9669
[09/26 07:39:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 32.50	
[09/26 07:39:18 visual_prompt]: Best epoch 52: best metric: 0.175
[09/26 07:39:18 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[09/26 07:39:25 visual_prompt]: Epoch 53 / 100: avg data time: 6.28e-02, avg batch time: 0.5046, average train loss: 7.5724
[09/26 07:39:27 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1658, average loss: 11.1048
[09/26 07:39:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 34.50	
[09/26 07:39:27 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[09/26 07:39:34 visual_prompt]: Epoch 54 / 100: avg data time: 6.51e-02, avg batch time: 0.5060, average train loss: 7.6624
[09/26 07:39:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 10.4909
[09/26 07:39:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 38.00	
[09/26 07:39:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[09/26 07:39:42 visual_prompt]: Epoch 55 / 100: avg data time: 5.64e-02, avg batch time: 0.4991, average train loss: 7.3204
[09/26 07:39:43 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 8.6558
[09/26 07:39:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 43.50	
[09/26 07:39:43 visual_prompt]: Best epoch 55: best metric: 0.180
[09/26 07:39:43 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[09/26 07:39:50 visual_prompt]: Epoch 56 / 100: avg data time: 5.92e-02, avg batch time: 0.5008, average train loss: 7.1611
[09/26 07:39:52 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 8.4595
[09/26 07:39:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 39.50	
[09/26 07:39:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[09/26 07:39:59 visual_prompt]: Epoch 57 / 100: avg data time: 5.78e-02, avg batch time: 0.4985, average train loss: 6.2299
[09/26 07:40:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 10.1202
[09/26 07:40:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.00	top5: 33.00	
[09/26 07:40:00 visual_prompt]: Training 58 / 100 epoch, with learning rate 23.256088156396867
[09/26 07:40:07 visual_prompt]: Epoch 58 / 100: avg data time: 4.36e-02, avg batch time: 0.4861, average train loss: 5.9958
[09/26 07:40:08 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 10.5722
[09/26 07:40:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 39.00	
[09/26 07:40:08 visual_prompt]: Training 59 / 100 epoch, with learning rate 22.38678841830867
[09/26 07:40:15 visual_prompt]: Epoch 59 / 100: avg data time: 5.32e-02, avg batch time: 0.4957, average train loss: 5.3893
[09/26 07:40:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 10.3092
[09/26 07:40:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 38.00	
[09/26 07:40:16 visual_prompt]: Training 60 / 100 epoch, with learning rate 21.52067247599837
[09/26 07:40:23 visual_prompt]: Epoch 60 / 100: avg data time: 5.39e-02, avg batch time: 0.4958, average train loss: 5.9183
[09/26 07:40:25 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 9.4696
[09/26 07:40:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 41.50	
[09/26 07:40:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 20.65879555832674
[09/26 07:40:31 visual_prompt]: Epoch 61 / 100: avg data time: 4.43e-02, avg batch time: 0.4867, average train loss: 5.1969
[09/26 07:40:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 8.1005
[09/26 07:40:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 39.50	
[09/26 07:40:33 visual_prompt]: Best epoch 61: best metric: 0.235
[09/26 07:40:33 visual_prompt]: Training 62 / 100 epoch, with learning rate 19.80220772955602
[09/26 07:40:40 visual_prompt]: Epoch 62 / 100: avg data time: 5.87e-02, avg batch time: 0.4994, average train loss: 5.5543
[09/26 07:40:41 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1657, average loss: 7.6437
[09/26 07:40:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 42.00	
[09/26 07:40:41 visual_prompt]: Training 63 / 100 epoch, with learning rate 18.95195261000831
[09/26 07:40:48 visual_prompt]: Epoch 63 / 100: avg data time: 4.60e-02, avg batch time: 0.4898, average train loss: 5.2570
[09/26 07:40:49 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1660, average loss: 5.3824
[09/26 07:40:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 28.50	top5: 53.00	
[09/26 07:40:49 visual_prompt]: Best epoch 63: best metric: 0.285
[09/26 07:40:49 visual_prompt]: Training 64 / 100 epoch, with learning rate 18.10906610457502
[09/26 07:40:56 visual_prompt]: Epoch 64 / 100: avg data time: 5.71e-02, avg batch time: 0.4979, average train loss: 4.9886
[09/26 07:40:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 8.0447
[09/26 07:40:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 45.50	
[09/26 07:40:58 visual_prompt]: Training 65 / 100 epoch, with learning rate 17.274575140626318
[09/26 07:41:04 visual_prompt]: Epoch 65 / 100: avg data time: 4.72e-02, avg batch time: 0.4910, average train loss: 4.8888
[09/26 07:41:06 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1659, average loss: 8.0160
[09/26 07:41:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.00	top5: 42.50	
[09/26 07:41:06 visual_prompt]: Training 66 / 100 epoch, with learning rate 16.449496416858285
[09/26 07:41:13 visual_prompt]: Epoch 66 / 100: avg data time: 5.33e-02, avg batch time: 0.4960, average train loss: 4.6466
[09/26 07:41:14 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1659, average loss: 7.6075
[09/26 07:41:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.00	top5: 41.50	
[09/26 07:41:14 visual_prompt]: Training 67 / 100 epoch, with learning rate 15.634835164602197
[09/26 07:41:21 visual_prompt]: Epoch 67 / 100: avg data time: 4.94e-02, avg batch time: 0.4927, average train loss: 4.6283
[09/26 07:41:22 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1659, average loss: 8.4508
[09/26 07:41:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.50	top5: 40.00	
[09/26 07:41:22 visual_prompt]: Training 68 / 100 epoch, with learning rate 14.831583923104999
[09/26 07:41:29 visual_prompt]: Epoch 68 / 100: avg data time: 5.92e-02, avg batch time: 0.5002, average train loss: 4.5523
[09/26 07:41:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 7.1359
[09/26 07:41:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 46.00	
[09/26 07:41:31 visual_prompt]: Training 69 / 100 epoch, with learning rate 14.040721330273062
[09/26 07:41:37 visual_prompt]: Epoch 69 / 100: avg data time: 4.68e-02, avg batch time: 0.4879, average train loss: 4.2640
[09/26 07:41:39 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1659, average loss: 8.1671
[09/26 07:41:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.00	top5: 44.50	
[09/26 07:41:39 visual_prompt]: Training 70 / 100 epoch, with learning rate 13.263210930352736
[09/26 07:41:46 visual_prompt]: Epoch 70 / 100: avg data time: 5.62e-02, avg batch time: 0.4979, average train loss: 4.2721
[09/26 07:41:47 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 7.6818
[09/26 07:41:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 45.50	
[09/26 07:41:47 visual_prompt]: Training 71 / 100 epoch, with learning rate 12.500000000000005
[09/26 07:41:54 visual_prompt]: Epoch 71 / 100: avg data time: 5.86e-02, avg batch time: 0.5010, average train loss: 4.2701
[09/26 07:41:56 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1659, average loss: 7.6355
[09/26 07:41:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.00	top5: 44.50	
[09/26 07:41:56 visual_prompt]: Training 72 / 100 epoch, with learning rate 11.75201839416988
[09/26 07:42:02 visual_prompt]: Epoch 72 / 100: avg data time: 5.85e-02, avg batch time: 0.4994, average train loss: 3.9175
[09/26 07:42:04 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1659, average loss: 7.7629
[09/26 07:42:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 45.50	
[09/26 07:42:04 visual_prompt]: Training 73 / 100 epoch, with learning rate 11.020177413231332
[09/26 07:42:11 visual_prompt]: Epoch 73 / 100: avg data time: 5.44e-02, avg batch time: 0.4962, average train loss: 3.6669
[09/26 07:42:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 8.0530
[09/26 07:42:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.00	top5: 42.50	
[09/26 07:42:12 visual_prompt]: Training 74 / 100 epoch, with learning rate 10.305368692688175
[09/26 07:42:19 visual_prompt]: Epoch 74 / 100: avg data time: 6.29e-02, avg batch time: 0.5047, average train loss: 3.7565
[09/26 07:42:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 6.7248
[09/26 07:42:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 49.00	
[09/26 07:42:21 visual_prompt]: Training 75 / 100 epoch, with learning rate 9.608463116858543
[09/26 07:42:27 visual_prompt]: Epoch 75 / 100: avg data time: 5.56e-02, avg batch time: 0.4965, average train loss: 3.6175
[09/26 07:42:29 visual_prompt]: Inference (val):avg data time: 4.05e-05, avg batch time: 0.1662, average loss: 7.2110
[09/26 07:42:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.00	top5: 46.00	
[09/26 07:42:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 8.930309757836516
[09/26 07:42:36 visual_prompt]: Epoch 76 / 100: avg data time: 5.57e-02, avg batch time: 0.4972, average train loss: 3.6083
[09/26 07:42:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 6.9216
[09/26 07:42:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 48.00	
[09/26 07:42:37 visual_prompt]: Training 77 / 100 epoch, with learning rate 8.271734841028552
[09/26 07:42:44 visual_prompt]: Epoch 77 / 100: avg data time: 5.67e-02, avg batch time: 0.4984, average train loss: 3.2709
[09/26 07:42:45 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 5.7953
[09/26 07:42:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 50.00	
[09/26 07:42:45 visual_prompt]: Training 78 / 100 epoch, with learning rate 7.633540738525066
[09/26 07:42:52 visual_prompt]: Epoch 78 / 100: avg data time: 5.13e-02, avg batch time: 0.4936, average train loss: 3.3790
[09/26 07:42:54 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 5.1357
[09/26 07:42:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 55.50	
[09/26 07:42:54 visual_prompt]: Training 79 / 100 epoch, with learning rate 7.016504991533726
[09/26 07:43:00 visual_prompt]: Epoch 79 / 100: avg data time: 5.22e-02, avg batch time: 0.4945, average train loss: 3.1777
[09/26 07:43:02 visual_prompt]: Inference (val):avg data time: 4.41e-05, avg batch time: 0.1661, average loss: 7.1053
[09/26 07:43:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 51.50	
[09/26 07:43:02 visual_prompt]: Training 80 / 100 epoch, with learning rate 6.4213793630651415
[09/26 07:43:09 visual_prompt]: Epoch 80 / 100: avg data time: 4.83e-02, avg batch time: 0.4898, average train loss: 3.0702
[09/26 07:43:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1660, average loss: 6.8199
[09/26 07:43:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 49.50	
[09/26 07:43:10 visual_prompt]: Training 81 / 100 epoch, with learning rate 5.848888922025552
[09/26 07:43:17 visual_prompt]: Epoch 81 / 100: avg data time: 5.21e-02, avg batch time: 0.4946, average train loss: 3.0163
[09/26 07:43:18 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1661, average loss: 6.3253
[09/26 07:43:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 49.00	
[09/26 07:43:18 visual_prompt]: Training 82 / 100 epoch, with learning rate 5.2997311598319525
[09/26 07:43:25 visual_prompt]: Epoch 82 / 100: avg data time: 4.86e-02, avg batch time: 0.4901, average train loss: 2.9655
[09/26 07:43:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1660, average loss: 6.4705
[09/26 07:43:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 50.00	
[09/26 07:43:27 visual_prompt]: Training 83 / 100 epoch, with learning rate 4.774575140626316
[09/26 07:43:33 visual_prompt]: Epoch 83 / 100: avg data time: 4.25e-02, avg batch time: 0.4853, average train loss: 3.2787
[09/26 07:43:35 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 6.5239
[09/26 07:43:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.00	top5: 50.00	
[09/26 07:43:35 visual_prompt]: Training 84 / 100 epoch, with learning rate 4.27406068612396
[09/26 07:43:42 visual_prompt]: Epoch 84 / 100: avg data time: 5.58e-02, avg batch time: 0.4965, average train loss: 3.0081
[09/26 07:43:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 5.7635
[09/26 07:43:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 49.50	
[09/26 07:43:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 3.798797596089351
[09/26 07:43:50 visual_prompt]: Epoch 85 / 100: avg data time: 5.38e-02, avg batch time: 0.4959, average train loss: 2.9844
[09/26 07:43:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 6.0795
[09/26 07:43:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 50.50	
[09/26 07:43:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 3.349364905389032
[09/26 07:43:58 visual_prompt]: Epoch 86 / 100: avg data time: 5.69e-02, avg batch time: 0.4986, average train loss: 2.8109
[09/26 07:43:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 6.2152
[09/26 07:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 49.50	
[09/26 07:43:59 visual_prompt]: Training 87 / 100 epoch, with learning rate 2.9263101785268253
[09/26 07:44:06 visual_prompt]: Epoch 87 / 100: avg data time: 5.71e-02, avg batch time: 0.4993, average train loss: 2.8244
[09/26 07:44:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 6.4949
[09/26 07:44:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 48.00	
[09/26 07:44:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 2.5301488425208296
[09/26 07:44:14 visual_prompt]: Epoch 88 / 100: avg data time: 4.69e-02, avg batch time: 0.4892, average train loss: 2.8875
[09/26 07:44:16 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1660, average loss: 6.2075
[09/26 07:44:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 49.00	
[09/26 07:44:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 2.1613635589349753
[09/26 07:44:23 visual_prompt]: Epoch 89 / 100: avg data time: 5.80e-02, avg batch time: 0.4995, average train loss: 2.9352
[09/26 07:44:24 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 6.3437
[09/26 07:44:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 50.50	
[09/26 07:44:24 visual_prompt]: Training 90 / 100 epoch, with learning rate 1.820403635830317
[09/26 07:44:31 visual_prompt]: Epoch 90 / 100: avg data time: 5.58e-02, avg batch time: 0.4974, average train loss: 2.7662
[09/26 07:44:33 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1659, average loss: 6.0183
[09/26 07:44:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.00	top5: 48.50	
[09/26 07:44:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 1.507684480352292
[09/26 07:44:39 visual_prompt]: Epoch 91 / 100: avg data time: 5.84e-02, avg batch time: 0.4997, average train loss: 2.8552
[09/26 07:44:41 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 6.1882
[09/26 07:44:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 49.50	
[09/26 07:44:41 visual_prompt]: Training 92 / 100 epoch, with learning rate 1.2235870926211616
[09/26 07:44:47 visual_prompt]: Epoch 92 / 100: avg data time: 4.54e-02, avg batch time: 0.4873, average train loss: 2.7179
[09/26 07:44:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1658, average loss: 6.2017
[09/26 07:44:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.50	top5: 49.00	
[09/26 07:44:49 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.9684576015420276
[09/26 07:44:56 visual_prompt]: Epoch 93 / 100: avg data time: 5.69e-02, avg batch time: 0.4978, average train loss: 2.7518
[09/26 07:44:57 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1656, average loss: 6.3180
[09/26 07:44:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 49.00	
[09/26 07:44:57 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.7426068431000882
[09/26 07:45:04 visual_prompt]: Epoch 94 / 100: avg data time: 5.25e-02, avg batch time: 0.4945, average train loss: 2.7437
[09/26 07:45:05 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1658, average loss: 6.3361
[09/26 07:45:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 48.00	
[09/26 07:45:05 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.5463099816548578
[09/26 07:45:12 visual_prompt]: Epoch 95 / 100: avg data time: 4.68e-02, avg batch time: 0.4906, average train loss: 2.5521
[09/26 07:45:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1659, average loss: 6.1213
[09/26 07:45:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 50.00	
[09/26 07:45:14 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.3798061746947995
[09/26 07:45:20 visual_prompt]: Epoch 96 / 100: avg data time: 5.15e-02, avg batch time: 0.4927, average train loss: 2.7258
[09/26 07:45:22 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1660, average loss: 6.1166
[09/26 07:45:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 49.50	
[09/26 07:45:22 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.24329828146074095
[09/26 07:45:29 visual_prompt]: Epoch 97 / 100: avg data time: 6.04e-02, avg batch time: 0.5019, average train loss: 2.6359
[09/26 07:45:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 6.2216
[09/26 07:45:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 50.00	
[09/26 07:45:30 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.13695261579316775
[09/26 07:45:37 visual_prompt]: Epoch 98 / 100: avg data time: 4.67e-02, avg batch time: 0.4893, average train loss: 2.7414
[09/26 07:45:38 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 6.1878
[09/26 07:45:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 49.50	
[09/26 07:45:38 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.06089874350439506
[09/26 07:45:45 visual_prompt]: Epoch 99 / 100: avg data time: 4.37e-02, avg batch time: 0.4870, average train loss: 2.5996
[09/26 07:45:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 6.1652
[09/26 07:45:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 49.50	
[09/26 07:45:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.015229324522605947
[09/26 07:45:53 visual_prompt]: Epoch 100 / 100: avg data time: 5.96e-02, avg batch time: 0.5009, average train loss: 2.4861
[09/26 07:45:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 6.1606
[09/26 07:45:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 49.50	
[09/26 07:45:55 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:45:55 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:45:55 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:45:55 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:45:55 visual_prompt]: Training with config:
[09/26 07:45:55 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:45:55 visual_prompt]: Loading training data...
[09/26 07:45:55 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:45:56 visual_prompt]: Number of images: 800
[09/26 07:45:56 visual_prompt]: Number of classes: 45 / 45
[09/26 07:45:56 visual_prompt]: Loading validation data...
[09/26 07:45:56 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:45:56 visual_prompt]: Number of images: 200
[09/26 07:45:56 visual_prompt]: Number of classes: 45 / 45
[09/26 07:45:56 visual_prompt]: Constructing models...
[09/26 07:45:59 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 07:45:59 visual_prompt]: tuned percent:0.574
[09/26 07:45:59 visual_prompt]: Device used for model: 0
[09/26 07:45:59 visual_prompt]: Setting up Evaluator...
[09/26 07:45:59 visual_prompt]: Setting up Trainer...
[09/26 07:45:59 visual_prompt]: 	Setting up the optimizer...
[09/26 07:45:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 07:46:06 visual_prompt]: Epoch 1 / 100: avg data time: 4.92e-02, avg batch time: 0.4907, average train loss: 3.8937
[09/26 07:46:07 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 07:46:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 07:46:07 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 07:46:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 07:46:14 visual_prompt]: Epoch 2 / 100: avg data time: 5.76e-02, avg batch time: 0.4997, average train loss: 4.1073
[09/26 07:46:15 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1659, average loss: 4.4531
[09/26 07:46:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 07:46:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 07:46:22 visual_prompt]: Epoch 3 / 100: avg data time: 5.96e-02, avg batch time: 0.5002, average train loss: 4.2353
[09/26 07:46:24 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1658, average loss: 4.2356
[09/26 07:46:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:46:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 07:46:31 visual_prompt]: Epoch 4 / 100: avg data time: 6.17e-02, avg batch time: 0.5019, average train loss: 4.6319
[09/26 07:46:32 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1657, average loss: 6.3346
[09/26 07:46:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 16.00	
[09/26 07:46:32 visual_prompt]: Best epoch 4: best metric: 0.040
[09/26 07:46:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 07:46:39 visual_prompt]: Epoch 5 / 100: avg data time: 4.16e-02, avg batch time: 0.4850, average train loss: 11.7225
[09/26 07:46:40 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1657, average loss: 11.6992
[09/26 07:46:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 07:46:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 07:46:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.58e-02, avg batch time: 0.4971, average train loss: 17.7746
[09/26 07:46:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1661, average loss: 28.4448
[09/26 07:46:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:46:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 07:46:55 visual_prompt]: Epoch 7 / 100: avg data time: 6.21e-02, avg batch time: 0.5038, average train loss: 30.0252
[09/26 07:46:57 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 26.2679
[09/26 07:46:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:46:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 07:47:04 visual_prompt]: Epoch 8 / 100: avg data time: 5.46e-02, avg batch time: 0.4975, average train loss: 38.5541
[09/26 07:47:05 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1659, average loss: 41.8583
[09/26 07:47:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:47:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 07:47:12 visual_prompt]: Epoch 9 / 100: avg data time: 6.26e-02, avg batch time: 0.5036, average train loss: 47.7693
[09/26 07:47:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 55.7678
[09/26 07:47:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 6.50	
[09/26 07:47:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 07:47:20 visual_prompt]: Epoch 10 / 100: avg data time: 5.66e-02, avg batch time: 0.4978, average train loss: 65.5146
[09/26 07:47:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 76.7035
[09/26 07:47:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 07:47:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 07:47:29 visual_prompt]: Epoch 11 / 100: avg data time: 6.14e-02, avg batch time: 0.5025, average train loss: 103.3399
[09/26 07:47:30 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 120.8120
[09/26 07:47:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 7.50	
[09/26 07:47:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 07:47:37 visual_prompt]: Epoch 12 / 100: avg data time: 5.66e-02, avg batch time: 0.4979, average train loss: 125.2176
[09/26 07:47:38 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1659, average loss: 134.9939
[09/26 07:47:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:47:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 07:47:45 visual_prompt]: Epoch 13 / 100: avg data time: 5.81e-02, avg batch time: 0.4997, average train loss: 116.2374
[09/26 07:47:47 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1659, average loss: 151.4042
[09/26 07:47:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 07:47:47 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 07:47:54 visual_prompt]: Epoch 14 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 123.1917
[09/26 07:47:55 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1659, average loss: 153.4383
[09/26 07:47:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.50	
[09/26 07:47:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 07:48:02 visual_prompt]: Epoch 15 / 100: avg data time: 6.32e-02, avg batch time: 0.5041, average train loss: 129.8564
[09/26 07:48:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 132.8298
[09/26 07:48:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 07:48:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 07:48:10 visual_prompt]: Epoch 16 / 100: avg data time: 5.04e-02, avg batch time: 0.4923, average train loss: 123.2033
[09/26 07:48:12 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 157.5367
[09/26 07:48:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:48:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 07:48:19 visual_prompt]: Epoch 17 / 100: avg data time: 5.72e-02, avg batch time: 0.4983, average train loss: 112.3571
[09/26 07:48:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 106.4619
[09/26 07:48:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 07:48:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 07:48:27 visual_prompt]: Epoch 18 / 100: avg data time: 6.43e-02, avg batch time: 0.5051, average train loss: 109.3551
[09/26 07:48:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 86.3812
[09/26 07:48:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 07:48:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 07:48:35 visual_prompt]: Epoch 19 / 100: avg data time: 4.62e-02, avg batch time: 0.4893, average train loss: 108.2925
[09/26 07:48:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 103.4223
[09/26 07:48:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 07:48:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 07:48:44 visual_prompt]: Epoch 20 / 100: avg data time: 6.15e-02, avg batch time: 0.5026, average train loss: 119.5201
[09/26 07:48:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 133.0282
[09/26 07:48:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 07:48:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 07:48:52 visual_prompt]: Epoch 21 / 100: avg data time: 4.99e-02, avg batch time: 0.4931, average train loss: 133.4343
[09/26 07:48:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 117.0522
[09/26 07:48:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 14.00	
[09/26 07:48:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 07:49:00 visual_prompt]: Epoch 22 / 100: avg data time: 6.27e-02, avg batch time: 0.5034, average train loss: 117.2588
[09/26 07:49:02 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 117.8821
[09/26 07:49:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 07:49:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 07:49:09 visual_prompt]: Epoch 23 / 100: avg data time: 5.86e-02, avg batch time: 0.4996, average train loss: 114.6858
[09/26 07:49:10 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 114.2196
[09/26 07:49:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 07:49:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 07:49:17 visual_prompt]: Epoch 24 / 100: avg data time: 5.30e-02, avg batch time: 0.4956, average train loss: 110.1217
[09/26 07:49:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 107.6982
[09/26 07:49:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 07:49:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 07:49:25 visual_prompt]: Epoch 25 / 100: avg data time: 5.97e-02, avg batch time: 0.5006, average train loss: 92.5551
[09/26 07:49:27 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1663, average loss: 91.1351
[09/26 07:49:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 07:49:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 07:49:33 visual_prompt]: Epoch 26 / 100: avg data time: 4.95e-02, avg batch time: 0.4929, average train loss: 88.0820
[09/26 07:49:35 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 92.3753
[09/26 07:49:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:49:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 07:49:42 visual_prompt]: Epoch 27 / 100: avg data time: 6.09e-02, avg batch time: 0.5023, average train loss: 86.9423
[09/26 07:49:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 111.9898
[09/26 07:49:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:49:44 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 07:49:50 visual_prompt]: Epoch 28 / 100: avg data time: 5.82e-02, avg batch time: 0.5007, average train loss: 102.4948
[09/26 07:49:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 105.5228
[09/26 07:49:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:49:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 07:49:59 visual_prompt]: Epoch 29 / 100: avg data time: 5.41e-02, avg batch time: 0.4956, average train loss: 104.6172
[09/26 07:50:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 81.2023
[09/26 07:50:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.00	
[09/26 07:50:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 07:50:07 visual_prompt]: Epoch 30 / 100: avg data time: 4.86e-02, avg batch time: 0.4913, average train loss: 91.5464
[09/26 07:50:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 77.8222
[09/26 07:50:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 07:50:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 07:50:15 visual_prompt]: Epoch 31 / 100: avg data time: 5.60e-02, avg batch time: 0.4972, average train loss: 91.3076
[09/26 07:50:17 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 74.3469
[09/26 07:50:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:50:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 07:50:23 visual_prompt]: Epoch 32 / 100: avg data time: 5.74e-02, avg batch time: 0.5002, average train loss: 84.0063
[09/26 07:50:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 88.3955
[09/26 07:50:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:50:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 07:50:32 visual_prompt]: Epoch 33 / 100: avg data time: 5.08e-02, avg batch time: 0.4923, average train loss: 82.5330
[09/26 07:50:33 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1658, average loss: 91.8127
[09/26 07:50:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:50:33 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 07:50:40 visual_prompt]: Epoch 34 / 100: avg data time: 5.07e-02, avg batch time: 0.4934, average train loss: 78.1936
[09/26 07:50:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1660, average loss: 62.4164
[09/26 07:50:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:50:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 07:50:48 visual_prompt]: Epoch 35 / 100: avg data time: 5.95e-02, avg batch time: 0.5020, average train loss: 77.7038
[09/26 07:50:50 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 80.3957
[09/26 07:50:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 07:50:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 07:50:57 visual_prompt]: Epoch 36 / 100: avg data time: 6.06e-02, avg batch time: 0.5026, average train loss: 82.6827
[09/26 07:50:58 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1659, average loss: 89.9439
[09/26 07:50:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.00	
[09/26 07:50:58 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 07:51:05 visual_prompt]: Epoch 37 / 100: avg data time: 5.16e-02, avg batch time: 0.4942, average train loss: 75.1042
[09/26 07:51:07 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 93.8587
[09/26 07:51:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 07:51:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 07:51:13 visual_prompt]: Epoch 38 / 100: avg data time: 5.80e-02, avg batch time: 0.5001, average train loss: 93.4261
[09/26 07:51:15 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 191.8366
[09/26 07:51:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 07:51:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 07:51:22 visual_prompt]: Epoch 39 / 100: avg data time: 4.62e-02, avg batch time: 0.4882, average train loss: 94.6892
[09/26 07:51:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 80.3667
[09/26 07:51:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 07:51:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 07:51:30 visual_prompt]: Epoch 40 / 100: avg data time: 4.79e-02, avg batch time: 0.4905, average train loss: 89.2623
[09/26 07:51:31 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1659, average loss: 94.5112
[09/26 07:51:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 07:51:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 07:51:38 visual_prompt]: Epoch 41 / 100: avg data time: 5.83e-02, avg batch time: 0.4988, average train loss: 75.9181
[09/26 07:51:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 72.4854
[09/26 07:51:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 07:51:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 07:51:46 visual_prompt]: Epoch 42 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 69.4509
[09/26 07:51:48 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 70.8782
[09/26 07:51:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 07:51:48 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 07:51:55 visual_prompt]: Epoch 43 / 100: avg data time: 5.78e-02, avg batch time: 0.4995, average train loss: 68.9624
[09/26 07:51:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 69.3661
[09/26 07:51:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 07:51:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 07:52:03 visual_prompt]: Epoch 44 / 100: avg data time: 6.37e-02, avg batch time: 0.5043, average train loss: 64.8382
[09/26 07:52:05 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1658, average loss: 49.3967
[09/26 07:52:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 07:52:05 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 07:52:12 visual_prompt]: Epoch 45 / 100: avg data time: 5.61e-02, avg batch time: 0.4982, average train loss: 61.6760
[09/26 07:52:13 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1661, average loss: 53.5428
[09/26 07:52:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:52:13 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 07:52:20 visual_prompt]: Epoch 46 / 100: avg data time: 5.89e-02, avg batch time: 0.5001, average train loss: 63.0169
[09/26 07:52:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 46.4776
[09/26 07:52:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 07:52:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 07:52:28 visual_prompt]: Epoch 47 / 100: avg data time: 5.87e-02, avg batch time: 0.5001, average train loss: 76.0214
[09/26 07:52:30 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1660, average loss: 72.0155
[09/26 07:52:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:52:30 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 07:52:37 visual_prompt]: Epoch 48 / 100: avg data time: 5.61e-02, avg batch time: 0.4978, average train loss: 74.7217
[09/26 07:52:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 55.2185
[09/26 07:52:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 12.00	
[09/26 07:52:38 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 07:52:45 visual_prompt]: Epoch 49 / 100: avg data time: 5.47e-02, avg batch time: 0.4958, average train loss: 62.8896
[09/26 07:52:47 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 72.4007
[09/26 07:52:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 07:52:47 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 07:52:53 visual_prompt]: Epoch 50 / 100: avg data time: 5.67e-02, avg batch time: 0.4984, average train loss: 67.5246
[09/26 07:52:55 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 63.0658
[09/26 07:52:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:52:55 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 07:53:02 visual_prompt]: Epoch 51 / 100: avg data time: 5.63e-02, avg batch time: 0.4980, average train loss: 62.0511
[09/26 07:53:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1660, average loss: 61.8357
[09/26 07:53:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 07:53:03 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 07:53:10 visual_prompt]: Epoch 52 / 100: avg data time: 5.05e-02, avg batch time: 0.4913, average train loss: 69.3787
[09/26 07:53:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1660, average loss: 65.5622
[09/26 07:53:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 07:53:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 07:53:18 visual_prompt]: Epoch 53 / 100: avg data time: 5.78e-02, avg batch time: 0.4986, average train loss: 61.3661
[09/26 07:53:20 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 70.3574
[09/26 07:53:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:53:20 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 07:53:26 visual_prompt]: Epoch 54 / 100: avg data time: 4.50e-02, avg batch time: 0.4869, average train loss: 58.9512
[09/26 07:53:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 60.7183
[09/26 07:53:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 07:53:28 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 07:53:35 visual_prompt]: Epoch 55 / 100: avg data time: 6.18e-02, avg batch time: 0.5026, average train loss: 54.2972
[09/26 07:53:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 49.4890
[09/26 07:53:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 07:53:36 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 07:53:43 visual_prompt]: Epoch 56 / 100: avg data time: 5.43e-02, avg batch time: 0.4963, average train loss: 52.1505
[09/26 07:53:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 46.9618
[09/26 07:53:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 07:53:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 07:53:51 visual_prompt]: Epoch 57 / 100: avg data time: 5.64e-02, avg batch time: 0.4971, average train loss: 45.0333
[09/26 07:53:53 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 48.0648
[09/26 07:53:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 07:53:53 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 07:54:00 visual_prompt]: Epoch 58 / 100: avg data time: 4.78e-02, avg batch time: 0.4935, average train loss: 48.7343
[09/26 07:54:01 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1665, average loss: 40.7409
[09/26 07:54:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 07:54:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 07:54:08 visual_prompt]: Epoch 59 / 100: avg data time: 6.13e-02, avg batch time: 0.5020, average train loss: 44.5911
[09/26 07:54:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1659, average loss: 39.3172
[09/26 07:54:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 07:54:10 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 07:54:16 visual_prompt]: Epoch 60 / 100: avg data time: 4.28e-02, avg batch time: 0.4848, average train loss: 40.2949
[09/26 07:54:18 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1659, average loss: 38.1949
[09/26 07:54:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 07:54:18 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 07:54:25 visual_prompt]: Epoch 61 / 100: avg data time: 5.65e-02, avg batch time: 0.4981, average train loss: 37.8850
[09/26 07:54:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 30.3690
[09/26 07:54:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 16.00	
[09/26 07:54:26 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 07:54:33 visual_prompt]: Epoch 62 / 100: avg data time: 5.84e-02, avg batch time: 0.4998, average train loss: 33.5307
[09/26 07:54:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 36.7909
[09/26 07:54:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 07:54:34 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 07:54:41 visual_prompt]: Epoch 63 / 100: avg data time: 6.31e-02, avg batch time: 0.5039, average train loss: 30.5892
[09/26 07:54:43 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 28.6729
[09/26 07:54:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 07:54:43 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 07:54:50 visual_prompt]: Epoch 64 / 100: avg data time: 5.98e-02, avg batch time: 0.5022, average train loss: 30.4685
[09/26 07:54:51 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1661, average loss: 27.1882
[09/26 07:54:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:54:51 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 07:54:58 visual_prompt]: Epoch 65 / 100: avg data time: 5.65e-02, avg batch time: 0.4984, average train loss: 32.4715
[09/26 07:54:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 26.0809
[09/26 07:54:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 07:54:59 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 07:55:06 visual_prompt]: Epoch 66 / 100: avg data time: 5.73e-02, avg batch time: 0.4975, average train loss: 26.3646
[09/26 07:55:08 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1659, average loss: 21.4134
[09/26 07:55:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 07:55:08 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 07:55:15 visual_prompt]: Epoch 67 / 100: avg data time: 6.11e-02, avg batch time: 0.5027, average train loss: 21.1727
[09/26 07:55:16 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 19.6708
[09/26 07:55:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 12.00	
[09/26 07:55:16 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 07:55:23 visual_prompt]: Epoch 68 / 100: avg data time: 5.10e-02, avg batch time: 0.4917, average train loss: 18.3462
[09/26 07:55:24 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1658, average loss: 16.7879
[09/26 07:55:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 17.00	
[09/26 07:55:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 07:55:31 visual_prompt]: Epoch 69 / 100: avg data time: 4.81e-02, avg batch time: 0.4908, average train loss: 14.4641
[09/26 07:55:33 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 11.1992
[09/26 07:55:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 8.50	
[09/26 07:55:33 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 07:55:39 visual_prompt]: Epoch 70 / 100: avg data time: 6.11e-02, avg batch time: 0.5028, average train loss: 12.7758
[09/26 07:55:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 9.6769
[09/26 07:55:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 07:55:41 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 07:55:48 visual_prompt]: Epoch 71 / 100: avg data time: 5.58e-02, avg batch time: 0.4975, average train loss: 12.3999
[09/26 07:55:49 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 11.7787
[09/26 07:55:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 07:55:49 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 07:55:56 visual_prompt]: Epoch 72 / 100: avg data time: 6.19e-02, avg batch time: 0.5031, average train loss: 11.8883
[09/26 07:55:58 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 8.6649
[09/26 07:55:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 07:55:58 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 07:56:04 visual_prompt]: Epoch 73 / 100: avg data time: 5.64e-02, avg batch time: 0.4979, average train loss: 10.3270
[09/26 07:56:06 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1661, average loss: 8.5781
[09/26 07:56:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 16.00	
[09/26 07:56:06 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 07:56:13 visual_prompt]: Epoch 74 / 100: avg data time: 5.35e-02, avg batch time: 0.4959, average train loss: 10.5818
[09/26 07:56:14 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 9.8514
[09/26 07:56:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 07:56:14 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 07:56:21 visual_prompt]: Epoch 75 / 100: avg data time: 4.13e-02, avg batch time: 0.4839, average train loss: 8.7058
[09/26 07:56:22 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 6.5825
[09/26 07:56:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 07:56:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 07:56:29 visual_prompt]: Epoch 76 / 100: avg data time: 5.74e-02, avg batch time: 0.4990, average train loss: 7.1387
[09/26 07:56:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 6.8114
[09/26 07:56:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 07:56:31 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 07:56:38 visual_prompt]: Epoch 77 / 100: avg data time: 6.05e-02, avg batch time: 0.5029, average train loss: 6.3328
[09/26 07:56:39 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 4.4262
[09/26 07:56:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 07:56:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 07:56:46 visual_prompt]: Epoch 78 / 100: avg data time: 5.57e-02, avg batch time: 0.4968, average train loss: 5.3162
[09/26 07:56:47 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 5.0452
[09/26 07:56:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 07:56:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 07:56:54 visual_prompt]: Epoch 79 / 100: avg data time: 5.62e-02, avg batch time: 0.4983, average train loss: 5.0973
[09/26 07:56:56 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 5.2177
[09/26 07:56:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.00	
[09/26 07:56:56 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 07:57:03 visual_prompt]: Epoch 80 / 100: avg data time: 6.30e-02, avg batch time: 0.5042, average train loss: 5.7110
[09/26 07:57:04 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 5.8102
[09/26 07:57:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 07:57:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 07:57:11 visual_prompt]: Epoch 81 / 100: avg data time: 4.97e-02, avg batch time: 0.4914, average train loss: 5.7660
[09/26 07:57:12 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 5.3859
[09/26 07:57:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 14.00	
[09/26 07:57:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 07:57:19 visual_prompt]: Epoch 82 / 100: avg data time: 5.94e-02, avg batch time: 0.5020, average train loss: 5.1706
[09/26 07:57:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 4.3645
[09/26 07:57:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 07:57:21 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 07:57:28 visual_prompt]: Epoch 83 / 100: avg data time: 5.46e-02, avg batch time: 0.4963, average train loss: 6.1024
[09/26 07:57:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 5.5389
[09/26 07:57:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 07:57:29 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 07:57:36 visual_prompt]: Epoch 84 / 100: avg data time: 5.54e-02, avg batch time: 0.4971, average train loss: 7.1645
[09/26 07:57:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 5.7341
[09/26 07:57:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.50	
[09/26 07:57:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 07:57:44 visual_prompt]: Epoch 85 / 100: avg data time: 6.12e-02, avg batch time: 0.5017, average train loss: 5.3306
[09/26 07:57:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 5.5298
[09/26 07:57:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 07:57:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 07:57:52 visual_prompt]: Epoch 86 / 100: avg data time: 4.72e-02, avg batch time: 0.4909, average train loss: 5.1947
[09/26 07:57:54 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 5.2356
[09/26 07:57:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 07:57:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 07:58:01 visual_prompt]: Epoch 87 / 100: avg data time: 4.52e-02, avg batch time: 0.4873, average train loss: 5.4450
[09/26 07:58:02 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 5.3080
[09/26 07:58:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.00	
[09/26 07:58:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 07:58:09 visual_prompt]: Epoch 88 / 100: avg data time: 5.32e-02, avg batch time: 0.4958, average train loss: 5.2734
[09/26 07:58:10 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1665, average loss: 5.0526
[09/26 07:58:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 13.50	
[09/26 07:58:10 visual_prompt]: Best epoch 88: best metric: 0.050
[09/26 07:58:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 07:58:17 visual_prompt]: Epoch 89 / 100: avg data time: 4.49e-02, avg batch time: 0.4873, average train loss: 5.2149
[09/26 07:58:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1660, average loss: 4.9468
[09/26 07:58:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 07:58:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 07:58:25 visual_prompt]: Epoch 90 / 100: avg data time: 6.32e-02, avg batch time: 0.5041, average train loss: 5.1485
[09/26 07:58:27 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 4.8669
[09/26 07:58:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 07:58:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 07:58:34 visual_prompt]: Epoch 91 / 100: avg data time: 5.67e-02, avg batch time: 0.4985, average train loss: 4.9180
[09/26 07:58:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 4.7126
[09/26 07:58:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 6.50	
[09/26 07:58:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 07:58:42 visual_prompt]: Epoch 92 / 100: avg data time: 5.74e-02, avg batch time: 0.4987, average train loss: 4.6965
[09/26 07:58:44 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 4.1756
[09/26 07:58:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 17.00	
[09/26 07:58:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 07:58:50 visual_prompt]: Epoch 93 / 100: avg data time: 6.33e-02, avg batch time: 0.5035, average train loss: 4.3079
[09/26 07:58:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1659, average loss: 4.1313
[09/26 07:58:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 07:58:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 07:58:59 visual_prompt]: Epoch 94 / 100: avg data time: 6.02e-02, avg batch time: 0.5010, average train loss: 4.1234
[09/26 07:59:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 4.2381
[09/26 07:59:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 07:59:00 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 07:59:07 visual_prompt]: Epoch 95 / 100: avg data time: 6.12e-02, avg batch time: 0.5026, average train loss: 4.0649
[09/26 07:59:09 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 3.8971
[09/26 07:59:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 17.00	
[09/26 07:59:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 07:59:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.46e-02, avg batch time: 0.4968, average train loss: 3.8509
[09/26 07:59:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 3.6352
[09/26 07:59:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 17.00	
[09/26 07:59:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 07:59:24 visual_prompt]: Epoch 97 / 100: avg data time: 5.53e-02, avg batch time: 0.4979, average train loss: 3.7074
[09/26 07:59:25 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 3.7043
[09/26 07:59:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.50	
[09/26 07:59:25 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 07:59:32 visual_prompt]: Epoch 98 / 100: avg data time: 5.77e-02, avg batch time: 0.4998, average train loss: 3.5897
[09/26 07:59:34 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 3.5008
[09/26 07:59:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 25.00	
[09/26 07:59:34 visual_prompt]: Best epoch 98: best metric: 0.065
[09/26 07:59:34 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 07:59:41 visual_prompt]: Epoch 99 / 100: avg data time: 6.42e-02, avg batch time: 0.5051, average train loss: 3.4660
[09/26 07:59:42 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1664, average loss: 3.4848
[09/26 07:59:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 25.50	
[09/26 07:59:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 07:59:49 visual_prompt]: Epoch 100 / 100: avg data time: 5.76e-02, avg batch time: 0.4999, average train loss: 3.3855
[09/26 07:59:50 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 3.4609
[09/26 07:59:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 28.50	
[09/26 07:59:50 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 07:59:50 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 07:59:50 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 07:59:50 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 07:59:50 visual_prompt]: Training with config:
[09/26 07:59:50 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 07:59:50 visual_prompt]: Loading training data...
[09/26 07:59:50 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:59:52 visual_prompt]: Number of images: 800
[09/26 07:59:52 visual_prompt]: Number of classes: 45 / 45
[09/26 07:59:52 visual_prompt]: Loading validation data...
[09/26 07:59:52 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 07:59:52 visual_prompt]: Number of images: 200
[09/26 07:59:52 visual_prompt]: Number of classes: 45 / 45
[09/26 07:59:52 visual_prompt]: Constructing models...
[09/26 07:59:54 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 07:59:54 visual_prompt]: tuned percent:0.574
[09/26 07:59:54 visual_prompt]: Device used for model: 0
[09/26 07:59:54 visual_prompt]: Setting up Evaluator...
[09/26 07:59:54 visual_prompt]: Setting up Trainer...
[09/26 07:59:54 visual_prompt]: 	Setting up the optimizer...
[09/26 07:59:54 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:00:01 visual_prompt]: Epoch 1 / 100: avg data time: 5.52e-02, avg batch time: 0.4952, average train loss: 3.8951
[09/26 08:00:03 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 3.9529
[09/26 08:00:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 08:00:03 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 08:00:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:00:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.76e-02, avg batch time: 0.4978, average train loss: 4.1277
[09/26 08:00:11 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 4.0909
[09/26 08:00:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 08:00:11 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 08:00:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:00:18 visual_prompt]: Epoch 3 / 100: avg data time: 5.51e-02, avg batch time: 0.4979, average train loss: 4.3541
[09/26 08:00:19 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1659, average loss: 4.1607
[09/26 08:00:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 14.50	
[09/26 08:00:19 visual_prompt]: Best epoch 3: best metric: 0.050
[09/26 08:00:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:00:26 visual_prompt]: Epoch 4 / 100: avg data time: 5.74e-02, avg batch time: 0.4981, average train loss: 5.8240
[09/26 08:00:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1656, average loss: 12.1891
[09/26 08:00:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:00:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:00:34 visual_prompt]: Epoch 5 / 100: avg data time: 5.50e-02, avg batch time: 0.4961, average train loss: 25.4538
[09/26 08:00:36 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1656, average loss: 31.1268
[09/26 08:00:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 08:00:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:00:43 visual_prompt]: Epoch 6 / 100: avg data time: 6.18e-02, avg batch time: 0.5021, average train loss: 66.7307
[09/26 08:00:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1659, average loss: 88.7469
[09/26 08:00:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:00:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:00:51 visual_prompt]: Epoch 7 / 100: avg data time: 5.98e-02, avg batch time: 0.5003, average train loss: 74.6772
[09/26 08:00:53 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1660, average loss: 60.9801
[09/26 08:00:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 12.50	
[09/26 08:00:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:00:59 visual_prompt]: Epoch 8 / 100: avg data time: 4.99e-02, avg batch time: 0.4908, average train loss: 76.0921
[09/26 08:01:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 75.4747
[09/26 08:01:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:01:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:01:08 visual_prompt]: Epoch 9 / 100: avg data time: 5.92e-02, avg batch time: 0.5001, average train loss: 78.0226
[09/26 08:01:09 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1659, average loss: 73.5703
[09/26 08:01:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:01:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:01:16 visual_prompt]: Epoch 10 / 100: avg data time: 5.66e-02, avg batch time: 0.4973, average train loss: 77.4317
[09/26 08:01:18 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1658, average loss: 112.4483
[09/26 08:01:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 08:01:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:01:24 visual_prompt]: Epoch 11 / 100: avg data time: 5.14e-02, avg batch time: 0.4919, average train loss: 122.8024
[09/26 08:01:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1657, average loss: 117.5538
[09/26 08:01:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 08:01:26 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:01:33 visual_prompt]: Epoch 12 / 100: avg data time: 5.44e-02, avg batch time: 0.4958, average train loss: 105.9558
[09/26 08:01:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1661, average loss: 148.9545
[09/26 08:01:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 08:01:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:01:41 visual_prompt]: Epoch 13 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 130.3448
[09/26 08:01:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 108.6853
[09/26 08:01:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:01:43 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:01:49 visual_prompt]: Epoch 14 / 100: avg data time: 5.34e-02, avg batch time: 0.4949, average train loss: 118.4789
[09/26 08:01:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 114.8251
[09/26 08:01:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:01:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:01:58 visual_prompt]: Epoch 15 / 100: avg data time: 6.48e-02, avg batch time: 0.5057, average train loss: 115.5085
[09/26 08:01:59 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 112.7440
[09/26 08:01:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:01:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:02:06 visual_prompt]: Epoch 16 / 100: avg data time: 6.01e-02, avg batch time: 0.5027, average train loss: 115.5740
[09/26 08:02:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1660, average loss: 129.6386
[09/26 08:02:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.50	
[09/26 08:02:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:02:15 visual_prompt]: Epoch 17 / 100: avg data time: 4.62e-02, avg batch time: 0.4881, average train loss: 119.9522
[09/26 08:02:16 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1659, average loss: 139.7272
[09/26 08:02:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 08:02:16 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:02:23 visual_prompt]: Epoch 18 / 100: avg data time: 5.51e-02, avg batch time: 0.4964, average train loss: 140.6841
[09/26 08:02:24 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1657, average loss: 110.0723
[09/26 08:02:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:02:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:02:31 visual_prompt]: Epoch 19 / 100: avg data time: 5.55e-02, avg batch time: 0.4972, average train loss: 111.0544
[09/26 08:02:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 103.3373
[09/26 08:02:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 08:02:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:02:39 visual_prompt]: Epoch 20 / 100: avg data time: 4.86e-02, avg batch time: 0.4910, average train loss: 97.7405
[09/26 08:02:41 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 114.1842
[09/26 08:02:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 08:02:41 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:02:48 visual_prompt]: Epoch 21 / 100: avg data time: 5.90e-02, avg batch time: 0.5002, average train loss: 112.5184
[09/26 08:02:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 97.5512
[09/26 08:02:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 08:02:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:02:56 visual_prompt]: Epoch 22 / 100: avg data time: 5.41e-02, avg batch time: 0.4953, average train loss: 130.9503
[09/26 08:02:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 141.9491
[09/26 08:02:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:02:58 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:03:04 visual_prompt]: Epoch 23 / 100: avg data time: 5.78e-02, avg batch time: 0.4996, average train loss: 120.8898
[09/26 08:03:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 130.2256
[09/26 08:03:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 08:03:06 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:03:13 visual_prompt]: Epoch 24 / 100: avg data time: 4.24e-02, avg batch time: 0.4843, average train loss: 90.5099
[09/26 08:03:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 133.8873
[09/26 08:03:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:03:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:03:21 visual_prompt]: Epoch 25 / 100: avg data time: 6.24e-02, avg batch time: 0.5037, average train loss: 120.2735
[09/26 08:03:22 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1659, average loss: 116.6279
[09/26 08:03:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:03:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:03:29 visual_prompt]: Epoch 26 / 100: avg data time: 5.87e-02, avg batch time: 0.4993, average train loss: 122.7260
[09/26 08:03:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 112.8719
[09/26 08:03:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 08:03:31 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:03:38 visual_prompt]: Epoch 27 / 100: avg data time: 6.61e-02, avg batch time: 0.5070, average train loss: 116.2395
[09/26 08:03:39 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 76.6238
[09/26 08:03:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:03:39 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:03:46 visual_prompt]: Epoch 28 / 100: avg data time: 5.06e-02, avg batch time: 0.4917, average train loss: 113.2702
[09/26 08:03:47 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 152.8486
[09/26 08:03:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 08:03:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:03:54 visual_prompt]: Epoch 29 / 100: avg data time: 5.27e-02, avg batch time: 0.4940, average train loss: 133.7896
[09/26 08:03:56 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 118.8765
[09/26 08:03:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.00	
[09/26 08:03:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:04:02 visual_prompt]: Epoch 30 / 100: avg data time: 5.17e-02, avg batch time: 0.4935, average train loss: 111.8462
[09/26 08:04:04 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1658, average loss: 91.6868
[09/26 08:04:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 08:04:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:04:11 visual_prompt]: Epoch 31 / 100: avg data time: 5.57e-02, avg batch time: 0.4989, average train loss: 93.3408
[09/26 08:04:12 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 82.6371
[09/26 08:04:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.50	
[09/26 08:04:12 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:04:19 visual_prompt]: Epoch 32 / 100: avg data time: 5.52e-02, avg batch time: 0.4979, average train loss: 94.1645
[09/26 08:04:21 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 122.6299
[09/26 08:04:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 08:04:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:04:27 visual_prompt]: Epoch 33 / 100: avg data time: 5.90e-02, avg batch time: 0.5006, average train loss: 128.5342
[09/26 08:04:29 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 104.9618
[09/26 08:04:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:04:29 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:04:36 visual_prompt]: Epoch 34 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 111.7621
[09/26 08:04:37 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1658, average loss: 97.9975
[09/26 08:04:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 08:04:37 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:04:44 visual_prompt]: Epoch 35 / 100: avg data time: 5.67e-02, avg batch time: 0.4982, average train loss: 102.3571
[09/26 08:04:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1660, average loss: 105.6757
[09/26 08:04:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 08:04:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:04:52 visual_prompt]: Epoch 36 / 100: avg data time: 5.56e-02, avg batch time: 0.4956, average train loss: 96.8843
[09/26 08:04:54 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1657, average loss: 116.4673
[09/26 08:04:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:04:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:05:01 visual_prompt]: Epoch 37 / 100: avg data time: 5.20e-02, avg batch time: 0.4954, average train loss: 120.6120
[09/26 08:05:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 90.3096
[09/26 08:05:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 08:05:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:05:09 visual_prompt]: Epoch 38 / 100: avg data time: 5.92e-02, avg batch time: 0.5009, average train loss: 106.2148
[09/26 08:05:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 102.6221
[09/26 08:05:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 08:05:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:05:17 visual_prompt]: Epoch 39 / 100: avg data time: 6.17e-02, avg batch time: 0.5022, average train loss: 125.4260
[09/26 08:05:19 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 138.4649
[09/26 08:05:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:05:19 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:05:26 visual_prompt]: Epoch 40 / 100: avg data time: 6.24e-02, avg batch time: 0.5033, average train loss: 141.6599
[09/26 08:05:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1662, average loss: 120.9646
[09/26 08:05:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 08:05:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:05:34 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 138.9010
[09/26 08:05:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 126.0007
[09/26 08:05:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 6.00	
[09/26 08:05:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:05:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.77e-02, avg batch time: 0.4988, average train loss: 120.5067
[09/26 08:05:44 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1662, average loss: 104.9226
[09/26 08:05:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.50	
[09/26 08:05:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:05:51 visual_prompt]: Epoch 43 / 100: avg data time: 6.21e-02, avg batch time: 0.5035, average train loss: 84.7782
[09/26 08:05:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1657, average loss: 93.4618
[09/26 08:05:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:05:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:05:59 visual_prompt]: Epoch 44 / 100: avg data time: 4.86e-02, avg batch time: 0.4900, average train loss: 94.7055
[09/26 08:06:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 67.6543
[09/26 08:06:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:06:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:06:07 visual_prompt]: Epoch 45 / 100: avg data time: 6.69e-02, avg batch time: 0.5077, average train loss: 81.6248
[09/26 08:06:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 62.5688
[09/26 08:06:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.50	
[09/26 08:06:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:06:16 visual_prompt]: Epoch 46 / 100: avg data time: 6.39e-02, avg batch time: 0.5045, average train loss: 77.5689
[09/26 08:06:17 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1661, average loss: 128.3021
[09/26 08:06:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:06:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:06:24 visual_prompt]: Epoch 47 / 100: avg data time: 5.62e-02, avg batch time: 0.4975, average train loss: 81.8205
[09/26 08:06:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 88.6183
[09/26 08:06:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 08:06:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:06:32 visual_prompt]: Epoch 48 / 100: avg data time: 4.38e-02, avg batch time: 0.4859, average train loss: 89.4541
[09/26 08:06:34 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 82.0550
[09/26 08:06:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:06:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:06:40 visual_prompt]: Epoch 49 / 100: avg data time: 4.63e-02, avg batch time: 0.4898, average train loss: 74.6910
[09/26 08:06:42 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1659, average loss: 56.8107
[09/26 08:06:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.00	
[09/26 08:06:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:06:49 visual_prompt]: Epoch 50 / 100: avg data time: 4.49e-02, avg batch time: 0.4889, average train loss: 90.1651
[09/26 08:06:50 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 71.9840
[09/26 08:06:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 08:06:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:06:57 visual_prompt]: Epoch 51 / 100: avg data time: 6.11e-02, avg batch time: 0.5030, average train loss: 73.5775
[09/26 08:06:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 58.4534
[09/26 08:06:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 08:06:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:07:05 visual_prompt]: Epoch 52 / 100: avg data time: 4.70e-02, avg batch time: 0.4880, average train loss: 68.9938
[09/26 08:07:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 62.4863
[09/26 08:07:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.00	
[09/26 08:07:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:07:13 visual_prompt]: Epoch 53 / 100: avg data time: 6.02e-02, avg batch time: 0.5009, average train loss: 78.5876
[09/26 08:07:15 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 90.6993
[09/26 08:07:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:07:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:07:22 visual_prompt]: Epoch 54 / 100: avg data time: 5.49e-02, avg batch time: 0.4972, average train loss: 77.5410
[09/26 08:07:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 72.9326
[09/26 08:07:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 08:07:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:07:30 visual_prompt]: Epoch 55 / 100: avg data time: 6.03e-02, avg batch time: 0.5020, average train loss: 56.2935
[09/26 08:07:32 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1659, average loss: 58.1660
[09/26 08:07:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.00	
[09/26 08:07:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:07:38 visual_prompt]: Epoch 56 / 100: avg data time: 5.61e-02, avg batch time: 0.4978, average train loss: 57.2686
[09/26 08:07:40 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1660, average loss: 60.5703
[09/26 08:07:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:07:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:07:47 visual_prompt]: Epoch 57 / 100: avg data time: 5.46e-02, avg batch time: 0.4961, average train loss: 60.1822
[09/26 08:07:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 80.6705
[09/26 08:07:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.00	
[09/26 08:07:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:07:55 visual_prompt]: Epoch 58 / 100: avg data time: 6.28e-02, avg batch time: 0.5036, average train loss: 87.7632
[09/26 08:07:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 87.5997
[09/26 08:07:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 13.00	
[09/26 08:07:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:08:03 visual_prompt]: Epoch 59 / 100: avg data time: 6.06e-02, avg batch time: 0.5028, average train loss: 100.9518
[09/26 08:08:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 91.2450
[09/26 08:08:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 08:08:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:08:12 visual_prompt]: Epoch 60 / 100: avg data time: 4.56e-02, avg batch time: 0.4892, average train loss: 83.2945
[09/26 08:08:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 88.9399
[09/26 08:08:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 08:08:13 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:08:20 visual_prompt]: Epoch 61 / 100: avg data time: 4.69e-02, avg batch time: 0.4883, average train loss: 81.9610
[09/26 08:08:21 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 82.0680
[09/26 08:08:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 08:08:21 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:08:28 visual_prompt]: Epoch 62 / 100: avg data time: 5.94e-02, avg batch time: 0.5003, average train loss: 58.7483
[09/26 08:08:30 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1658, average loss: 59.8612
[09/26 08:08:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 08:08:30 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:08:36 visual_prompt]: Epoch 63 / 100: avg data time: 4.73e-02, avg batch time: 0.4899, average train loss: 58.9836
[09/26 08:08:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 47.3141
[09/26 08:08:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:08:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:08:45 visual_prompt]: Epoch 64 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 42.4773
[09/26 08:08:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 31.3384
[09/26 08:08:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:08:46 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:08:53 visual_prompt]: Epoch 65 / 100: avg data time: 4.81e-02, avg batch time: 0.4913, average train loss: 36.4926
[09/26 08:08:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 31.5589
[09/26 08:08:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 08:08:55 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:09:01 visual_prompt]: Epoch 66 / 100: avg data time: 4.77e-02, avg batch time: 0.4916, average train loss: 40.3026
[09/26 08:09:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 58.0997
[09/26 08:09:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 17.00	
[09/26 08:09:03 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:09:10 visual_prompt]: Epoch 67 / 100: avg data time: 6.06e-02, avg batch time: 0.5017, average train loss: 52.5396
[09/26 08:09:11 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 48.0340
[09/26 08:09:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 08:09:11 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:09:18 visual_prompt]: Epoch 68 / 100: avg data time: 5.41e-02, avg batch time: 0.4949, average train loss: 52.8913
[09/26 08:09:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 47.0387
[09/26 08:09:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 10.50	
[09/26 08:09:20 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:09:26 visual_prompt]: Epoch 69 / 100: avg data time: 6.14e-02, avg batch time: 0.5031, average train loss: 47.5529
[09/26 08:09:28 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1658, average loss: 47.7147
[09/26 08:09:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 08:09:28 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:09:35 visual_prompt]: Epoch 70 / 100: avg data time: 5.54e-02, avg batch time: 0.4963, average train loss: 34.4479
[09/26 08:09:36 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 25.4075
[09/26 08:09:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 08:09:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:09:43 visual_prompt]: Epoch 71 / 100: avg data time: 5.99e-02, avg batch time: 0.5014, average train loss: 25.1155
[09/26 08:09:45 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 12.9132
[09/26 08:09:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 08:09:45 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:09:51 visual_prompt]: Epoch 72 / 100: avg data time: 5.66e-02, avg batch time: 0.4975, average train loss: 9.6219
[09/26 08:09:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 6.6786
[09/26 08:09:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:09:53 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:10:00 visual_prompt]: Epoch 73 / 100: avg data time: 5.29e-02, avg batch time: 0.4941, average train loss: 6.2726
[09/26 08:10:01 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1662, average loss: 5.5571
[09/26 08:10:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 08:10:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:10:08 visual_prompt]: Epoch 74 / 100: avg data time: 4.45e-02, avg batch time: 0.4871, average train loss: 7.8357
[09/26 08:10:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 10.4164
[09/26 08:10:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 9.00	
[09/26 08:10:09 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:10:16 visual_prompt]: Epoch 75 / 100: avg data time: 5.31e-02, avg batch time: 0.4938, average train loss: 11.7521
[09/26 08:10:18 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 14.6171
[09/26 08:10:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:10:18 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:10:24 visual_prompt]: Epoch 76 / 100: avg data time: 5.61e-02, avg batch time: 0.4968, average train loss: 10.3459
[09/26 08:10:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 12.6071
[09/26 08:10:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:10:26 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:10:33 visual_prompt]: Epoch 77 / 100: avg data time: 5.07e-02, avg batch time: 0.4912, average train loss: 10.1466
[09/26 08:10:34 visual_prompt]: Inference (val):avg data time: 5.13e-05, avg batch time: 0.1661, average loss: 8.7910
[09/26 08:10:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 11.00	
[09/26 08:10:34 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:10:41 visual_prompt]: Epoch 78 / 100: avg data time: 6.51e-02, avg batch time: 0.5062, average train loss: 6.7005
[09/26 08:10:43 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 6.3061
[09/26 08:10:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.50	
[09/26 08:10:43 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 08:10:49 visual_prompt]: Epoch 79 / 100: avg data time: 5.59e-02, avg batch time: 0.4973, average train loss: 5.0919
[09/26 08:10:51 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 4.6418
[09/26 08:10:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.50	
[09/26 08:10:51 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 08:10:58 visual_prompt]: Epoch 80 / 100: avg data time: 4.76e-02, avg batch time: 0.4892, average train loss: 4.2873
[09/26 08:10:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 4.1298
[09/26 08:10:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 08:10:59 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 08:11:06 visual_prompt]: Epoch 81 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 4.1458
[09/26 08:11:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 4.2329
[09/26 08:11:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.00	
[09/26 08:11:07 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 08:11:14 visual_prompt]: Epoch 82 / 100: avg data time: 4.92e-02, avg batch time: 0.4920, average train loss: 4.1417
[09/26 08:11:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 4.1401
[09/26 08:11:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 15.50	
[09/26 08:11:16 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 08:11:23 visual_prompt]: Epoch 83 / 100: avg data time: 6.33e-02, avg batch time: 0.5045, average train loss: 4.0315
[09/26 08:11:24 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 3.9660
[09/26 08:11:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:11:24 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 08:11:31 visual_prompt]: Epoch 84 / 100: avg data time: 5.33e-02, avg batch time: 0.4956, average train loss: 3.9636
[09/26 08:11:32 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1658, average loss: 3.9866
[09/26 08:11:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 14.50	
[09/26 08:11:32 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 08:11:39 visual_prompt]: Epoch 85 / 100: avg data time: 4.49e-02, avg batch time: 0.4876, average train loss: 3.9901
[09/26 08:11:41 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 4.0780
[09/26 08:11:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.00	
[09/26 08:11:41 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 08:11:47 visual_prompt]: Epoch 86 / 100: avg data time: 4.58e-02, avg batch time: 0.4882, average train loss: 4.0130
[09/26 08:11:49 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1663, average loss: 3.9720
[09/26 08:11:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 12.00	
[09/26 08:11:49 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 08:11:56 visual_prompt]: Epoch 87 / 100: avg data time: 5.29e-02, avg batch time: 0.4944, average train loss: 3.9914
[09/26 08:11:57 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 4.0502
[09/26 08:11:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 08:11:57 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 08:12:04 visual_prompt]: Epoch 88 / 100: avg data time: 5.56e-02, avg batch time: 0.4971, average train loss: 3.9546
[09/26 08:12:05 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 3.9093
[09/26 08:12:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.50	
[09/26 08:12:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 08:12:12 visual_prompt]: Epoch 89 / 100: avg data time: 5.43e-02, avg batch time: 0.4953, average train loss: 3.8330
[09/26 08:12:14 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 3.8006
[09/26 08:12:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 08:12:14 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 08:12:20 visual_prompt]: Epoch 90 / 100: avg data time: 4.76e-02, avg batch time: 0.4908, average train loss: 3.6646
[09/26 08:12:22 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 3.5215
[09/26 08:12:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 22.50	
[09/26 08:12:22 visual_prompt]: Best epoch 90: best metric: 0.080
[09/26 08:12:22 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 08:12:29 visual_prompt]: Epoch 91 / 100: avg data time: 5.96e-02, avg batch time: 0.5009, average train loss: 3.6503
[09/26 08:12:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 3.5563
[09/26 08:12:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 28.50	
[09/26 08:12:30 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 08:12:37 visual_prompt]: Epoch 92 / 100: avg data time: 4.89e-02, avg batch time: 0.4915, average train loss: 3.5722
[09/26 08:12:39 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 3.3944
[09/26 08:12:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.50	top5: 24.50	
[09/26 08:12:39 visual_prompt]: Best epoch 92: best metric: 0.105
[09/26 08:12:39 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 08:12:45 visual_prompt]: Epoch 93 / 100: avg data time: 5.07e-02, avg batch time: 0.4941, average train loss: 3.4552
[09/26 08:12:47 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1660, average loss: 3.4120
[09/26 08:12:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 24.50	
[09/26 08:12:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 08:12:54 visual_prompt]: Epoch 94 / 100: avg data time: 5.19e-02, avg batch time: 0.4943, average train loss: 3.3043
[09/26 08:12:55 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1662, average loss: 3.2551
[09/26 08:12:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 34.00	
[09/26 08:12:55 visual_prompt]: Best epoch 94: best metric: 0.130
[09/26 08:12:55 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 08:13:02 visual_prompt]: Epoch 95 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 3.1049
[09/26 08:13:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 3.0821
[09/26 08:13:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 45.50	
[09/26 08:13:03 visual_prompt]: Best epoch 95: best metric: 0.155
[09/26 08:13:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 08:13:10 visual_prompt]: Epoch 96 / 100: avg data time: 4.75e-02, avg batch time: 0.4901, average train loss: 2.7977
[09/26 08:13:12 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1661, average loss: 2.8479
[09/26 08:13:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.00	top5: 54.00	
[09/26 08:13:12 visual_prompt]: Best epoch 96: best metric: 0.210
[09/26 08:13:12 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 08:13:19 visual_prompt]: Epoch 97 / 100: avg data time: 5.81e-02, avg batch time: 0.4998, average train loss: 2.5392
[09/26 08:13:20 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 2.6204
[09/26 08:13:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 31.00	top5: 60.50	
[09/26 08:13:20 visual_prompt]: Best epoch 97: best metric: 0.310
[09/26 08:13:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 08:13:27 visual_prompt]: Epoch 98 / 100: avg data time: 6.10e-02, avg batch time: 0.5035, average train loss: 2.2595
[09/26 08:13:28 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 2.3745
[09/26 08:13:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 33.00	top5: 69.50	
[09/26 08:13:28 visual_prompt]: Best epoch 98: best metric: 0.330
[09/26 08:13:28 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 08:13:35 visual_prompt]: Epoch 99 / 100: avg data time: 5.12e-02, avg batch time: 0.4948, average train loss: 2.0536
[09/26 08:13:37 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 2.3328
[09/26 08:13:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 32.50	top5: 68.50	
[09/26 08:13:37 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 08:13:43 visual_prompt]: Epoch 100 / 100: avg data time: 4.14e-02, avg batch time: 0.4834, average train loss: 1.9384
[09/26 08:13:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 2.2936
[09/26 08:13:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 32.50	top5: 69.50	
[09/26 08:13:45 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:13:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:13:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:13:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:13:45 visual_prompt]: Training with config:
[09/26 08:13:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:13:45 visual_prompt]: Loading training data...
[09/26 08:13:45 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:13:46 visual_prompt]: Number of images: 800
[09/26 08:13:46 visual_prompt]: Number of classes: 45 / 45
[09/26 08:13:46 visual_prompt]: Loading validation data...
[09/26 08:13:46 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:13:46 visual_prompt]: Number of images: 200
[09/26 08:13:46 visual_prompt]: Number of classes: 45 / 45
[09/26 08:13:46 visual_prompt]: Constructing models...
[09/26 08:13:49 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 08:13:49 visual_prompt]: tuned percent:0.574
[09/26 08:13:49 visual_prompt]: Device used for model: 0
[09/26 08:13:49 visual_prompt]: Setting up Evaluator...
[09/26 08:13:49 visual_prompt]: Setting up Trainer...
[09/26 08:13:49 visual_prompt]: 	Setting up the optimizer...
[09/26 08:13:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:13:56 visual_prompt]: Epoch 1 / 100: avg data time: 5.84e-02, avg batch time: 0.4994, average train loss: 3.8877
[09/26 08:13:57 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 08:13:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 08:13:57 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 08:13:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:14:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.83e-02, avg batch time: 0.4994, average train loss: 4.1824
[09/26 08:14:06 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1658, average loss: 4.2007
[09/26 08:14:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 15.50	
[09/26 08:14:06 visual_prompt]: Best epoch 2: best metric: 0.035
[09/26 08:14:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:14:12 visual_prompt]: Epoch 3 / 100: avg data time: 6.20e-02, avg batch time: 0.5026, average train loss: 5.3377
[09/26 08:14:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1657, average loss: 6.0952
[09/26 08:14:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:14:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:14:21 visual_prompt]: Epoch 4 / 100: avg data time: 5.59e-02, avg batch time: 0.4983, average train loss: 10.3978
[09/26 08:14:22 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1656, average loss: 12.8368
[09/26 08:14:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 08:14:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:14:29 visual_prompt]: Epoch 5 / 100: avg data time: 5.13e-02, avg batch time: 0.4914, average train loss: 20.7523
[09/26 08:14:31 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1655, average loss: 27.9257
[09/26 08:14:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:14:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:14:37 visual_prompt]: Epoch 6 / 100: avg data time: 6.37e-02, avg batch time: 0.5041, average train loss: 34.4443
[09/26 08:14:39 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 43.8357
[09/26 08:14:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:14:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:14:46 visual_prompt]: Epoch 7 / 100: avg data time: 6.57e-02, avg batch time: 0.5076, average train loss: 50.1778
[09/26 08:14:47 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 58.8647
[09/26 08:14:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 08:14:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:14:54 visual_prompt]: Epoch 8 / 100: avg data time: 6.18e-02, avg batch time: 0.5035, average train loss: 56.5603
[09/26 08:14:56 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 89.7788
[09/26 08:14:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 11.00	
[09/26 08:14:56 visual_prompt]: Best epoch 8: best metric: 0.040
[09/26 08:14:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:15:03 visual_prompt]: Epoch 9 / 100: avg data time: 5.24e-02, avg batch time: 0.4955, average train loss: 73.4183
[09/26 08:15:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 81.9732
[09/26 08:15:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 14.50	
[09/26 08:15:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:15:11 visual_prompt]: Epoch 10 / 100: avg data time: 6.03e-02, avg batch time: 0.5015, average train loss: 103.1543
[09/26 08:15:13 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 113.7624
[09/26 08:15:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 08:15:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:15:19 visual_prompt]: Epoch 11 / 100: avg data time: 5.77e-02, avg batch time: 0.4999, average train loss: 95.4337
[09/26 08:15:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 139.3619
[09/26 08:15:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 08:15:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:15:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.62e-02, avg batch time: 0.4890, average train loss: 204.9522
[09/26 08:15:29 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1657, average loss: 264.7051
[09/26 08:15:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:15:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:15:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.76e-02, avg batch time: 0.5004, average train loss: 139.2501
[09/26 08:15:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 114.9404
[09/26 08:15:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 08:15:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:15:44 visual_prompt]: Epoch 14 / 100: avg data time: 4.77e-02, avg batch time: 0.4919, average train loss: 129.7224
[09/26 08:15:46 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 117.2531
[09/26 08:15:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 08:15:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:15:52 visual_prompt]: Epoch 15 / 100: avg data time: 4.90e-02, avg batch time: 0.4918, average train loss: 141.1493
[09/26 08:15:54 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1660, average loss: 137.4208
[09/26 08:15:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 08:15:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:16:01 visual_prompt]: Epoch 16 / 100: avg data time: 4.96e-02, avg batch time: 0.4925, average train loss: 180.2554
[09/26 08:16:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 163.8829
[09/26 08:16:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:16:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:16:09 visual_prompt]: Epoch 17 / 100: avg data time: 5.01e-02, avg batch time: 0.4924, average train loss: 172.2783
[09/26 08:16:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 187.3963
[09/26 08:16:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:16:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:16:17 visual_prompt]: Epoch 18 / 100: avg data time: 5.70e-02, avg batch time: 0.4988, average train loss: 167.9931
[09/26 08:16:19 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1658, average loss: 138.9182
[09/26 08:16:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:16:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:16:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.71e-02, avg batch time: 0.4992, average train loss: 148.4204
[09/26 08:16:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 117.7131
[09/26 08:16:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 08:16:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:16:34 visual_prompt]: Epoch 20 / 100: avg data time: 6.26e-02, avg batch time: 0.5040, average train loss: 120.0154
[09/26 08:16:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 120.9447
[09/26 08:16:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:16:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:16:43 visual_prompt]: Epoch 21 / 100: avg data time: 6.39e-02, avg batch time: 0.5044, average train loss: 167.6838
[09/26 08:16:44 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 255.1032
[09/26 08:16:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:16:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:16:51 visual_prompt]: Epoch 22 / 100: avg data time: 5.93e-02, avg batch time: 0.5008, average train loss: 179.2459
[09/26 08:16:52 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 135.8895
[09/26 08:16:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:16:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:16:59 visual_prompt]: Epoch 23 / 100: avg data time: 4.51e-02, avg batch time: 0.4885, average train loss: 158.6177
[09/26 08:17:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 160.1220
[09/26 08:17:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:17:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:17:07 visual_prompt]: Epoch 24 / 100: avg data time: 6.17e-02, avg batch time: 0.5029, average train loss: 160.1724
[09/26 08:17:09 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1660, average loss: 162.4389
[09/26 08:17:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.00	
[09/26 08:17:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:17:16 visual_prompt]: Epoch 25 / 100: avg data time: 5.85e-02, avg batch time: 0.4995, average train loss: 158.4330
[09/26 08:17:17 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1659, average loss: 148.7387
[09/26 08:17:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.00	
[09/26 08:17:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:17:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.32e-02, avg batch time: 0.4956, average train loss: 136.3851
[09/26 08:17:26 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1659, average loss: 136.2054
[09/26 08:17:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 10.50	
[09/26 08:17:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:17:32 visual_prompt]: Epoch 27 / 100: avg data time: 5.23e-02, avg batch time: 0.4954, average train loss: 119.4264
[09/26 08:17:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 105.0615
[09/26 08:17:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 08:17:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:17:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.88e-02, avg batch time: 0.5002, average train loss: 105.5333
[09/26 08:17:42 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 132.5536
[09/26 08:17:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 08:17:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:17:49 visual_prompt]: Epoch 29 / 100: avg data time: 4.88e-02, avg batch time: 0.4895, average train loss: 112.7538
[09/26 08:17:50 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 104.0733
[09/26 08:17:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:17:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:17:57 visual_prompt]: Epoch 30 / 100: avg data time: 5.95e-02, avg batch time: 0.4996, average train loss: 110.0927
[09/26 08:17:59 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 131.8283
[09/26 08:17:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:17:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:18:06 visual_prompt]: Epoch 31 / 100: avg data time: 6.58e-02, avg batch time: 0.5066, average train loss: 166.1743
[09/26 08:18:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 115.3447
[09/26 08:18:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:18:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:18:14 visual_prompt]: Epoch 32 / 100: avg data time: 5.25e-02, avg batch time: 0.4951, average train loss: 120.3603
[09/26 08:18:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 130.5956
[09/26 08:18:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:18:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:18:22 visual_prompt]: Epoch 33 / 100: avg data time: 5.54e-02, avg batch time: 0.4966, average train loss: 125.9738
[09/26 08:18:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 101.8190
[09/26 08:18:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 08:18:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:18:31 visual_prompt]: Epoch 34 / 100: avg data time: 6.36e-02, avg batch time: 0.5049, average train loss: 99.9696
[09/26 08:18:32 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1658, average loss: 99.0786
[09/26 08:18:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 16.00	
[09/26 08:18:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:18:39 visual_prompt]: Epoch 35 / 100: avg data time: 6.29e-02, avg batch time: 0.5042, average train loss: 98.0536
[09/26 08:18:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 87.4334
[09/26 08:18:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.00	
[09/26 08:18:41 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:18:48 visual_prompt]: Epoch 36 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 91.1321
[09/26 08:18:49 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 83.4968
[09/26 08:18:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 11.00	
[09/26 08:18:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:18:56 visual_prompt]: Epoch 37 / 100: avg data time: 5.36e-02, avg batch time: 0.4953, average train loss: 91.2436
[09/26 08:18:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 97.1458
[09/26 08:18:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 08:18:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:19:04 visual_prompt]: Epoch 38 / 100: avg data time: 6.44e-02, avg batch time: 0.5066, average train loss: 96.8208
[09/26 08:19:06 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 100.3476
[09/26 08:19:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:19:06 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:19:13 visual_prompt]: Epoch 39 / 100: avg data time: 6.13e-02, avg batch time: 0.5016, average train loss: 101.6228
[09/26 08:19:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1658, average loss: 84.8322
[09/26 08:19:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 08:19:14 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:19:21 visual_prompt]: Epoch 40 / 100: avg data time: 6.41e-02, avg batch time: 0.5041, average train loss: 104.6437
[09/26 08:19:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1657, average loss: 89.3688
[09/26 08:19:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:19:23 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:19:29 visual_prompt]: Epoch 41 / 100: avg data time: 6.16e-02, avg batch time: 0.5031, average train loss: 79.5152
[09/26 08:19:31 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 87.3897
[09/26 08:19:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 08:19:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:19:38 visual_prompt]: Epoch 42 / 100: avg data time: 4.81e-02, avg batch time: 0.4898, average train loss: 79.1479
[09/26 08:19:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 89.7809
[09/26 08:19:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:19:39 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:19:46 visual_prompt]: Epoch 43 / 100: avg data time: 5.42e-02, avg batch time: 0.4948, average train loss: 88.2921
[09/26 08:19:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1657, average loss: 76.3955
[09/26 08:19:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 08:19:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:19:54 visual_prompt]: Epoch 44 / 100: avg data time: 4.54e-02, avg batch time: 0.4873, average train loss: 73.3531
[09/26 08:19:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 70.0475
[09/26 08:19:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 08:19:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:20:02 visual_prompt]: Epoch 45 / 100: avg data time: 4.56e-02, avg batch time: 0.4881, average train loss: 67.8231
[09/26 08:20:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 82.3439
[09/26 08:20:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:20:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:20:11 visual_prompt]: Epoch 46 / 100: avg data time: 4.60e-02, avg batch time: 0.4887, average train loss: 71.7019
[09/26 08:20:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 74.6556
[09/26 08:20:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:20:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:20:19 visual_prompt]: Epoch 47 / 100: avg data time: 6.02e-02, avg batch time: 0.5009, average train loss: 70.4761
[09/26 08:20:20 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1658, average loss: 80.7084
[09/26 08:20:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:20:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:20:27 visual_prompt]: Epoch 48 / 100: avg data time: 6.30e-02, avg batch time: 0.5053, average train loss: 73.6940
[09/26 08:20:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 65.3741
[09/26 08:20:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:20:29 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:20:36 visual_prompt]: Epoch 49 / 100: avg data time: 4.67e-02, avg batch time: 0.4901, average train loss: 77.5639
[09/26 08:20:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 100.8989
[09/26 08:20:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.00	
[09/26 08:20:37 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:20:44 visual_prompt]: Epoch 50 / 100: avg data time: 5.69e-02, avg batch time: 0.4983, average train loss: 80.6634
[09/26 08:20:46 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 61.0348
[09/26 08:20:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 08:20:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:20:52 visual_prompt]: Epoch 51 / 100: avg data time: 5.78e-02, avg batch time: 0.4985, average train loss: 54.2072
[09/26 08:20:54 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1661, average loss: 48.3965
[09/26 08:20:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 08:20:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:21:01 visual_prompt]: Epoch 52 / 100: avg data time: 5.79e-02, avg batch time: 0.4991, average train loss: 55.1619
[09/26 08:21:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1660, average loss: 49.9931
[09/26 08:21:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:21:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:21:09 visual_prompt]: Epoch 53 / 100: avg data time: 4.97e-02, avg batch time: 0.4925, average train loss: 47.8011
[09/26 08:21:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1661, average loss: 31.5082
[09/26 08:21:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 08:21:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:21:17 visual_prompt]: Epoch 54 / 100: avg data time: 6.17e-02, avg batch time: 0.5030, average train loss: 36.9433
[09/26 08:21:19 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1660, average loss: 38.3484
[09/26 08:21:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 08:21:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:21:26 visual_prompt]: Epoch 55 / 100: avg data time: 6.00e-02, avg batch time: 0.5012, average train loss: 39.2415
[09/26 08:21:27 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1660, average loss: 42.2209
[09/26 08:21:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:21:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:21:34 visual_prompt]: Epoch 56 / 100: avg data time: 5.82e-02, avg batch time: 0.4986, average train loss: 36.7212
[09/26 08:21:36 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 41.1231
[09/26 08:21:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 08:21:36 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:21:43 visual_prompt]: Epoch 57 / 100: avg data time: 5.36e-02, avg batch time: 0.4949, average train loss: 36.7921
[09/26 08:21:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1662, average loss: 37.7016
[09/26 08:21:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 08:21:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:21:51 visual_prompt]: Epoch 58 / 100: avg data time: 6.24e-02, avg batch time: 0.5028, average train loss: 37.4978
[09/26 08:21:52 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 30.6351
[09/26 08:21:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:21:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:21:59 visual_prompt]: Epoch 59 / 100: avg data time: 5.64e-02, avg batch time: 0.4966, average train loss: 34.3635
[09/26 08:22:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1657, average loss: 34.9726
[09/26 08:22:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 6.00	
[09/26 08:22:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:22:08 visual_prompt]: Epoch 60 / 100: avg data time: 6.20e-02, avg batch time: 0.5021, average train loss: 36.1669
[09/26 08:22:09 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1659, average loss: 29.6206
[09/26 08:22:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:22:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:22:16 visual_prompt]: Epoch 61 / 100: avg data time: 5.66e-02, avg batch time: 0.4980, average train loss: 26.5692
[09/26 08:22:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1658, average loss: 21.2602
[09/26 08:22:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:22:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:22:24 visual_prompt]: Epoch 62 / 100: avg data time: 6.52e-02, avg batch time: 0.5057, average train loss: 20.5798
[09/26 08:22:26 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1658, average loss: 24.0900
[09/26 08:22:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.00	
[09/26 08:22:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:22:33 visual_prompt]: Epoch 63 / 100: avg data time: 5.11e-02, avg batch time: 0.4964, average train loss: 21.1819
[09/26 08:22:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 17.5472
[09/26 08:22:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:22:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:22:41 visual_prompt]: Epoch 64 / 100: avg data time: 5.29e-02, avg batch time: 0.4951, average train loss: 14.3188
[09/26 08:22:43 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1660, average loss: 12.7638
[09/26 08:22:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 08:22:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:22:49 visual_prompt]: Epoch 65 / 100: avg data time: 5.98e-02, avg batch time: 0.5003, average train loss: 11.0229
[09/26 08:22:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 8.3162
[09/26 08:22:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:22:51 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:22:58 visual_prompt]: Epoch 66 / 100: avg data time: 4.69e-02, avg batch time: 0.4886, average train loss: 7.5411
[09/26 08:22:59 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 5.8150
[09/26 08:22:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 08:22:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:23:06 visual_prompt]: Epoch 67 / 100: avg data time: 5.11e-02, avg batch time: 0.4931, average train loss: 5.5613
[09/26 08:23:07 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 5.1479
[09/26 08:23:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:23:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:23:14 visual_prompt]: Epoch 68 / 100: avg data time: 5.88e-02, avg batch time: 0.5024, average train loss: 4.7477
[09/26 08:23:16 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.1661, average loss: 4.2947
[09/26 08:23:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 08:23:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:23:23 visual_prompt]: Epoch 69 / 100: avg data time: 5.79e-02, avg batch time: 0.4989, average train loss: 4.2624
[09/26 08:23:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1662, average loss: 4.3000
[09/26 08:23:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.50	
[09/26 08:23:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:23:31 visual_prompt]: Epoch 70 / 100: avg data time: 5.13e-02, avg batch time: 0.4925, average train loss: 4.2290
[09/26 08:23:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 4.2227
[09/26 08:23:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 08:23:32 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:23:39 visual_prompt]: Epoch 71 / 100: avg data time: 5.88e-02, avg batch time: 0.5009, average train loss: 4.3341
[09/26 08:23:41 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 4.2577
[09/26 08:23:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 19.00	
[09/26 08:23:41 visual_prompt]: Best epoch 71: best metric: 0.070
[09/26 08:23:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:23:48 visual_prompt]: Epoch 72 / 100: avg data time: 6.09e-02, avg batch time: 0.5025, average train loss: 3.9304
[09/26 08:23:49 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 3.8596
[09/26 08:23:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.00	top5: 27.00	
[09/26 08:23:49 visual_prompt]: Best epoch 72: best metric: 0.100
[09/26 08:23:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:23:56 visual_prompt]: Epoch 73 / 100: avg data time: 5.65e-02, avg batch time: 0.4985, average train loss: 3.7446
[09/26 08:23:58 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1661, average loss: 3.6985
[09/26 08:23:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 29.00	
[09/26 08:23:58 visual_prompt]: Best epoch 73: best metric: 0.110
[09/26 08:23:58 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:24:04 visual_prompt]: Epoch 74 / 100: avg data time: 6.12e-02, avg batch time: 0.5029, average train loss: 3.5587
[09/26 08:24:06 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 3.6248
[09/26 08:24:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 30.50	
[09/26 08:24:06 visual_prompt]: Best epoch 74: best metric: 0.125
[09/26 08:24:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:24:13 visual_prompt]: Epoch 75 / 100: avg data time: 6.06e-02, avg batch time: 0.5026, average train loss: 3.3596
[09/26 08:24:14 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1664, average loss: 3.2354
[09/26 08:24:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 41.00	
[09/26 08:24:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:24:21 visual_prompt]: Epoch 76 / 100: avg data time: 6.76e-02, avg batch time: 0.5092, average train loss: 3.1780
[09/26 08:24:23 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 3.4961
[09/26 08:24:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 34.00	
[09/26 08:24:23 visual_prompt]: Best epoch 76: best metric: 0.130
[09/26 08:24:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:24:30 visual_prompt]: Epoch 77 / 100: avg data time: 5.70e-02, avg batch time: 0.4996, average train loss: 3.0753
[09/26 08:24:31 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 2.9833
[09/26 08:24:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 53.50	
[09/26 08:24:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:24:38 visual_prompt]: Epoch 78 / 100: avg data time: 5.38e-02, avg batch time: 0.4965, average train loss: 2.6888
[09/26 08:24:39 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1663, average loss: 2.7094
[09/26 08:24:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.00	top5: 56.00	
[09/26 08:24:39 visual_prompt]: Best epoch 78: best metric: 0.210
[09/26 08:24:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 08:24:46 visual_prompt]: Epoch 79 / 100: avg data time: 5.19e-02, avg batch time: 0.4950, average train loss: 2.5416
[09/26 08:24:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 3.1057
[09/26 08:24:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.00	top5: 49.00	
[09/26 08:24:48 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 08:24:55 visual_prompt]: Epoch 80 / 100: avg data time: 5.83e-02, avg batch time: 0.5005, average train loss: 2.4761
[09/26 08:24:56 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 2.7438
[09/26 08:24:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 57.50	
[09/26 08:24:56 visual_prompt]: Best epoch 80: best metric: 0.245
[09/26 08:24:56 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 08:25:03 visual_prompt]: Epoch 81 / 100: avg data time: 6.32e-02, avg batch time: 0.5048, average train loss: 2.2055
[09/26 08:25:05 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1664, average loss: 2.3255
[09/26 08:25:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.00	top5: 70.00	
[09/26 08:25:05 visual_prompt]: Best epoch 81: best metric: 0.400
[09/26 08:25:05 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 08:25:11 visual_prompt]: Epoch 82 / 100: avg data time: 5.01e-02, avg batch time: 0.4938, average train loss: 1.9787
[09/26 08:25:13 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 2.0303
[09/26 08:25:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 38.00	top5: 75.50	
[09/26 08:25:13 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 08:25:20 visual_prompt]: Epoch 83 / 100: avg data time: 5.50e-02, avg batch time: 0.4981, average train loss: 1.6493
[09/26 08:25:21 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1664, average loss: 1.7993
[09/26 08:25:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.50	top5: 83.00	
[09/26 08:25:21 visual_prompt]: Best epoch 83: best metric: 0.495
[09/26 08:25:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 08:25:28 visual_prompt]: Epoch 84 / 100: avg data time: 6.14e-02, avg batch time: 0.5043, average train loss: 1.3404
[09/26 08:25:30 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 1.7581
[09/26 08:25:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.00	top5: 83.50	
[09/26 08:25:30 visual_prompt]: Best epoch 84: best metric: 0.500
[09/26 08:25:30 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 08:25:36 visual_prompt]: Epoch 85 / 100: avg data time: 4.81e-02, avg batch time: 0.4916, average train loss: 1.0349
[09/26 08:25:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.8256
[09/26 08:25:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 51.50	top5: 85.00	
[09/26 08:25:38 visual_prompt]: Best epoch 85: best metric: 0.515
[09/26 08:25:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 08:25:45 visual_prompt]: Epoch 86 / 100: avg data time: 5.02e-02, avg batch time: 0.4937, average train loss: 0.9878
[09/26 08:25:46 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1664, average loss: 1.6664
[09/26 08:25:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.50	top5: 88.00	
[09/26 08:25:46 visual_prompt]: Best epoch 86: best metric: 0.565
[09/26 08:25:46 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 08:25:53 visual_prompt]: Epoch 87 / 100: avg data time: 5.57e-02, avg batch time: 0.4986, average train loss: 0.7019
[09/26 08:25:55 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1668, average loss: 1.6173
[09/26 08:25:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 59.00	top5: 89.00	
[09/26 08:25:55 visual_prompt]: Best epoch 87: best metric: 0.590
[09/26 08:25:55 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 08:26:01 visual_prompt]: Epoch 88 / 100: avg data time: 5.53e-02, avg batch time: 0.4971, average train loss: 0.5380
[09/26 08:26:03 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1665, average loss: 1.4962
[09/26 08:26:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 92.50	
[09/26 08:26:03 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 08:26:10 visual_prompt]: Epoch 89 / 100: avg data time: 5.44e-02, avg batch time: 0.4979, average train loss: 0.3754
[09/26 08:26:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 1.4187
[09/26 08:26:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.00	
[09/26 08:26:11 visual_prompt]: Best epoch 89: best metric: 0.670
[09/26 08:26:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 08:26:18 visual_prompt]: Epoch 90 / 100: avg data time: 5.74e-02, avg batch time: 0.5001, average train loss: 0.2522
[09/26 08:26:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.4451
[09/26 08:26:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.50	
[09/26 08:26:20 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 08:26:27 visual_prompt]: Epoch 91 / 100: avg data time: 6.04e-02, avg batch time: 0.5031, average train loss: 0.1970
[09/26 08:26:28 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.4758
[09/26 08:26:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 94.00	
[09/26 08:26:28 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 08:26:35 visual_prompt]: Epoch 92 / 100: avg data time: 5.31e-02, avg batch time: 0.4976, average train loss: 0.1182
[09/26 08:26:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.3001
[09/26 08:26:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 94.00	
[09/26 08:26:36 visual_prompt]: Best epoch 92: best metric: 0.680
[09/26 08:26:36 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 08:26:43 visual_prompt]: Epoch 93 / 100: avg data time: 6.04e-02, avg batch time: 0.5022, average train loss: 0.0697
[09/26 08:26:45 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 1.2850
[09/26 08:26:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 08:26:45 visual_prompt]: Best epoch 93: best metric: 0.710
[09/26 08:26:45 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 08:26:52 visual_prompt]: Epoch 94 / 100: avg data time: 5.41e-02, avg batch time: 0.4970, average train loss: 0.0404
[09/26 08:26:53 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.2475
[09/26 08:26:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.00	
[09/26 08:26:53 visual_prompt]: Best epoch 94: best metric: 0.730
[09/26 08:26:53 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 08:27:00 visual_prompt]: Epoch 95 / 100: avg data time: 5.63e-02, avg batch time: 0.4997, average train loss: 0.0289
[09/26 08:27:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 1.3002
[09/26 08:27:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 94.50	
[09/26 08:27:02 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 08:27:08 visual_prompt]: Epoch 96 / 100: avg data time: 5.78e-02, avg batch time: 0.4997, average train loss: 0.0276
[09/26 08:27:10 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.2989
[09/26 08:27:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 95.00	
[09/26 08:27:10 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 08:27:17 visual_prompt]: Epoch 97 / 100: avg data time: 6.29e-02, avg batch time: 0.5068, average train loss: 0.0227
[09/26 08:27:18 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1666, average loss: 1.2663
[09/26 08:27:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 08:27:18 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 08:27:25 visual_prompt]: Epoch 98 / 100: avg data time: 5.40e-02, avg batch time: 0.4962, average train loss: 0.0233
[09/26 08:27:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1671, average loss: 1.2700
[09/26 08:27:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 08:27:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 08:27:34 visual_prompt]: Epoch 99 / 100: avg data time: 5.30e-02, avg batch time: 0.4970, average train loss: 0.0209
[09/26 08:27:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 1.2742
[09/26 08:27:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 08:27:35 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 08:27:42 visual_prompt]: Epoch 100 / 100: avg data time: 5.83e-02, avg batch time: 0.5015, average train loss: 0.0223
[09/26 08:27:43 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1666, average loss: 1.2755
[09/26 08:27:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 08:27:43 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:27:43 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:27:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:27:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:27:43 visual_prompt]: Training with config:
[09/26 08:27:43 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr25.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:27:43 visual_prompt]: Loading training data...
[09/26 08:27:43 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:27:45 visual_prompt]: Number of images: 800
[09/26 08:27:45 visual_prompt]: Number of classes: 45 / 45
[09/26 08:27:45 visual_prompt]: Loading validation data...
[09/26 08:27:45 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:27:45 visual_prompt]: Number of images: 200
[09/26 08:27:45 visual_prompt]: Number of classes: 45 / 45
[09/26 08:27:45 visual_prompt]: Constructing models...
[09/26 08:27:48 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 08:27:48 visual_prompt]: tuned percent:0.574
[09/26 08:27:48 visual_prompt]: Device used for model: 0
[09/26 08:27:48 visual_prompt]: Setting up Evaluator...
[09/26 08:27:48 visual_prompt]: Setting up Trainer...
[09/26 08:27:48 visual_prompt]: 	Setting up the optimizer...
[09/26 08:27:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:27:55 visual_prompt]: Epoch 1 / 100: avg data time: 5.67e-02, avg batch time: 0.4989, average train loss: 3.8963
[09/26 08:27:56 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 08:27:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 08:27:56 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 08:27:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[09/26 08:28:03 visual_prompt]: Epoch 2 / 100: avg data time: 5.48e-02, avg batch time: 0.4960, average train loss: 4.5790
[09/26 08:28:04 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1657, average loss: 4.2639
[09/26 08:28:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.50	
[09/26 08:28:04 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 08:28:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[09/26 08:28:11 visual_prompt]: Epoch 3 / 100: avg data time: 5.41e-02, avg batch time: 0.4949, average train loss: 4.8666
[09/26 08:28:13 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1657, average loss: 6.1400
[09/26 08:28:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:28:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[09/26 08:28:19 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e-02, avg batch time: 0.4912, average train loss: 7.1564
[09/26 08:28:21 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1659, average loss: 7.6590
[09/26 08:28:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 18.00	
[09/26 08:28:21 visual_prompt]: Best epoch 4: best metric: 0.065
[09/26 08:28:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[09/26 08:28:28 visual_prompt]: Epoch 5 / 100: avg data time: 5.05e-02, avg batch time: 0.4930, average train loss: 9.1324
[09/26 08:28:29 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 10.5872
[09/26 08:28:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 16.50	
[09/26 08:28:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[09/26 08:28:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.41e-02, avg batch time: 0.4967, average train loss: 12.9994
[09/26 08:28:38 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1660, average loss: 18.6190
[09/26 08:28:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.00	
[09/26 08:28:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[09/26 08:28:44 visual_prompt]: Epoch 7 / 100: avg data time: 5.55e-02, avg batch time: 0.4974, average train loss: 21.5165
[09/26 08:28:46 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1660, average loss: 24.0318
[09/26 08:28:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 10.50	
[09/26 08:28:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[09/26 08:28:53 visual_prompt]: Epoch 8 / 100: avg data time: 5.85e-02, avg batch time: 0.4999, average train loss: 42.7879
[09/26 08:28:54 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1656, average loss: 77.8676
[09/26 08:28:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.00	
[09/26 08:28:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[09/26 08:29:01 visual_prompt]: Epoch 9 / 100: avg data time: 5.68e-02, avg batch time: 0.4994, average train loss: 72.3555
[09/26 08:29:03 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1662, average loss: 92.4596
[09/26 08:29:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 11.00	
[09/26 08:29:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[09/26 08:29:10 visual_prompt]: Epoch 10 / 100: avg data time: 5.98e-02, avg batch time: 0.5016, average train loss: 102.5245
[09/26 08:29:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 91.7940
[09/26 08:29:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:29:11 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[09/26 08:29:18 visual_prompt]: Epoch 11 / 100: avg data time: 5.30e-02, avg batch time: 0.4943, average train loss: 108.4689
[09/26 08:29:19 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1661, average loss: 108.3728
[09/26 08:29:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:29:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[09/26 08:29:26 visual_prompt]: Epoch 12 / 100: avg data time: 5.87e-02, avg batch time: 0.5007, average train loss: 108.7174
[09/26 08:29:28 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1656, average loss: 119.7814
[09/26 08:29:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:29:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[09/26 08:29:34 visual_prompt]: Epoch 13 / 100: avg data time: 5.28e-02, avg batch time: 0.4940, average train loss: 123.2803
[09/26 08:29:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 123.3525
[09/26 08:29:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 7.50	
[09/26 08:29:36 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[09/26 08:29:43 visual_prompt]: Epoch 14 / 100: avg data time: 5.70e-02, avg batch time: 0.4982, average train loss: 126.8488
[09/26 08:29:44 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1659, average loss: 122.9046
[09/26 08:29:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 15.00	
[09/26 08:29:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[09/26 08:29:51 visual_prompt]: Epoch 15 / 100: avg data time: 5.37e-02, avg batch time: 0.4955, average train loss: 107.4709
[09/26 08:29:53 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1659, average loss: 81.4503
[09/26 08:29:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.00	
[09/26 08:29:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[09/26 08:29:59 visual_prompt]: Epoch 16 / 100: avg data time: 4.69e-02, avg batch time: 0.4899, average train loss: 90.3395
[09/26 08:30:01 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1660, average loss: 77.7076
[09/26 08:30:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 17.50	
[09/26 08:30:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[09/26 08:30:08 visual_prompt]: Epoch 17 / 100: avg data time: 6.19e-02, avg batch time: 0.5032, average train loss: 84.0245
[09/26 08:30:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 97.2025
[09/26 08:30:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:30:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[09/26 08:30:16 visual_prompt]: Epoch 18 / 100: avg data time: 5.49e-02, avg batch time: 0.4962, average train loss: 94.2195
[09/26 08:30:18 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1661, average loss: 80.7584
[09/26 08:30:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:30:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[09/26 08:30:24 visual_prompt]: Epoch 19 / 100: avg data time: 6.47e-02, avg batch time: 0.5060, average train loss: 80.3654
[09/26 08:30:26 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 64.5854
[09/26 08:30:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 12.50	
[09/26 08:30:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[09/26 08:30:33 visual_prompt]: Epoch 20 / 100: avg data time: 5.82e-02, avg batch time: 0.4995, average train loss: 56.3772
[09/26 08:30:34 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 55.0010
[09/26 08:30:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:30:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[09/26 08:30:41 visual_prompt]: Epoch 21 / 100: avg data time: 5.79e-02, avg batch time: 0.4990, average train loss: 50.5927
[09/26 08:30:43 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 43.9282
[09/26 08:30:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 18.50	
[09/26 08:30:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[09/26 08:30:49 visual_prompt]: Epoch 22 / 100: avg data time: 4.95e-02, avg batch time: 0.4907, average train loss: 40.5191
[09/26 08:30:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 35.5052
[09/26 08:30:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 23.00	
[09/26 08:30:51 visual_prompt]: Best epoch 22: best metric: 0.070
[09/26 08:30:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[09/26 08:30:58 visual_prompt]: Epoch 23 / 100: avg data time: 5.73e-02, avg batch time: 0.4994, average train loss: 31.2503
[09/26 08:30:59 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 23.7245
[09/26 08:30:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 20.50	
[09/26 08:30:59 visual_prompt]: Best epoch 23: best metric: 0.090
[09/26 08:30:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[09/26 08:31:06 visual_prompt]: Epoch 24 / 100: avg data time: 5.13e-02, avg batch time: 0.4933, average train loss: 21.2870
[09/26 08:31:07 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 17.2719
[09/26 08:31:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 26.00	
[09/26 08:31:07 visual_prompt]: Best epoch 24: best metric: 0.095
[09/26 08:31:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[09/26 08:31:14 visual_prompt]: Epoch 25 / 100: avg data time: 5.40e-02, avg batch time: 0.4960, average train loss: 15.1442
[09/26 08:31:16 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 11.5530
[09/26 08:31:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 28.00	
[09/26 08:31:16 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[09/26 08:31:23 visual_prompt]: Epoch 26 / 100: avg data time: 5.74e-02, avg batch time: 0.4986, average train loss: 11.6089
[09/26 08:31:24 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 9.5748
[09/26 08:31:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 34.00	
[09/26 08:31:24 visual_prompt]: Best epoch 26: best metric: 0.120
[09/26 08:31:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[09/26 08:31:31 visual_prompt]: Epoch 27 / 100: avg data time: 5.91e-02, avg batch time: 0.5005, average train loss: 8.9491
[09/26 08:31:33 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 9.8964
[09/26 08:31:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 16.50	top5: 36.50	
[09/26 08:31:33 visual_prompt]: Best epoch 27: best metric: 0.165
[09/26 08:31:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[09/26 08:31:39 visual_prompt]: Epoch 28 / 100: avg data time: 5.79e-02, avg batch time: 0.4998, average train loss: 7.6730
[09/26 08:31:41 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1661, average loss: 6.7780
[09/26 08:31:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.00	top5: 49.00	
[09/26 08:31:41 visual_prompt]: Best epoch 28: best metric: 0.190
[09/26 08:31:41 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[09/26 08:31:48 visual_prompt]: Epoch 29 / 100: avg data time: 5.70e-02, avg batch time: 0.4986, average train loss: 6.7747
[09/26 08:31:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 5.6041
[09/26 08:31:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 28.50	top5: 50.50	
[09/26 08:31:49 visual_prompt]: Best epoch 29: best metric: 0.285
[09/26 08:31:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[09/26 08:31:56 visual_prompt]: Epoch 30 / 100: avg data time: 5.95e-02, avg batch time: 0.5005, average train loss: 5.7106
[09/26 08:31:58 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1661, average loss: 4.1906
[09/26 08:31:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.00	top5: 60.00	
[09/26 08:31:58 visual_prompt]: Best epoch 30: best metric: 0.290
[09/26 08:31:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[09/26 08:32:05 visual_prompt]: Epoch 31 / 100: avg data time: 5.44e-02, avg batch time: 0.4965, average train loss: 4.9521
[09/26 08:32:06 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 6.1458
[09/26 08:32:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.00	top5: 50.50	
[09/26 08:32:06 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[09/26 08:32:13 visual_prompt]: Epoch 32 / 100: avg data time: 4.59e-02, avg batch time: 0.4882, average train loss: 4.9658
[09/26 08:32:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 5.2264
[09/26 08:32:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.00	top5: 55.50	
[09/26 08:32:14 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[09/26 08:32:21 visual_prompt]: Epoch 33 / 100: avg data time: 5.69e-02, avg batch time: 0.4986, average train loss: 4.7595
[09/26 08:32:23 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 3.9585
[09/26 08:32:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.50	top5: 63.50	
[09/26 08:32:23 visual_prompt]: Best epoch 33: best metric: 0.305
[09/26 08:32:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[09/26 08:32:30 visual_prompt]: Epoch 34 / 100: avg data time: 5.54e-02, avg batch time: 0.4978, average train loss: 4.6906
[09/26 08:32:31 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 5.2639
[09/26 08:32:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 35.00	top5: 59.00	
[09/26 08:32:31 visual_prompt]: Best epoch 34: best metric: 0.350
[09/26 08:32:31 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[09/26 08:32:38 visual_prompt]: Epoch 35 / 100: avg data time: 4.83e-02, avg batch time: 0.4908, average train loss: 4.6184
[09/26 08:32:39 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1662, average loss: 5.1959
[09/26 08:32:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 58.50	
[09/26 08:32:39 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[09/26 08:32:46 visual_prompt]: Epoch 36 / 100: avg data time: 6.69e-02, avg batch time: 0.5080, average train loss: 4.2312
[09/26 08:32:48 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1660, average loss: 3.3031
[09/26 08:32:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 42.50	top5: 69.00	
[09/26 08:32:48 visual_prompt]: Best epoch 36: best metric: 0.425
[09/26 08:32:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[09/26 08:32:55 visual_prompt]: Epoch 37 / 100: avg data time: 5.26e-02, avg batch time: 0.4945, average train loss: 3.7432
[09/26 08:32:56 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1659, average loss: 3.4145
[09/26 08:32:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.00	top5: 74.00	
[09/26 08:32:56 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[09/26 08:33:03 visual_prompt]: Epoch 38 / 100: avg data time: 5.85e-02, avg batch time: 0.5003, average train loss: 3.6950
[09/26 08:33:05 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1661, average loss: 3.7469
[09/26 08:33:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 41.00	top5: 70.00	
[09/26 08:33:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[09/26 08:33:11 visual_prompt]: Epoch 39 / 100: avg data time: 5.34e-02, avg batch time: 0.4965, average train loss: 3.8963
[09/26 08:33:13 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1661, average loss: 2.9933
[09/26 08:33:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.00	top5: 77.50	
[09/26 08:33:13 visual_prompt]: Best epoch 39: best metric: 0.430
[09/26 08:33:13 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[09/26 08:33:20 visual_prompt]: Epoch 40 / 100: avg data time: 6.11e-02, avg batch time: 0.5035, average train loss: 3.2882
[09/26 08:33:21 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 3.6924
[09/26 08:33:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 42.00	top5: 72.00	
[09/26 08:33:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[09/26 08:33:28 visual_prompt]: Epoch 41 / 100: avg data time: 4.67e-02, avg batch time: 0.4887, average train loss: 2.9472
[09/26 08:33:29 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1662, average loss: 3.6554
[09/26 08:33:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.00	top5: 69.50	
[09/26 08:33:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[09/26 08:33:36 visual_prompt]: Epoch 42 / 100: avg data time: 6.34e-02, avg batch time: 0.5047, average train loss: 2.7920
[09/26 08:33:38 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 3.1217
[09/26 08:33:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 44.50	top5: 75.50	
[09/26 08:33:38 visual_prompt]: Best epoch 42: best metric: 0.445
[09/26 08:33:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[09/26 08:33:45 visual_prompt]: Epoch 43 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 2.7589
[09/26 08:33:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 3.3581
[09/26 08:33:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.00	top5: 69.50	
[09/26 08:33:46 visual_prompt]: Best epoch 43: best metric: 0.450
[09/26 08:33:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[09/26 08:33:53 visual_prompt]: Epoch 44 / 100: avg data time: 4.77e-02, avg batch time: 0.4910, average train loss: 2.6341
[09/26 08:33:55 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 3.3008
[09/26 08:33:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.50	top5: 70.00	
[09/26 08:33:55 visual_prompt]: Best epoch 44: best metric: 0.475
[09/26 08:33:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[09/26 08:34:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.95e-02, avg batch time: 0.5012, average train loss: 2.5012
[09/26 08:34:03 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 2.7814
[09/26 08:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.00	top5: 80.50	
[09/26 08:34:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[09/26 08:34:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.27e-02, avg batch time: 0.4968, average train loss: 1.9457
[09/26 08:34:11 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 2.0637
[09/26 08:34:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.50	top5: 82.50	
[09/26 08:34:11 visual_prompt]: Best epoch 46: best metric: 0.555
[09/26 08:34:11 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[09/26 08:34:18 visual_prompt]: Epoch 47 / 100: avg data time: 5.72e-02, avg batch time: 0.4996, average train loss: 2.1985
[09/26 08:34:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 2.8785
[09/26 08:34:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.00	top5: 81.00	
[09/26 08:34:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[09/26 08:34:26 visual_prompt]: Epoch 48 / 100: avg data time: 4.99e-02, avg batch time: 0.4915, average train loss: 2.0612
[09/26 08:34:28 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 3.1672
[09/26 08:34:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.00	top5: 75.50	
[09/26 08:34:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[09/26 08:34:35 visual_prompt]: Epoch 49 / 100: avg data time: 4.98e-02, avg batch time: 0.4912, average train loss: 1.9104
[09/26 08:34:36 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 2.4156
[09/26 08:34:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 83.50	
[09/26 08:34:36 visual_prompt]: Best epoch 49: best metric: 0.570
[09/26 08:34:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[09/26 08:34:43 visual_prompt]: Epoch 50 / 100: avg data time: 5.99e-02, avg batch time: 0.5027, average train loss: 1.8487
[09/26 08:34:45 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 2.0950
[09/26 08:34:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.00	top5: 86.50	
[09/26 08:34:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[09/26 08:34:52 visual_prompt]: Epoch 51 / 100: avg data time: 5.63e-02, avg batch time: 0.4993, average train loss: 1.5180
[09/26 08:34:53 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 2.7970
[09/26 08:34:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.00	top5: 79.00	
[09/26 08:34:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[09/26 08:35:00 visual_prompt]: Epoch 52 / 100: avg data time: 6.42e-02, avg batch time: 0.5052, average train loss: 1.6211
[09/26 08:35:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 2.1585
[09/26 08:35:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 83.50	
[09/26 08:35:01 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[09/26 08:35:08 visual_prompt]: Epoch 53 / 100: avg data time: 5.74e-02, avg batch time: 0.4988, average train loss: 1.5439
[09/26 08:35:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 2.1572
[09/26 08:35:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.00	top5: 86.00	
[09/26 08:35:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[09/26 08:35:17 visual_prompt]: Epoch 54 / 100: avg data time: 6.57e-02, avg batch time: 0.5068, average train loss: 1.6120
[09/26 08:35:18 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 2.5345
[09/26 08:35:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 80.50	
[09/26 08:35:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[09/26 08:35:25 visual_prompt]: Epoch 55 / 100: avg data time: 6.13e-02, avg batch time: 0.5032, average train loss: 1.3028
[09/26 08:35:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 1.8428
[09/26 08:35:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.50	top5: 87.50	
[09/26 08:35:27 visual_prompt]: Best epoch 55: best metric: 0.575
[09/26 08:35:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[09/26 08:35:33 visual_prompt]: Epoch 56 / 100: avg data time: 5.32e-02, avg batch time: 0.4956, average train loss: 1.1608
[09/26 08:35:35 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 1.6650
[09/26 08:35:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 88.50	
[09/26 08:35:35 visual_prompt]: Best epoch 56: best metric: 0.640
[09/26 08:35:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[09/26 08:35:42 visual_prompt]: Epoch 57 / 100: avg data time: 5.61e-02, avg batch time: 0.4976, average train loss: 1.0001
[09/26 08:35:43 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1661, average loss: 1.6351
[09/26 08:35:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 89.50	
[09/26 08:35:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[09/26 08:35:50 visual_prompt]: Epoch 58 / 100: avg data time: 6.02e-02, avg batch time: 0.5023, average train loss: 1.2460
[09/26 08:35:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 2.0860
[09/26 08:35:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.00	top5: 85.50	
[09/26 08:35:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[09/26 08:35:59 visual_prompt]: Epoch 59 / 100: avg data time: 6.21e-02, avg batch time: 0.5036, average train loss: 1.2427
[09/26 08:36:00 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 2.2080
[09/26 08:36:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.50	top5: 85.50	
[09/26 08:36:00 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[09/26 08:36:07 visual_prompt]: Epoch 60 / 100: avg data time: 6.16e-02, avg batch time: 0.5030, average train loss: 1.1734
[09/26 08:36:09 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1662, average loss: 1.5171
[09/26 08:36:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 89.00	
[09/26 08:36:09 visual_prompt]: Best epoch 60: best metric: 0.650
[09/26 08:36:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[09/26 08:36:15 visual_prompt]: Epoch 61 / 100: avg data time: 5.63e-02, avg batch time: 0.4976, average train loss: 1.0354
[09/26 08:36:17 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.7566
[09/26 08:36:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 86.50	
[09/26 08:36:17 visual_prompt]: Best epoch 61: best metric: 0.655
[09/26 08:36:17 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[09/26 08:36:24 visual_prompt]: Epoch 62 / 100: avg data time: 5.16e-02, avg batch time: 0.4933, average train loss: 0.9078
[09/26 08:36:25 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 1.7087
[09/26 08:36:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 59.00	top5: 90.00	
[09/26 08:36:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[09/26 08:36:32 visual_prompt]: Epoch 63 / 100: avg data time: 4.83e-02, avg batch time: 0.4905, average train loss: 0.8171
[09/26 08:36:34 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 1.7558
[09/26 08:36:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 88.50	
[09/26 08:36:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[09/26 08:36:40 visual_prompt]: Epoch 64 / 100: avg data time: 6.02e-02, avg batch time: 0.5028, average train loss: 0.7531
[09/26 08:36:42 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.6974
[09/26 08:36:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 89.00	
[09/26 08:36:42 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[09/26 08:36:49 visual_prompt]: Epoch 65 / 100: avg data time: 6.31e-02, avg batch time: 0.5054, average train loss: 0.7746
[09/26 08:36:50 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.6604
[09/26 08:36:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 86.50	
[09/26 08:36:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[09/26 08:36:57 visual_prompt]: Epoch 66 / 100: avg data time: 6.14e-02, avg batch time: 0.5030, average train loss: 0.7460
[09/26 08:36:59 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 1.7812
[09/26 08:36:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 89.00	
[09/26 08:36:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[09/26 08:37:05 visual_prompt]: Epoch 67 / 100: avg data time: 4.58e-02, avg batch time: 0.4877, average train loss: 0.7540
[09/26 08:37:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1662, average loss: 1.8270
[09/26 08:37:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.00	top5: 88.50	
[09/26 08:37:07 visual_prompt]: Training 68 / 100 epoch, with learning rate 7.415791961552499
[09/26 08:37:14 visual_prompt]: Epoch 68 / 100: avg data time: 5.54e-02, avg batch time: 0.4976, average train loss: 0.6678
[09/26 08:37:15 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.5699
[09/26 08:37:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 91.50	
[09/26 08:37:15 visual_prompt]: Training 69 / 100 epoch, with learning rate 7.020360665136531
[09/26 08:37:22 visual_prompt]: Epoch 69 / 100: avg data time: 5.21e-02, avg batch time: 0.4943, average train loss: 0.6907
[09/26 08:37:23 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 1.8373
[09/26 08:37:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 89.50	
[09/26 08:37:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 6.631605465176368
[09/26 08:37:30 visual_prompt]: Epoch 70 / 100: avg data time: 6.32e-02, avg batch time: 0.5042, average train loss: 0.6478
[09/26 08:37:32 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1661, average loss: 1.5559
[09/26 08:37:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 08:37:32 visual_prompt]: Best epoch 70: best metric: 0.665
[09/26 08:37:32 visual_prompt]: Training 71 / 100 epoch, with learning rate 6.250000000000003
[09/26 08:37:39 visual_prompt]: Epoch 71 / 100: avg data time: 5.97e-02, avg batch time: 0.5018, average train loss: 0.5194
[09/26 08:37:40 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1661, average loss: 1.5473
[09/26 08:37:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 90.50	
[09/26 08:37:40 visual_prompt]: Training 72 / 100 epoch, with learning rate 5.87600919708494
[09/26 08:37:47 visual_prompt]: Epoch 72 / 100: avg data time: 5.94e-02, avg batch time: 0.5006, average train loss: 0.5223
[09/26 08:37:49 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1658, average loss: 1.5991
[09/26 08:37:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 90.50	
[09/26 08:37:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 5.510088706615666
[09/26 08:37:55 visual_prompt]: Epoch 73 / 100: avg data time: 4.96e-02, avg batch time: 0.4938, average train loss: 0.5250
[09/26 08:37:57 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 1.5931
[09/26 08:37:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 90.50	
[09/26 08:37:57 visual_prompt]: Training 74 / 100 epoch, with learning rate 5.1526843463440875
[09/26 08:38:04 visual_prompt]: Epoch 74 / 100: avg data time: 5.98e-02, avg batch time: 0.5036, average train loss: 0.5832
[09/26 08:38:05 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1660, average loss: 1.5539
[09/26 08:38:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 91.50	
[09/26 08:38:05 visual_prompt]: Training 75 / 100 epoch, with learning rate 4.804231558429271
[09/26 08:38:12 visual_prompt]: Epoch 75 / 100: avg data time: 6.61e-02, avg batch time: 0.5073, average train loss: 0.5049
[09/26 08:38:14 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.6306
[09/26 08:38:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 91.00	
[09/26 08:38:14 visual_prompt]: Training 76 / 100 epoch, with learning rate 4.465154878918258
[09/26 08:38:21 visual_prompt]: Epoch 76 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 0.4299
[09/26 08:38:22 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1661, average loss: 1.5846
[09/26 08:38:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 88.00	
[09/26 08:38:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 4.135867420514276
[09/26 08:38:29 visual_prompt]: Epoch 77 / 100: avg data time: 6.01e-02, avg batch time: 0.5017, average train loss: 0.4294
[09/26 08:38:31 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.5806
[09/26 08:38:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 92.00	
[09/26 08:38:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 3.816770369262533
[09/26 08:38:37 visual_prompt]: Epoch 78 / 100: avg data time: 5.25e-02, avg batch time: 0.4952, average train loss: 0.4285
[09/26 08:38:39 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1659, average loss: 1.5835
[09/26 08:38:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.00	
[09/26 08:38:39 visual_prompt]: Training 79 / 100 epoch, with learning rate 3.508252495766863
[09/26 08:38:46 visual_prompt]: Epoch 79 / 100: avg data time: 5.58e-02, avg batch time: 0.4981, average train loss: 0.4157
[09/26 08:38:47 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1658, average loss: 1.5908
[09/26 08:38:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 90.50	
[09/26 08:38:47 visual_prompt]: Training 80 / 100 epoch, with learning rate 3.2106896815325707
[09/26 08:38:54 visual_prompt]: Epoch 80 / 100: avg data time: 4.72e-02, avg batch time: 0.4892, average train loss: 0.4151
[09/26 08:38:55 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1660, average loss: 1.6296
[09/26 08:38:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 91.00	
[09/26 08:38:55 visual_prompt]: Training 81 / 100 epoch, with learning rate 2.924444461012776
[09/26 08:39:02 visual_prompt]: Epoch 81 / 100: avg data time: 4.89e-02, avg batch time: 0.4902, average train loss: 0.3439
[09/26 08:39:04 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1661, average loss: 1.5975
[09/26 08:39:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 08:39:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 2.6498655799159763
[09/26 08:39:11 visual_prompt]: Epoch 82 / 100: avg data time: 5.79e-02, avg batch time: 0.5001, average train loss: 0.3541
[09/26 08:39:12 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 1.5339
[09/26 08:39:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 90.50	
[09/26 08:39:12 visual_prompt]: Best epoch 82: best metric: 0.680
[09/26 08:39:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 2.387287570313158
[09/26 08:39:19 visual_prompt]: Epoch 83 / 100: avg data time: 5.57e-02, avg batch time: 0.4976, average train loss: 0.3489
[09/26 08:39:20 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1659, average loss: 1.5980
[09/26 08:39:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 90.50	
[09/26 08:39:20 visual_prompt]: Training 84 / 100 epoch, with learning rate 2.13703034306198
[09/26 08:39:27 visual_prompt]: Epoch 84 / 100: avg data time: 5.34e-02, avg batch time: 0.4947, average train loss: 0.4268
[09/26 08:39:29 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1659, average loss: 1.5962
[09/26 08:39:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 90.50	
[09/26 08:39:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 1.8993987980446756
[09/26 08:39:35 visual_prompt]: Epoch 85 / 100: avg data time: 4.61e-02, avg batch time: 0.4886, average train loss: 0.3603
[09/26 08:39:37 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1659, average loss: 1.5673
[09/26 08:39:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 91.00	
[09/26 08:39:37 visual_prompt]: Training 86 / 100 epoch, with learning rate 1.674682452694516
[09/26 08:39:44 visual_prompt]: Epoch 86 / 100: avg data time: 6.14e-02, avg batch time: 0.5028, average train loss: 0.3614
[09/26 08:39:45 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1656, average loss: 1.4799
[09/26 08:39:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.00	
[09/26 08:39:45 visual_prompt]: Training 87 / 100 epoch, with learning rate 1.4631550892634126
[09/26 08:39:52 visual_prompt]: Epoch 87 / 100: avg data time: 4.56e-02, avg batch time: 0.4886, average train loss: 0.3241
[09/26 08:39:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 1.5240
[09/26 08:39:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 92.00	
[09/26 08:39:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 1.2650744212604148
[09/26 08:40:00 visual_prompt]: Epoch 88 / 100: avg data time: 4.94e-02, avg batch time: 0.4917, average train loss: 0.3566
[09/26 08:40:02 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1662, average loss: 1.5195
[09/26 08:40:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 89.00	
[09/26 08:40:02 visual_prompt]: Training 89 / 100 epoch, with learning rate 1.0806817794674877
[09/26 08:40:08 visual_prompt]: Epoch 89 / 100: avg data time: 5.15e-02, avg batch time: 0.4923, average train loss: 0.3256
[09/26 08:40:10 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 1.5326
[09/26 08:40:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 90.00	
[09/26 08:40:10 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.9102018179151585
[09/26 08:40:17 visual_prompt]: Epoch 90 / 100: avg data time: 5.53e-02, avg batch time: 0.4963, average train loss: 0.3758
[09/26 08:40:18 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 1.5203
[09/26 08:40:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 89.50	
[09/26 08:40:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.753842240176146
[09/26 08:40:25 visual_prompt]: Epoch 91 / 100: avg data time: 5.58e-02, avg batch time: 0.4995, average train loss: 0.3101
[09/26 08:40:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 1.5107
[09/26 08:40:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 90.50	
[09/26 08:40:27 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.6117935463105808
[09/26 08:40:34 visual_prompt]: Epoch 92 / 100: avg data time: 6.13e-02, avg batch time: 0.5037, average train loss: 0.3434
[09/26 08:40:35 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1658, average loss: 1.5187
[09/26 08:40:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 91.00	
[09/26 08:40:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.4842288007710138
[09/26 08:40:42 visual_prompt]: Epoch 93 / 100: avg data time: 4.70e-02, avg batch time: 0.4895, average train loss: 0.2928
[09/26 08:40:43 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 1.5115
[09/26 08:40:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 91.00	
[09/26 08:40:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.3713034215500441
[09/26 08:40:50 visual_prompt]: Epoch 94 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.3152
[09/26 08:40:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1659, average loss: 1.4890
[09/26 08:40:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 08:40:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.2731549908274289
[09/26 08:40:59 visual_prompt]: Epoch 95 / 100: avg data time: 6.00e-02, avg batch time: 0.5008, average train loss: 0.2723
[09/26 08:41:00 visual_prompt]: Inference (val):avg data time: 4.78e-05, avg batch time: 0.1660, average loss: 1.4888
[09/26 08:41:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 08:41:00 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.18990308734739975
[09/26 08:41:07 visual_prompt]: Epoch 96 / 100: avg data time: 5.84e-02, avg batch time: 0.5005, average train loss: 0.3048
[09/26 08:41:09 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1661, average loss: 1.5121
[09/26 08:41:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 91.00	
[09/26 08:41:09 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.12164914073037048
[09/26 08:41:15 visual_prompt]: Epoch 97 / 100: avg data time: 4.94e-02, avg batch time: 0.4925, average train loss: 0.3271
[09/26 08:41:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.5215
[09/26 08:41:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 08:41:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.06847630789658388
[09/26 08:41:24 visual_prompt]: Epoch 98 / 100: avg data time: 5.76e-02, avg batch time: 0.4988, average train loss: 0.3112
[09/26 08:41:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.5271
[09/26 08:41:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.50	
[09/26 08:41:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.03044937175219753
[09/26 08:41:32 visual_prompt]: Epoch 99 / 100: avg data time: 5.97e-02, avg batch time: 0.5021, average train loss: 0.3307
[09/26 08:41:34 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1660, average loss: 1.5288
[09/26 08:41:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.50	
[09/26 08:41:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0076146622613029735
[09/26 08:41:40 visual_prompt]: Epoch 100 / 100: avg data time: 6.21e-02, avg batch time: 0.5034, average train loss: 0.3192
[09/26 08:41:42 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 1.5282
[09/26 08:41:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.50	
[09/26 08:41:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:41:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:41:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:41:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:41:42 visual_prompt]: Training with config:
[09/26 08:41:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:41:42 visual_prompt]: Loading training data...
[09/26 08:41:42 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:41:43 visual_prompt]: Number of images: 800
[09/26 08:41:43 visual_prompt]: Number of classes: 45 / 45
[09/26 08:41:43 visual_prompt]: Loading validation data...
[09/26 08:41:43 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:41:44 visual_prompt]: Number of images: 200
[09/26 08:41:44 visual_prompt]: Number of classes: 45 / 45
[09/26 08:41:44 visual_prompt]: Constructing models...
[09/26 08:41:46 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 08:41:46 visual_prompt]: tuned percent:0.574
[09/26 08:41:46 visual_prompt]: Device used for model: 0
[09/26 08:41:46 visual_prompt]: Setting up Evaluator...
[09/26 08:41:46 visual_prompt]: Setting up Trainer...
[09/26 08:41:46 visual_prompt]: 	Setting up the optimizer...
[09/26 08:41:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:41:53 visual_prompt]: Epoch 1 / 100: avg data time: 5.30e-02, avg batch time: 0.4926, average train loss: 3.8997
[09/26 08:41:54 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1654, average loss: 3.9529
[09/26 08:41:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 08:41:54 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 08:41:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 08:42:01 visual_prompt]: Epoch 2 / 100: avg data time: 4.85e-02, avg batch time: 0.4899, average train loss: 3.8969
[09/26 08:42:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1654, average loss: 3.9286
[09/26 08:42:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 08:42:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 08:42:09 visual_prompt]: Epoch 3 / 100: avg data time: 5.28e-02, avg batch time: 0.4941, average train loss: 3.9529
[09/26 08:42:11 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 3.9710
[09/26 08:42:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 08:42:11 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 08:42:17 visual_prompt]: Epoch 4 / 100: avg data time: 5.80e-02, avg batch time: 0.4987, average train loss: 4.0968
[09/26 08:42:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 4.2631
[09/26 08:42:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 08:42:19 visual_prompt]: Best epoch 4: best metric: 0.025
[09/26 08:42:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 08:42:26 visual_prompt]: Epoch 5 / 100: avg data time: 4.92e-02, avg batch time: 0.4920, average train loss: 4.1927
[09/26 08:42:27 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1653, average loss: 4.2344
[09/26 08:42:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 08:42:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 08:42:34 visual_prompt]: Epoch 6 / 100: avg data time: 5.01e-02, avg batch time: 0.4916, average train loss: 4.2507
[09/26 08:42:36 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1656, average loss: 4.5726
[09/26 08:42:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:42:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 08:42:42 visual_prompt]: Epoch 7 / 100: avg data time: 5.35e-02, avg batch time: 0.4941, average train loss: 5.6004
[09/26 08:42:44 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1656, average loss: 9.6744
[09/26 08:42:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:42:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 08:42:51 visual_prompt]: Epoch 8 / 100: avg data time: 6.05e-02, avg batch time: 0.5018, average train loss: 8.1422
[09/26 08:42:52 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1656, average loss: 15.9397
[09/26 08:42:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 08:42:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 08:42:59 visual_prompt]: Epoch 9 / 100: avg data time: 4.68e-02, avg batch time: 0.4883, average train loss: 14.5668
[09/26 08:43:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1657, average loss: 11.8687
[09/26 08:43:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 08:43:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 08:43:07 visual_prompt]: Epoch 10 / 100: avg data time: 5.98e-02, avg batch time: 0.5015, average train loss: 16.6735
[09/26 08:43:09 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1658, average loss: 21.1038
[09/26 08:43:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:43:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 08:43:16 visual_prompt]: Epoch 11 / 100: avg data time: 5.52e-02, avg batch time: 0.4962, average train loss: 27.2932
[09/26 08:43:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 25.9587
[09/26 08:43:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 13.50	
[09/26 08:43:17 visual_prompt]: Best epoch 11: best metric: 0.045
[09/26 08:43:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 08:43:24 visual_prompt]: Epoch 12 / 100: avg data time: 5.58e-02, avg batch time: 0.4962, average train loss: 27.9540
[09/26 08:43:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 26.8318
[09/26 08:43:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 08:43:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 08:43:32 visual_prompt]: Epoch 13 / 100: avg data time: 5.56e-02, avg batch time: 0.4964, average train loss: 30.6027
[09/26 08:43:34 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 32.2828
[09/26 08:43:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:43:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 08:43:40 visual_prompt]: Epoch 14 / 100: avg data time: 5.77e-02, avg batch time: 0.4982, average train loss: 34.1365
[09/26 08:43:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 30.8633
[09/26 08:43:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:43:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 08:43:49 visual_prompt]: Epoch 15 / 100: avg data time: 5.76e-02, avg batch time: 0.4991, average train loss: 34.9828
[09/26 08:43:50 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1657, average loss: 26.3103
[09/26 08:43:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:43:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 08:43:57 visual_prompt]: Epoch 16 / 100: avg data time: 5.10e-02, avg batch time: 0.4931, average train loss: 33.2184
[09/26 08:43:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1660, average loss: 32.1069
[09/26 08:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 08:43:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 08:44:05 visual_prompt]: Epoch 17 / 100: avg data time: 5.30e-02, avg batch time: 0.4939, average train loss: 34.4901
[09/26 08:44:07 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 51.4702
[09/26 08:44:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 14.00	
[09/26 08:44:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 08:44:14 visual_prompt]: Epoch 18 / 100: avg data time: 5.05e-02, avg batch time: 0.4919, average train loss: 39.2897
[09/26 08:44:15 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1661, average loss: 38.0753
[09/26 08:44:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:44:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 08:44:22 visual_prompt]: Epoch 19 / 100: avg data time: 5.32e-02, avg batch time: 0.4950, average train loss: 40.5907
[09/26 08:44:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 33.8702
[09/26 08:44:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:44:23 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 08:44:30 visual_prompt]: Epoch 20 / 100: avg data time: 6.10e-02, avg batch time: 0.5030, average train loss: 35.9961
[09/26 08:44:32 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 31.7411
[09/26 08:44:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:44:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 08:44:39 visual_prompt]: Epoch 21 / 100: avg data time: 5.66e-02, avg batch time: 0.4984, average train loss: 28.7638
[09/26 08:44:40 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1662, average loss: 30.8337
[09/26 08:44:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 08:44:40 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 08:44:47 visual_prompt]: Epoch 22 / 100: avg data time: 6.55e-02, avg batch time: 0.5069, average train loss: 39.3121
[09/26 08:44:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 39.8105
[09/26 08:44:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:44:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 08:44:56 visual_prompt]: Epoch 23 / 100: avg data time: 5.70e-02, avg batch time: 0.4978, average train loss: 33.4651
[09/26 08:44:57 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 28.6470
[09/26 08:44:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 08:44:57 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 08:45:04 visual_prompt]: Epoch 24 / 100: avg data time: 5.82e-02, avg batch time: 0.4999, average train loss: 32.8165
[09/26 08:45:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 38.8821
[09/26 08:45:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 08:45:05 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 08:45:12 visual_prompt]: Epoch 25 / 100: avg data time: 5.57e-02, avg batch time: 0.4967, average train loss: 31.5799
[09/26 08:45:14 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 28.4253
[09/26 08:45:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 08:45:14 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 08:45:21 visual_prompt]: Epoch 26 / 100: avg data time: 6.27e-02, avg batch time: 0.5045, average train loss: 28.2219
[09/26 08:45:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 28.8195
[09/26 08:45:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:45:22 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 08:45:29 visual_prompt]: Epoch 27 / 100: avg data time: 5.60e-02, avg batch time: 0.4970, average train loss: 32.4783
[09/26 08:45:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1659, average loss: 25.4368
[09/26 08:45:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:45:31 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 08:45:37 visual_prompt]: Epoch 28 / 100: avg data time: 5.39e-02, avg batch time: 0.4964, average train loss: 28.3037
[09/26 08:45:39 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1658, average loss: 35.3177
[09/26 08:45:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:45:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 08:45:46 visual_prompt]: Epoch 29 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 27.2762
[09/26 08:45:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 24.9203
[09/26 08:45:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:45:47 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 08:45:54 visual_prompt]: Epoch 30 / 100: avg data time: 6.22e-02, avg batch time: 0.5039, average train loss: 26.7609
[09/26 08:45:56 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 24.3902
[09/26 08:45:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 08:45:56 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 08:46:02 visual_prompt]: Epoch 31 / 100: avg data time: 5.73e-02, avg batch time: 0.4987, average train loss: 23.8527
[09/26 08:46:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 25.3646
[09/26 08:46:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 12.50	
[09/26 08:46:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 08:46:11 visual_prompt]: Epoch 32 / 100: avg data time: 5.53e-02, avg batch time: 0.4969, average train loss: 27.3687
[09/26 08:46:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1661, average loss: 26.1821
[09/26 08:46:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:46:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 08:46:19 visual_prompt]: Epoch 33 / 100: avg data time: 6.39e-02, avg batch time: 0.5071, average train loss: 28.5757
[09/26 08:46:21 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 27.8053
[09/26 08:46:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:46:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 08:46:27 visual_prompt]: Epoch 34 / 100: avg data time: 5.70e-02, avg batch time: 0.4992, average train loss: 29.0064
[09/26 08:46:29 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 32.5622
[09/26 08:46:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:46:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 08:46:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.11e-02, avg batch time: 0.4925, average train loss: 30.0638
[09/26 08:46:37 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 25.8662
[09/26 08:46:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:46:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 08:46:44 visual_prompt]: Epoch 36 / 100: avg data time: 6.21e-02, avg batch time: 0.5036, average train loss: 26.5214
[09/26 08:46:46 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 31.2078
[09/26 08:46:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 08:46:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 08:46:52 visual_prompt]: Epoch 37 / 100: avg data time: 5.66e-02, avg batch time: 0.4977, average train loss: 29.5403
[09/26 08:46:54 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 22.7410
[09/26 08:46:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.50	
[09/26 08:46:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 08:47:01 visual_prompt]: Epoch 38 / 100: avg data time: 5.68e-02, avg batch time: 0.5000, average train loss: 24.1917
[09/26 08:47:02 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1659, average loss: 23.6129
[09/26 08:47:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:47:02 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 08:47:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.44e-02, avg batch time: 0.4968, average train loss: 28.1834
[09/26 08:47:11 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1660, average loss: 25.6791
[09/26 08:47:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.50	
[09/26 08:47:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 08:47:17 visual_prompt]: Epoch 40 / 100: avg data time: 4.91e-02, avg batch time: 0.4918, average train loss: 24.7707
[09/26 08:47:19 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 23.9338
[09/26 08:47:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:47:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 08:47:26 visual_prompt]: Epoch 41 / 100: avg data time: 6.10e-02, avg batch time: 0.5026, average train loss: 20.3623
[09/26 08:47:27 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 18.4562
[09/26 08:47:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 08:47:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 08:47:34 visual_prompt]: Epoch 42 / 100: avg data time: 4.41e-02, avg batch time: 0.4877, average train loss: 17.0669
[09/26 08:47:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1659, average loss: 10.7600
[09/26 08:47:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:47:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 08:47:42 visual_prompt]: Epoch 43 / 100: avg data time: 6.39e-02, avg batch time: 0.5045, average train loss: 14.6067
[09/26 08:47:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 14.6091
[09/26 08:47:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 8.00	
[09/26 08:47:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 08:47:51 visual_prompt]: Epoch 44 / 100: avg data time: 5.83e-02, avg batch time: 0.4996, average train loss: 16.9889
[09/26 08:47:52 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 15.4694
[09/26 08:47:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:47:52 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 08:47:59 visual_prompt]: Epoch 45 / 100: avg data time: 6.33e-02, avg batch time: 0.5036, average train loss: 15.7735
[09/26 08:48:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 15.4546
[09/26 08:48:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 6.00	
[09/26 08:48:01 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 08:48:07 visual_prompt]: Epoch 46 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 13.7228
[09/26 08:48:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1660, average loss: 12.4831
[09/26 08:48:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:48:09 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 08:48:16 visual_prompt]: Epoch 47 / 100: avg data time: 6.09e-02, avg batch time: 0.5011, average train loss: 11.5180
[09/26 08:48:17 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1657, average loss: 13.5550
[09/26 08:48:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:48:17 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 08:48:24 visual_prompt]: Epoch 48 / 100: avg data time: 5.76e-02, avg batch time: 0.4990, average train loss: 11.9942
[09/26 08:48:26 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1661, average loss: 17.6741
[09/26 08:48:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:48:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 08:48:33 visual_prompt]: Epoch 49 / 100: avg data time: 5.99e-02, avg batch time: 0.5014, average train loss: 10.9446
[09/26 08:48:34 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1660, average loss: 7.2207
[09/26 08:48:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 08:48:34 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 08:48:41 visual_prompt]: Epoch 50 / 100: avg data time: 5.44e-02, avg batch time: 0.4968, average train loss: 9.8368
[09/26 08:48:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 10.3192
[09/26 08:48:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 08:48:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 08:48:49 visual_prompt]: Epoch 51 / 100: avg data time: 6.18e-02, avg batch time: 0.5029, average train loss: 8.8869
[09/26 08:48:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1661, average loss: 10.0526
[09/26 08:48:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:48:51 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 08:48:58 visual_prompt]: Epoch 52 / 100: avg data time: 5.29e-02, avg batch time: 0.4949, average train loss: 9.7696
[09/26 08:48:59 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 10.4537
[09/26 08:48:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 08:48:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 08:49:06 visual_prompt]: Epoch 53 / 100: avg data time: 5.78e-02, avg batch time: 0.5003, average train loss: 12.6360
[09/26 08:49:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 11.1360
[09/26 08:49:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 11.00	
[09/26 08:49:08 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 08:49:14 visual_prompt]: Epoch 54 / 100: avg data time: 4.54e-02, avg batch time: 0.4898, average train loss: 10.3206
[09/26 08:49:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 8.3729
[09/26 08:49:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 08:49:16 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 08:49:23 visual_prompt]: Epoch 55 / 100: avg data time: 5.67e-02, avg batch time: 0.4988, average train loss: 12.9885
[09/26 08:49:24 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1659, average loss: 14.6541
[09/26 08:49:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 08:49:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 08:49:31 visual_prompt]: Epoch 56 / 100: avg data time: 5.98e-02, avg batch time: 0.5016, average train loss: 8.5927
[09/26 08:49:32 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 6.2017
[09/26 08:49:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 16.00	
[09/26 08:49:32 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 08:49:39 visual_prompt]: Epoch 57 / 100: avg data time: 6.37e-02, avg batch time: 0.5043, average train loss: 7.5948
[09/26 08:49:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 7.7291
[09/26 08:49:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 08:49:41 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 08:49:48 visual_prompt]: Epoch 58 / 100: avg data time: 5.61e-02, avg batch time: 0.4979, average train loss: 8.0693
[09/26 08:49:49 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1657, average loss: 6.1224
[09/26 08:49:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 10.00	
[09/26 08:49:49 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 08:49:56 visual_prompt]: Epoch 59 / 100: avg data time: 6.14e-02, avg batch time: 0.5032, average train loss: 6.1798
[09/26 08:49:58 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1658, average loss: 5.3994
[09/26 08:49:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 08:49:58 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 08:50:04 visual_prompt]: Epoch 60 / 100: avg data time: 5.72e-02, avg batch time: 0.4983, average train loss: 5.4570
[09/26 08:50:06 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1658, average loss: 5.0849
[09/26 08:50:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:50:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 08:50:13 visual_prompt]: Epoch 61 / 100: avg data time: 4.54e-02, avg batch time: 0.4876, average train loss: 5.3183
[09/26 08:50:14 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1659, average loss: 4.3530
[09/26 08:50:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 08:50:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 08:50:21 visual_prompt]: Epoch 62 / 100: avg data time: 5.74e-02, avg batch time: 0.4983, average train loss: 4.3292
[09/26 08:50:23 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1658, average loss: 4.1514
[09/26 08:50:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 12.00	
[09/26 08:50:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 08:50:29 visual_prompt]: Epoch 63 / 100: avg data time: 6.37e-02, avg batch time: 0.5045, average train loss: 4.5654
[09/26 08:50:31 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1660, average loss: 4.2432
[09/26 08:50:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 08:50:31 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 08:50:38 visual_prompt]: Epoch 64 / 100: avg data time: 4.68e-02, avg batch time: 0.4898, average train loss: 4.6695
[09/26 08:50:39 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 4.2771
[09/26 08:50:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 08:50:39 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 08:50:46 visual_prompt]: Epoch 65 / 100: avg data time: 5.78e-02, avg batch time: 0.4998, average train loss: 4.3223
[09/26 08:50:47 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1658, average loss: 4.1529
[09/26 08:50:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 08:50:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 08:50:54 visual_prompt]: Epoch 66 / 100: avg data time: 5.12e-02, avg batch time: 0.4937, average train loss: 4.0449
[09/26 08:50:56 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1658, average loss: 4.0366
[09/26 08:50:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.00	
[09/26 08:50:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 08:51:03 visual_prompt]: Epoch 67 / 100: avg data time: 6.59e-02, avg batch time: 0.5066, average train loss: 4.1651
[09/26 08:51:04 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 4.0198
[09/26 08:51:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:51:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 08:51:11 visual_prompt]: Epoch 68 / 100: avg data time: 4.94e-02, avg batch time: 0.4918, average train loss: 4.0859
[09/26 08:51:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 3.9713
[09/26 08:51:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.00	
[09/26 08:51:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 08:51:19 visual_prompt]: Epoch 69 / 100: avg data time: 5.65e-02, avg batch time: 0.4974, average train loss: 3.9571
[09/26 08:51:21 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 4.0204
[09/26 08:51:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:51:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 08:51:28 visual_prompt]: Epoch 70 / 100: avg data time: 5.80e-02, avg batch time: 0.4995, average train loss: 4.0010
[09/26 08:51:29 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 3.9905
[09/26 08:51:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 08:51:29 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 08:51:36 visual_prompt]: Epoch 71 / 100: avg data time: 5.38e-02, avg batch time: 0.4951, average train loss: 3.9931
[09/26 08:51:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 3.9455
[09/26 08:51:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 08:51:37 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 08:51:44 visual_prompt]: Epoch 72 / 100: avg data time: 6.50e-02, avg batch time: 0.5063, average train loss: 3.9567
[09/26 08:51:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 3.9161
[09/26 08:51:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 08:51:46 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 08:51:53 visual_prompt]: Epoch 73 / 100: avg data time: 5.52e-02, avg batch time: 0.4960, average train loss: 3.9192
[09/26 08:51:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 3.9227
[09/26 08:51:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:51:54 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 08:52:01 visual_prompt]: Epoch 74 / 100: avg data time: 5.70e-02, avg batch time: 0.4975, average train loss: 4.0027
[09/26 08:52:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 4.0322
[09/26 08:52:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 9.00	
[09/26 08:52:02 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 08:52:09 visual_prompt]: Epoch 75 / 100: avg data time: 5.77e-02, avg batch time: 0.4994, average train loss: 3.9526
[09/26 08:52:11 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1659, average loss: 3.8802
[09/26 08:52:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 11.50	
[09/26 08:52:11 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 08:52:18 visual_prompt]: Epoch 76 / 100: avg data time: 5.78e-02, avg batch time: 0.4995, average train loss: 3.9414
[09/26 08:52:19 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 3.9522
[09/26 08:52:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 08:52:19 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 08:52:26 visual_prompt]: Epoch 77 / 100: avg data time: 6.07e-02, avg batch time: 0.5026, average train loss: 3.9315
[09/26 08:52:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 3.9957
[09/26 08:52:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:52:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 08:52:34 visual_prompt]: Epoch 78 / 100: avg data time: 5.73e-02, avg batch time: 0.4983, average train loss: 3.9401
[09/26 08:52:36 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1658, average loss: 3.9511
[09/26 08:52:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 08:52:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 08:52:43 visual_prompt]: Epoch 79 / 100: avg data time: 5.54e-02, avg batch time: 0.4962, average train loss: 3.8668
[09/26 08:52:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 3.9432
[09/26 08:52:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 08:52:44 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 08:52:51 visual_prompt]: Epoch 80 / 100: avg data time: 5.34e-02, avg batch time: 0.4963, average train loss: 3.8873
[09/26 08:52:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 3.8577
[09/26 08:52:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.00	
[09/26 08:52:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 08:52:59 visual_prompt]: Epoch 81 / 100: avg data time: 5.28e-02, avg batch time: 0.4943, average train loss: 3.8870
[09/26 08:53:01 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1663, average loss: 3.8950
[09/26 08:53:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 08:53:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 08:53:08 visual_prompt]: Epoch 82 / 100: avg data time: 5.60e-02, avg batch time: 0.4977, average train loss: 3.9205
[09/26 08:53:09 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1661, average loss: 3.8800
[09/26 08:53:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:53:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 08:53:16 visual_prompt]: Epoch 83 / 100: avg data time: 6.03e-02, avg batch time: 0.5028, average train loss: 3.8725
[09/26 08:53:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1659, average loss: 3.8760
[09/26 08:53:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:53:17 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 08:53:24 visual_prompt]: Epoch 84 / 100: avg data time: 6.08e-02, avg batch time: 0.5018, average train loss: 3.8602
[09/26 08:53:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 3.8949
[09/26 08:53:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 10.50	
[09/26 08:53:26 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 08:53:33 visual_prompt]: Epoch 85 / 100: avg data time: 5.42e-02, avg batch time: 0.4951, average train loss: 3.8565
[09/26 08:53:34 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1659, average loss: 3.8581
[09/26 08:53:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 08:53:34 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 08:53:41 visual_prompt]: Epoch 86 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 3.8406
[09/26 08:53:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 3.8429
[09/26 08:53:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 08:53:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 08:53:49 visual_prompt]: Epoch 87 / 100: avg data time: 5.67e-02, avg batch time: 0.4983, average train loss: 3.8212
[09/26 08:53:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 3.8491
[09/26 08:53:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 08:53:51 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 08:53:58 visual_prompt]: Epoch 88 / 100: avg data time: 5.53e-02, avg batch time: 0.4964, average train loss: 3.8305
[09/26 08:53:59 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1662, average loss: 3.8470
[09/26 08:53:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 08:53:59 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 08:54:06 visual_prompt]: Epoch 89 / 100: avg data time: 6.03e-02, avg batch time: 0.5022, average train loss: 3.8073
[09/26 08:54:08 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 3.8167
[09/26 08:54:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 08:54:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 08:54:14 visual_prompt]: Epoch 90 / 100: avg data time: 5.83e-02, avg batch time: 0.5005, average train loss: 3.7778
[09/26 08:54:16 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1658, average loss: 3.8008
[09/26 08:54:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 08:54:16 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 08:54:23 visual_prompt]: Epoch 91 / 100: avg data time: 6.02e-02, avg batch time: 0.5009, average train loss: 3.7599
[09/26 08:54:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 3.6664
[09/26 08:54:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 20.00	
[09/26 08:54:24 visual_prompt]: Best epoch 91: best metric: 0.050
[09/26 08:54:24 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 08:54:31 visual_prompt]: Epoch 92 / 100: avg data time: 5.95e-02, avg batch time: 0.5023, average train loss: 3.6260
[09/26 08:54:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 3.5467
[09/26 08:54:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 23.50	
[09/26 08:54:33 visual_prompt]: Best epoch 92: best metric: 0.065
[09/26 08:54:33 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 08:54:39 visual_prompt]: Epoch 93 / 100: avg data time: 5.32e-02, avg batch time: 0.4950, average train loss: 3.5465
[09/26 08:54:41 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1660, average loss: 3.4685
[09/26 08:54:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 29.50	
[09/26 08:54:41 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 08:54:48 visual_prompt]: Epoch 94 / 100: avg data time: 4.95e-02, avg batch time: 0.4906, average train loss: 3.2626
[09/26 08:54:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 3.2161
[09/26 08:54:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 36.00	
[09/26 08:54:49 visual_prompt]: Best epoch 94: best metric: 0.125
[09/26 08:54:49 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 08:54:56 visual_prompt]: Epoch 95 / 100: avg data time: 6.25e-02, avg batch time: 0.5040, average train loss: 3.0509
[09/26 08:54:58 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 3.2158
[09/26 08:54:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 38.00	
[09/26 08:54:58 visual_prompt]: Best epoch 95: best metric: 0.130
[09/26 08:54:58 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 08:55:04 visual_prompt]: Epoch 96 / 100: avg data time: 5.64e-02, avg batch time: 0.4986, average train loss: 2.8680
[09/26 08:55:06 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 2.8776
[09/26 08:55:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.50	top5: 50.00	
[09/26 08:55:06 visual_prompt]: Best epoch 96: best metric: 0.205
[09/26 08:55:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 08:55:13 visual_prompt]: Epoch 97 / 100: avg data time: 5.84e-02, avg batch time: 0.5003, average train loss: 2.5947
[09/26 08:55:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 2.7123
[09/26 08:55:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 53.00	
[09/26 08:55:14 visual_prompt]: Best epoch 97: best metric: 0.235
[09/26 08:55:14 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 08:55:21 visual_prompt]: Epoch 98 / 100: avg data time: 6.25e-02, avg batch time: 0.5039, average train loss: 2.3661
[09/26 08:55:23 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1659, average loss: 2.5534
[09/26 08:55:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 63.00	
[09/26 08:55:23 visual_prompt]: Best epoch 98: best metric: 0.245
[09/26 08:55:23 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 08:55:29 visual_prompt]: Epoch 99 / 100: avg data time: 5.02e-02, avg batch time: 0.4921, average train loss: 2.2154
[09/26 08:55:31 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 2.5071
[09/26 08:55:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 64.00	
[09/26 08:55:31 visual_prompt]: Best epoch 99: best metric: 0.255
[09/26 08:55:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 08:55:38 visual_prompt]: Epoch 100 / 100: avg data time: 5.51e-02, avg batch time: 0.4967, average train loss: 2.1113
[09/26 08:55:39 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1663, average loss: 2.4032
[09/26 08:55:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.50	top5: 66.00	
[09/26 08:55:39 visual_prompt]: Best epoch 100: best metric: 0.295
[09/26 08:55:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 08:55:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 08:55:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 08:55:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 08:55:39 visual_prompt]: Training with config:
[09/26 08:55:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 08:55:39 visual_prompt]: Loading training data...
[09/26 08:55:39 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:55:40 visual_prompt]: Number of images: 800
[09/26 08:55:40 visual_prompt]: Number of classes: 45 / 45
[09/26 08:55:40 visual_prompt]: Loading validation data...
[09/26 08:55:40 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 08:55:41 visual_prompt]: Number of images: 200
[09/26 08:55:41 visual_prompt]: Number of classes: 45 / 45
[09/26 08:55:41 visual_prompt]: Constructing models...
[09/26 08:55:43 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 08:55:43 visual_prompt]: tuned percent:0.574
[09/26 08:55:43 visual_prompt]: Device used for model: 0
[09/26 08:55:43 visual_prompt]: Setting up Evaluator...
[09/26 08:55:43 visual_prompt]: Setting up Trainer...
[09/26 08:55:43 visual_prompt]: 	Setting up the optimizer...
[09/26 08:55:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 08:55:50 visual_prompt]: Epoch 1 / 100: avg data time: 5.26e-02, avg batch time: 0.4942, average train loss: 3.8926
[09/26 08:55:51 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 08:55:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 08:55:51 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 08:55:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 08:55:58 visual_prompt]: Epoch 2 / 100: avg data time: 5.56e-02, avg batch time: 0.4974, average train loss: 3.9982
[09/26 08:56:00 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1658, average loss: 3.8949
[09/26 08:56:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 11.50	
[09/26 08:56:00 visual_prompt]: Best epoch 2: best metric: 0.050
[09/26 08:56:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 08:56:07 visual_prompt]: Epoch 3 / 100: avg data time: 5.54e-02, avg batch time: 0.4977, average train loss: 3.9805
[09/26 08:56:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 3.9729
[09/26 08:56:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.00	
[09/26 08:56:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 08:56:15 visual_prompt]: Epoch 4 / 100: avg data time: 6.16e-02, avg batch time: 0.5043, average train loss: 4.0447
[09/26 08:56:17 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1661, average loss: 4.1326
[09/26 08:56:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 08:56:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 08:56:23 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.4978, average train loss: 4.1714
[09/26 08:56:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 4.1812
[09/26 08:56:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.50	
[09/26 08:56:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 08:56:32 visual_prompt]: Epoch 6 / 100: avg data time: 5.84e-02, avg batch time: 0.5004, average train loss: 4.2154
[09/26 08:56:33 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 4.2850
[09/26 08:56:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 08:56:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 08:56:40 visual_prompt]: Epoch 7 / 100: avg data time: 5.39e-02, avg batch time: 0.4974, average train loss: 4.2242
[09/26 08:56:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 4.4719
[09/26 08:56:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 18.00	
[09/26 08:56:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 08:56:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.69e-02, avg batch time: 0.4998, average train loss: 5.0671
[09/26 08:56:50 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 5.7947
[09/26 08:56:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 08:56:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 08:56:57 visual_prompt]: Epoch 9 / 100: avg data time: 6.18e-02, avg batch time: 0.5034, average train loss: 10.9159
[09/26 08:56:58 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1659, average loss: 15.8443
[09/26 08:56:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 08:56:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 08:57:05 visual_prompt]: Epoch 10 / 100: avg data time: 6.00e-02, avg batch time: 0.5009, average train loss: 37.3248
[09/26 08:57:07 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 35.1707
[09/26 08:57:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 08:57:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 08:57:14 visual_prompt]: Epoch 11 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 57.3505
[09/26 08:57:15 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 25.8431
[09/26 08:57:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 08:57:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 08:57:22 visual_prompt]: Epoch 12 / 100: avg data time: 6.39e-02, avg batch time: 0.5050, average train loss: 34.2299
[09/26 08:57:23 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 49.1604
[09/26 08:57:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 08:57:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 08:57:30 visual_prompt]: Epoch 13 / 100: avg data time: 6.66e-02, avg batch time: 0.5082, average train loss: 46.5367
[09/26 08:57:32 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 46.1622
[09/26 08:57:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 13.00	
[09/26 08:57:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 08:57:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.06e-02, avg batch time: 0.4924, average train loss: 50.6103
[09/26 08:57:40 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 48.4773
[09/26 08:57:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:57:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 08:57:47 visual_prompt]: Epoch 15 / 100: avg data time: 5.73e-02, avg batch time: 0.4992, average train loss: 47.5550
[09/26 08:57:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 45.2402
[09/26 08:57:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 08:57:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 08:57:55 visual_prompt]: Epoch 16 / 100: avg data time: 6.35e-02, avg batch time: 0.5052, average train loss: 41.4603
[09/26 08:57:57 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 31.6016
[09/26 08:57:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:57:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 08:58:04 visual_prompt]: Epoch 17 / 100: avg data time: 5.19e-02, avg batch time: 0.4951, average train loss: 32.3457
[09/26 08:58:05 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 26.6340
[09/26 08:58:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 08:58:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 08:58:12 visual_prompt]: Epoch 18 / 100: avg data time: 4.80e-02, avg batch time: 0.4930, average train loss: 27.7685
[09/26 08:58:14 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 25.8962
[09/26 08:58:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 08:58:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 08:58:20 visual_prompt]: Epoch 19 / 100: avg data time: 6.22e-02, avg batch time: 0.5039, average train loss: 28.9239
[09/26 08:58:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 34.0239
[09/26 08:58:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:58:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 08:58:29 visual_prompt]: Epoch 20 / 100: avg data time: 5.69e-02, avg batch time: 0.5000, average train loss: 29.6524
[09/26 08:58:30 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 20.9553
[09/26 08:58:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 08:58:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 08:58:37 visual_prompt]: Epoch 21 / 100: avg data time: 6.56e-02, avg batch time: 0.5071, average train loss: 35.9024
[09/26 08:58:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 30.7634
[09/26 08:58:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 08:58:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 08:58:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.67e-02, avg batch time: 0.4986, average train loss: 29.0085
[09/26 08:58:47 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 31.7119
[09/26 08:58:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 08:58:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 08:58:54 visual_prompt]: Epoch 23 / 100: avg data time: 5.72e-02, avg batch time: 0.4989, average train loss: 26.7316
[09/26 08:58:55 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1659, average loss: 27.5132
[09/26 08:58:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 08:58:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 08:59:02 visual_prompt]: Epoch 24 / 100: avg data time: 4.47e-02, avg batch time: 0.4869, average train loss: 30.0053
[09/26 08:59:04 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 24.3440
[09/26 08:59:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 08:59:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 08:59:10 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e-02, avg batch time: 0.4917, average train loss: 30.3266
[09/26 08:59:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 31.9463
[09/26 08:59:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 08:59:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 08:59:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.77e-02, avg batch time: 0.5003, average train loss: 29.8189
[09/26 08:59:20 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 26.2506
[09/26 08:59:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 08:59:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 08:59:27 visual_prompt]: Epoch 27 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 28.2303
[09/26 08:59:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 22.4404
[09/26 08:59:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 08:59:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 08:59:35 visual_prompt]: Epoch 28 / 100: avg data time: 5.07e-02, avg batch time: 0.4935, average train loss: 30.1185
[09/26 08:59:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 28.7234
[09/26 08:59:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.50	
[09/26 08:59:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 08:59:43 visual_prompt]: Epoch 29 / 100: avg data time: 4.54e-02, avg batch time: 0.4864, average train loss: 28.6309
[09/26 08:59:45 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 29.5210
[09/26 08:59:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 08:59:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 08:59:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.52e-02, avg batch time: 0.4979, average train loss: 28.5970
[09/26 08:59:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 20.5691
[09/26 08:59:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 08:59:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:00:00 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e-02, avg batch time: 0.4990, average train loss: 27.2276
[09/26 09:00:02 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 20.5822
[09/26 09:00:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 6.00	
[09/26 09:00:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:00:08 visual_prompt]: Epoch 32 / 100: avg data time: 5.74e-02, avg batch time: 0.4991, average train loss: 30.7434
[09/26 09:00:10 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 33.2492
[09/26 09:00:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 09:00:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:00:17 visual_prompt]: Epoch 33 / 100: avg data time: 5.19e-02, avg batch time: 0.4937, average train loss: 33.1310
[09/26 09:00:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 31.8358
[09/26 09:00:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.00	
[09/26 09:00:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:00:25 visual_prompt]: Epoch 34 / 100: avg data time: 4.47e-02, avg batch time: 0.4868, average train loss: 29.5786
[09/26 09:00:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 25.4230
[09/26 09:00:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 09:00:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:00:33 visual_prompt]: Epoch 35 / 100: avg data time: 6.09e-02, avg batch time: 0.5031, average train loss: 24.9821
[09/26 09:00:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 23.7817
[09/26 09:00:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 09:00:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:00:42 visual_prompt]: Epoch 36 / 100: avg data time: 6.17e-02, avg batch time: 0.5030, average train loss: 26.6067
[09/26 09:00:43 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1665, average loss: 21.2775
[09/26 09:00:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.50	
[09/26 09:00:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:00:50 visual_prompt]: Epoch 37 / 100: avg data time: 6.02e-02, avg batch time: 0.5014, average train loss: 22.7524
[09/26 09:00:52 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 17.1113
[09/26 09:00:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 09:00:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:00:59 visual_prompt]: Epoch 38 / 100: avg data time: 5.61e-02, avg batch time: 0.4988, average train loss: 19.9436
[09/26 09:01:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1660, average loss: 20.7360
[09/26 09:01:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 09:01:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:01:07 visual_prompt]: Epoch 39 / 100: avg data time: 6.23e-02, avg batch time: 0.5023, average train loss: 35.1309
[09/26 09:01:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1662, average loss: 36.3903
[09/26 09:01:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 09:01:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:01:15 visual_prompt]: Epoch 40 / 100: avg data time: 5.92e-02, avg batch time: 0.5011, average train loss: 26.9911
[09/26 09:01:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 21.9615
[09/26 09:01:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 09:01:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:01:24 visual_prompt]: Epoch 41 / 100: avg data time: 6.18e-02, avg batch time: 0.5039, average train loss: 25.5011
[09/26 09:01:25 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 23.2567
[09/26 09:01:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 09:01:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:01:32 visual_prompt]: Epoch 42 / 100: avg data time: 6.22e-02, avg batch time: 0.5045, average train loss: 24.3142
[09/26 09:01:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 22.6836
[09/26 09:01:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 09:01:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:01:40 visual_prompt]: Epoch 43 / 100: avg data time: 4.58e-02, avg batch time: 0.4899, average train loss: 25.9560
[09/26 09:01:42 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1659, average loss: 22.2381
[09/26 09:01:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 09:01:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:01:49 visual_prompt]: Epoch 44 / 100: avg data time: 5.96e-02, avg batch time: 0.5012, average train loss: 23.9798
[09/26 09:01:50 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 21.0122
[09/26 09:01:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 14.50	
[09/26 09:01:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:01:57 visual_prompt]: Epoch 45 / 100: avg data time: 4.18e-02, avg batch time: 0.4857, average train loss: 22.4618
[09/26 09:01:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 21.4752
[09/26 09:01:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.00	
[09/26 09:01:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:02:05 visual_prompt]: Epoch 46 / 100: avg data time: 5.97e-02, avg batch time: 0.5007, average train loss: 22.3069
[09/26 09:02:07 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1655, average loss: 13.1111
[09/26 09:02:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 09:02:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:02:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.60e-02, avg batch time: 0.4963, average train loss: 20.2981
[09/26 09:02:15 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 21.0730
[09/26 09:02:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:02:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:02:22 visual_prompt]: Epoch 48 / 100: avg data time: 5.95e-02, avg batch time: 0.5018, average train loss: 20.2362
[09/26 09:02:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 17.8846
[09/26 09:02:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 09:02:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:02:30 visual_prompt]: Epoch 49 / 100: avg data time: 5.84e-02, avg batch time: 0.4995, average train loss: 16.4009
[09/26 09:02:32 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 12.7257
[09/26 09:02:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 09:02:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:02:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.02e-02, avg batch time: 0.4925, average train loss: 12.4648
[09/26 09:02:40 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 9.6948
[09/26 09:02:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.00	
[09/26 09:02:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:02:47 visual_prompt]: Epoch 51 / 100: avg data time: 6.46e-02, avg batch time: 0.5063, average train loss: 9.4225
[09/26 09:02:49 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 9.0590
[09/26 09:02:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 09:02:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:02:56 visual_prompt]: Epoch 52 / 100: avg data time: 5.56e-02, avg batch time: 0.4983, average train loss: 9.5692
[09/26 09:02:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 6.5828
[09/26 09:02:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:02:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:03:04 visual_prompt]: Epoch 53 / 100: avg data time: 4.69e-02, avg batch time: 0.4895, average train loss: 7.8635
[09/26 09:03:05 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 8.8428
[09/26 09:03:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 09:03:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:03:12 visual_prompt]: Epoch 54 / 100: avg data time: 6.18e-02, avg batch time: 0.5029, average train loss: 10.4059
[09/26 09:03:14 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1658, average loss: 7.5067
[09/26 09:03:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:03:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:03:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.34e-02, avg batch time: 0.4947, average train loss: 12.6546
[09/26 09:03:22 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 10.7645
[09/26 09:03:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:03:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:03:29 visual_prompt]: Epoch 56 / 100: avg data time: 5.30e-02, avg batch time: 0.4959, average train loss: 12.7520
[09/26 09:03:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 9.5188
[09/26 09:03:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.50	
[09/26 09:03:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:03:37 visual_prompt]: Epoch 57 / 100: avg data time: 6.38e-02, avg batch time: 0.5048, average train loss: 10.7185
[09/26 09:03:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 9.5908
[09/26 09:03:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.00	
[09/26 09:03:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:03:45 visual_prompt]: Epoch 58 / 100: avg data time: 5.25e-02, avg batch time: 0.4943, average train loss: 8.7919
[09/26 09:03:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1656, average loss: 6.0610
[09/26 09:03:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.00	
[09/26 09:03:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:03:54 visual_prompt]: Epoch 59 / 100: avg data time: 5.77e-02, avg batch time: 0.4988, average train loss: 6.6292
[09/26 09:03:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1659, average loss: 6.2650
[09/26 09:03:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 09:03:55 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:04:02 visual_prompt]: Epoch 60 / 100: avg data time: 6.04e-02, avg batch time: 0.5006, average train loss: 6.3790
[09/26 09:04:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 5.5329
[09/26 09:04:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:04:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:04:11 visual_prompt]: Epoch 61 / 100: avg data time: 5.72e-02, avg batch time: 0.4980, average train loss: 5.3138
[09/26 09:04:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 4.8547
[09/26 09:04:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:04:12 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:04:19 visual_prompt]: Epoch 62 / 100: avg data time: 5.80e-02, avg batch time: 0.4989, average train loss: 4.7915
[09/26 09:04:21 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 4.6232
[09/26 09:04:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 09:04:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:04:27 visual_prompt]: Epoch 63 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 5.0457
[09/26 09:04:29 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 4.6705
[09/26 09:04:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.00	
[09/26 09:04:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:04:36 visual_prompt]: Epoch 64 / 100: avg data time: 5.52e-02, avg batch time: 0.4971, average train loss: 5.7424
[09/26 09:04:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 4.6785
[09/26 09:04:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:04:37 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:04:44 visual_prompt]: Epoch 65 / 100: avg data time: 6.23e-02, avg batch time: 0.5030, average train loss: 6.5648
[09/26 09:04:46 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 4.7667
[09/26 09:04:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 09:04:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:04:52 visual_prompt]: Epoch 66 / 100: avg data time: 5.59e-02, avg batch time: 0.4975, average train loss: 6.5802
[09/26 09:04:54 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 5.7200
[09/26 09:04:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:04:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:05:01 visual_prompt]: Epoch 67 / 100: avg data time: 5.99e-02, avg batch time: 0.5003, average train loss: 7.4483
[09/26 09:05:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 4.9733
[09/26 09:05:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 09:05:02 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:05:09 visual_prompt]: Epoch 68 / 100: avg data time: 5.73e-02, avg batch time: 0.4996, average train loss: 6.3928
[09/26 09:05:11 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 5.6493
[09/26 09:05:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 09:05:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:05:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 6.3483
[09/26 09:05:19 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 6.2990
[09/26 09:05:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.50	
[09/26 09:05:19 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:05:26 visual_prompt]: Epoch 70 / 100: avg data time: 4.88e-02, avg batch time: 0.4906, average train loss: 8.2073
[09/26 09:05:27 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1663, average loss: 5.3186
[09/26 09:05:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 09:05:27 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:05:34 visual_prompt]: Epoch 71 / 100: avg data time: 4.86e-02, avg batch time: 0.4926, average train loss: 8.1402
[09/26 09:05:36 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 6.2569
[09/26 09:05:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.00	
[09/26 09:05:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:05:43 visual_prompt]: Epoch 72 / 100: avg data time: 6.13e-02, avg batch time: 0.5025, average train loss: 6.3037
[09/26 09:05:44 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 4.8444
[09/26 09:05:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:05:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:05:51 visual_prompt]: Epoch 73 / 100: avg data time: 4.49e-02, avg batch time: 0.4877, average train loss: 4.9067
[09/26 09:05:52 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 4.4318
[09/26 09:05:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 09:05:52 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:05:59 visual_prompt]: Epoch 74 / 100: avg data time: 5.76e-02, avg batch time: 0.5011, average train loss: 4.6667
[09/26 09:06:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1667, average loss: 4.4038
[09/26 09:06:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:06:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:06:07 visual_prompt]: Epoch 75 / 100: avg data time: 6.09e-02, avg batch time: 0.5036, average train loss: 4.2574
[09/26 09:06:09 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 4.2434
[09/26 09:06:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 09:06:09 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:06:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.92e-02, avg batch time: 0.5015, average train loss: 4.2364
[09/26 09:06:17 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 4.2858
[09/26 09:06:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 09:06:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:06:24 visual_prompt]: Epoch 77 / 100: avg data time: 4.45e-02, avg batch time: 0.4858, average train loss: 4.1067
[09/26 09:06:26 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 4.1281
[09/26 09:06:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.00	
[09/26 09:06:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:06:32 visual_prompt]: Epoch 78 / 100: avg data time: 6.13e-02, avg batch time: 0.5033, average train loss: 4.1703
[09/26 09:06:34 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1660, average loss: 4.0978
[09/26 09:06:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 09:06:34 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:06:41 visual_prompt]: Epoch 79 / 100: avg data time: 4.96e-02, avg batch time: 0.4932, average train loss: 4.0704
[09/26 09:06:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 4.2386
[09/26 09:06:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 09:06:42 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:06:49 visual_prompt]: Epoch 80 / 100: avg data time: 4.94e-02, avg batch time: 0.4925, average train loss: 4.0952
[09/26 09:06:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 4.0075
[09/26 09:06:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 09:06:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:06:57 visual_prompt]: Epoch 81 / 100: avg data time: 5.94e-02, avg batch time: 0.5010, average train loss: 4.0809
[09/26 09:06:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 3.9549
[09/26 09:06:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 09:06:59 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:07:06 visual_prompt]: Epoch 82 / 100: avg data time: 5.53e-02, avg batch time: 0.4969, average train loss: 4.0056
[09/26 09:07:07 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 3.9481
[09/26 09:07:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 09:07:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:07:14 visual_prompt]: Epoch 83 / 100: avg data time: 5.83e-02, avg batch time: 0.4999, average train loss: 3.9277
[09/26 09:07:16 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1665, average loss: 3.7522
[09/26 09:07:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 19.50	
[09/26 09:07:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:07:22 visual_prompt]: Epoch 84 / 100: avg data time: 5.83e-02, avg batch time: 0.5005, average train loss: 3.9801
[09/26 09:07:24 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 3.9950
[09/26 09:07:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 09:07:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:07:31 visual_prompt]: Epoch 85 / 100: avg data time: 5.57e-02, avg batch time: 0.4983, average train loss: 3.9391
[09/26 09:07:32 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 3.9128
[09/26 09:07:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 09:07:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:07:39 visual_prompt]: Epoch 86 / 100: avg data time: 6.12e-02, avg batch time: 0.5047, average train loss: 3.9122
[09/26 09:07:41 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 3.8437
[09/26 09:07:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 09:07:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:07:48 visual_prompt]: Epoch 87 / 100: avg data time: 5.74e-02, avg batch time: 0.4994, average train loss: 3.8948
[09/26 09:07:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 3.8440
[09/26 09:07:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 09:07:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:07:56 visual_prompt]: Epoch 88 / 100: avg data time: 5.72e-02, avg batch time: 0.4996, average train loss: 3.8639
[09/26 09:07:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 3.7927
[09/26 09:07:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:07:57 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:08:04 visual_prompt]: Epoch 89 / 100: avg data time: 5.49e-02, avg batch time: 0.4968, average train loss: 3.8320
[09/26 09:08:06 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 3.7598
[09/26 09:08:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 09:08:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:08:12 visual_prompt]: Epoch 90 / 100: avg data time: 5.38e-02, avg batch time: 0.4966, average train loss: 3.7565
[09/26 09:08:14 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 3.6481
[09/26 09:08:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 29.00	
[09/26 09:08:14 visual_prompt]: Best epoch 90: best metric: 0.055
[09/26 09:08:14 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:08:21 visual_prompt]: Epoch 91 / 100: avg data time: 4.97e-02, avg batch time: 0.4911, average train loss: 3.6242
[09/26 09:08:22 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 3.5543
[09/26 09:08:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 24.50	
[09/26 09:08:22 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:08:29 visual_prompt]: Epoch 92 / 100: avg data time: 4.61e-02, avg batch time: 0.4874, average train loss: 3.7625
[09/26 09:08:30 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 3.8398
[09/26 09:08:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:08:30 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:08:37 visual_prompt]: Epoch 93 / 100: avg data time: 5.92e-02, avg batch time: 0.5004, average train loss: 3.7085
[09/26 09:08:39 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 3.7102
[09/26 09:08:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 19.50	
[09/26 09:08:39 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:08:46 visual_prompt]: Epoch 94 / 100: avg data time: 6.21e-02, avg batch time: 0.5061, average train loss: 3.5947
[09/26 09:08:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 3.5530
[09/26 09:08:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 27.50	
[09/26 09:08:47 visual_prompt]: Best epoch 94: best metric: 0.065
[09/26 09:08:47 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:08:54 visual_prompt]: Epoch 95 / 100: avg data time: 5.78e-02, avg batch time: 0.4992, average train loss: 3.4958
[09/26 09:08:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 3.5250
[09/26 09:08:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 22.00	
[09/26 09:08:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:09:02 visual_prompt]: Epoch 96 / 100: avg data time: 5.90e-02, avg batch time: 0.5011, average train loss: 3.4293
[09/26 09:09:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 3.4315
[09/26 09:09:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 25.50	
[09/26 09:09:04 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:09:11 visual_prompt]: Epoch 97 / 100: avg data time: 5.31e-02, avg batch time: 0.4954, average train loss: 3.3599
[09/26 09:09:12 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 3.4057
[09/26 09:09:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 24.00	
[09/26 09:09:12 visual_prompt]: Best epoch 97: best metric: 0.080
[09/26 09:09:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:09:19 visual_prompt]: Epoch 98 / 100: avg data time: 5.36e-02, avg batch time: 0.4960, average train loss: 3.3043
[09/26 09:09:21 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 3.3684
[09/26 09:09:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 29.50	
[09/26 09:09:21 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:09:27 visual_prompt]: Epoch 99 / 100: avg data time: 5.87e-02, avg batch time: 0.5007, average train loss: 3.2665
[09/26 09:09:29 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 3.3760
[09/26 09:09:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 30.00	
[09/26 09:09:29 visual_prompt]: Best epoch 99: best metric: 0.085
[09/26 09:09:29 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:09:36 visual_prompt]: Epoch 100 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 3.2515
[09/26 09:09:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 3.3538
[09/26 09:09:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 30.50	
[09/26 09:09:37 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:09:37 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:09:37 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:09:37 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:09:37 visual_prompt]: Training with config:
[09/26 09:09:37 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:09:37 visual_prompt]: Loading training data...
[09/26 09:09:37 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:09:38 visual_prompt]: Number of images: 800
[09/26 09:09:38 visual_prompt]: Number of classes: 45 / 45
[09/26 09:09:38 visual_prompt]: Loading validation data...
[09/26 09:09:38 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:09:39 visual_prompt]: Number of images: 200
[09/26 09:09:39 visual_prompt]: Number of classes: 45 / 45
[09/26 09:09:39 visual_prompt]: Constructing models...
[09/26 09:09:41 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 09:09:41 visual_prompt]: tuned percent:0.574
[09/26 09:09:41 visual_prompt]: Device used for model: 0
[09/26 09:09:41 visual_prompt]: Setting up Evaluator...
[09/26 09:09:41 visual_prompt]: Setting up Trainer...
[09/26 09:09:41 visual_prompt]: 	Setting up the optimizer...
[09/26 09:09:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:09:48 visual_prompt]: Epoch 1 / 100: avg data time: 5.67e-02, avg batch time: 0.4980, average train loss: 3.8964
[09/26 09:09:50 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 09:09:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 09:09:50 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 09:09:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:09:57 visual_prompt]: Epoch 2 / 100: avg data time: 6.16e-02, avg batch time: 0.5039, average train loss: 3.9481
[09/26 09:09:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 3.8111
[09/26 09:09:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 11.50	
[09/26 09:09:58 visual_prompt]: Best epoch 2: best metric: 0.045
[09/26 09:09:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:10:05 visual_prompt]: Epoch 3 / 100: avg data time: 5.00e-02, avg batch time: 0.4929, average train loss: 3.7721
[09/26 09:10:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 3.7404
[09/26 09:10:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 24.50	
[09/26 09:10:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:10:13 visual_prompt]: Epoch 4 / 100: avg data time: 6.08e-02, avg batch time: 0.5029, average train loss: 3.7952
[09/26 09:10:15 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 3.7535
[09/26 09:10:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 24.50	
[09/26 09:10:15 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:10:22 visual_prompt]: Epoch 5 / 100: avg data time: 5.89e-02, avg batch time: 0.5007, average train loss: 3.9494
[09/26 09:10:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 3.9824
[09/26 09:10:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.50	top5: 26.50	
[09/26 09:10:23 visual_prompt]: Best epoch 5: best metric: 0.115
[09/26 09:10:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:10:30 visual_prompt]: Epoch 6 / 100: avg data time: 5.46e-02, avg batch time: 0.4961, average train loss: 4.2593
[09/26 09:10:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 4.0605
[09/26 09:10:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 31.50	
[09/26 09:10:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:10:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.85e-02, avg batch time: 0.4906, average train loss: 4.7440
[09/26 09:10:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 5.3715
[09/26 09:10:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 20.00	
[09/26 09:10:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:10:47 visual_prompt]: Epoch 8 / 100: avg data time: 5.49e-02, avg batch time: 0.4975, average train loss: 4.1518
[09/26 09:10:48 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 4.9029
[09/26 09:10:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 38.50	
[09/26 09:10:48 visual_prompt]: Best epoch 8: best metric: 0.140
[09/26 09:10:48 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:10:55 visual_prompt]: Epoch 9 / 100: avg data time: 5.49e-02, avg batch time: 0.4968, average train loss: 4.4215
[09/26 09:10:56 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 5.5060
[09/26 09:10:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.50	top5: 41.50	
[09/26 09:10:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 09:11:03 visual_prompt]: Epoch 10 / 100: avg data time: 4.97e-02, avg batch time: 0.4918, average train loss: 8.4811
[09/26 09:11:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 14.7768
[09/26 09:11:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 09:11:05 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 09:11:12 visual_prompt]: Epoch 11 / 100: avg data time: 5.56e-02, avg batch time: 0.4972, average train loss: 20.1893
[09/26 09:11:13 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 30.6519
[09/26 09:11:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 09:11:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 09:11:20 visual_prompt]: Epoch 12 / 100: avg data time: 6.00e-02, avg batch time: 0.5019, average train loss: 29.7274
[09/26 09:11:21 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1662, average loss: 29.2523
[09/26 09:11:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.00	
[09/26 09:11:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 09:11:28 visual_prompt]: Epoch 13 / 100: avg data time: 5.67e-02, avg batch time: 0.4994, average train loss: 37.9165
[09/26 09:11:30 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 44.0972
[09/26 09:11:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 09:11:30 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 09:11:37 visual_prompt]: Epoch 14 / 100: avg data time: 6.49e-02, avg batch time: 0.5063, average train loss: 47.8225
[09/26 09:11:38 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 45.0468
[09/26 09:11:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 09:11:38 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 09:11:45 visual_prompt]: Epoch 15 / 100: avg data time: 6.06e-02, avg batch time: 0.5033, average train loss: 53.1633
[09/26 09:11:47 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1658, average loss: 48.6803
[09/26 09:11:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 09:11:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 09:11:54 visual_prompt]: Epoch 16 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 50.6749
[09/26 09:11:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 36.1826
[09/26 09:11:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 15.00	
[09/26 09:11:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 09:12:02 visual_prompt]: Epoch 17 / 100: avg data time: 5.24e-02, avg batch time: 0.4936, average train loss: 49.4587
[09/26 09:12:04 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 60.5542
[09/26 09:12:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 09:12:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 09:12:11 visual_prompt]: Epoch 18 / 100: avg data time: 6.40e-02, avg batch time: 0.5051, average train loss: 52.1910
[09/26 09:12:12 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 48.1865
[09/26 09:12:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 7.50	
[09/26 09:12:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 09:12:19 visual_prompt]: Epoch 19 / 100: avg data time: 5.88e-02, avg batch time: 0.5005, average train loss: 42.7883
[09/26 09:12:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1659, average loss: 40.1972
[09/26 09:12:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 14.00	
[09/26 09:12:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 09:12:27 visual_prompt]: Epoch 20 / 100: avg data time: 5.49e-02, avg batch time: 0.4967, average train loss: 50.4005
[09/26 09:12:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 38.2409
[09/26 09:12:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:12:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 09:12:36 visual_prompt]: Epoch 21 / 100: avg data time: 5.25e-02, avg batch time: 0.4937, average train loss: 37.2271
[09/26 09:12:37 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 34.8354
[09/26 09:12:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 14.00	
[09/26 09:12:37 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 09:12:44 visual_prompt]: Epoch 22 / 100: avg data time: 4.82e-02, avg batch time: 0.4905, average train loss: 35.4932
[09/26 09:12:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 27.4168
[09/26 09:12:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 09:12:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 09:12:52 visual_prompt]: Epoch 23 / 100: avg data time: 6.01e-02, avg batch time: 0.5025, average train loss: 30.6046
[09/26 09:12:54 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 35.0309
[09/26 09:12:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 09:12:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 09:13:01 visual_prompt]: Epoch 24 / 100: avg data time: 5.93e-02, avg batch time: 0.5011, average train loss: 28.9990
[09/26 09:13:02 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1660, average loss: 24.0946
[09/26 09:13:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 09:13:02 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 09:13:09 visual_prompt]: Epoch 25 / 100: avg data time: 5.82e-02, avg batch time: 0.4994, average train loss: 26.0148
[09/26 09:13:11 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1663, average loss: 19.4087
[09/26 09:13:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 09:13:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 09:13:18 visual_prompt]: Epoch 26 / 100: avg data time: 6.22e-02, avg batch time: 0.5046, average train loss: 16.4892
[09/26 09:13:19 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 14.8908
[09/26 09:13:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 09:13:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 09:13:26 visual_prompt]: Epoch 27 / 100: avg data time: 5.82e-02, avg batch time: 0.4993, average train loss: 14.3904
[09/26 09:13:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 11.2746
[09/26 09:13:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 09:13:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 09:13:34 visual_prompt]: Epoch 28 / 100: avg data time: 5.64e-02, avg batch time: 0.4986, average train loss: 9.3020
[09/26 09:13:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 9.1087
[09/26 09:13:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 14.50	
[09/26 09:13:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 09:13:43 visual_prompt]: Epoch 29 / 100: avg data time: 6.61e-02, avg batch time: 0.5071, average train loss: 9.3949
[09/26 09:13:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 6.2243
[09/26 09:13:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.00	
[09/26 09:13:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 09:13:51 visual_prompt]: Epoch 30 / 100: avg data time: 5.67e-02, avg batch time: 0.4985, average train loss: 6.1034
[09/26 09:13:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 5.3251
[09/26 09:13:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 21.00	
[09/26 09:13:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:14:00 visual_prompt]: Epoch 31 / 100: avg data time: 6.11e-02, avg batch time: 0.5022, average train loss: 4.9673
[09/26 09:14:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 4.8581
[09/26 09:14:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.50	
[09/26 09:14:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:14:08 visual_prompt]: Epoch 32 / 100: avg data time: 5.77e-02, avg batch time: 0.5006, average train loss: 4.4612
[09/26 09:14:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 4.3468
[09/26 09:14:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 25.50	
[09/26 09:14:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:14:17 visual_prompt]: Epoch 33 / 100: avg data time: 6.41e-02, avg batch time: 0.5067, average train loss: 4.1215
[09/26 09:14:18 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1660, average loss: 3.7887
[09/26 09:14:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 36.00	
[09/26 09:14:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:14:25 visual_prompt]: Epoch 34 / 100: avg data time: 6.28e-02, avg batch time: 0.5041, average train loss: 3.5058
[09/26 09:14:26 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 3.2736
[09/26 09:14:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.00	top5: 45.50	
[09/26 09:14:26 visual_prompt]: Best epoch 34: best metric: 0.190
[09/26 09:14:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:14:33 visual_prompt]: Epoch 35 / 100: avg data time: 5.82e-02, avg batch time: 0.4996, average train loss: 3.3955
[09/26 09:14:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 3.9711
[09/26 09:14:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 34.50	
[09/26 09:14:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:14:42 visual_prompt]: Epoch 36 / 100: avg data time: 6.10e-02, avg batch time: 0.5044, average train loss: 3.4626
[09/26 09:14:43 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 3.4613
[09/26 09:14:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 43.50	
[09/26 09:14:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:14:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.81e-02, avg batch time: 0.5012, average train loss: 2.9523
[09/26 09:14:52 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 3.3581
[09/26 09:14:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.50	top5: 49.50	
[09/26 09:14:52 visual_prompt]: Best epoch 37: best metric: 0.215
[09/26 09:14:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:14:58 visual_prompt]: Epoch 38 / 100: avg data time: 5.87e-02, avg batch time: 0.5014, average train loss: 2.4873
[09/26 09:15:00 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1661, average loss: 2.7021
[09/26 09:15:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.50	top5: 66.00	
[09/26 09:15:00 visual_prompt]: Best epoch 38: best metric: 0.295
[09/26 09:15:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:15:07 visual_prompt]: Epoch 39 / 100: avg data time: 5.72e-02, avg batch time: 0.4997, average train loss: 2.3669
[09/26 09:15:08 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1659, average loss: 3.8953
[09/26 09:15:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 35.50	
[09/26 09:15:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:15:15 visual_prompt]: Epoch 40 / 100: avg data time: 6.43e-02, avg batch time: 0.5063, average train loss: 2.8015
[09/26 09:15:17 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 2.6672
[09/26 09:15:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 38.50	top5: 68.00	
[09/26 09:15:17 visual_prompt]: Best epoch 40: best metric: 0.385
[09/26 09:15:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:15:23 visual_prompt]: Epoch 41 / 100: avg data time: 5.54e-02, avg batch time: 0.4967, average train loss: 1.9626
[09/26 09:15:25 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 2.3042
[09/26 09:15:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 48.00	top5: 74.00	
[09/26 09:15:25 visual_prompt]: Best epoch 41: best metric: 0.480
[09/26 09:15:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:15:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.67e-02, avg batch time: 0.4984, average train loss: 1.1504
[09/26 09:15:33 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.6367
[09/26 09:15:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 87.00	
[09/26 09:15:33 visual_prompt]: Best epoch 42: best metric: 0.610
[09/26 09:15:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:15:40 visual_prompt]: Epoch 43 / 100: avg data time: 5.41e-02, avg batch time: 0.4968, average train loss: 0.8249
[09/26 09:15:42 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 1.7104
[09/26 09:15:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 59.50	top5: 90.00	
[09/26 09:15:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:15:48 visual_prompt]: Epoch 44 / 100: avg data time: 6.08e-02, avg batch time: 0.5022, average train loss: 0.5075
[09/26 09:15:50 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 1.5344
[09/26 09:15:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.00	
[09/26 09:15:50 visual_prompt]: Best epoch 44: best metric: 0.670
[09/26 09:15:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:15:57 visual_prompt]: Epoch 45 / 100: avg data time: 6.24e-02, avg batch time: 0.5041, average train loss: 0.3824
[09/26 09:15:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 1.2196
[09/26 09:15:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 95.50	
[09/26 09:15:59 visual_prompt]: Best epoch 45: best metric: 0.685
[09/26 09:15:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:16:05 visual_prompt]: Epoch 46 / 100: avg data time: 6.63e-02, avg batch time: 0.5083, average train loss: 0.1501
[09/26 09:16:07 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1663, average loss: 1.3222
[09/26 09:16:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 09:16:07 visual_prompt]: Best epoch 46: best metric: 0.700
[09/26 09:16:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:16:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.62e-02, avg batch time: 0.4978, average train loss: 0.1720
[09/26 09:16:15 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1660, average loss: 1.5100
[09/26 09:16:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 91.50	
[09/26 09:16:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:16:22 visual_prompt]: Epoch 48 / 100: avg data time: 6.52e-02, avg batch time: 0.5075, average train loss: 0.1643
[09/26 09:16:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 1.3069
[09/26 09:16:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 09:16:24 visual_prompt]: Best epoch 48: best metric: 0.760
[09/26 09:16:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:16:31 visual_prompt]: Epoch 49 / 100: avg data time: 5.63e-02, avg batch time: 0.4979, average train loss: 0.1465
[09/26 09:16:32 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1664, average loss: 1.3435
[09/26 09:16:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.00	
[09/26 09:16:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:16:39 visual_prompt]: Epoch 50 / 100: avg data time: 6.33e-02, avg batch time: 0.5043, average train loss: 0.0955
[09/26 09:16:41 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.0147
[09/26 09:16:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 97.50	
[09/26 09:16:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:16:47 visual_prompt]: Epoch 51 / 100: avg data time: 6.10e-02, avg batch time: 0.5019, average train loss: 0.1159
[09/26 09:16:49 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.2388
[09/26 09:16:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 09:16:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:16:56 visual_prompt]: Epoch 52 / 100: avg data time: 4.44e-02, avg batch time: 0.4896, average train loss: 0.0996
[09/26 09:16:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.3251
[09/26 09:16:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 90.50	
[09/26 09:16:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:17:04 visual_prompt]: Epoch 53 / 100: avg data time: 5.82e-02, avg batch time: 0.4998, average train loss: 0.0783
[09/26 09:17:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 1.1820
[09/26 09:17:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.50	
[09/26 09:17:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:17:12 visual_prompt]: Epoch 54 / 100: avg data time: 5.71e-02, avg batch time: 0.4990, average train loss: 0.0957
[09/26 09:17:14 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.3039
[09/26 09:17:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 09:17:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:17:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 0.0908
[09/26 09:17:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.4285
[09/26 09:17:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 09:17:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:17:29 visual_prompt]: Epoch 56 / 100: avg data time: 5.85e-02, avg batch time: 0.4999, average train loss: 0.0767
[09/26 09:17:31 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.1162
[09/26 09:17:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 97.00	
[09/26 09:17:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:17:38 visual_prompt]: Epoch 57 / 100: avg data time: 5.83e-02, avg batch time: 0.5008, average train loss: 0.0770
[09/26 09:17:39 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.0404
[09/26 09:17:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 09:17:39 visual_prompt]: Best epoch 57: best metric: 0.765
[09/26 09:17:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:17:46 visual_prompt]: Epoch 58 / 100: avg data time: 6.08e-02, avg batch time: 0.5024, average train loss: 0.0352
[09/26 09:17:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.3028
[09/26 09:17:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 09:17:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:17:54 visual_prompt]: Epoch 59 / 100: avg data time: 5.65e-02, avg batch time: 0.4979, average train loss: 0.0309
[09/26 09:17:56 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.1128
[09/26 09:17:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 94.00	
[09/26 09:17:56 visual_prompt]: Best epoch 59: best metric: 0.770
[09/26 09:17:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:18:03 visual_prompt]: Epoch 60 / 100: avg data time: 6.32e-02, avg batch time: 0.5057, average train loss: 0.0102
[09/26 09:18:04 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 1.0884
[09/26 09:18:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 94.00	
[09/26 09:18:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:18:11 visual_prompt]: Epoch 61 / 100: avg data time: 6.11e-02, avg batch time: 0.5033, average train loss: 0.0070
[09/26 09:18:13 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 1.0179
[09/26 09:18:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 09:18:13 visual_prompt]: Best epoch 61: best metric: 0.780
[09/26 09:18:13 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:18:19 visual_prompt]: Epoch 62 / 100: avg data time: 4.73e-02, avg batch time: 0.4899, average train loss: 0.0052
[09/26 09:18:21 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.0357
[09/26 09:18:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.00	
[09/26 09:18:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:18:28 visual_prompt]: Epoch 63 / 100: avg data time: 6.52e-02, avg batch time: 0.5072, average train loss: 0.0061
[09/26 09:18:29 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 0.9992
[09/26 09:18:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 94.50	
[09/26 09:18:29 visual_prompt]: Best epoch 63: best metric: 0.785
[09/26 09:18:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:18:36 visual_prompt]: Epoch 64 / 100: avg data time: 6.25e-02, avg batch time: 0.5047, average train loss: 0.0096
[09/26 09:18:38 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 0.9421
[09/26 09:18:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 09:18:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:18:45 visual_prompt]: Epoch 65 / 100: avg data time: 5.81e-02, avg batch time: 0.5001, average train loss: 0.0130
[09/26 09:18:46 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.8599
[09/26 09:18:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 09:18:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:18:53 visual_prompt]: Epoch 66 / 100: avg data time: 4.68e-02, avg batch time: 0.4890, average train loss: 0.0069
[09/26 09:18:54 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1663, average loss: 0.8063
[09/26 09:18:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 09:18:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:19:01 visual_prompt]: Epoch 67 / 100: avg data time: 5.58e-02, avg batch time: 0.4986, average train loss: 0.0040
[09/26 09:19:03 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.8099
[09/26 09:19:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.00	
[09/26 09:19:03 visual_prompt]: Best epoch 67: best metric: 0.800
[09/26 09:19:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:19:10 visual_prompt]: Epoch 68 / 100: avg data time: 5.86e-02, avg batch time: 0.5010, average train loss: 0.0032
[09/26 09:19:11 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 0.7797
[09/26 09:19:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 09:19:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:19:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.67e-02, avg batch time: 0.5007, average train loss: 0.0030
[09/26 09:19:19 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 0.7551
[09/26 09:19:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 09:19:19 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:19:26 visual_prompt]: Epoch 70 / 100: avg data time: 5.73e-02, avg batch time: 0.4995, average train loss: 0.0030
[09/26 09:19:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 0.7488
[09/26 09:19:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.50	
[09/26 09:19:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:19:35 visual_prompt]: Epoch 71 / 100: avg data time: 4.74e-02, avg batch time: 0.4890, average train loss: 0.0031
[09/26 09:19:36 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 0.7332
[09/26 09:19:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.50	
[09/26 09:19:36 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:19:43 visual_prompt]: Epoch 72 / 100: avg data time: 5.90e-02, avg batch time: 0.5013, average train loss: 0.0033
[09/26 09:19:44 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1663, average loss: 0.7287
[09/26 09:19:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.50	
[09/26 09:19:44 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:19:51 visual_prompt]: Epoch 73 / 100: avg data time: 6.02e-02, avg batch time: 0.5022, average train loss: 0.0036
[09/26 09:19:53 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 0.7237
[09/26 09:19:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 09:19:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:20:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.45e-02, avg batch time: 0.4977, average train loss: 0.0036
[09/26 09:20:01 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 0.7215
[09/26 09:20:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 09:20:01 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:20:08 visual_prompt]: Epoch 75 / 100: avg data time: 6.10e-02, avg batch time: 0.5023, average train loss: 0.0039
[09/26 09:20:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 0.7125
[09/26 09:20:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 09:20:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:20:16 visual_prompt]: Epoch 76 / 100: avg data time: 5.89e-02, avg batch time: 0.5013, average train loss: 0.0039
[09/26 09:20:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.7051
[09/26 09:20:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 09:20:18 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:20:25 visual_prompt]: Epoch 77 / 100: avg data time: 4.72e-02, avg batch time: 0.4903, average train loss: 0.0039
[09/26 09:20:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 0.6962
[09/26 09:20:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 09:20:26 visual_prompt]: Best epoch 77: best metric: 0.805
[09/26 09:20:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:20:33 visual_prompt]: Epoch 78 / 100: avg data time: 6.22e-02, avg batch time: 0.5046, average train loss: 0.0040
[09/26 09:20:35 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 0.6968
[09/26 09:20:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 09:20:35 visual_prompt]: Best epoch 78: best metric: 0.815
[09/26 09:20:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:20:41 visual_prompt]: Epoch 79 / 100: avg data time: 5.48e-02, avg batch time: 0.4960, average train loss: 0.0040
[09/26 09:20:43 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1662, average loss: 0.6886
[09/26 09:20:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 09:20:43 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:20:50 visual_prompt]: Epoch 80 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 0.0041
[09/26 09:20:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 0.6893
[09/26 09:20:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 09:20:51 visual_prompt]: Best epoch 80: best metric: 0.820
[09/26 09:20:51 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:20:58 visual_prompt]: Epoch 81 / 100: avg data time: 4.92e-02, avg batch time: 0.4919, average train loss: 0.0041
[09/26 09:21:00 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1664, average loss: 0.6805
[09/26 09:21:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 09:21:00 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:21:06 visual_prompt]: Epoch 82 / 100: avg data time: 5.73e-02, avg batch time: 0.4997, average train loss: 0.0041
[09/26 09:21:08 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 0.6783
[09/26 09:21:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:21:08 visual_prompt]: Best epoch 82: best metric: 0.825
[09/26 09:21:08 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:21:15 visual_prompt]: Epoch 83 / 100: avg data time: 5.83e-02, avg batch time: 0.5006, average train loss: 0.0041
[09/26 09:21:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 0.6743
[09/26 09:21:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.00	
[09/26 09:21:16 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:21:23 visual_prompt]: Epoch 84 / 100: avg data time: 5.75e-02, avg batch time: 0.5002, average train loss: 0.0042
[09/26 09:21:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 0.6797
[09/26 09:21:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 09:21:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:21:32 visual_prompt]: Epoch 85 / 100: avg data time: 4.73e-02, avg batch time: 0.4919, average train loss: 0.0041
[09/26 09:21:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 0.6717
[09/26 09:21:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 09:21:33 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:21:40 visual_prompt]: Epoch 86 / 100: avg data time: 4.64e-02, avg batch time: 0.4896, average train loss: 0.0041
[09/26 09:21:41 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.6709
[09/26 09:21:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.50	
[09/26 09:21:41 visual_prompt]: Best epoch 86: best metric: 0.830
[09/26 09:21:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:21:48 visual_prompt]: Epoch 87 / 100: avg data time: 5.13e-02, avg batch time: 0.4958, average train loss: 0.0041
[09/26 09:21:50 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1664, average loss: 0.6701
[09/26 09:21:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 09:21:50 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:21:57 visual_prompt]: Epoch 88 / 100: avg data time: 6.47e-02, avg batch time: 0.5064, average train loss: 0.0041
[09/26 09:21:58 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 0.6632
[09/26 09:21:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 09:21:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:22:05 visual_prompt]: Epoch 89 / 100: avg data time: 5.76e-02, avg batch time: 0.5013, average train loss: 0.0041
[09/26 09:22:06 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 0.6608
[09/26 09:22:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 09:22:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:22:13 visual_prompt]: Epoch 90 / 100: avg data time: 5.62e-02, avg batch time: 0.4989, average train loss: 0.0041
[09/26 09:22:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 0.6590
[09/26 09:22:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 09:22:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:22:22 visual_prompt]: Epoch 91 / 100: avg data time: 6.07e-02, avg batch time: 0.5036, average train loss: 0.0041
[09/26 09:22:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 0.6575
[09/26 09:22:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:22:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:22:30 visual_prompt]: Epoch 92 / 100: avg data time: 5.88e-02, avg batch time: 0.5015, average train loss: 0.0041
[09/26 09:22:32 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 0.6576
[09/26 09:22:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:22:32 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:22:38 visual_prompt]: Epoch 93 / 100: avg data time: 5.87e-02, avg batch time: 0.5013, average train loss: 0.0041
[09/26 09:22:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 0.6579
[09/26 09:22:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 09:22:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:22:47 visual_prompt]: Epoch 94 / 100: avg data time: 5.79e-02, avg batch time: 0.5003, average train loss: 0.0040
[09/26 09:22:48 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 0.6591
[09/26 09:22:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:22:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:22:55 visual_prompt]: Epoch 95 / 100: avg data time: 5.66e-02, avg batch time: 0.4985, average train loss: 0.0041
[09/26 09:22:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.6603
[09/26 09:22:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:22:57 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:23:04 visual_prompt]: Epoch 96 / 100: avg data time: 6.48e-02, avg batch time: 0.5068, average train loss: 0.0041
[09/26 09:23:05 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1665, average loss: 0.6607
[09/26 09:23:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:23:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:23:12 visual_prompt]: Epoch 97 / 100: avg data time: 5.73e-02, avg batch time: 0.4998, average train loss: 0.0040
[09/26 09:23:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 0.6599
[09/26 09:23:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:23:14 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:23:20 visual_prompt]: Epoch 98 / 100: avg data time: 5.64e-02, avg batch time: 0.4982, average train loss: 0.0040
[09/26 09:23:22 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 0.6597
[09/26 09:23:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:23:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:23:29 visual_prompt]: Epoch 99 / 100: avg data time: 5.08e-02, avg batch time: 0.4937, average train loss: 0.0040
[09/26 09:23:30 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.6595
[09/26 09:23:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:23:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:23:37 visual_prompt]: Epoch 100 / 100: avg data time: 5.56e-02, avg batch time: 0.4986, average train loss: 0.0041
[09/26 09:23:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 0.6595
[09/26 09:23:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 09:23:39 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:23:39 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:23:39 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:23:39 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:23:39 visual_prompt]: Training with config:
[09/26 09:23:39 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr10.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:23:39 visual_prompt]: Loading training data...
[09/26 09:23:39 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:23:40 visual_prompt]: Number of images: 800
[09/26 09:23:40 visual_prompt]: Number of classes: 45 / 45
[09/26 09:23:40 visual_prompt]: Loading validation data...
[09/26 09:23:40 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:23:40 visual_prompt]: Number of images: 200
[09/26 09:23:40 visual_prompt]: Number of classes: 45 / 45
[09/26 09:23:40 visual_prompt]: Constructing models...
[09/26 09:23:43 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 09:23:43 visual_prompt]: tuned percent:0.574
[09/26 09:23:43 visual_prompt]: Device used for model: 0
[09/26 09:23:43 visual_prompt]: Setting up Evaluator...
[09/26 09:23:43 visual_prompt]: Setting up Trainer...
[09/26 09:23:43 visual_prompt]: 	Setting up the optimizer...
[09/26 09:23:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:23:50 visual_prompt]: Epoch 1 / 100: avg data time: 6.08e-02, avg batch time: 0.5013, average train loss: 3.8852
[09/26 09:23:51 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 09:23:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 09:23:51 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 09:23:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[09/26 09:23:58 visual_prompt]: Epoch 2 / 100: avg data time: 5.94e-02, avg batch time: 0.5007, average train loss: 3.9593
[09/26 09:23:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 3.8929
[09/26 09:23:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 17.00	
[09/26 09:23:59 visual_prompt]: Best epoch 2: best metric: 0.030
[09/26 09:23:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[09/26 09:24:06 visual_prompt]: Epoch 3 / 100: avg data time: 5.27e-02, avg batch time: 0.4950, average train loss: 4.0505
[09/26 09:24:08 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1660, average loss: 4.0432
[09/26 09:24:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 09:24:08 visual_prompt]: Best epoch 3: best metric: 0.035
[09/26 09:24:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[09/26 09:24:15 visual_prompt]: Epoch 4 / 100: avg data time: 5.65e-02, avg batch time: 0.4981, average train loss: 4.0730
[09/26 09:24:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1660, average loss: 3.7463
[09/26 09:24:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 35.50	
[09/26 09:24:16 visual_prompt]: Best epoch 4: best metric: 0.120
[09/26 09:24:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[09/26 09:24:23 visual_prompt]: Epoch 5 / 100: avg data time: 6.24e-02, avg batch time: 0.5042, average train loss: 4.0275
[09/26 09:24:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 5.0632
[09/26 09:24:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 30.50	
[09/26 09:24:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[09/26 09:24:31 visual_prompt]: Epoch 6 / 100: avg data time: 5.93e-02, avg batch time: 0.5010, average train loss: 3.6825
[09/26 09:24:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 4.7373
[09/26 09:24:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 22.50	
[09/26 09:24:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[09/26 09:24:40 visual_prompt]: Epoch 7 / 100: avg data time: 5.76e-02, avg batch time: 0.5001, average train loss: 5.4100
[09/26 09:24:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1661, average loss: 7.3610
[09/26 09:24:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 17.50	
[09/26 09:24:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[09/26 09:24:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.12e-02, avg batch time: 0.4938, average train loss: 9.3877
[09/26 09:24:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1662, average loss: 11.8107
[09/26 09:24:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 21.50	
[09/26 09:24:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[09/26 09:24:57 visual_prompt]: Epoch 9 / 100: avg data time: 5.45e-02, avg batch time: 0.4970, average train loss: 16.1995
[09/26 09:24:58 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1662, average loss: 21.8632
[09/26 09:24:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:24:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[09/26 09:25:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.88e-02, avg batch time: 0.4998, average train loss: 27.7878
[09/26 09:25:06 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1663, average loss: 28.3626
[09/26 09:25:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 11.50	
[09/26 09:25:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[09/26 09:25:13 visual_prompt]: Epoch 11 / 100: avg data time: 5.74e-02, avg batch time: 0.5012, average train loss: 41.0222
[09/26 09:25:15 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 41.7636
[09/26 09:25:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:25:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[09/26 09:25:22 visual_prompt]: Epoch 12 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 38.2079
[09/26 09:25:23 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 34.5749
[09/26 09:25:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 09:25:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[09/26 09:25:30 visual_prompt]: Epoch 13 / 100: avg data time: 5.69e-02, avg batch time: 0.4986, average train loss: 33.1737
[09/26 09:25:32 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 26.3314
[09/26 09:25:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 13.50	
[09/26 09:25:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[09/26 09:25:39 visual_prompt]: Epoch 14 / 100: avg data time: 5.96e-02, avg batch time: 0.5014, average train loss: 24.2861
[09/26 09:25:40 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 17.0382
[09/26 09:25:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 18.50	
[09/26 09:25:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[09/26 09:25:47 visual_prompt]: Epoch 15 / 100: avg data time: 6.14e-02, avg batch time: 0.5027, average train loss: 17.7927
[09/26 09:25:49 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1663, average loss: 15.4547
[09/26 09:25:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 24.50	
[09/26 09:25:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[09/26 09:25:55 visual_prompt]: Epoch 16 / 100: avg data time: 5.53e-02, avg batch time: 0.4993, average train loss: 14.4840
[09/26 09:25:57 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 14.0415
[09/26 09:25:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 22.00	
[09/26 09:25:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[09/26 09:26:04 visual_prompt]: Epoch 17 / 100: avg data time: 5.81e-02, avg batch time: 0.5006, average train loss: 9.2152
[09/26 09:26:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 5.7735
[09/26 09:26:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 36.50	
[09/26 09:26:05 visual_prompt]: Best epoch 17: best metric: 0.145
[09/26 09:26:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[09/26 09:26:12 visual_prompt]: Epoch 18 / 100: avg data time: 6.22e-02, avg batch time: 0.5046, average train loss: 6.0720
[09/26 09:26:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 5.7618
[09/26 09:26:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 39.50	
[09/26 09:26:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[09/26 09:26:20 visual_prompt]: Epoch 19 / 100: avg data time: 4.54e-02, avg batch time: 0.4879, average train loss: 5.1086
[09/26 09:26:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 4.5629
[09/26 09:26:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.00	top5: 39.50	
[09/26 09:26:22 visual_prompt]: Best epoch 19: best metric: 0.170
[09/26 09:26:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[09/26 09:26:29 visual_prompt]: Epoch 20 / 100: avg data time: 6.04e-02, avg batch time: 0.5020, average train loss: 4.5695
[09/26 09:26:30 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 4.6168
[09/26 09:26:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.00	top5: 50.50	
[09/26 09:26:30 visual_prompt]: Best epoch 20: best metric: 0.190
[09/26 09:26:30 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[09/26 09:26:37 visual_prompt]: Epoch 21 / 100: avg data time: 5.71e-02, avg batch time: 0.4988, average train loss: 3.2676
[09/26 09:26:39 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 2.9911
[09/26 09:26:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 59.00	
[09/26 09:26:39 visual_prompt]: Best epoch 21: best metric: 0.270
[09/26 09:26:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[09/26 09:26:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.09e-02, avg batch time: 0.4928, average train loss: 2.7367
[09/26 09:26:47 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 3.1808
[09/26 09:26:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 37.00	top5: 63.50	
[09/26 09:26:47 visual_prompt]: Best epoch 22: best metric: 0.370
[09/26 09:26:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[09/26 09:26:54 visual_prompt]: Epoch 23 / 100: avg data time: 6.19e-02, avg batch time: 0.5031, average train loss: 2.3867
[09/26 09:26:56 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 3.0586
[09/26 09:26:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 34.00	top5: 64.50	
[09/26 09:26:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[09/26 09:27:02 visual_prompt]: Epoch 24 / 100: avg data time: 5.48e-02, avg batch time: 0.4978, average train loss: 2.0352
[09/26 09:27:04 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1660, average loss: 3.0273
[09/26 09:27:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.00	top5: 66.00	
[09/26 09:27:04 visual_prompt]: Best epoch 24: best metric: 0.400
[09/26 09:27:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[09/26 09:27:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.63e-02, avg batch time: 0.4979, average train loss: 1.8618
[09/26 09:27:12 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 2.5413
[09/26 09:27:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 42.00	top5: 73.00	
[09/26 09:27:12 visual_prompt]: Best epoch 25: best metric: 0.420
[09/26 09:27:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[09/26 09:27:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.83e-02, avg batch time: 0.5013, average train loss: 1.5472
[09/26 09:27:21 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 2.2200
[09/26 09:27:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.00	top5: 76.50	
[09/26 09:27:21 visual_prompt]: Best epoch 26: best metric: 0.460
[09/26 09:27:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[09/26 09:27:27 visual_prompt]: Epoch 27 / 100: avg data time: 5.43e-02, avg batch time: 0.4963, average train loss: 1.6814
[09/26 09:27:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 1.9393
[09/26 09:27:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.50	top5: 79.50	
[09/26 09:27:29 visual_prompt]: Best epoch 27: best metric: 0.505
[09/26 09:27:29 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[09/26 09:27:36 visual_prompt]: Epoch 28 / 100: avg data time: 4.87e-02, avg batch time: 0.4922, average train loss: 1.4240
[09/26 09:27:37 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 1.7343
[09/26 09:27:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 51.50	top5: 83.50	
[09/26 09:27:37 visual_prompt]: Best epoch 28: best metric: 0.515
[09/26 09:27:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[09/26 09:27:44 visual_prompt]: Epoch 29 / 100: avg data time: 5.76e-02, avg batch time: 0.4992, average train loss: 1.2302
[09/26 09:27:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 1.5910
[09/26 09:27:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.50	top5: 87.00	
[09/26 09:27:46 visual_prompt]: Best epoch 29: best metric: 0.555
[09/26 09:27:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[09/26 09:27:52 visual_prompt]: Epoch 30 / 100: avg data time: 5.29e-02, avg batch time: 0.4947, average train loss: 1.0182
[09/26 09:27:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.6945
[09/26 09:27:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.00	top5: 87.00	
[09/26 09:27:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[09/26 09:28:01 visual_prompt]: Epoch 31 / 100: avg data time: 5.69e-02, avg batch time: 0.4995, average train loss: 0.9545
[09/26 09:28:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 1.6899
[09/26 09:28:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.00	top5: 88.50	
[09/26 09:28:02 visual_prompt]: Best epoch 31: best metric: 0.580
[09/26 09:28:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[09/26 09:28:09 visual_prompt]: Epoch 32 / 100: avg data time: 5.80e-02, avg batch time: 0.4998, average train loss: 0.7571
[09/26 09:28:11 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1661, average loss: 1.6866
[09/26 09:28:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.50	top5: 88.00	
[09/26 09:28:11 visual_prompt]: Best epoch 32: best metric: 0.625
[09/26 09:28:11 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[09/26 09:28:18 visual_prompt]: Epoch 33 / 100: avg data time: 6.09e-02, avg batch time: 0.5030, average train loss: 0.7247
[09/26 09:28:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.8206
[09/26 09:28:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.50	top5: 87.00	
[09/26 09:28:19 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[09/26 09:28:26 visual_prompt]: Epoch 34 / 100: avg data time: 5.16e-02, avg batch time: 0.4936, average train loss: 0.6100
[09/26 09:28:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 1.7030
[09/26 09:28:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 90.00	
[09/26 09:28:27 visual_prompt]: Best epoch 34: best metric: 0.650
[09/26 09:28:27 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[09/26 09:28:34 visual_prompt]: Epoch 35 / 100: avg data time: 5.76e-02, avg batch time: 0.4990, average train loss: 0.5423
[09/26 09:28:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 1.7618
[09/26 09:28:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.00	top5: 88.50	
[09/26 09:28:36 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[09/26 09:28:43 visual_prompt]: Epoch 36 / 100: avg data time: 6.48e-02, avg batch time: 0.5075, average train loss: 0.4750
[09/26 09:28:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 1.3241
[09/26 09:28:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 91.00	
[09/26 09:28:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[09/26 09:28:51 visual_prompt]: Epoch 37 / 100: avg data time: 5.75e-02, avg batch time: 0.4987, average train loss: 0.3850
[09/26 09:28:53 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1662, average loss: 1.2859
[09/26 09:28:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.00	
[09/26 09:28:53 visual_prompt]: Best epoch 37: best metric: 0.685
[09/26 09:28:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[09/26 09:29:00 visual_prompt]: Epoch 38 / 100: avg data time: 6.15e-02, avg batch time: 0.5040, average train loss: 0.3549
[09/26 09:29:01 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 1.4250
[09/26 09:29:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 93.50	
[09/26 09:29:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[09/26 09:29:08 visual_prompt]: Epoch 39 / 100: avg data time: 5.62e-02, avg batch time: 0.4976, average train loss: 0.3428
[09/26 09:29:10 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1658, average loss: 1.3656
[09/26 09:29:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.50	
[09/26 09:29:10 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[09/26 09:29:16 visual_prompt]: Epoch 40 / 100: avg data time: 5.39e-02, avg batch time: 0.4964, average train loss: 0.2772
[09/26 09:29:18 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1663, average loss: 1.2101
[09/26 09:29:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 94.00	
[09/26 09:29:18 visual_prompt]: Best epoch 40: best metric: 0.695
[09/26 09:29:18 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[09/26 09:29:25 visual_prompt]: Epoch 41 / 100: avg data time: 4.94e-02, avg batch time: 0.4917, average train loss: 0.2454
[09/26 09:29:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 1.2315
[09/26 09:29:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 09:29:26 visual_prompt]: Best epoch 41: best metric: 0.700
[09/26 09:29:26 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[09/26 09:29:33 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e-02, avg batch time: 0.4893, average train loss: 0.2117
[09/26 09:29:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 1.7168
[09/26 09:29:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.00	
[09/26 09:29:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[09/26 09:29:41 visual_prompt]: Epoch 43 / 100: avg data time: 4.47e-02, avg batch time: 0.4863, average train loss: 0.2190
[09/26 09:29:43 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 1.1419
[09/26 09:29:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 09:29:43 visual_prompt]: Best epoch 43: best metric: 0.710
[09/26 09:29:43 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[09/26 09:29:50 visual_prompt]: Epoch 44 / 100: avg data time: 6.33e-02, avg batch time: 0.5055, average train loss: 0.1460
[09/26 09:29:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.3326
[09/26 09:29:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 92.50	
[09/26 09:29:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[09/26 09:29:58 visual_prompt]: Epoch 45 / 100: avg data time: 6.26e-02, avg batch time: 0.5041, average train loss: 0.1325
[09/26 09:30:00 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.4564
[09/26 09:30:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 93.00	
[09/26 09:30:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[09/26 09:30:07 visual_prompt]: Epoch 46 / 100: avg data time: 6.72e-02, avg batch time: 0.5082, average train loss: 0.1201
[09/26 09:30:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.1668
[09/26 09:30:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.50	
[09/26 09:30:08 visual_prompt]: Best epoch 46: best metric: 0.735
[09/26 09:30:08 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[09/26 09:30:15 visual_prompt]: Epoch 47 / 100: avg data time: 6.09e-02, avg batch time: 0.5028, average train loss: 0.1064
[09/26 09:30:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1656, average loss: 1.3851
[09/26 09:30:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.50	
[09/26 09:30:17 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[09/26 09:30:24 visual_prompt]: Epoch 48 / 100: avg data time: 5.37e-02, avg batch time: 0.4964, average train loss: 0.0895
[09/26 09:30:25 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.3966
[09/26 09:30:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.00	
[09/26 09:30:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[09/26 09:30:32 visual_prompt]: Epoch 49 / 100: avg data time: 4.92e-02, avg batch time: 0.4927, average train loss: 0.0878
[09/26 09:30:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 1.2971
[09/26 09:30:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.00	
[09/26 09:30:33 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[09/26 09:30:40 visual_prompt]: Epoch 50 / 100: avg data time: 5.88e-02, avg batch time: 0.5012, average train loss: 0.0843
[09/26 09:30:42 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.2894
[09/26 09:30:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 09:30:42 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[09/26 09:30:49 visual_prompt]: Epoch 51 / 100: avg data time: 5.70e-02, avg batch time: 0.4988, average train loss: 0.0751
[09/26 09:30:50 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1665, average loss: 1.2799
[09/26 09:30:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 09:30:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[09/26 09:30:57 visual_prompt]: Epoch 52 / 100: avg data time: 5.54e-02, avg batch time: 0.4972, average train loss: 0.0629
[09/26 09:30:59 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1663, average loss: 1.4308
[09/26 09:30:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 09:30:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[09/26 09:31:05 visual_prompt]: Epoch 53 / 100: avg data time: 5.66e-02, avg batch time: 0.4994, average train loss: 0.0573
[09/26 09:31:07 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.1824
[09/26 09:31:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 09:31:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[09/26 09:31:14 visual_prompt]: Epoch 54 / 100: avg data time: 5.50e-02, avg batch time: 0.4980, average train loss: 0.0452
[09/26 09:31:15 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.4334
[09/26 09:31:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 09:31:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[09/26 09:31:22 visual_prompt]: Epoch 55 / 100: avg data time: 4.46e-02, avg batch time: 0.4889, average train loss: 0.0506
[09/26 09:31:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 1.6158
[09/26 09:31:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 09:31:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[09/26 09:31:30 visual_prompt]: Epoch 56 / 100: avg data time: 5.92e-02, avg batch time: 0.5007, average train loss: 0.0665
[09/26 09:31:32 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1664, average loss: 1.3999
[09/26 09:31:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 09:31:32 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[09/26 09:31:39 visual_prompt]: Epoch 57 / 100: avg data time: 5.50e-02, avg batch time: 0.4971, average train loss: 0.0649
[09/26 09:31:40 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1664, average loss: 1.3245
[09/26 09:31:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 09:31:40 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[09/26 09:31:47 visual_prompt]: Epoch 58 / 100: avg data time: 5.85e-02, avg batch time: 0.5008, average train loss: 0.0539
[09/26 09:31:49 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.2938
[09/26 09:31:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 09:31:49 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[09/26 09:31:55 visual_prompt]: Epoch 59 / 100: avg data time: 4.51e-02, avg batch time: 0.4868, average train loss: 0.0446
[09/26 09:31:57 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 1.3714
[09/26 09:31:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.00	
[09/26 09:31:57 visual_prompt]: Training 60 / 100 epoch, with learning rate 4.3041344951996745
[09/26 09:32:04 visual_prompt]: Epoch 60 / 100: avg data time: 5.70e-02, avg batch time: 0.4983, average train loss: 0.0313
[09/26 09:32:05 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1658, average loss: 1.5657
[09/26 09:32:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 09:32:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 4.131759111665349
[09/26 09:32:12 visual_prompt]: Epoch 61 / 100: avg data time: 6.79e-02, avg batch time: 0.5102, average train loss: 0.0492
[09/26 09:32:14 visual_prompt]: Inference (val):avg data time: 4.24e-05, avg batch time: 0.1663, average loss: 1.3467
[09/26 09:32:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 09:32:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 3.960441545911204
[09/26 09:32:21 visual_prompt]: Epoch 62 / 100: avg data time: 5.83e-02, avg batch time: 0.5016, average train loss: 0.0899
[09/26 09:32:22 visual_prompt]: Inference (val):avg data time: 4.66e-05, avg batch time: 0.1664, average loss: 1.4191
[09/26 09:32:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.50	
[09/26 09:32:22 visual_prompt]: Training 63 / 100 epoch, with learning rate 3.790390522001662
[09/26 09:32:29 visual_prompt]: Epoch 63 / 100: avg data time: 6.15e-02, avg batch time: 0.5038, average train loss: 0.0492
[09/26 09:32:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 1.3293
[09/26 09:32:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 09:32:31 visual_prompt]: Training 64 / 100 epoch, with learning rate 3.6218132209150045
[09/26 09:32:38 visual_prompt]: Epoch 64 / 100: avg data time: 5.89e-02, avg batch time: 0.5015, average train loss: 0.0397
[09/26 09:32:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1664, average loss: 1.3438
[09/26 09:32:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.50	
[09/26 09:32:39 visual_prompt]: Training 65 / 100 epoch, with learning rate 3.454915028125263
[09/26 09:32:46 visual_prompt]: Epoch 65 / 100: avg data time: 6.14e-02, avg batch time: 0.5044, average train loss: 0.0286
[09/26 09:32:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 1.4342
[09/26 09:32:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.00	
[09/26 09:32:48 visual_prompt]: Training 66 / 100 epoch, with learning rate 3.289899283371657
[09/26 09:32:54 visual_prompt]: Epoch 66 / 100: avg data time: 5.67e-02, avg batch time: 0.4998, average train loss: 0.0237
[09/26 09:32:56 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.3163
[09/26 09:32:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 09:32:56 visual_prompt]: Best epoch 66: best metric: 0.745
[09/26 09:32:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 3.1269670329204398
[09/26 09:33:03 visual_prompt]: Epoch 67 / 100: avg data time: 4.65e-02, avg batch time: 0.4911, average train loss: 0.0262
[09/26 09:33:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.2930
[09/26 09:33:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 09:33:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 2.9663167846209997
[09/26 09:33:11 visual_prompt]: Epoch 68 / 100: avg data time: 5.85e-02, avg batch time: 0.5000, average train loss: 0.0243
[09/26 09:33:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.3311
[09/26 09:33:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:33:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 2.8081442660546125
[09/26 09:33:20 visual_prompt]: Epoch 69 / 100: avg data time: 6.09e-02, avg batch time: 0.5029, average train loss: 0.0197
[09/26 09:33:21 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1662, average loss: 1.4628
[09/26 09:33:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 93.00	
[09/26 09:33:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 2.6526421860705476
[09/26 09:33:28 visual_prompt]: Epoch 70 / 100: avg data time: 6.17e-02, avg batch time: 0.5036, average train loss: 0.0177
[09/26 09:33:30 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1660, average loss: 1.4475
[09/26 09:33:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 93.50	
[09/26 09:33:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 2.500000000000001
[09/26 09:33:36 visual_prompt]: Epoch 71 / 100: avg data time: 5.85e-02, avg batch time: 0.5002, average train loss: 0.0192
[09/26 09:33:38 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1666, average loss: 1.4227
[09/26 09:33:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 09:33:38 visual_prompt]: Training 72 / 100 epoch, with learning rate 2.350403678833976
[09/26 09:33:45 visual_prompt]: Epoch 72 / 100: avg data time: 5.71e-02, avg batch time: 0.4990, average train loss: 0.0198
[09/26 09:33:46 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1663, average loss: 1.4077
[09/26 09:33:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 09:33:46 visual_prompt]: Training 73 / 100 epoch, with learning rate 2.2040354826462667
[09/26 09:33:53 visual_prompt]: Epoch 73 / 100: avg data time: 5.58e-02, avg batch time: 0.4982, average train loss: 0.0143
[09/26 09:33:55 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.4092
[09/26 09:33:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.00	
[09/26 09:33:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 2.061073738537635
[09/26 09:34:02 visual_prompt]: Epoch 74 / 100: avg data time: 6.26e-02, avg batch time: 0.5058, average train loss: 0.0162
[09/26 09:34:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.3806
[09/26 09:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 09:34:03 visual_prompt]: Training 75 / 100 epoch, with learning rate 1.9216926233717087
[09/26 09:34:10 visual_prompt]: Epoch 75 / 100: avg data time: 6.17e-02, avg batch time: 0.5038, average train loss: 0.0191
[09/26 09:34:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 1.5490
[09/26 09:34:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 09:34:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 1.7860619515673033
[09/26 09:34:18 visual_prompt]: Epoch 76 / 100: avg data time: 5.24e-02, avg batch time: 0.4950, average train loss: 0.0155
[09/26 09:34:20 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 1.5021
[09/26 09:34:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 93.50	
[09/26 09:34:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 1.6543469682057106
[09/26 09:34:27 visual_prompt]: Epoch 77 / 100: avg data time: 5.95e-02, avg batch time: 0.5013, average train loss: 0.0237
[09/26 09:34:29 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.4271
[09/26 09:34:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 09:34:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 1.5267081477050133
[09/26 09:34:35 visual_prompt]: Epoch 78 / 100: avg data time: 6.66e-02, avg batch time: 0.5077, average train loss: 0.0114
[09/26 09:34:37 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1662, average loss: 1.4288
[09/26 09:34:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 09:34:37 visual_prompt]: Training 79 / 100 epoch, with learning rate 1.403300998306745
[09/26 09:34:44 visual_prompt]: Epoch 79 / 100: avg data time: 5.96e-02, avg batch time: 0.5015, average train loss: 0.0118
[09/26 09:34:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.4532
[09/26 09:34:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:34:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 1.2842758726130281
[09/26 09:34:52 visual_prompt]: Epoch 80 / 100: avg data time: 5.27e-02, avg batch time: 0.4944, average train loss: 0.0160
[09/26 09:34:54 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.4542
[09/26 09:34:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 09:34:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 1.1697777844051105
[09/26 09:35:01 visual_prompt]: Epoch 81 / 100: avg data time: 6.03e-02, avg batch time: 0.5029, average train loss: 0.0119
[09/26 09:35:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.4509
[09/26 09:35:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 09:35:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 1.0599462319663906
[09/26 09:35:09 visual_prompt]: Epoch 82 / 100: avg data time: 5.69e-02, avg batch time: 0.4994, average train loss: 0.0115
[09/26 09:35:11 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.4593
[09/26 09:35:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 09:35:11 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.9549150281252633
[09/26 09:35:17 visual_prompt]: Epoch 83 / 100: avg data time: 5.73e-02, avg batch time: 0.4990, average train loss: 0.0119
[09/26 09:35:19 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 1.4701
[09/26 09:35:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:35:19 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.8548121372247919
[09/26 09:35:26 visual_prompt]: Epoch 84 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 0.0138
[09/26 09:35:27 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.4812
[09/26 09:35:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.00	
[09/26 09:35:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.7597595192178702
[09/26 09:35:34 visual_prompt]: Epoch 85 / 100: avg data time: 5.10e-02, avg batch time: 0.4938, average train loss: 0.0099
[09/26 09:35:36 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.4802
[09/26 09:35:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:35:36 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.6698729810778065
[09/26 09:35:42 visual_prompt]: Epoch 86 / 100: avg data time: 5.87e-02, avg batch time: 0.5000, average train loss: 0.0114
[09/26 09:35:44 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 1.4722
[09/26 09:35:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:35:44 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.5852620357053651
[09/26 09:35:51 visual_prompt]: Epoch 87 / 100: avg data time: 6.04e-02, avg batch time: 0.5028, average train loss: 0.0099
[09/26 09:35:52 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1663, average loss: 1.4702
[09/26 09:35:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:35:52 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.5060297685041659
[09/26 09:35:59 visual_prompt]: Epoch 88 / 100: avg data time: 5.72e-02, avg batch time: 0.5018, average train loss: 0.0098
[09/26 09:36:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.4711
[09/26 09:36:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 09:36:01 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.4322727117869951
[09/26 09:36:08 visual_prompt]: Epoch 89 / 100: avg data time: 5.65e-02, avg batch time: 0.4979, average train loss: 0.0143
[09/26 09:36:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.4643
[09/26 09:36:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.36408072716606343
[09/26 09:36:16 visual_prompt]: Epoch 90 / 100: avg data time: 5.85e-02, avg batch time: 0.5009, average train loss: 0.0098
[09/26 09:36:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.4550
[09/26 09:36:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.3015368960704584
[09/26 09:36:24 visual_prompt]: Epoch 91 / 100: avg data time: 6.53e-02, avg batch time: 0.5085, average train loss: 0.0129
[09/26 09:36:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.4396
[09/26 09:36:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.24471741852423234
[09/26 09:36:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.69e-02, avg batch time: 0.4984, average train loss: 0.0127
[09/26 09:36:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.4405
[09/26 09:36:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:34 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.19369152030840553
[09/26 09:36:41 visual_prompt]: Epoch 93 / 100: avg data time: 5.78e-02, avg batch time: 0.4989, average train loss: 0.0122
[09/26 09:36:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 1.4437
[09/26 09:36:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.14852136862001764
[09/26 09:36:49 visual_prompt]: Epoch 94 / 100: avg data time: 5.08e-02, avg batch time: 0.4928, average train loss: 0.0121
[09/26 09:36:51 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 1.4470
[09/26 09:36:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.10926199633097156
[09/26 09:36:58 visual_prompt]: Epoch 95 / 100: avg data time: 5.66e-02, avg batch time: 0.5004, average train loss: 0.0126
[09/26 09:36:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 1.4509
[09/26 09:36:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:36:59 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0759612349389599
[09/26 09:37:06 visual_prompt]: Epoch 96 / 100: avg data time: 6.01e-02, avg batch time: 0.5015, average train loss: 0.0130
[09/26 09:37:08 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.4542
[09/26 09:37:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:37:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.04865965629214819
[09/26 09:37:15 visual_prompt]: Epoch 97 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 0.0101
[09/26 09:37:16 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1660, average loss: 1.4549
[09/26 09:37:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:37:16 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.02739052315863355
[09/26 09:37:23 visual_prompt]: Epoch 98 / 100: avg data time: 5.71e-02, avg batch time: 0.4980, average train loss: 0.0107
[09/26 09:37:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.4554
[09/26 09:37:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:37:24 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.012179748700879012
[09/26 09:37:31 visual_prompt]: Epoch 99 / 100: avg data time: 5.57e-02, avg batch time: 0.4971, average train loss: 0.0109
[09/26 09:37:33 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1661, average loss: 1.4548
[09/26 09:37:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:37:33 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0030458649045211894
[09/26 09:37:40 visual_prompt]: Epoch 100 / 100: avg data time: 5.79e-02, avg batch time: 0.4996, average train loss: 0.0111
[09/26 09:37:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 1.4548
[09/26 09:37:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 09:37:41 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:37:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:37:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:37:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:37:41 visual_prompt]: Training with config:
[09/26 09:37:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:37:41 visual_prompt]: Loading training data...
[09/26 09:37:41 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:37:42 visual_prompt]: Number of images: 800
[09/26 09:37:42 visual_prompt]: Number of classes: 45 / 45
[09/26 09:37:42 visual_prompt]: Loading validation data...
[09/26 09:37:42 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:37:43 visual_prompt]: Number of images: 200
[09/26 09:37:43 visual_prompt]: Number of classes: 45 / 45
[09/26 09:37:43 visual_prompt]: Constructing models...
[09/26 09:37:45 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 09:37:45 visual_prompt]: tuned percent:0.574
[09/26 09:37:45 visual_prompt]: Device used for model: 0
[09/26 09:37:45 visual_prompt]: Setting up Evaluator...
[09/26 09:37:45 visual_prompt]: Setting up Trainer...
[09/26 09:37:45 visual_prompt]: 	Setting up the optimizer...
[09/26 09:37:45 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:37:52 visual_prompt]: Epoch 1 / 100: avg data time: 5.74e-02, avg batch time: 0.4992, average train loss: 3.9031
[09/26 09:37:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 09:37:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 09:37:54 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 09:37:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 09:38:00 visual_prompt]: Epoch 2 / 100: avg data time: 6.40e-02, avg batch time: 0.5044, average train loss: 3.8700
[09/26 09:38:02 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1655, average loss: 3.7500
[09/26 09:38:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 19.00	
[09/26 09:38:02 visual_prompt]: Best epoch 2: best metric: 0.075
[09/26 09:38:02 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 09:38:09 visual_prompt]: Epoch 3 / 100: avg data time: 5.53e-02, avg batch time: 0.4962, average train loss: 3.8425
[09/26 09:38:10 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1653, average loss: 3.8561
[09/26 09:38:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 09:38:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 09:38:17 visual_prompt]: Epoch 4 / 100: avg data time: 6.29e-02, avg batch time: 0.5031, average train loss: 3.8906
[09/26 09:38:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1655, average loss: 3.9747
[09/26 09:38:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 09:38:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 09:38:26 visual_prompt]: Epoch 5 / 100: avg data time: 5.14e-02, avg batch time: 0.4925, average train loss: 3.9821
[09/26 09:38:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1655, average loss: 4.1410
[09/26 09:38:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.50	
[09/26 09:38:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 09:38:34 visual_prompt]: Epoch 6 / 100: avg data time: 5.59e-02, avg batch time: 0.4959, average train loss: 3.9665
[09/26 09:38:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1657, average loss: 3.9450
[09/26 09:38:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 09:38:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 09:38:42 visual_prompt]: Epoch 7 / 100: avg data time: 5.87e-02, avg batch time: 0.5009, average train loss: 4.1991
[09/26 09:38:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1654, average loss: 4.1242
[09/26 09:38:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 09:38:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 09:38:51 visual_prompt]: Epoch 8 / 100: avg data time: 5.84e-02, avg batch time: 0.4984, average train loss: 4.1061
[09/26 09:38:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1656, average loss: 4.0824
[09/26 09:38:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 15.00	
[09/26 09:38:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 09:38:59 visual_prompt]: Epoch 9 / 100: avg data time: 5.92e-02, avg batch time: 0.4999, average train loss: 4.2718
[09/26 09:39:01 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 4.4639
[09/26 09:39:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:39:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 09:39:07 visual_prompt]: Epoch 10 / 100: avg data time: 5.69e-02, avg batch time: 0.4977, average train loss: 4.2491
[09/26 09:39:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 4.2064
[09/26 09:39:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 09:39:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 09:39:16 visual_prompt]: Epoch 11 / 100: avg data time: 5.65e-02, avg batch time: 0.4977, average train loss: 4.2542
[09/26 09:39:17 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 5.1558
[09/26 09:39:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:39:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 09:39:24 visual_prompt]: Epoch 12 / 100: avg data time: 6.43e-02, avg batch time: 0.5065, average train loss: 6.2384
[09/26 09:39:26 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1657, average loss: 5.0394
[09/26 09:39:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:39:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 09:39:33 visual_prompt]: Epoch 13 / 100: avg data time: 6.23e-02, avg batch time: 0.5024, average train loss: 8.0355
[09/26 09:39:34 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1657, average loss: 6.2888
[09/26 09:39:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 09:39:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 09:39:41 visual_prompt]: Epoch 14 / 100: avg data time: 5.32e-02, avg batch time: 0.4935, average train loss: 10.8905
[09/26 09:39:43 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1658, average loss: 8.9417
[09/26 09:39:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 09:39:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 09:39:49 visual_prompt]: Epoch 15 / 100: avg data time: 4.74e-02, avg batch time: 0.4887, average train loss: 8.6170
[09/26 09:39:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 6.3145
[09/26 09:39:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:39:51 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 09:39:58 visual_prompt]: Epoch 16 / 100: avg data time: 6.02e-02, avg batch time: 0.5017, average train loss: 10.2272
[09/26 09:39:59 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 7.6628
[09/26 09:39:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 09:39:59 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 09:40:06 visual_prompt]: Epoch 17 / 100: avg data time: 5.85e-02, avg batch time: 0.5000, average train loss: 9.0093
[09/26 09:40:08 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1660, average loss: 6.6484
[09/26 09:40:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 09:40:08 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 09:40:14 visual_prompt]: Epoch 18 / 100: avg data time: 5.84e-02, avg batch time: 0.4993, average train loss: 7.2289
[09/26 09:40:16 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 5.6196
[09/26 09:40:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 09:40:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 09:40:23 visual_prompt]: Epoch 19 / 100: avg data time: 6.31e-02, avg batch time: 0.5049, average train loss: 7.0830
[09/26 09:40:24 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1655, average loss: 6.8551
[09/26 09:40:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 09:40:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 09:40:31 visual_prompt]: Epoch 20 / 100: avg data time: 5.33e-02, avg batch time: 0.4941, average train loss: 6.8584
[09/26 09:40:33 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 5.8143
[09/26 09:40:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.00	
[09/26 09:40:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 09:40:40 visual_prompt]: Epoch 21 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 7.3576
[09/26 09:40:41 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 28.4954
[09/26 09:40:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:40:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 09:40:48 visual_prompt]: Epoch 22 / 100: avg data time: 6.06e-02, avg batch time: 0.5008, average train loss: 9.1139
[09/26 09:40:50 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 6.0127
[09/26 09:40:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 09:40:50 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 09:40:57 visual_prompt]: Epoch 23 / 100: avg data time: 6.30e-02, avg batch time: 0.5047, average train loss: 7.6391
[09/26 09:40:58 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1658, average loss: 8.4101
[09/26 09:40:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.50	
[09/26 09:40:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 09:41:05 visual_prompt]: Epoch 24 / 100: avg data time: 6.11e-02, avg batch time: 0.5019, average train loss: 8.7760
[09/26 09:41:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1658, average loss: 6.3171
[09/26 09:41:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 09:41:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 09:41:13 visual_prompt]: Epoch 25 / 100: avg data time: 5.52e-02, avg batch time: 0.4967, average train loss: 6.5147
[09/26 09:41:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1658, average loss: 7.0686
[09/26 09:41:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.00	
[09/26 09:41:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 09:41:22 visual_prompt]: Epoch 26 / 100: avg data time: 5.32e-02, avg batch time: 0.4947, average train loss: 5.7465
[09/26 09:41:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1658, average loss: 5.5323
[09/26 09:41:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.50	
[09/26 09:41:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 09:41:30 visual_prompt]: Epoch 27 / 100: avg data time: 5.45e-02, avg batch time: 0.4952, average train loss: 5.5601
[09/26 09:41:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1660, average loss: 5.5529
[09/26 09:41:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 09:41:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 09:41:38 visual_prompt]: Epoch 28 / 100: avg data time: 6.39e-02, avg batch time: 0.5041, average train loss: 5.8316
[09/26 09:41:40 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1658, average loss: 5.1135
[09/26 09:41:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:41:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 09:41:47 visual_prompt]: Epoch 29 / 100: avg data time: 5.72e-02, avg batch time: 0.4984, average train loss: 5.8946
[09/26 09:41:48 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1660, average loss: 6.3064
[09/26 09:41:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:41:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 09:41:55 visual_prompt]: Epoch 30 / 100: avg data time: 6.54e-02, avg batch time: 0.5056, average train loss: 5.5213
[09/26 09:41:57 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1661, average loss: 4.7375
[09/26 09:41:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.00	
[09/26 09:41:57 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 09:42:04 visual_prompt]: Epoch 31 / 100: avg data time: 6.22e-02, avg batch time: 0.5035, average train loss: 5.3356
[09/26 09:42:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1661, average loss: 5.6509
[09/26 09:42:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 09:42:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 09:42:12 visual_prompt]: Epoch 32 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 5.2897
[09/26 09:42:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1658, average loss: 4.5160
[09/26 09:42:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 09:42:14 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 09:42:21 visual_prompt]: Epoch 33 / 100: avg data time: 5.79e-02, avg batch time: 0.4990, average train loss: 5.0563
[09/26 09:42:22 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1657, average loss: 4.4629
[09/26 09:42:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 09:42:22 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 09:42:29 visual_prompt]: Epoch 34 / 100: avg data time: 5.81e-02, avg batch time: 0.4978, average train loss: 4.7872
[09/26 09:42:31 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 5.6989
[09/26 09:42:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:42:31 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 09:42:37 visual_prompt]: Epoch 35 / 100: avg data time: 5.83e-02, avg batch time: 0.4989, average train loss: 5.9089
[09/26 09:42:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1659, average loss: 4.8436
[09/26 09:42:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 11.00	
[09/26 09:42:39 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 09:42:46 visual_prompt]: Epoch 36 / 100: avg data time: 6.44e-02, avg batch time: 0.5059, average train loss: 6.1510
[09/26 09:42:47 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 6.1817
[09/26 09:42:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 09:42:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 09:42:54 visual_prompt]: Epoch 37 / 100: avg data time: 5.62e-02, avg batch time: 0.4979, average train loss: 6.7326
[09/26 09:42:56 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1659, average loss: 5.6719
[09/26 09:42:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:42:56 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 09:43:03 visual_prompt]: Epoch 38 / 100: avg data time: 5.12e-02, avg batch time: 0.4925, average train loss: 8.8394
[09/26 09:43:04 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1657, average loss: 7.0446
[09/26 09:43:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:43:04 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 09:43:11 visual_prompt]: Epoch 39 / 100: avg data time: 6.38e-02, avg batch time: 0.5057, average train loss: 8.1438
[09/26 09:43:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 6.6619
[09/26 09:43:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 09:43:13 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 09:43:19 visual_prompt]: Epoch 40 / 100: avg data time: 5.71e-02, avg batch time: 0.4987, average train loss: 7.6514
[09/26 09:43:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 6.7219
[09/26 09:43:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.00	
[09/26 09:43:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 09:43:28 visual_prompt]: Epoch 41 / 100: avg data time: 6.47e-02, avg batch time: 0.5063, average train loss: 6.5804
[09/26 09:43:30 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1661, average loss: 4.9628
[09/26 09:43:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 09:43:30 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 09:43:36 visual_prompt]: Epoch 42 / 100: avg data time: 5.88e-02, avg batch time: 0.4993, average train loss: 5.3102
[09/26 09:43:38 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1661, average loss: 4.4082
[09/26 09:43:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:43:38 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 09:43:45 visual_prompt]: Epoch 43 / 100: avg data time: 6.04e-02, avg batch time: 0.5010, average train loss: 4.5619
[09/26 09:43:46 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1661, average loss: 5.0386
[09/26 09:43:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 09:43:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 09:43:53 visual_prompt]: Epoch 44 / 100: avg data time: 5.57e-02, avg batch time: 0.4974, average train loss: 4.4397
[09/26 09:43:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 4.4333
[09/26 09:43:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 09:43:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 09:44:01 visual_prompt]: Epoch 45 / 100: avg data time: 5.29e-02, avg batch time: 0.4954, average train loss: 4.3577
[09/26 09:44:03 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 4.2663
[09/26 09:44:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 09:44:03 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 09:44:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.87e-02, avg batch time: 0.4993, average train loss: 4.2421
[09/26 09:44:11 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 4.0200
[09/26 09:44:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 11.00	
[09/26 09:44:11 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 09:44:18 visual_prompt]: Epoch 47 / 100: avg data time: 5.53e-02, avg batch time: 0.4975, average train loss: 4.7389
[09/26 09:44:20 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1659, average loss: 4.5769
[09/26 09:44:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 09:44:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 09:44:26 visual_prompt]: Epoch 48 / 100: avg data time: 5.72e-02, avg batch time: 0.4985, average train loss: 4.6976
[09/26 09:44:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 4.2243
[09/26 09:44:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 09:44:28 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 09:44:35 visual_prompt]: Epoch 49 / 100: avg data time: 5.83e-02, avg batch time: 0.4993, average train loss: 4.4304
[09/26 09:44:36 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1659, average loss: 4.7468
[09/26 09:44:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 09:44:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 09:44:43 visual_prompt]: Epoch 50 / 100: avg data time: 6.72e-02, avg batch time: 0.5082, average train loss: 4.4626
[09/26 09:44:45 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1670, average loss: 4.1560
[09/26 09:44:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 09:44:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 09:44:52 visual_prompt]: Epoch 51 / 100: avg data time: 5.69e-02, avg batch time: 0.4994, average train loss: 4.0518
[09/26 09:44:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 3.8969
[09/26 09:44:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 15.50	
[09/26 09:44:53 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 09:45:00 visual_prompt]: Epoch 52 / 100: avg data time: 5.69e-02, avg batch time: 0.4996, average train loss: 4.0557
[09/26 09:45:02 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 3.9231
[09/26 09:45:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.00	
[09/26 09:45:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 09:45:09 visual_prompt]: Epoch 53 / 100: avg data time: 6.18e-02, avg batch time: 0.5038, average train loss: 3.9716
[09/26 09:45:10 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1659, average loss: 3.9280
[09/26 09:45:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:45:10 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 09:45:17 visual_prompt]: Epoch 54 / 100: avg data time: 5.95e-02, avg batch time: 0.5005, average train loss: 4.0757
[09/26 09:45:19 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 4.4816
[09/26 09:45:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:45:19 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 09:45:25 visual_prompt]: Epoch 55 / 100: avg data time: 5.64e-02, avg batch time: 0.4976, average train loss: 4.2633
[09/26 09:45:27 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1661, average loss: 3.9888
[09/26 09:45:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 09:45:27 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 09:45:34 visual_prompt]: Epoch 56 / 100: avg data time: 5.65e-02, avg batch time: 0.4982, average train loss: 4.0211
[09/26 09:45:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1659, average loss: 4.1922
[09/26 09:45:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 09:45:35 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 09:45:42 visual_prompt]: Epoch 57 / 100: avg data time: 6.01e-02, avg batch time: 0.5006, average train loss: 3.9570
[09/26 09:45:44 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1658, average loss: 4.0806
[09/26 09:45:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:45:44 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 09:45:51 visual_prompt]: Epoch 58 / 100: avg data time: 6.20e-02, avg batch time: 0.5030, average train loss: 4.0568
[09/26 09:45:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 3.9706
[09/26 09:45:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 09:45:52 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 09:45:59 visual_prompt]: Epoch 59 / 100: avg data time: 6.26e-02, avg batch time: 0.5042, average train loss: 4.2159
[09/26 09:46:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 4.1293
[09/26 09:46:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:46:01 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 09:46:08 visual_prompt]: Epoch 60 / 100: avg data time: 6.22e-02, avg batch time: 0.5026, average train loss: 4.1541
[09/26 09:46:09 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1661, average loss: 3.9754
[09/26 09:46:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 09:46:09 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 09:46:16 visual_prompt]: Epoch 61 / 100: avg data time: 6.18e-02, avg batch time: 0.5039, average train loss: 3.9887
[09/26 09:46:18 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1654, average loss: 4.0963
[09/26 09:46:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:46:18 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 09:46:24 visual_prompt]: Epoch 62 / 100: avg data time: 4.84e-02, avg batch time: 0.4921, average train loss: 4.0464
[09/26 09:46:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 3.9956
[09/26 09:46:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 09:46:26 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 09:46:33 visual_prompt]: Epoch 63 / 100: avg data time: 5.72e-02, avg batch time: 0.4989, average train loss: 3.9993
[09/26 09:46:34 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1658, average loss: 4.0132
[09/26 09:46:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.00	
[09/26 09:46:34 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 09:46:41 visual_prompt]: Epoch 64 / 100: avg data time: 5.13e-02, avg batch time: 0.4918, average train loss: 3.9129
[09/26 09:46:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 3.8657
[09/26 09:46:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:46:43 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 09:46:49 visual_prompt]: Epoch 65 / 100: avg data time: 5.90e-02, avg batch time: 0.5003, average train loss: 3.9287
[09/26 09:46:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 3.8328
[09/26 09:46:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 15.00	
[09/26 09:46:51 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 09:46:58 visual_prompt]: Epoch 66 / 100: avg data time: 6.68e-02, avg batch time: 0.5073, average train loss: 3.9249
[09/26 09:46:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1656, average loss: 4.2345
[09/26 09:46:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:46:59 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 09:47:06 visual_prompt]: Epoch 67 / 100: avg data time: 6.05e-02, avg batch time: 0.5010, average train loss: 4.0596
[09/26 09:47:08 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1657, average loss: 3.9692
[09/26 09:47:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:47:08 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 09:47:15 visual_prompt]: Epoch 68 / 100: avg data time: 6.26e-02, avg batch time: 0.5048, average train loss: 3.9235
[09/26 09:47:16 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1659, average loss: 3.9039
[09/26 09:47:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 09:47:16 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 09:47:23 visual_prompt]: Epoch 69 / 100: avg data time: 4.85e-02, avg batch time: 0.4894, average train loss: 3.9165
[09/26 09:47:24 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 3.9199
[09/26 09:47:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 09:47:24 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 09:47:31 visual_prompt]: Epoch 70 / 100: avg data time: 6.33e-02, avg batch time: 0.5052, average train loss: 3.9159
[09/26 09:47:33 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1660, average loss: 4.0063
[09/26 09:47:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 09:47:33 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 09:47:40 visual_prompt]: Epoch 71 / 100: avg data time: 5.77e-02, avg batch time: 0.4989, average train loss: 3.9463
[09/26 09:47:41 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1657, average loss: 3.9159
[09/26 09:47:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.50	
[09/26 09:47:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 09:47:48 visual_prompt]: Epoch 72 / 100: avg data time: 5.81e-02, avg batch time: 0.5006, average train loss: 3.9118
[09/26 09:47:49 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1656, average loss: 3.9012
[09/26 09:47:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 09:47:49 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 09:47:56 visual_prompt]: Epoch 73 / 100: avg data time: 5.63e-02, avg batch time: 0.4978, average train loss: 3.8893
[09/26 09:47:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1657, average loss: 3.8936
[09/26 09:47:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 09:47:58 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 09:48:05 visual_prompt]: Epoch 74 / 100: avg data time: 5.56e-02, avg batch time: 0.4971, average train loss: 3.8703
[09/26 09:48:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 3.8317
[09/26 09:48:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 09:48:06 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 09:48:13 visual_prompt]: Epoch 75 / 100: avg data time: 5.84e-02, avg batch time: 0.4990, average train loss: 3.8580
[09/26 09:48:15 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 3.8743
[09/26 09:48:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:48:15 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 09:48:22 visual_prompt]: Epoch 76 / 100: avg data time: 6.85e-02, avg batch time: 0.5088, average train loss: 3.9311
[09/26 09:48:23 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 3.8953
[09/26 09:48:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 09:48:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 09:48:30 visual_prompt]: Epoch 77 / 100: avg data time: 4.84e-02, avg batch time: 0.4897, average train loss: 3.8668
[09/26 09:48:31 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 4.1381
[09/26 09:48:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:48:31 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 09:48:38 visual_prompt]: Epoch 78 / 100: avg data time: 6.10e-02, avg batch time: 0.5016, average train loss: 3.9160
[09/26 09:48:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 3.8694
[09/26 09:48:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 09:48:40 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 09:48:47 visual_prompt]: Epoch 79 / 100: avg data time: 6.20e-02, avg batch time: 0.5040, average train loss: 3.8553
[09/26 09:48:48 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1661, average loss: 3.8426
[09/26 09:48:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 14.00	
[09/26 09:48:48 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 09:48:55 visual_prompt]: Epoch 80 / 100: avg data time: 6.06e-02, avg batch time: 0.5026, average train loss: 3.8431
[09/26 09:48:57 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 3.8466
[09/26 09:48:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 09:48:57 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 09:49:03 visual_prompt]: Epoch 81 / 100: avg data time: 6.58e-02, avg batch time: 0.5070, average train loss: 3.8183
[09/26 09:49:05 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 3.8359
[09/26 09:49:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.50	
[09/26 09:49:05 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 09:49:12 visual_prompt]: Epoch 82 / 100: avg data time: 6.43e-02, avg batch time: 0.5044, average train loss: 3.8357
[09/26 09:49:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 3.8433
[09/26 09:49:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 09:49:14 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 09:49:20 visual_prompt]: Epoch 83 / 100: avg data time: 5.57e-02, avg batch time: 0.4972, average train loss: 3.8251
[09/26 09:49:22 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 3.8398
[09/26 09:49:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:49:22 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 09:49:29 visual_prompt]: Epoch 84 / 100: avg data time: 5.61e-02, avg batch time: 0.4982, average train loss: 3.8180
[09/26 09:49:30 visual_prompt]: Inference (val):avg data time: 4.39e-05, avg batch time: 0.1658, average loss: 3.8407
[09/26 09:49:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 09:49:30 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 09:49:37 visual_prompt]: Epoch 85 / 100: avg data time: 5.72e-02, avg batch time: 0.4978, average train loss: 3.8162
[09/26 09:49:39 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 3.8422
[09/26 09:49:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 09:49:39 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 09:49:45 visual_prompt]: Epoch 86 / 100: avg data time: 5.20e-02, avg batch time: 0.4950, average train loss: 3.8143
[09/26 09:49:47 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1659, average loss: 3.8449
[09/26 09:49:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 09:49:47 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 09:49:54 visual_prompt]: Epoch 87 / 100: avg data time: 5.77e-02, avg batch time: 0.5006, average train loss: 3.8071
[09/26 09:49:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1658, average loss: 3.8311
[09/26 09:49:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 09:49:55 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 09:50:02 visual_prompt]: Epoch 88 / 100: avg data time: 5.93e-02, avg batch time: 0.4999, average train loss: 3.8007
[09/26 09:50:04 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 3.8222
[09/26 09:50:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 09:50:04 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 09:50:11 visual_prompt]: Epoch 89 / 100: avg data time: 5.52e-02, avg batch time: 0.4975, average train loss: 3.7747
[09/26 09:50:12 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1661, average loss: 3.8223
[09/26 09:50:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 09:50:12 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 09:50:19 visual_prompt]: Epoch 90 / 100: avg data time: 5.71e-02, avg batch time: 0.4987, average train loss: 3.7738
[09/26 09:50:21 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1660, average loss: 3.8123
[09/26 09:50:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 09:50:21 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 09:50:27 visual_prompt]: Epoch 91 / 100: avg data time: 5.31e-02, avg batch time: 0.4960, average train loss: 3.7483
[09/26 09:50:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 3.7638
[09/26 09:50:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 16.50	
[09/26 09:50:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 09:50:36 visual_prompt]: Epoch 92 / 100: avg data time: 6.22e-02, avg batch time: 0.5029, average train loss: 3.7618
[09/26 09:50:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1657, average loss: 3.8264
[09/26 09:50:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 09:50:37 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 09:50:44 visual_prompt]: Epoch 93 / 100: avg data time: 6.25e-02, avg batch time: 0.5042, average train loss: 3.7844
[09/26 09:50:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 3.8063
[09/26 09:50:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.00	
[09/26 09:50:46 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 09:50:53 visual_prompt]: Epoch 94 / 100: avg data time: 6.04e-02, avg batch time: 0.5017, average train loss: 3.7327
[09/26 09:50:54 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 3.7443
[09/26 09:50:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.00	
[09/26 09:50:54 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 09:51:01 visual_prompt]: Epoch 95 / 100: avg data time: 6.00e-02, avg batch time: 0.5009, average train loss: 3.6601
[09/26 09:51:03 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 3.6459
[09/26 09:51:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 20.50	
[09/26 09:51:03 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 09:51:10 visual_prompt]: Epoch 96 / 100: avg data time: 5.97e-02, avg batch time: 0.5003, average train loss: 3.5511
[09/26 09:51:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 3.6865
[09/26 09:51:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 19.00	
[09/26 09:51:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 09:51:18 visual_prompt]: Epoch 97 / 100: avg data time: 5.95e-02, avg batch time: 0.5010, average train loss: 3.4844
[09/26 09:51:20 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1660, average loss: 3.5012
[09/26 09:51:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 26.00	
[09/26 09:51:20 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 09:51:27 visual_prompt]: Epoch 98 / 100: avg data time: 5.65e-02, avg batch time: 0.5007, average train loss: 3.3973
[09/26 09:51:28 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 3.4871
[09/26 09:51:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 28.50	
[09/26 09:51:28 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 09:51:35 visual_prompt]: Epoch 99 / 100: avg data time: 5.97e-02, avg batch time: 0.5006, average train loss: 3.3646
[09/26 09:51:37 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1656, average loss: 3.4598
[09/26 09:51:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 28.00	
[09/26 09:51:37 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 09:51:43 visual_prompt]: Epoch 100 / 100: avg data time: 5.80e-02, avg batch time: 0.4987, average train loss: 3.3574
[09/26 09:51:45 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1661, average loss: 3.4806
[09/26 09:51:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 29.50	
[09/26 09:51:45 visual_prompt]: Best epoch 100: best metric: 0.090
[09/26 09:51:45 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 09:51:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 09:51:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 09:51:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 09:51:45 visual_prompt]: Training with config:
[09/26 09:51:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 09:51:45 visual_prompt]: Loading training data...
[09/26 09:51:45 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:51:46 visual_prompt]: Number of images: 800
[09/26 09:51:46 visual_prompt]: Number of classes: 45 / 45
[09/26 09:51:46 visual_prompt]: Loading validation data...
[09/26 09:51:46 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 09:51:47 visual_prompt]: Number of images: 200
[09/26 09:51:47 visual_prompt]: Number of classes: 45 / 45
[09/26 09:51:47 visual_prompt]: Constructing models...
[09/26 09:51:49 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 09:51:49 visual_prompt]: tuned percent:0.574
[09/26 09:51:49 visual_prompt]: Device used for model: 0
[09/26 09:51:49 visual_prompt]: Setting up Evaluator...
[09/26 09:51:49 visual_prompt]: Setting up Trainer...
[09/26 09:51:49 visual_prompt]: 	Setting up the optimizer...
[09/26 09:51:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 09:51:56 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e-02, avg batch time: 0.4935, average train loss: 3.8901
[09/26 09:51:57 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 09:51:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 09:51:57 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 09:51:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 09:52:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.58e-02, avg batch time: 0.4967, average train loss: 3.8499
[09/26 09:52:06 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 3.7710
[09/26 09:52:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 17.50	
[09/26 09:52:06 visual_prompt]: Best epoch 2: best metric: 0.055
[09/26 09:52:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 09:52:12 visual_prompt]: Epoch 3 / 100: avg data time: 5.50e-02, avg batch time: 0.4964, average train loss: 3.6701
[09/26 09:52:14 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1660, average loss: 3.5133
[09/26 09:52:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 27.50	
[09/26 09:52:14 visual_prompt]: Best epoch 3: best metric: 0.095
[09/26 09:52:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 09:52:21 visual_prompt]: Epoch 4 / 100: avg data time: 6.17e-02, avg batch time: 0.5027, average train loss: 3.8116
[09/26 09:52:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 3.6199
[09/26 09:52:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 28.00	
[09/26 09:52:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 09:52:29 visual_prompt]: Epoch 5 / 100: avg data time: 5.52e-02, avg batch time: 0.4971, average train loss: 3.7301
[09/26 09:52:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 3.5975
[09/26 09:52:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 26.00	
[09/26 09:52:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 09:52:38 visual_prompt]: Epoch 6 / 100: avg data time: 5.90e-02, avg batch time: 0.5027, average train loss: 3.8276
[09/26 09:52:39 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 3.9754
[09/26 09:52:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 23.00	
[09/26 09:52:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 09:52:46 visual_prompt]: Epoch 7 / 100: avg data time: 4.88e-02, avg batch time: 0.4920, average train loss: 4.0041
[09/26 09:52:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 4.5981
[09/26 09:52:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 13.00	
[09/26 09:52:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 09:52:54 visual_prompt]: Epoch 8 / 100: avg data time: 5.33e-02, avg batch time: 0.4962, average train loss: 4.3188
[09/26 09:52:56 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1660, average loss: 3.9724
[09/26 09:52:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.00	
[09/26 09:52:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 09:53:03 visual_prompt]: Epoch 9 / 100: avg data time: 5.82e-02, avg batch time: 0.4999, average train loss: 4.1183
[09/26 09:53:04 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 4.5715
[09/26 09:53:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:53:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 09:53:11 visual_prompt]: Epoch 10 / 100: avg data time: 5.35e-02, avg batch time: 0.4947, average train loss: 4.1161
[09/26 09:53:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 4.1993
[09/26 09:53:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 16.50	
[09/26 09:53:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 09:53:19 visual_prompt]: Epoch 11 / 100: avg data time: 6.14e-02, avg batch time: 0.5038, average train loss: 4.1721
[09/26 09:53:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 4.0753
[09/26 09:53:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 10.50	
[09/26 09:53:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 09:53:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.38e-02, avg batch time: 0.4952, average train loss: 4.1271
[09/26 09:53:29 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 4.2027
[09/26 09:53:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 15.00	
[09/26 09:53:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 09:53:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.94e-02, avg batch time: 0.5008, average train loss: 4.0727
[09/26 09:53:38 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 4.0679
[09/26 09:53:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 09:53:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 09:53:45 visual_prompt]: Epoch 14 / 100: avg data time: 4.60e-02, avg batch time: 0.4869, average train loss: 3.9458
[09/26 09:53:46 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 3.8349
[09/26 09:53:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.50	
[09/26 09:53:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 09:53:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.75e-02, avg batch time: 0.4995, average train loss: 4.2456
[09/26 09:53:55 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1659, average loss: 4.6002
[09/26 09:53:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 09:53:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 09:54:01 visual_prompt]: Epoch 16 / 100: avg data time: 6.28e-02, avg batch time: 0.5046, average train loss: 5.0687
[09/26 09:54:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 5.6726
[09/26 09:54:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 09:54:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 09:54:10 visual_prompt]: Epoch 17 / 100: avg data time: 6.40e-02, avg batch time: 0.5055, average train loss: 6.9932
[09/26 09:54:12 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1662, average loss: 7.3046
[09/26 09:54:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.00	
[09/26 09:54:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 09:54:18 visual_prompt]: Epoch 18 / 100: avg data time: 5.70e-02, avg batch time: 0.4992, average train loss: 8.4473
[09/26 09:54:20 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 7.4253
[09/26 09:54:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 9.50	
[09/26 09:54:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 09:54:27 visual_prompt]: Epoch 19 / 100: avg data time: 5.67e-02, avg batch time: 0.4992, average train loss: 6.6099
[09/26 09:54:28 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 7.8827
[09/26 09:54:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 09:54:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 09:54:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.34e-02, avg batch time: 0.4939, average train loss: 9.8932
[09/26 09:54:37 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1665, average loss: 8.9811
[09/26 09:54:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 09:54:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 09:54:44 visual_prompt]: Epoch 21 / 100: avg data time: 6.45e-02, avg batch time: 0.5059, average train loss: 7.6853
[09/26 09:54:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 6.8997
[09/26 09:54:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 09:54:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 09:54:52 visual_prompt]: Epoch 22 / 100: avg data time: 5.77e-02, avg batch time: 0.5002, average train loss: 6.1218
[09/26 09:54:54 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1663, average loss: 5.4580
[09/26 09:54:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 09:54:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 09:55:01 visual_prompt]: Epoch 23 / 100: avg data time: 6.03e-02, avg batch time: 0.5016, average train loss: 5.1232
[09/26 09:55:02 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1661, average loss: 4.4164
[09/26 09:55:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 09:55:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 09:55:09 visual_prompt]: Epoch 24 / 100: avg data time: 5.98e-02, avg batch time: 0.5011, average train loss: 4.7506
[09/26 09:55:11 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1660, average loss: 4.6603
[09/26 09:55:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 09:55:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 09:55:18 visual_prompt]: Epoch 25 / 100: avg data time: 6.05e-02, avg batch time: 0.5015, average train loss: 4.5529
[09/26 09:55:19 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1661, average loss: 4.8752
[09/26 09:55:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 09:55:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 09:55:26 visual_prompt]: Epoch 26 / 100: avg data time: 5.98e-02, avg batch time: 0.5003, average train loss: 4.4629
[09/26 09:55:28 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 4.3078
[09/26 09:55:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 09:55:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 09:55:34 visual_prompt]: Epoch 27 / 100: avg data time: 5.81e-02, avg batch time: 0.4987, average train loss: 4.2844
[09/26 09:55:36 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 4.3043
[09/26 09:55:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 09:55:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 09:55:43 visual_prompt]: Epoch 28 / 100: avg data time: 5.87e-02, avg batch time: 0.5007, average train loss: 4.2191
[09/26 09:55:45 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 5.1617
[09/26 09:55:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:55:45 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 09:55:51 visual_prompt]: Epoch 29 / 100: avg data time: 5.82e-02, avg batch time: 0.4994, average train loss: 4.3703
[09/26 09:55:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1659, average loss: 4.5060
[09/26 09:55:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.00	
[09/26 09:55:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 09:56:00 visual_prompt]: Epoch 30 / 100: avg data time: 5.53e-02, avg batch time: 0.4970, average train loss: 4.3351
[09/26 09:56:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 4.3471
[09/26 09:56:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 09:56:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 09:56:08 visual_prompt]: Epoch 31 / 100: avg data time: 6.04e-02, avg batch time: 0.5010, average train loss: 4.2618
[09/26 09:56:10 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1660, average loss: 4.0046
[09/26 09:56:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 09:56:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 09:56:17 visual_prompt]: Epoch 32 / 100: avg data time: 6.00e-02, avg batch time: 0.5020, average train loss: 4.1061
[09/26 09:56:18 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1674, average loss: 4.2237
[09/26 09:56:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 11.50	
[09/26 09:56:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 09:56:25 visual_prompt]: Epoch 33 / 100: avg data time: 6.81e-02, avg batch time: 0.5105, average train loss: 4.0727
[09/26 09:56:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 4.0330
[09/26 09:56:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 09:56:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 09:56:34 visual_prompt]: Epoch 34 / 100: avg data time: 6.71e-02, avg batch time: 0.5082, average train loss: 4.0562
[09/26 09:56:35 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1660, average loss: 3.9097
[09/26 09:56:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 12.50	
[09/26 09:56:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 09:56:42 visual_prompt]: Epoch 35 / 100: avg data time: 6.25e-02, avg batch time: 0.5026, average train loss: 4.0381
[09/26 09:56:44 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1656, average loss: 4.1118
[09/26 09:56:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:56:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 09:56:51 visual_prompt]: Epoch 36 / 100: avg data time: 5.42e-02, avg batch time: 0.4954, average train loss: 4.0532
[09/26 09:56:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1658, average loss: 3.9507
[09/26 09:56:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.50	
[09/26 09:56:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 09:56:59 visual_prompt]: Epoch 37 / 100: avg data time: 6.84e-02, avg batch time: 0.5085, average train loss: 4.0240
[09/26 09:57:01 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1656, average loss: 4.0498
[09/26 09:57:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 09:57:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 09:57:08 visual_prompt]: Epoch 38 / 100: avg data time: 6.33e-02, avg batch time: 0.5066, average train loss: 4.0984
[09/26 09:57:10 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1660, average loss: 4.1357
[09/26 09:57:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 13.00	
[09/26 09:57:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 09:57:16 visual_prompt]: Epoch 39 / 100: avg data time: 7.05e-02, avg batch time: 0.5117, average train loss: 4.1745
[09/26 09:57:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1669, average loss: 4.1964
[09/26 09:57:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 09:57:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 09:57:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.66e-02, avg batch time: 0.4903, average train loss: 4.0994
[09/26 09:57:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 4.0492
[09/26 09:57:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 09:57:26 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 09:57:33 visual_prompt]: Epoch 41 / 100: avg data time: 6.55e-02, avg batch time: 0.5066, average train loss: 4.0469
[09/26 09:57:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1661, average loss: 3.9925
[09/26 09:57:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 09:57:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 09:57:42 visual_prompt]: Epoch 42 / 100: avg data time: 6.19e-02, avg batch time: 0.5041, average train loss: 4.0074
[09/26 09:57:43 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 4.0187
[09/26 09:57:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 14.50	
[09/26 09:57:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 09:57:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.04e-02, avg batch time: 0.4940, average train loss: 4.0330
[09/26 09:57:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 3.9155
[09/26 09:57:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 15.50	
[09/26 09:57:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 09:57:59 visual_prompt]: Epoch 44 / 100: avg data time: 5.90e-02, avg batch time: 0.5021, average train loss: 3.9966
[09/26 09:58:00 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 3.9489
[09/26 09:58:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 12.50	
[09/26 09:58:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 09:58:07 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e-02, avg batch time: 0.4902, average train loss: 3.9879
[09/26 09:58:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 3.8773
[09/26 09:58:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 17.00	
[09/26 09:58:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 09:58:15 visual_prompt]: Epoch 46 / 100: avg data time: 5.59e-02, avg batch time: 0.4970, average train loss: 4.0456
[09/26 09:58:17 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1657, average loss: 4.0052
[09/26 09:58:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 09:58:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 09:58:24 visual_prompt]: Epoch 47 / 100: avg data time: 7.04e-02, avg batch time: 0.5109, average train loss: 3.9696
[09/26 09:58:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1659, average loss: 4.2256
[09/26 09:58:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 09:58:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 09:58:32 visual_prompt]: Epoch 48 / 100: avg data time: 5.67e-02, avg batch time: 0.4970, average train loss: 3.9795
[09/26 09:58:34 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 4.0102
[09/26 09:58:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 17.50	
[09/26 09:58:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 09:58:40 visual_prompt]: Epoch 49 / 100: avg data time: 6.00e-02, avg batch time: 0.5029, average train loss: 3.9093
[09/26 09:58:42 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1655, average loss: 3.7397
[09/26 09:58:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 20.00	
[09/26 09:58:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 09:58:49 visual_prompt]: Epoch 50 / 100: avg data time: 5.26e-02, avg batch time: 0.4938, average train loss: 3.8783
[09/26 09:58:50 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 4.0301
[09/26 09:58:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.50	
[09/26 09:58:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 09:58:57 visual_prompt]: Epoch 51 / 100: avg data time: 4.99e-02, avg batch time: 0.4926, average train loss: 4.0088
[09/26 09:58:59 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 3.9252
[09/26 09:58:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 09:58:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 09:59:06 visual_prompt]: Epoch 52 / 100: avg data time: 6.01e-02, avg batch time: 0.5009, average train loss: 3.9796
[09/26 09:59:07 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1651, average loss: 4.1259
[09/26 09:59:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 09:59:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 09:59:14 visual_prompt]: Epoch 53 / 100: avg data time: 4.77e-02, avg batch time: 0.4881, average train loss: 3.9582
[09/26 09:59:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1658, average loss: 4.0740
[09/26 09:59:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.00	
[09/26 09:59:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 09:59:22 visual_prompt]: Epoch 54 / 100: avg data time: 6.18e-02, avg batch time: 0.5017, average train loss: 3.9487
[09/26 09:59:24 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1659, average loss: 3.9244
[09/26 09:59:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 09:59:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 09:59:31 visual_prompt]: Epoch 55 / 100: avg data time: 6.18e-02, avg batch time: 0.5045, average train loss: 3.9120
[09/26 09:59:32 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1660, average loss: 3.8674
[09/26 09:59:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 18.50	
[09/26 09:59:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 09:59:39 visual_prompt]: Epoch 56 / 100: avg data time: 5.41e-02, avg batch time: 0.4965, average train loss: 3.8495
[09/26 09:59:41 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1659, average loss: 3.8909
[09/26 09:59:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 09:59:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 09:59:48 visual_prompt]: Epoch 57 / 100: avg data time: 6.32e-02, avg batch time: 0.5039, average train loss: 3.8849
[09/26 09:59:49 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 3.6770
[09/26 09:59:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 17.50	
[09/26 09:59:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 09:59:56 visual_prompt]: Epoch 58 / 100: avg data time: 5.89e-02, avg batch time: 0.4998, average train loss: 3.7891
[09/26 09:59:58 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 3.6422
[09/26 09:59:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 23.00	
[09/26 09:59:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:00:04 visual_prompt]: Epoch 59 / 100: avg data time: 4.83e-02, avg batch time: 0.4898, average train loss: 3.6897
[09/26 10:00:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 3.7176
[09/26 10:00:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 16.00	
[09/26 10:00:06 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:00:13 visual_prompt]: Epoch 60 / 100: avg data time: 6.19e-02, avg batch time: 0.5031, average train loss: 3.6548
[09/26 10:00:14 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1660, average loss: 3.6349
[09/26 10:00:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 18.00	
[09/26 10:00:14 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:00:21 visual_prompt]: Epoch 61 / 100: avg data time: 5.71e-02, avg batch time: 0.4988, average train loss: 3.7180
[09/26 10:00:23 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1658, average loss: 3.5880
[09/26 10:00:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 20.00	
[09/26 10:00:23 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:00:30 visual_prompt]: Epoch 62 / 100: avg data time: 6.78e-02, avg batch time: 0.5081, average train loss: 4.0025
[09/26 10:00:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1658, average loss: 3.8798
[09/26 10:00:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 10:00:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:00:38 visual_prompt]: Epoch 63 / 100: avg data time: 5.68e-02, avg batch time: 0.4975, average train loss: 3.9478
[09/26 10:00:40 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1656, average loss: 3.9932
[09/26 10:00:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 10.50	
[09/26 10:00:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:00:46 visual_prompt]: Epoch 64 / 100: avg data time: 5.90e-02, avg batch time: 0.5017, average train loss: 3.9221
[09/26 10:00:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1660, average loss: 3.9544
[09/26 10:00:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.50	
[09/26 10:00:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:00:55 visual_prompt]: Epoch 65 / 100: avg data time: 6.12e-02, avg batch time: 0.5031, average train loss: 3.9976
[09/26 10:00:56 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1659, average loss: 3.8672
[09/26 10:00:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 14.50	
[09/26 10:00:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:01:03 visual_prompt]: Epoch 66 / 100: avg data time: 5.98e-02, avg batch time: 0.5004, average train loss: 3.9669
[09/26 10:01:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1657, average loss: 3.9384
[09/26 10:01:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 17.00	
[09/26 10:01:05 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:01:12 visual_prompt]: Epoch 67 / 100: avg data time: 6.04e-02, avg batch time: 0.5011, average train loss: 3.8836
[09/26 10:01:13 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1658, average loss: 3.6756
[09/26 10:01:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 20.00	
[09/26 10:01:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:01:20 visual_prompt]: Epoch 68 / 100: avg data time: 5.83e-02, avg batch time: 0.5005, average train loss: 3.6679
[09/26 10:01:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 3.9331
[09/26 10:01:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 18.00	
[09/26 10:01:22 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:01:29 visual_prompt]: Epoch 69 / 100: avg data time: 6.23e-02, avg batch time: 0.5029, average train loss: 3.6626
[09/26 10:01:30 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1658, average loss: 3.6975
[09/26 10:01:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 20.50	
[09/26 10:01:30 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:01:37 visual_prompt]: Epoch 70 / 100: avg data time: 6.52e-02, avg batch time: 0.5054, average train loss: 3.6554
[09/26 10:01:39 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1658, average loss: 3.6908
[09/26 10:01:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 22.00	
[09/26 10:01:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:01:46 visual_prompt]: Epoch 71 / 100: avg data time: 6.25e-02, avg batch time: 0.5048, average train loss: 3.5853
[09/26 10:01:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 3.5241
[09/26 10:01:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 25.00	
[09/26 10:01:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:01:54 visual_prompt]: Epoch 72 / 100: avg data time: 6.95e-02, avg batch time: 0.5105, average train loss: 3.5413
[09/26 10:01:56 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 3.3896
[09/26 10:01:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 30.50	
[09/26 10:01:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:02:03 visual_prompt]: Epoch 73 / 100: avg data time: 6.40e-02, avg batch time: 0.5057, average train loss: 3.4151
[09/26 10:02:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 3.6156
[09/26 10:02:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 24.50	
[09/26 10:02:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:02:11 visual_prompt]: Epoch 74 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 3.4040
[09/26 10:02:13 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 3.4996
[09/26 10:02:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 26.50	
[09/26 10:02:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:02:19 visual_prompt]: Epoch 75 / 100: avg data time: 5.82e-02, avg batch time: 0.5000, average train loss: 3.4341
[09/26 10:02:21 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1659, average loss: 3.3105
[09/26 10:02:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 35.00	
[09/26 10:02:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:02:28 visual_prompt]: Epoch 76 / 100: avg data time: 4.85e-02, avg batch time: 0.4898, average train loss: 3.3409
[09/26 10:02:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 3.4373
[09/26 10:02:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 28.50	
[09/26 10:02:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:02:36 visual_prompt]: Epoch 77 / 100: avg data time: 6.59e-02, avg batch time: 0.5064, average train loss: 3.2761
[09/26 10:02:38 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1658, average loss: 3.1444
[09/26 10:02:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 43.50	
[09/26 10:02:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:02:44 visual_prompt]: Epoch 78 / 100: avg data time: 4.59e-02, avg batch time: 0.4887, average train loss: 3.0744
[09/26 10:02:46 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1660, average loss: 3.0355
[09/26 10:02:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 46.00	
[09/26 10:02:46 visual_prompt]: Best epoch 78: best metric: 0.125
[09/26 10:02:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:02:53 visual_prompt]: Epoch 79 / 100: avg data time: 5.92e-02, avg batch time: 0.5007, average train loss: 3.0386
[09/26 10:02:54 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 3.0647
[09/26 10:02:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 41.00	
[09/26 10:02:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:03:01 visual_prompt]: Epoch 80 / 100: avg data time: 5.86e-02, avg batch time: 0.4991, average train loss: 2.8863
[09/26 10:03:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1656, average loss: 2.8342
[09/26 10:03:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 56.00	
[09/26 10:03:03 visual_prompt]: Best epoch 80: best metric: 0.195
[09/26 10:03:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:03:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.31e-02, avg batch time: 0.4943, average train loss: 2.7449
[09/26 10:03:11 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1658, average loss: 2.7809
[09/26 10:03:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 53.50	
[09/26 10:03:11 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:03:18 visual_prompt]: Epoch 82 / 100: avg data time: 6.09e-02, avg batch time: 0.5024, average train loss: 2.4802
[09/26 10:03:19 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 2.9192
[09/26 10:03:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 57.00	
[09/26 10:03:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:03:26 visual_prompt]: Epoch 83 / 100: avg data time: 6.62e-02, avg batch time: 0.5083, average train loss: 2.2052
[09/26 10:03:28 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 2.4125
[09/26 10:03:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 69.00	
[09/26 10:03:28 visual_prompt]: Best epoch 83: best metric: 0.255
[09/26 10:03:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:03:35 visual_prompt]: Epoch 84 / 100: avg data time: 5.99e-02, avg batch time: 0.5004, average train loss: 1.8299
[09/26 10:03:36 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1658, average loss: 2.2827
[09/26 10:03:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 34.50	top5: 70.50	
[09/26 10:03:36 visual_prompt]: Best epoch 84: best metric: 0.345
[09/26 10:03:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:03:43 visual_prompt]: Epoch 85 / 100: avg data time: 6.20e-02, avg batch time: 0.5030, average train loss: 1.5832
[09/26 10:03:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 1.7611
[09/26 10:03:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 48.50	top5: 81.50	
[09/26 10:03:45 visual_prompt]: Best epoch 85: best metric: 0.485
[09/26 10:03:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:03:52 visual_prompt]: Epoch 86 / 100: avg data time: 5.67e-02, avg batch time: 0.4972, average train loss: 1.2602
[09/26 10:03:53 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 1.6569
[09/26 10:03:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.50	top5: 84.50	
[09/26 10:03:53 visual_prompt]: Best epoch 86: best metric: 0.535
[09/26 10:03:53 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:04:00 visual_prompt]: Epoch 87 / 100: avg data time: 6.32e-02, avg batch time: 0.5047, average train loss: 0.9343
[09/26 10:04:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1658, average loss: 1.4914
[09/26 10:04:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.50	top5: 87.50	
[09/26 10:04:02 visual_prompt]: Best epoch 87: best metric: 0.565
[09/26 10:04:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:04:09 visual_prompt]: Epoch 88 / 100: avg data time: 6.25e-02, avg batch time: 0.5041, average train loss: 0.7217
[09/26 10:04:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 1.4379
[09/26 10:04:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.00	top5: 88.50	
[09/26 10:04:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:04:17 visual_prompt]: Epoch 89 / 100: avg data time: 6.02e-02, avg batch time: 0.5026, average train loss: 0.5259
[09/26 10:04:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1657, average loss: 1.3059
[09/26 10:04:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 59.00	top5: 89.50	
[09/26 10:04:18 visual_prompt]: Best epoch 89: best metric: 0.590
[09/26 10:04:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:04:25 visual_prompt]: Epoch 90 / 100: avg data time: 4.63e-02, avg batch time: 0.4890, average train loss: 0.3837
[09/26 10:04:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 1.3071
[09/26 10:04:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.50	top5: 89.00	
[09/26 10:04:27 visual_prompt]: Best epoch 90: best metric: 0.625
[09/26 10:04:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:04:33 visual_prompt]: Epoch 91 / 100: avg data time: 6.29e-02, avg batch time: 0.5035, average train loss: 0.2828
[09/26 10:04:35 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.3189
[09/26 10:04:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.50	top5: 89.50	
[09/26 10:04:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:04:42 visual_prompt]: Epoch 92 / 100: avg data time: 5.83e-02, avg batch time: 0.5002, average train loss: 0.2163
[09/26 10:04:43 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 1.2864
[09/26 10:04:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 89.50	
[09/26 10:04:43 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:04:50 visual_prompt]: Epoch 93 / 100: avg data time: 5.67e-02, avg batch time: 0.4985, average train loss: 0.1667
[09/26 10:04:52 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 1.2676
[09/26 10:04:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 89.00	
[09/26 10:04:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:04:59 visual_prompt]: Epoch 94 / 100: avg data time: 5.70e-02, avg batch time: 0.4997, average train loss: 0.1340
[09/26 10:05:00 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1660, average loss: 1.2529
[09/26 10:05:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 89.00	
[09/26 10:05:00 visual_prompt]: Best epoch 94: best metric: 0.630
[09/26 10:05:00 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:05:07 visual_prompt]: Epoch 95 / 100: avg data time: 5.93e-02, avg batch time: 0.5006, average train loss: 0.1173
[09/26 10:05:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 1.2659
[09/26 10:05:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 88.50	
[09/26 10:05:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:05:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.96e-02, avg batch time: 0.5007, average train loss: 0.1058
[09/26 10:05:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 1.2611
[09/26 10:05:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 88.00	
[09/26 10:05:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:05:24 visual_prompt]: Epoch 97 / 100: avg data time: 4.55e-02, avg batch time: 0.4893, average train loss: 0.1031
[09/26 10:05:26 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1662, average loss: 1.2698
[09/26 10:05:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 89.50	
[09/26 10:05:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:05:32 visual_prompt]: Epoch 98 / 100: avg data time: 5.46e-02, avg batch time: 0.4957, average train loss: 0.1010
[09/26 10:05:34 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1661, average loss: 1.2679
[09/26 10:05:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 89.50	
[09/26 10:05:34 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:05:41 visual_prompt]: Epoch 99 / 100: avg data time: 5.40e-02, avg batch time: 0.4959, average train loss: 0.0982
[09/26 10:05:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 1.2642
[09/26 10:05:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 89.00	
[09/26 10:05:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:05:49 visual_prompt]: Epoch 100 / 100: avg data time: 5.76e-02, avg batch time: 0.4986, average train loss: 0.0936
[09/26 10:05:51 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1660, average loss: 1.2641
[09/26 10:05:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 89.00	
[09/26 10:05:51 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:05:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:05:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:05:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:05:51 visual_prompt]: Training with config:
[09/26 10:05:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:05:51 visual_prompt]: Loading training data...
[09/26 10:05:51 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:05:52 visual_prompt]: Number of images: 800
[09/26 10:05:52 visual_prompt]: Number of classes: 45 / 45
[09/26 10:05:52 visual_prompt]: Loading validation data...
[09/26 10:05:52 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:05:52 visual_prompt]: Number of images: 200
[09/26 10:05:52 visual_prompt]: Number of classes: 45 / 45
[09/26 10:05:52 visual_prompt]: Constructing models...
[09/26 10:05:55 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 10:05:55 visual_prompt]: tuned percent:0.574
[09/26 10:05:55 visual_prompt]: Device used for model: 0
[09/26 10:05:55 visual_prompt]: Setting up Evaluator...
[09/26 10:05:55 visual_prompt]: Setting up Trainer...
[09/26 10:05:55 visual_prompt]: 	Setting up the optimizer...
[09/26 10:05:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:06:01 visual_prompt]: Epoch 1 / 100: avg data time: 5.75e-02, avg batch time: 0.4979, average train loss: 3.8921
[09/26 10:06:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 10:06:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 10:06:03 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 10:06:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:06:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.79e-02, avg batch time: 0.4987, average train loss: 3.8726
[09/26 10:06:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 3.7774
[09/26 10:06:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 18.00	
[09/26 10:06:11 visual_prompt]: Best epoch 2: best metric: 0.095
[09/26 10:06:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:06:18 visual_prompt]: Epoch 3 / 100: avg data time: 5.77e-02, avg batch time: 0.4988, average train loss: 3.8264
[09/26 10:06:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 3.7797
[09/26 10:06:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 24.00	
[09/26 10:06:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:06:27 visual_prompt]: Epoch 4 / 100: avg data time: 6.59e-02, avg batch time: 0.5066, average train loss: 3.8128
[09/26 10:06:28 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 3.9441
[09/26 10:06:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 21.50	
[09/26 10:06:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:06:35 visual_prompt]: Epoch 5 / 100: avg data time: 5.66e-02, avg batch time: 0.4972, average train loss: 4.0321
[09/26 10:06:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1659, average loss: 3.7705
[09/26 10:06:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 28.00	
[09/26 10:06:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:06:43 visual_prompt]: Epoch 6 / 100: avg data time: 5.78e-02, avg batch time: 0.4996, average train loss: 3.5886
[09/26 10:06:45 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 3.4508
[09/26 10:06:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 36.00	
[09/26 10:06:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:06:52 visual_prompt]: Epoch 7 / 100: avg data time: 5.57e-02, avg batch time: 0.4988, average train loss: 3.4441
[09/26 10:06:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 3.5150
[09/26 10:06:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 37.00	
[09/26 10:06:53 visual_prompt]: Best epoch 7: best metric: 0.120
[09/26 10:06:53 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:07:00 visual_prompt]: Epoch 8 / 100: avg data time: 5.56e-02, avg batch time: 0.4963, average train loss: 3.1021
[09/26 10:07:02 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 3.3481
[09/26 10:07:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 41.50	
[09/26 10:07:02 visual_prompt]: Best epoch 8: best metric: 0.130
[09/26 10:07:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:07:08 visual_prompt]: Epoch 9 / 100: avg data time: 5.60e-02, avg batch time: 0.4964, average train loss: 4.1721
[09/26 10:07:10 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1656, average loss: 5.5444
[09/26 10:07:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 16.50	
[09/26 10:07:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:07:17 visual_prompt]: Epoch 10 / 100: avg data time: 6.28e-02, avg batch time: 0.5033, average train loss: 5.1798
[09/26 10:07:18 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1656, average loss: 4.9829
[09/26 10:07:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 10:07:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:07:25 visual_prompt]: Epoch 11 / 100: avg data time: 6.26e-02, avg batch time: 0.5034, average train loss: 5.3787
[09/26 10:07:27 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1657, average loss: 6.9155
[09/26 10:07:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 20.00	
[09/26 10:07:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:07:34 visual_prompt]: Epoch 12 / 100: avg data time: 6.28e-02, avg batch time: 0.5036, average train loss: 5.5038
[09/26 10:07:35 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1660, average loss: 4.2988
[09/26 10:07:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.50	top5: 37.00	
[09/26 10:07:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:07:42 visual_prompt]: Epoch 13 / 100: avg data time: 5.52e-02, avg batch time: 0.4958, average train loss: 4.4627
[09/26 10:07:44 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1661, average loss: 4.7715
[09/26 10:07:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.00	top5: 41.00	
[09/26 10:07:44 visual_prompt]: Best epoch 13: best metric: 0.210
[09/26 10:07:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:07:51 visual_prompt]: Epoch 14 / 100: avg data time: 6.52e-02, avg batch time: 0.5065, average train loss: 3.6500
[09/26 10:07:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 3.6654
[09/26 10:07:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 52.00	
[09/26 10:07:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:07:59 visual_prompt]: Epoch 15 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 4.1400
[09/26 10:08:01 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 3.5490
[09/26 10:08:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.50	top5: 48.00	
[09/26 10:08:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:08:07 visual_prompt]: Epoch 16 / 100: avg data time: 5.92e-02, avg batch time: 0.5001, average train loss: 2.7022
[09/26 10:08:09 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 2.6967
[09/26 10:08:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 35.50	top5: 69.50	
[09/26 10:08:09 visual_prompt]: Best epoch 16: best metric: 0.355
[09/26 10:08:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:08:16 visual_prompt]: Epoch 17 / 100: avg data time: 4.51e-02, avg batch time: 0.4866, average train loss: 2.0320
[09/26 10:08:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.9242
[09/26 10:08:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.00	top5: 82.50	
[09/26 10:08:17 visual_prompt]: Best epoch 17: best metric: 0.470
[09/26 10:08:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:08:24 visual_prompt]: Epoch 18 / 100: avg data time: 6.17e-02, avg batch time: 0.5033, average train loss: 1.1985
[09/26 10:08:25 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 1.7787
[09/26 10:08:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.00	top5: 83.50	
[09/26 10:08:25 visual_prompt]: Best epoch 18: best metric: 0.560
[09/26 10:08:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:08:32 visual_prompt]: Epoch 19 / 100: avg data time: 6.12e-02, avg batch time: 0.5035, average train loss: 1.2564
[09/26 10:08:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.6939
[09/26 10:08:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.00	top5: 84.00	
[09/26 10:08:34 visual_prompt]: Best epoch 19: best metric: 0.580
[09/26 10:08:34 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:08:41 visual_prompt]: Epoch 20 / 100: avg data time: 5.99e-02, avg batch time: 0.5022, average train loss: 0.8307
[09/26 10:08:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1663, average loss: 1.2123
[09/26 10:08:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 91.50	
[09/26 10:08:42 visual_prompt]: Best epoch 20: best metric: 0.690
[09/26 10:08:42 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:08:49 visual_prompt]: Epoch 21 / 100: avg data time: 6.25e-02, avg batch time: 0.5049, average train loss: 0.6810
[09/26 10:08:51 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 1.2977
[09/26 10:08:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.50	
[09/26 10:08:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:08:58 visual_prompt]: Epoch 22 / 100: avg data time: 5.36e-02, avg batch time: 0.4958, average train loss: 0.5873
[09/26 10:08:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1664, average loss: 1.9838
[09/26 10:08:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.50	top5: 85.50	
[09/26 10:08:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:09:06 visual_prompt]: Epoch 23 / 100: avg data time: 5.46e-02, avg batch time: 0.4964, average train loss: 0.7215
[09/26 10:09:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.2708
[09/26 10:09:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.50	
[09/26 10:09:08 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:09:15 visual_prompt]: Epoch 24 / 100: avg data time: 6.36e-02, avg batch time: 0.5067, average train loss: 0.3312
[09/26 10:09:16 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 1.2568
[09/26 10:09:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.50	
[09/26 10:09:16 visual_prompt]: Best epoch 24: best metric: 0.700
[09/26 10:09:16 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:09:23 visual_prompt]: Epoch 25 / 100: avg data time: 5.03e-02, avg batch time: 0.4925, average train loss: 0.1950
[09/26 10:09:25 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.5324
[09/26 10:09:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.00	
[09/26 10:09:25 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:09:32 visual_prompt]: Epoch 26 / 100: avg data time: 6.52e-02, avg batch time: 0.5085, average train loss: 0.2390
[09/26 10:09:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.4299
[09/26 10:09:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 10:09:33 visual_prompt]: Best epoch 26: best metric: 0.705
[09/26 10:09:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:09:40 visual_prompt]: Epoch 27 / 100: avg data time: 5.79e-02, avg batch time: 0.5001, average train loss: 0.2870
[09/26 10:09:42 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.1664, average loss: 1.3020
[09/26 10:09:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.50	
[09/26 10:09:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:09:49 visual_prompt]: Epoch 28 / 100: avg data time: 5.82e-02, avg batch time: 0.5001, average train loss: 0.1903
[09/26 10:09:50 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.4264
[09/26 10:09:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.00	
[09/26 10:09:50 visual_prompt]: Best epoch 28: best metric: 0.715
[09/26 10:09:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:09:57 visual_prompt]: Epoch 29 / 100: avg data time: 5.72e-02, avg batch time: 0.5001, average train loss: 0.1614
[09/26 10:09:59 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1664, average loss: 1.6884
[09/26 10:09:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 90.00	
[09/26 10:09:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:10:06 visual_prompt]: Epoch 30 / 100: avg data time: 4.83e-02, avg batch time: 0.4916, average train loss: 0.1471
[09/26 10:10:07 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 1.4998
[09/26 10:10:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.50	
[09/26 10:10:07 visual_prompt]: Best epoch 30: best metric: 0.720
[09/26 10:10:07 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:10:14 visual_prompt]: Epoch 31 / 100: avg data time: 4.66e-02, avg batch time: 0.4889, average train loss: 0.1115
[09/26 10:10:16 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1667, average loss: 1.0959
[09/26 10:10:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 94.50	
[09/26 10:10:16 visual_prompt]: Best epoch 31: best metric: 0.750
[09/26 10:10:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:10:22 visual_prompt]: Epoch 32 / 100: avg data time: 6.09e-02, avg batch time: 0.5020, average train loss: 0.1089
[09/26 10:10:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 1.8928
[09/26 10:10:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 85.00	
[09/26 10:10:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:10:31 visual_prompt]: Epoch 33 / 100: avg data time: 5.72e-02, avg batch time: 0.4998, average train loss: 0.1509
[09/26 10:10:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 1.9876
[09/26 10:10:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.00	
[09/26 10:10:33 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:10:40 visual_prompt]: Epoch 34 / 100: avg data time: 6.10e-02, avg batch time: 0.5029, average train loss: 0.1381
[09/26 10:10:41 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1663, average loss: 1.3391
[09/26 10:10:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 93.50	
[09/26 10:10:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:10:48 visual_prompt]: Epoch 35 / 100: avg data time: 5.76e-02, avg batch time: 0.5006, average train loss: 0.1931
[09/26 10:10:50 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.0197
[09/26 10:10:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 10:10:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:10:57 visual_prompt]: Epoch 36 / 100: avg data time: 6.29e-02, avg batch time: 0.5040, average train loss: 0.2317
[09/26 10:10:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 1.4175
[09/26 10:10:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 91.00	
[09/26 10:10:58 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:11:05 visual_prompt]: Epoch 37 / 100: avg data time: 5.74e-02, avg batch time: 0.4999, average train loss: 0.1923
[09/26 10:11:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.3035
[09/26 10:11:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 94.00	
[09/26 10:11:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 10:11:13 visual_prompt]: Epoch 38 / 100: avg data time: 5.86e-02, avg batch time: 0.5016, average train loss: 0.1712
[09/26 10:11:15 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 1.2295
[09/26 10:11:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 10:11:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 10:11:22 visual_prompt]: Epoch 39 / 100: avg data time: 5.00e-02, avg batch time: 0.4927, average train loss: 0.0947
[09/26 10:11:23 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1667, average loss: 1.2405
[09/26 10:11:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 95.00	
[09/26 10:11:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 10:11:30 visual_prompt]: Epoch 40 / 100: avg data time: 7.29e-02, avg batch time: 0.5141, average train loss: 0.1091
[09/26 10:11:32 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1662, average loss: 1.3403
[09/26 10:11:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.00	
[09/26 10:11:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 10:11:39 visual_prompt]: Epoch 41 / 100: avg data time: 5.93e-02, avg batch time: 0.5015, average train loss: 0.1275
[09/26 10:11:40 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 1.2174
[09/26 10:11:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 10:11:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 10:11:47 visual_prompt]: Epoch 42 / 100: avg data time: 6.38e-02, avg batch time: 0.5052, average train loss: 0.0900
[09/26 10:11:49 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1666, average loss: 1.0243
[09/26 10:11:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.00	
[09/26 10:11:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 10:11:56 visual_prompt]: Epoch 43 / 100: avg data time: 6.63e-02, avg batch time: 0.5094, average train loss: 0.0274
[09/26 10:11:57 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.0327
[09/26 10:11:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.50	
[09/26 10:11:57 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 10:12:04 visual_prompt]: Epoch 44 / 100: avg data time: 6.28e-02, avg batch time: 0.5050, average train loss: 0.0478
[09/26 10:12:06 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 0.8814
[09/26 10:12:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 99.00	
[09/26 10:12:06 visual_prompt]: Best epoch 44: best metric: 0.755
[09/26 10:12:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 10:12:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.93e-02, avg batch time: 0.5013, average train loss: 0.0223
[09/26 10:12:14 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1665, average loss: 0.8253
[09/26 10:12:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 97.00	
[09/26 10:12:14 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 10:12:21 visual_prompt]: Epoch 46 / 100: avg data time: 5.81e-02, avg batch time: 0.4997, average train loss: 0.0228
[09/26 10:12:22 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1665, average loss: 0.9385
[09/26 10:12:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 10:12:22 visual_prompt]: Best epoch 46: best metric: 0.775
[09/26 10:12:22 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 10:12:29 visual_prompt]: Epoch 47 / 100: avg data time: 5.21e-02, avg batch time: 0.4944, average train loss: 0.0176
[09/26 10:12:31 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 0.9023
[09/26 10:12:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 97.00	
[09/26 10:12:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 10:12:38 visual_prompt]: Epoch 48 / 100: avg data time: 7.00e-02, avg batch time: 0.5117, average train loss: 0.0214
[09/26 10:12:39 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 0.7658
[09/26 10:12:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 95.50	
[09/26 10:12:39 visual_prompt]: Best epoch 48: best metric: 0.800
[09/26 10:12:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 10:12:46 visual_prompt]: Epoch 49 / 100: avg data time: 5.81e-02, avg batch time: 0.4998, average train loss: 0.0247
[09/26 10:12:48 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.9237
[09/26 10:12:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.00	
[09/26 10:12:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 10:12:54 visual_prompt]: Epoch 50 / 100: avg data time: 5.22e-02, avg batch time: 0.4963, average train loss: 0.0256
[09/26 10:12:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 0.7843
[09/26 10:12:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 10:12:56 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 10:13:03 visual_prompt]: Epoch 51 / 100: avg data time: 6.45e-02, avg batch time: 0.5059, average train loss: 0.0137
[09/26 10:13:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.8276
[09/26 10:13:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 10:13:04 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 10:13:11 visual_prompt]: Epoch 52 / 100: avg data time: 6.24e-02, avg batch time: 0.5044, average train loss: 0.0076
[09/26 10:13:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.6975
[09/26 10:13:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 10:13:13 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 10:13:20 visual_prompt]: Epoch 53 / 100: avg data time: 5.20e-02, avg batch time: 0.4938, average train loss: 0.0065
[09/26 10:13:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.7303
[09/26 10:13:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 98.00	
[09/26 10:13:21 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 10:13:28 visual_prompt]: Epoch 54 / 100: avg data time: 6.18e-02, avg batch time: 0.5030, average train loss: 0.0072
[09/26 10:13:30 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1665, average loss: 0.6762
[09/26 10:13:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 10:13:30 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 10:13:36 visual_prompt]: Epoch 55 / 100: avg data time: 4.46e-02, avg batch time: 0.4876, average train loss: 0.0047
[09/26 10:13:38 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 0.6850
[09/26 10:13:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:13:38 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 10:13:45 visual_prompt]: Epoch 56 / 100: avg data time: 5.96e-02, avg batch time: 0.5010, average train loss: 0.0038
[09/26 10:13:46 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1666, average loss: 0.6658
[09/26 10:13:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 10:13:46 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 10:13:53 visual_prompt]: Epoch 57 / 100: avg data time: 6.07e-02, avg batch time: 0.5023, average train loss: 0.0034
[09/26 10:13:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 0.6355
[09/26 10:13:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:13:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 10:14:02 visual_prompt]: Epoch 58 / 100: avg data time: 5.44e-02, avg batch time: 0.4966, average train loss: 0.0033
[09/26 10:14:03 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 0.6212
[09/26 10:14:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 10:14:03 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:14:10 visual_prompt]: Epoch 59 / 100: avg data time: 5.54e-02, avg batch time: 0.4984, average train loss: 0.0034
[09/26 10:14:11 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1664, average loss: 0.6201
[09/26 10:14:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:14:11 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:14:18 visual_prompt]: Epoch 60 / 100: avg data time: 5.31e-02, avg batch time: 0.4946, average train loss: 0.0037
[09/26 10:14:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1666, average loss: 0.6222
[09/26 10:14:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 10:14:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:14:27 visual_prompt]: Epoch 61 / 100: avg data time: 5.50e-02, avg batch time: 0.4971, average train loss: 0.0039
[09/26 10:14:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1665, average loss: 0.6167
[09/26 10:14:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 10:14:28 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:14:35 visual_prompt]: Epoch 62 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.0040
[09/26 10:14:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 0.6108
[09/26 10:14:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 10:14:36 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:14:43 visual_prompt]: Epoch 63 / 100: avg data time: 5.38e-02, avg batch time: 0.4950, average train loss: 0.0041
[09/26 10:14:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 0.6104
[09/26 10:14:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 10:14:45 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:14:52 visual_prompt]: Epoch 64 / 100: avg data time: 5.48e-02, avg batch time: 0.4972, average train loss: 0.0043
[09/26 10:14:53 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1666, average loss: 0.6069
[09/26 10:14:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 10:14:53 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:15:00 visual_prompt]: Epoch 65 / 100: avg data time: 5.68e-02, avg batch time: 0.4999, average train loss: 0.0043
[09/26 10:15:02 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1664, average loss: 0.6034
[09/26 10:15:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 10:15:02 visual_prompt]: Best epoch 65: best metric: 0.805
[09/26 10:15:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:15:08 visual_prompt]: Epoch 66 / 100: avg data time: 5.90e-02, avg batch time: 0.5004, average train loss: 0.0046
[09/26 10:15:10 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 0.5999
[09/26 10:15:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.00	
[09/26 10:15:10 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:15:17 visual_prompt]: Epoch 67 / 100: avg data time: 6.50e-02, avg batch time: 0.5062, average train loss: 0.0046
[09/26 10:15:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 0.6058
[09/26 10:15:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 99.00	
[09/26 10:15:18 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:15:25 visual_prompt]: Epoch 68 / 100: avg data time: 5.54e-02, avg batch time: 0.4981, average train loss: 0.0048
[09/26 10:15:27 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.6011
[09/26 10:15:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 99.00	
[09/26 10:15:27 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:15:34 visual_prompt]: Epoch 69 / 100: avg data time: 5.22e-02, avg batch time: 0.4939, average train loss: 0.0048
[09/26 10:15:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 0.5974
[09/26 10:15:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 10:15:35 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:15:42 visual_prompt]: Epoch 70 / 100: avg data time: 5.11e-02, avg batch time: 0.4943, average train loss: 0.0050
[09/26 10:15:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 0.6031
[09/26 10:15:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 99.00	
[09/26 10:15:43 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:15:50 visual_prompt]: Epoch 71 / 100: avg data time: 6.15e-02, avg batch time: 0.5041, average train loss: 0.0049
[09/26 10:15:52 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 0.5991
[09/26 10:15:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 99.00	
[09/26 10:15:52 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:15:59 visual_prompt]: Epoch 72 / 100: avg data time: 4.95e-02, avg batch time: 0.4922, average train loss: 0.0048
[09/26 10:16:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 0.5992
[09/26 10:16:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 99.00	
[09/26 10:16:00 visual_prompt]: Best epoch 72: best metric: 0.810
[09/26 10:16:00 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:16:07 visual_prompt]: Epoch 73 / 100: avg data time: 5.59e-02, avg batch time: 0.4978, average train loss: 0.0049
[09/26 10:16:09 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1665, average loss: 0.6024
[09/26 10:16:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 99.00	
[09/26 10:16:09 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:16:16 visual_prompt]: Epoch 74 / 100: avg data time: 6.45e-02, avg batch time: 0.5060, average train loss: 0.0049
[09/26 10:16:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.6006
[09/26 10:16:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.50	
[09/26 10:16:17 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:16:24 visual_prompt]: Epoch 75 / 100: avg data time: 4.61e-02, avg batch time: 0.4889, average train loss: 0.0048
[09/26 10:16:25 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1663, average loss: 0.6074
[09/26 10:16:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 99.00	
[09/26 10:16:25 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:16:32 visual_prompt]: Epoch 76 / 100: avg data time: 6.44e-02, avg batch time: 0.5055, average train loss: 0.0048
[09/26 10:16:34 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 0.6107
[09/26 10:16:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:16:34 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:16:41 visual_prompt]: Epoch 77 / 100: avg data time: 5.36e-02, avg batch time: 0.4961, average train loss: 0.0049
[09/26 10:16:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 0.6074
[09/26 10:16:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:16:42 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:16:49 visual_prompt]: Epoch 78 / 100: avg data time: 4.35e-02, avg batch time: 0.4866, average train loss: 0.0049
[09/26 10:16:50 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1666, average loss: 0.6128
[09/26 10:16:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:16:50 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:16:57 visual_prompt]: Epoch 79 / 100: avg data time: 4.99e-02, avg batch time: 0.4933, average train loss: 0.0047
[09/26 10:16:58 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1665, average loss: 0.6116
[09/26 10:16:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:16:58 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:17:05 visual_prompt]: Epoch 80 / 100: avg data time: 4.76e-02, avg batch time: 0.4921, average train loss: 0.0047
[09/26 10:17:07 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 0.6086
[09/26 10:17:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:17:07 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:17:13 visual_prompt]: Epoch 81 / 100: avg data time: 6.21e-02, avg batch time: 0.5033, average train loss: 0.0046
[09/26 10:17:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 0.6059
[09/26 10:17:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:17:15 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:17:22 visual_prompt]: Epoch 82 / 100: avg data time: 4.57e-02, avg batch time: 0.4872, average train loss: 0.0045
[09/26 10:17:23 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1664, average loss: 0.6162
[09/26 10:17:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 99.00	
[09/26 10:17:23 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:17:30 visual_prompt]: Epoch 83 / 100: avg data time: 4.93e-02, avg batch time: 0.4927, average train loss: 0.0047
[09/26 10:17:32 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1664, average loss: 0.6162
[09/26 10:17:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:17:32 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:17:38 visual_prompt]: Epoch 84 / 100: avg data time: 5.16e-02, avg batch time: 0.4952, average train loss: 0.0046
[09/26 10:17:40 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 0.6142
[09/26 10:17:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:17:40 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:17:47 visual_prompt]: Epoch 85 / 100: avg data time: 5.63e-02, avg batch time: 0.4983, average train loss: 0.0046
[09/26 10:17:48 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1664, average loss: 0.6153
[09/26 10:17:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:17:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:17:55 visual_prompt]: Epoch 86 / 100: avg data time: 5.98e-02, avg batch time: 0.5021, average train loss: 0.0046
[09/26 10:17:57 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 0.6151
[09/26 10:17:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:17:57 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:18:03 visual_prompt]: Epoch 87 / 100: avg data time: 5.69e-02, avg batch time: 0.4989, average train loss: 0.0045
[09/26 10:18:05 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 0.6150
[09/26 10:18:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 99.00	
[09/26 10:18:05 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:18:12 visual_prompt]: Epoch 88 / 100: avg data time: 5.59e-02, avg batch time: 0.4983, average train loss: 0.0045
[09/26 10:18:13 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 0.6137
[09/26 10:18:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.00	
[09/26 10:18:13 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:18:20 visual_prompt]: Epoch 89 / 100: avg data time: 5.56e-02, avg batch time: 0.4984, average train loss: 0.0046
[09/26 10:18:22 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 0.6117
[09/26 10:18:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:18:22 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:18:28 visual_prompt]: Epoch 90 / 100: avg data time: 5.65e-02, avg batch time: 0.4991, average train loss: 0.0046
[09/26 10:18:30 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 0.6132
[09/26 10:18:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:18:30 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:18:37 visual_prompt]: Epoch 91 / 100: avg data time: 6.01e-02, avg batch time: 0.5009, average train loss: 0.0045
[09/26 10:18:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 0.6161
[09/26 10:18:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:18:38 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:18:45 visual_prompt]: Epoch 92 / 100: avg data time: 5.39e-02, avg batch time: 0.4949, average train loss: 0.0046
[09/26 10:18:47 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 0.6162
[09/26 10:18:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:18:47 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:18:54 visual_prompt]: Epoch 93 / 100: avg data time: 5.26e-02, avg batch time: 0.4952, average train loss: 0.0045
[09/26 10:18:55 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.6152
[09/26 10:18:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:18:55 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:19:02 visual_prompt]: Epoch 94 / 100: avg data time: 5.52e-02, avg batch time: 0.4963, average train loss: 0.0044
[09/26 10:19:03 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1664, average loss: 0.6155
[09/26 10:19:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:03 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:19:10 visual_prompt]: Epoch 95 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 0.0044
[09/26 10:19:12 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1660, average loss: 0.6154
[09/26 10:19:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:12 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:19:19 visual_prompt]: Epoch 96 / 100: avg data time: 5.03e-02, avg batch time: 0.4917, average train loss: 0.0045
[09/26 10:19:20 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.6156
[09/26 10:19:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:20 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:19:27 visual_prompt]: Epoch 97 / 100: avg data time: 5.21e-02, avg batch time: 0.4937, average train loss: 0.0044
[09/26 10:19:29 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1662, average loss: 0.6154
[09/26 10:19:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:19:35 visual_prompt]: Epoch 98 / 100: avg data time: 5.46e-02, avg batch time: 0.4981, average train loss: 0.0044
[09/26 10:19:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.6153
[09/26 10:19:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:37 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:19:44 visual_prompt]: Epoch 99 / 100: avg data time: 4.78e-02, avg batch time: 0.4899, average train loss: 0.0044
[09/26 10:19:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 0.6153
[09/26 10:19:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:45 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:19:52 visual_prompt]: Epoch 100 / 100: avg data time: 4.71e-02, avg batch time: 0.4916, average train loss: 0.0045
[09/26 10:19:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 0.6153
[09/26 10:19:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 99.00	
[09/26 10:19:54 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:19:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:19:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:19:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:19:54 visual_prompt]: Training with config:
[09/26 10:19:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr5.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:19:54 visual_prompt]: Loading training data...
[09/26 10:19:54 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:19:55 visual_prompt]: Number of images: 800
[09/26 10:19:55 visual_prompt]: Number of classes: 45 / 45
[09/26 10:19:55 visual_prompt]: Loading validation data...
[09/26 10:19:55 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:19:55 visual_prompt]: Number of images: 200
[09/26 10:19:55 visual_prompt]: Number of classes: 45 / 45
[09/26 10:19:55 visual_prompt]: Constructing models...
[09/26 10:19:57 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 10:19:57 visual_prompt]: tuned percent:0.574
[09/26 10:19:58 visual_prompt]: Device used for model: 0
[09/26 10:19:58 visual_prompt]: Setting up Evaluator...
[09/26 10:19:58 visual_prompt]: Setting up Trainer...
[09/26 10:19:58 visual_prompt]: 	Setting up the optimizer...
[09/26 10:19:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:20:04 visual_prompt]: Epoch 1 / 100: avg data time: 5.95e-02, avg batch time: 0.4989, average train loss: 3.8930
[09/26 10:20:06 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1659, average loss: 3.9529
[09/26 10:20:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 10:20:06 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 10:20:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/26 10:20:13 visual_prompt]: Epoch 2 / 100: avg data time: 5.02e-02, avg batch time: 0.4911, average train loss: 3.8477
[09/26 10:20:14 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1659, average loss: 3.7519
[09/26 10:20:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 21.50	
[09/26 10:20:14 visual_prompt]: Best epoch 2: best metric: 0.045
[09/26 10:20:14 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/26 10:20:21 visual_prompt]: Epoch 3 / 100: avg data time: 5.05e-02, avg batch time: 0.4923, average train loss: 3.8435
[09/26 10:20:22 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1659, average loss: 3.7883
[09/26 10:20:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 19.50	
[09/26 10:20:22 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/26 10:20:29 visual_prompt]: Epoch 4 / 100: avg data time: 5.89e-02, avg batch time: 0.5010, average train loss: 3.8771
[09/26 10:20:31 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1657, average loss: 3.7377
[09/26 10:20:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 20.00	
[09/26 10:20:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/26 10:20:38 visual_prompt]: Epoch 5 / 100: avg data time: 5.89e-02, avg batch time: 0.4988, average train loss: 3.6666
[09/26 10:20:39 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1658, average loss: 3.5209
[09/26 10:20:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 30.50	
[09/26 10:20:39 visual_prompt]: Best epoch 5: best metric: 0.055
[09/26 10:20:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/26 10:20:46 visual_prompt]: Epoch 6 / 100: avg data time: 5.47e-02, avg batch time: 0.4956, average train loss: 3.4856
[09/26 10:20:48 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1658, average loss: 4.0459
[09/26 10:20:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 19.50	
[09/26 10:20:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/26 10:20:55 visual_prompt]: Epoch 7 / 100: avg data time: 6.61e-02, avg batch time: 0.5069, average train loss: 3.5866
[09/26 10:20:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1659, average loss: 3.4022
[09/26 10:20:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 38.50	
[09/26 10:20:56 visual_prompt]: Best epoch 7: best metric: 0.140
[09/26 10:20:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/26 10:21:03 visual_prompt]: Epoch 8 / 100: avg data time: 6.82e-02, avg batch time: 0.5087, average train loss: 3.0582
[09/26 10:21:05 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 2.9595
[09/26 10:21:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 53.00	
[09/26 10:21:05 visual_prompt]: Best epoch 8: best metric: 0.195
[09/26 10:21:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/26 10:21:12 visual_prompt]: Epoch 9 / 100: avg data time: 6.59e-02, avg batch time: 0.5080, average train loss: 2.5278
[09/26 10:21:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 3.4808
[09/26 10:21:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 55.00	
[09/26 10:21:14 visual_prompt]: Best epoch 9: best metric: 0.255
[09/26 10:21:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/26 10:21:21 visual_prompt]: Epoch 10 / 100: avg data time: 5.82e-02, avg batch time: 0.5010, average train loss: 2.2552
[09/26 10:21:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 2.4535
[09/26 10:21:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.00	top5: 76.00	
[09/26 10:21:22 visual_prompt]: Best epoch 10: best metric: 0.430
[09/26 10:21:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/26 10:21:29 visual_prompt]: Epoch 11 / 100: avg data time: 6.43e-02, avg batch time: 0.5056, average train loss: 1.6691
[09/26 10:21:31 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 2.2957
[09/26 10:21:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 44.50	top5: 74.00	
[09/26 10:21:31 visual_prompt]: Best epoch 11: best metric: 0.445
[09/26 10:21:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/26 10:21:38 visual_prompt]: Epoch 12 / 100: avg data time: 6.14e-02, avg batch time: 0.5029, average train loss: 1.2772
[09/26 10:21:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 1.6822
[09/26 10:21:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 87.00	
[09/26 10:21:39 visual_prompt]: Best epoch 12: best metric: 0.585
[09/26 10:21:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/26 10:21:46 visual_prompt]: Epoch 13 / 100: avg data time: 6.27e-02, avg batch time: 0.5054, average train loss: 0.9431
[09/26 10:21:48 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1659, average loss: 1.3248
[09/26 10:21:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 93.00	
[09/26 10:21:48 visual_prompt]: Best epoch 13: best metric: 0.645
[09/26 10:21:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/26 10:21:55 visual_prompt]: Epoch 14 / 100: avg data time: 6.38e-02, avg batch time: 0.5045, average train loss: 0.6026
[09/26 10:21:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 1.2446
[09/26 10:21:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 91.50	
[09/26 10:21:56 visual_prompt]: Best epoch 14: best metric: 0.670
[09/26 10:21:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/26 10:22:03 visual_prompt]: Epoch 15 / 100: avg data time: 4.86e-02, avg batch time: 0.4923, average train loss: 0.4456
[09/26 10:22:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 1.6284
[09/26 10:22:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 92.00	
[09/26 10:22:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/26 10:22:11 visual_prompt]: Epoch 16 / 100: avg data time: 5.21e-02, avg batch time: 0.4946, average train loss: 0.2977
[09/26 10:22:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 1.5130
[09/26 10:22:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 93.50	
[09/26 10:22:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/26 10:22:19 visual_prompt]: Epoch 17 / 100: avg data time: 5.31e-02, avg batch time: 0.4963, average train loss: 0.3103
[09/26 10:22:21 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 1.3993
[09/26 10:22:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.50	
[09/26 10:22:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/26 10:22:28 visual_prompt]: Epoch 18 / 100: avg data time: 6.39e-02, avg batch time: 0.5049, average train loss: 0.1571
[09/26 10:22:30 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1659, average loss: 1.2887
[09/26 10:22:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.50	
[09/26 10:22:30 visual_prompt]: Best epoch 18: best metric: 0.720
[09/26 10:22:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/26 10:22:37 visual_prompt]: Epoch 19 / 100: avg data time: 6.24e-02, avg batch time: 0.5049, average train loss: 0.0575
[09/26 10:22:38 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1659, average loss: 1.6011
[09/26 10:22:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.50	
[09/26 10:22:38 visual_prompt]: Best epoch 19: best metric: 0.740
[09/26 10:22:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/26 10:22:45 visual_prompt]: Epoch 20 / 100: avg data time: 6.11e-02, avg batch time: 0.5028, average train loss: 0.1154
[09/26 10:22:47 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1658, average loss: 1.7431
[09/26 10:22:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 10:22:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/26 10:22:54 visual_prompt]: Epoch 21 / 100: avg data time: 8.02e-02, avg batch time: 0.5207, average train loss: 0.1180
[09/26 10:22:55 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 1.6901
[09/26 10:22:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 95.50	
[09/26 10:22:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/26 10:23:02 visual_prompt]: Epoch 22 / 100: avg data time: 5.03e-02, avg batch time: 0.4932, average train loss: 0.0970
[09/26 10:23:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 1.7097
[09/26 10:23:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.50	
[09/26 10:23:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/26 10:23:11 visual_prompt]: Epoch 23 / 100: avg data time: 6.53e-02, avg batch time: 0.5060, average train loss: 0.1951
[09/26 10:23:12 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1660, average loss: 1.3871
[09/26 10:23:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 10:23:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/26 10:23:19 visual_prompt]: Epoch 24 / 100: avg data time: 6.48e-02, avg batch time: 0.5051, average train loss: 0.1229
[09/26 10:23:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 1.4584
[09/26 10:23:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 95.00	
[09/26 10:23:21 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/26 10:23:28 visual_prompt]: Epoch 25 / 100: avg data time: 6.81e-02, avg batch time: 0.5083, average train loss: 0.0867
[09/26 10:23:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 1.2193
[09/26 10:23:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.50	
[09/26 10:23:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/26 10:23:36 visual_prompt]: Epoch 26 / 100: avg data time: 6.25e-02, avg batch time: 0.5036, average train loss: 0.0285
[09/26 10:23:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 1.1173
[09/26 10:23:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.00	
[09/26 10:23:38 visual_prompt]: Best epoch 26: best metric: 0.800
[09/26 10:23:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/26 10:23:45 visual_prompt]: Epoch 27 / 100: avg data time: 6.34e-02, avg batch time: 0.5047, average train loss: 0.0277
[09/26 10:23:46 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1660, average loss: 1.3170
[09/26 10:23:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 10:23:46 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/26 10:23:53 visual_prompt]: Epoch 28 / 100: avg data time: 6.47e-02, avg batch time: 0.5056, average train loss: 0.0167
[09/26 10:23:55 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 1.3963
[09/26 10:23:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 97.50	
[09/26 10:23:55 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/26 10:24:02 visual_prompt]: Epoch 29 / 100: avg data time: 5.89e-02, avg batch time: 0.5012, average train loss: 0.0135
[09/26 10:24:04 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 1.3572
[09/26 10:24:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 10:24:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/26 10:24:10 visual_prompt]: Epoch 30 / 100: avg data time: 4.47e-02, avg batch time: 0.4867, average train loss: 0.0074
[09/26 10:24:12 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 1.4225
[09/26 10:24:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.00	
[09/26 10:24:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/26 10:24:19 visual_prompt]: Epoch 31 / 100: avg data time: 6.25e-02, avg batch time: 0.5040, average train loss: 0.0080
[09/26 10:24:20 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1659, average loss: 1.2616
[09/26 10:24:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 10:24:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/26 10:24:27 visual_prompt]: Epoch 32 / 100: avg data time: 5.75e-02, avg batch time: 0.4986, average train loss: 0.0034
[09/26 10:24:29 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 1.3340
[09/26 10:24:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 10:24:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/26 10:24:36 visual_prompt]: Epoch 33 / 100: avg data time: 6.29e-02, avg batch time: 0.5050, average train loss: 0.0025
[09/26 10:24:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 1.2211
[09/26 10:24:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 10:24:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/26 10:24:44 visual_prompt]: Epoch 34 / 100: avg data time: 6.14e-02, avg batch time: 0.5023, average train loss: 0.0002
[09/26 10:24:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 1.2439
[09/26 10:24:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:24:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/26 10:24:52 visual_prompt]: Epoch 35 / 100: avg data time: 5.43e-02, avg batch time: 0.4951, average train loss: 0.0008
[09/26 10:24:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.2380
[09/26 10:24:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 10:24:54 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/26 10:25:01 visual_prompt]: Epoch 36 / 100: avg data time: 6.37e-02, avg batch time: 0.5060, average train loss: 0.0004
[09/26 10:25:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.2182
[09/26 10:25:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 10:25:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/26 10:25:09 visual_prompt]: Epoch 37 / 100: avg data time: 6.14e-02, avg batch time: 0.5023, average train loss: 0.0006
[09/26 10:25:11 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 1.2292
[09/26 10:25:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 10:25:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/26 10:25:18 visual_prompt]: Epoch 38 / 100: avg data time: 6.58e-02, avg batch time: 0.5070, average train loss: 0.0002
[09/26 10:25:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 1.2425
[09/26 10:25:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 10:25:20 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/26 10:25:26 visual_prompt]: Epoch 39 / 100: avg data time: 4.74e-02, avg batch time: 0.4888, average train loss: 0.0002
[09/26 10:25:28 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 1.2547
[09/26 10:25:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 10:25:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/26 10:25:35 visual_prompt]: Epoch 40 / 100: avg data time: 6.56e-02, avg batch time: 0.5076, average train loss: 0.0003
[09/26 10:25:36 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1660, average loss: 1.2647
[09/26 10:25:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 10:25:36 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/26 10:25:43 visual_prompt]: Epoch 41 / 100: avg data time: 6.18e-02, avg batch time: 0.5041, average train loss: 0.0002
[09/26 10:25:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1659, average loss: 1.2791
[09/26 10:25:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 10:25:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/26 10:25:52 visual_prompt]: Epoch 42 / 100: avg data time: 5.04e-02, avg batch time: 0.4925, average train loss: 0.0002
[09/26 10:25:53 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 1.2918
[09/26 10:25:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 10:25:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/26 10:26:00 visual_prompt]: Epoch 43 / 100: avg data time: 6.67e-02, avg batch time: 0.5076, average train loss: 0.0002
[09/26 10:26:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 1.2961
[09/26 10:26:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 10:26:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/26 10:26:09 visual_prompt]: Epoch 44 / 100: avg data time: 7.00e-02, avg batch time: 0.5121, average train loss: 0.0002
[09/26 10:26:10 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 1.3022
[09/26 10:26:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:26:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/26 10:26:17 visual_prompt]: Epoch 45 / 100: avg data time: 5.88e-02, avg batch time: 0.4997, average train loss: 0.0003
[09/26 10:26:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 1.2857
[09/26 10:26:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 10:26:19 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/26 10:26:26 visual_prompt]: Epoch 46 / 100: avg data time: 6.16e-02, avg batch time: 0.5024, average train loss: 0.0001
[09/26 10:26:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.2825
[09/26 10:26:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 10:26:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/26 10:26:34 visual_prompt]: Epoch 47 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 0.0001
[09/26 10:26:36 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 1.2848
[09/26 10:26:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 10:26:36 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/26 10:26:43 visual_prompt]: Epoch 48 / 100: avg data time: 7.40e-02, avg batch time: 0.5146, average train loss: 0.0001
[09/26 10:26:44 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.2877
[09/26 10:26:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 10:26:44 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/26 10:26:51 visual_prompt]: Epoch 49 / 100: avg data time: 5.91e-02, avg batch time: 0.4998, average train loss: 0.0001
[09/26 10:26:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.2921
[09/26 10:26:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 10:26:53 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/26 10:27:00 visual_prompt]: Epoch 50 / 100: avg data time: 6.48e-02, avg batch time: 0.5066, average train loss: 0.0001
[09/26 10:27:01 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 1.2984
[09/26 10:27:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:27:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/26 10:27:08 visual_prompt]: Epoch 51 / 100: avg data time: 6.83e-02, avg batch time: 0.5097, average train loss: 0.0001
[09/26 10:27:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 1.3031
[09/26 10:27:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:27:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/26 10:27:17 visual_prompt]: Epoch 52 / 100: avg data time: 6.01e-02, avg batch time: 0.5006, average train loss: 0.0001
[09/26 10:27:19 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.3050
[09/26 10:27:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:27:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/26 10:27:25 visual_prompt]: Epoch 53 / 100: avg data time: 5.36e-02, avg batch time: 0.4972, average train loss: 0.0001
[09/26 10:27:27 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1662, average loss: 1.3075
[09/26 10:27:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:27:27 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/26 10:27:34 visual_prompt]: Epoch 54 / 100: avg data time: 5.57e-02, avg batch time: 0.4965, average train loss: 0.0001
[09/26 10:27:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1660, average loss: 1.3095
[09/26 10:27:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:27:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/26 10:27:42 visual_prompt]: Epoch 55 / 100: avg data time: 6.39e-02, avg batch time: 0.5045, average train loss: 0.0001
[09/26 10:27:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.3111
[09/26 10:27:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 10:27:44 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/26 10:27:51 visual_prompt]: Epoch 56 / 100: avg data time: 6.11e-02, avg batch time: 0.5024, average train loss: 0.0001
[09/26 10:27:52 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 1.3125
[09/26 10:27:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 10:27:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/26 10:27:59 visual_prompt]: Epoch 57 / 100: avg data time: 5.21e-02, avg batch time: 0.4946, average train loss: 0.0001
[09/26 10:28:01 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1661, average loss: 1.3081
[09/26 10:28:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 10:28:01 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/26 10:28:07 visual_prompt]: Epoch 58 / 100: avg data time: 4.66e-02, avg batch time: 0.4888, average train loss: 0.0001
[09/26 10:28:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 1.3049
[09/26 10:28:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 10:28:09 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/26 10:28:16 visual_prompt]: Epoch 59 / 100: avg data time: 6.18e-02, avg batch time: 0.5027, average train loss: 0.0001
[09/26 10:28:17 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 1.3039
[09/26 10:28:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 10:28:17 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/26 10:28:24 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.4995, average train loss: 0.0001
[09/26 10:28:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.3041
[09/26 10:28:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:28:26 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/26 10:28:33 visual_prompt]: Epoch 61 / 100: avg data time: 6.30e-02, avg batch time: 0.5039, average train loss: 0.0002
[09/26 10:28:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 1.3043
[09/26 10:28:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:28:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/26 10:28:41 visual_prompt]: Epoch 62 / 100: avg data time: 6.28e-02, avg batch time: 0.5043, average train loss: 0.0001
[09/26 10:28:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 1.3047
[09/26 10:28:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:28:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/26 10:28:50 visual_prompt]: Epoch 63 / 100: avg data time: 6.98e-02, avg batch time: 0.5107, average train loss: 0.0001
[09/26 10:28:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.3051
[09/26 10:28:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:28:51 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/26 10:28:58 visual_prompt]: Epoch 64 / 100: avg data time: 5.98e-02, avg batch time: 0.5018, average train loss: 0.0010
[09/26 10:29:00 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.3448
[09/26 10:29:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:29:00 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/26 10:29:07 visual_prompt]: Epoch 65 / 100: avg data time: 6.31e-02, avg batch time: 0.5049, average train loss: 0.0007
[09/26 10:29:08 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 1.3815
[09/26 10:29:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 10:29:08 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/26 10:29:15 visual_prompt]: Epoch 66 / 100: avg data time: 6.62e-02, avg batch time: 0.5082, average train loss: 0.0002
[09/26 10:29:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 1.3755
[09/26 10:29:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:17 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/26 10:29:24 visual_prompt]: Epoch 67 / 100: avg data time: 6.22e-02, avg batch time: 0.5030, average train loss: 0.0001
[09/26 10:29:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 1.3750
[09/26 10:29:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:25 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/26 10:29:32 visual_prompt]: Epoch 68 / 100: avg data time: 5.94e-02, avg batch time: 0.5010, average train loss: 0.0001
[09/26 10:29:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.3762
[09/26 10:29:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:34 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/26 10:29:41 visual_prompt]: Epoch 69 / 100: avg data time: 6.47e-02, avg batch time: 0.5057, average train loss: 0.0001
[09/26 10:29:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 1.3766
[09/26 10:29:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:42 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/26 10:29:49 visual_prompt]: Epoch 70 / 100: avg data time: 5.41e-02, avg batch time: 0.4965, average train loss: 0.0001
[09/26 10:29:51 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1660, average loss: 1.3760
[09/26 10:29:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:51 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/26 10:29:58 visual_prompt]: Epoch 71 / 100: avg data time: 6.29e-02, avg batch time: 0.5038, average train loss: 0.0001
[09/26 10:29:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.3754
[09/26 10:29:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:29:59 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/26 10:30:06 visual_prompt]: Epoch 72 / 100: avg data time: 6.30e-02, avg batch time: 0.5037, average train loss: 0.0001
[09/26 10:30:08 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 1.3764
[09/26 10:30:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:08 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/26 10:30:15 visual_prompt]: Epoch 73 / 100: avg data time: 5.94e-02, avg batch time: 0.5004, average train loss: 0.0001
[09/26 10:30:16 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 1.3768
[09/26 10:30:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:16 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/26 10:30:23 visual_prompt]: Epoch 74 / 100: avg data time: 6.21e-02, avg batch time: 0.5032, average train loss: 0.0001
[09/26 10:30:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 1.3770
[09/26 10:30:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:25 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/26 10:30:32 visual_prompt]: Epoch 75 / 100: avg data time: 6.12e-02, avg batch time: 0.5021, average train loss: 0.0003
[09/26 10:30:33 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1661, average loss: 1.3751
[09/26 10:30:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:33 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/26 10:30:40 visual_prompt]: Epoch 76 / 100: avg data time: 5.98e-02, avg batch time: 0.5018, average train loss: 0.0001
[09/26 10:30:42 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 1.3753
[09/26 10:30:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:42 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/26 10:30:49 visual_prompt]: Epoch 77 / 100: avg data time: 6.03e-02, avg batch time: 0.5014, average train loss: 0.0002
[09/26 10:30:50 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 1.3718
[09/26 10:30:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:50 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/26 10:30:57 visual_prompt]: Epoch 78 / 100: avg data time: 6.41e-02, avg batch time: 0.5062, average train loss: 0.0001
[09/26 10:30:59 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 1.3707
[09/26 10:30:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:30:59 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/26 10:31:06 visual_prompt]: Epoch 79 / 100: avg data time: 6.13e-02, avg batch time: 0.5023, average train loss: 0.0000
[09/26 10:31:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 1.3706
[09/26 10:31:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:07 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/26 10:31:14 visual_prompt]: Epoch 80 / 100: avg data time: 6.87e-02, avg batch time: 0.5097, average train loss: 0.0000
[09/26 10:31:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.3706
[09/26 10:31:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:16 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/26 10:31:23 visual_prompt]: Epoch 81 / 100: avg data time: 6.44e-02, avg batch time: 0.5054, average train loss: 0.0001
[09/26 10:31:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 1.3706
[09/26 10:31:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:25 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/26 10:31:31 visual_prompt]: Epoch 82 / 100: avg data time: 6.10e-02, avg batch time: 0.5032, average train loss: 0.0000
[09/26 10:31:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.3707
[09/26 10:31:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:33 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/26 10:31:40 visual_prompt]: Epoch 83 / 100: avg data time: 6.35e-02, avg batch time: 0.5055, average train loss: 0.0001
[09/26 10:31:41 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.3710
[09/26 10:31:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:41 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/26 10:31:48 visual_prompt]: Epoch 84 / 100: avg data time: 6.92e-02, avg batch time: 0.5103, average train loss: 0.0001
[09/26 10:31:50 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.3714
[09/26 10:31:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:50 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/26 10:31:57 visual_prompt]: Epoch 85 / 100: avg data time: 5.23e-02, avg batch time: 0.4944, average train loss: 0.0001
[09/26 10:31:58 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.3715
[09/26 10:31:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:31:58 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/26 10:32:05 visual_prompt]: Epoch 86 / 100: avg data time: 6.61e-02, avg batch time: 0.5093, average train loss: 0.0001
[09/26 10:32:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 1.3715
[09/26 10:32:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:07 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/26 10:32:14 visual_prompt]: Epoch 87 / 100: avg data time: 6.57e-02, avg batch time: 0.5069, average train loss: 0.0001
[09/26 10:32:15 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.3716
[09/26 10:32:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:15 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/26 10:32:22 visual_prompt]: Epoch 88 / 100: avg data time: 4.92e-02, avg batch time: 0.4909, average train loss: 0.0001
[09/26 10:32:24 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 1.3717
[09/26 10:32:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:24 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/26 10:32:31 visual_prompt]: Epoch 89 / 100: avg data time: 5.53e-02, avg batch time: 0.4976, average train loss: 0.0000
[09/26 10:32:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 1.3717
[09/26 10:32:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:32 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/26 10:32:39 visual_prompt]: Epoch 90 / 100: avg data time: 6.43e-02, avg batch time: 0.5059, average train loss: 0.0001
[09/26 10:32:41 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 1.3717
[09/26 10:32:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:41 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/26 10:32:48 visual_prompt]: Epoch 91 / 100: avg data time: 6.86e-02, avg batch time: 0.5095, average train loss: 0.0002
[09/26 10:32:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.3720
[09/26 10:32:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:49 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/26 10:32:56 visual_prompt]: Epoch 92 / 100: avg data time: 6.66e-02, avg batch time: 0.5086, average train loss: 0.0001
[09/26 10:32:58 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.3721
[09/26 10:32:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:32:58 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/26 10:33:05 visual_prompt]: Epoch 93 / 100: avg data time: 6.02e-02, avg batch time: 0.5011, average train loss: 0.0000
[09/26 10:33:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1661, average loss: 1.3721
[09/26 10:33:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:06 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/26 10:33:13 visual_prompt]: Epoch 94 / 100: avg data time: 5.57e-02, avg batch time: 0.4975, average train loss: 0.0001
[09/26 10:33:15 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.3721
[09/26 10:33:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:15 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/26 10:33:21 visual_prompt]: Epoch 95 / 100: avg data time: 5.29e-02, avg batch time: 0.4939, average train loss: 0.0001
[09/26 10:33:23 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.3721
[09/26 10:33:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:23 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/26 10:33:30 visual_prompt]: Epoch 96 / 100: avg data time: 6.78e-02, avg batch time: 0.5088, average train loss: 0.0001
[09/26 10:33:32 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.3722
[09/26 10:33:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:32 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/26 10:33:39 visual_prompt]: Epoch 97 / 100: avg data time: 7.19e-02, avg batch time: 0.5129, average train loss: 0.0001
[09/26 10:33:40 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.3722
[09/26 10:33:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:40 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/26 10:33:47 visual_prompt]: Epoch 98 / 100: avg data time: 6.60e-02, avg batch time: 0.5073, average train loss: 0.0001
[09/26 10:33:49 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 1.3722
[09/26 10:33:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:49 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/26 10:33:56 visual_prompt]: Epoch 99 / 100: avg data time: 6.28e-02, avg batch time: 0.5037, average train loss: 0.0001
[09/26 10:33:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 1.3722
[09/26 10:33:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:33:57 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/26 10:34:04 visual_prompt]: Epoch 100 / 100: avg data time: 6.78e-02, avg batch time: 0.5084, average train loss: 0.0001
[09/26 10:34:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 1.3722
[09/26 10:34:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 10:34:06 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:34:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:34:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:34:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:34:06 visual_prompt]: Training with config:
[09/26 10:34:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:34:06 visual_prompt]: Loading training data...
[09/26 10:34:06 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:34:07 visual_prompt]: Number of images: 800
[09/26 10:34:07 visual_prompt]: Number of classes: 45 / 45
[09/26 10:34:07 visual_prompt]: Loading validation data...
[09/26 10:34:07 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:34:08 visual_prompt]: Number of images: 200
[09/26 10:34:08 visual_prompt]: Number of classes: 45 / 45
[09/26 10:34:08 visual_prompt]: Constructing models...
[09/26 10:34:10 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 10:34:10 visual_prompt]: tuned percent:0.574
[09/26 10:34:10 visual_prompt]: Device used for model: 0
[09/26 10:34:10 visual_prompt]: Setting up Evaluator...
[09/26 10:34:10 visual_prompt]: Setting up Trainer...
[09/26 10:34:10 visual_prompt]: 	Setting up the optimizer...
[09/26 10:34:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:34:17 visual_prompt]: Epoch 1 / 100: avg data time: 5.99e-02, avg batch time: 0.4992, average train loss: 3.8880
[09/26 10:34:18 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 10:34:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 10:34:18 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 10:34:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 10:34:25 visual_prompt]: Epoch 2 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 3.8215
[09/26 10:34:27 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1656, average loss: 3.7779
[09/26 10:34:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 18.50	
[09/26 10:34:27 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 10:34:27 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 10:34:34 visual_prompt]: Epoch 3 / 100: avg data time: 6.20e-02, avg batch time: 0.5031, average train loss: 3.7786
[09/26 10:34:35 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 3.9373
[09/26 10:34:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 14.00	
[09/26 10:34:35 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 10:34:42 visual_prompt]: Epoch 4 / 100: avg data time: 5.65e-02, avg batch time: 0.4971, average train loss: 3.8603
[09/26 10:34:44 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 3.8652
[09/26 10:34:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 14.50	
[09/26 10:34:44 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 10:34:50 visual_prompt]: Epoch 5 / 100: avg data time: 6.07e-02, avg batch time: 0.5018, average train loss: 3.8744
[09/26 10:34:52 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 3.8283
[09/26 10:34:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 10:34:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 10:34:59 visual_prompt]: Epoch 6 / 100: avg data time: 6.61e-02, avg batch time: 0.5068, average train loss: 3.8594
[09/26 10:35:01 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 4.1314
[09/26 10:35:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 10:35:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 10:35:07 visual_prompt]: Epoch 7 / 100: avg data time: 6.23e-02, avg batch time: 0.5041, average train loss: 4.0106
[09/26 10:35:09 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1658, average loss: 3.9944
[09/26 10:35:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 12.00	
[09/26 10:35:09 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 10:35:16 visual_prompt]: Epoch 8 / 100: avg data time: 6.36e-02, avg batch time: 0.5056, average train loss: 3.9802
[09/26 10:35:18 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 4.1320
[09/26 10:35:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 10:35:18 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 10:35:24 visual_prompt]: Epoch 9 / 100: avg data time: 6.36e-02, avg batch time: 0.5036, average train loss: 3.9650
[09/26 10:35:26 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1660, average loss: 3.9500
[09/26 10:35:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 10:35:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 10:35:33 visual_prompt]: Epoch 10 / 100: avg data time: 6.93e-02, avg batch time: 0.5102, average train loss: 3.9975
[09/26 10:35:35 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 3.9389
[09/26 10:35:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 10:35:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 10:35:41 visual_prompt]: Epoch 11 / 100: avg data time: 6.82e-02, avg batch time: 0.5097, average train loss: 4.0466
[09/26 10:35:43 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1662, average loss: 4.1854
[09/26 10:35:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 10:35:43 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 10:35:50 visual_prompt]: Epoch 12 / 100: avg data time: 6.44e-02, avg batch time: 0.5056, average train loss: 4.0108
[09/26 10:35:52 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 5.1019
[09/26 10:35:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 10:35:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 10:35:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.71e-02, avg batch time: 0.4991, average train loss: 4.2481
[09/26 10:36:00 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 4.0973
[09/26 10:36:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 10:36:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 10:36:07 visual_prompt]: Epoch 14 / 100: avg data time: 6.70e-02, avg batch time: 0.5078, average train loss: 3.9934
[09/26 10:36:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 4.0355
[09/26 10:36:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 10:36:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 10:36:16 visual_prompt]: Epoch 15 / 100: avg data time: 6.49e-02, avg batch time: 0.5068, average train loss: 3.9904
[09/26 10:36:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 3.9266
[09/26 10:36:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 10:36:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 10:36:24 visual_prompt]: Epoch 16 / 100: avg data time: 7.06e-02, avg batch time: 0.5115, average train loss: 3.9954
[09/26 10:36:26 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 3.9959
[09/26 10:36:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 10:36:26 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 10:36:33 visual_prompt]: Epoch 17 / 100: avg data time: 6.05e-02, avg batch time: 0.5024, average train loss: 4.0210
[09/26 10:36:35 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 4.0932
[09/26 10:36:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 6.00	
[09/26 10:36:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 10:36:41 visual_prompt]: Epoch 18 / 100: avg data time: 6.56e-02, avg batch time: 0.5068, average train loss: 3.9780
[09/26 10:36:43 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 3.9927
[09/26 10:36:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 10:36:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 10:36:50 visual_prompt]: Epoch 19 / 100: avg data time: 6.04e-02, avg batch time: 0.5009, average train loss: 4.0937
[09/26 10:36:52 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1662, average loss: 4.1986
[09/26 10:36:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 10:36:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 10:36:58 visual_prompt]: Epoch 20 / 100: avg data time: 6.51e-02, avg batch time: 0.5058, average train loss: 4.0291
[09/26 10:37:00 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 4.1844
[09/26 10:37:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 10:37:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 10:37:07 visual_prompt]: Epoch 21 / 100: avg data time: 5.85e-02, avg batch time: 0.5006, average train loss: 3.9869
[09/26 10:37:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 3.9391
[09/26 10:37:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 9.00	
[09/26 10:37:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 10:37:16 visual_prompt]: Epoch 22 / 100: avg data time: 5.85e-02, avg batch time: 0.5012, average train loss: 3.9656
[09/26 10:37:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1658, average loss: 3.8445
[09/26 10:37:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 10:37:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 10:37:24 visual_prompt]: Epoch 23 / 100: avg data time: 4.93e-02, avg batch time: 0.4903, average train loss: 3.9959
[09/26 10:37:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 3.9118
[09/26 10:37:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:37:25 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 10:37:32 visual_prompt]: Epoch 24 / 100: avg data time: 5.72e-02, avg batch time: 0.4985, average train loss: 3.9581
[09/26 10:37:34 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1658, average loss: 3.9221
[09/26 10:37:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.50	
[09/26 10:37:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 10:37:40 visual_prompt]: Epoch 25 / 100: avg data time: 4.74e-02, avg batch time: 0.4893, average train loss: 3.9292
[09/26 10:37:42 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 4.0398
[09/26 10:37:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 10:37:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 10:37:49 visual_prompt]: Epoch 26 / 100: avg data time: 4.98e-02, avg batch time: 0.4930, average train loss: 3.9493
[09/26 10:37:51 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1662, average loss: 3.8794
[09/26 10:37:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 10:37:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 10:37:57 visual_prompt]: Epoch 27 / 100: avg data time: 6.15e-02, avg batch time: 0.5024, average train loss: 3.9444
[09/26 10:37:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1660, average loss: 4.0456
[09/26 10:37:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 10:37:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 10:38:06 visual_prompt]: Epoch 28 / 100: avg data time: 4.87e-02, avg batch time: 0.4913, average train loss: 3.9852
[09/26 10:38:07 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 3.9926
[09/26 10:38:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 10:38:07 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 10:38:14 visual_prompt]: Epoch 29 / 100: avg data time: 5.90e-02, avg batch time: 0.5029, average train loss: 3.9694
[09/26 10:38:16 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 6.0081
[09/26 10:38:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 13.50	
[09/26 10:38:16 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 10:38:23 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e-02, avg batch time: 0.4920, average train loss: 4.4090
[09/26 10:38:24 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 4.8487
[09/26 10:38:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 10:38:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 10:38:31 visual_prompt]: Epoch 31 / 100: avg data time: 5.62e-02, avg batch time: 0.4978, average train loss: 4.3562
[09/26 10:38:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1658, average loss: 4.2626
[09/26 10:38:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 10:38:33 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 10:38:40 visual_prompt]: Epoch 32 / 100: avg data time: 6.52e-02, avg batch time: 0.5055, average train loss: 4.0920
[09/26 10:38:41 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1658, average loss: 4.1604
[09/26 10:38:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 10:38:41 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 10:38:48 visual_prompt]: Epoch 33 / 100: avg data time: 5.84e-02, avg batch time: 0.5001, average train loss: 4.1526
[09/26 10:38:50 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1658, average loss: 3.9731
[09/26 10:38:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 10:38:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 10:38:56 visual_prompt]: Epoch 34 / 100: avg data time: 5.24e-02, avg batch time: 0.4936, average train loss: 3.9765
[09/26 10:38:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1658, average loss: 3.9050
[09/26 10:38:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 10:38:58 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 10:39:05 visual_prompt]: Epoch 35 / 100: avg data time: 4.75e-02, avg batch time: 0.4920, average train loss: 3.9517
[09/26 10:39:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 3.9511
[09/26 10:39:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 10:39:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 10:39:13 visual_prompt]: Epoch 36 / 100: avg data time: 6.02e-02, avg batch time: 0.5018, average train loss: 3.9065
[09/26 10:39:15 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1657, average loss: 4.0157
[09/26 10:39:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 10:39:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 10:39:21 visual_prompt]: Epoch 37 / 100: avg data time: 4.92e-02, avg batch time: 0.4904, average train loss: 4.0172
[09/26 10:39:23 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1653, average loss: 3.9208
[09/26 10:39:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 10:39:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 10:39:30 visual_prompt]: Epoch 38 / 100: avg data time: 5.96e-02, avg batch time: 0.4996, average train loss: 3.9475
[09/26 10:39:31 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1658, average loss: 3.9629
[09/26 10:39:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 10:39:31 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 10:39:38 visual_prompt]: Epoch 39 / 100: avg data time: 4.93e-02, avg batch time: 0.4910, average train loss: 3.9638
[09/26 10:39:40 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1657, average loss: 4.2166
[09/26 10:39:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 10:39:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 10:39:46 visual_prompt]: Epoch 40 / 100: avg data time: 5.06e-02, avg batch time: 0.4917, average train loss: 3.9907
[09/26 10:39:48 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1654, average loss: 4.1719
[09/26 10:39:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.50	
[09/26 10:39:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 10:39:55 visual_prompt]: Epoch 41 / 100: avg data time: 5.15e-02, avg batch time: 0.4928, average train loss: 3.9758
[09/26 10:39:56 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 4.1717
[09/26 10:39:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:39:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 10:40:03 visual_prompt]: Epoch 42 / 100: avg data time: 5.71e-02, avg batch time: 0.4973, average train loss: 3.9995
[09/26 10:40:05 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1657, average loss: 4.0577
[09/26 10:40:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.50	
[09/26 10:40:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 10:40:11 visual_prompt]: Epoch 43 / 100: avg data time: 5.77e-02, avg batch time: 0.4992, average train loss: 3.9920
[09/26 10:40:13 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 3.9902
[09/26 10:40:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 10:40:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 10:40:20 visual_prompt]: Epoch 44 / 100: avg data time: 5.49e-02, avg batch time: 0.4963, average train loss: 4.0479
[09/26 10:40:21 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1656, average loss: 3.9823
[09/26 10:40:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.00	
[09/26 10:40:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 10:40:28 visual_prompt]: Epoch 45 / 100: avg data time: 6.47e-02, avg batch time: 0.5065, average train loss: 4.0551
[09/26 10:40:30 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1654, average loss: 4.0188
[09/26 10:40:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 10:40:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 10:40:37 visual_prompt]: Epoch 46 / 100: avg data time: 6.85e-02, avg batch time: 0.5086, average train loss: 3.9110
[09/26 10:40:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1656, average loss: 4.1515
[09/26 10:40:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 10:40:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 10:40:45 visual_prompt]: Epoch 47 / 100: avg data time: 5.93e-02, avg batch time: 0.4996, average train loss: 3.9876
[09/26 10:40:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 3.9618
[09/26 10:40:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 10:40:47 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 10:40:54 visual_prompt]: Epoch 48 / 100: avg data time: 5.99e-02, avg batch time: 0.5010, average train loss: 3.9337
[09/26 10:40:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 3.9450
[09/26 10:40:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 10.50	
[09/26 10:40:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 10:41:02 visual_prompt]: Epoch 49 / 100: avg data time: 6.72e-02, avg batch time: 0.5082, average train loss: 3.9475
[09/26 10:41:04 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1655, average loss: 3.9040
[09/26 10:41:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 10:41:04 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 10:41:11 visual_prompt]: Epoch 50 / 100: avg data time: 5.94e-02, avg batch time: 0.4990, average train loss: 3.9184
[09/26 10:41:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 3.9004
[09/26 10:41:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.00	
[09/26 10:41:12 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 10:41:19 visual_prompt]: Epoch 51 / 100: avg data time: 5.60e-02, avg batch time: 0.4967, average train loss: 3.9312
[09/26 10:41:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1657, average loss: 3.8957
[09/26 10:41:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 10:41:21 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 10:41:27 visual_prompt]: Epoch 52 / 100: avg data time: 4.91e-02, avg batch time: 0.4907, average train loss: 3.8782
[09/26 10:41:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1657, average loss: 3.9533
[09/26 10:41:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.00	
[09/26 10:41:29 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 10:41:36 visual_prompt]: Epoch 53 / 100: avg data time: 5.19e-02, avg batch time: 0.4929, average train loss: 3.8747
[09/26 10:41:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1657, average loss: 3.9656
[09/26 10:41:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 10:41:37 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 10:41:44 visual_prompt]: Epoch 54 / 100: avg data time: 5.06e-02, avg batch time: 0.4924, average train loss: 3.9286
[09/26 10:41:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 3.9058
[09/26 10:41:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 10:41:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 10:41:52 visual_prompt]: Epoch 55 / 100: avg data time: 5.24e-02, avg batch time: 0.4931, average train loss: 3.8767
[09/26 10:41:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1658, average loss: 3.8684
[09/26 10:41:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 10:41:54 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 10:42:01 visual_prompt]: Epoch 56 / 100: avg data time: 5.45e-02, avg batch time: 0.4974, average train loss: 3.8745
[09/26 10:42:02 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 3.9313
[09/26 10:42:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 10:42:02 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 10:42:09 visual_prompt]: Epoch 57 / 100: avg data time: 5.02e-02, avg batch time: 0.4921, average train loss: 3.8847
[09/26 10:42:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 3.8612
[09/26 10:42:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 9.50	
[09/26 10:42:11 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 10:42:17 visual_prompt]: Epoch 58 / 100: avg data time: 5.46e-02, avg batch time: 0.4961, average train loss: 3.8804
[09/26 10:42:19 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1657, average loss: 3.8828
[09/26 10:42:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 10:42:19 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 10:42:26 visual_prompt]: Epoch 59 / 100: avg data time: 5.53e-02, avg batch time: 0.4963, average train loss: 3.8744
[09/26 10:42:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 3.8679
[09/26 10:42:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 14.50	
[09/26 10:42:27 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 10:42:34 visual_prompt]: Epoch 60 / 100: avg data time: 5.51e-02, avg batch time: 0.4978, average train loss: 3.8546
[09/26 10:42:36 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1659, average loss: 3.8551
[09/26 10:42:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 10:42:36 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 10:42:43 visual_prompt]: Epoch 61 / 100: avg data time: 5.07e-02, avg batch time: 0.4926, average train loss: 3.8766
[09/26 10:42:44 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 3.8725
[09/26 10:42:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 10:42:44 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 10:42:51 visual_prompt]: Epoch 62 / 100: avg data time: 5.79e-02, avg batch time: 0.4993, average train loss: 3.8358
[09/26 10:42:53 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1659, average loss: 3.8917
[09/26 10:42:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 8.00	
[09/26 10:42:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 10:42:59 visual_prompt]: Epoch 63 / 100: avg data time: 6.03e-02, avg batch time: 0.5009, average train loss: 3.8590
[09/26 10:43:01 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 3.8286
[09/26 10:43:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 10:43:01 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 10:43:08 visual_prompt]: Epoch 64 / 100: avg data time: 5.48e-02, avg batch time: 0.4966, average train loss: 3.8453
[09/26 10:43:09 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 3.8792
[09/26 10:43:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 10:43:09 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 10:43:16 visual_prompt]: Epoch 65 / 100: avg data time: 6.06e-02, avg batch time: 0.5014, average train loss: 3.8537
[09/26 10:43:18 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 3.8558
[09/26 10:43:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 10:43:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 10:43:24 visual_prompt]: Epoch 66 / 100: avg data time: 4.73e-02, avg batch time: 0.4905, average train loss: 3.8243
[09/26 10:43:26 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 3.8394
[09/26 10:43:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 7.00	
[09/26 10:43:26 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 10:43:33 visual_prompt]: Epoch 67 / 100: avg data time: 5.48e-02, avg batch time: 0.4967, average train loss: 3.8267
[09/26 10:43:34 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 3.8265
[09/26 10:43:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 12.00	
[09/26 10:43:34 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 10:43:41 visual_prompt]: Epoch 68 / 100: avg data time: 5.16e-02, avg batch time: 0.4930, average train loss: 3.8338
[09/26 10:43:43 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 3.8251
[09/26 10:43:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 10:43:43 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 10:43:49 visual_prompt]: Epoch 69 / 100: avg data time: 5.59e-02, avg batch time: 0.4984, average train loss: 3.8357
[09/26 10:43:51 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1659, average loss: 3.8836
[09/26 10:43:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 10:43:51 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 10:43:58 visual_prompt]: Epoch 70 / 100: avg data time: 6.59e-02, avg batch time: 0.5072, average train loss: 3.8538
[09/26 10:43:59 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 3.8710
[09/26 10:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:43:59 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 10:44:06 visual_prompt]: Epoch 71 / 100: avg data time: 6.44e-02, avg batch time: 0.5062, average train loss: 3.8331
[09/26 10:44:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 3.8483
[09/26 10:44:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 10:44:08 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 10:44:15 visual_prompt]: Epoch 72 / 100: avg data time: 7.59e-02, avg batch time: 0.5167, average train loss: 3.8248
[09/26 10:44:17 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1659, average loss: 3.8529
[09/26 10:44:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 10:44:17 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 10:44:24 visual_prompt]: Epoch 73 / 100: avg data time: 6.88e-02, avg batch time: 0.5095, average train loss: 3.8166
[09/26 10:44:25 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 3.8138
[09/26 10:44:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 12.50	
[09/26 10:44:25 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 10:44:32 visual_prompt]: Epoch 74 / 100: avg data time: 6.97e-02, avg batch time: 0.5121, average train loss: 3.7892
[09/26 10:44:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1659, average loss: 3.8350
[09/26 10:44:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 10:44:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 10:44:41 visual_prompt]: Epoch 75 / 100: avg data time: 6.30e-02, avg batch time: 0.5039, average train loss: 3.7988
[09/26 10:44:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1659, average loss: 3.8725
[09/26 10:44:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.50	
[09/26 10:44:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 10:44:49 visual_prompt]: Epoch 76 / 100: avg data time: 5.18e-02, avg batch time: 0.4967, average train loss: 3.8420
[09/26 10:44:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1661, average loss: 3.8620
[09/26 10:44:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:44:51 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 10:44:58 visual_prompt]: Epoch 77 / 100: avg data time: 5.88e-02, avg batch time: 0.5006, average train loss: 3.8256
[09/26 10:44:59 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 3.8359
[09/26 10:44:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.50	
[09/26 10:44:59 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 10:45:06 visual_prompt]: Epoch 78 / 100: avg data time: 6.52e-02, avg batch time: 0.5061, average train loss: 3.8046
[09/26 10:45:08 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1662, average loss: 3.8346
[09/26 10:45:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 10:45:08 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 10:45:15 visual_prompt]: Epoch 79 / 100: avg data time: 7.21e-02, avg batch time: 0.5129, average train loss: 3.7917
[09/26 10:45:16 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1659, average loss: 3.8273
[09/26 10:45:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:45:16 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 10:45:23 visual_prompt]: Epoch 80 / 100: avg data time: 5.46e-02, avg batch time: 0.4951, average train loss: 3.8100
[09/26 10:45:25 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1657, average loss: 3.8369
[09/26 10:45:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 10:45:25 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 10:45:32 visual_prompt]: Epoch 81 / 100: avg data time: 6.88e-02, avg batch time: 0.5100, average train loss: 3.8181
[09/26 10:45:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1657, average loss: 3.8384
[09/26 10:45:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 10:45:33 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 10:45:40 visual_prompt]: Epoch 82 / 100: avg data time: 6.49e-02, avg batch time: 0.5049, average train loss: 3.7923
[09/26 10:45:42 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1658, average loss: 3.7930
[09/26 10:45:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 9.50	
[09/26 10:45:42 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 10:45:49 visual_prompt]: Epoch 83 / 100: avg data time: 5.36e-02, avg batch time: 0.4953, average train loss: 3.7747
[09/26 10:45:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 3.7969
[09/26 10:45:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 17.50	
[09/26 10:45:50 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 10:45:57 visual_prompt]: Epoch 84 / 100: avg data time: 6.42e-02, avg batch time: 0.5058, average train loss: 3.7807
[09/26 10:45:59 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1658, average loss: 3.8377
[09/26 10:45:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.50	
[09/26 10:45:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 10:46:06 visual_prompt]: Epoch 85 / 100: avg data time: 6.53e-02, avg batch time: 0.5069, average train loss: 3.7811
[09/26 10:46:08 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1657, average loss: 3.8562
[09/26 10:46:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 10:46:08 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 10:46:15 visual_prompt]: Epoch 86 / 100: avg data time: 6.52e-02, avg batch time: 0.5064, average train loss: 3.7908
[09/26 10:46:16 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1658, average loss: 3.8211
[09/26 10:46:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.50	
[09/26 10:46:16 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 10:46:23 visual_prompt]: Epoch 87 / 100: avg data time: 5.67e-02, avg batch time: 0.4979, average train loss: 3.7481
[09/26 10:46:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1658, average loss: 3.7233
[09/26 10:46:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 19.50	
[09/26 10:46:25 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 10:46:32 visual_prompt]: Epoch 88 / 100: avg data time: 6.63e-02, avg batch time: 0.5070, average train loss: 3.6587
[09/26 10:46:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1656, average loss: 3.6486
[09/26 10:46:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 19.50	
[09/26 10:46:33 visual_prompt]: Best epoch 88: best metric: 0.045
[09/26 10:46:33 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 10:46:40 visual_prompt]: Epoch 89 / 100: avg data time: 4.82e-02, avg batch time: 0.4900, average train loss: 3.6372
[09/26 10:46:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1655, average loss: 3.5948
[09/26 10:46:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 23.00	
[09/26 10:46:42 visual_prompt]: Best epoch 89: best metric: 0.080
[09/26 10:46:42 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 10:46:49 visual_prompt]: Epoch 90 / 100: avg data time: 5.80e-02, avg batch time: 0.4997, average train loss: 3.7137
[09/26 10:46:50 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1660, average loss: 3.7821
[09/26 10:46:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.00	
[09/26 10:46:50 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 10:46:57 visual_prompt]: Epoch 91 / 100: avg data time: 5.90e-02, avg batch time: 0.4998, average train loss: 3.7537
[09/26 10:46:59 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1658, average loss: 3.7308
[09/26 10:46:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 10:46:59 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 10:47:05 visual_prompt]: Epoch 92 / 100: avg data time: 4.99e-02, avg batch time: 0.4921, average train loss: 3.6377
[09/26 10:47:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1657, average loss: 3.5540
[09/26 10:47:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 23.00	
[09/26 10:47:07 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 10:47:14 visual_prompt]: Epoch 93 / 100: avg data time: 5.92e-02, avg batch time: 0.4998, average train loss: 3.5126
[09/26 10:47:15 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1655, average loss: 3.4489
[09/26 10:47:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 27.50	
[09/26 10:47:15 visual_prompt]: Best epoch 93: best metric: 0.085
[09/26 10:47:15 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 10:47:22 visual_prompt]: Epoch 94 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 3.4187
[09/26 10:47:24 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1658, average loss: 3.5361
[09/26 10:47:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 25.50	
[09/26 10:47:24 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 10:47:30 visual_prompt]: Epoch 95 / 100: avg data time: 5.63e-02, avg batch time: 0.4982, average train loss: 3.3989
[09/26 10:47:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1657, average loss: 3.4052
[09/26 10:47:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 27.00	
[09/26 10:47:32 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 10:47:39 visual_prompt]: Epoch 96 / 100: avg data time: 5.36e-02, avg batch time: 0.4942, average train loss: 3.3684
[09/26 10:47:40 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1657, average loss: 3.3993
[09/26 10:47:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 27.50	
[09/26 10:47:40 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 10:47:47 visual_prompt]: Epoch 97 / 100: avg data time: 5.30e-02, avg batch time: 0.4931, average train loss: 3.3379
[09/26 10:47:49 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1657, average loss: 3.3278
[09/26 10:47:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 29.50	
[09/26 10:47:49 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 10:47:55 visual_prompt]: Epoch 98 / 100: avg data time: 4.73e-02, avg batch time: 0.4888, average train loss: 3.3008
[09/26 10:47:57 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1658, average loss: 3.3334
[09/26 10:47:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 28.50	
[09/26 10:47:57 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 10:48:04 visual_prompt]: Epoch 99 / 100: avg data time: 5.84e-02, avg batch time: 0.4992, average train loss: 3.2852
[09/26 10:48:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1658, average loss: 3.3065
[09/26 10:48:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 27.50	
[09/26 10:48:06 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 10:48:12 visual_prompt]: Epoch 100 / 100: avg data time: 5.15e-02, avg batch time: 0.4945, average train loss: 3.2536
[09/26 10:48:14 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1658, average loss: 3.3028
[09/26 10:48:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 28.00	
[09/26 10:48:14 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 10:48:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 10:48:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 10:48:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 10:48:14 visual_prompt]: Training with config:
[09/26 10:48:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 10:48:14 visual_prompt]: Loading training data...
[09/26 10:48:14 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:48:15 visual_prompt]: Number of images: 800
[09/26 10:48:15 visual_prompt]: Number of classes: 45 / 45
[09/26 10:48:15 visual_prompt]: Loading validation data...
[09/26 10:48:15 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 10:48:15 visual_prompt]: Number of images: 200
[09/26 10:48:15 visual_prompt]: Number of classes: 45 / 45
[09/26 10:48:15 visual_prompt]: Constructing models...
[09/26 10:48:18 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 10:48:18 visual_prompt]: tuned percent:0.574
[09/26 10:48:18 visual_prompt]: Device used for model: 0
[09/26 10:48:18 visual_prompt]: Setting up Evaluator...
[09/26 10:48:18 visual_prompt]: Setting up Trainer...
[09/26 10:48:18 visual_prompt]: 	Setting up the optimizer...
[09/26 10:48:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 10:48:25 visual_prompt]: Epoch 1 / 100: avg data time: 6.61e-02, avg batch time: 0.5060, average train loss: 3.8931
[09/26 10:48:27 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 10:48:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 10:48:27 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 10:48:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 10:48:33 visual_prompt]: Epoch 2 / 100: avg data time: 5.27e-02, avg batch time: 0.4938, average train loss: 3.8473
[09/26 10:48:35 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1656, average loss: 3.8089
[09/26 10:48:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.00	
[09/26 10:48:35 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 10:48:35 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 10:48:42 visual_prompt]: Epoch 3 / 100: avg data time: 6.41e-02, avg batch time: 0.5041, average train loss: 3.7294
[09/26 10:48:44 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1657, average loss: 3.6435
[09/26 10:48:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 24.00	
[09/26 10:48:44 visual_prompt]: Best epoch 3: best metric: 0.075
[09/26 10:48:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 10:48:50 visual_prompt]: Epoch 4 / 100: avg data time: 5.21e-02, avg batch time: 0.4921, average train loss: 3.5748
[09/26 10:48:52 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1660, average loss: 3.3948
[09/26 10:48:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 28.00	
[09/26 10:48:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 10:48:59 visual_prompt]: Epoch 5 / 100: avg data time: 5.38e-02, avg batch time: 0.4958, average train loss: 3.4920
[09/26 10:49:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 3.2324
[09/26 10:49:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 40.00	
[09/26 10:49:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 10:49:07 visual_prompt]: Epoch 6 / 100: avg data time: 6.75e-02, avg batch time: 0.5082, average train loss: 3.1798
[09/26 10:49:09 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1659, average loss: 4.4680
[09/26 10:49:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 26.00	
[09/26 10:49:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 10:49:16 visual_prompt]: Epoch 7 / 100: avg data time: 5.78e-02, avg batch time: 0.5007, average train loss: 3.6490
[09/26 10:49:17 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1659, average loss: 3.7070
[09/26 10:49:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 22.50	
[09/26 10:49:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 10:49:24 visual_prompt]: Epoch 8 / 100: avg data time: 5.73e-02, avg batch time: 0.4982, average train loss: 3.4075
[09/26 10:49:26 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1660, average loss: 3.9190
[09/26 10:49:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 30.00	
[09/26 10:49:26 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 10:49:33 visual_prompt]: Epoch 9 / 100: avg data time: 5.15e-02, avg batch time: 0.4956, average train loss: 3.3640
[09/26 10:49:34 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 3.2688
[09/26 10:49:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.50	top5: 45.50	
[09/26 10:49:34 visual_prompt]: Best epoch 9: best metric: 0.105
[09/26 10:49:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 10:49:41 visual_prompt]: Epoch 10 / 100: avg data time: 5.65e-02, avg batch time: 0.4977, average train loss: 3.1998
[09/26 10:49:43 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1659, average loss: 3.9429
[09/26 10:49:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 32.00	
[09/26 10:49:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 10:49:50 visual_prompt]: Epoch 11 / 100: avg data time: 5.57e-02, avg batch time: 0.4976, average train loss: 3.4537
[09/26 10:49:51 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1660, average loss: 3.2415
[09/26 10:49:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 39.00	
[09/26 10:49:51 visual_prompt]: Best epoch 11: best metric: 0.145
[09/26 10:49:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 10:49:58 visual_prompt]: Epoch 12 / 100: avg data time: 4.98e-02, avg batch time: 0.4916, average train loss: 3.1743
[09/26 10:49:59 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1660, average loss: 3.2432
[09/26 10:49:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 16.00	top5: 45.00	
[09/26 10:49:59 visual_prompt]: Best epoch 12: best metric: 0.160
[09/26 10:49:59 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 10:50:06 visual_prompt]: Epoch 13 / 100: avg data time: 5.01e-02, avg batch time: 0.4929, average train loss: 3.0205
[09/26 10:50:08 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 3.0449
[09/26 10:50:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 54.00	
[09/26 10:50:08 visual_prompt]: Best epoch 13: best metric: 0.180
[09/26 10:50:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 10:50:15 visual_prompt]: Epoch 14 / 100: avg data time: 5.78e-02, avg batch time: 0.5001, average train loss: 3.1052
[09/26 10:50:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 3.1187
[09/26 10:50:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 50.00	
[09/26 10:50:16 visual_prompt]: Best epoch 14: best metric: 0.185
[09/26 10:50:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 10:50:23 visual_prompt]: Epoch 15 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 2.9887
[09/26 10:50:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 3.3967
[09/26 10:50:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 44.50	
[09/26 10:50:25 visual_prompt]: Best epoch 15: best metric: 0.195
[09/26 10:50:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 10:50:31 visual_prompt]: Epoch 16 / 100: avg data time: 5.29e-02, avg batch time: 0.4965, average train loss: 3.3278
[09/26 10:50:33 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 3.3808
[09/26 10:50:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 38.50	
[09/26 10:50:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 10:50:40 visual_prompt]: Epoch 17 / 100: avg data time: 5.09e-02, avg batch time: 0.4926, average train loss: 4.8059
[09/26 10:50:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 5.2940
[09/26 10:50:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 14.50	
[09/26 10:50:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 10:50:48 visual_prompt]: Epoch 18 / 100: avg data time: 5.68e-02, avg batch time: 0.4988, average train loss: 5.2722
[09/26 10:50:50 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1658, average loss: 5.4198
[09/26 10:50:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 19.50	
[09/26 10:50:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 10:50:57 visual_prompt]: Epoch 19 / 100: avg data time: 6.32e-02, avg batch time: 0.5057, average train loss: 4.4527
[09/26 10:50:58 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 4.2129
[09/26 10:50:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 22.50	
[09/26 10:50:58 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 10:51:05 visual_prompt]: Epoch 20 / 100: avg data time: 5.42e-02, avg batch time: 0.4959, average train loss: 3.4415
[09/26 10:51:07 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 3.3456
[09/26 10:51:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 40.00	
[09/26 10:51:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 10:51:13 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e-02, avg batch time: 0.4931, average train loss: 3.2588
[09/26 10:51:15 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 3.5794
[09/26 10:51:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 41.50	
[09/26 10:51:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 10:51:22 visual_prompt]: Epoch 22 / 100: avg data time: 4.93e-02, avg batch time: 0.4920, average train loss: 3.0961
[09/26 10:51:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 3.6031
[09/26 10:51:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 41.50	
[09/26 10:51:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 10:51:30 visual_prompt]: Epoch 23 / 100: avg data time: 7.21e-02, avg batch time: 0.5133, average train loss: 3.1080
[09/26 10:51:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 3.8091
[09/26 10:51:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 41.00	
[09/26 10:51:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 10:51:39 visual_prompt]: Epoch 24 / 100: avg data time: 5.30e-02, avg batch time: 0.4971, average train loss: 2.6942
[09/26 10:51:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1661, average loss: 2.7877
[09/26 10:51:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.00	top5: 63.00	
[09/26 10:51:40 visual_prompt]: Best epoch 24: best metric: 0.290
[09/26 10:51:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 10:51:47 visual_prompt]: Epoch 25 / 100: avg data time: 5.32e-02, avg batch time: 0.4970, average train loss: 2.0625
[09/26 10:51:49 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1661, average loss: 3.0435
[09/26 10:51:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.50	top5: 58.00	
[09/26 10:51:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 10:51:56 visual_prompt]: Epoch 26 / 100: avg data time: 8.02e-02, avg batch time: 0.5211, average train loss: 2.1762
[09/26 10:51:57 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1661, average loss: 2.7982
[09/26 10:51:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 34.50	top5: 60.50	
[09/26 10:51:57 visual_prompt]: Best epoch 26: best metric: 0.345
[09/26 10:51:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 10:52:04 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e-02, avg batch time: 0.4932, average train loss: 2.6822
[09/26 10:52:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1658, average loss: 5.4248
[09/26 10:52:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 29.00	
[09/26 10:52:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 10:52:13 visual_prompt]: Epoch 28 / 100: avg data time: 5.61e-02, avg batch time: 0.4984, average train loss: 3.7786
[09/26 10:52:14 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1660, average loss: 3.4697
[09/26 10:52:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.50	top5: 51.50	
[09/26 10:52:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 10:52:21 visual_prompt]: Epoch 29 / 100: avg data time: 6.69e-02, avg batch time: 0.5077, average train loss: 2.9860
[09/26 10:52:23 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1661, average loss: 2.8206
[09/26 10:52:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 32.00	top5: 64.00	
[09/26 10:52:23 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 10:52:30 visual_prompt]: Epoch 30 / 100: avg data time: 5.66e-02, avg batch time: 0.4984, average train loss: 2.5527
[09/26 10:52:31 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1658, average loss: 2.9367
[09/26 10:52:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.50	top5: 68.50	
[09/26 10:52:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 10:52:38 visual_prompt]: Epoch 31 / 100: avg data time: 5.86e-02, avg batch time: 0.5003, average train loss: 1.6104
[09/26 10:52:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 1.8172
[09/26 10:52:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 81.50	
[09/26 10:52:40 visual_prompt]: Best epoch 31: best metric: 0.490
[09/26 10:52:40 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 10:52:46 visual_prompt]: Epoch 32 / 100: avg data time: 4.81e-02, avg batch time: 0.4908, average train loss: 1.4211
[09/26 10:52:48 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1660, average loss: 1.5292
[09/26 10:52:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.00	top5: 88.50	
[09/26 10:52:48 visual_prompt]: Best epoch 32: best metric: 0.540
[09/26 10:52:48 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 10:52:55 visual_prompt]: Epoch 33 / 100: avg data time: 5.55e-02, avg batch time: 0.4989, average train loss: 0.8532
[09/26 10:52:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 1.6256
[09/26 10:52:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.50	top5: 86.50	
[09/26 10:52:57 visual_prompt]: Best epoch 33: best metric: 0.545
[09/26 10:52:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 10:53:03 visual_prompt]: Epoch 34 / 100: avg data time: 5.77e-02, avg batch time: 0.5001, average train loss: 1.6045
[09/26 10:53:05 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1659, average loss: 1.5713
[09/26 10:53:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.00	top5: 87.00	
[09/26 10:53:05 visual_prompt]: Best epoch 34: best metric: 0.560
[09/26 10:53:05 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 10:53:12 visual_prompt]: Epoch 35 / 100: avg data time: 5.57e-02, avg batch time: 0.4981, average train loss: 2.6499
[09/26 10:53:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 3.2059
[09/26 10:53:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 47.00	
[09/26 10:53:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 10:53:20 visual_prompt]: Epoch 36 / 100: avg data time: 6.35e-02, avg batch time: 0.5052, average train loss: 2.9531
[09/26 10:53:22 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1659, average loss: 3.5200
[09/26 10:53:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.50	top5: 66.00	
[09/26 10:53:22 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 10:53:29 visual_prompt]: Epoch 37 / 100: avg data time: 6.22e-02, avg batch time: 0.5031, average train loss: 2.1198
[09/26 10:53:30 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1662, average loss: 1.8346
[09/26 10:53:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.00	top5: 80.50	
[09/26 10:53:30 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 10:53:37 visual_prompt]: Epoch 38 / 100: avg data time: 6.76e-02, avg batch time: 0.5091, average train loss: 1.2178
[09/26 10:53:39 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 1.4608
[09/26 10:53:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 90.50	
[09/26 10:53:39 visual_prompt]: Best epoch 38: best metric: 0.630
[09/26 10:53:39 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 10:53:46 visual_prompt]: Epoch 39 / 100: avg data time: 6.68e-02, avg batch time: 0.5083, average train loss: 0.8259
[09/26 10:53:48 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1660, average loss: 1.3612
[09/26 10:53:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 90.00	
[09/26 10:53:48 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 10:53:54 visual_prompt]: Epoch 40 / 100: avg data time: 5.14e-02, avg batch time: 0.4954, average train loss: 0.6804
[09/26 10:53:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1661, average loss: 1.6007
[09/26 10:53:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.50	top5: 87.00	
[09/26 10:53:56 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 10:54:03 visual_prompt]: Epoch 41 / 100: avg data time: 5.37e-02, avg batch time: 0.4953, average train loss: 0.5913
[09/26 10:54:04 visual_prompt]: Inference (val):avg data time: 4.33e-05, avg batch time: 0.1663, average loss: 1.4850
[09/26 10:54:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 89.00	
[09/26 10:54:04 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 10:54:11 visual_prompt]: Epoch 42 / 100: avg data time: 5.54e-02, avg batch time: 0.4979, average train loss: 0.4722
[09/26 10:54:13 visual_prompt]: Inference (val):avg data time: 3.41e-04, avg batch time: 0.1664, average loss: 1.0182
[09/26 10:54:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 10:54:13 visual_prompt]: Best epoch 42: best metric: 0.765
[09/26 10:54:13 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 10:54:20 visual_prompt]: Epoch 43 / 100: avg data time: 6.25e-02, avg batch time: 0.5055, average train loss: 0.3741
[09/26 10:54:22 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1662, average loss: 1.0368
[09/26 10:54:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 10:54:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 10:54:28 visual_prompt]: Epoch 44 / 100: avg data time: 5.90e-02, avg batch time: 0.5002, average train loss: 0.2813
[09/26 10:54:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 1.0698
[09/26 10:54:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 94.00	
[09/26 10:54:30 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 10:54:37 visual_prompt]: Epoch 45 / 100: avg data time: 5.90e-02, avg batch time: 0.5004, average train loss: 0.1955
[09/26 10:54:39 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.9193
[09/26 10:54:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.50	
[09/26 10:54:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 10:54:45 visual_prompt]: Epoch 46 / 100: avg data time: 5.11e-02, avg batch time: 0.4928, average train loss: 0.2510
[09/26 10:54:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 1.0931
[09/26 10:54:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 91.50	
[09/26 10:54:47 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 10:54:54 visual_prompt]: Epoch 47 / 100: avg data time: 5.21e-02, avg batch time: 0.4963, average train loss: 0.2320
[09/26 10:54:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.0632
[09/26 10:54:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 91.50	
[09/26 10:54:55 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 10:55:02 visual_prompt]: Epoch 48 / 100: avg data time: 4.99e-02, avg batch time: 0.4924, average train loss: 0.1767
[09/26 10:55:04 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.8728
[09/26 10:55:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 10:55:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 10:55:11 visual_prompt]: Epoch 49 / 100: avg data time: 6.04e-02, avg batch time: 0.5043, average train loss: 0.1061
[09/26 10:55:12 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 0.7668
[09/26 10:55:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 98.50	
[09/26 10:55:12 visual_prompt]: Best epoch 49: best metric: 0.770
[09/26 10:55:12 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 10:55:19 visual_prompt]: Epoch 50 / 100: avg data time: 5.99e-02, avg batch time: 0.5021, average train loss: 0.0957
[09/26 10:55:21 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1661, average loss: 0.7331
[09/26 10:55:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 98.50	
[09/26 10:55:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 10:55:28 visual_prompt]: Epoch 51 / 100: avg data time: 5.98e-02, avg batch time: 0.5013, average train loss: 0.1044
[09/26 10:55:29 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 0.8069
[09/26 10:55:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 98.00	
[09/26 10:55:29 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 10:55:36 visual_prompt]: Epoch 52 / 100: avg data time: 5.66e-02, avg batch time: 0.4986, average train loss: 0.1270
[09/26 10:55:38 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 0.8552
[09/26 10:55:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 96.00	
[09/26 10:55:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 10:55:44 visual_prompt]: Epoch 53 / 100: avg data time: 5.13e-02, avg batch time: 0.4954, average train loss: 0.1182
[09/26 10:55:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 0.7972
[09/26 10:55:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 10:55:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 10:55:53 visual_prompt]: Epoch 54 / 100: avg data time: 6.70e-02, avg batch time: 0.5110, average train loss: 0.0946
[09/26 10:55:55 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1661, average loss: 0.8789
[09/26 10:55:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 10:55:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 10:56:02 visual_prompt]: Epoch 55 / 100: avg data time: 5.54e-02, avg batch time: 0.4973, average train loss: 0.1164
[09/26 10:56:03 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1662, average loss: 0.7154
[09/26 10:56:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 10:56:03 visual_prompt]: Best epoch 55: best metric: 0.815
[09/26 10:56:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 10:56:10 visual_prompt]: Epoch 56 / 100: avg data time: 6.18e-02, avg batch time: 0.5040, average train loss: 0.0777
[09/26 10:56:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 0.6169
[09/26 10:56:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 10:56:12 visual_prompt]: Best epoch 56: best metric: 0.845
[09/26 10:56:12 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 10:56:19 visual_prompt]: Epoch 57 / 100: avg data time: 6.56e-02, avg batch time: 0.5067, average train loss: 0.0652
[09/26 10:56:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1661, average loss: 0.6618
[09/26 10:56:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 10:56:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 10:56:27 visual_prompt]: Epoch 58 / 100: avg data time: 6.34e-02, avg batch time: 0.5062, average train loss: 0.0609
[09/26 10:56:29 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1661, average loss: 0.7303
[09/26 10:56:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 10:56:29 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 10:56:36 visual_prompt]: Epoch 59 / 100: avg data time: 5.08e-02, avg batch time: 0.4928, average train loss: 0.0515
[09/26 10:56:37 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1660, average loss: 0.6326
[09/26 10:56:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 10:56:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 10:56:44 visual_prompt]: Epoch 60 / 100: avg data time: 5.37e-02, avg batch time: 0.4950, average train loss: 0.0478
[09/26 10:56:46 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 0.6492
[09/26 10:56:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 99.00	
[09/26 10:56:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 10:56:53 visual_prompt]: Epoch 61 / 100: avg data time: 5.13e-02, avg batch time: 0.4928, average train loss: 0.0663
[09/26 10:56:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 0.7153
[09/26 10:56:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 99.50	
[09/26 10:56:54 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 10:57:01 visual_prompt]: Epoch 62 / 100: avg data time: 5.36e-02, avg batch time: 0.4961, average train loss: 0.1437
[09/26 10:57:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 0.9041
[09/26 10:57:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 10:57:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 10:57:09 visual_prompt]: Epoch 63 / 100: avg data time: 5.18e-02, avg batch time: 0.4941, average train loss: 0.1469
[09/26 10:57:11 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 0.7864
[09/26 10:57:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 10:57:11 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 10:57:18 visual_prompt]: Epoch 64 / 100: avg data time: 5.83e-02, avg batch time: 0.5011, average train loss: 0.1062
[09/26 10:57:20 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.6689
[09/26 10:57:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.50	
[09/26 10:57:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 10:57:26 visual_prompt]: Epoch 65 / 100: avg data time: 5.24e-02, avg batch time: 0.4952, average train loss: 0.0549
[09/26 10:57:28 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 0.6048
[09/26 10:57:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 97.50	
[09/26 10:57:28 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 10:57:35 visual_prompt]: Epoch 66 / 100: avg data time: 5.66e-02, avg batch time: 0.4985, average train loss: 0.0317
[09/26 10:57:36 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 0.5667
[09/26 10:57:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 99.00	
[09/26 10:57:36 visual_prompt]: Best epoch 66: best metric: 0.870
[09/26 10:57:36 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 10:57:43 visual_prompt]: Epoch 67 / 100: avg data time: 5.04e-02, avg batch time: 0.4934, average train loss: 0.0257
[09/26 10:57:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.5566
[09/26 10:57:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.00	
[09/26 10:57:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 10:57:51 visual_prompt]: Epoch 68 / 100: avg data time: 5.19e-02, avg batch time: 0.4932, average train loss: 0.0253
[09/26 10:57:53 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.5557
[09/26 10:57:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 99.00	
[09/26 10:57:53 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 10:58:00 visual_prompt]: Epoch 69 / 100: avg data time: 6.23e-02, avg batch time: 0.5038, average train loss: 0.0247
[09/26 10:58:01 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 0.5526
[09/26 10:58:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 88.00	top5: 98.50	
[09/26 10:58:01 visual_prompt]: Best epoch 69: best metric: 0.880
[09/26 10:58:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 10:58:08 visual_prompt]: Epoch 70 / 100: avg data time: 6.16e-02, avg batch time: 0.5040, average train loss: 0.0244
[09/26 10:58:10 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1663, average loss: 0.5391
[09/26 10:58:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 98.50	
[09/26 10:58:10 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 10:58:17 visual_prompt]: Epoch 71 / 100: avg data time: 6.29e-02, avg batch time: 0.5042, average train loss: 0.0241
[09/26 10:58:18 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 0.5839
[09/26 10:58:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.50	
[09/26 10:58:18 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 10:58:25 visual_prompt]: Epoch 72 / 100: avg data time: 5.44e-02, avg batch time: 0.4965, average train loss: 0.0223
[09/26 10:58:27 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 0.5404
[09/26 10:58:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.50	
[09/26 10:58:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 10:58:34 visual_prompt]: Epoch 73 / 100: avg data time: 4.88e-02, avg batch time: 0.4924, average train loss: 0.0219
[09/26 10:58:35 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1661, average loss: 0.5763
[09/26 10:58:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 99.50	
[09/26 10:58:35 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 10:58:42 visual_prompt]: Epoch 74 / 100: avg data time: 6.02e-02, avg batch time: 0.5024, average train loss: 0.0226
[09/26 10:58:44 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 0.7160
[09/26 10:58:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 10:58:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 10:58:51 visual_prompt]: Epoch 75 / 100: avg data time: 6.83e-02, avg batch time: 0.5118, average train loss: 0.2788
[09/26 10:58:52 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 1.1990
[09/26 10:58:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.00	
[09/26 10:58:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 10:58:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.11e-02, avg batch time: 0.4928, average train loss: 0.3081
[09/26 10:59:01 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1661, average loss: 0.7754
[09/26 10:59:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 97.50	
[09/26 10:59:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 10:59:08 visual_prompt]: Epoch 77 / 100: avg data time: 5.69e-02, avg batch time: 0.4994, average train loss: 0.1319
[09/26 10:59:09 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 0.6430
[09/26 10:59:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 99.50	
[09/26 10:59:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 10:59:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.30e-02, avg batch time: 0.4973, average train loss: 0.0620
[09/26 10:59:17 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 0.6020
[09/26 10:59:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 100.00	
[09/26 10:59:17 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 10:59:24 visual_prompt]: Epoch 79 / 100: avg data time: 6.23e-02, avg batch time: 0.5033, average train loss: 0.0432
[09/26 10:59:26 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1661, average loss: 0.6192
[09/26 10:59:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 10:59:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 10:59:33 visual_prompt]: Epoch 80 / 100: avg data time: 5.37e-02, avg batch time: 0.4959, average train loss: 0.0327
[09/26 10:59:34 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 0.5240
[09/26 10:59:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 99.00	
[09/26 10:59:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 10:59:41 visual_prompt]: Epoch 81 / 100: avg data time: 7.04e-02, avg batch time: 0.5127, average train loss: 0.0411
[09/26 10:59:43 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 0.5577
[09/26 10:59:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 100.00	
[09/26 10:59:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 10:59:50 visual_prompt]: Epoch 82 / 100: avg data time: 6.98e-02, avg batch time: 0.5106, average train loss: 0.0306
[09/26 10:59:51 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 0.5234
[09/26 10:59:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 99.50	
[09/26 10:59:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 10:59:59 visual_prompt]: Epoch 83 / 100: avg data time: 8.52e-02, avg batch time: 0.5258, average train loss: 0.0227
[09/26 11:00:00 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1661, average loss: 0.5215
[09/26 11:00:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 99.50	
[09/26 11:00:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:00:07 visual_prompt]: Epoch 84 / 100: avg data time: 5.39e-02, avg batch time: 0.4956, average train loss: 0.0201
[09/26 11:00:09 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1662, average loss: 0.5221
[09/26 11:00:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 88.00	top5: 99.50	
[09/26 11:00:09 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:00:16 visual_prompt]: Epoch 85 / 100: avg data time: 6.67e-02, avg batch time: 0.5077, average train loss: 0.0189
[09/26 11:00:17 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 0.5214
[09/26 11:00:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 100.00	
[09/26 11:00:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:00:24 visual_prompt]: Epoch 86 / 100: avg data time: 5.20e-02, avg batch time: 0.4946, average train loss: 0.0175
[09/26 11:00:26 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1662, average loss: 0.5297
[09/26 11:00:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 100.00	
[09/26 11:00:26 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:00:33 visual_prompt]: Epoch 87 / 100: avg data time: 7.11e-02, avg batch time: 0.5121, average train loss: 0.0175
[09/26 11:00:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 0.5297
[09/26 11:00:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 99.50	
[09/26 11:00:34 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:00:41 visual_prompt]: Epoch 88 / 100: avg data time: 6.13e-02, avg batch time: 0.5032, average train loss: 0.0171
[09/26 11:00:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 0.5333
[09/26 11:00:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 100.00	
[09/26 11:00:43 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:00:50 visual_prompt]: Epoch 89 / 100: avg data time: 4.91e-02, avg batch time: 0.4928, average train loss: 0.0168
[09/26 11:00:51 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1660, average loss: 0.5356
[09/26 11:00:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 100.00	
[09/26 11:00:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:00:58 visual_prompt]: Epoch 90 / 100: avg data time: 5.07e-02, avg batch time: 0.4933, average train loss: 0.0165
[09/26 11:01:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 0.5424
[09/26 11:01:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 100.00	
[09/26 11:01:00 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:01:07 visual_prompt]: Epoch 91 / 100: avg data time: 7.06e-02, avg batch time: 0.5119, average train loss: 0.0161
[09/26 11:01:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 0.5333
[09/26 11:01:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 100.00	
[09/26 11:01:08 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:01:15 visual_prompt]: Epoch 92 / 100: avg data time: 6.35e-02, avg batch time: 0.5061, average train loss: 0.0162
[09/26 11:01:17 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1662, average loss: 0.5335
[09/26 11:01:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 100.00	
[09/26 11:01:17 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:01:24 visual_prompt]: Epoch 93 / 100: avg data time: 6.11e-02, avg batch time: 0.5034, average train loss: 0.0160
[09/26 11:01:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 0.5360
[09/26 11:01:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:01:26 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:01:32 visual_prompt]: Epoch 94 / 100: avg data time: 5.41e-02, avg batch time: 0.4965, average train loss: 0.0158
[09/26 11:01:34 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 0.5386
[09/26 11:01:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:01:34 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:01:41 visual_prompt]: Epoch 95 / 100: avg data time: 5.17e-02, avg batch time: 0.4935, average train loss: 0.0157
[09/26 11:01:42 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 0.5396
[09/26 11:01:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 100.00	
[09/26 11:01:42 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:01:49 visual_prompt]: Epoch 96 / 100: avg data time: 6.30e-02, avg batch time: 0.5070, average train loss: 0.0158
[09/26 11:01:51 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 0.5406
[09/26 11:01:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:01:51 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:01:58 visual_prompt]: Epoch 97 / 100: avg data time: 6.51e-02, avg batch time: 0.5072, average train loss: 0.0154
[09/26 11:02:00 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 0.5401
[09/26 11:02:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:02:00 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:02:06 visual_prompt]: Epoch 98 / 100: avg data time: 5.67e-02, avg batch time: 0.4996, average train loss: 0.0157
[09/26 11:02:08 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 0.5398
[09/26 11:02:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:02:08 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:02:15 visual_prompt]: Epoch 99 / 100: avg data time: 5.08e-02, avg batch time: 0.4959, average train loss: 0.0155
[09/26 11:02:16 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 0.5396
[09/26 11:02:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:02:16 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:02:23 visual_prompt]: Epoch 100 / 100: avg data time: 5.09e-02, avg batch time: 0.4947, average train loss: 0.0155
[09/26 11:02:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 0.5397
[09/26 11:02:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 100.00	
[09/26 11:02:25 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:02:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:02:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:02:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:02:25 visual_prompt]: Training with config:
[09/26 11:02:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:02:25 visual_prompt]: Loading training data...
[09/26 11:02:25 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:02:26 visual_prompt]: Number of images: 800
[09/26 11:02:26 visual_prompt]: Number of classes: 45 / 45
[09/26 11:02:26 visual_prompt]: Loading validation data...
[09/26 11:02:26 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:02:26 visual_prompt]: Number of images: 200
[09/26 11:02:26 visual_prompt]: Number of classes: 45 / 45
[09/26 11:02:26 visual_prompt]: Constructing models...
[09/26 11:02:29 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 11:02:29 visual_prompt]: tuned percent:0.574
[09/26 11:02:29 visual_prompt]: Device used for model: 0
[09/26 11:02:29 visual_prompt]: Setting up Evaluator...
[09/26 11:02:29 visual_prompt]: Setting up Trainer...
[09/26 11:02:29 visual_prompt]: 	Setting up the optimizer...
[09/26 11:02:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:02:36 visual_prompt]: Epoch 1 / 100: avg data time: 6.50e-02, avg batch time: 0.5086, average train loss: 3.8909
[09/26 11:02:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 11:02:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 11:02:37 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 11:02:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:02:44 visual_prompt]: Epoch 2 / 100: avg data time: 6.04e-02, avg batch time: 0.5013, average train loss: 3.8370
[09/26 11:02:46 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1656, average loss: 3.7836
[09/26 11:02:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 11:02:46 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 11:02:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:02:53 visual_prompt]: Epoch 3 / 100: avg data time: 5.40e-02, avg batch time: 0.4959, average train loss: 3.7311
[09/26 11:02:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1658, average loss: 3.7426
[09/26 11:02:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 25.50	
[09/26 11:02:54 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 11:02:54 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:03:01 visual_prompt]: Epoch 4 / 100: avg data time: 6.62e-02, avg batch time: 0.5079, average train loss: 3.5871
[09/26 11:03:03 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1661, average loss: 3.3611
[09/26 11:03:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 33.00	
[09/26 11:03:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:03:10 visual_prompt]: Epoch 5 / 100: avg data time: 6.37e-02, avg batch time: 0.5048, average train loss: 3.4590
[09/26 11:03:11 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1660, average loss: 3.2552
[09/26 11:03:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 44.50	
[09/26 11:03:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:03:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.11e-02, avg batch time: 0.4941, average train loss: 3.0827
[09/26 11:03:20 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 3.0019
[09/26 11:03:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 16.00	top5: 47.50	
[09/26 11:03:20 visual_prompt]: Best epoch 6: best metric: 0.160
[09/26 11:03:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:03:27 visual_prompt]: Epoch 7 / 100: avg data time: 7.18e-02, avg batch time: 0.5135, average train loss: 2.8624
[09/26 11:03:29 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 2.6287
[09/26 11:03:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 21.50	top5: 62.50	
[09/26 11:03:29 visual_prompt]: Best epoch 7: best metric: 0.215
[09/26 11:03:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:03:35 visual_prompt]: Epoch 8 / 100: avg data time: 5.17e-02, avg batch time: 0.4968, average train loss: 3.2967
[09/26 11:03:37 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 3.3586
[09/26 11:03:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.50	top5: 36.50	
[09/26 11:03:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:03:44 visual_prompt]: Epoch 9 / 100: avg data time: 5.27e-02, avg batch time: 0.4965, average train loss: 2.9045
[09/26 11:03:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 2.4458
[09/26 11:03:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 31.50	top5: 66.00	
[09/26 11:03:45 visual_prompt]: Best epoch 9: best metric: 0.315
[09/26 11:03:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:03:52 visual_prompt]: Epoch 10 / 100: avg data time: 7.08e-02, avg batch time: 0.5125, average train loss: 2.1287
[09/26 11:03:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 2.6333
[09/26 11:03:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 66.50	
[09/26 11:03:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:04:01 visual_prompt]: Epoch 11 / 100: avg data time: 7.21e-02, avg batch time: 0.5138, average train loss: 1.6832
[09/26 11:04:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 2.1625
[09/26 11:04:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 41.50	top5: 72.50	
[09/26 11:04:03 visual_prompt]: Best epoch 11: best metric: 0.415
[09/26 11:04:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:04:10 visual_prompt]: Epoch 12 / 100: avg data time: 5.12e-02, avg batch time: 0.4955, average train loss: 1.8038
[09/26 11:04:11 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 4.0534
[09/26 11:04:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 16.00	top5: 41.50	
[09/26 11:04:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:04:18 visual_prompt]: Epoch 13 / 100: avg data time: 5.80e-02, avg batch time: 0.4996, average train loss: 2.6625
[09/26 11:04:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 1.9349
[09/26 11:04:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.00	top5: 79.50	
[09/26 11:04:20 visual_prompt]: Best epoch 13: best metric: 0.430
[09/26 11:04:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:04:27 visual_prompt]: Epoch 14 / 100: avg data time: 5.61e-02, avg batch time: 0.4994, average train loss: 1.2287
[09/26 11:04:28 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.6690
[09/26 11:04:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 83.50	
[09/26 11:04:28 visual_prompt]: Best epoch 14: best metric: 0.610
[09/26 11:04:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:04:35 visual_prompt]: Epoch 15 / 100: avg data time: 5.27e-02, avg batch time: 0.4959, average train loss: 0.9424
[09/26 11:04:37 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 1.6552
[09/26 11:04:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 86.50	
[09/26 11:04:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:04:44 visual_prompt]: Epoch 16 / 100: avg data time: 5.72e-02, avg batch time: 0.5006, average train loss: 0.7430
[09/26 11:04:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.3878
[09/26 11:04:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 89.50	
[09/26 11:04:45 visual_prompt]: Best epoch 16: best metric: 0.710
[09/26 11:04:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:04:52 visual_prompt]: Epoch 17 / 100: avg data time: 5.76e-02, avg batch time: 0.5006, average train loss: 0.7470
[09/26 11:04:54 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.2690
[09/26 11:04:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 92.50	
[09/26 11:04:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:05:01 visual_prompt]: Epoch 18 / 100: avg data time: 5.78e-02, avg batch time: 0.4998, average train loss: 0.3013
[09/26 11:05:02 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.1798
[09/26 11:05:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 96.00	
[09/26 11:05:02 visual_prompt]: Best epoch 18: best metric: 0.725
[09/26 11:05:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:05:09 visual_prompt]: Epoch 19 / 100: avg data time: 4.88e-02, avg batch time: 0.4929, average train loss: 0.1848
[09/26 11:05:11 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 1.2492
[09/26 11:05:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.50	
[09/26 11:05:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:05:17 visual_prompt]: Epoch 20 / 100: avg data time: 4.75e-02, avg batch time: 0.4942, average train loss: 0.1383
[09/26 11:05:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.2005
[09/26 11:05:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 92.50	
[09/26 11:05:19 visual_prompt]: Best epoch 20: best metric: 0.735
[09/26 11:05:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:05:26 visual_prompt]: Epoch 21 / 100: avg data time: 5.52e-02, avg batch time: 0.4973, average train loss: 0.0814
[09/26 11:05:27 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.0052
[09/26 11:05:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 98.50	
[09/26 11:05:27 visual_prompt]: Best epoch 21: best metric: 0.745
[09/26 11:05:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:05:34 visual_prompt]: Epoch 22 / 100: avg data time: 5.71e-02, avg batch time: 0.5006, average train loss: 0.0689
[09/26 11:05:36 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 1.3578
[09/26 11:05:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 11:05:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:05:42 visual_prompt]: Epoch 23 / 100: avg data time: 5.03e-02, avg batch time: 0.4939, average train loss: 0.0522
[09/26 11:05:44 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1665, average loss: 1.0859
[09/26 11:05:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 11:05:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:05:51 visual_prompt]: Epoch 24 / 100: avg data time: 5.57e-02, avg batch time: 0.4977, average train loss: 0.0338
[09/26 11:05:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 0.9545
[09/26 11:05:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 11:05:52 visual_prompt]: Best epoch 24: best metric: 0.770
[09/26 11:05:52 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:05:59 visual_prompt]: Epoch 25 / 100: avg data time: 5.92e-02, avg batch time: 0.5013, average train loss: 0.0113
[09/26 11:06:01 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.9786
[09/26 11:06:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 11:06:01 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:06:08 visual_prompt]: Epoch 26 / 100: avg data time: 4.53e-02, avg batch time: 0.4893, average train loss: 0.0051
[09/26 11:06:09 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 0.9821
[09/26 11:06:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 11:06:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:06:16 visual_prompt]: Epoch 27 / 100: avg data time: 4.90e-02, avg batch time: 0.4933, average train loss: 0.0025
[09/26 11:06:17 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.9299
[09/26 11:06:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 11:06:17 visual_prompt]: Best epoch 27: best metric: 0.780
[09/26 11:06:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:06:24 visual_prompt]: Epoch 28 / 100: avg data time: 6.05e-02, avg batch time: 0.5032, average train loss: 0.0019
[09/26 11:06:26 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 0.8969
[09/26 11:06:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 11:06:26 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:06:33 visual_prompt]: Epoch 29 / 100: avg data time: 6.90e-02, avg batch time: 0.5118, average train loss: 0.0017
[09/26 11:06:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 0.8756
[09/26 11:06:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 11:06:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:06:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.14e-02, avg batch time: 0.4939, average train loss: 0.0017
[09/26 11:06:43 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.8559
[09/26 11:06:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 11:06:43 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:06:50 visual_prompt]: Epoch 31 / 100: avg data time: 5.21e-02, avg batch time: 0.4965, average train loss: 0.0018
[09/26 11:06:51 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1663, average loss: 0.8312
[09/26 11:06:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 11:06:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:06:58 visual_prompt]: Epoch 32 / 100: avg data time: 5.25e-02, avg batch time: 0.4950, average train loss: 0.0019
[09/26 11:07:00 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 0.8134
[09/26 11:07:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 11:07:00 visual_prompt]: Best epoch 32: best metric: 0.785
[09/26 11:07:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:07:07 visual_prompt]: Epoch 33 / 100: avg data time: 5.54e-02, avg batch time: 0.4986, average train loss: 0.0020
[09/26 11:07:08 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1661, average loss: 0.8023
[09/26 11:07:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 11:07:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:07:15 visual_prompt]: Epoch 34 / 100: avg data time: 4.91e-02, avg batch time: 0.4925, average train loss: 0.0021
[09/26 11:07:16 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 0.7898
[09/26 11:07:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 11:07:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:07:23 visual_prompt]: Epoch 35 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 0.0024
[09/26 11:07:25 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 0.7825
[09/26 11:07:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 11:07:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:07:32 visual_prompt]: Epoch 36 / 100: avg data time: 5.43e-02, avg batch time: 0.4965, average train loss: 0.0024
[09/26 11:07:33 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1661, average loss: 0.7744
[09/26 11:07:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 11:07:33 visual_prompt]: Best epoch 36: best metric: 0.795
[09/26 11:07:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:07:40 visual_prompt]: Epoch 37 / 100: avg data time: 5.13e-02, avg batch time: 0.4944, average train loss: 0.0027
[09/26 11:07:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 0.7550
[09/26 11:07:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 11:07:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:07:48 visual_prompt]: Epoch 38 / 100: avg data time: 4.97e-02, avg batch time: 0.4947, average train loss: 0.0029
[09/26 11:07:50 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1662, average loss: 0.7448
[09/26 11:07:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 11:07:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:07:57 visual_prompt]: Epoch 39 / 100: avg data time: 5.21e-02, avg batch time: 0.4943, average train loss: 0.0028
[09/26 11:07:58 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.7319
[09/26 11:07:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 11:07:58 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:08:05 visual_prompt]: Epoch 40 / 100: avg data time: 4.73e-02, avg batch time: 0.4917, average train loss: 0.0033
[09/26 11:08:07 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 0.7271
[09/26 11:08:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 11:08:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:08:13 visual_prompt]: Epoch 41 / 100: avg data time: 5.17e-02, avg batch time: 0.4951, average train loss: 0.0032
[09/26 11:08:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.7134
[09/26 11:08:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 11:08:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:08:22 visual_prompt]: Epoch 42 / 100: avg data time: 5.31e-02, avg batch time: 0.4958, average train loss: 0.0036
[09/26 11:08:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 0.7025
[09/26 11:08:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 11:08:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:08:30 visual_prompt]: Epoch 43 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 0.0035
[09/26 11:08:32 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 0.7031
[09/26 11:08:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 11:08:32 visual_prompt]: Best epoch 43: best metric: 0.805
[09/26 11:08:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:08:39 visual_prompt]: Epoch 44 / 100: avg data time: 7.64e-02, avg batch time: 0.5191, average train loss: 0.0035
[09/26 11:08:41 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 0.7007
[09/26 11:08:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 11:08:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:08:47 visual_prompt]: Epoch 45 / 100: avg data time: 6.38e-02, avg batch time: 0.5068, average train loss: 0.0037
[09/26 11:08:49 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 0.6947
[09/26 11:08:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 11:08:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:08:56 visual_prompt]: Epoch 46 / 100: avg data time: 6.57e-02, avg batch time: 0.5069, average train loss: 0.0040
[09/26 11:08:58 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.6947
[09/26 11:08:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 11:08:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:09:04 visual_prompt]: Epoch 47 / 100: avg data time: 5.76e-02, avg batch time: 0.5004, average train loss: 0.0043
[09/26 11:09:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 0.6838
[09/26 11:09:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 11:09:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:09:13 visual_prompt]: Epoch 48 / 100: avg data time: 4.97e-02, avg batch time: 0.4922, average train loss: 0.0039
[09/26 11:09:14 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1660, average loss: 0.6817
[09/26 11:09:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 11:09:14 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:09:21 visual_prompt]: Epoch 49 / 100: avg data time: 4.71e-02, avg batch time: 0.4910, average train loss: 0.0041
[09/26 11:09:23 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1660, average loss: 0.6765
[09/26 11:09:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 11:09:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:09:29 visual_prompt]: Epoch 50 / 100: avg data time: 5.11e-02, avg batch time: 0.4951, average train loss: 0.0043
[09/26 11:09:31 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 0.6931
[09/26 11:09:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 11:09:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:09:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.75e-02, avg batch time: 0.4906, average train loss: 0.0043
[09/26 11:09:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 0.6664
[09/26 11:09:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 11:09:39 visual_prompt]: Best epoch 51: best metric: 0.820
[09/26 11:09:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:09:46 visual_prompt]: Epoch 52 / 100: avg data time: 5.04e-02, avg batch time: 0.4944, average train loss: 0.0045
[09/26 11:09:48 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 0.6684
[09/26 11:09:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 11:09:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:09:54 visual_prompt]: Epoch 53 / 100: avg data time: 6.25e-02, avg batch time: 0.5039, average train loss: 0.0042
[09/26 11:09:56 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1660, average loss: 0.6658
[09/26 11:09:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 11:09:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:10:03 visual_prompt]: Epoch 54 / 100: avg data time: 4.93e-02, avg batch time: 0.4919, average train loss: 0.0042
[09/26 11:10:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 0.6641
[09/26 11:10:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 11:10:04 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:10:11 visual_prompt]: Epoch 55 / 100: avg data time: 4.90e-02, avg batch time: 0.4925, average train loss: 0.0044
[09/26 11:10:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 0.6641
[09/26 11:10:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.50	
[09/26 11:10:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:10:20 visual_prompt]: Epoch 56 / 100: avg data time: 5.94e-02, avg batch time: 0.5035, average train loss: 0.0043
[09/26 11:10:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 0.6608
[09/26 11:10:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 11:10:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:10:28 visual_prompt]: Epoch 57 / 100: avg data time: 4.86e-02, avg batch time: 0.4910, average train loss: 0.0043
[09/26 11:10:30 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1660, average loss: 0.6630
[09/26 11:10:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.00	
[09/26 11:10:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:10:36 visual_prompt]: Epoch 58 / 100: avg data time: 5.24e-02, avg batch time: 0.4957, average train loss: 0.0045
[09/26 11:10:38 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1659, average loss: 0.6658
[09/26 11:10:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.50	
[09/26 11:10:38 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:10:45 visual_prompt]: Epoch 59 / 100: avg data time: 6.01e-02, avg batch time: 0.5014, average train loss: 0.0044
[09/26 11:10:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 0.6395
[09/26 11:10:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 11:10:46 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:10:53 visual_prompt]: Epoch 60 / 100: avg data time: 5.01e-02, avg batch time: 0.4939, average train loss: 0.0043
[09/26 11:10:55 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 0.6385
[09/26 11:10:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 11:10:55 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:11:01 visual_prompt]: Epoch 61 / 100: avg data time: 5.42e-02, avg batch time: 0.4961, average train loss: 0.0043
[09/26 11:11:03 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 0.6423
[09/26 11:11:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.50	
[09/26 11:11:03 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 11:11:10 visual_prompt]: Epoch 62 / 100: avg data time: 5.94e-02, avg batch time: 0.5017, average train loss: 0.0044
[09/26 11:11:11 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1659, average loss: 0.6451
[09/26 11:11:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 11:11:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 11:11:18 visual_prompt]: Epoch 63 / 100: avg data time: 5.18e-02, avg batch time: 0.4948, average train loss: 0.0044
[09/26 11:11:20 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1660, average loss: 0.6339
[09/26 11:11:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 11:11:20 visual_prompt]: Best epoch 63: best metric: 0.830
[09/26 11:11:20 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 11:11:26 visual_prompt]: Epoch 64 / 100: avg data time: 5.18e-02, avg batch time: 0.4939, average train loss: 0.0042
[09/26 11:11:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1659, average loss: 0.6310
[09/26 11:11:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.50	
[09/26 11:11:28 visual_prompt]: Best epoch 64: best metric: 0.835
[09/26 11:11:28 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 11:11:35 visual_prompt]: Epoch 65 / 100: avg data time: 5.00e-02, avg batch time: 0.4916, average train loss: 0.0044
[09/26 11:11:36 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1661, average loss: 0.6293
[09/26 11:11:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 11:11:36 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 11:11:43 visual_prompt]: Epoch 66 / 100: avg data time: 5.02e-02, avg batch time: 0.4945, average train loss: 0.0043
[09/26 11:11:45 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1661, average loss: 0.6435
[09/26 11:11:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 11:11:45 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 11:11:51 visual_prompt]: Epoch 67 / 100: avg data time: 4.71e-02, avg batch time: 0.4901, average train loss: 0.0044
[09/26 11:11:53 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 0.6402
[09/26 11:11:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 11:11:53 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 11:12:00 visual_prompt]: Epoch 68 / 100: avg data time: 5.07e-02, avg batch time: 0.4948, average train loss: 0.0043
[09/26 11:12:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 0.6427
[09/26 11:12:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 11:12:01 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 11:12:08 visual_prompt]: Epoch 69 / 100: avg data time: 5.50e-02, avg batch time: 0.4975, average train loss: 0.0041
[09/26 11:12:10 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 0.6324
[09/26 11:12:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.50	
[09/26 11:12:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 11:12:17 visual_prompt]: Epoch 70 / 100: avg data time: 5.08e-02, avg batch time: 0.4953, average train loss: 0.0042
[09/26 11:12:18 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1658, average loss: 0.6369
[09/26 11:12:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.00	
[09/26 11:12:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 11:12:25 visual_prompt]: Epoch 71 / 100: avg data time: 5.19e-02, avg batch time: 0.4956, average train loss: 0.0041
[09/26 11:12:27 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 0.6366
[09/26 11:12:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.50	
[09/26 11:12:27 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 11:12:33 visual_prompt]: Epoch 72 / 100: avg data time: 5.27e-02, avg batch time: 0.4941, average train loss: 0.0042
[09/26 11:12:35 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 0.6380
[09/26 11:12:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.50	
[09/26 11:12:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 11:12:42 visual_prompt]: Epoch 73 / 100: avg data time: 5.03e-02, avg batch time: 0.4933, average train loss: 0.0041
[09/26 11:12:43 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1660, average loss: 0.6320
[09/26 11:12:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 97.50	
[09/26 11:12:43 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 11:12:50 visual_prompt]: Epoch 74 / 100: avg data time: 5.72e-02, avg batch time: 0.4993, average train loss: 0.0041
[09/26 11:12:51 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1661, average loss: 0.6261
[09/26 11:12:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.50	
[09/26 11:12:51 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 11:12:58 visual_prompt]: Epoch 75 / 100: avg data time: 5.32e-02, avg batch time: 0.4949, average train loss: 0.0040
[09/26 11:13:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 0.6307
[09/26 11:13:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 97.50	
[09/26 11:13:00 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 11:13:07 visual_prompt]: Epoch 76 / 100: avg data time: 7.40e-02, avg batch time: 0.5148, average train loss: 0.0040
[09/26 11:13:08 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 0.6265
[09/26 11:13:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 11:13:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 11:13:15 visual_prompt]: Epoch 77 / 100: avg data time: 5.60e-02, avg batch time: 0.4968, average train loss: 0.0040
[09/26 11:13:17 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 0.6273
[09/26 11:13:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.50	
[09/26 11:13:17 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 11:13:24 visual_prompt]: Epoch 78 / 100: avg data time: 5.15e-02, avg batch time: 0.4944, average train loss: 0.0041
[09/26 11:13:25 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 0.6297
[09/26 11:13:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 97.50	
[09/26 11:13:25 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 11:13:32 visual_prompt]: Epoch 79 / 100: avg data time: 5.34e-02, avg batch time: 0.4955, average train loss: 0.0039
[09/26 11:13:33 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1660, average loss: 0.6277
[09/26 11:13:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 97.50	
[09/26 11:13:33 visual_prompt]: Best epoch 79: best metric: 0.840
[09/26 11:13:33 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 11:13:40 visual_prompt]: Epoch 80 / 100: avg data time: 6.08e-02, avg batch time: 0.5034, average train loss: 0.0040
[09/26 11:13:42 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1658, average loss: 0.6287
[09/26 11:13:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 11:13:42 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 11:13:49 visual_prompt]: Epoch 81 / 100: avg data time: 5.82e-02, avg batch time: 0.4990, average train loss: 0.0039
[09/26 11:13:50 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 0.6291
[09/26 11:13:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 11:13:50 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 11:13:57 visual_prompt]: Epoch 82 / 100: avg data time: 6.03e-02, avg batch time: 0.5031, average train loss: 0.0039
[09/26 11:13:59 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1661, average loss: 0.6283
[09/26 11:13:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 11:13:59 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 11:14:06 visual_prompt]: Epoch 83 / 100: avg data time: 5.55e-02, avg batch time: 0.4983, average train loss: 0.0039
[09/26 11:14:07 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 0.6288
[09/26 11:14:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.50	
[09/26 11:14:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:14:14 visual_prompt]: Epoch 84 / 100: avg data time: 5.13e-02, avg batch time: 0.4950, average train loss: 0.0040
[09/26 11:14:16 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 0.6297
[09/26 11:14:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 11:14:16 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:14:22 visual_prompt]: Epoch 85 / 100: avg data time: 5.88e-02, avg batch time: 0.5006, average train loss: 0.0037
[09/26 11:14:24 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1660, average loss: 0.6298
[09/26 11:14:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.50	
[09/26 11:14:24 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:14:31 visual_prompt]: Epoch 86 / 100: avg data time: 7.22e-02, avg batch time: 0.5128, average train loss: 0.0040
[09/26 11:14:33 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1660, average loss: 0.6263
[09/26 11:14:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.00	
[09/26 11:14:33 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:14:40 visual_prompt]: Epoch 87 / 100: avg data time: 7.53e-02, avg batch time: 0.5158, average train loss: 0.0038
[09/26 11:14:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1657, average loss: 0.6244
[09/26 11:14:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 11:14:41 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:14:48 visual_prompt]: Epoch 88 / 100: avg data time: 4.83e-02, avg batch time: 0.4915, average train loss: 0.0038
[09/26 11:14:50 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 0.6270
[09/26 11:14:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 11:14:50 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:14:57 visual_prompt]: Epoch 89 / 100: avg data time: 5.14e-02, avg batch time: 0.4934, average train loss: 0.0039
[09/26 11:14:58 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 0.6287
[09/26 11:14:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:14:58 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:15:05 visual_prompt]: Epoch 90 / 100: avg data time: 5.18e-02, avg batch time: 0.4943, average train loss: 0.0038
[09/26 11:15:07 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 0.6293
[09/26 11:15:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:07 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:15:14 visual_prompt]: Epoch 91 / 100: avg data time: 7.12e-02, avg batch time: 0.5118, average train loss: 0.0039
[09/26 11:15:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1658, average loss: 0.6289
[09/26 11:15:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:15 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:15:22 visual_prompt]: Epoch 92 / 100: avg data time: 6.61e-02, avg batch time: 0.5069, average train loss: 0.0039
[09/26 11:15:24 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 0.6283
[09/26 11:15:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:24 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:15:31 visual_prompt]: Epoch 93 / 100: avg data time: 5.76e-02, avg batch time: 0.4989, average train loss: 0.0039
[09/26 11:15:32 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 0.6278
[09/26 11:15:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.00	
[09/26 11:15:32 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:15:39 visual_prompt]: Epoch 94 / 100: avg data time: 5.62e-02, avg batch time: 0.4981, average train loss: 0.0040
[09/26 11:15:41 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 0.6277
[09/26 11:15:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:41 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:15:47 visual_prompt]: Epoch 95 / 100: avg data time: 4.85e-02, avg batch time: 0.4899, average train loss: 0.0038
[09/26 11:15:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 0.6279
[09/26 11:15:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:49 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:15:56 visual_prompt]: Epoch 96 / 100: avg data time: 5.40e-02, avg batch time: 0.4970, average train loss: 0.0037
[09/26 11:15:58 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 0.6282
[09/26 11:15:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:15:58 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:16:05 visual_prompt]: Epoch 97 / 100: avg data time: 5.70e-02, avg batch time: 0.5000, average train loss: 0.0039
[09/26 11:16:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1660, average loss: 0.6282
[09/26 11:16:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:16:06 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:16:13 visual_prompt]: Epoch 98 / 100: avg data time: 6.54e-02, avg batch time: 0.5062, average train loss: 0.0038
[09/26 11:16:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 0.6282
[09/26 11:16:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:16:15 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:16:22 visual_prompt]: Epoch 99 / 100: avg data time: 6.24e-02, avg batch time: 0.5033, average train loss: 0.0038
[09/26 11:16:23 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1659, average loss: 0.6281
[09/26 11:16:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:16:23 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:16:30 visual_prompt]: Epoch 100 / 100: avg data time: 5.54e-02, avg batch time: 0.4970, average train loss: 0.0038
[09/26 11:16:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 0.6281
[09/26 11:16:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:16:32 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:16:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:16:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:16:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:16:32 visual_prompt]: Training with config:
[09/26 11:16:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr2.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:16:32 visual_prompt]: Loading training data...
[09/26 11:16:32 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:16:33 visual_prompt]: Number of images: 800
[09/26 11:16:33 visual_prompt]: Number of classes: 45 / 45
[09/26 11:16:33 visual_prompt]: Loading validation data...
[09/26 11:16:33 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:16:33 visual_prompt]: Number of images: 200
[09/26 11:16:33 visual_prompt]: Number of classes: 45 / 45
[09/26 11:16:33 visual_prompt]: Constructing models...
[09/26 11:16:35 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 11:16:35 visual_prompt]: tuned percent:0.574
[09/26 11:16:36 visual_prompt]: Device used for model: 0
[09/26 11:16:36 visual_prompt]: Setting up Evaluator...
[09/26 11:16:36 visual_prompt]: Setting up Trainer...
[09/26 11:16:36 visual_prompt]: 	Setting up the optimizer...
[09/26 11:16:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:16:42 visual_prompt]: Epoch 1 / 100: avg data time: 5.93e-02, avg batch time: 0.5001, average train loss: 3.8881
[09/26 11:16:44 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1659, average loss: 3.9529
[09/26 11:16:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 11:16:44 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 11:16:44 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/26 11:16:51 visual_prompt]: Epoch 2 / 100: avg data time: 4.81e-02, avg batch time: 0.4885, average train loss: 3.8406
[09/26 11:16:52 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1658, average loss: 3.8038
[09/26 11:16:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 11:16:52 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 11:16:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/26 11:16:59 visual_prompt]: Epoch 3 / 100: avg data time: 4.66e-02, avg batch time: 0.4912, average train loss: 3.7145
[09/26 11:17:00 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 3.7721
[09/26 11:17:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 29.50	
[09/26 11:17:00 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 11:17:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/26 11:17:07 visual_prompt]: Epoch 4 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 3.8355
[09/26 11:17:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 3.7874
[09/26 11:17:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 18.00	
[09/26 11:17:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/26 11:17:16 visual_prompt]: Epoch 5 / 100: avg data time: 6.27e-02, avg batch time: 0.5038, average train loss: 3.5597
[09/26 11:17:17 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 3.3597
[09/26 11:17:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 32.00	
[09/26 11:17:17 visual_prompt]: Best epoch 5: best metric: 0.080
[09/26 11:17:17 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/26 11:17:24 visual_prompt]: Epoch 6 / 100: avg data time: 5.16e-02, avg batch time: 0.4957, average train loss: 3.2175
[09/26 11:17:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 3.2562
[09/26 11:17:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 43.00	
[09/26 11:17:26 visual_prompt]: Best epoch 6: best metric: 0.085
[09/26 11:17:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/26 11:17:32 visual_prompt]: Epoch 7 / 100: avg data time: 4.79e-02, avg batch time: 0.4907, average train loss: 2.8368
[09/26 11:17:34 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1661, average loss: 2.6891
[09/26 11:17:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 58.50	
[09/26 11:17:34 visual_prompt]: Best epoch 7: best metric: 0.255
[09/26 11:17:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/26 11:17:41 visual_prompt]: Epoch 8 / 100: avg data time: 5.23e-02, avg batch time: 0.4951, average train loss: 2.8663
[09/26 11:17:42 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1660, average loss: 3.4064
[09/26 11:17:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 35.00	
[09/26 11:17:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/26 11:17:49 visual_prompt]: Epoch 9 / 100: avg data time: 5.08e-02, avg batch time: 0.4924, average train loss: 2.6223
[09/26 11:17:51 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 2.8372
[09/26 11:17:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 62.00	
[09/26 11:17:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/26 11:17:57 visual_prompt]: Epoch 10 / 100: avg data time: 5.37e-02, avg batch time: 0.4950, average train loss: 2.0821
[09/26 11:17:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 2.3110
[09/26 11:17:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 37.50	top5: 73.00	
[09/26 11:17:59 visual_prompt]: Best epoch 10: best metric: 0.375
[09/26 11:17:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/26 11:18:06 visual_prompt]: Epoch 11 / 100: avg data time: 5.27e-02, avg batch time: 0.4947, average train loss: 2.1926
[09/26 11:18:07 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 2.0720
[09/26 11:18:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 42.00	top5: 74.00	
[09/26 11:18:07 visual_prompt]: Best epoch 11: best metric: 0.420
[09/26 11:18:07 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/26 11:18:14 visual_prompt]: Epoch 12 / 100: avg data time: 4.82e-02, avg batch time: 0.4905, average train loss: 1.5444
[09/26 11:18:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 1.6408
[09/26 11:18:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.50	top5: 87.00	
[09/26 11:18:15 visual_prompt]: Best epoch 12: best metric: 0.575
[09/26 11:18:15 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/26 11:18:22 visual_prompt]: Epoch 13 / 100: avg data time: 4.51e-02, avg batch time: 0.4881, average train loss: 1.0755
[09/26 11:18:24 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 2.0134
[09/26 11:18:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 51.50	top5: 83.00	
[09/26 11:18:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/26 11:18:31 visual_prompt]: Epoch 14 / 100: avg data time: 5.54e-02, avg batch time: 0.4974, average train loss: 0.7701
[09/26 11:18:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.3109
[09/26 11:18:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 90.50	
[09/26 11:18:32 visual_prompt]: Best epoch 14: best metric: 0.635
[09/26 11:18:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/26 11:18:39 visual_prompt]: Epoch 15 / 100: avg data time: 6.15e-02, avg batch time: 0.5026, average train loss: 0.4925
[09/26 11:18:41 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 1.2334
[09/26 11:18:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 95.50	
[09/26 11:18:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/26 11:18:47 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e-02, avg batch time: 0.4923, average train loss: 0.2546
[09/26 11:18:49 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.3648
[09/26 11:18:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 93.50	
[09/26 11:18:49 visual_prompt]: Best epoch 16: best metric: 0.655
[09/26 11:18:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/26 11:18:56 visual_prompt]: Epoch 17 / 100: avg data time: 4.94e-02, avg batch time: 0.4923, average train loss: 0.1916
[09/26 11:18:57 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 1.3603
[09/26 11:18:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 11:18:57 visual_prompt]: Best epoch 17: best metric: 0.710
[09/26 11:18:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/26 11:19:04 visual_prompt]: Epoch 18 / 100: avg data time: 4.96e-02, avg batch time: 0.4922, average train loss: 0.1217
[09/26 11:19:06 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.3015
[09/26 11:19:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 11:19:06 visual_prompt]: Best epoch 18: best metric: 0.730
[09/26 11:19:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/26 11:19:12 visual_prompt]: Epoch 19 / 100: avg data time: 4.88e-02, avg batch time: 0.4908, average train loss: 0.0852
[09/26 11:19:14 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 1.3089
[09/26 11:19:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 11:19:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/26 11:19:21 visual_prompt]: Epoch 20 / 100: avg data time: 6.16e-02, avg batch time: 0.5032, average train loss: 0.0536
[09/26 11:19:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.4145
[09/26 11:19:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 95.00	
[09/26 11:19:22 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/26 11:19:29 visual_prompt]: Epoch 21 / 100: avg data time: 5.17e-02, avg batch time: 0.4934, average train loss: 0.0482
[09/26 11:19:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 1.7069
[09/26 11:19:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 11:19:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/26 11:19:38 visual_prompt]: Epoch 22 / 100: avg data time: 6.47e-02, avg batch time: 0.5063, average train loss: 0.0605
[09/26 11:19:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 1.5235
[09/26 11:19:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 11:19:39 visual_prompt]: Best epoch 22: best metric: 0.740
[09/26 11:19:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/26 11:19:46 visual_prompt]: Epoch 23 / 100: avg data time: 4.79e-02, avg batch time: 0.4908, average train loss: 0.0321
[09/26 11:19:47 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1665, average loss: 1.2409
[09/26 11:19:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 11:19:47 visual_prompt]: Best epoch 23: best metric: 0.760
[09/26 11:19:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/26 11:19:54 visual_prompt]: Epoch 24 / 100: avg data time: 6.96e-02, avg batch time: 0.5115, average train loss: 0.0323
[09/26 11:19:56 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 1.2504
[09/26 11:19:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.50	
[09/26 11:19:56 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/26 11:20:03 visual_prompt]: Epoch 25 / 100: avg data time: 5.17e-02, avg batch time: 0.4954, average train loss: 0.0122
[09/26 11:20:04 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 1.1645
[09/26 11:20:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 11:20:04 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/26 11:20:11 visual_prompt]: Epoch 26 / 100: avg data time: 5.14e-02, avg batch time: 0.4956, average train loss: 0.0171
[09/26 11:20:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 1.2519
[09/26 11:20:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.50	
[09/26 11:20:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/26 11:20:20 visual_prompt]: Epoch 27 / 100: avg data time: 4.92e-02, avg batch time: 0.4923, average train loss: 0.0063
[09/26 11:20:21 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1664, average loss: 1.2925
[09/26 11:20:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 11:20:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/26 11:20:28 visual_prompt]: Epoch 28 / 100: avg data time: 5.00e-02, avg batch time: 0.4929, average train loss: 0.0017
[09/26 11:20:29 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.3234
[09/26 11:20:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.00	
[09/26 11:20:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/26 11:20:36 visual_prompt]: Epoch 29 / 100: avg data time: 5.12e-02, avg batch time: 0.4945, average train loss: 0.0025
[09/26 11:20:38 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 1.2627
[09/26 11:20:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 11:20:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/26 11:20:45 visual_prompt]: Epoch 30 / 100: avg data time: 5.23e-02, avg batch time: 0.4951, average train loss: 0.0008
[09/26 11:20:46 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.2113
[09/26 11:20:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:20:46 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/26 11:20:53 visual_prompt]: Epoch 31 / 100: avg data time: 5.13e-02, avg batch time: 0.4935, average train loss: 0.0005
[09/26 11:20:55 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.1998
[09/26 11:20:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:20:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/26 11:21:01 visual_prompt]: Epoch 32 / 100: avg data time: 5.06e-02, avg batch time: 0.4930, average train loss: 0.0004
[09/26 11:21:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 1.1984
[09/26 11:21:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/26 11:21:10 visual_prompt]: Epoch 33 / 100: avg data time: 5.84e-02, avg batch time: 0.5015, average train loss: 0.0004
[09/26 11:21:11 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 1.1942
[09/26 11:21:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/26 11:21:18 visual_prompt]: Epoch 34 / 100: avg data time: 5.65e-02, avg batch time: 0.4988, average train loss: 0.0004
[09/26 11:21:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.1887
[09/26 11:21:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/26 11:21:27 visual_prompt]: Epoch 35 / 100: avg data time: 6.05e-02, avg batch time: 0.5023, average train loss: 0.0003
[09/26 11:21:28 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1665, average loss: 1.1837
[09/26 11:21:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/26 11:21:35 visual_prompt]: Epoch 36 / 100: avg data time: 6.14e-02, avg batch time: 0.5035, average train loss: 0.0004
[09/26 11:21:37 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 1.1825
[09/26 11:21:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/26 11:21:44 visual_prompt]: Epoch 37 / 100: avg data time: 5.17e-02, avg batch time: 0.4968, average train loss: 0.0003
[09/26 11:21:45 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 1.1817
[09/26 11:21:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 11:21:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/26 11:21:52 visual_prompt]: Epoch 38 / 100: avg data time: 5.45e-02, avg batch time: 0.4966, average train loss: 0.0005
[09/26 11:21:54 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.1849
[09/26 11:21:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:21:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/26 11:22:00 visual_prompt]: Epoch 39 / 100: avg data time: 5.25e-02, avg batch time: 0.4958, average train loss: 0.0003
[09/26 11:22:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.1870
[09/26 11:22:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:02 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/26 11:22:09 visual_prompt]: Epoch 40 / 100: avg data time: 6.39e-02, avg batch time: 0.5061, average train loss: 0.0003
[09/26 11:22:11 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 1.1840
[09/26 11:22:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:11 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/26 11:22:17 visual_prompt]: Epoch 41 / 100: avg data time: 5.74e-02, avg batch time: 0.5000, average train loss: 0.0003
[09/26 11:22:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 1.1689
[09/26 11:22:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/26 11:22:26 visual_prompt]: Epoch 42 / 100: avg data time: 4.85e-02, avg batch time: 0.4924, average train loss: 0.0003
[09/26 11:22:27 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1663, average loss: 1.1595
[09/26 11:22:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/26 11:22:34 visual_prompt]: Epoch 43 / 100: avg data time: 4.95e-02, avg batch time: 0.4930, average train loss: 0.0003
[09/26 11:22:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.1538
[09/26 11:22:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/26 11:22:43 visual_prompt]: Epoch 44 / 100: avg data time: 5.62e-02, avg batch time: 0.4983, average train loss: 0.0003
[09/26 11:22:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1664, average loss: 1.1519
[09/26 11:22:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/26 11:22:51 visual_prompt]: Epoch 45 / 100: avg data time: 4.96e-02, avg batch time: 0.4923, average train loss: 0.0002
[09/26 11:22:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.1517
[09/26 11:22:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:22:53 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/26 11:22:59 visual_prompt]: Epoch 46 / 100: avg data time: 5.46e-02, avg batch time: 0.4970, average train loss: 0.0002
[09/26 11:23:01 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.1497
[09/26 11:23:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:23:01 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/26 11:23:08 visual_prompt]: Epoch 47 / 100: avg data time: 5.00e-02, avg batch time: 0.4934, average train loss: 0.0002
[09/26 11:23:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.1487
[09/26 11:23:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:23:09 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/26 11:23:16 visual_prompt]: Epoch 48 / 100: avg data time: 4.92e-02, avg batch time: 0.4936, average train loss: 0.0002
[09/26 11:23:18 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1663, average loss: 1.1488
[09/26 11:23:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:23:18 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/26 11:23:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.67e-02, avg batch time: 0.4993, average train loss: 0.0002
[09/26 11:23:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.1500
[09/26 11:23:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:23:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/26 11:23:33 visual_prompt]: Epoch 50 / 100: avg data time: 5.39e-02, avg batch time: 0.4956, average train loss: 0.0003
[09/26 11:23:34 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1664, average loss: 1.1523
[09/26 11:23:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:23:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/26 11:23:41 visual_prompt]: Epoch 51 / 100: avg data time: 5.06e-02, avg batch time: 0.4936, average train loss: 0.0002
[09/26 11:23:43 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 1.1546
[09/26 11:23:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:23:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/26 11:23:50 visual_prompt]: Epoch 52 / 100: avg data time: 5.54e-02, avg batch time: 0.4995, average train loss: 0.0002
[09/26 11:23:51 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1666, average loss: 1.1561
[09/26 11:23:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:23:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/26 11:23:58 visual_prompt]: Epoch 53 / 100: avg data time: 4.80e-02, avg batch time: 0.4918, average train loss: 0.0002
[09/26 11:24:00 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1664, average loss: 1.1564
[09/26 11:24:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:24:00 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/26 11:24:06 visual_prompt]: Epoch 54 / 100: avg data time: 4.93e-02, avg batch time: 0.4943, average train loss: 0.0003
[09/26 11:24:08 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1666, average loss: 1.1571
[09/26 11:24:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:24:08 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/26 11:24:15 visual_prompt]: Epoch 55 / 100: avg data time: 4.75e-02, avg batch time: 0.4896, average train loss: 0.0002
[09/26 11:24:16 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 1.1573
[09/26 11:24:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:16 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/26 11:24:23 visual_prompt]: Epoch 56 / 100: avg data time: 5.50e-02, avg batch time: 0.4978, average train loss: 0.0002
[09/26 11:24:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1667, average loss: 1.1565
[09/26 11:24:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:25 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/26 11:24:31 visual_prompt]: Epoch 57 / 100: avg data time: 5.08e-02, avg batch time: 0.4939, average train loss: 0.0002
[09/26 11:24:33 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1668, average loss: 1.1561
[09/26 11:24:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:33 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/26 11:24:40 visual_prompt]: Epoch 58 / 100: avg data time: 5.00e-02, avg batch time: 0.4932, average train loss: 0.0002
[09/26 11:24:41 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1666, average loss: 1.1554
[09/26 11:24:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:41 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/26 11:24:48 visual_prompt]: Epoch 59 / 100: avg data time: 5.16e-02, avg batch time: 0.4957, average train loss: 0.0002
[09/26 11:24:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1666, average loss: 1.1545
[09/26 11:24:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:49 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/26 11:24:56 visual_prompt]: Epoch 60 / 100: avg data time: 5.07e-02, avg batch time: 0.4953, average train loss: 0.0002
[09/26 11:24:58 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1666, average loss: 1.1529
[09/26 11:24:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:24:58 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/26 11:25:05 visual_prompt]: Epoch 61 / 100: avg data time: 6.45e-02, avg batch time: 0.5064, average train loss: 0.0002
[09/26 11:25:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 1.1526
[09/26 11:25:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:25:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/26 11:25:13 visual_prompt]: Epoch 62 / 100: avg data time: 5.16e-02, avg batch time: 0.4948, average train loss: 0.0002
[09/26 11:25:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1666, average loss: 1.1520
[09/26 11:25:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:25:15 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/26 11:25:21 visual_prompt]: Epoch 63 / 100: avg data time: 5.08e-02, avg batch time: 0.4934, average train loss: 0.0002
[09/26 11:25:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 1.1516
[09/26 11:25:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:25:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/26 11:25:30 visual_prompt]: Epoch 64 / 100: avg data time: 5.56e-02, avg batch time: 0.4976, average train loss: 0.0002
[09/26 11:25:31 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1665, average loss: 1.1512
[09/26 11:25:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:25:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/26 11:25:38 visual_prompt]: Epoch 65 / 100: avg data time: 5.46e-02, avg batch time: 0.4976, average train loss: 0.0002
[09/26 11:25:40 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 1.1510
[09/26 11:25:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 11:25:40 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/26 11:25:47 visual_prompt]: Epoch 66 / 100: avg data time: 5.54e-02, avg batch time: 0.4998, average train loss: 0.0002
[09/26 11:25:48 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1664, average loss: 1.1514
[09/26 11:25:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:25:48 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/26 11:25:55 visual_prompt]: Epoch 67 / 100: avg data time: 6.60e-02, avg batch time: 0.5074, average train loss: 0.0002
[09/26 11:25:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 1.1514
[09/26 11:25:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:25:57 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/26 11:26:03 visual_prompt]: Epoch 68 / 100: avg data time: 5.17e-02, avg batch time: 0.4942, average train loss: 0.0002
[09/26 11:26:05 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1665, average loss: 1.1506
[09/26 11:26:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:05 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/26 11:26:12 visual_prompt]: Epoch 69 / 100: avg data time: 6.20e-02, avg batch time: 0.5039, average train loss: 0.0002
[09/26 11:26:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 1.1507
[09/26 11:26:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:13 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/26 11:26:20 visual_prompt]: Epoch 70 / 100: avg data time: 5.05e-02, avg batch time: 0.4955, average train loss: 0.0001
[09/26 11:26:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1666, average loss: 1.1505
[09/26 11:26:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:22 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/26 11:26:29 visual_prompt]: Epoch 71 / 100: avg data time: 6.06e-02, avg batch time: 0.5029, average train loss: 0.0002
[09/26 11:26:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.1506
[09/26 11:26:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:30 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/26 11:26:37 visual_prompt]: Epoch 72 / 100: avg data time: 5.37e-02, avg batch time: 0.4983, average train loss: 0.0002
[09/26 11:26:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1667, average loss: 1.1503
[09/26 11:26:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/26 11:26:45 visual_prompt]: Epoch 73 / 100: avg data time: 5.79e-02, avg batch time: 0.5007, average train loss: 0.0002
[09/26 11:26:47 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1681, average loss: 1.1503
[09/26 11:26:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:47 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/26 11:26:54 visual_prompt]: Epoch 74 / 100: avg data time: 5.05e-02, avg batch time: 0.4943, average train loss: 0.0002
[09/26 11:26:55 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1668, average loss: 1.1506
[09/26 11:26:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:26:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/26 11:27:02 visual_prompt]: Epoch 75 / 100: avg data time: 5.18e-02, avg batch time: 0.4946, average train loss: 0.0002
[09/26 11:27:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1667, average loss: 1.1504
[09/26 11:27:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:04 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/26 11:27:11 visual_prompt]: Epoch 76 / 100: avg data time: 5.68e-02, avg batch time: 0.4989, average train loss: 0.0001
[09/26 11:27:12 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1665, average loss: 1.1501
[09/26 11:27:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/26 11:27:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.51e-02, avg batch time: 0.4991, average train loss: 0.0003
[09/26 11:27:21 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.1666, average loss: 1.1505
[09/26 11:27:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:21 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/26 11:27:27 visual_prompt]: Epoch 78 / 100: avg data time: 5.02e-02, avg batch time: 0.4926, average train loss: 0.0002
[09/26 11:27:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1667, average loss: 1.1495
[09/26 11:27:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/26 11:27:36 visual_prompt]: Epoch 79 / 100: avg data time: 6.08e-02, avg batch time: 0.5033, average train loss: 0.0002
[09/26 11:27:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.1483
[09/26 11:27:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/26 11:27:44 visual_prompt]: Epoch 80 / 100: avg data time: 5.75e-02, avg batch time: 0.4993, average train loss: 0.0002
[09/26 11:27:46 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.1477
[09/26 11:27:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:46 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/26 11:27:53 visual_prompt]: Epoch 81 / 100: avg data time: 5.02e-02, avg batch time: 0.4938, average train loss: 0.0002
[09/26 11:27:54 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.1476
[09/26 11:27:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:27:54 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/26 11:28:01 visual_prompt]: Epoch 82 / 100: avg data time: 4.99e-02, avg batch time: 0.4940, average train loss: 0.0002
[09/26 11:28:03 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 1.1474
[09/26 11:28:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/26 11:28:10 visual_prompt]: Epoch 83 / 100: avg data time: 6.16e-02, avg batch time: 0.5039, average train loss: 0.0002
[09/26 11:28:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.1473
[09/26 11:28:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/26 11:28:18 visual_prompt]: Epoch 84 / 100: avg data time: 4.99e-02, avg batch time: 0.4928, average train loss: 0.0001
[09/26 11:28:20 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1665, average loss: 1.1473
[09/26 11:28:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/26 11:28:26 visual_prompt]: Epoch 85 / 100: avg data time: 5.68e-02, avg batch time: 0.4985, average train loss: 0.0002
[09/26 11:28:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 1.1472
[09/26 11:28:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:28 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/26 11:28:35 visual_prompt]: Epoch 86 / 100: avg data time: 5.97e-02, avg batch time: 0.5022, average train loss: 0.0002
[09/26 11:28:36 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 1.1471
[09/26 11:28:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/26 11:28:43 visual_prompt]: Epoch 87 / 100: avg data time: 6.41e-02, avg batch time: 0.5067, average train loss: 0.0002
[09/26 11:28:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 1.1470
[09/26 11:28:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/26 11:28:52 visual_prompt]: Epoch 88 / 100: avg data time: 5.83e-02, avg batch time: 0.4996, average train loss: 0.0002
[09/26 11:28:53 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.1471
[09/26 11:28:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:28:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/26 11:29:00 visual_prompt]: Epoch 89 / 100: avg data time: 4.98e-02, avg batch time: 0.4925, average train loss: 0.0002
[09/26 11:29:02 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1663, average loss: 1.1472
[09/26 11:29:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/26 11:29:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.33e-02, avg batch time: 0.4963, average train loss: 0.0002
[09/26 11:29:10 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 1.1472
[09/26 11:29:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/26 11:29:17 visual_prompt]: Epoch 91 / 100: avg data time: 6.10e-02, avg batch time: 0.5026, average train loss: 0.0002
[09/26 11:29:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 1.1472
[09/26 11:29:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:19 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/26 11:29:25 visual_prompt]: Epoch 92 / 100: avg data time: 5.19e-02, avg batch time: 0.4966, average train loss: 0.0002
[09/26 11:29:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.1471
[09/26 11:29:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/26 11:29:34 visual_prompt]: Epoch 93 / 100: avg data time: 6.25e-02, avg batch time: 0.5049, average train loss: 0.0002
[09/26 11:29:35 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1663, average loss: 1.1471
[09/26 11:29:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/26 11:29:42 visual_prompt]: Epoch 94 / 100: avg data time: 5.59e-02, avg batch time: 0.5000, average train loss: 0.0001
[09/26 11:29:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 1.1471
[09/26 11:29:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:44 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/26 11:29:50 visual_prompt]: Epoch 95 / 100: avg data time: 5.00e-02, avg batch time: 0.4929, average train loss: 0.0001
[09/26 11:29:52 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1664, average loss: 1.1470
[09/26 11:29:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:29:52 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/26 11:29:59 visual_prompt]: Epoch 96 / 100: avg data time: 4.84e-02, avg batch time: 0.4908, average train loss: 0.0002
[09/26 11:30:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.1471
[09/26 11:30:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:30:00 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/26 11:30:07 visual_prompt]: Epoch 97 / 100: avg data time: 5.18e-02, avg batch time: 0.4936, average train loss: 0.0001
[09/26 11:30:09 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.1470
[09/26 11:30:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:30:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/26 11:30:16 visual_prompt]: Epoch 98 / 100: avg data time: 5.02e-02, avg batch time: 0.4937, average train loss: 0.0002
[09/26 11:30:17 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.1471
[09/26 11:30:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:30:17 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/26 11:30:24 visual_prompt]: Epoch 99 / 100: avg data time: 5.01e-02, avg batch time: 0.4914, average train loss: 0.0002
[09/26 11:30:25 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1663, average loss: 1.1471
[09/26 11:30:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:30:25 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/26 11:30:32 visual_prompt]: Epoch 100 / 100: avg data time: 6.04e-02, avg batch time: 0.5021, average train loss: 0.0002
[09/26 11:30:34 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.1471
[09/26 11:30:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 11:30:34 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:30:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:30:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:30:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:30:34 visual_prompt]: Training with config:
[09/26 11:30:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:30:34 visual_prompt]: Loading training data...
[09/26 11:30:34 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:30:35 visual_prompt]: Number of images: 800
[09/26 11:30:35 visual_prompt]: Number of classes: 45 / 45
[09/26 11:30:35 visual_prompt]: Loading validation data...
[09/26 11:30:35 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:30:35 visual_prompt]: Number of images: 200
[09/26 11:30:35 visual_prompt]: Number of classes: 45 / 45
[09/26 11:30:35 visual_prompt]: Constructing models...
[09/26 11:30:38 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 11:30:38 visual_prompt]: tuned percent:0.574
[09/26 11:30:38 visual_prompt]: Device used for model: 0
[09/26 11:30:38 visual_prompt]: Setting up Evaluator...
[09/26 11:30:38 visual_prompt]: Setting up Trainer...
[09/26 11:30:38 visual_prompt]: 	Setting up the optimizer...
[09/26 11:30:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:30:45 visual_prompt]: Epoch 1 / 100: avg data time: 6.01e-02, avg batch time: 0.5015, average train loss: 3.8951
[09/26 11:30:46 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 11:30:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 11:30:46 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 11:30:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 11:30:53 visual_prompt]: Epoch 2 / 100: avg data time: 6.31e-02, avg batch time: 0.5048, average train loss: 3.8278
[09/26 11:30:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 3.7719
[09/26 11:30:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 18.00	
[09/26 11:30:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 11:31:02 visual_prompt]: Epoch 3 / 100: avg data time: 6.42e-02, avg batch time: 0.5051, average train loss: 3.6609
[09/26 11:31:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1659, average loss: 4.3099
[09/26 11:31:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 12.50	
[09/26 11:31:03 visual_prompt]: Best epoch 3: best metric: 0.075
[09/26 11:31:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 11:31:10 visual_prompt]: Epoch 4 / 100: avg data time: 5.28e-02, avg batch time: 0.4938, average train loss: 3.8679
[09/26 11:31:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 3.8388
[09/26 11:31:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 11:31:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 11:31:19 visual_prompt]: Epoch 5 / 100: avg data time: 5.28e-02, avg batch time: 0.4954, average train loss: 3.7559
[09/26 11:31:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 3.8095
[09/26 11:31:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 17.00	
[09/26 11:31:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 11:31:27 visual_prompt]: Epoch 6 / 100: avg data time: 5.41e-02, avg batch time: 0.4951, average train loss: 3.8003
[09/26 11:31:29 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1661, average loss: 3.7152
[09/26 11:31:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 15.00	
[09/26 11:31:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 11:31:35 visual_prompt]: Epoch 7 / 100: avg data time: 6.59e-02, avg batch time: 0.5063, average train loss: 3.7565
[09/26 11:31:37 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1657, average loss: 3.7218
[09/26 11:31:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 18.50	
[09/26 11:31:37 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 11:31:44 visual_prompt]: Epoch 8 / 100: avg data time: 6.64e-02, avg batch time: 0.5071, average train loss: 3.8987
[09/26 11:31:46 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 3.8599
[09/26 11:31:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 15.00	
[09/26 11:31:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 11:31:52 visual_prompt]: Epoch 9 / 100: avg data time: 5.06e-02, avg batch time: 0.4919, average train loss: 3.8757
[09/26 11:31:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 3.8783
[09/26 11:31:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 13.00	
[09/26 11:31:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 11:32:01 visual_prompt]: Epoch 10 / 100: avg data time: 6.43e-02, avg batch time: 0.5048, average train loss: 3.8747
[09/26 11:32:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 3.8785
[09/26 11:32:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 11:32:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 11:32:09 visual_prompt]: Epoch 11 / 100: avg data time: 6.21e-02, avg batch time: 0.5033, average train loss: 3.8860
[09/26 11:32:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 3.8872
[09/26 11:32:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 11:32:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 11:32:18 visual_prompt]: Epoch 12 / 100: avg data time: 5.47e-02, avg batch time: 0.4965, average train loss: 3.8843
[09/26 11:32:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1658, average loss: 3.8593
[09/26 11:32:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 11:32:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 11:32:26 visual_prompt]: Epoch 13 / 100: avg data time: 5.34e-02, avg batch time: 0.4948, average train loss: 3.8660
[09/26 11:32:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 3.8442
[09/26 11:32:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 11:32:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 11:32:34 visual_prompt]: Epoch 14 / 100: avg data time: 6.03e-02, avg batch time: 0.5011, average train loss: 3.8542
[09/26 11:32:36 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 3.9368
[09/26 11:32:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.00	
[09/26 11:32:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 11:32:43 visual_prompt]: Epoch 15 / 100: avg data time: 4.94e-02, avg batch time: 0.4918, average train loss: 3.8489
[09/26 11:32:44 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1659, average loss: 3.8301
[09/26 11:32:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 10.50	
[09/26 11:32:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 11:32:51 visual_prompt]: Epoch 16 / 100: avg data time: 5.58e-02, avg batch time: 0.4976, average train loss: 3.8662
[09/26 11:32:53 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 3.9013
[09/26 11:32:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 11:32:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 11:33:00 visual_prompt]: Epoch 17 / 100: avg data time: 4.98e-02, avg batch time: 0.4927, average train loss: 3.8655
[09/26 11:33:01 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1662, average loss: 3.8745
[09/26 11:33:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 11:33:01 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 11:33:08 visual_prompt]: Epoch 18 / 100: avg data time: 5.12e-02, avg batch time: 0.4953, average train loss: 3.8577
[09/26 11:33:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 3.8764
[09/26 11:33:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 12.00	
[09/26 11:33:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 11:33:16 visual_prompt]: Epoch 19 / 100: avg data time: 5.20e-02, avg batch time: 0.4937, average train loss: 3.8805
[09/26 11:33:18 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 3.8684
[09/26 11:33:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 11:33:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 11:33:25 visual_prompt]: Epoch 20 / 100: avg data time: 4.90e-02, avg batch time: 0.4914, average train loss: 3.8696
[09/26 11:33:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 3.8835
[09/26 11:33:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.50	
[09/26 11:33:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 11:33:33 visual_prompt]: Epoch 21 / 100: avg data time: 5.40e-02, avg batch time: 0.4969, average train loss: 3.8977
[09/26 11:33:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 3.8595
[09/26 11:33:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:33:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 11:33:41 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 3.8993
[09/26 11:33:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 3.8764
[09/26 11:33:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 11.50	
[09/26 11:33:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 11:33:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.36e-02, avg batch time: 0.4969, average train loss: 3.8613
[09/26 11:33:51 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 3.8635
[09/26 11:33:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 8.50	
[09/26 11:33:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 11:33:58 visual_prompt]: Epoch 24 / 100: avg data time: 4.88e-02, avg batch time: 0.4925, average train loss: 3.8582
[09/26 11:34:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 3.8660
[09/26 11:34:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 9.00	
[09/26 11:34:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 11:34:07 visual_prompt]: Epoch 25 / 100: avg data time: 4.97e-02, avg batch time: 0.4935, average train loss: 3.8657
[09/26 11:34:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 4.0104
[09/26 11:34:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 11:34:08 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 11:34:15 visual_prompt]: Epoch 26 / 100: avg data time: 6.50e-02, avg batch time: 0.5071, average train loss: 3.8487
[09/26 11:34:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 3.8462
[09/26 11:34:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.00	
[09/26 11:34:17 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 11:34:23 visual_prompt]: Epoch 27 / 100: avg data time: 5.30e-02, avg batch time: 0.4948, average train loss: 3.8857
[09/26 11:34:25 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 3.8782
[09/26 11:34:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 11:34:25 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 11:34:32 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e-02, avg batch time: 0.4926, average train loss: 3.8659
[09/26 11:34:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1660, average loss: 3.8337
[09/26 11:34:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 11:34:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 11:34:40 visual_prompt]: Epoch 29 / 100: avg data time: 5.34e-02, avg batch time: 0.4941, average train loss: 3.8452
[09/26 11:34:42 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 3.8410
[09/26 11:34:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 11:34:42 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 11:34:49 visual_prompt]: Epoch 30 / 100: avg data time: 5.61e-02, avg batch time: 0.4995, average train loss: 3.8299
[09/26 11:34:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1661, average loss: 3.9168
[09/26 11:34:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 11:34:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 11:34:57 visual_prompt]: Epoch 31 / 100: avg data time: 5.55e-02, avg batch time: 0.4962, average train loss: 3.8568
[09/26 11:34:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 3.8587
[09/26 11:34:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.00	
[09/26 11:34:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 11:35:05 visual_prompt]: Epoch 32 / 100: avg data time: 6.07e-02, avg batch time: 0.5022, average train loss: 3.8602
[09/26 11:35:07 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 3.8642
[09/26 11:35:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 11.50	
[09/26 11:35:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 11:35:14 visual_prompt]: Epoch 33 / 100: avg data time: 5.82e-02, avg batch time: 0.4987, average train loss: 3.8504
[09/26 11:35:15 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1660, average loss: 3.8590
[09/26 11:35:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:35:15 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 11:35:22 visual_prompt]: Epoch 34 / 100: avg data time: 6.68e-02, avg batch time: 0.5078, average train loss: 3.8463
[09/26 11:35:24 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1661, average loss: 3.8445
[09/26 11:35:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 11:35:24 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 11:35:31 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e-02, avg batch time: 0.4920, average train loss: 3.8607
[09/26 11:35:32 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1660, average loss: 3.9091
[09/26 11:35:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 7.00	
[09/26 11:35:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 11:35:39 visual_prompt]: Epoch 36 / 100: avg data time: 6.73e-02, avg batch time: 0.5083, average train loss: 3.8471
[09/26 11:35:41 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 3.8573
[09/26 11:35:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 10.00	
[09/26 11:35:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 11:35:48 visual_prompt]: Epoch 37 / 100: avg data time: 5.93e-02, avg batch time: 0.5006, average train loss: 3.8722
[09/26 11:35:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 3.8230
[09/26 11:35:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.00	
[09/26 11:35:49 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 11:35:56 visual_prompt]: Epoch 38 / 100: avg data time: 6.57e-02, avg batch time: 0.5054, average train loss: 3.8471
[09/26 11:35:58 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1658, average loss: 3.8732
[09/26 11:35:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:35:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 11:36:05 visual_prompt]: Epoch 39 / 100: avg data time: 6.03e-02, avg batch time: 0.5008, average train loss: 3.8571
[09/26 11:36:06 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 3.9060
[09/26 11:36:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 11:36:06 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 11:36:13 visual_prompt]: Epoch 40 / 100: avg data time: 5.14e-02, avg batch time: 0.4930, average train loss: 3.8541
[09/26 11:36:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1658, average loss: 3.8241
[09/26 11:36:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.00	
[09/26 11:36:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 11:36:21 visual_prompt]: Epoch 41 / 100: avg data time: 5.63e-02, avg batch time: 0.4990, average train loss: 3.8426
[09/26 11:36:23 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1659, average loss: 3.8626
[09/26 11:36:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 9.00	
[09/26 11:36:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 11:36:30 visual_prompt]: Epoch 42 / 100: avg data time: 6.58e-02, avg batch time: 0.5064, average train loss: 3.8370
[09/26 11:36:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 3.8176
[09/26 11:36:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 14.50	
[09/26 11:36:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 11:36:39 visual_prompt]: Epoch 43 / 100: avg data time: 6.45e-02, avg batch time: 0.5055, average train loss: 3.8581
[09/26 11:36:40 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1657, average loss: 3.8321
[09/26 11:36:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 11:36:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 11:36:47 visual_prompt]: Epoch 44 / 100: avg data time: 6.26e-02, avg batch time: 0.5035, average train loss: 3.8440
[09/26 11:36:49 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1660, average loss: 3.8562
[09/26 11:36:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.50	
[09/26 11:36:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 11:36:56 visual_prompt]: Epoch 45 / 100: avg data time: 6.14e-02, avg batch time: 0.5032, average train loss: 3.8351
[09/26 11:36:57 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1661, average loss: 3.8179
[09/26 11:36:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 16.50	
[09/26 11:36:57 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 11:37:04 visual_prompt]: Epoch 46 / 100: avg data time: 5.03e-02, avg batch time: 0.4917, average train loss: 3.8205
[09/26 11:37:05 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 3.8421
[09/26 11:37:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 11:37:05 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 11:37:12 visual_prompt]: Epoch 47 / 100: avg data time: 6.08e-02, avg batch time: 0.5018, average train loss: 3.8263
[09/26 11:37:14 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1662, average loss: 3.8603
[09/26 11:37:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 11:37:14 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 11:37:21 visual_prompt]: Epoch 48 / 100: avg data time: 6.59e-02, avg batch time: 0.5067, average train loss: 3.8541
[09/26 11:37:23 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1659, average loss: 3.8744
[09/26 11:37:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 11:37:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 11:37:29 visual_prompt]: Epoch 49 / 100: avg data time: 5.24e-02, avg batch time: 0.4952, average train loss: 3.8666
[09/26 11:37:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1659, average loss: 3.8734
[09/26 11:37:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.00	
[09/26 11:37:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 11:37:38 visual_prompt]: Epoch 50 / 100: avg data time: 5.25e-02, avg batch time: 0.4944, average train loss: 3.8389
[09/26 11:37:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 3.8432
[09/26 11:37:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:37:39 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 11:37:46 visual_prompt]: Epoch 51 / 100: avg data time: 4.87e-02, avg batch time: 0.4910, average train loss: 3.8798
[09/26 11:37:47 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1659, average loss: 3.8634
[09/26 11:37:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 11:37:47 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 11:37:54 visual_prompt]: Epoch 52 / 100: avg data time: 5.36e-02, avg batch time: 0.4952, average train loss: 3.8260
[09/26 11:37:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 3.9038
[09/26 11:37:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 11:37:56 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 11:38:03 visual_prompt]: Epoch 53 / 100: avg data time: 5.29e-02, avg batch time: 0.4958, average train loss: 3.8398
[09/26 11:38:04 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1657, average loss: 3.8190
[09/26 11:38:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 12.50	
[09/26 11:38:04 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 11:38:11 visual_prompt]: Epoch 54 / 100: avg data time: 5.65e-02, avg batch time: 0.4998, average train loss: 3.8251
[09/26 11:38:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 3.8994
[09/26 11:38:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:38:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 11:38:19 visual_prompt]: Epoch 55 / 100: avg data time: 5.44e-02, avg batch time: 0.4978, average train loss: 3.8205
[09/26 11:38:21 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 3.8816
[09/26 11:38:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 13.50	
[09/26 11:38:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 11:38:28 visual_prompt]: Epoch 56 / 100: avg data time: 4.70e-02, avg batch time: 0.4892, average train loss: 3.8390
[09/26 11:38:29 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1661, average loss: 3.8730
[09/26 11:38:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:38:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 11:38:36 visual_prompt]: Epoch 57 / 100: avg data time: 5.04e-02, avg batch time: 0.4931, average train loss: 3.8358
[09/26 11:38:38 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 3.8702
[09/26 11:38:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 8.00	
[09/26 11:38:38 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 11:38:44 visual_prompt]: Epoch 58 / 100: avg data time: 5.05e-02, avg batch time: 0.4926, average train loss: 3.8370
[09/26 11:38:46 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 3.8484
[09/26 11:38:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.00	
[09/26 11:38:46 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 11:38:53 visual_prompt]: Epoch 59 / 100: avg data time: 5.12e-02, avg batch time: 0.4948, average train loss: 3.8302
[09/26 11:38:54 visual_prompt]: Inference (val):avg data time: 4.23e-05, avg batch time: 0.1662, average loss: 3.8599
[09/26 11:38:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 11:38:54 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 11:39:01 visual_prompt]: Epoch 60 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 3.8275
[09/26 11:39:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 3.8534
[09/26 11:39:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 9.50	
[09/26 11:39:03 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 11:39:09 visual_prompt]: Epoch 61 / 100: avg data time: 5.01e-02, avg batch time: 0.4940, average train loss: 3.8299
[09/26 11:39:11 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 3.8409
[09/26 11:39:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 14.00	
[09/26 11:39:11 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 11:39:18 visual_prompt]: Epoch 62 / 100: avg data time: 5.52e-02, avg batch time: 0.4966, average train loss: 3.8353
[09/26 11:39:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 3.8529
[09/26 11:39:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.50	
[09/26 11:39:19 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 11:39:26 visual_prompt]: Epoch 63 / 100: avg data time: 5.10e-02, avg batch time: 0.4954, average train loss: 3.8280
[09/26 11:39:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 3.8353
[09/26 11:39:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 13.50	
[09/26 11:39:28 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 11:39:35 visual_prompt]: Epoch 64 / 100: avg data time: 6.24e-02, avg batch time: 0.5049, average train loss: 3.8401
[09/26 11:39:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 3.8329
[09/26 11:39:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.50	top5: 14.00	
[09/26 11:39:36 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 11:39:43 visual_prompt]: Epoch 65 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 3.8182
[09/26 11:39:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 3.8350
[09/26 11:39:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 11:39:45 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 11:39:51 visual_prompt]: Epoch 66 / 100: avg data time: 4.95e-02, avg batch time: 0.4936, average train loss: 3.8229
[09/26 11:39:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 3.8535
[09/26 11:39:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 8.50	
[09/26 11:39:53 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 11:40:00 visual_prompt]: Epoch 67 / 100: avg data time: 6.78e-02, avg batch time: 0.5104, average train loss: 3.8187
[09/26 11:40:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 3.8359
[09/26 11:40:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 0.50	top5: 12.50	
[09/26 11:40:01 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 11:40:08 visual_prompt]: Epoch 68 / 100: avg data time: 5.76e-02, avg batch time: 0.5000, average train loss: 3.8105
[09/26 11:40:10 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 3.8218
[09/26 11:40:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 12.50	
[09/26 11:40:10 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 11:40:17 visual_prompt]: Epoch 69 / 100: avg data time: 5.31e-02, avg batch time: 0.4953, average train loss: 3.8053
[09/26 11:40:18 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 3.8487
[09/26 11:40:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.50	
[09/26 11:40:18 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 11:40:25 visual_prompt]: Epoch 70 / 100: avg data time: 5.31e-02, avg batch time: 0.4960, average train loss: 3.8147
[09/26 11:40:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 3.8229
[09/26 11:40:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 10.00	
[09/26 11:40:26 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 11:40:33 visual_prompt]: Epoch 71 / 100: avg data time: 5.81e-02, avg batch time: 0.5006, average train loss: 3.8085
[09/26 11:40:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 3.8274
[09/26 11:40:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:40:35 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 11:40:42 visual_prompt]: Epoch 72 / 100: avg data time: 5.11e-02, avg batch time: 0.4947, average train loss: 3.7917
[09/26 11:40:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 3.8355
[09/26 11:40:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 12.00	
[09/26 11:40:43 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 11:40:50 visual_prompt]: Epoch 73 / 100: avg data time: 6.10e-02, avg batch time: 0.5024, average train loss: 3.8012
[09/26 11:40:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 3.8314
[09/26 11:40:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 8.00	
[09/26 11:40:51 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 11:40:58 visual_prompt]: Epoch 74 / 100: avg data time: 5.67e-02, avg batch time: 0.5006, average train loss: 3.7679
[09/26 11:41:00 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1664, average loss: 3.7238
[09/26 11:41:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 21.50	
[09/26 11:41:00 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 11:41:07 visual_prompt]: Epoch 75 / 100: avg data time: 4.86e-02, avg batch time: 0.4928, average train loss: 3.7667
[09/26 11:41:08 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 3.8254
[09/26 11:41:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 15.50	
[09/26 11:41:08 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 11:41:15 visual_prompt]: Epoch 76 / 100: avg data time: 5.93e-02, avg batch time: 0.5006, average train loss: 3.7516
[09/26 11:41:17 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 3.8976
[09/26 11:41:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 11.50	
[09/26 11:41:17 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 11:41:24 visual_prompt]: Epoch 77 / 100: avg data time: 6.06e-02, avg batch time: 0.5013, average train loss: 3.8095
[09/26 11:41:25 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 3.8346
[09/26 11:41:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.00	
[09/26 11:41:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 11:41:32 visual_prompt]: Epoch 78 / 100: avg data time: 5.25e-02, avg batch time: 0.4938, average train loss: 3.7833
[09/26 11:41:33 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 3.8148
[09/26 11:41:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 11.50	
[09/26 11:41:33 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 11:41:40 visual_prompt]: Epoch 79 / 100: avg data time: 5.35e-02, avg batch time: 0.4968, average train loss: 3.7863
[09/26 11:41:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 3.8267
[09/26 11:41:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.00	
[09/26 11:41:42 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 11:41:49 visual_prompt]: Epoch 80 / 100: avg data time: 4.94e-02, avg batch time: 0.4906, average train loss: 3.7741
[09/26 11:41:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 3.8116
[09/26 11:41:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 1.00	top5: 11.50	
[09/26 11:41:50 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 11:41:57 visual_prompt]: Epoch 81 / 100: avg data time: 6.12e-02, avg batch time: 0.5023, average train loss: 3.7642
[09/26 11:41:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 3.6869
[09/26 11:41:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 20.00	
[09/26 11:41:59 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 11:42:05 visual_prompt]: Epoch 82 / 100: avg data time: 5.37e-02, avg batch time: 0.4957, average train loss: 3.7250
[09/26 11:42:07 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1663, average loss: 3.7695
[09/26 11:42:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 18.50	
[09/26 11:42:07 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 11:42:14 visual_prompt]: Epoch 83 / 100: avg data time: 6.12e-02, avg batch time: 0.5024, average train loss: 3.7881
[09/26 11:42:15 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 3.7978
[09/26 11:42:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 16.50	
[09/26 11:42:15 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 11:42:22 visual_prompt]: Epoch 84 / 100: avg data time: 6.76e-02, avg batch time: 0.5085, average train loss: 3.7162
[09/26 11:42:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 3.7257
[09/26 11:42:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 19.00	
[09/26 11:42:24 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 11:42:31 visual_prompt]: Epoch 85 / 100: avg data time: 6.00e-02, avg batch time: 0.5026, average train loss: 3.6841
[09/26 11:42:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 3.7420
[09/26 11:42:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 16.00	
[09/26 11:42:32 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 11:42:39 visual_prompt]: Epoch 86 / 100: avg data time: 6.04e-02, avg batch time: 0.5029, average train loss: 3.6767
[09/26 11:42:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 3.6655
[09/26 11:42:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 23.00	
[09/26 11:42:41 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 11:42:48 visual_prompt]: Epoch 87 / 100: avg data time: 5.46e-02, avg batch time: 0.4961, average train loss: 3.6608
[09/26 11:42:49 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1662, average loss: 3.6175
[09/26 11:42:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 20.00	
[09/26 11:42:49 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 11:42:56 visual_prompt]: Epoch 88 / 100: avg data time: 6.11e-02, avg batch time: 0.5023, average train loss: 3.6823
[09/26 11:42:58 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 3.6115
[09/26 11:42:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 18.00	
[09/26 11:42:58 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 11:43:05 visual_prompt]: Epoch 89 / 100: avg data time: 6.14e-02, avg batch time: 0.5031, average train loss: 3.5538
[09/26 11:43:06 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1661, average loss: 3.5342
[09/26 11:43:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 23.00	
[09/26 11:43:06 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 11:43:13 visual_prompt]: Epoch 90 / 100: avg data time: 4.75e-02, avg batch time: 0.4929, average train loss: 3.4853
[09/26 11:43:15 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 3.5367
[09/26 11:43:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 23.00	
[09/26 11:43:15 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 11:43:21 visual_prompt]: Epoch 91 / 100: avg data time: 5.10e-02, avg batch time: 0.4930, average train loss: 3.4305
[09/26 11:43:23 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 3.4426
[09/26 11:43:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 27.50	
[09/26 11:43:23 visual_prompt]: Best epoch 91: best metric: 0.090
[09/26 11:43:23 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 11:43:30 visual_prompt]: Epoch 92 / 100: avg data time: 4.60e-02, avg batch time: 0.4889, average train loss: 3.3917
[09/26 11:43:31 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 3.4729
[09/26 11:43:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 24.00	
[09/26 11:43:31 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 11:43:38 visual_prompt]: Epoch 93 / 100: avg data time: 4.94e-02, avg batch time: 0.4925, average train loss: 3.3606
[09/26 11:43:40 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1659, average loss: 3.4285
[09/26 11:43:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 24.50	
[09/26 11:43:40 visual_prompt]: Best epoch 93: best metric: 0.110
[09/26 11:43:40 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 11:43:46 visual_prompt]: Epoch 94 / 100: avg data time: 4.89e-02, avg batch time: 0.4914, average train loss: 3.3705
[09/26 11:43:48 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1661, average loss: 3.4181
[09/26 11:43:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.00	top5: 29.00	
[09/26 11:43:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 11:43:55 visual_prompt]: Epoch 95 / 100: avg data time: 6.31e-02, avg batch time: 0.5044, average train loss: 3.3125
[09/26 11:43:56 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 3.3292
[09/26 11:43:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 30.50	
[09/26 11:43:56 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 11:44:03 visual_prompt]: Epoch 96 / 100: avg data time: 5.07e-02, avg batch time: 0.4925, average train loss: 3.2738
[09/26 11:44:05 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1659, average loss: 3.3302
[09/26 11:44:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 29.00	
[09/26 11:44:05 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 11:44:12 visual_prompt]: Epoch 97 / 100: avg data time: 5.22e-02, avg batch time: 0.4941, average train loss: 3.2419
[09/26 11:44:13 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 3.3075
[09/26 11:44:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 31.00	
[09/26 11:44:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 11:44:20 visual_prompt]: Epoch 98 / 100: avg data time: 6.05e-02, avg batch time: 0.5030, average train loss: 3.2224
[09/26 11:44:22 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1662, average loss: 3.3067
[09/26 11:44:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 29.00	
[09/26 11:44:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 11:44:28 visual_prompt]: Epoch 99 / 100: avg data time: 4.86e-02, avg batch time: 0.4914, average train loss: 3.2090
[09/26 11:44:30 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1664, average loss: 3.2964
[09/26 11:44:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 30.00	
[09/26 11:44:30 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 11:44:37 visual_prompt]: Epoch 100 / 100: avg data time: 5.91e-02, avg batch time: 0.5003, average train loss: 3.2022
[09/26 11:44:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 3.2984
[09/26 11:44:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 29.50	
[09/26 11:44:38 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:44:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:44:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:44:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:44:38 visual_prompt]: Training with config:
[09/26 11:44:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:44:38 visual_prompt]: Loading training data...
[09/26 11:44:38 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:44:40 visual_prompt]: Number of images: 800
[09/26 11:44:40 visual_prompt]: Number of classes: 45 / 45
[09/26 11:44:40 visual_prompt]: Loading validation data...
[09/26 11:44:40 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:44:40 visual_prompt]: Number of images: 200
[09/26 11:44:40 visual_prompt]: Number of classes: 45 / 45
[09/26 11:44:40 visual_prompt]: Constructing models...
[09/26 11:44:42 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 11:44:42 visual_prompt]: tuned percent:0.574
[09/26 11:44:42 visual_prompt]: Device used for model: 0
[09/26 11:44:42 visual_prompt]: Setting up Evaluator...
[09/26 11:44:42 visual_prompt]: Setting up Trainer...
[09/26 11:44:42 visual_prompt]: 	Setting up the optimizer...
[09/26 11:44:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:44:49 visual_prompt]: Epoch 1 / 100: avg data time: 5.18e-02, avg batch time: 0.4935, average train loss: 3.9000
[09/26 11:44:51 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 11:44:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 11:44:51 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 11:44:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 11:44:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.71e-02, avg batch time: 0.4907, average train loss: 3.8082
[09/26 11:44:59 visual_prompt]: Inference (val):avg data time: 4.10e-05, avg batch time: 0.1659, average loss: 3.7851
[09/26 11:44:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 18.50	
[09/26 11:44:59 visual_prompt]: Best epoch 2: best metric: 0.045
[09/26 11:44:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 11:45:06 visual_prompt]: Epoch 3 / 100: avg data time: 4.85e-02, avg batch time: 0.4912, average train loss: 3.6327
[09/26 11:45:07 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 3.4180
[09/26 11:45:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 34.50	
[09/26 11:45:07 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 11:45:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 11:45:14 visual_prompt]: Epoch 4 / 100: avg data time: 6.38e-02, avg batch time: 0.5055, average train loss: 3.3173
[09/26 11:45:16 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 3.3572
[09/26 11:45:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 36.50	
[09/26 11:45:16 visual_prompt]: Best epoch 4: best metric: 0.120
[09/26 11:45:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 11:45:23 visual_prompt]: Epoch 5 / 100: avg data time: 6.03e-02, avg batch time: 0.5022, average train loss: 3.1486
[09/26 11:45:24 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 3.0087
[09/26 11:45:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 48.50	
[09/26 11:45:24 visual_prompt]: Best epoch 5: best metric: 0.185
[09/26 11:45:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 11:45:31 visual_prompt]: Epoch 6 / 100: avg data time: 5.89e-02, avg batch time: 0.4998, average train loss: 2.6265
[09/26 11:45:32 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 2.4153
[09/26 11:45:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 28.50	top5: 66.00	
[09/26 11:45:32 visual_prompt]: Best epoch 6: best metric: 0.285
[09/26 11:45:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 11:45:39 visual_prompt]: Epoch 7 / 100: avg data time: 6.07e-02, avg batch time: 0.5033, average train loss: 2.3492
[09/26 11:45:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 2.1135
[09/26 11:45:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 39.00	top5: 75.50	
[09/26 11:45:41 visual_prompt]: Best epoch 7: best metric: 0.390
[09/26 11:45:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 11:45:48 visual_prompt]: Epoch 8 / 100: avg data time: 6.07e-02, avg batch time: 0.5037, average train loss: 2.4641
[09/26 11:45:49 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 2.7382
[09/26 11:45:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 58.00	
[09/26 11:45:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 11:45:56 visual_prompt]: Epoch 9 / 100: avg data time: 5.09e-02, avg batch time: 0.4926, average train loss: 1.8763
[09/26 11:45:58 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 2.3496
[09/26 11:45:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 38.50	top5: 71.50	
[09/26 11:45:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 11:46:05 visual_prompt]: Epoch 10 / 100: avg data time: 5.18e-02, avg batch time: 0.4940, average train loss: 1.3667
[09/26 11:46:06 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.5347
[09/26 11:46:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.50	top5: 85.50	
[09/26 11:46:06 visual_prompt]: Best epoch 10: best metric: 0.525
[09/26 11:46:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 11:46:13 visual_prompt]: Epoch 11 / 100: avg data time: 5.25e-02, avg batch time: 0.4960, average train loss: 0.6674
[09/26 11:46:15 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 1.2720
[09/26 11:46:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.00	
[09/26 11:46:15 visual_prompt]: Best epoch 11: best metric: 0.645
[09/26 11:46:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 11:46:21 visual_prompt]: Epoch 12 / 100: avg data time: 6.08e-02, avg batch time: 0.5030, average train loss: 0.4009
[09/26 11:46:23 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 0.8737
[09/26 11:46:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 97.00	
[09/26 11:46:23 visual_prompt]: Best epoch 12: best metric: 0.735
[09/26 11:46:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 11:46:30 visual_prompt]: Epoch 13 / 100: avg data time: 5.17e-02, avg batch time: 0.4946, average train loss: 0.2144
[09/26 11:46:31 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.9618
[09/26 11:46:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.50	
[09/26 11:46:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 11:46:38 visual_prompt]: Epoch 14 / 100: avg data time: 6.07e-02, avg batch time: 0.5028, average train loss: 0.1550
[09/26 11:46:40 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 0.8342
[09/26 11:46:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.50	
[09/26 11:46:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 11:46:47 visual_prompt]: Epoch 15 / 100: avg data time: 5.51e-02, avg batch time: 0.4983, average train loss: 0.0949
[09/26 11:46:48 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1666, average loss: 0.7290
[09/26 11:46:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 11:46:48 visual_prompt]: Best epoch 15: best metric: 0.785
[09/26 11:46:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 11:46:55 visual_prompt]: Epoch 16 / 100: avg data time: 4.88e-02, avg batch time: 0.4930, average train loss: 0.0637
[09/26 11:46:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.6606
[09/26 11:46:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 11:46:57 visual_prompt]: Best epoch 16: best metric: 0.795
[09/26 11:46:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 11:47:04 visual_prompt]: Epoch 17 / 100: avg data time: 5.40e-02, avg batch time: 0.4968, average train loss: 0.0543
[09/26 11:47:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.7422
[09/26 11:47:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.00	
[09/26 11:47:05 visual_prompt]: Best epoch 17: best metric: 0.800
[09/26 11:47:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 11:47:12 visual_prompt]: Epoch 18 / 100: avg data time: 5.48e-02, avg batch time: 0.4975, average train loss: 0.0581
[09/26 11:47:13 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1662, average loss: 0.7367
[09/26 11:47:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 11:47:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 11:47:20 visual_prompt]: Epoch 19 / 100: avg data time: 6.79e-02, avg batch time: 0.5100, average train loss: 0.0509
[09/26 11:47:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.7109
[09/26 11:47:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 11:47:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 11:47:29 visual_prompt]: Epoch 20 / 100: avg data time: 6.28e-02, avg batch time: 0.5046, average train loss: 0.0472
[09/26 11:47:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 0.6844
[09/26 11:47:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 11:47:31 visual_prompt]: Best epoch 20: best metric: 0.815
[09/26 11:47:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 11:47:37 visual_prompt]: Epoch 21 / 100: avg data time: 5.59e-02, avg batch time: 0.4980, average train loss: 0.0432
[09/26 11:47:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.7233
[09/26 11:47:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.50	
[09/26 11:47:39 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 11:47:46 visual_prompt]: Epoch 22 / 100: avg data time: 5.30e-02, avg batch time: 0.4947, average train loss: 0.1315
[09/26 11:47:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 0.9299
[09/26 11:47:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 11:47:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 11:47:54 visual_prompt]: Epoch 23 / 100: avg data time: 6.46e-02, avg batch time: 0.5069, average train loss: 0.2416
[09/26 11:47:56 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.7837
[09/26 11:47:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 11:47:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 11:48:03 visual_prompt]: Epoch 24 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 0.1622
[09/26 11:48:04 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.7433
[09/26 11:48:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 11:48:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 11:48:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.85e-02, avg batch time: 0.5000, average train loss: 0.1061
[09/26 11:48:13 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 0.7026
[09/26 11:48:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 11:48:13 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 11:48:20 visual_prompt]: Epoch 26 / 100: avg data time: 5.84e-02, avg batch time: 0.5013, average train loss: 0.0904
[09/26 11:48:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 0.7114
[09/26 11:48:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 11:48:21 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 11:48:28 visual_prompt]: Epoch 27 / 100: avg data time: 5.88e-02, avg batch time: 0.5007, average train loss: 0.0772
[09/26 11:48:30 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1662, average loss: 0.7138
[09/26 11:48:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 11:48:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 11:48:37 visual_prompt]: Epoch 28 / 100: avg data time: 4.99e-02, avg batch time: 0.4938, average train loss: 0.0519
[09/26 11:48:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 0.6882
[09/26 11:48:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 11:48:38 visual_prompt]: Best epoch 28: best metric: 0.820
[09/26 11:48:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 11:48:45 visual_prompt]: Epoch 29 / 100: avg data time: 5.16e-02, avg batch time: 0.4937, average train loss: 0.0453
[09/26 11:48:46 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 0.6452
[09/26 11:48:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.00	
[09/26 11:48:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 11:48:53 visual_prompt]: Epoch 30 / 100: avg data time: 5.28e-02, avg batch time: 0.4960, average train loss: 0.0415
[09/26 11:48:55 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 0.6468
[09/26 11:48:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 11:48:55 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 11:49:02 visual_prompt]: Epoch 31 / 100: avg data time: 5.03e-02, avg batch time: 0.4932, average train loss: 0.0344
[09/26 11:49:03 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 0.6500
[09/26 11:49:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 97.50	
[09/26 11:49:03 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 11:49:10 visual_prompt]: Epoch 32 / 100: avg data time: 4.89e-02, avg batch time: 0.4910, average train loss: 0.0294
[09/26 11:49:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 0.6257
[09/26 11:49:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 11:49:12 visual_prompt]: Best epoch 32: best metric: 0.845
[09/26 11:49:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 11:49:19 visual_prompt]: Epoch 33 / 100: avg data time: 4.79e-02, avg batch time: 0.4920, average train loss: 0.0283
[09/26 11:49:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 0.6457
[09/26 11:49:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.00	
[09/26 11:49:20 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 11:49:27 visual_prompt]: Epoch 34 / 100: avg data time: 5.12e-02, avg batch time: 0.4963, average train loss: 0.0291
[09/26 11:49:29 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 0.6749
[09/26 11:49:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 11:49:29 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 11:49:35 visual_prompt]: Epoch 35 / 100: avg data time: 6.16e-02, avg batch time: 0.5045, average train loss: 0.6789
[09/26 11:49:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 2.6848
[09/26 11:49:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 68.50	
[09/26 11:49:37 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 11:49:44 visual_prompt]: Epoch 36 / 100: avg data time: 6.22e-02, avg batch time: 0.5048, average train loss: 1.3266
[09/26 11:49:46 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 0.9722
[09/26 11:49:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 11:49:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 11:49:52 visual_prompt]: Epoch 37 / 100: avg data time: 6.36e-02, avg batch time: 0.5050, average train loss: 0.3860
[09/26 11:49:54 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1666, average loss: 0.8590
[09/26 11:49:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 11:49:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 11:50:01 visual_prompt]: Epoch 38 / 100: avg data time: 6.11e-02, avg batch time: 0.5038, average train loss: 0.1963
[09/26 11:50:03 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 0.6496
[09/26 11:50:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.00	
[09/26 11:50:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 11:50:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.45e-02, avg batch time: 0.4974, average train loss: 0.0891
[09/26 11:50:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 0.5937
[09/26 11:50:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 11:50:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 11:50:18 visual_prompt]: Epoch 40 / 100: avg data time: 5.25e-02, avg batch time: 0.4947, average train loss: 0.0518
[09/26 11:50:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 0.5701
[09/26 11:50:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 11:50:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 11:50:26 visual_prompt]: Epoch 41 / 100: avg data time: 5.68e-02, avg batch time: 0.5002, average train loss: 0.0396
[09/26 11:50:28 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.5723
[09/26 11:50:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 97.50	
[09/26 11:50:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 11:50:35 visual_prompt]: Epoch 42 / 100: avg data time: 5.90e-02, avg batch time: 0.5013, average train loss: 0.0389
[09/26 11:50:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 0.5883
[09/26 11:50:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 99.00	
[09/26 11:50:36 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 11:50:43 visual_prompt]: Epoch 43 / 100: avg data time: 4.93e-02, avg batch time: 0.4918, average train loss: 0.0368
[09/26 11:50:45 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 0.5872
[09/26 11:50:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 98.00	
[09/26 11:50:45 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 11:50:51 visual_prompt]: Epoch 44 / 100: avg data time: 4.98e-02, avg batch time: 0.4918, average train loss: 0.0383
[09/26 11:50:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 0.5841
[09/26 11:50:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 11:50:53 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 11:51:00 visual_prompt]: Epoch 45 / 100: avg data time: 5.36e-02, avg batch time: 0.4980, average train loss: 0.0367
[09/26 11:51:01 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 0.5768
[09/26 11:51:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.50	
[09/26 11:51:01 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 11:51:08 visual_prompt]: Epoch 46 / 100: avg data time: 5.22e-02, avg batch time: 0.4949, average train loss: 0.0355
[09/26 11:51:10 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1664, average loss: 0.5860
[09/26 11:51:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 11:51:10 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 11:51:16 visual_prompt]: Epoch 47 / 100: avg data time: 5.45e-02, avg batch time: 0.4980, average train loss: 0.0368
[09/26 11:51:18 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 0.5854
[09/26 11:51:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:51:18 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 11:51:25 visual_prompt]: Epoch 48 / 100: avg data time: 5.06e-02, avg batch time: 0.4925, average train loss: 0.0378
[09/26 11:51:26 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 0.5945
[09/26 11:51:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.50	
[09/26 11:51:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 11:51:33 visual_prompt]: Epoch 49 / 100: avg data time: 5.21e-02, avg batch time: 0.4972, average train loss: 0.0380
[09/26 11:51:35 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.6322
[09/26 11:51:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.50	
[09/26 11:51:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 11:51:41 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e-02, avg batch time: 0.4905, average train loss: 0.0381
[09/26 11:51:43 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 0.5906
[09/26 11:51:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 98.50	
[09/26 11:51:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 11:51:50 visual_prompt]: Epoch 51 / 100: avg data time: 4.77e-02, avg batch time: 0.4912, average train loss: 0.0526
[09/26 11:51:51 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1665, average loss: 0.7224
[09/26 11:51:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 11:51:51 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 11:51:58 visual_prompt]: Epoch 52 / 100: avg data time: 5.06e-02, avg batch time: 0.4957, average train loss: 0.0649
[09/26 11:52:00 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 0.6490
[09/26 11:52:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.00	
[09/26 11:52:00 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 11:52:06 visual_prompt]: Epoch 53 / 100: avg data time: 4.91e-02, avg batch time: 0.4942, average train loss: 0.0724
[09/26 11:52:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.0387
[09/26 11:52:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 11:52:08 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 11:52:15 visual_prompt]: Epoch 54 / 100: avg data time: 4.88e-02, avg batch time: 0.4930, average train loss: 0.2912
[09/26 11:52:16 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 0.9025
[09/26 11:52:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 11:52:16 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 11:52:23 visual_prompt]: Epoch 55 / 100: avg data time: 5.13e-02, avg batch time: 0.4930, average train loss: 0.2056
[09/26 11:52:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 0.7054
[09/26 11:52:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 11:52:25 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 11:52:32 visual_prompt]: Epoch 56 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 0.0982
[09/26 11:52:33 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 0.6336
[09/26 11:52:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.50	
[09/26 11:52:33 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 11:52:40 visual_prompt]: Epoch 57 / 100: avg data time: 5.76e-02, avg batch time: 0.4997, average train loss: 0.0503
[09/26 11:52:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1667, average loss: 0.5837
[09/26 11:52:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 11:52:42 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 11:52:48 visual_prompt]: Epoch 58 / 100: avg data time: 4.81e-02, avg batch time: 0.4924, average train loss: 0.0313
[09/26 11:52:50 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1664, average loss: 0.5835
[09/26 11:52:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 98.00	
[09/26 11:52:50 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 11:52:57 visual_prompt]: Epoch 59 / 100: avg data time: 5.16e-02, avg batch time: 0.4947, average train loss: 0.0258
[09/26 11:52:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 0.5241
[09/26 11:52:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.50	
[09/26 11:52:58 visual_prompt]: Best epoch 59: best metric: 0.850
[09/26 11:52:58 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 11:53:05 visual_prompt]: Epoch 60 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 0.0225
[09/26 11:53:07 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 0.5317
[09/26 11:53:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.50	
[09/26 11:53:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 11:53:13 visual_prompt]: Epoch 61 / 100: avg data time: 4.91e-02, avg batch time: 0.4930, average train loss: 0.0219
[09/26 11:53:15 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 0.5183
[09/26 11:53:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 99.00	
[09/26 11:53:15 visual_prompt]: Best epoch 61: best metric: 0.860
[09/26 11:53:15 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 11:53:22 visual_prompt]: Epoch 62 / 100: avg data time: 5.50e-02, avg batch time: 0.4979, average train loss: 0.0220
[09/26 11:53:23 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 0.5155
[09/26 11:53:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.50	top5: 98.00	
[09/26 11:53:23 visual_prompt]: Best epoch 62: best metric: 0.875
[09/26 11:53:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 11:53:30 visual_prompt]: Epoch 63 / 100: avg data time: 4.93e-02, avg batch time: 0.4924, average train loss: 0.0216
[09/26 11:53:32 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1665, average loss: 0.5090
[09/26 11:53:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 99.00	
[09/26 11:53:32 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 11:53:38 visual_prompt]: Epoch 64 / 100: avg data time: 5.25e-02, avg batch time: 0.4940, average train loss: 0.0216
[09/26 11:53:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1665, average loss: 0.5208
[09/26 11:53:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 99.00	
[09/26 11:53:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 11:53:47 visual_prompt]: Epoch 65 / 100: avg data time: 5.78e-02, avg batch time: 0.4993, average train loss: 0.0220
[09/26 11:53:49 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 0.5277
[09/26 11:53:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 99.50	
[09/26 11:53:49 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 11:53:55 visual_prompt]: Epoch 66 / 100: avg data time: 5.06e-02, avg batch time: 0.4927, average train loss: 0.0227
[09/26 11:53:57 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1663, average loss: 0.5227
[09/26 11:53:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 98.50	
[09/26 11:53:57 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 11:54:04 visual_prompt]: Epoch 67 / 100: avg data time: 6.69e-02, avg batch time: 0.5086, average train loss: 0.0219
[09/26 11:54:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 0.5231
[09/26 11:54:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 99.00	
[09/26 11:54:05 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 11:54:12 visual_prompt]: Epoch 68 / 100: avg data time: 6.55e-02, avg batch time: 0.5080, average train loss: 0.0209
[09/26 11:54:14 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 0.5111
[09/26 11:54:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 99.00	
[09/26 11:54:14 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 11:54:21 visual_prompt]: Epoch 69 / 100: avg data time: 5.01e-02, avg batch time: 0.4943, average train loss: 0.0200
[09/26 11:54:22 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 0.5152
[09/26 11:54:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 88.00	top5: 98.50	
[09/26 11:54:22 visual_prompt]: Best epoch 69: best metric: 0.880
[09/26 11:54:22 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 11:54:29 visual_prompt]: Epoch 70 / 100: avg data time: 5.07e-02, avg batch time: 0.4940, average train loss: 0.0192
[09/26 11:54:31 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1665, average loss: 0.5224
[09/26 11:54:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.50	top5: 98.00	
[09/26 11:54:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 11:54:37 visual_prompt]: Epoch 71 / 100: avg data time: 5.34e-02, avg batch time: 0.4966, average train loss: 0.0186
[09/26 11:54:39 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 0.5308
[09/26 11:54:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 88.00	top5: 98.50	
[09/26 11:54:39 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 11:54:46 visual_prompt]: Epoch 72 / 100: avg data time: 5.24e-02, avg batch time: 0.4968, average train loss: 0.0186
[09/26 11:54:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.5364
[09/26 11:54:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 99.00	
[09/26 11:54:47 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 11:54:54 visual_prompt]: Epoch 73 / 100: avg data time: 5.74e-02, avg batch time: 0.4999, average train loss: 0.0177
[09/26 11:54:56 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 0.5328
[09/26 11:54:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.50	top5: 98.50	
[09/26 11:54:56 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 11:55:03 visual_prompt]: Epoch 74 / 100: avg data time: 6.18e-02, avg batch time: 0.5030, average train loss: 0.0174
[09/26 11:55:04 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1666, average loss: 0.5366
[09/26 11:55:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 99.00	
[09/26 11:55:04 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 11:55:11 visual_prompt]: Epoch 75 / 100: avg data time: 5.18e-02, avg batch time: 0.4938, average train loss: 0.0169
[09/26 11:55:13 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 0.5261
[09/26 11:55:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 98.00	
[09/26 11:55:13 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 11:55:20 visual_prompt]: Epoch 76 / 100: avg data time: 6.29e-02, avg batch time: 0.5052, average train loss: 0.0164
[09/26 11:55:21 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1666, average loss: 0.5548
[09/26 11:55:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 98.00	
[09/26 11:55:21 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 11:55:28 visual_prompt]: Epoch 77 / 100: avg data time: 6.04e-02, avg batch time: 0.5024, average train loss: 0.0161
[09/26 11:55:30 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 0.5246
[09/26 11:55:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 88.00	top5: 98.00	
[09/26 11:55:30 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 11:55:37 visual_prompt]: Epoch 78 / 100: avg data time: 6.62e-02, avg batch time: 0.5081, average train loss: 0.0159
[09/26 11:55:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 0.5391
[09/26 11:55:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 98.00	
[09/26 11:55:38 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 11:55:45 visual_prompt]: Epoch 79 / 100: avg data time: 6.22e-02, avg batch time: 0.5055, average train loss: 0.0158
[09/26 11:55:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.5405
[09/26 11:55:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.50	top5: 98.50	
[09/26 11:55:47 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 11:55:54 visual_prompt]: Epoch 80 / 100: avg data time: 5.83e-02, avg batch time: 0.5003, average train loss: 0.0157
[09/26 11:55:55 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 0.5699
[09/26 11:55:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 99.00	
[09/26 11:55:55 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 11:56:02 visual_prompt]: Epoch 81 / 100: avg data time: 5.52e-02, avg batch time: 0.4984, average train loss: 0.0155
[09/26 11:56:04 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 0.5428
[09/26 11:56:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 98.50	
[09/26 11:56:04 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 11:56:11 visual_prompt]: Epoch 82 / 100: avg data time: 5.08e-02, avg batch time: 0.4949, average train loss: 0.0154
[09/26 11:56:12 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 0.5639
[09/26 11:56:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:56:12 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 11:56:19 visual_prompt]: Epoch 83 / 100: avg data time: 4.97e-02, avg batch time: 0.4924, average train loss: 0.0152
[09/26 11:56:21 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 0.5520
[09/26 11:56:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 99.00	
[09/26 11:56:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 11:56:28 visual_prompt]: Epoch 84 / 100: avg data time: 5.55e-02, avg batch time: 0.4978, average train loss: 0.0150
[09/26 11:56:29 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 0.5543
[09/26 11:56:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 87.00	top5: 98.50	
[09/26 11:56:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 11:56:36 visual_prompt]: Epoch 85 / 100: avg data time: 6.14e-02, avg batch time: 0.5046, average train loss: 0.0148
[09/26 11:56:38 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1668, average loss: 0.5628
[09/26 11:56:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.50	
[09/26 11:56:38 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 11:56:44 visual_prompt]: Epoch 86 / 100: avg data time: 4.62e-02, avg batch time: 0.4909, average train loss: 0.0150
[09/26 11:56:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 0.5554
[09/26 11:56:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:56:46 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 11:56:53 visual_prompt]: Epoch 87 / 100: avg data time: 5.89e-02, avg batch time: 0.5017, average train loss: 0.0147
[09/26 11:56:54 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 0.5523
[09/26 11:56:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 98.50	
[09/26 11:56:54 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 11:57:01 visual_prompt]: Epoch 88 / 100: avg data time: 6.77e-02, avg batch time: 0.5104, average train loss: 0.0143
[09/26 11:57:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 0.5500
[09/26 11:57:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 98.50	
[09/26 11:57:03 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 11:57:10 visual_prompt]: Epoch 89 / 100: avg data time: 6.21e-02, avg batch time: 0.5035, average train loss: 0.0143
[09/26 11:57:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 0.5663
[09/26 11:57:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 98.50	
[09/26 11:57:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 11:57:18 visual_prompt]: Epoch 90 / 100: avg data time: 6.41e-02, avg batch time: 0.5070, average train loss: 0.0141
[09/26 11:57:20 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1666, average loss: 0.5612
[09/26 11:57:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.00	top5: 98.50	
[09/26 11:57:20 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 11:57:27 visual_prompt]: Epoch 91 / 100: avg data time: 6.09e-02, avg batch time: 0.5028, average train loss: 0.0141
[09/26 11:57:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 0.5696
[09/26 11:57:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:57:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 11:57:35 visual_prompt]: Epoch 92 / 100: avg data time: 5.27e-02, avg batch time: 0.4976, average train loss: 0.0138
[09/26 11:57:37 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1666, average loss: 0.5680
[09/26 11:57:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 98.50	
[09/26 11:57:37 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 11:57:44 visual_prompt]: Epoch 93 / 100: avg data time: 5.21e-02, avg batch time: 0.4955, average train loss: 0.0140
[09/26 11:57:45 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1666, average loss: 0.5696
[09/26 11:57:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:57:45 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 11:57:52 visual_prompt]: Epoch 94 / 100: avg data time: 4.45e-02, avg batch time: 0.4877, average train loss: 0.0139
[09/26 11:57:54 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1667, average loss: 0.5712
[09/26 11:57:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:57:54 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 11:58:01 visual_prompt]: Epoch 95 / 100: avg data time: 5.11e-02, avg batch time: 0.4945, average train loss: 0.0139
[09/26 11:58:02 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 0.5721
[09/26 11:58:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:02 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 11:58:09 visual_prompt]: Epoch 96 / 100: avg data time: 5.53e-02, avg batch time: 0.4980, average train loss: 0.0138
[09/26 11:58:11 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 0.5735
[09/26 11:58:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:11 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 11:58:17 visual_prompt]: Epoch 97 / 100: avg data time: 4.59e-02, avg batch time: 0.4899, average train loss: 0.0138
[09/26 11:58:19 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1667, average loss: 0.5715
[09/26 11:58:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:19 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 11:58:26 visual_prompt]: Epoch 98 / 100: avg data time: 4.72e-02, avg batch time: 0.4907, average train loss: 0.0137
[09/26 11:58:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 0.5706
[09/26 11:58:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:27 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 11:58:34 visual_prompt]: Epoch 99 / 100: avg data time: 6.20e-02, avg batch time: 0.5053, average train loss: 0.0139
[09/26 11:58:36 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1667, average loss: 0.5704
[09/26 11:58:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:36 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 11:58:43 visual_prompt]: Epoch 100 / 100: avg data time: 5.39e-02, avg batch time: 0.4965, average train loss: 0.0138
[09/26 11:58:44 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 0.5705
[09/26 11:58:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 98.50	
[09/26 11:58:44 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 11:58:44 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 11:58:44 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 11:58:44 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 11:58:44 visual_prompt]: Training with config:
[09/26 11:58:44 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 11:58:44 visual_prompt]: Loading training data...
[09/26 11:58:44 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:58:45 visual_prompt]: Number of images: 800
[09/26 11:58:45 visual_prompt]: Number of classes: 45 / 45
[09/26 11:58:45 visual_prompt]: Loading validation data...
[09/26 11:58:45 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 11:58:46 visual_prompt]: Number of images: 200
[09/26 11:58:46 visual_prompt]: Number of classes: 45 / 45
[09/26 11:58:46 visual_prompt]: Constructing models...
[09/26 11:58:48 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 11:58:48 visual_prompt]: tuned percent:0.574
[09/26 11:58:48 visual_prompt]: Device used for model: 0
[09/26 11:58:48 visual_prompt]: Setting up Evaluator...
[09/26 11:58:48 visual_prompt]: Setting up Trainer...
[09/26 11:58:48 visual_prompt]: 	Setting up the optimizer...
[09/26 11:58:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 11:58:55 visual_prompt]: Epoch 1 / 100: avg data time: 6.79e-02, avg batch time: 0.5114, average train loss: 3.8963
[09/26 11:58:57 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 11:58:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 11:58:57 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 11:58:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 11:59:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.78e-02, avg batch time: 0.5000, average train loss: 3.8000
[09/26 11:59:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 3.7419
[09/26 11:59:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 23.00	
[09/26 11:59:05 visual_prompt]: Best epoch 2: best metric: 0.030
[09/26 11:59:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 11:59:12 visual_prompt]: Epoch 3 / 100: avg data time: 5.96e-02, avg batch time: 0.5011, average train loss: 3.5742
[09/26 11:59:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1664, average loss: 3.3550
[09/26 11:59:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 33.00	
[09/26 11:59:14 visual_prompt]: Best epoch 3: best metric: 0.095
[09/26 11:59:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 11:59:21 visual_prompt]: Epoch 4 / 100: avg data time: 5.32e-02, avg batch time: 0.4952, average train loss: 3.2246
[09/26 11:59:22 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1666, average loss: 4.0335
[09/26 11:59:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 23.50	
[09/26 11:59:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 11:59:29 visual_prompt]: Epoch 5 / 100: avg data time: 6.05e-02, avg batch time: 0.5037, average train loss: 3.2693
[09/26 11:59:31 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1667, average loss: 2.9088
[09/26 11:59:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.50	top5: 53.50	
[09/26 11:59:31 visual_prompt]: Best epoch 5: best metric: 0.205
[09/26 11:59:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 11:59:37 visual_prompt]: Epoch 6 / 100: avg data time: 4.92e-02, avg batch time: 0.4929, average train loss: 2.7434
[09/26 11:59:39 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 2.7876
[09/26 11:59:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 54.00	
[09/26 11:59:39 visual_prompt]: Best epoch 6: best metric: 0.240
[09/26 11:59:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 11:59:46 visual_prompt]: Epoch 7 / 100: avg data time: 4.90e-02, avg batch time: 0.4926, average train loss: 2.2021
[09/26 11:59:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1668, average loss: 3.2495
[09/26 11:59:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.00	top5: 55.00	
[09/26 11:59:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 11:59:54 visual_prompt]: Epoch 8 / 100: avg data time: 5.01e-02, avg batch time: 0.4935, average train loss: 1.8358
[09/26 11:59:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 1.7816
[09/26 11:59:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 79.50	
[09/26 11:59:56 visual_prompt]: Best epoch 8: best metric: 0.520
[09/26 11:59:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:00:03 visual_prompt]: Epoch 9 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 1.1812
[09/26 12:00:04 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1668, average loss: 2.0682
[09/26 12:00:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.50	top5: 77.50	
[09/26 12:00:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:00:11 visual_prompt]: Epoch 10 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 1.0178
[09/26 12:00:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1669, average loss: 1.2645
[09/26 12:00:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.00	
[09/26 12:00:12 visual_prompt]: Best epoch 10: best metric: 0.645
[09/26 12:00:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:00:19 visual_prompt]: Epoch 11 / 100: avg data time: 4.97e-02, avg batch time: 0.4922, average train loss: 0.4736
[09/26 12:00:21 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1669, average loss: 1.1188
[09/26 12:00:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.50	
[09/26 12:00:21 visual_prompt]: Best epoch 11: best metric: 0.690
[09/26 12:00:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:00:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.34e-02, avg batch time: 0.4969, average train loss: 0.2909
[09/26 12:00:29 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1668, average loss: 1.0558
[09/26 12:00:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 12:00:29 visual_prompt]: Best epoch 12: best metric: 0.715
[09/26 12:00:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:00:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.16e-02, avg batch time: 0.4953, average train loss: 0.1230
[09/26 12:00:38 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1670, average loss: 0.9952
[09/26 12:00:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 12:00:38 visual_prompt]: Best epoch 13: best metric: 0.735
[09/26 12:00:38 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:00:44 visual_prompt]: Epoch 14 / 100: avg data time: 4.71e-02, avg batch time: 0.4906, average train loss: 0.0667
[09/26 12:00:46 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1669, average loss: 0.8044
[09/26 12:00:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.00	
[09/26 12:00:46 visual_prompt]: Best epoch 14: best metric: 0.740
[09/26 12:00:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:00:53 visual_prompt]: Epoch 15 / 100: avg data time: 4.81e-02, avg batch time: 0.4930, average train loss: 0.0294
[09/26 12:00:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1669, average loss: 0.8143
[09/26 12:00:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 98.00	
[09/26 12:00:54 visual_prompt]: Best epoch 15: best metric: 0.760
[09/26 12:00:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:01:01 visual_prompt]: Epoch 16 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 0.0157
[09/26 12:01:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1670, average loss: 0.7932
[09/26 12:01:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:01:03 visual_prompt]: Best epoch 16: best metric: 0.780
[09/26 12:01:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:01:09 visual_prompt]: Epoch 17 / 100: avg data time: 5.15e-02, avg batch time: 0.4960, average train loss: 0.0126
[09/26 12:01:11 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1668, average loss: 0.7072
[09/26 12:01:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:01:11 visual_prompt]: Best epoch 17: best metric: 0.795
[09/26 12:01:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:01:18 visual_prompt]: Epoch 18 / 100: avg data time: 6.01e-02, avg batch time: 0.5029, average train loss: 0.0125
[09/26 12:01:19 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1669, average loss: 0.7538
[09/26 12:01:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.50	
[09/26 12:01:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:01:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.22e-02, avg batch time: 0.4962, average train loss: 0.0093
[09/26 12:01:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1669, average loss: 0.7499
[09/26 12:01:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 98.00	
[09/26 12:01:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:01:35 visual_prompt]: Epoch 20 / 100: avg data time: 5.63e-02, avg batch time: 0.4994, average train loss: 0.0064
[09/26 12:01:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1669, average loss: 0.7581
[09/26 12:01:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:01:36 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:01:43 visual_prompt]: Epoch 21 / 100: avg data time: 5.79e-02, avg batch time: 0.5016, average train loss: 0.0050
[09/26 12:01:45 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1667, average loss: 0.7483
[09/26 12:01:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 12:01:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:01:52 visual_prompt]: Epoch 22 / 100: avg data time: 5.80e-02, avg batch time: 0.5013, average train loss: 0.0050
[09/26 12:01:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1670, average loss: 0.7373
[09/26 12:01:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:01:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:02:00 visual_prompt]: Epoch 23 / 100: avg data time: 5.84e-02, avg batch time: 0.5007, average train loss: 0.0049
[09/26 12:02:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1668, average loss: 0.7354
[09/26 12:02:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 12:02:02 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:02:09 visual_prompt]: Epoch 24 / 100: avg data time: 7.00e-02, avg batch time: 0.5128, average train loss: 0.0047
[09/26 12:02:10 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 0.7358
[09/26 12:02:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:02:10 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:02:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.60e-02, avg batch time: 0.4994, average train loss: 0.0045
[09/26 12:02:19 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 0.7465
[09/26 12:02:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 12:02:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:02:26 visual_prompt]: Epoch 26 / 100: avg data time: 5.82e-02, avg batch time: 0.5005, average train loss: 0.0045
[09/26 12:02:27 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 0.7407
[09/26 12:02:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 12:02:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:02:34 visual_prompt]: Epoch 27 / 100: avg data time: 5.70e-02, avg batch time: 0.4996, average train loss: 0.0041
[09/26 12:02:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 0.7345
[09/26 12:02:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 12:02:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:02:43 visual_prompt]: Epoch 28 / 100: avg data time: 6.08e-02, avg batch time: 0.5038, average train loss: 0.0041
[09/26 12:02:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1668, average loss: 0.7348
[09/26 12:02:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:02:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:02:51 visual_prompt]: Epoch 29 / 100: avg data time: 5.11e-02, avg batch time: 0.4931, average train loss: 0.0043
[09/26 12:02:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 0.7414
[09/26 12:02:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:02:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:03:00 visual_prompt]: Epoch 30 / 100: avg data time: 6.10e-02, avg batch time: 0.5028, average train loss: 0.0040
[09/26 12:03:01 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 0.7358
[09/26 12:03:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:03:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:03:08 visual_prompt]: Epoch 31 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.0042
[09/26 12:03:09 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1668, average loss: 0.7355
[09/26 12:03:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:03:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:03:16 visual_prompt]: Epoch 32 / 100: avg data time: 5.48e-02, avg batch time: 0.4973, average train loss: 0.0042
[09/26 12:03:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1667, average loss: 0.7358
[09/26 12:03:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:03:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:03:25 visual_prompt]: Epoch 33 / 100: avg data time: 4.92e-02, avg batch time: 0.4927, average train loss: 0.0042
[09/26 12:03:26 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 0.7280
[09/26 12:03:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:03:26 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:03:33 visual_prompt]: Epoch 34 / 100: avg data time: 6.22e-02, avg batch time: 0.5048, average train loss: 0.0041
[09/26 12:03:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 0.7306
[09/26 12:03:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:03:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:03:42 visual_prompt]: Epoch 35 / 100: avg data time: 7.10e-02, avg batch time: 0.5142, average train loss: 0.0040
[09/26 12:03:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 0.7326
[09/26 12:03:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:03:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:03:50 visual_prompt]: Epoch 36 / 100: avg data time: 7.05e-02, avg batch time: 0.5116, average train loss: 0.0038
[09/26 12:03:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 0.7288
[09/26 12:03:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 12:03:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:03:59 visual_prompt]: Epoch 37 / 100: avg data time: 4.88e-02, avg batch time: 0.4928, average train loss: 0.0039
[09/26 12:04:00 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 0.7381
[09/26 12:04:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:04:00 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:04:07 visual_prompt]: Epoch 38 / 100: avg data time: 5.85e-02, avg batch time: 0.5013, average train loss: 0.0040
[09/26 12:04:09 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1667, average loss: 0.7280
[09/26 12:04:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:04:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:04:16 visual_prompt]: Epoch 39 / 100: avg data time: 6.99e-02, avg batch time: 0.5121, average train loss: 0.0040
[09/26 12:04:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1664, average loss: 0.7319
[09/26 12:04:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 12:04:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:04:24 visual_prompt]: Epoch 40 / 100: avg data time: 6.28e-02, avg batch time: 0.5046, average train loss: 0.0038
[09/26 12:04:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 0.7349
[09/26 12:04:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 12:04:26 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:04:33 visual_prompt]: Epoch 41 / 100: avg data time: 5.87e-02, avg batch time: 0.4998, average train loss: 0.0041
[09/26 12:04:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 0.7394
[09/26 12:04:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:04:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:04:41 visual_prompt]: Epoch 42 / 100: avg data time: 5.50e-02, avg batch time: 0.4972, average train loss: 0.0039
[09/26 12:04:43 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1664, average loss: 0.7365
[09/26 12:04:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 12:04:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:04:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e-02, avg batch time: 0.4940, average train loss: 0.0039
[09/26 12:04:51 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1666, average loss: 0.7239
[09/26 12:04:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 12:04:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:04:58 visual_prompt]: Epoch 44 / 100: avg data time: 4.82e-02, avg batch time: 0.4910, average train loss: 0.0040
[09/26 12:05:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 0.7147
[09/26 12:05:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 12:05:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:05:06 visual_prompt]: Epoch 45 / 100: avg data time: 5.43e-02, avg batch time: 0.4969, average train loss: 0.0039
[09/26 12:05:08 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 0.7146
[09/26 12:05:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 12:05:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:05:15 visual_prompt]: Epoch 46 / 100: avg data time: 5.84e-02, avg batch time: 0.5001, average train loss: 0.0040
[09/26 12:05:17 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 0.7165
[09/26 12:05:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:05:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:05:23 visual_prompt]: Epoch 47 / 100: avg data time: 5.09e-02, avg batch time: 0.4944, average train loss: 0.0039
[09/26 12:05:25 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1665, average loss: 0.7269
[09/26 12:05:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:05:25 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:05:32 visual_prompt]: Epoch 48 / 100: avg data time: 5.16e-02, avg batch time: 0.4961, average train loss: 0.0041
[09/26 12:05:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 0.7243
[09/26 12:05:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:05:33 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:05:40 visual_prompt]: Epoch 49 / 100: avg data time: 6.34e-02, avg batch time: 0.5054, average train loss: 0.0038
[09/26 12:05:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.7304
[09/26 12:05:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 12:05:42 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:05:49 visual_prompt]: Epoch 50 / 100: avg data time: 5.84e-02, avg batch time: 0.5017, average train loss: 0.0038
[09/26 12:05:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 0.7251
[09/26 12:05:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 12:05:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:05:57 visual_prompt]: Epoch 51 / 100: avg data time: 6.45e-02, avg batch time: 0.5073, average train loss: 0.0036
[09/26 12:05:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.7244
[09/26 12:05:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 12:05:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:06:06 visual_prompt]: Epoch 52 / 100: avg data time: 6.41e-02, avg batch time: 0.5055, average train loss: 0.0037
[09/26 12:06:07 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 0.7391
[09/26 12:06:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 12:06:07 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:06:14 visual_prompt]: Epoch 53 / 100: avg data time: 5.94e-02, avg batch time: 0.5021, average train loss: 0.0037
[09/26 12:06:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 0.7294
[09/26 12:06:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:06:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:06:23 visual_prompt]: Epoch 54 / 100: avg data time: 5.52e-02, avg batch time: 0.4970, average train loss: 0.0036
[09/26 12:06:24 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 0.7211
[09/26 12:06:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:06:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:06:31 visual_prompt]: Epoch 55 / 100: avg data time: 5.55e-02, avg batch time: 0.4986, average train loss: 0.0038
[09/26 12:06:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 0.7246
[09/26 12:06:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:06:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:06:40 visual_prompt]: Epoch 56 / 100: avg data time: 6.77e-02, avg batch time: 0.5098, average train loss: 0.0038
[09/26 12:06:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1666, average loss: 0.7186
[09/26 12:06:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:06:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:06:48 visual_prompt]: Epoch 57 / 100: avg data time: 6.07e-02, avg batch time: 0.5035, average train loss: 0.0037
[09/26 12:06:50 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1663, average loss: 0.7195
[09/26 12:06:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 12:06:50 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:06:56 visual_prompt]: Epoch 58 / 100: avg data time: 4.85e-02, avg batch time: 0.4907, average train loss: 0.0036
[09/26 12:06:58 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1666, average loss: 0.7321
[09/26 12:06:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:06:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:07:05 visual_prompt]: Epoch 59 / 100: avg data time: 5.32e-02, avg batch time: 0.4960, average train loss: 0.0036
[09/26 12:07:06 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1666, average loss: 0.7248
[09/26 12:07:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:07:06 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:07:13 visual_prompt]: Epoch 60 / 100: avg data time: 4.71e-02, avg batch time: 0.4894, average train loss: 0.0035
[09/26 12:07:15 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.7271
[09/26 12:07:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.50	
[09/26 12:07:15 visual_prompt]: Best epoch 60: best metric: 0.805
[09/26 12:07:15 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:07:21 visual_prompt]: Epoch 61 / 100: avg data time: 4.65e-02, avg batch time: 0.4921, average train loss: 0.0035
[09/26 12:07:23 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1665, average loss: 0.7230
[09/26 12:07:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 12:07:23 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:07:30 visual_prompt]: Epoch 62 / 100: avg data time: 5.33e-02, avg batch time: 0.4962, average train loss: 0.0036
[09/26 12:07:32 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1668, average loss: 0.7272
[09/26 12:07:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 12:07:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:07:38 visual_prompt]: Epoch 63 / 100: avg data time: 5.78e-02, avg batch time: 0.5000, average train loss: 0.0035
[09/26 12:07:40 visual_prompt]: Inference (val):avg data time: 4.08e-05, avg batch time: 0.1665, average loss: 0.7283
[09/26 12:07:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 12:07:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:07:47 visual_prompt]: Epoch 64 / 100: avg data time: 5.99e-02, avg batch time: 0.5033, average train loss: 0.0034
[09/26 12:07:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 0.7249
[09/26 12:07:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:07:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:07:55 visual_prompt]: Epoch 65 / 100: avg data time: 5.97e-02, avg batch time: 0.5014, average train loss: 0.0034
[09/26 12:07:57 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1666, average loss: 0.7199
[09/26 12:07:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 12:07:57 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:08:04 visual_prompt]: Epoch 66 / 100: avg data time: 4.72e-02, avg batch time: 0.4918, average train loss: 0.0035
[09/26 12:08:05 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1666, average loss: 0.7320
[09/26 12:08:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 12:08:05 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:08:12 visual_prompt]: Epoch 67 / 100: avg data time: 6.20e-02, avg batch time: 0.5046, average train loss: 0.0033
[09/26 12:08:14 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1667, average loss: 0.7244
[09/26 12:08:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:08:14 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:08:21 visual_prompt]: Epoch 68 / 100: avg data time: 6.51e-02, avg batch time: 0.5069, average train loss: 0.0033
[09/26 12:08:22 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1667, average loss: 0.7206
[09/26 12:08:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:08:22 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:08:29 visual_prompt]: Epoch 69 / 100: avg data time: 4.66e-02, avg batch time: 0.4899, average train loss: 0.0033
[09/26 12:08:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 0.7250
[09/26 12:08:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:08:31 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:08:37 visual_prompt]: Epoch 70 / 100: avg data time: 5.89e-02, avg batch time: 0.5018, average train loss: 0.0034
[09/26 12:08:39 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1665, average loss: 0.7208
[09/26 12:08:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.50	
[09/26 12:08:39 visual_prompt]: Best epoch 70: best metric: 0.810
[09/26 12:08:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:08:46 visual_prompt]: Epoch 71 / 100: avg data time: 6.03e-02, avg batch time: 0.5038, average train loss: 0.0034
[09/26 12:08:47 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 0.7198
[09/26 12:08:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:08:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:08:54 visual_prompt]: Epoch 72 / 100: avg data time: 5.08e-02, avg batch time: 0.4963, average train loss: 0.0034
[09/26 12:08:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 0.7165
[09/26 12:08:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:08:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:09:03 visual_prompt]: Epoch 73 / 100: avg data time: 5.08e-02, avg batch time: 0.4952, average train loss: 0.0033
[09/26 12:09:04 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 0.7168
[09/26 12:09:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 12:09:04 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:09:11 visual_prompt]: Epoch 74 / 100: avg data time: 6.05e-02, avg batch time: 0.5027, average train loss: 0.0033
[09/26 12:09:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1668, average loss: 0.7267
[09/26 12:09:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.50	
[09/26 12:09:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:09:20 visual_prompt]: Epoch 75 / 100: avg data time: 6.71e-02, avg batch time: 0.5090, average train loss: 0.0033
[09/26 12:09:21 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 0.7269
[09/26 12:09:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:09:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:09:28 visual_prompt]: Epoch 76 / 100: avg data time: 5.23e-02, avg batch time: 0.4945, average train loss: 0.0033
[09/26 12:09:30 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 0.7248
[09/26 12:09:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 12:09:30 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:09:36 visual_prompt]: Epoch 77 / 100: avg data time: 5.45e-02, avg batch time: 0.4964, average train loss: 0.0033
[09/26 12:09:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 0.7265
[09/26 12:09:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.00	
[09/26 12:09:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:09:45 visual_prompt]: Epoch 78 / 100: avg data time: 5.59e-02, avg batch time: 0.5005, average train loss: 0.0032
[09/26 12:09:47 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.7285
[09/26 12:09:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:09:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:09:54 visual_prompt]: Epoch 79 / 100: avg data time: 6.61e-02, avg batch time: 0.5092, average train loss: 0.0033
[09/26 12:09:55 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1666, average loss: 0.7243
[09/26 12:09:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:09:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:10:02 visual_prompt]: Epoch 80 / 100: avg data time: 6.43e-02, avg batch time: 0.5058, average train loss: 0.0032
[09/26 12:10:04 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1667, average loss: 0.7259
[09/26 12:10:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:10:04 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:10:11 visual_prompt]: Epoch 81 / 100: avg data time: 6.09e-02, avg batch time: 0.5027, average train loss: 0.0033
[09/26 12:10:12 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.7189
[09/26 12:10:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:10:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:10:19 visual_prompt]: Epoch 82 / 100: avg data time: 6.29e-02, avg batch time: 0.5043, average train loss: 0.0032
[09/26 12:10:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1666, average loss: 0.7175
[09/26 12:10:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 12:10:21 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:10:28 visual_prompt]: Epoch 83 / 100: avg data time: 6.82e-02, avg batch time: 0.5105, average train loss: 0.0032
[09/26 12:10:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 0.7216
[09/26 12:10:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:10:29 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:10:36 visual_prompt]: Epoch 84 / 100: avg data time: 5.46e-02, avg batch time: 0.4978, average train loss: 0.0031
[09/26 12:10:38 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1662, average loss: 0.7257
[09/26 12:10:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:10:38 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:10:45 visual_prompt]: Epoch 85 / 100: avg data time: 4.68e-02, avg batch time: 0.4898, average train loss: 0.0032
[09/26 12:10:46 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1668, average loss: 0.7235
[09/26 12:10:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:10:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:10:53 visual_prompt]: Epoch 86 / 100: avg data time: 6.06e-02, avg batch time: 0.5022, average train loss: 0.0032
[09/26 12:10:55 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1666, average loss: 0.7206
[09/26 12:10:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:10:55 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:11:01 visual_prompt]: Epoch 87 / 100: avg data time: 5.04e-02, avg batch time: 0.4944, average train loss: 0.0031
[09/26 12:11:03 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.7212
[09/26 12:11:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:11:03 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:11:10 visual_prompt]: Epoch 88 / 100: avg data time: 5.33e-02, avg batch time: 0.4956, average train loss: 0.0032
[09/26 12:11:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 0.7208
[09/26 12:11:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:11:11 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:11:18 visual_prompt]: Epoch 89 / 100: avg data time: 5.74e-02, avg batch time: 0.4997, average train loss: 0.0032
[09/26 12:11:20 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1665, average loss: 0.7214
[09/26 12:11:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:11:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 12:11:27 visual_prompt]: Epoch 90 / 100: avg data time: 4.81e-02, avg batch time: 0.4930, average train loss: 0.0031
[09/26 12:11:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 0.7222
[09/26 12:11:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:11:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 12:11:35 visual_prompt]: Epoch 91 / 100: avg data time: 4.94e-02, avg batch time: 0.4927, average train loss: 0.0032
[09/26 12:11:36 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1665, average loss: 0.7217
[09/26 12:11:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:11:36 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 12:11:43 visual_prompt]: Epoch 92 / 100: avg data time: 6.07e-02, avg batch time: 0.5029, average train loss: 0.0032
[09/26 12:11:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1665, average loss: 0.7215
[09/26 12:11:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:11:45 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 12:11:52 visual_prompt]: Epoch 93 / 100: avg data time: 5.92e-02, avg batch time: 0.5020, average train loss: 0.0032
[09/26 12:11:53 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1663, average loss: 0.7217
[09/26 12:11:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:11:53 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 12:12:00 visual_prompt]: Epoch 94 / 100: avg data time: 4.84e-02, avg batch time: 0.4918, average train loss: 0.0032
[09/26 12:12:02 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1666, average loss: 0.7218
[09/26 12:12:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:02 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 12:12:09 visual_prompt]: Epoch 95 / 100: avg data time: 4.94e-02, avg batch time: 0.4938, average train loss: 0.0031
[09/26 12:12:10 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1665, average loss: 0.7221
[09/26 12:12:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:10 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 12:12:17 visual_prompt]: Epoch 96 / 100: avg data time: 5.08e-02, avg batch time: 0.4932, average train loss: 0.0031
[09/26 12:12:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 0.7223
[09/26 12:12:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:19 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 12:12:25 visual_prompt]: Epoch 97 / 100: avg data time: 4.68e-02, avg batch time: 0.4910, average train loss: 0.0032
[09/26 12:12:27 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1664, average loss: 0.7223
[09/26 12:12:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:27 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 12:12:34 visual_prompt]: Epoch 98 / 100: avg data time: 5.15e-02, avg batch time: 0.4950, average train loss: 0.0032
[09/26 12:12:36 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1666, average loss: 0.7224
[09/26 12:12:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:36 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 12:12:42 visual_prompt]: Epoch 99 / 100: avg data time: 5.19e-02, avg batch time: 0.4963, average train loss: 0.0031
[09/26 12:12:44 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1665, average loss: 0.7224
[09/26 12:12:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 12:12:51 visual_prompt]: Epoch 100 / 100: avg data time: 6.14e-02, avg batch time: 0.5029, average train loss: 0.0033
[09/26 12:12:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 0.7224
[09/26 12:12:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:12:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:12:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:12:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:12:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:12:52 visual_prompt]: Training with config:
[09/26 12:12:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr1.0_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:12:52 visual_prompt]: Loading training data...
[09/26 12:12:52 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:12:54 visual_prompt]: Number of images: 800
[09/26 12:12:54 visual_prompt]: Number of classes: 45 / 45
[09/26 12:12:54 visual_prompt]: Loading validation data...
[09/26 12:12:54 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:12:54 visual_prompt]: Number of images: 200
[09/26 12:12:54 visual_prompt]: Number of classes: 45 / 45
[09/26 12:12:54 visual_prompt]: Constructing models...
[09/26 12:12:56 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 12:12:56 visual_prompt]: tuned percent:0.574
[09/26 12:12:56 visual_prompt]: Device used for model: 0
[09/26 12:12:56 visual_prompt]: Setting up Evaluator...
[09/26 12:12:56 visual_prompt]: Setting up Trainer...
[09/26 12:12:56 visual_prompt]: 	Setting up the optimizer...
[09/26 12:12:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:13:03 visual_prompt]: Epoch 1 / 100: avg data time: 5.80e-02, avg batch time: 0.4987, average train loss: 3.8918
[09/26 12:13:05 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 12:13:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 12:13:05 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 12:13:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/26 12:13:12 visual_prompt]: Epoch 2 / 100: avg data time: 5.93e-02, avg batch time: 0.5009, average train loss: 3.7851
[09/26 12:13:13 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 3.7308
[09/26 12:13:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 24.50	
[09/26 12:13:13 visual_prompt]: Best epoch 2: best metric: 0.050
[09/26 12:13:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/26 12:13:20 visual_prompt]: Epoch 3 / 100: avg data time: 5.73e-02, avg batch time: 0.4995, average train loss: 3.5418
[09/26 12:13:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 3.2786
[09/26 12:13:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 34.00	
[09/26 12:13:21 visual_prompt]: Best epoch 3: best metric: 0.095
[09/26 12:13:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/26 12:13:28 visual_prompt]: Epoch 4 / 100: avg data time: 4.88e-02, avg batch time: 0.4905, average train loss: 3.1705
[09/26 12:13:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 3.4722
[09/26 12:13:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 33.50	
[09/26 12:13:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/26 12:13:36 visual_prompt]: Epoch 5 / 100: avg data time: 4.87e-02, avg batch time: 0.4915, average train loss: 2.7248
[09/26 12:13:38 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 2.5971
[09/26 12:13:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.50	top5: 62.50	
[09/26 12:13:38 visual_prompt]: Best epoch 5: best metric: 0.295
[09/26 12:13:38 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/26 12:13:45 visual_prompt]: Epoch 6 / 100: avg data time: 4.93e-02, avg batch time: 0.4934, average train loss: 2.4005
[09/26 12:13:46 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 2.2498
[09/26 12:13:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 34.50	top5: 68.50	
[09/26 12:13:46 visual_prompt]: Best epoch 6: best metric: 0.345
[09/26 12:13:46 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/26 12:13:53 visual_prompt]: Epoch 7 / 100: avg data time: 4.87e-02, avg batch time: 0.4921, average train loss: 1.8810
[09/26 12:13:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 2.4404
[09/26 12:13:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 38.00	top5: 72.50	
[09/26 12:13:55 visual_prompt]: Best epoch 7: best metric: 0.380
[09/26 12:13:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/26 12:14:02 visual_prompt]: Epoch 8 / 100: avg data time: 5.40e-02, avg batch time: 0.4964, average train loss: 1.6135
[09/26 12:14:03 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 2.5476
[09/26 12:14:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 35.00	top5: 72.00	
[09/26 12:14:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/26 12:14:10 visual_prompt]: Epoch 9 / 100: avg data time: 5.48e-02, avg batch time: 0.4985, average train loss: 1.2433
[09/26 12:14:12 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.8994
[09/26 12:14:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.50	top5: 84.00	
[09/26 12:14:12 visual_prompt]: Best epoch 9: best metric: 0.465
[09/26 12:14:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/26 12:14:19 visual_prompt]: Epoch 10 / 100: avg data time: 6.34e-02, avg batch time: 0.5049, average train loss: 0.8213
[09/26 12:14:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1664, average loss: 1.5602
[09/26 12:14:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 85.00	
[09/26 12:14:20 visual_prompt]: Best epoch 10: best metric: 0.615
[09/26 12:14:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/26 12:14:27 visual_prompt]: Epoch 11 / 100: avg data time: 4.78e-02, avg batch time: 0.4930, average train loss: 0.4789
[09/26 12:14:29 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1664, average loss: 1.2947
[09/26 12:14:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 89.00	
[09/26 12:14:29 visual_prompt]: Best epoch 11: best metric: 0.635
[09/26 12:14:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/26 12:14:36 visual_prompt]: Epoch 12 / 100: avg data time: 6.67e-02, avg batch time: 0.5085, average train loss: 0.2396
[09/26 12:14:37 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.1039
[09/26 12:14:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 93.00	
[09/26 12:14:37 visual_prompt]: Best epoch 12: best metric: 0.725
[09/26 12:14:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/26 12:14:44 visual_prompt]: Epoch 13 / 100: avg data time: 6.14e-02, avg batch time: 0.5044, average train loss: 0.1395
[09/26 12:14:46 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1666, average loss: 1.1554
[09/26 12:14:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.00	
[09/26 12:14:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/26 12:14:53 visual_prompt]: Epoch 14 / 100: avg data time: 5.92e-02, avg batch time: 0.5029, average train loss: 0.0948
[09/26 12:14:54 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 1.1672
[09/26 12:14:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 12:14:54 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/26 12:15:01 visual_prompt]: Epoch 15 / 100: avg data time: 4.97e-02, avg batch time: 0.4931, average train loss: 0.0398
[09/26 12:15:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 0.9546
[09/26 12:15:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.50	
[09/26 12:15:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/26 12:15:09 visual_prompt]: Epoch 16 / 100: avg data time: 5.47e-02, avg batch time: 0.4967, average train loss: 0.0287
[09/26 12:15:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.0080
[09/26 12:15:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 95.00	
[09/26 12:15:11 visual_prompt]: Best epoch 16: best metric: 0.735
[09/26 12:15:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/26 12:15:18 visual_prompt]: Epoch 17 / 100: avg data time: 5.40e-02, avg batch time: 0.4969, average train loss: 0.0167
[09/26 12:15:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 0.9646
[09/26 12:15:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 95.50	
[09/26 12:15:19 visual_prompt]: Best epoch 17: best metric: 0.800
[09/26 12:15:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/26 12:15:26 visual_prompt]: Epoch 18 / 100: avg data time: 5.19e-02, avg batch time: 0.4953, average train loss: 0.0089
[09/26 12:15:28 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1664, average loss: 0.9117
[09/26 12:15:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:15:28 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/26 12:15:35 visual_prompt]: Epoch 19 / 100: avg data time: 6.44e-02, avg batch time: 0.5074, average train loss: 0.0051
[09/26 12:15:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 0.8997
[09/26 12:15:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:15:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/26 12:15:43 visual_prompt]: Epoch 20 / 100: avg data time: 5.10e-02, avg batch time: 0.4979, average train loss: 0.0039
[09/26 12:15:45 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 0.8842
[09/26 12:15:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:15:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/26 12:15:52 visual_prompt]: Epoch 21 / 100: avg data time: 6.01e-02, avg batch time: 0.5016, average train loss: 0.0032
[09/26 12:15:53 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 0.8814
[09/26 12:15:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:15:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/26 12:16:00 visual_prompt]: Epoch 22 / 100: avg data time: 6.45e-02, avg batch time: 0.5069, average train loss: 0.0028
[09/26 12:16:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 0.8826
[09/26 12:16:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:16:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/26 12:16:08 visual_prompt]: Epoch 23 / 100: avg data time: 4.79e-02, avg batch time: 0.4941, average train loss: 0.0026
[09/26 12:16:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 0.8889
[09/26 12:16:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:16:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/26 12:16:17 visual_prompt]: Epoch 24 / 100: avg data time: 4.89e-02, avg batch time: 0.4938, average train loss: 0.0024
[09/26 12:16:18 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.8883
[09/26 12:16:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:16:18 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/26 12:16:25 visual_prompt]: Epoch 25 / 100: avg data time: 5.23e-02, avg batch time: 0.4954, average train loss: 0.0022
[09/26 12:16:27 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 0.8854
[09/26 12:16:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:16:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/26 12:16:33 visual_prompt]: Epoch 26 / 100: avg data time: 4.98e-02, avg batch time: 0.4937, average train loss: 0.0019
[09/26 12:16:35 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 0.8838
[09/26 12:16:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:16:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/26 12:16:42 visual_prompt]: Epoch 27 / 100: avg data time: 4.98e-02, avg batch time: 0.4933, average train loss: 0.0022
[09/26 12:16:43 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1668, average loss: 0.8850
[09/26 12:16:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:16:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/26 12:16:50 visual_prompt]: Epoch 28 / 100: avg data time: 6.06e-02, avg batch time: 0.5026, average train loss: 0.0017
[09/26 12:16:52 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 0.8881
[09/26 12:16:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:16:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/26 12:16:59 visual_prompt]: Epoch 29 / 100: avg data time: 4.97e-02, avg batch time: 0.4939, average train loss: 0.0019
[09/26 12:17:00 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 0.8894
[09/26 12:17:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:17:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/26 12:17:07 visual_prompt]: Epoch 30 / 100: avg data time: 4.85e-02, avg batch time: 0.4922, average train loss: 0.0016
[09/26 12:17:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 0.8899
[09/26 12:17:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:17:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/26 12:17:15 visual_prompt]: Epoch 31 / 100: avg data time: 5.04e-02, avg batch time: 0.4978, average train loss: 0.0017
[09/26 12:17:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.8908
[09/26 12:17:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 12:17:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/26 12:17:24 visual_prompt]: Epoch 32 / 100: avg data time: 5.76e-02, avg batch time: 0.5008, average train loss: 0.0016
[09/26 12:17:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 0.8880
[09/26 12:17:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 12:17:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/26 12:17:32 visual_prompt]: Epoch 33 / 100: avg data time: 4.96e-02, avg batch time: 0.4942, average train loss: 0.0014
[09/26 12:17:34 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 0.8883
[09/26 12:17:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:17:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/26 12:17:41 visual_prompt]: Epoch 34 / 100: avg data time: 5.24e-02, avg batch time: 0.4959, average train loss: 0.0014
[09/26 12:17:42 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 0.8905
[09/26 12:17:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:17:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/26 12:17:49 visual_prompt]: Epoch 35 / 100: avg data time: 5.69e-02, avg batch time: 0.4988, average train loss: 0.0014
[09/26 12:17:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 0.8884
[09/26 12:17:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:17:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/26 12:17:58 visual_prompt]: Epoch 36 / 100: avg data time: 6.07e-02, avg batch time: 0.5029, average train loss: 0.0014
[09/26 12:17:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1664, average loss: 0.8889
[09/26 12:17:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:17:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/26 12:18:06 visual_prompt]: Epoch 37 / 100: avg data time: 6.47e-02, avg batch time: 0.5067, average train loss: 0.0015
[09/26 12:18:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1665, average loss: 0.8883
[09/26 12:18:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:18:08 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/26 12:18:14 visual_prompt]: Epoch 38 / 100: avg data time: 4.93e-02, avg batch time: 0.4909, average train loss: 0.0013
[09/26 12:18:16 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 0.8907
[09/26 12:18:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:18:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/26 12:18:23 visual_prompt]: Epoch 39 / 100: avg data time: 5.03e-02, avg batch time: 0.4945, average train loss: 0.0013
[09/26 12:18:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 0.8896
[09/26 12:18:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:18:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/26 12:18:31 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e-02, avg batch time: 0.4943, average train loss: 0.0012
[09/26 12:18:33 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1664, average loss: 0.8888
[09/26 12:18:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:18:33 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/26 12:18:40 visual_prompt]: Epoch 41 / 100: avg data time: 5.23e-02, avg batch time: 0.4974, average train loss: 0.0012
[09/26 12:18:41 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1664, average loss: 0.8881
[09/26 12:18:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:18:41 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/26 12:18:48 visual_prompt]: Epoch 42 / 100: avg data time: 5.81e-02, avg batch time: 0.5016, average train loss: 0.0012
[09/26 12:18:50 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1661, average loss: 0.8873
[09/26 12:18:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:18:50 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/26 12:18:57 visual_prompt]: Epoch 43 / 100: avg data time: 4.78e-02, avg batch time: 0.4904, average train loss: 0.0012
[09/26 12:18:58 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 0.8858
[09/26 12:18:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:18:58 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/26 12:19:05 visual_prompt]: Epoch 44 / 100: avg data time: 4.80e-02, avg batch time: 0.4914, average train loss: 0.0011
[09/26 12:19:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 0.8842
[09/26 12:19:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:19:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/26 12:19:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.13e-02, avg batch time: 0.4943, average train loss: 0.0012
[09/26 12:19:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 0.8878
[09/26 12:19:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:19:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/26 12:19:22 visual_prompt]: Epoch 46 / 100: avg data time: 6.15e-02, avg batch time: 0.5029, average train loss: 0.0011
[09/26 12:19:23 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 0.8898
[09/26 12:19:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:19:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/26 12:19:30 visual_prompt]: Epoch 47 / 100: avg data time: 4.97e-02, avg batch time: 0.4926, average train loss: 0.0011
[09/26 12:19:31 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.8930
[09/26 12:19:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:19:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/26 12:19:38 visual_prompt]: Epoch 48 / 100: avg data time: 6.31e-02, avg batch time: 0.5049, average train loss: 0.0010
[09/26 12:19:40 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 0.8944
[09/26 12:19:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:19:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/26 12:19:47 visual_prompt]: Epoch 49 / 100: avg data time: 4.97e-02, avg batch time: 0.4952, average train loss: 0.0011
[09/26 12:19:48 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 0.8934
[09/26 12:19:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:19:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/26 12:19:55 visual_prompt]: Epoch 50 / 100: avg data time: 4.77e-02, avg batch time: 0.4900, average train loss: 0.0010
[09/26 12:19:57 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 0.8924
[09/26 12:19:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:19:57 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/26 12:20:04 visual_prompt]: Epoch 51 / 100: avg data time: 5.03e-02, avg batch time: 0.4935, average train loss: 0.0010
[09/26 12:20:05 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 0.8922
[09/26 12:20:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:20:05 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/26 12:20:12 visual_prompt]: Epoch 52 / 100: avg data time: 5.84e-02, avg batch time: 0.4995, average train loss: 0.0010
[09/26 12:20:14 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 0.8914
[09/26 12:20:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:20:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/26 12:20:20 visual_prompt]: Epoch 53 / 100: avg data time: 5.15e-02, avg batch time: 0.4951, average train loss: 0.0009
[09/26 12:20:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 0.8924
[09/26 12:20:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:20:22 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/26 12:20:29 visual_prompt]: Epoch 54 / 100: avg data time: 5.12e-02, avg batch time: 0.4938, average train loss: 0.0009
[09/26 12:20:30 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.8931
[09/26 12:20:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:20:30 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/26 12:20:37 visual_prompt]: Epoch 55 / 100: avg data time: 4.82e-02, avg batch time: 0.4900, average train loss: 0.0010
[09/26 12:20:38 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 0.8933
[09/26 12:20:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:20:38 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/26 12:20:45 visual_prompt]: Epoch 56 / 100: avg data time: 6.25e-02, avg batch time: 0.5045, average train loss: 0.0010
[09/26 12:20:47 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 0.8936
[09/26 12:20:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:20:47 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/26 12:20:54 visual_prompt]: Epoch 57 / 100: avg data time: 4.79e-02, avg batch time: 0.4917, average train loss: 0.0009
[09/26 12:20:55 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 0.8939
[09/26 12:20:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:20:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/26 12:21:02 visual_prompt]: Epoch 58 / 100: avg data time: 5.16e-02, avg batch time: 0.4930, average train loss: 0.0010
[09/26 12:21:04 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1662, average loss: 0.8940
[09/26 12:21:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:04 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/26 12:21:10 visual_prompt]: Epoch 59 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 0.0009
[09/26 12:21:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 0.8946
[09/26 12:21:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:12 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/26 12:21:19 visual_prompt]: Epoch 60 / 100: avg data time: 5.31e-02, avg batch time: 0.4946, average train loss: 0.0009
[09/26 12:21:20 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1662, average loss: 0.8950
[09/26 12:21:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/26 12:21:27 visual_prompt]: Epoch 61 / 100: avg data time: 5.61e-02, avg batch time: 0.4998, average train loss: 0.0009
[09/26 12:21:29 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.8949
[09/26 12:21:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/26 12:21:36 visual_prompt]: Epoch 62 / 100: avg data time: 5.26e-02, avg batch time: 0.4954, average train loss: 0.0009
[09/26 12:21:37 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1660, average loss: 0.8949
[09/26 12:21:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:37 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/26 12:21:44 visual_prompt]: Epoch 63 / 100: avg data time: 4.91e-02, avg batch time: 0.4910, average train loss: 0.0009
[09/26 12:21:46 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 0.8953
[09/26 12:21:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:21:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/26 12:21:52 visual_prompt]: Epoch 64 / 100: avg data time: 5.01e-02, avg batch time: 0.4922, average train loss: 0.0008
[09/26 12:21:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 0.8951
[09/26 12:21:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 95.50	
[09/26 12:21:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/26 12:22:01 visual_prompt]: Epoch 65 / 100: avg data time: 5.01e-02, avg batch time: 0.4946, average train loss: 0.0009
[09/26 12:22:02 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8949
[09/26 12:22:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 12:22:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/26 12:22:09 visual_prompt]: Epoch 66 / 100: avg data time: 4.76e-02, avg batch time: 0.4906, average train loss: 0.0009
[09/26 12:22:11 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 0.8951
[09/26 12:22:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 12:22:11 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/26 12:22:18 visual_prompt]: Epoch 67 / 100: avg data time: 5.67e-02, avg batch time: 0.4997, average train loss: 0.0009
[09/26 12:22:19 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1660, average loss: 0.8943
[09/26 12:22:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:22:19 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/26 12:22:26 visual_prompt]: Epoch 68 / 100: avg data time: 6.29e-02, avg batch time: 0.5048, average train loss: 0.0008
[09/26 12:22:28 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 0.8946
[09/26 12:22:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:22:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/26 12:22:35 visual_prompt]: Epoch 69 / 100: avg data time: 6.17e-02, avg batch time: 0.5025, average train loss: 0.0008
[09/26 12:22:36 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1658, average loss: 0.8957
[09/26 12:22:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:22:36 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/26 12:22:43 visual_prompt]: Epoch 70 / 100: avg data time: 4.78e-02, avg batch time: 0.4906, average train loss: 0.0008
[09/26 12:22:44 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 0.8964
[09/26 12:22:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:22:44 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/26 12:22:51 visual_prompt]: Epoch 71 / 100: avg data time: 4.86e-02, avg batch time: 0.4929, average train loss: 0.0008
[09/26 12:22:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1659, average loss: 0.8968
[09/26 12:22:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:22:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/26 12:23:00 visual_prompt]: Epoch 72 / 100: avg data time: 6.13e-02, avg batch time: 0.5023, average train loss: 0.0009
[09/26 12:23:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1659, average loss: 0.8964
[09/26 12:23:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:23:01 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/26 12:23:08 visual_prompt]: Epoch 73 / 100: avg data time: 5.54e-02, avg batch time: 0.4965, average train loss: 0.0008
[09/26 12:23:10 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 0.8961
[09/26 12:23:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 12:23:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/26 12:23:17 visual_prompt]: Epoch 74 / 100: avg data time: 5.35e-02, avg batch time: 0.4968, average train loss: 0.0008
[09/26 12:23:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 0.8958
[09/26 12:23:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 12:23:18 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/26 12:23:25 visual_prompt]: Epoch 75 / 100: avg data time: 5.60e-02, avg batch time: 0.4968, average train loss: 0.0008
[09/26 12:23:26 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.8957
[09/26 12:23:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 12:23:26 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/26 12:23:33 visual_prompt]: Epoch 76 / 100: avg data time: 4.85e-02, avg batch time: 0.4917, average train loss: 0.0008
[09/26 12:23:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1661, average loss: 0.8959
[09/26 12:23:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:23:35 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/26 12:23:41 visual_prompt]: Epoch 77 / 100: avg data time: 5.17e-02, avg batch time: 0.4941, average train loss: 0.0009
[09/26 12:23:43 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1659, average loss: 0.8964
[09/26 12:23:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:23:43 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/26 12:23:50 visual_prompt]: Epoch 78 / 100: avg data time: 6.35e-02, avg batch time: 0.5043, average train loss: 0.0009
[09/26 12:23:51 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1659, average loss: 0.8970
[09/26 12:23:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:23:51 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/26 12:23:58 visual_prompt]: Epoch 79 / 100: avg data time: 5.53e-02, avg batch time: 0.4968, average train loss: 0.0008
[09/26 12:24:00 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1660, average loss: 0.8971
[09/26 12:24:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/26 12:24:07 visual_prompt]: Epoch 80 / 100: avg data time: 5.16e-02, avg batch time: 0.4929, average train loss: 0.0008
[09/26 12:24:08 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1660, average loss: 0.8970
[09/26 12:24:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:08 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/26 12:24:15 visual_prompt]: Epoch 81 / 100: avg data time: 5.23e-02, avg batch time: 0.4960, average train loss: 0.0008
[09/26 12:24:17 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1659, average loss: 0.8970
[09/26 12:24:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:17 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/26 12:24:23 visual_prompt]: Epoch 82 / 100: avg data time: 5.14e-02, avg batch time: 0.4934, average train loss: 0.0008
[09/26 12:24:25 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1659, average loss: 0.8971
[09/26 12:24:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:25 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/26 12:24:32 visual_prompt]: Epoch 83 / 100: avg data time: 6.36e-02, avg batch time: 0.5044, average train loss: 0.0008
[09/26 12:24:34 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1660, average loss: 0.8972
[09/26 12:24:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:34 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/26 12:24:40 visual_prompt]: Epoch 84 / 100: avg data time: 6.13e-02, avg batch time: 0.5022, average train loss: 0.0008
[09/26 12:24:42 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1659, average loss: 0.8971
[09/26 12:24:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:42 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/26 12:24:49 visual_prompt]: Epoch 85 / 100: avg data time: 6.37e-02, avg batch time: 0.5050, average train loss: 0.0009
[09/26 12:24:51 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 0.8969
[09/26 12:24:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/26 12:24:57 visual_prompt]: Epoch 86 / 100: avg data time: 5.84e-02, avg batch time: 0.5001, average train loss: 0.0009
[09/26 12:24:59 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1659, average loss: 0.8969
[09/26 12:24:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:24:59 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/26 12:25:06 visual_prompt]: Epoch 87 / 100: avg data time: 6.59e-02, avg batch time: 0.5064, average train loss: 0.0008
[09/26 12:25:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1657, average loss: 0.8970
[09/26 12:25:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/26 12:25:15 visual_prompt]: Epoch 88 / 100: avg data time: 6.92e-02, avg batch time: 0.5109, average train loss: 0.0007
[09/26 12:25:16 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.8971
[09/26 12:25:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/26 12:25:23 visual_prompt]: Epoch 89 / 100: avg data time: 6.17e-02, avg batch time: 0.5031, average train loss: 0.0008
[09/26 12:25:25 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1661, average loss: 0.8972
[09/26 12:25:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/26 12:25:32 visual_prompt]: Epoch 90 / 100: avg data time: 6.04e-02, avg batch time: 0.5019, average train loss: 0.0008
[09/26 12:25:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 0.8972
[09/26 12:25:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/26 12:25:40 visual_prompt]: Epoch 91 / 100: avg data time: 4.95e-02, avg batch time: 0.4925, average train loss: 0.0008
[09/26 12:25:42 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1661, average loss: 0.8972
[09/26 12:25:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/26 12:25:48 visual_prompt]: Epoch 92 / 100: avg data time: 4.81e-02, avg batch time: 0.4898, average train loss: 0.0007
[09/26 12:25:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1660, average loss: 0.8972
[09/26 12:25:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:25:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/26 12:25:57 visual_prompt]: Epoch 93 / 100: avg data time: 5.67e-02, avg batch time: 0.4974, average train loss: 0.0007
[09/26 12:25:58 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1661, average loss: 0.8973
[09/26 12:25:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:25:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/26 12:26:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 0.0008
[09/26 12:26:07 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1661, average loss: 0.8973
[09/26 12:26:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/26 12:26:14 visual_prompt]: Epoch 95 / 100: avg data time: 5.09e-02, avg batch time: 0.4934, average train loss: 0.0009
[09/26 12:26:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1660, average loss: 0.8973
[09/26 12:26:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/26 12:26:22 visual_prompt]: Epoch 96 / 100: avg data time: 5.91e-02, avg batch time: 0.5012, average train loss: 0.0008
[09/26 12:26:24 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1659, average loss: 0.8973
[09/26 12:26:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/26 12:26:31 visual_prompt]: Epoch 97 / 100: avg data time: 6.38e-02, avg batch time: 0.5045, average train loss: 0.0009
[09/26 12:26:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1661, average loss: 0.8973
[09/26 12:26:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/26 12:26:39 visual_prompt]: Epoch 98 / 100: avg data time: 6.92e-02, avg batch time: 0.5109, average train loss: 0.0008
[09/26 12:26:41 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 0.8973
[09/26 12:26:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:41 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/26 12:26:48 visual_prompt]: Epoch 99 / 100: avg data time: 5.16e-02, avg batch time: 0.4939, average train loss: 0.0008
[09/26 12:26:49 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1661, average loss: 0.8973
[09/26 12:26:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:49 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/26 12:26:56 visual_prompt]: Epoch 100 / 100: avg data time: 6.89e-02, avg batch time: 0.5097, average train loss: 0.0008
[09/26 12:26:58 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1659, average loss: 0.8973
[09/26 12:26:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.50	
[09/26 12:26:58 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:26:58 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:26:58 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:26:58 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:26:58 visual_prompt]: Training with config:
[09/26 12:26:58 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:26:58 visual_prompt]: Loading training data...
[09/26 12:26:58 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:26:59 visual_prompt]: Number of images: 800
[09/26 12:26:59 visual_prompt]: Number of classes: 45 / 45
[09/26 12:26:59 visual_prompt]: Loading validation data...
[09/26 12:26:59 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:26:59 visual_prompt]: Number of images: 200
[09/26 12:26:59 visual_prompt]: Number of classes: 45 / 45
[09/26 12:26:59 visual_prompt]: Constructing models...
[09/26 12:27:02 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 12:27:02 visual_prompt]: tuned percent:0.574
[09/26 12:27:02 visual_prompt]: Device used for model: 0
[09/26 12:27:02 visual_prompt]: Setting up Evaluator...
[09/26 12:27:02 visual_prompt]: Setting up Trainer...
[09/26 12:27:02 visual_prompt]: 	Setting up the optimizer...
[09/26 12:27:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:27:09 visual_prompt]: Epoch 1 / 100: avg data time: 4.48e-02, avg batch time: 0.4861, average train loss: 3.8908
[09/26 12:27:10 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 12:27:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 12:27:10 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 12:27:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 12:27:17 visual_prompt]: Epoch 2 / 100: avg data time: 4.59e-02, avg batch time: 0.4883, average train loss: 3.8130
[09/26 12:27:18 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1657, average loss: 3.8204
[09/26 12:27:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.00	
[09/26 12:27:18 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 12:27:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 12:27:25 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e-02, avg batch time: 0.4906, average train loss: 3.7176
[09/26 12:27:27 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1658, average loss: 3.6503
[09/26 12:27:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 22.50	
[09/26 12:27:27 visual_prompt]: Best epoch 3: best metric: 0.050
[09/26 12:27:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 12:27:34 visual_prompt]: Epoch 4 / 100: avg data time: 5.23e-02, avg batch time: 0.4937, average train loss: 3.3844
[09/26 12:27:35 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 2.9683
[09/26 12:27:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 47.00	
[09/26 12:27:35 visual_prompt]: Best epoch 4: best metric: 0.140
[09/26 12:27:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 12:27:42 visual_prompt]: Epoch 5 / 100: avg data time: 5.53e-02, avg batch time: 0.4969, average train loss: 3.0571
[09/26 12:27:44 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1658, average loss: 3.2021
[09/26 12:27:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 41.00	
[09/26 12:27:44 visual_prompt]: Best epoch 5: best metric: 0.145
[09/26 12:27:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 12:27:50 visual_prompt]: Epoch 6 / 100: avg data time: 4.85e-02, avg batch time: 0.4907, average train loss: 2.9776
[09/26 12:27:52 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1660, average loss: 3.7008
[09/26 12:27:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 26.00	
[09/26 12:27:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 12:27:59 visual_prompt]: Epoch 7 / 100: avg data time: 5.48e-02, avg batch time: 0.4983, average train loss: 3.4958
[09/26 12:28:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 3.0422
[09/26 12:28:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 44.50	
[09/26 12:28:00 visual_prompt]: Best epoch 7: best metric: 0.185
[09/26 12:28:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 12:28:07 visual_prompt]: Epoch 8 / 100: avg data time: 5.45e-02, avg batch time: 0.4952, average train loss: 2.8427
[09/26 12:28:09 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1660, average loss: 2.6042
[09/26 12:28:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 61.50	
[09/26 12:28:09 visual_prompt]: Best epoch 8: best metric: 0.255
[09/26 12:28:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 12:28:16 visual_prompt]: Epoch 9 / 100: avg data time: 5.49e-02, avg batch time: 0.4955, average train loss: 2.5259
[09/26 12:28:17 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 2.6712
[09/26 12:28:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 36.00	top5: 67.00	
[09/26 12:28:17 visual_prompt]: Best epoch 9: best metric: 0.360
[09/26 12:28:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 12:28:24 visual_prompt]: Epoch 10 / 100: avg data time: 6.18e-02, avg batch time: 0.5034, average train loss: 2.5664
[09/26 12:28:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 2.2357
[09/26 12:28:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 38.00	top5: 78.00	
[09/26 12:28:26 visual_prompt]: Best epoch 10: best metric: 0.380
[09/26 12:28:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 12:28:32 visual_prompt]: Epoch 11 / 100: avg data time: 4.91e-02, avg batch time: 0.4908, average train loss: 2.0214
[09/26 12:28:34 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 2.0321
[09/26 12:28:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.00	top5: 78.00	
[09/26 12:28:34 visual_prompt]: Best epoch 11: best metric: 0.450
[09/26 12:28:34 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 12:28:41 visual_prompt]: Epoch 12 / 100: avg data time: 4.78e-02, avg batch time: 0.4915, average train loss: 1.6051
[09/26 12:28:42 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 2.3204
[09/26 12:28:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 36.00	top5: 74.50	
[09/26 12:28:42 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 12:28:49 visual_prompt]: Epoch 13 / 100: avg data time: 5.73e-02, avg batch time: 0.4996, average train loss: 1.6095
[09/26 12:28:51 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1660, average loss: 1.5324
[09/26 12:28:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 92.00	
[09/26 12:28:51 visual_prompt]: Best epoch 13: best metric: 0.620
[09/26 12:28:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 12:28:57 visual_prompt]: Epoch 14 / 100: avg data time: 4.87e-02, avg batch time: 0.4916, average train loss: 1.3715
[09/26 12:28:59 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.3481
[09/26 12:28:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 94.00	
[09/26 12:28:59 visual_prompt]: Best epoch 14: best metric: 0.680
[09/26 12:28:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 12:29:06 visual_prompt]: Epoch 15 / 100: avg data time: 4.88e-02, avg batch time: 0.4918, average train loss: 1.2161
[09/26 12:29:07 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 1.7607
[09/26 12:29:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.50	
[09/26 12:29:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 12:29:14 visual_prompt]: Epoch 16 / 100: avg data time: 6.52e-02, avg batch time: 0.5071, average train loss: 1.0264
[09/26 12:29:16 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1659, average loss: 1.4096
[09/26 12:29:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 12:29:16 visual_prompt]: Best epoch 16: best metric: 0.710
[09/26 12:29:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 12:29:23 visual_prompt]: Epoch 17 / 100: avg data time: 4.61e-02, avg batch time: 0.4878, average train loss: 1.0371
[09/26 12:29:24 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 2.8332
[09/26 12:29:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 59.00	
[09/26 12:29:24 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 12:29:31 visual_prompt]: Epoch 18 / 100: avg data time: 5.19e-02, avg batch time: 0.4949, average train loss: 1.6676
[09/26 12:29:33 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1658, average loss: 2.2000
[09/26 12:29:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.00	top5: 82.50	
[09/26 12:29:33 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 12:29:39 visual_prompt]: Epoch 19 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 1.9146
[09/26 12:29:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 1.6679
[09/26 12:29:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 56.00	top5: 88.00	
[09/26 12:29:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 12:29:48 visual_prompt]: Epoch 20 / 100: avg data time: 4.93e-02, avg batch time: 0.4932, average train loss: 1.0664
[09/26 12:29:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 1.9178
[09/26 12:29:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 86.50	
[09/26 12:29:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 12:29:56 visual_prompt]: Epoch 21 / 100: avg data time: 5.57e-02, avg batch time: 0.4970, average train loss: 2.6223
[09/26 12:29:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1659, average loss: 2.0257
[09/26 12:29:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 83.00	
[09/26 12:29:58 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 12:30:05 visual_prompt]: Epoch 22 / 100: avg data time: 5.31e-02, avg batch time: 0.4953, average train loss: 1.5307
[09/26 12:30:06 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1662, average loss: 1.8619
[09/26 12:30:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.50	top5: 88.00	
[09/26 12:30:06 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 12:30:13 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e-02, avg batch time: 0.4928, average train loss: 1.6315
[09/26 12:30:14 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1661, average loss: 2.0439
[09/26 12:30:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.00	top5: 77.00	
[09/26 12:30:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 12:30:21 visual_prompt]: Epoch 24 / 100: avg data time: 5.99e-02, avg batch time: 0.5011, average train loss: 3.3440
[09/26 12:30:23 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1658, average loss: 3.4578
[09/26 12:30:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.50	top5: 29.00	
[09/26 12:30:23 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 12:30:30 visual_prompt]: Epoch 25 / 100: avg data time: 5.92e-02, avg batch time: 0.4999, average train loss: 3.0604
[09/26 12:30:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 2.9266
[09/26 12:30:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.50	top5: 59.50	
[09/26 12:30:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 12:30:38 visual_prompt]: Epoch 26 / 100: avg data time: 5.38e-02, avg batch time: 0.4944, average train loss: 2.9463
[09/26 12:30:40 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 2.7901
[09/26 12:30:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 60.00	
[09/26 12:30:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 12:30:47 visual_prompt]: Epoch 27 / 100: avg data time: 5.61e-02, avg batch time: 0.4985, average train loss: 3.4550
[09/26 12:30:48 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1659, average loss: 3.0999
[09/26 12:30:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 46.50	
[09/26 12:30:48 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 12:30:55 visual_prompt]: Epoch 28 / 100: avg data time: 5.96e-02, avg batch time: 0.5014, average train loss: 2.9510
[09/26 12:30:57 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 3.0542
[09/26 12:30:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 17.50	top5: 50.00	
[09/26 12:30:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 12:31:04 visual_prompt]: Epoch 29 / 100: avg data time: 6.58e-02, avg batch time: 0.5071, average train loss: 2.9769
[09/26 12:31:05 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1662, average loss: 2.8582
[09/26 12:31:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 19.50	top5: 53.50	
[09/26 12:31:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 12:31:12 visual_prompt]: Epoch 30 / 100: avg data time: 7.09e-02, avg batch time: 0.5114, average train loss: 2.3244
[09/26 12:31:14 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1658, average loss: 2.5214
[09/26 12:31:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.50	top5: 65.00	
[09/26 12:31:14 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 12:31:21 visual_prompt]: Epoch 31 / 100: avg data time: 5.71e-02, avg batch time: 0.4992, average train loss: 2.1601
[09/26 12:31:22 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 2.0095
[09/26 12:31:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.50	top5: 80.50	
[09/26 12:31:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 12:31:29 visual_prompt]: Epoch 32 / 100: avg data time: 4.96e-02, avg batch time: 0.4941, average train loss: 1.4601
[09/26 12:31:31 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.5510
[09/26 12:31:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.00	top5: 89.50	
[09/26 12:31:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 12:31:37 visual_prompt]: Epoch 33 / 100: avg data time: 5.95e-02, avg batch time: 0.5014, average train loss: 1.3859
[09/26 12:31:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 1.9785
[09/26 12:31:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 79.50	
[09/26 12:31:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 12:31:46 visual_prompt]: Epoch 34 / 100: avg data time: 6.62e-02, avg batch time: 0.5082, average train loss: 1.5050
[09/26 12:31:47 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 1.8825
[09/26 12:31:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.50	top5: 84.00	
[09/26 12:31:47 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 12:31:54 visual_prompt]: Epoch 35 / 100: avg data time: 5.80e-02, avg batch time: 0.5001, average train loss: 1.7254
[09/26 12:31:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1667, average loss: 1.4571
[09/26 12:31:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 89.50	
[09/26 12:31:56 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 12:32:03 visual_prompt]: Epoch 36 / 100: avg data time: 5.05e-02, avg batch time: 0.4947, average train loss: 1.0831
[09/26 12:32:04 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1670, average loss: 1.4444
[09/26 12:32:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 91.50	
[09/26 12:32:04 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 12:32:11 visual_prompt]: Epoch 37 / 100: avg data time: 5.27e-02, avg batch time: 0.4986, average train loss: 1.0646
[09/26 12:32:13 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1672, average loss: 1.3350
[09/26 12:32:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.50	
[09/26 12:32:13 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 12:32:20 visual_prompt]: Epoch 38 / 100: avg data time: 5.55e-02, avg batch time: 0.4995, average train loss: 0.8172
[09/26 12:32:21 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1676, average loss: 1.1554
[09/26 12:32:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 12:32:21 visual_prompt]: Best epoch 38: best metric: 0.745
[09/26 12:32:21 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 12:32:28 visual_prompt]: Epoch 39 / 100: avg data time: 4.93e-02, avg batch time: 0.4943, average train loss: 2.5906
[09/26 12:32:29 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1673, average loss: 3.0557
[09/26 12:32:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.00	top5: 45.50	
[09/26 12:32:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 12:32:36 visual_prompt]: Epoch 40 / 100: avg data time: 5.56e-02, avg batch time: 0.5018, average train loss: 2.3190
[09/26 12:32:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1678, average loss: 1.9876
[09/26 12:32:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 48.50	top5: 83.00	
[09/26 12:32:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 12:32:45 visual_prompt]: Epoch 41 / 100: avg data time: 6.19e-02, avg batch time: 0.5073, average train loss: 1.5059
[09/26 12:32:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1680, average loss: 1.9645
[09/26 12:32:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 86.50	
[09/26 12:32:47 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 12:32:53 visual_prompt]: Epoch 42 / 100: avg data time: 4.66e-02, avg batch time: 0.4924, average train loss: 1.3291
[09/26 12:32:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1680, average loss: 1.3246
[09/26 12:32:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 91.50	
[09/26 12:32:55 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 12:33:02 visual_prompt]: Epoch 43 / 100: avg data time: 6.03e-02, avg batch time: 0.5072, average train loss: 0.9930
[09/26 12:33:03 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1680, average loss: 1.4020
[09/26 12:33:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 93.50	
[09/26 12:33:03 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 12:33:10 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e-02, avg batch time: 0.4954, average train loss: 0.8724
[09/26 12:33:12 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1680, average loss: 1.2368
[09/26 12:33:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 12:33:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 12:33:19 visual_prompt]: Epoch 45 / 100: avg data time: 5.12e-02, avg batch time: 0.4975, average train loss: 1.2080
[09/26 12:33:20 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1679, average loss: 1.6695
[09/26 12:33:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 59.00	top5: 96.00	
[09/26 12:33:20 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 12:33:27 visual_prompt]: Epoch 46 / 100: avg data time: 5.16e-02, avg batch time: 0.5002, average train loss: 1.0234
[09/26 12:33:29 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1681, average loss: 1.0950
[09/26 12:33:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 12:33:29 visual_prompt]: Best epoch 46: best metric: 0.750
[09/26 12:33:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 12:33:36 visual_prompt]: Epoch 47 / 100: avg data time: 5.30e-02, avg batch time: 0.4995, average train loss: 0.9982
[09/26 12:33:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1680, average loss: 1.0155
[09/26 12:33:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:33:37 visual_prompt]: Best epoch 47: best metric: 0.780
[09/26 12:33:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 12:33:44 visual_prompt]: Epoch 48 / 100: avg data time: 4.67e-02, avg batch time: 0.4950, average train loss: 0.7603
[09/26 12:33:46 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1679, average loss: 0.9752
[09/26 12:33:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.00	
[09/26 12:33:46 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 12:33:53 visual_prompt]: Epoch 49 / 100: avg data time: 6.09e-02, avg batch time: 0.5077, average train loss: 0.6414
[09/26 12:33:54 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1680, average loss: 1.0403
[09/26 12:33:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 12:33:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 12:34:01 visual_prompt]: Epoch 50 / 100: avg data time: 5.16e-02, avg batch time: 0.5015, average train loss: 0.7055
[09/26 12:34:03 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1681, average loss: 1.1766
[09/26 12:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.00	
[09/26 12:34:03 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 12:34:09 visual_prompt]: Epoch 51 / 100: avg data time: 4.81e-02, avg batch time: 0.4953, average train loss: 0.7271
[09/26 12:34:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1678, average loss: 1.0942
[09/26 12:34:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 12:34:11 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 12:34:18 visual_prompt]: Epoch 52 / 100: avg data time: 4.98e-02, avg batch time: 0.4964, average train loss: 0.6923
[09/26 12:34:19 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1680, average loss: 1.1860
[09/26 12:34:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 12:34:19 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 12:34:26 visual_prompt]: Epoch 53 / 100: avg data time: 4.97e-02, avg batch time: 0.4962, average train loss: 0.7221
[09/26 12:34:28 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1679, average loss: 1.6019
[09/26 12:34:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 90.50	
[09/26 12:34:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 12:34:35 visual_prompt]: Epoch 54 / 100: avg data time: 4.87e-02, avg batch time: 0.4966, average train loss: 0.7516
[09/26 12:34:36 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1677, average loss: 0.9364
[09/26 12:34:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 12:34:36 visual_prompt]: Best epoch 54: best metric: 0.795
[09/26 12:34:36 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 12:34:43 visual_prompt]: Epoch 55 / 100: avg data time: 5.26e-02, avg batch time: 0.4994, average train loss: 0.5015
[09/26 12:34:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1679, average loss: 0.9787
[09/26 12:34:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:34:45 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 12:34:52 visual_prompt]: Epoch 56 / 100: avg data time: 4.83e-02, avg batch time: 0.4960, average train loss: 0.4527
[09/26 12:34:53 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1677, average loss: 0.9234
[09/26 12:34:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 12:34:53 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 12:35:00 visual_prompt]: Epoch 57 / 100: avg data time: 5.84e-02, avg batch time: 0.5052, average train loss: 0.4542
[09/26 12:35:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1677, average loss: 1.0101
[09/26 12:35:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 12:35:02 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 12:35:09 visual_prompt]: Epoch 58 / 100: avg data time: 7.05e-02, avg batch time: 0.5158, average train loss: 0.4201
[09/26 12:35:10 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1674, average loss: 0.9663
[09/26 12:35:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 12:35:10 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 12:35:17 visual_prompt]: Epoch 59 / 100: avg data time: 5.81e-02, avg batch time: 0.5036, average train loss: 0.4035
[09/26 12:35:19 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 0.8579
[09/26 12:35:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.00	
[09/26 12:35:19 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 12:35:26 visual_prompt]: Epoch 60 / 100: avg data time: 7.00e-02, avg batch time: 0.5140, average train loss: 0.4160
[09/26 12:35:28 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1673, average loss: 0.9635
[09/26 12:35:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:35:28 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 12:35:35 visual_prompt]: Epoch 61 / 100: avg data time: 6.15e-02, avg batch time: 0.5059, average train loss: 0.4155
[09/26 12:35:36 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1672, average loss: 0.9069
[09/26 12:35:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 12:35:36 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 12:35:43 visual_prompt]: Epoch 62 / 100: avg data time: 5.37e-02, avg batch time: 0.4979, average train loss: 0.3823
[09/26 12:35:45 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1674, average loss: 0.9662
[09/26 12:35:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 94.00	
[09/26 12:35:45 visual_prompt]: Best epoch 62: best metric: 0.815
[09/26 12:35:45 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 12:35:52 visual_prompt]: Epoch 63 / 100: avg data time: 6.24e-02, avg batch time: 0.5063, average train loss: 0.3681
[09/26 12:35:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1674, average loss: 0.8722
[09/26 12:35:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:35:53 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 12:36:00 visual_prompt]: Epoch 64 / 100: avg data time: 4.76e-02, avg batch time: 0.4928, average train loss: 0.3376
[09/26 12:36:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1674, average loss: 0.8582
[09/26 12:36:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 12:36:02 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 12:36:09 visual_prompt]: Epoch 65 / 100: avg data time: 6.53e-02, avg batch time: 0.5105, average train loss: 0.3914
[09/26 12:36:10 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1674, average loss: 0.9675
[09/26 12:36:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 12:36:10 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 12:36:17 visual_prompt]: Epoch 66 / 100: avg data time: 5.88e-02, avg batch time: 0.5028, average train loss: 0.4762
[09/26 12:36:19 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1672, average loss: 0.9926
[09/26 12:36:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 12:36:19 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 12:36:25 visual_prompt]: Epoch 67 / 100: avg data time: 5.39e-02, avg batch time: 0.4997, average train loss: 0.3388
[09/26 12:36:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1673, average loss: 0.8751
[09/26 12:36:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 12:36:27 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 12:36:34 visual_prompt]: Epoch 68 / 100: avg data time: 5.29e-02, avg batch time: 0.4970, average train loss: 0.4156
[09/26 12:36:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1673, average loss: 1.0612
[09/26 12:36:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.50	
[09/26 12:36:36 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 12:36:43 visual_prompt]: Epoch 69 / 100: avg data time: 6.46e-02, avg batch time: 0.5086, average train loss: 0.5254
[09/26 12:36:44 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1674, average loss: 0.9374
[09/26 12:36:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 12:36:44 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 12:36:51 visual_prompt]: Epoch 70 / 100: avg data time: 5.82e-02, avg batch time: 0.5019, average train loss: 0.3297
[09/26 12:36:53 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1672, average loss: 0.8457
[09/26 12:36:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 95.00	
[09/26 12:36:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 12:36:59 visual_prompt]: Epoch 71 / 100: avg data time: 4.82e-02, avg batch time: 0.4926, average train loss: 0.2877
[09/26 12:37:01 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1671, average loss: 0.8907
[09/26 12:37:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 95.00	
[09/26 12:37:01 visual_prompt]: Best epoch 71: best metric: 0.820
[09/26 12:37:01 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 12:37:08 visual_prompt]: Epoch 72 / 100: avg data time: 5.75e-02, avg batch time: 0.5011, average train loss: 0.2498
[09/26 12:37:09 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1670, average loss: 0.7430
[09/26 12:37:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.00	
[09/26 12:37:09 visual_prompt]: Best epoch 72: best metric: 0.825
[09/26 12:37:09 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 12:37:16 visual_prompt]: Epoch 73 / 100: avg data time: 5.83e-02, avg batch time: 0.5033, average train loss: 0.4258
[09/26 12:37:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1669, average loss: 0.8450
[09/26 12:37:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 97.00	
[09/26 12:37:18 visual_prompt]: Best epoch 73: best metric: 0.835
[09/26 12:37:18 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 12:37:25 visual_prompt]: Epoch 74 / 100: avg data time: 5.02e-02, avg batch time: 0.4933, average train loss: 0.3137
[09/26 12:37:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1672, average loss: 0.9811
[09/26 12:37:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 93.50	
[09/26 12:37:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 12:37:33 visual_prompt]: Epoch 75 / 100: avg data time: 5.59e-02, avg batch time: 0.4999, average train loss: 0.2419
[09/26 12:37:35 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1669, average loss: 0.7766
[09/26 12:37:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 12:37:35 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 12:37:42 visual_prompt]: Epoch 76 / 100: avg data time: 6.44e-02, avg batch time: 0.5092, average train loss: 0.2185
[09/26 12:37:43 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1671, average loss: 0.6766
[09/26 12:37:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 97.50	
[09/26 12:37:43 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 12:37:50 visual_prompt]: Epoch 77 / 100: avg data time: 5.02e-02, avg batch time: 0.4968, average train loss: 0.1831
[09/26 12:37:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1670, average loss: 0.6405
[09/26 12:37:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 12:37:52 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 12:37:59 visual_prompt]: Epoch 78 / 100: avg data time: 5.16e-02, avg batch time: 0.4959, average train loss: 0.1582
[09/26 12:38:00 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 0.6767
[09/26 12:38:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 85.50	top5: 96.00	
[09/26 12:38:00 visual_prompt]: Best epoch 78: best metric: 0.855
[09/26 12:38:00 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 12:38:07 visual_prompt]: Epoch 79 / 100: avg data time: 6.48e-02, avg batch time: 0.5069, average train loss: 0.1501
[09/26 12:38:09 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 0.6963
[09/26 12:38:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:38:09 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 12:38:16 visual_prompt]: Epoch 80 / 100: avg data time: 6.40e-02, avg batch time: 0.5063, average train loss: 0.1349
[09/26 12:38:17 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1673, average loss: 0.7651
[09/26 12:38:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 95.50	
[09/26 12:38:17 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 12:38:24 visual_prompt]: Epoch 81 / 100: avg data time: 6.64e-02, avg batch time: 0.5101, average train loss: 0.4658
[09/26 12:38:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.3165
[09/26 12:38:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 12:38:26 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 12:38:33 visual_prompt]: Epoch 82 / 100: avg data time: 6.24e-02, avg batch time: 0.5051, average train loss: 0.4259
[09/26 12:38:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1669, average loss: 0.8733
[09/26 12:38:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.50	
[09/26 12:38:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 12:38:41 visual_prompt]: Epoch 83 / 100: avg data time: 5.63e-02, avg batch time: 0.5012, average train loss: 0.2697
[09/26 12:38:43 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1669, average loss: 0.7830
[09/26 12:38:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 12:38:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 12:38:50 visual_prompt]: Epoch 84 / 100: avg data time: 6.54e-02, avg batch time: 0.5078, average train loss: 0.1838
[09/26 12:38:52 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1667, average loss: 0.7668
[09/26 12:38:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 12:38:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 12:38:58 visual_prompt]: Epoch 85 / 100: avg data time: 6.00e-02, avg batch time: 0.5044, average train loss: 0.1638
[09/26 12:39:00 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1667, average loss: 0.8181
[09/26 12:39:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 12:39:00 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 12:39:07 visual_prompt]: Epoch 86 / 100: avg data time: 5.37e-02, avg batch time: 0.4994, average train loss: 0.1373
[09/26 12:39:09 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1667, average loss: 0.7317
[09/26 12:39:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.00	
[09/26 12:39:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 12:39:16 visual_prompt]: Epoch 87 / 100: avg data time: 6.46e-02, avg batch time: 0.5077, average train loss: 0.1151
[09/26 12:39:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 0.6937
[09/26 12:39:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 95.50	
[09/26 12:39:17 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 12:39:24 visual_prompt]: Epoch 88 / 100: avg data time: 6.01e-02, avg batch time: 0.5029, average train loss: 0.1060
[09/26 12:39:26 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 0.6755
[09/26 12:39:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 86.00	top5: 96.00	
[09/26 12:39:26 visual_prompt]: Best epoch 88: best metric: 0.860
[09/26 12:39:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 12:39:33 visual_prompt]: Epoch 89 / 100: avg data time: 5.12e-02, avg batch time: 0.4944, average train loss: 0.1044
[09/26 12:39:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 0.7343
[09/26 12:39:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 96.00	
[09/26 12:39:34 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 12:39:41 visual_prompt]: Epoch 90 / 100: avg data time: 5.69e-02, avg batch time: 0.4992, average train loss: 0.1026
[09/26 12:39:43 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 0.7113
[09/26 12:39:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 96.50	
[09/26 12:39:43 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 12:39:50 visual_prompt]: Epoch 91 / 100: avg data time: 5.06e-02, avg batch time: 0.4942, average train loss: 0.0983
[09/26 12:39:51 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1667, average loss: 0.7084
[09/26 12:39:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 97.00	
[09/26 12:39:51 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 12:39:58 visual_prompt]: Epoch 92 / 100: avg data time: 5.17e-02, avg batch time: 0.4948, average train loss: 0.0972
[09/26 12:40:00 visual_prompt]: Inference (val):avg data time: 4.30e-05, avg batch time: 0.1670, average loss: 0.7149
[09/26 12:40:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 96.50	
[09/26 12:40:00 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 12:40:06 visual_prompt]: Epoch 93 / 100: avg data time: 5.15e-02, avg batch time: 0.4934, average train loss: 0.0965
[09/26 12:40:08 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 0.7199
[09/26 12:40:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.00	top5: 97.00	
[09/26 12:40:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 12:40:15 visual_prompt]: Epoch 94 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 0.0962
[09/26 12:40:16 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1668, average loss: 0.7079
[09/26 12:40:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:16 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 12:40:23 visual_prompt]: Epoch 95 / 100: avg data time: 5.05e-02, avg batch time: 0.4929, average train loss: 0.0960
[09/26 12:40:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 0.7020
[09/26 12:40:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:25 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 12:40:32 visual_prompt]: Epoch 96 / 100: avg data time: 6.15e-02, avg batch time: 0.5035, average train loss: 0.0959
[09/26 12:40:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.7089
[09/26 12:40:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:33 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 12:40:40 visual_prompt]: Epoch 97 / 100: avg data time: 4.87e-02, avg batch time: 0.4926, average train loss: 0.0958
[09/26 12:40:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.7093
[09/26 12:40:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:42 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 12:40:49 visual_prompt]: Epoch 98 / 100: avg data time: 5.69e-02, avg batch time: 0.4994, average train loss: 0.0959
[09/26 12:40:50 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 0.7091
[09/26 12:40:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:50 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 12:40:57 visual_prompt]: Epoch 99 / 100: avg data time: 5.11e-02, avg batch time: 0.4940, average train loss: 0.0955
[09/26 12:40:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 0.7089
[09/26 12:40:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:40:59 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 12:41:05 visual_prompt]: Epoch 100 / 100: avg data time: 4.70e-02, avg batch time: 0.4919, average train loss: 0.0952
[09/26 12:41:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1666, average loss: 0.7086
[09/26 12:41:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 96.50	
[09/26 12:41:07 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:41:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:41:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:41:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:41:07 visual_prompt]: Training with config:
[09/26 12:41:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:41:07 visual_prompt]: Loading training data...
[09/26 12:41:07 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:41:08 visual_prompt]: Number of images: 800
[09/26 12:41:08 visual_prompt]: Number of classes: 45 / 45
[09/26 12:41:08 visual_prompt]: Loading validation data...
[09/26 12:41:08 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:41:08 visual_prompt]: Number of images: 200
[09/26 12:41:08 visual_prompt]: Number of classes: 45 / 45
[09/26 12:41:08 visual_prompt]: Constructing models...
[09/26 12:41:11 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 12:41:11 visual_prompt]: tuned percent:0.574
[09/26 12:41:11 visual_prompt]: Device used for model: 0
[09/26 12:41:11 visual_prompt]: Setting up Evaluator...
[09/26 12:41:11 visual_prompt]: Setting up Trainer...
[09/26 12:41:11 visual_prompt]: 	Setting up the optimizer...
[09/26 12:41:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:41:18 visual_prompt]: Epoch 1 / 100: avg data time: 5.06e-02, avg batch time: 0.4956, average train loss: 3.8868
[09/26 12:41:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 3.9529
[09/26 12:41:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 12:41:19 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 12:41:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 12:41:26 visual_prompt]: Epoch 2 / 100: avg data time: 4.91e-02, avg batch time: 0.4915, average train loss: 3.8164
[09/26 12:41:28 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1660, average loss: 3.7612
[09/26 12:41:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 19.50	
[09/26 12:41:28 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 12:41:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 12:41:34 visual_prompt]: Epoch 3 / 100: avg data time: 5.74e-02, avg batch time: 0.4993, average train loss: 3.6505
[09/26 12:41:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 3.4308
[09/26 12:41:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.00	top5: 38.00	
[09/26 12:41:36 visual_prompt]: Best epoch 3: best metric: 0.140
[09/26 12:41:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 12:41:43 visual_prompt]: Epoch 4 / 100: avg data time: 5.94e-02, avg batch time: 0.5015, average train loss: 3.2803
[09/26 12:41:45 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1666, average loss: 3.4425
[09/26 12:41:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 29.50	
[09/26 12:41:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 12:41:51 visual_prompt]: Epoch 5 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 3.1668
[09/26 12:41:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 2.9700
[09/26 12:41:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 14.50	top5: 50.00	
[09/26 12:41:53 visual_prompt]: Best epoch 5: best metric: 0.145
[09/26 12:41:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 12:42:00 visual_prompt]: Epoch 6 / 100: avg data time: 5.54e-02, avg batch time: 0.4980, average train loss: 2.5485
[09/26 12:42:01 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1667, average loss: 2.3092
[09/26 12:42:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 33.00	top5: 68.00	
[09/26 12:42:01 visual_prompt]: Best epoch 6: best metric: 0.330
[09/26 12:42:01 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 12:42:08 visual_prompt]: Epoch 7 / 100: avg data time: 6.13e-02, avg batch time: 0.5029, average train loss: 2.0864
[09/26 12:42:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 1.9223
[09/26 12:42:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.50	top5: 77.50	
[09/26 12:42:10 visual_prompt]: Best epoch 7: best metric: 0.435
[09/26 12:42:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 12:42:17 visual_prompt]: Epoch 8 / 100: avg data time: 5.47e-02, avg batch time: 0.4983, average train loss: 1.6151
[09/26 12:42:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1667, average loss: 1.7352
[09/26 12:42:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.00	top5: 77.50	
[09/26 12:42:18 visual_prompt]: Best epoch 8: best metric: 0.530
[09/26 12:42:18 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 12:42:25 visual_prompt]: Epoch 9 / 100: avg data time: 4.54e-02, avg batch time: 0.4916, average train loss: 1.1233
[09/26 12:42:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1665, average loss: 1.4563
[09/26 12:42:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.50	top5: 88.00	
[09/26 12:42:27 visual_prompt]: Best epoch 9: best metric: 0.575
[09/26 12:42:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 12:42:34 visual_prompt]: Epoch 10 / 100: avg data time: 5.41e-02, avg batch time: 0.4962, average train loss: 0.7607
[09/26 12:42:35 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1667, average loss: 1.0740
[09/26 12:42:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 92.00	
[09/26 12:42:35 visual_prompt]: Best epoch 10: best metric: 0.720
[09/26 12:42:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 12:42:42 visual_prompt]: Epoch 11 / 100: avg data time: 5.41e-02, avg batch time: 0.4980, average train loss: 0.4897
[09/26 12:42:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1666, average loss: 0.9646
[09/26 12:42:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.50	
[09/26 12:42:44 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 12:42:50 visual_prompt]: Epoch 12 / 100: avg data time: 5.46e-02, avg batch time: 0.4963, average train loss: 0.2549
[09/26 12:42:52 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 0.9508
[09/26 12:42:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 95.00	
[09/26 12:42:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 12:42:59 visual_prompt]: Epoch 13 / 100: avg data time: 5.17e-02, avg batch time: 0.4955, average train loss: 0.1783
[09/26 12:43:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1669, average loss: 0.8739
[09/26 12:43:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.50	
[09/26 12:43:00 visual_prompt]: Best epoch 13: best metric: 0.730
[09/26 12:43:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 12:43:07 visual_prompt]: Epoch 14 / 100: avg data time: 5.11e-02, avg batch time: 0.4939, average train loss: 0.1243
[09/26 12:43:09 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1668, average loss: 0.9412
[09/26 12:43:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 12:43:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 12:43:16 visual_prompt]: Epoch 15 / 100: avg data time: 5.29e-02, avg batch time: 0.4954, average train loss: 0.0771
[09/26 12:43:17 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.8249
[09/26 12:43:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 12:43:17 visual_prompt]: Best epoch 15: best metric: 0.740
[09/26 12:43:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 12:43:24 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e-02, avg batch time: 0.4938, average train loss: 0.0529
[09/26 12:43:26 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1666, average loss: 0.7567
[09/26 12:43:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 12:43:26 visual_prompt]: Best epoch 16: best metric: 0.770
[09/26 12:43:26 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 12:43:32 visual_prompt]: Epoch 17 / 100: avg data time: 4.96e-02, avg batch time: 0.4949, average train loss: 0.0404
[09/26 12:43:34 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 0.7803
[09/26 12:43:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 12:43:34 visual_prompt]: Best epoch 17: best metric: 0.775
[09/26 12:43:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 12:43:41 visual_prompt]: Epoch 18 / 100: avg data time: 6.07e-02, avg batch time: 0.5026, average train loss: 0.0364
[09/26 12:43:42 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1665, average loss: 0.7070
[09/26 12:43:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 12:43:42 visual_prompt]: Best epoch 18: best metric: 0.790
[09/26 12:43:42 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 12:43:49 visual_prompt]: Epoch 19 / 100: avg data time: 5.26e-02, avg batch time: 0.4959, average train loss: 0.0293
[09/26 12:43:51 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1666, average loss: 0.7433
[09/26 12:43:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 12:43:51 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 12:43:58 visual_prompt]: Epoch 20 / 100: avg data time: 5.28e-02, avg batch time: 0.4967, average train loss: 0.0284
[09/26 12:43:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 0.7688
[09/26 12:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 12:43:59 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 12:44:06 visual_prompt]: Epoch 21 / 100: avg data time: 5.65e-02, avg batch time: 0.5001, average train loss: 0.0295
[09/26 12:44:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1665, average loss: 0.6935
[09/26 12:44:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 12:44:08 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 12:44:14 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e-02, avg batch time: 0.4930, average train loss: 0.0273
[09/26 12:44:16 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1665, average loss: 0.7560
[09/26 12:44:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.00	
[09/26 12:44:16 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 12:44:23 visual_prompt]: Epoch 23 / 100: avg data time: 5.14e-02, avg batch time: 0.4958, average train loss: 0.0252
[09/26 12:44:24 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1669, average loss: 0.7084
[09/26 12:44:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 12:44:24 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 12:44:31 visual_prompt]: Epoch 24 / 100: avg data time: 5.11e-02, avg batch time: 0.4948, average train loss: 0.0252
[09/26 12:44:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1667, average loss: 0.7644
[09/26 12:44:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 12:44:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 12:44:39 visual_prompt]: Epoch 25 / 100: avg data time: 5.48e-02, avg batch time: 0.4989, average train loss: 0.0252
[09/26 12:44:41 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1668, average loss: 0.7810
[09/26 12:44:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 12:44:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 12:44:48 visual_prompt]: Epoch 26 / 100: avg data time: 5.82e-02, avg batch time: 0.5009, average train loss: 0.0321
[09/26 12:44:49 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1671, average loss: 0.7582
[09/26 12:44:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 12:44:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 12:44:56 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e-02, avg batch time: 0.4949, average train loss: 0.1081
[09/26 12:44:58 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.1471
[09/26 12:44:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 92.50	
[09/26 12:44:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 12:45:05 visual_prompt]: Epoch 28 / 100: avg data time: 5.13e-02, avg batch time: 0.4959, average train loss: 0.4316
[09/26 12:45:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 1.1487
[09/26 12:45:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.50	
[09/26 12:45:06 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 12:45:13 visual_prompt]: Epoch 29 / 100: avg data time: 6.08e-02, avg batch time: 0.5022, average train loss: 0.3423
[09/26 12:45:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1667, average loss: 0.8919
[09/26 12:45:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 12:45:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 12:45:21 visual_prompt]: Epoch 30 / 100: avg data time: 5.36e-02, avg batch time: 0.4970, average train loss: 0.1767
[09/26 12:45:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1666, average loss: 0.8287
[09/26 12:45:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 12:45:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 12:45:30 visual_prompt]: Epoch 31 / 100: avg data time: 5.98e-02, avg batch time: 0.5016, average train loss: 0.0882
[09/26 12:45:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 0.7276
[09/26 12:45:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 12:45:32 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 12:45:38 visual_prompt]: Epoch 32 / 100: avg data time: 5.17e-02, avg batch time: 0.4947, average train loss: 0.0556
[09/26 12:45:40 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1666, average loss: 0.7487
[09/26 12:45:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 12:45:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 12:45:47 visual_prompt]: Epoch 33 / 100: avg data time: 5.08e-02, avg batch time: 0.4934, average train loss: 0.0479
[09/26 12:45:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 0.7575
[09/26 12:45:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 12:45:48 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 12:45:55 visual_prompt]: Epoch 34 / 100: avg data time: 5.01e-02, avg batch time: 0.4936, average train loss: 0.0327
[09/26 12:45:57 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1668, average loss: 0.6858
[09/26 12:45:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:45:57 visual_prompt]: Best epoch 34: best metric: 0.800
[09/26 12:45:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 12:46:04 visual_prompt]: Epoch 35 / 100: avg data time: 5.06e-02, avg batch time: 0.4943, average train loss: 0.0251
[09/26 12:46:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 0.6206
[09/26 12:46:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 12:46:05 visual_prompt]: Best epoch 35: best metric: 0.820
[09/26 12:46:05 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 12:46:12 visual_prompt]: Epoch 36 / 100: avg data time: 5.80e-02, avg batch time: 0.5020, average train loss: 0.0193
[09/26 12:46:14 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 0.6398
[09/26 12:46:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 12:46:14 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 12:46:20 visual_prompt]: Epoch 37 / 100: avg data time: 6.05e-02, avg batch time: 0.5024, average train loss: 0.0174
[09/26 12:46:22 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 0.6201
[09/26 12:46:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 12:46:22 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 12:46:29 visual_prompt]: Epoch 38 / 100: avg data time: 5.65e-02, avg batch time: 0.4983, average train loss: 0.0173
[09/26 12:46:30 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 0.6202
[09/26 12:46:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 97.50	
[09/26 12:46:30 visual_prompt]: Best epoch 38: best metric: 0.825
[09/26 12:46:30 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 12:46:37 visual_prompt]: Epoch 39 / 100: avg data time: 5.92e-02, avg batch time: 0.5017, average train loss: 0.0173
[09/26 12:46:39 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1662, average loss: 0.6133
[09/26 12:46:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.50	top5: 98.00	
[09/26 12:46:39 visual_prompt]: Best epoch 39: best metric: 0.835
[09/26 12:46:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 12:46:46 visual_prompt]: Epoch 40 / 100: avg data time: 5.01e-02, avg batch time: 0.4942, average train loss: 0.0173
[09/26 12:46:47 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 0.6330
[09/26 12:46:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 12:46:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 12:46:54 visual_prompt]: Epoch 41 / 100: avg data time: 5.25e-02, avg batch time: 0.4956, average train loss: 0.0168
[09/26 12:46:56 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 0.6093
[09/26 12:46:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 12:46:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 12:47:03 visual_prompt]: Epoch 42 / 100: avg data time: 6.70e-02, avg batch time: 0.5099, average train loss: 0.0166
[09/26 12:47:04 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1662, average loss: 0.6217
[09/26 12:47:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 12:47:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 12:47:11 visual_prompt]: Epoch 43 / 100: avg data time: 6.50e-02, avg batch time: 0.5063, average train loss: 0.0162
[09/26 12:47:13 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1666, average loss: 0.6004
[09/26 12:47:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.50	top5: 98.00	
[09/26 12:47:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 12:47:20 visual_prompt]: Epoch 44 / 100: avg data time: 6.24e-02, avg batch time: 0.5051, average train loss: 0.0162
[09/26 12:47:21 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.5952
[09/26 12:47:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.00	
[09/26 12:47:21 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 12:47:28 visual_prompt]: Epoch 45 / 100: avg data time: 4.87e-02, avg batch time: 0.4918, average train loss: 0.0249
[09/26 12:47:30 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.6733
[09/26 12:47:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 12:47:30 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 12:47:36 visual_prompt]: Epoch 46 / 100: avg data time: 4.38e-02, avg batch time: 0.4869, average train loss: 0.0565
[09/26 12:47:38 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 0.8537
[09/26 12:47:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 12:47:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 12:47:45 visual_prompt]: Epoch 47 / 100: avg data time: 4.87e-02, avg batch time: 0.4923, average train loss: 0.3168
[09/26 12:47:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.1285
[09/26 12:47:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 12:47:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 12:47:53 visual_prompt]: Epoch 48 / 100: avg data time: 5.00e-02, avg batch time: 0.4951, average train loss: 0.3150
[09/26 12:47:55 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.0223
[09/26 12:47:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 12:47:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 12:48:02 visual_prompt]: Epoch 49 / 100: avg data time: 4.80e-02, avg batch time: 0.4900, average train loss: 0.1909
[09/26 12:48:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 0.8113
[09/26 12:48:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 12:48:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 12:48:10 visual_prompt]: Epoch 50 / 100: avg data time: 5.55e-02, avg batch time: 0.4984, average train loss: 0.0944
[09/26 12:48:11 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 0.7041
[09/26 12:48:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 12:48:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 12:48:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.17e-02, avg batch time: 0.4934, average train loss: 0.0609
[09/26 12:48:20 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 0.7819
[09/26 12:48:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 97.50	
[09/26 12:48:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 12:48:27 visual_prompt]: Epoch 52 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 0.0386
[09/26 12:48:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 0.6660
[09/26 12:48:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 12:48:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 12:48:35 visual_prompt]: Epoch 53 / 100: avg data time: 5.16e-02, avg batch time: 0.4949, average train loss: 0.0232
[09/26 12:48:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 0.6995
[09/26 12:48:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 12:48:37 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 12:48:43 visual_prompt]: Epoch 54 / 100: avg data time: 5.19e-02, avg batch time: 0.4952, average train loss: 0.0171
[09/26 12:48:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 0.7012
[09/26 12:48:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 12:48:45 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 12:48:52 visual_prompt]: Epoch 55 / 100: avg data time: 4.65e-02, avg batch time: 0.4903, average train loss: 0.0157
[09/26 12:48:53 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 0.6695
[09/26 12:48:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 12:48:53 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 12:49:00 visual_prompt]: Epoch 56 / 100: avg data time: 6.05e-02, avg batch time: 0.5026, average train loss: 0.0146
[09/26 12:49:02 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 0.6762
[09/26 12:49:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:49:02 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 12:49:08 visual_prompt]: Epoch 57 / 100: avg data time: 5.06e-02, avg batch time: 0.4954, average train loss: 0.0139
[09/26 12:49:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 0.6706
[09/26 12:49:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:49:10 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 12:49:17 visual_prompt]: Epoch 58 / 100: avg data time: 4.93e-02, avg batch time: 0.4915, average train loss: 0.0138
[09/26 12:49:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 0.6674
[09/26 12:49:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 12:49:18 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 12:49:25 visual_prompt]: Epoch 59 / 100: avg data time: 5.51e-02, avg batch time: 0.4968, average train loss: 0.0136
[09/26 12:49:27 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 0.6936
[09/26 12:49:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 12:49:27 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 12:49:33 visual_prompt]: Epoch 60 / 100: avg data time: 5.57e-02, avg batch time: 0.4986, average train loss: 0.0139
[09/26 12:49:35 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.6674
[09/26 12:49:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 12:49:35 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 12:49:42 visual_prompt]: Epoch 61 / 100: avg data time: 6.07e-02, avg batch time: 0.5023, average train loss: 0.0139
[09/26 12:49:43 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 0.6693
[09/26 12:49:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 12:49:43 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 12:49:50 visual_prompt]: Epoch 62 / 100: avg data time: 4.99e-02, avg batch time: 0.4916, average train loss: 0.0141
[09/26 12:49:52 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 0.6644
[09/26 12:49:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:49:52 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 12:49:58 visual_prompt]: Epoch 63 / 100: avg data time: 5.00e-02, avg batch time: 0.4931, average train loss: 0.0139
[09/26 12:50:00 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1665, average loss: 0.6660
[09/26 12:50:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:50:00 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 12:50:07 visual_prompt]: Epoch 64 / 100: avg data time: 4.85e-02, avg batch time: 0.4906, average train loss: 0.0139
[09/26 12:50:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 0.6707
[09/26 12:50:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 12:50:08 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 12:50:15 visual_prompt]: Epoch 65 / 100: avg data time: 6.18e-02, avg batch time: 0.5043, average train loss: 0.0139
[09/26 12:50:17 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 0.6802
[09/26 12:50:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 98.00	
[09/26 12:50:17 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 12:50:23 visual_prompt]: Epoch 66 / 100: avg data time: 4.95e-02, avg batch time: 0.4924, average train loss: 0.0140
[09/26 12:50:25 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 0.6774
[09/26 12:50:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.50	
[09/26 12:50:25 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 12:50:32 visual_prompt]: Epoch 67 / 100: avg data time: 5.04e-02, avg batch time: 0.4920, average train loss: 0.0140
[09/26 12:50:33 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 0.6667
[09/26 12:50:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 12:50:33 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 12:50:40 visual_prompt]: Epoch 68 / 100: avg data time: 5.15e-02, avg batch time: 0.4963, average train loss: 0.0140
[09/26 12:50:42 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.6813
[09/26 12:50:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:50:42 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 12:50:49 visual_prompt]: Epoch 69 / 100: avg data time: 5.83e-02, avg batch time: 0.5000, average train loss: 0.0138
[09/26 12:50:50 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.6875
[09/26 12:50:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.50	
[09/26 12:50:50 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 12:50:57 visual_prompt]: Epoch 70 / 100: avg data time: 4.81e-02, avg batch time: 0.4916, average train loss: 0.0138
[09/26 12:50:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.6831
[09/26 12:50:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 12:50:59 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 12:51:05 visual_prompt]: Epoch 71 / 100: avg data time: 4.94e-02, avg batch time: 0.4918, average train loss: 0.0137
[09/26 12:51:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 0.7037
[09/26 12:51:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:51:07 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 12:51:14 visual_prompt]: Epoch 72 / 100: avg data time: 5.88e-02, avg batch time: 0.5018, average train loss: 0.0139
[09/26 12:51:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1663, average loss: 0.6886
[09/26 12:51:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 12:51:15 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 12:51:22 visual_prompt]: Epoch 73 / 100: avg data time: 4.89e-02, avg batch time: 0.4918, average train loss: 0.0136
[09/26 12:51:24 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1665, average loss: 0.6831
[09/26 12:51:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 12:51:24 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 12:51:30 visual_prompt]: Epoch 74 / 100: avg data time: 5.02e-02, avg batch time: 0.4946, average train loss: 0.0136
[09/26 12:51:32 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 0.6763
[09/26 12:51:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 12:51:32 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 12:51:39 visual_prompt]: Epoch 75 / 100: avg data time: 6.13e-02, avg batch time: 0.5037, average train loss: 0.0134
[09/26 12:51:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.6807
[09/26 12:51:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 12:51:41 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 12:51:47 visual_prompt]: Epoch 76 / 100: avg data time: 5.56e-02, avg batch time: 0.4982, average train loss: 0.0134
[09/26 12:51:49 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1667, average loss: 0.6886
[09/26 12:51:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 12:51:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 12:51:56 visual_prompt]: Epoch 77 / 100: avg data time: 6.25e-02, avg batch time: 0.5055, average train loss: 0.0133
[09/26 12:51:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.6866
[09/26 12:51:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.50	
[09/26 12:51:57 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 12:52:04 visual_prompt]: Epoch 78 / 100: avg data time: 5.99e-02, avg batch time: 0.5027, average train loss: 0.0134
[09/26 12:52:06 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1665, average loss: 0.6949
[09/26 12:52:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 12:52:06 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 12:52:13 visual_prompt]: Epoch 79 / 100: avg data time: 5.49e-02, avg batch time: 0.4969, average train loss: 0.0131
[09/26 12:52:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 0.6889
[09/26 12:52:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 12:52:14 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 12:52:21 visual_prompt]: Epoch 80 / 100: avg data time: 5.08e-02, avg batch time: 0.4955, average train loss: 0.0132
[09/26 12:52:23 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1666, average loss: 0.7016
[09/26 12:52:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.00	
[09/26 12:52:23 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 12:52:29 visual_prompt]: Epoch 81 / 100: avg data time: 4.86e-02, avg batch time: 0.4926, average train loss: 0.0133
[09/26 12:52:31 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 0.7010
[09/26 12:52:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 12:52:31 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 12:52:38 visual_prompt]: Epoch 82 / 100: avg data time: 6.28e-02, avg batch time: 0.5040, average train loss: 0.0132
[09/26 12:52:39 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1667, average loss: 0.6902
[09/26 12:52:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 12:52:39 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 12:52:46 visual_prompt]: Epoch 83 / 100: avg data time: 6.51e-02, avg batch time: 0.5082, average train loss: 0.0132
[09/26 12:52:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1666, average loss: 0.6859
[09/26 12:52:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 12:52:48 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 12:52:55 visual_prompt]: Epoch 84 / 100: avg data time: 6.26e-02, avg batch time: 0.5043, average train loss: 0.0133
[09/26 12:52:56 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 0.6946
[09/26 12:52:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:52:56 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 12:53:03 visual_prompt]: Epoch 85 / 100: avg data time: 6.05e-02, avg batch time: 0.5030, average train loss: 0.0131
[09/26 12:53:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1667, average loss: 0.6954
[09/26 12:53:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 12:53:05 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 12:53:12 visual_prompt]: Epoch 86 / 100: avg data time: 5.86e-02, avg batch time: 0.5001, average train loss: 0.0131
[09/26 12:53:13 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 0.7056
[09/26 12:53:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 12:53:13 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 12:53:20 visual_prompt]: Epoch 87 / 100: avg data time: 5.54e-02, avg batch time: 0.4971, average train loss: 0.0131
[09/26 12:53:22 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1665, average loss: 0.7026
[09/26 12:53:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 12:53:22 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 12:53:28 visual_prompt]: Epoch 88 / 100: avg data time: 5.27e-02, avg batch time: 0.4976, average train loss: 0.0130
[09/26 12:53:30 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1667, average loss: 0.7045
[09/26 12:53:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 12:53:30 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 12:53:37 visual_prompt]: Epoch 89 / 100: avg data time: 5.42e-02, avg batch time: 0.4967, average train loss: 0.0130
[09/26 12:53:38 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1669, average loss: 0.6992
[09/26 12:53:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 12:53:38 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 12:53:45 visual_prompt]: Epoch 90 / 100: avg data time: 5.78e-02, avg batch time: 0.5025, average train loss: 0.0130
[09/26 12:53:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1666, average loss: 0.6958
[09/26 12:53:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 12:53:47 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 12:53:54 visual_prompt]: Epoch 91 / 100: avg data time: 5.09e-02, avg batch time: 0.4937, average train loss: 0.0130
[09/26 12:53:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 0.6967
[09/26 12:53:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 12:53:55 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 12:54:02 visual_prompt]: Epoch 92 / 100: avg data time: 6.10e-02, avg batch time: 0.5034, average train loss: 0.0129
[09/26 12:54:04 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1667, average loss: 0.6974
[09/26 12:54:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:54:04 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 12:54:10 visual_prompt]: Epoch 93 / 100: avg data time: 4.77e-02, avg batch time: 0.4926, average train loss: 0.0130
[09/26 12:54:12 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1665, average loss: 0.6965
[09/26 12:54:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:54:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 12:54:19 visual_prompt]: Epoch 94 / 100: avg data time: 5.73e-02, avg batch time: 0.4989, average train loss: 0.0129
[09/26 12:54:20 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1669, average loss: 0.6958
[09/26 12:54:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.00	
[09/26 12:54:20 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 12:54:27 visual_prompt]: Epoch 95 / 100: avg data time: 5.65e-02, avg batch time: 0.5005, average train loss: 0.0128
[09/26 12:54:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 0.6968
[09/26 12:54:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:54:29 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 12:54:36 visual_prompt]: Epoch 96 / 100: avg data time: 6.68e-02, avg batch time: 0.5084, average train loss: 0.0129
[09/26 12:54:37 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1664, average loss: 0.6980
[09/26 12:54:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 12:54:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 12:54:44 visual_prompt]: Epoch 97 / 100: avg data time: 5.05e-02, avg batch time: 0.4964, average train loss: 0.0128
[09/26 12:54:46 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1666, average loss: 0.6982
[09/26 12:54:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 12:54:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 12:54:53 visual_prompt]: Epoch 98 / 100: avg data time: 5.80e-02, avg batch time: 0.5010, average train loss: 0.0130
[09/26 12:54:54 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1667, average loss: 0.6979
[09/26 12:54:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:54:54 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 12:55:01 visual_prompt]: Epoch 99 / 100: avg data time: 4.90e-02, avg batch time: 0.4939, average train loss: 0.0130
[09/26 12:55:03 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1668, average loss: 0.6979
[09/26 12:55:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:55:03 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 12:55:09 visual_prompt]: Epoch 100 / 100: avg data time: 5.23e-02, avg batch time: 0.4969, average train loss: 0.0129
[09/26 12:55:11 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 0.6979
[09/26 12:55:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 12:55:11 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 12:55:11 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 12:55:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 12:55:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 12:55:11 visual_prompt]: Training with config:
[09/26 12:55:11 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 12:55:11 visual_prompt]: Loading training data...
[09/26 12:55:11 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:55:12 visual_prompt]: Number of images: 800
[09/26 12:55:12 visual_prompt]: Number of classes: 45 / 45
[09/26 12:55:13 visual_prompt]: Loading validation data...
[09/26 12:55:13 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 12:55:13 visual_prompt]: Number of images: 200
[09/26 12:55:13 visual_prompt]: Number of classes: 45 / 45
[09/26 12:55:13 visual_prompt]: Constructing models...
[09/26 12:55:15 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 12:55:15 visual_prompt]: tuned percent:0.574
[09/26 12:55:15 visual_prompt]: Device used for model: 0
[09/26 12:55:15 visual_prompt]: Setting up Evaluator...
[09/26 12:55:15 visual_prompt]: Setting up Trainer...
[09/26 12:55:15 visual_prompt]: 	Setting up the optimizer...
[09/26 12:55:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 12:55:22 visual_prompt]: Epoch 1 / 100: avg data time: 6.30e-02, avg batch time: 0.5078, average train loss: 3.8930
[09/26 12:55:24 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 12:55:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 12:55:24 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 12:55:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 12:55:31 visual_prompt]: Epoch 2 / 100: avg data time: 5.25e-02, avg batch time: 0.4965, average train loss: 3.7923
[09/26 12:55:32 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1660, average loss: 3.7611
[09/26 12:55:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 20.50	
[09/26 12:55:32 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 12:55:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 12:55:39 visual_prompt]: Epoch 3 / 100: avg data time: 5.07e-02, avg batch time: 0.4942, average train loss: 3.6651
[09/26 12:55:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 3.5489
[09/26 12:55:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 31.50	
[09/26 12:55:41 visual_prompt]: Best epoch 3: best metric: 0.055
[09/26 12:55:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 12:55:47 visual_prompt]: Epoch 4 / 100: avg data time: 4.91e-02, avg batch time: 0.4930, average train loss: 3.3303
[09/26 12:55:49 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1660, average loss: 3.3701
[09/26 12:55:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.00	top5: 33.00	
[09/26 12:55:49 visual_prompt]: Best epoch 4: best metric: 0.100
[09/26 12:55:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 12:55:56 visual_prompt]: Epoch 5 / 100: avg data time: 5.07e-02, avg batch time: 0.4949, average train loss: 2.9169
[09/26 12:55:57 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 2.7114
[09/26 12:55:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 26.00	top5: 59.00	
[09/26 12:55:57 visual_prompt]: Best epoch 5: best metric: 0.260
[09/26 12:55:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 12:56:04 visual_prompt]: Epoch 6 / 100: avg data time: 6.17e-02, avg batch time: 0.5041, average train loss: 2.3437
[09/26 12:56:06 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1660, average loss: 2.4299
[09/26 12:56:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 65.00	
[09/26 12:56:06 visual_prompt]: Best epoch 6: best metric: 0.270
[09/26 12:56:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 12:56:13 visual_prompt]: Epoch 7 / 100: avg data time: 6.10e-02, avg batch time: 0.5039, average train loss: 1.9817
[09/26 12:56:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1660, average loss: 1.7085
[09/26 12:56:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 83.50	
[09/26 12:56:14 visual_prompt]: Best epoch 7: best metric: 0.490
[09/26 12:56:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 12:56:21 visual_prompt]: Epoch 8 / 100: avg data time: 6.26e-02, avg batch time: 0.5039, average train loss: 1.4335
[09/26 12:56:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.4587
[09/26 12:56:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.00	top5: 89.50	
[09/26 12:56:23 visual_prompt]: Best epoch 8: best metric: 0.580
[09/26 12:56:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 12:56:30 visual_prompt]: Epoch 9 / 100: avg data time: 4.82e-02, avg batch time: 0.4917, average train loss: 1.1199
[09/26 12:56:31 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.3127
[09/26 12:56:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 89.50	
[09/26 12:56:31 visual_prompt]: Best epoch 9: best metric: 0.655
[09/26 12:56:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 12:56:38 visual_prompt]: Epoch 10 / 100: avg data time: 4.92e-02, avg batch time: 0.4936, average train loss: 0.7579
[09/26 12:56:39 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.2199
[09/26 12:56:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.50	top5: 90.50	
[09/26 12:56:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 12:56:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.24e-02, avg batch time: 0.4940, average train loss: 0.4785
[09/26 12:56:48 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.1639
[09/26 12:56:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 91.00	
[09/26 12:56:48 visual_prompt]: Best epoch 11: best metric: 0.685
[09/26 12:56:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 12:56:55 visual_prompt]: Epoch 12 / 100: avg data time: 5.52e-02, avg batch time: 0.4981, average train loss: 0.2880
[09/26 12:56:56 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1666, average loss: 0.9481
[09/26 12:56:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 12:56:56 visual_prompt]: Best epoch 12: best metric: 0.715
[09/26 12:56:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 12:57:03 visual_prompt]: Epoch 13 / 100: avg data time: 5.12e-02, avg batch time: 0.4935, average train loss: 0.1893
[09/26 12:57:05 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.0489
[09/26 12:57:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.00	
[09/26 12:57:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 12:57:11 visual_prompt]: Epoch 14 / 100: avg data time: 5.62e-02, avg batch time: 0.4989, average train loss: 0.1206
[09/26 12:57:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 0.9230
[09/26 12:57:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 12:57:13 visual_prompt]: Best epoch 14: best metric: 0.730
[09/26 12:57:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 12:57:20 visual_prompt]: Epoch 15 / 100: avg data time: 5.55e-02, avg batch time: 0.4984, average train loss: 0.0654
[09/26 12:57:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 0.9543
[09/26 12:57:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.00	
[09/26 12:57:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 12:57:28 visual_prompt]: Epoch 16 / 100: avg data time: 5.15e-02, avg batch time: 0.4946, average train loss: 0.0324
[09/26 12:57:30 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.9300
[09/26 12:57:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.50	
[09/26 12:57:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 12:57:37 visual_prompt]: Epoch 17 / 100: avg data time: 5.63e-02, avg batch time: 0.5010, average train loss: 0.0246
[09/26 12:57:38 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 0.9482
[09/26 12:57:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 12:57:38 visual_prompt]: Best epoch 17: best metric: 0.755
[09/26 12:57:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 12:57:45 visual_prompt]: Epoch 18 / 100: avg data time: 5.53e-02, avg batch time: 0.4992, average train loss: 0.0177
[09/26 12:57:47 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 0.8667
[09/26 12:57:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.50	
[09/26 12:57:47 visual_prompt]: Best epoch 18: best metric: 0.765
[09/26 12:57:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 12:57:54 visual_prompt]: Epoch 19 / 100: avg data time: 5.71e-02, avg batch time: 0.4999, average train loss: 0.0129
[09/26 12:57:55 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1663, average loss: 0.8996
[09/26 12:57:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 12:57:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 12:58:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.48e-02, avg batch time: 0.4987, average train loss: 0.0090
[09/26 12:58:04 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1671, average loss: 0.8876
[09/26 12:58:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 12:58:04 visual_prompt]: Best epoch 20: best metric: 0.775
[09/26 12:58:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 12:58:10 visual_prompt]: Epoch 21 / 100: avg data time: 6.01e-02, avg batch time: 0.5028, average train loss: 0.0077
[09/26 12:58:12 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 0.8576
[09/26 12:58:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 12:58:12 visual_prompt]: Best epoch 21: best metric: 0.780
[09/26 12:58:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 12:58:19 visual_prompt]: Epoch 22 / 100: avg data time: 5.17e-02, avg batch time: 0.4936, average train loss: 0.0063
[09/26 12:58:20 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.8544
[09/26 12:58:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:58:20 visual_prompt]: Best epoch 22: best metric: 0.785
[09/26 12:58:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 12:58:27 visual_prompt]: Epoch 23 / 100: avg data time: 6.47e-02, avg batch time: 0.5068, average train loss: 0.0064
[09/26 12:58:29 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 0.8471
[09/26 12:58:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 12:58:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 12:58:36 visual_prompt]: Epoch 24 / 100: avg data time: 6.49e-02, avg batch time: 0.5085, average train loss: 0.0053
[09/26 12:58:37 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 0.8424
[09/26 12:58:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 95.50	
[09/26 12:58:37 visual_prompt]: Best epoch 24: best metric: 0.800
[09/26 12:58:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 12:58:44 visual_prompt]: Epoch 25 / 100: avg data time: 5.37e-02, avg batch time: 0.4967, average train loss: 0.0053
[09/26 12:58:46 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 0.8479
[09/26 12:58:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 12:58:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 12:58:53 visual_prompt]: Epoch 26 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 0.0048
[09/26 12:58:54 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 0.8441
[09/26 12:58:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:58:54 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 12:59:01 visual_prompt]: Epoch 27 / 100: avg data time: 5.53e-02, avg batch time: 0.4975, average train loss: 0.0048
[09/26 12:59:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 0.8398
[09/26 12:59:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:59:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 12:59:10 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e-02, avg batch time: 0.4939, average train loss: 0.0045
[09/26 12:59:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.8395
[09/26 12:59:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 94.00	
[09/26 12:59:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 12:59:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.44e-02, avg batch time: 0.4987, average train loss: 0.0046
[09/26 12:59:19 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 0.8473
[09/26 12:59:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 94.50	
[09/26 12:59:19 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 12:59:26 visual_prompt]: Epoch 30 / 100: avg data time: 5.57e-02, avg batch time: 0.4986, average train loss: 0.0045
[09/26 12:59:28 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1663, average loss: 0.8588
[09/26 12:59:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 12:59:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 12:59:35 visual_prompt]: Epoch 31 / 100: avg data time: 5.46e-02, avg batch time: 0.5003, average train loss: 0.0041
[09/26 12:59:36 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1665, average loss: 0.8640
[09/26 12:59:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 12:59:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 12:59:43 visual_prompt]: Epoch 32 / 100: avg data time: 5.23e-02, avg batch time: 0.4957, average train loss: 0.0042
[09/26 12:59:45 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 0.8560
[09/26 12:59:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 12:59:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 12:59:52 visual_prompt]: Epoch 33 / 100: avg data time: 6.73e-02, avg batch time: 0.5117, average train loss: 0.0041
[09/26 12:59:53 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 0.8459
[09/26 12:59:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 95.00	
[09/26 12:59:53 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:00:00 visual_prompt]: Epoch 34 / 100: avg data time: 6.35e-02, avg batch time: 0.5061, average train loss: 0.0038
[09/26 13:00:02 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 0.8530
[09/26 13:00:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:00:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:00:09 visual_prompt]: Epoch 35 / 100: avg data time: 6.07e-02, avg batch time: 0.5034, average train loss: 0.0038
[09/26 13:00:10 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 0.8546
[09/26 13:00:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:00:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:00:17 visual_prompt]: Epoch 36 / 100: avg data time: 6.42e-02, avg batch time: 0.5070, average train loss: 0.0037
[09/26 13:00:19 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1666, average loss: 0.8546
[09/26 13:00:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:00:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:00:26 visual_prompt]: Epoch 37 / 100: avg data time: 5.41e-02, avg batch time: 0.4985, average train loss: 0.0036
[09/26 13:00:27 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 0.8588
[09/26 13:00:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 13:00:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:00:34 visual_prompt]: Epoch 38 / 100: avg data time: 5.83e-02, avg batch time: 0.5020, average train loss: 0.0035
[09/26 13:00:36 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.8536
[09/26 13:00:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 13:00:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:00:43 visual_prompt]: Epoch 39 / 100: avg data time: 5.70e-02, avg batch time: 0.5010, average train loss: 0.0036
[09/26 13:00:44 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.8557
[09/26 13:00:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 13:00:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:00:51 visual_prompt]: Epoch 40 / 100: avg data time: 6.36e-02, avg batch time: 0.5054, average train loss: 0.0035
[09/26 13:00:53 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 0.8557
[09/26 13:00:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:00:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:00:59 visual_prompt]: Epoch 41 / 100: avg data time: 5.16e-02, avg batch time: 0.4972, average train loss: 0.0036
[09/26 13:01:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1667, average loss: 0.8548
[09/26 13:01:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:01:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:01:08 visual_prompt]: Epoch 42 / 100: avg data time: 5.40e-02, avg batch time: 0.4990, average train loss: 0.0035
[09/26 13:01:09 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 0.8518
[09/26 13:01:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:01:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:01:16 visual_prompt]: Epoch 43 / 100: avg data time: 5.25e-02, avg batch time: 0.4955, average train loss: 0.0035
[09/26 13:01:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 0.8598
[09/26 13:01:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 13:01:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:01:25 visual_prompt]: Epoch 44 / 100: avg data time: 5.18e-02, avg batch time: 0.4946, average train loss: 0.0033
[09/26 13:01:26 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 0.8635
[09/26 13:01:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 13:01:26 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:01:33 visual_prompt]: Epoch 45 / 100: avg data time: 6.04e-02, avg batch time: 0.5026, average train loss: 0.0035
[09/26 13:01:35 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1663, average loss: 0.8567
[09/26 13:01:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:01:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:01:41 visual_prompt]: Epoch 46 / 100: avg data time: 5.05e-02, avg batch time: 0.4945, average train loss: 0.0035
[09/26 13:01:43 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 0.8535
[09/26 13:01:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:01:43 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:01:50 visual_prompt]: Epoch 47 / 100: avg data time: 5.15e-02, avg batch time: 0.4959, average train loss: 0.0033
[09/26 13:01:51 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.8537
[09/26 13:01:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:01:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:01:58 visual_prompt]: Epoch 48 / 100: avg data time: 4.80e-02, avg batch time: 0.4932, average train loss: 0.0035
[09/26 13:02:00 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 0.8582
[09/26 13:02:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.00	
[09/26 13:02:00 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:02:06 visual_prompt]: Epoch 49 / 100: avg data time: 5.00e-02, avg batch time: 0.4931, average train loss: 0.0032
[09/26 13:02:08 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 0.8536
[09/26 13:02:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:02:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:02:15 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e-02, avg batch time: 0.4907, average train loss: 0.0031
[09/26 13:02:16 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1662, average loss: 0.8527
[09/26 13:02:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:02:16 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:02:23 visual_prompt]: Epoch 51 / 100: avg data time: 5.64e-02, avg batch time: 0.4991, average train loss: 0.0031
[09/26 13:02:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 0.8556
[09/26 13:02:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:02:25 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:02:32 visual_prompt]: Epoch 52 / 100: avg data time: 5.56e-02, avg batch time: 0.4975, average train loss: 0.0031
[09/26 13:02:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.8511
[09/26 13:02:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:02:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:02:40 visual_prompt]: Epoch 53 / 100: avg data time: 5.27e-02, avg batch time: 0.4953, average train loss: 0.0031
[09/26 13:02:42 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 0.8499
[09/26 13:02:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:02:42 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:02:48 visual_prompt]: Epoch 54 / 100: avg data time: 5.26e-02, avg batch time: 0.4967, average train loss: 0.0031
[09/26 13:02:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 0.8587
[09/26 13:02:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:02:50 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:02:57 visual_prompt]: Epoch 55 / 100: avg data time: 5.31e-02, avg batch time: 0.4952, average train loss: 0.0030
[09/26 13:02:58 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.8585
[09/26 13:02:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:02:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:03:05 visual_prompt]: Epoch 56 / 100: avg data time: 5.44e-02, avg batch time: 0.4970, average train loss: 0.0030
[09/26 13:03:07 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8609
[09/26 13:03:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:03:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:03:14 visual_prompt]: Epoch 57 / 100: avg data time: 5.29e-02, avg batch time: 0.4961, average train loss: 0.0032
[09/26 13:03:15 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 0.8669
[09/26 13:03:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:03:15 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:03:22 visual_prompt]: Epoch 58 / 100: avg data time: 5.54e-02, avg batch time: 0.4985, average train loss: 0.0030
[09/26 13:03:24 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 0.8682
[09/26 13:03:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 13:03:24 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:03:30 visual_prompt]: Epoch 59 / 100: avg data time: 5.29e-02, avg batch time: 0.4965, average train loss: 0.0030
[09/26 13:03:32 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1664, average loss: 0.8636
[09/26 13:03:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:03:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:03:39 visual_prompt]: Epoch 60 / 100: avg data time: 6.33e-02, avg batch time: 0.5052, average train loss: 0.0032
[09/26 13:03:41 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 0.8551
[09/26 13:03:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:03:41 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:03:47 visual_prompt]: Epoch 61 / 100: avg data time: 4.87e-02, avg batch time: 0.4915, average train loss: 0.0031
[09/26 13:03:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 0.8562
[09/26 13:03:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:03:49 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:03:56 visual_prompt]: Epoch 62 / 100: avg data time: 5.61e-02, avg batch time: 0.4996, average train loss: 0.0030
[09/26 13:03:57 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 0.8573
[09/26 13:03:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:03:57 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:04:04 visual_prompt]: Epoch 63 / 100: avg data time: 4.96e-02, avg batch time: 0.4949, average train loss: 0.0029
[09/26 13:04:06 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 0.8570
[09/26 13:04:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 13:04:06 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:04:12 visual_prompt]: Epoch 64 / 100: avg data time: 5.13e-02, avg batch time: 0.4950, average train loss: 0.0029
[09/26 13:04:14 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1665, average loss: 0.8582
[09/26 13:04:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:04:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:04:21 visual_prompt]: Epoch 65 / 100: avg data time: 5.30e-02, avg batch time: 0.4961, average train loss: 0.0029
[09/26 13:04:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 0.8555
[09/26 13:04:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:04:22 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:04:29 visual_prompt]: Epoch 66 / 100: avg data time: 5.24e-02, avg batch time: 0.4963, average train loss: 0.0030
[09/26 13:04:31 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1661, average loss: 0.8562
[09/26 13:04:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:04:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:04:38 visual_prompt]: Epoch 67 / 100: avg data time: 5.71e-02, avg batch time: 0.5012, average train loss: 0.0028
[09/26 13:04:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 0.8530
[09/26 13:04:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:04:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:04:46 visual_prompt]: Epoch 68 / 100: avg data time: 5.92e-02, avg batch time: 0.5012, average train loss: 0.0029
[09/26 13:04:48 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1662, average loss: 0.8496
[09/26 13:04:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:04:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:04:55 visual_prompt]: Epoch 69 / 100: avg data time: 6.13e-02, avg batch time: 0.5036, average train loss: 0.0028
[09/26 13:04:56 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 0.8474
[09/26 13:04:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:04:56 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:05:03 visual_prompt]: Epoch 70 / 100: avg data time: 6.16e-02, avg batch time: 0.5052, average train loss: 0.0028
[09/26 13:05:05 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.8483
[09/26 13:05:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:05:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:05:12 visual_prompt]: Epoch 71 / 100: avg data time: 5.79e-02, avg batch time: 0.5009, average train loss: 0.0028
[09/26 13:05:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 0.8501
[09/26 13:05:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:05:13 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:05:20 visual_prompt]: Epoch 72 / 100: avg data time: 6.10e-02, avg batch time: 0.5040, average train loss: 0.0029
[09/26 13:05:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 0.8519
[09/26 13:05:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.50	
[09/26 13:05:22 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:05:29 visual_prompt]: Epoch 73 / 100: avg data time: 6.21e-02, avg batch time: 0.5040, average train loss: 0.0029
[09/26 13:05:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 0.8510
[09/26 13:05:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:05:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:05:37 visual_prompt]: Epoch 74 / 100: avg data time: 5.25e-02, avg batch time: 0.4966, average train loss: 0.0029
[09/26 13:05:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 0.8512
[09/26 13:05:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:05:39 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:05:46 visual_prompt]: Epoch 75 / 100: avg data time: 6.10e-02, avg batch time: 0.5025, average train loss: 0.0028
[09/26 13:05:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 0.8545
[09/26 13:05:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:05:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:05:54 visual_prompt]: Epoch 76 / 100: avg data time: 5.01e-02, avg batch time: 0.4938, average train loss: 0.0028
[09/26 13:05:56 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1662, average loss: 0.8558
[09/26 13:05:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.00	
[09/26 13:05:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:06:02 visual_prompt]: Epoch 77 / 100: avg data time: 5.97e-02, avg batch time: 0.5007, average train loss: 0.0027
[09/26 13:06:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.8568
[09/26 13:06:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:06:11 visual_prompt]: Epoch 78 / 100: avg data time: 5.45e-02, avg batch time: 0.4970, average train loss: 0.0029
[09/26 13:06:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 0.8579
[09/26 13:06:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:12 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:06:19 visual_prompt]: Epoch 79 / 100: avg data time: 5.96e-02, avg batch time: 0.5023, average train loss: 0.0028
[09/26 13:06:21 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1661, average loss: 0.8573
[09/26 13:06:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:06:28 visual_prompt]: Epoch 80 / 100: avg data time: 5.64e-02, avg batch time: 0.4975, average train loss: 0.0029
[09/26 13:06:29 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1662, average loss: 0.8565
[09/26 13:06:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:06:36 visual_prompt]: Epoch 81 / 100: avg data time: 4.67e-02, avg batch time: 0.4877, average train loss: 0.0029
[09/26 13:06:38 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 0.8560
[09/26 13:06:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:06:45 visual_prompt]: Epoch 82 / 100: avg data time: 6.59e-02, avg batch time: 0.5065, average train loss: 0.0028
[09/26 13:06:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 0.8572
[09/26 13:06:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:06:53 visual_prompt]: Epoch 83 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 0.0028
[09/26 13:06:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1661, average loss: 0.8564
[09/26 13:06:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:06:55 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:07:01 visual_prompt]: Epoch 84 / 100: avg data time: 4.96e-02, avg batch time: 0.4957, average train loss: 0.0029
[09/26 13:07:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1661, average loss: 0.8559
[09/26 13:07:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:07:10 visual_prompt]: Epoch 85 / 100: avg data time: 5.10e-02, avg batch time: 0.4923, average train loss: 0.0028
[09/26 13:07:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1660, average loss: 0.8565
[09/26 13:07:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:07:18 visual_prompt]: Epoch 86 / 100: avg data time: 5.69e-02, avg batch time: 0.4989, average train loss: 0.0029
[09/26 13:07:20 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 0.8576
[09/26 13:07:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:07:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:07:27 visual_prompt]: Epoch 87 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 0.0028
[09/26 13:07:28 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1660, average loss: 0.8572
[09/26 13:07:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:07:35 visual_prompt]: Epoch 88 / 100: avg data time: 5.19e-02, avg batch time: 0.4930, average train loss: 0.0027
[09/26 13:07:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1660, average loss: 0.8571
[09/26 13:07:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:07:43 visual_prompt]: Epoch 89 / 100: avg data time: 6.76e-02, avg batch time: 0.5089, average train loss: 0.0028
[09/26 13:07:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1661, average loss: 0.8567
[09/26 13:07:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:07:52 visual_prompt]: Epoch 90 / 100: avg data time: 5.65e-02, avg batch time: 0.4992, average train loss: 0.0028
[09/26 13:07:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 0.8564
[09/26 13:07:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:07:54 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:08:00 visual_prompt]: Epoch 91 / 100: avg data time: 4.96e-02, avg batch time: 0.4927, average train loss: 0.0028
[09/26 13:08:02 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 0.8558
[09/26 13:08:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:08:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:08:09 visual_prompt]: Epoch 92 / 100: avg data time: 5.26e-02, avg batch time: 0.4935, average train loss: 0.0029
[09/26 13:08:10 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1659, average loss: 0.8556
[09/26 13:08:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:08:10 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:08:17 visual_prompt]: Epoch 93 / 100: avg data time: 6.30e-02, avg batch time: 0.5036, average train loss: 0.0030
[09/26 13:08:19 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 0.8555
[09/26 13:08:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:08:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:08:26 visual_prompt]: Epoch 94 / 100: avg data time: 5.81e-02, avg batch time: 0.4984, average train loss: 0.0028
[09/26 13:08:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1659, average loss: 0.8554
[09/26 13:08:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:08:27 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:08:34 visual_prompt]: Epoch 95 / 100: avg data time: 5.59e-02, avg batch time: 0.4988, average train loss: 0.0030
[09/26 13:08:36 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1660, average loss: 0.8552
[09/26 13:08:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:08:36 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:08:42 visual_prompt]: Epoch 96 / 100: avg data time: 4.85e-02, avg batch time: 0.4917, average train loss: 0.0028
[09/26 13:08:44 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1660, average loss: 0.8551
[09/26 13:08:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:08:44 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:08:51 visual_prompt]: Epoch 97 / 100: avg data time: 5.73e-02, avg batch time: 0.4985, average train loss: 0.0027
[09/26 13:08:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1661, average loss: 0.8552
[09/26 13:08:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:08:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:08:59 visual_prompt]: Epoch 98 / 100: avg data time: 5.28e-02, avg batch time: 0.4941, average train loss: 0.0028
[09/26 13:09:01 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 0.8552
[09/26 13:09:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:09:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:09:08 visual_prompt]: Epoch 99 / 100: avg data time: 5.00e-02, avg batch time: 0.4947, average train loss: 0.0028
[09/26 13:09:09 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 0.8552
[09/26 13:09:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:09:09 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:09:16 visual_prompt]: Epoch 100 / 100: avg data time: 4.94e-02, avg batch time: 0.4920, average train loss: 0.0028
[09/26 13:09:17 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 0.8552
[09/26 13:09:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 13:09:18 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:09:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:09:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:09:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:09:18 visual_prompt]: Training with config:
[09/26 13:09:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.5_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:09:18 visual_prompt]: Loading training data...
[09/26 13:09:18 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:09:19 visual_prompt]: Number of images: 800
[09/26 13:09:19 visual_prompt]: Number of classes: 45 / 45
[09/26 13:09:19 visual_prompt]: Loading validation data...
[09/26 13:09:19 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:09:19 visual_prompt]: Number of images: 200
[09/26 13:09:19 visual_prompt]: Number of classes: 45 / 45
[09/26 13:09:19 visual_prompt]: Constructing models...
[09/26 13:09:21 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 13:09:21 visual_prompt]: tuned percent:0.574
[09/26 13:09:22 visual_prompt]: Device used for model: 0
[09/26 13:09:22 visual_prompt]: Setting up Evaluator...
[09/26 13:09:22 visual_prompt]: Setting up Trainer...
[09/26 13:09:22 visual_prompt]: 	Setting up the optimizer...
[09/26 13:09:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:09:28 visual_prompt]: Epoch 1 / 100: avg data time: 5.55e-02, avg batch time: 0.4958, average train loss: 3.8973
[09/26 13:09:30 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 13:09:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 13:09:30 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 13:09:30 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[09/26 13:09:37 visual_prompt]: Epoch 2 / 100: avg data time: 5.73e-02, avg batch time: 0.4974, average train loss: 3.8251
[09/26 13:09:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 3.7921
[09/26 13:09:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 16.50	
[09/26 13:09:38 visual_prompt]: Best epoch 2: best metric: 0.060
[09/26 13:09:38 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[09/26 13:09:45 visual_prompt]: Epoch 3 / 100: avg data time: 4.86e-02, avg batch time: 0.4906, average train loss: 3.7089
[09/26 13:09:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1659, average loss: 3.6052
[09/26 13:09:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.50	top5: 29.50	
[09/26 13:09:47 visual_prompt]: Best epoch 3: best metric: 0.075
[09/26 13:09:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[09/26 13:09:54 visual_prompt]: Epoch 4 / 100: avg data time: 5.37e-02, avg batch time: 0.4958, average train loss: 3.4508
[09/26 13:09:55 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1657, average loss: 3.3087
[09/26 13:09:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 12.00	top5: 38.50	
[09/26 13:09:55 visual_prompt]: Best epoch 4: best metric: 0.120
[09/26 13:09:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[09/26 13:10:02 visual_prompt]: Epoch 5 / 100: avg data time: 5.97e-02, avg batch time: 0.5020, average train loss: 3.0426
[09/26 13:10:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1658, average loss: 2.9946
[09/26 13:10:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 16.50	top5: 45.50	
[09/26 13:10:04 visual_prompt]: Best epoch 5: best metric: 0.165
[09/26 13:10:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[09/26 13:10:11 visual_prompt]: Epoch 6 / 100: avg data time: 6.83e-02, avg batch time: 0.5100, average train loss: 2.5382
[09/26 13:10:12 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1658, average loss: 2.3954
[09/26 13:10:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.00	top5: 66.00	
[09/26 13:10:12 visual_prompt]: Best epoch 6: best metric: 0.300
[09/26 13:10:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[09/26 13:10:19 visual_prompt]: Epoch 7 / 100: avg data time: 5.66e-02, avg batch time: 0.4980, average train loss: 2.1788
[09/26 13:10:21 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1658, average loss: 2.0706
[09/26 13:10:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 41.00	top5: 76.00	
[09/26 13:10:21 visual_prompt]: Best epoch 7: best metric: 0.410
[09/26 13:10:21 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[09/26 13:10:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.03e-02, avg batch time: 0.4931, average train loss: 1.6919
[09/26 13:10:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 1.9205
[09/26 13:10:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.00	top5: 77.00	
[09/26 13:10:29 visual_prompt]: Best epoch 8: best metric: 0.460
[09/26 13:10:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[09/26 13:10:36 visual_prompt]: Epoch 9 / 100: avg data time: 5.73e-02, avg batch time: 0.4994, average train loss: 1.3165
[09/26 13:10:37 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 2.1493
[09/26 13:10:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.50	top5: 77.00	
[09/26 13:10:37 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[09/26 13:10:44 visual_prompt]: Epoch 10 / 100: avg data time: 5.11e-02, avg batch time: 0.4935, average train loss: 1.0229
[09/26 13:10:46 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1660, average loss: 1.5352
[09/26 13:10:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.50	top5: 87.00	
[09/26 13:10:46 visual_prompt]: Best epoch 10: best metric: 0.545
[09/26 13:10:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[09/26 13:10:53 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e-02, avg batch time: 0.4916, average train loss: 0.6695
[09/26 13:10:54 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 1.2027
[09/26 13:10:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 92.00	
[09/26 13:10:54 visual_prompt]: Best epoch 11: best metric: 0.655
[09/26 13:10:54 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[09/26 13:11:01 visual_prompt]: Epoch 12 / 100: avg data time: 5.83e-02, avg batch time: 0.5015, average train loss: 0.4062
[09/26 13:11:03 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1660, average loss: 1.1424
[09/26 13:11:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.50	
[09/26 13:11:03 visual_prompt]: Best epoch 12: best metric: 0.675
[09/26 13:11:03 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[09/26 13:11:10 visual_prompt]: Epoch 13 / 100: avg data time: 6.08e-02, avg batch time: 0.5030, average train loss: 0.2289
[09/26 13:11:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1660, average loss: 1.0409
[09/26 13:11:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.00	
[09/26 13:11:11 visual_prompt]: Best epoch 13: best metric: 0.730
[09/26 13:11:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[09/26 13:11:18 visual_prompt]: Epoch 14 / 100: avg data time: 6.20e-02, avg batch time: 0.5029, average train loss: 0.1695
[09/26 13:11:20 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 1.1404
[09/26 13:11:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 92.50	
[09/26 13:11:20 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[09/26 13:11:26 visual_prompt]: Epoch 15 / 100: avg data time: 4.94e-02, avg batch time: 0.4926, average train loss: 0.1037
[09/26 13:11:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 0.9439
[09/26 13:11:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 96.50	
[09/26 13:11:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[09/26 13:11:35 visual_prompt]: Epoch 16 / 100: avg data time: 5.22e-02, avg batch time: 0.4943, average train loss: 0.0584
[09/26 13:11:36 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 0.8926
[09/26 13:11:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:11:36 visual_prompt]: Best epoch 16: best metric: 0.775
[09/26 13:11:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[09/26 13:11:43 visual_prompt]: Epoch 17 / 100: avg data time: 5.35e-02, avg batch time: 0.4957, average train loss: 0.0294
[09/26 13:11:45 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1661, average loss: 0.8230
[09/26 13:11:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 13:11:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[09/26 13:11:52 visual_prompt]: Epoch 18 / 100: avg data time: 5.28e-02, avg batch time: 0.4957, average train loss: 0.0208
[09/26 13:11:53 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1661, average loss: 0.8488
[09/26 13:11:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 13:11:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[09/26 13:12:00 visual_prompt]: Epoch 19 / 100: avg data time: 6.12e-02, avg batch time: 0.5033, average train loss: 0.0137
[09/26 13:12:02 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1659, average loss: 0.8081
[09/26 13:12:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.00	
[09/26 13:12:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[09/26 13:12:08 visual_prompt]: Epoch 20 / 100: avg data time: 5.18e-02, avg batch time: 0.4959, average train loss: 0.0101
[09/26 13:12:10 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 0.7927
[09/26 13:12:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 13:12:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[09/26 13:12:17 visual_prompt]: Epoch 21 / 100: avg data time: 4.85e-02, avg batch time: 0.4916, average train loss: 0.0076
[09/26 13:12:18 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 0.7995
[09/26 13:12:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.50	
[09/26 13:12:18 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[09/26 13:12:25 visual_prompt]: Epoch 22 / 100: avg data time: 5.98e-02, avg batch time: 0.5013, average train loss: 0.0060
[09/26 13:12:27 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1661, average loss: 0.8025
[09/26 13:12:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 13:12:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[09/26 13:12:34 visual_prompt]: Epoch 23 / 100: avg data time: 5.28e-02, avg batch time: 0.4955, average train loss: 0.0057
[09/26 13:12:35 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1662, average loss: 0.7924
[09/26 13:12:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 13:12:35 visual_prompt]: Best epoch 23: best metric: 0.785
[09/26 13:12:35 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[09/26 13:12:42 visual_prompt]: Epoch 24 / 100: avg data time: 5.08e-02, avg batch time: 0.4947, average train loss: 0.0051
[09/26 13:12:44 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1660, average loss: 0.7955
[09/26 13:12:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 13:12:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[09/26 13:12:50 visual_prompt]: Epoch 25 / 100: avg data time: 5.20e-02, avg batch time: 0.4954, average train loss: 0.0046
[09/26 13:12:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1660, average loss: 0.8052
[09/26 13:12:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:12:52 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[09/26 13:12:59 visual_prompt]: Epoch 26 / 100: avg data time: 6.21e-02, avg batch time: 0.5030, average train loss: 0.0041
[09/26 13:13:01 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 0.8112
[09/26 13:13:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:13:01 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[09/26 13:13:07 visual_prompt]: Epoch 27 / 100: avg data time: 5.23e-02, avg batch time: 0.4942, average train loss: 0.0040
[09/26 13:13:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 0.8062
[09/26 13:13:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 13:13:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[09/26 13:13:16 visual_prompt]: Epoch 28 / 100: avg data time: 4.62e-02, avg batch time: 0.4899, average train loss: 0.0037
[09/26 13:13:17 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1661, average loss: 0.8019
[09/26 13:13:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 13:13:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[09/26 13:13:24 visual_prompt]: Epoch 29 / 100: avg data time: 6.53e-02, avg batch time: 0.5066, average train loss: 0.0035
[09/26 13:13:26 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 0.8054
[09/26 13:13:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:13:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[09/26 13:13:33 visual_prompt]: Epoch 30 / 100: avg data time: 5.94e-02, avg batch time: 0.5024, average train loss: 0.0033
[09/26 13:13:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 0.8055
[09/26 13:13:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 13:13:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[09/26 13:13:41 visual_prompt]: Epoch 31 / 100: avg data time: 5.20e-02, avg batch time: 0.4951, average train loss: 0.0032
[09/26 13:13:43 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 0.8058
[09/26 13:13:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:13:43 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[09/26 13:13:49 visual_prompt]: Epoch 32 / 100: avg data time: 5.18e-02, avg batch time: 0.4942, average train loss: 0.0031
[09/26 13:13:51 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8111
[09/26 13:13:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:13:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[09/26 13:13:58 visual_prompt]: Epoch 33 / 100: avg data time: 4.62e-02, avg batch time: 0.4894, average train loss: 0.0030
[09/26 13:13:59 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1661, average loss: 0.8185
[09/26 13:13:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:13:59 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[09/26 13:14:06 visual_prompt]: Epoch 34 / 100: avg data time: 6.06e-02, avg batch time: 0.5025, average train loss: 0.0031
[09/26 13:14:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.8180
[09/26 13:14:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:14:08 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[09/26 13:14:15 visual_prompt]: Epoch 35 / 100: avg data time: 6.35e-02, avg batch time: 0.5054, average train loss: 0.0029
[09/26 13:14:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 0.8190
[09/26 13:14:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:14:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[09/26 13:14:23 visual_prompt]: Epoch 36 / 100: avg data time: 5.14e-02, avg batch time: 0.4945, average train loss: 0.0028
[09/26 13:14:25 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 0.8261
[09/26 13:14:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:14:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[09/26 13:14:32 visual_prompt]: Epoch 37 / 100: avg data time: 4.99e-02, avg batch time: 0.4924, average train loss: 0.0026
[09/26 13:14:33 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1664, average loss: 0.8327
[09/26 13:14:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:14:33 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[09/26 13:14:40 visual_prompt]: Epoch 38 / 100: avg data time: 5.06e-02, avg batch time: 0.4929, average train loss: 0.0027
[09/26 13:14:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 0.8297
[09/26 13:14:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 13:14:42 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[09/26 13:14:49 visual_prompt]: Epoch 39 / 100: avg data time: 6.49e-02, avg batch time: 0.5067, average train loss: 0.0024
[09/26 13:14:50 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1664, average loss: 0.8280
[09/26 13:14:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:14:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[09/26 13:14:57 visual_prompt]: Epoch 40 / 100: avg data time: 5.85e-02, avg batch time: 0.5003, average train loss: 0.0024
[09/26 13:14:59 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1663, average loss: 0.8277
[09/26 13:14:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:14:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[09/26 13:15:05 visual_prompt]: Epoch 41 / 100: avg data time: 5.81e-02, avg batch time: 0.5008, average train loss: 0.0023
[09/26 13:15:07 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 0.8274
[09/26 13:15:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:15:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[09/26 13:15:14 visual_prompt]: Epoch 42 / 100: avg data time: 6.09e-02, avg batch time: 0.5026, average train loss: 0.0022
[09/26 13:15:16 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8278
[09/26 13:15:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:15:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[09/26 13:15:22 visual_prompt]: Epoch 43 / 100: avg data time: 5.19e-02, avg batch time: 0.4947, average train loss: 0.0023
[09/26 13:15:24 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1662, average loss: 0.8330
[09/26 13:15:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:15:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[09/26 13:15:31 visual_prompt]: Epoch 44 / 100: avg data time: 4.86e-02, avg batch time: 0.4915, average train loss: 0.0022
[09/26 13:15:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 0.8375
[09/26 13:15:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.50	
[09/26 13:15:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[09/26 13:15:39 visual_prompt]: Epoch 45 / 100: avg data time: 4.86e-02, avg batch time: 0.4933, average train loss: 0.0022
[09/26 13:15:41 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1663, average loss: 0.8367
[09/26 13:15:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:15:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[09/26 13:15:48 visual_prompt]: Epoch 46 / 100: avg data time: 5.06e-02, avg batch time: 0.4950, average train loss: 0.0021
[09/26 13:15:49 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 0.8346
[09/26 13:15:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:15:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[09/26 13:15:56 visual_prompt]: Epoch 47 / 100: avg data time: 5.04e-02, avg batch time: 0.4942, average train loss: 0.0020
[09/26 13:15:58 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 0.8383
[09/26 13:15:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:15:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[09/26 13:16:04 visual_prompt]: Epoch 48 / 100: avg data time: 5.09e-02, avg batch time: 0.4932, average train loss: 0.0020
[09/26 13:16:06 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1665, average loss: 0.8374
[09/26 13:16:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.50	
[09/26 13:16:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[09/26 13:16:13 visual_prompt]: Epoch 49 / 100: avg data time: 5.47e-02, avg batch time: 0.4996, average train loss: 0.0020
[09/26 13:16:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 0.8379
[09/26 13:16:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.50	
[09/26 13:16:14 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[09/26 13:16:21 visual_prompt]: Epoch 50 / 100: avg data time: 4.43e-02, avg batch time: 0.4871, average train loss: 0.0020
[09/26 13:16:22 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 0.8418
[09/26 13:16:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.50	
[09/26 13:16:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[09/26 13:16:29 visual_prompt]: Epoch 51 / 100: avg data time: 5.18e-02, avg batch time: 0.4944, average train loss: 0.0020
[09/26 13:16:31 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 0.8429
[09/26 13:16:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 13:16:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[09/26 13:16:38 visual_prompt]: Epoch 52 / 100: avg data time: 5.10e-02, avg batch time: 0.4949, average train loss: 0.0018
[09/26 13:16:39 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1670, average loss: 0.8396
[09/26 13:16:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:16:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[09/26 13:16:46 visual_prompt]: Epoch 53 / 100: avg data time: 6.03e-02, avg batch time: 0.5027, average train loss: 0.0019
[09/26 13:16:48 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 0.8389
[09/26 13:16:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:16:48 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[09/26 13:16:55 visual_prompt]: Epoch 54 / 100: avg data time: 5.69e-02, avg batch time: 0.5006, average train loss: 0.0018
[09/26 13:16:56 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 0.8406
[09/26 13:16:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:16:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[09/26 13:17:03 visual_prompt]: Epoch 55 / 100: avg data time: 5.70e-02, avg batch time: 0.5005, average train loss: 0.0018
[09/26 13:17:05 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.8420
[09/26 13:17:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:05 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[09/26 13:17:11 visual_prompt]: Epoch 56 / 100: avg data time: 4.84e-02, avg batch time: 0.4914, average train loss: 0.0017
[09/26 13:17:13 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1663, average loss: 0.8421
[09/26 13:17:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:13 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[09/26 13:17:20 visual_prompt]: Epoch 57 / 100: avg data time: 5.03e-02, avg batch time: 0.4930, average train loss: 0.0018
[09/26 13:17:21 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 0.8430
[09/26 13:17:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:22 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[09/26 13:17:28 visual_prompt]: Epoch 58 / 100: avg data time: 4.98e-02, avg batch time: 0.4922, average train loss: 0.0017
[09/26 13:17:30 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1665, average loss: 0.8425
[09/26 13:17:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:30 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[09/26 13:17:37 visual_prompt]: Epoch 59 / 100: avg data time: 4.99e-02, avg batch time: 0.4925, average train loss: 0.0016
[09/26 13:17:38 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 0.8428
[09/26 13:17:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:38 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.2152067247599837
[09/26 13:17:45 visual_prompt]: Epoch 60 / 100: avg data time: 5.30e-02, avg batch time: 0.4955, average train loss: 0.0016
[09/26 13:17:47 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 0.8427
[09/26 13:17:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:47 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.20658795558326742
[09/26 13:17:53 visual_prompt]: Epoch 61 / 100: avg data time: 5.87e-02, avg batch time: 0.5013, average train loss: 0.0016
[09/26 13:17:55 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1665, average loss: 0.8438
[09/26 13:17:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:17:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.1980220772955602
[09/26 13:18:02 visual_prompt]: Epoch 62 / 100: avg data time: 4.96e-02, avg batch time: 0.4934, average train loss: 0.0017
[09/26 13:18:03 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 0.8431
[09/26 13:18:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:18:03 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.1895195261000831
[09/26 13:18:10 visual_prompt]: Epoch 63 / 100: avg data time: 5.46e-02, avg batch time: 0.4974, average train loss: 0.0017
[09/26 13:18:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 0.8438
[09/26 13:18:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:18:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.18109066104575022
[09/26 13:18:19 visual_prompt]: Epoch 64 / 100: avg data time: 6.00e-02, avg batch time: 0.5033, average train loss: 0.0015
[09/26 13:18:20 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 0.8435
[09/26 13:18:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:18:20 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.17274575140626316
[09/26 13:18:27 visual_prompt]: Epoch 65 / 100: avg data time: 5.15e-02, avg batch time: 0.4952, average train loss: 0.0015
[09/26 13:18:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 0.8453
[09/26 13:18:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 13:18:29 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.16449496416858284
[09/26 13:18:35 visual_prompt]: Epoch 66 / 100: avg data time: 5.68e-02, avg batch time: 0.5007, average train loss: 0.0015
[09/26 13:18:37 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1666, average loss: 0.8480
[09/26 13:18:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 13:18:37 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.15634835164602198
[09/26 13:18:44 visual_prompt]: Epoch 67 / 100: avg data time: 5.45e-02, avg batch time: 0.4984, average train loss: 0.0015
[09/26 13:18:45 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1665, average loss: 0.8490
[09/26 13:18:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 13:18:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.14831583923105
[09/26 13:18:52 visual_prompt]: Epoch 68 / 100: avg data time: 5.37e-02, avg batch time: 0.4975, average train loss: 0.0016
[09/26 13:18:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 0.8496
[09/26 13:18:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 98.00	
[09/26 13:18:54 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.14040721330273062
[09/26 13:19:01 visual_prompt]: Epoch 69 / 100: avg data time: 5.76e-02, avg batch time: 0.5003, average train loss: 0.0015
[09/26 13:19:02 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1665, average loss: 0.8496
[09/26 13:19:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:02 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.13263210930352737
[09/26 13:19:09 visual_prompt]: Epoch 70 / 100: avg data time: 5.17e-02, avg batch time: 0.4942, average train loss: 0.0015
[09/26 13:19:11 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 0.8486
[09/26 13:19:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:11 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.12500000000000006
[09/26 13:19:17 visual_prompt]: Epoch 71 / 100: avg data time: 5.29e-02, avg batch time: 0.4967, average train loss: 0.0015
[09/26 13:19:19 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1666, average loss: 0.8490
[09/26 13:19:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:19 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.1175201839416988
[09/26 13:19:26 visual_prompt]: Epoch 72 / 100: avg data time: 5.14e-02, avg batch time: 0.4971, average train loss: 0.0015
[09/26 13:19:27 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1666, average loss: 0.8483
[09/26 13:19:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:27 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.11020177413231333
[09/26 13:19:34 visual_prompt]: Epoch 73 / 100: avg data time: 4.81e-02, avg batch time: 0.4955, average train loss: 0.0015
[09/26 13:19:36 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1665, average loss: 0.8463
[09/26 13:19:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:36 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.10305368692688174
[09/26 13:19:42 visual_prompt]: Epoch 74 / 100: avg data time: 5.36e-02, avg batch time: 0.4962, average train loss: 0.0015
[09/26 13:19:44 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 0.8461
[09/26 13:19:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:44 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.09608463116858543
[09/26 13:19:51 visual_prompt]: Epoch 75 / 100: avg data time: 5.29e-02, avg batch time: 0.4954, average train loss: 0.0014
[09/26 13:19:52 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 0.8462
[09/26 13:19:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:19:52 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.08930309757836516
[09/26 13:19:59 visual_prompt]: Epoch 76 / 100: avg data time: 5.81e-02, avg batch time: 0.5013, average train loss: 0.0014
[09/26 13:20:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 0.8471
[09/26 13:20:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:01 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.08271734841028552
[09/26 13:20:08 visual_prompt]: Epoch 77 / 100: avg data time: 5.07e-02, avg batch time: 0.4938, average train loss: 0.0013
[09/26 13:20:09 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 0.8479
[09/26 13:20:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:09 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.07633540738525066
[09/26 13:20:16 visual_prompt]: Epoch 78 / 100: avg data time: 5.95e-02, avg batch time: 0.5024, average train loss: 0.0014
[09/26 13:20:18 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 0.8491
[09/26 13:20:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:18 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.07016504991533726
[09/26 13:20:24 visual_prompt]: Epoch 79 / 100: avg data time: 4.86e-02, avg batch time: 0.4933, average train loss: 0.0014
[09/26 13:20:26 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.8497
[09/26 13:20:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:26 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.06421379363065141
[09/26 13:20:33 visual_prompt]: Epoch 80 / 100: avg data time: 6.06e-02, avg batch time: 0.5032, average train loss: 0.0014
[09/26 13:20:34 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 0.8494
[09/26 13:20:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:34 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.058488889220255524
[09/26 13:20:41 visual_prompt]: Epoch 81 / 100: avg data time: 6.75e-02, avg batch time: 0.5098, average train loss: 0.0014
[09/26 13:20:43 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 0.8498
[09/26 13:20:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:43 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.052997311598319524
[09/26 13:20:50 visual_prompt]: Epoch 82 / 100: avg data time: 6.19e-02, avg batch time: 0.5050, average train loss: 0.0015
[09/26 13:20:52 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 0.8494
[09/26 13:20:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:20:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.047745751406263165
[09/26 13:20:59 visual_prompt]: Epoch 83 / 100: avg data time: 6.78e-02, avg batch time: 0.5100, average train loss: 0.0014
[09/26 13:21:00 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 0.8497
[09/26 13:21:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:00 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.042740606861239594
[09/26 13:21:07 visual_prompt]: Epoch 84 / 100: avg data time: 6.08e-02, avg batch time: 0.5038, average train loss: 0.0014
[09/26 13:21:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 0.8495
[09/26 13:21:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:09 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.03798797596089351
[09/26 13:21:16 visual_prompt]: Epoch 85 / 100: avg data time: 5.85e-02, avg batch time: 0.5004, average train loss: 0.0014
[09/26 13:21:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1662, average loss: 0.8497
[09/26 13:21:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:17 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.03349364905389032
[09/26 13:21:24 visual_prompt]: Epoch 86 / 100: avg data time: 5.07e-02, avg batch time: 0.4939, average train loss: 0.0014
[09/26 13:21:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 0.8497
[09/26 13:21:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:26 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.029263101785268253
[09/26 13:21:32 visual_prompt]: Epoch 87 / 100: avg data time: 5.03e-02, avg batch time: 0.4923, average train loss: 0.0014
[09/26 13:21:34 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1665, average loss: 0.8495
[09/26 13:21:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:34 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.025301488425208296
[09/26 13:21:41 visual_prompt]: Epoch 88 / 100: avg data time: 4.65e-02, avg batch time: 0.4886, average train loss: 0.0014
[09/26 13:21:42 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 0.8494
[09/26 13:21:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:42 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.021613635589349756
[09/26 13:21:49 visual_prompt]: Epoch 89 / 100: avg data time: 6.14e-02, avg batch time: 0.5056, average train loss: 0.0014
[09/26 13:21:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 0.8492
[09/26 13:21:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.01820403635830317
[09/26 13:21:58 visual_prompt]: Epoch 90 / 100: avg data time: 5.28e-02, avg batch time: 0.4963, average train loss: 0.0014
[09/26 13:21:59 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.8493
[09/26 13:21:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:21:59 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.01507684480352292
[09/26 13:22:06 visual_prompt]: Epoch 91 / 100: avg data time: 6.63e-02, avg batch time: 0.5086, average train loss: 0.0013
[09/26 13:22:08 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 0.8492
[09/26 13:22:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:08 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.012235870926211617
[09/26 13:22:15 visual_prompt]: Epoch 92 / 100: avg data time: 5.90e-02, avg batch time: 0.5020, average train loss: 0.0014
[09/26 13:22:16 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 0.8492
[09/26 13:22:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:16 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.009684576015420276
[09/26 13:22:23 visual_prompt]: Epoch 93 / 100: avg data time: 5.60e-02, avg batch time: 0.4995, average train loss: 0.0014
[09/26 13:22:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.8492
[09/26 13:22:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:25 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.007426068431000882
[09/26 13:22:31 visual_prompt]: Epoch 94 / 100: avg data time: 5.96e-02, avg batch time: 0.5019, average train loss: 0.0014
[09/26 13:22:33 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1663, average loss: 0.8492
[09/26 13:22:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:33 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.005463099816548578
[09/26 13:22:40 visual_prompt]: Epoch 95 / 100: avg data time: 6.25e-02, avg batch time: 0.5045, average train loss: 0.0014
[09/26 13:22:42 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 0.8493
[09/26 13:22:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:42 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.003798061746947995
[09/26 13:22:48 visual_prompt]: Epoch 96 / 100: avg data time: 6.11e-02, avg batch time: 0.5032, average train loss: 0.0014
[09/26 13:22:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 0.8494
[09/26 13:22:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:50 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0024329828146074095
[09/26 13:22:57 visual_prompt]: Epoch 97 / 100: avg data time: 5.19e-02, avg batch time: 0.4954, average train loss: 0.0014
[09/26 13:22:59 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 0.8494
[09/26 13:22:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:22:59 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0013695261579316775
[09/26 13:23:05 visual_prompt]: Epoch 98 / 100: avg data time: 6.34e-02, avg batch time: 0.5061, average train loss: 0.0014
[09/26 13:23:07 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 0.8494
[09/26 13:23:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:23:07 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0006089874350439506
[09/26 13:23:14 visual_prompt]: Epoch 99 / 100: avg data time: 6.09e-02, avg batch time: 0.5025, average train loss: 0.0013
[09/26 13:23:16 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 0.8494
[09/26 13:23:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:23:16 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00015229324522605947
[09/26 13:23:23 visual_prompt]: Epoch 100 / 100: avg data time: 6.31e-02, avg batch time: 0.5045, average train loss: 0.0015
[09/26 13:23:24 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1664, average loss: 0.8494
[09/26 13:23:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 98.00	
[09/26 13:23:24 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:23:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:23:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:23:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:23:24 visual_prompt]: Training with config:
[09/26 13:23:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:23:24 visual_prompt]: Loading training data...
[09/26 13:23:24 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:23:25 visual_prompt]: Number of images: 800
[09/26 13:23:25 visual_prompt]: Number of classes: 45 / 45
[09/26 13:23:25 visual_prompt]: Loading validation data...
[09/26 13:23:25 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:23:26 visual_prompt]: Number of images: 200
[09/26 13:23:26 visual_prompt]: Number of classes: 45 / 45
[09/26 13:23:26 visual_prompt]: Constructing models...
[09/26 13:23:28 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 13:23:28 visual_prompt]: tuned percent:0.574
[09/26 13:23:28 visual_prompt]: Device used for model: 0
[09/26 13:23:28 visual_prompt]: Setting up Evaluator...
[09/26 13:23:28 visual_prompt]: Setting up Trainer...
[09/26 13:23:28 visual_prompt]: 	Setting up the optimizer...
[09/26 13:23:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:23:35 visual_prompt]: Epoch 1 / 100: avg data time: 6.31e-02, avg batch time: 0.5039, average train loss: 3.8999
[09/26 13:23:37 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 13:23:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 13:23:37 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 13:23:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 13:23:43 visual_prompt]: Epoch 2 / 100: avg data time: 5.38e-02, avg batch time: 0.4963, average train loss: 3.8134
[09/26 13:23:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1658, average loss: 3.7722
[09/26 13:23:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 19.00	
[09/26 13:23:45 visual_prompt]: Best epoch 2: best metric: 0.055
[09/26 13:23:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 13:23:52 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e-02, avg batch time: 0.4923, average train loss: 3.6472
[09/26 13:23:53 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1659, average loss: 3.5252
[09/26 13:23:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 36.50	
[09/26 13:23:53 visual_prompt]: Best epoch 3: best metric: 0.085
[09/26 13:23:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 13:24:00 visual_prompt]: Epoch 4 / 100: avg data time: 5.46e-02, avg batch time: 0.4970, average train loss: 3.2252
[09/26 13:24:02 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1662, average loss: 2.9014
[09/26 13:24:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.00	top5: 50.50	
[09/26 13:24:02 visual_prompt]: Best epoch 4: best metric: 0.180
[09/26 13:24:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 13:24:09 visual_prompt]: Epoch 5 / 100: avg data time: 6.18e-02, avg batch time: 0.5039, average train loss: 2.7898
[09/26 13:24:10 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 2.6940
[09/26 13:24:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 24.00	top5: 65.50	
[09/26 13:24:10 visual_prompt]: Best epoch 5: best metric: 0.240
[09/26 13:24:10 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 13:24:17 visual_prompt]: Epoch 6 / 100: avg data time: 6.12e-02, avg batch time: 0.5032, average train loss: 2.5302
[09/26 13:24:19 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1664, average loss: 2.5607
[09/26 13:24:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 58.00	
[09/26 13:24:19 visual_prompt]: Best epoch 6: best metric: 0.275
[09/26 13:24:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 13:24:26 visual_prompt]: Epoch 7 / 100: avg data time: 4.92e-02, avg batch time: 0.4925, average train loss: 2.0907
[09/26 13:24:27 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.8816
[09/26 13:24:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.00	top5: 83.50	
[09/26 13:24:27 visual_prompt]: Best epoch 7: best metric: 0.450
[09/26 13:24:27 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 13:24:34 visual_prompt]: Epoch 8 / 100: avg data time: 6.32e-02, avg batch time: 0.5051, average train loss: 1.5145
[09/26 13:24:36 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1663, average loss: 1.8376
[09/26 13:24:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.50	top5: 84.50	
[09/26 13:24:36 visual_prompt]: Best epoch 8: best metric: 0.495
[09/26 13:24:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 13:24:43 visual_prompt]: Epoch 9 / 100: avg data time: 5.09e-02, avg batch time: 0.4931, average train loss: 1.2816
[09/26 13:24:44 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.6864
[09/26 13:24:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.00	top5: 87.50	
[09/26 13:24:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 13:24:51 visual_prompt]: Epoch 10 / 100: avg data time: 5.32e-02, avg batch time: 0.4973, average train loss: 1.8066
[09/26 13:24:53 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1660, average loss: 3.6576
[09/26 13:24:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 21.50	
[09/26 13:24:53 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 13:24:59 visual_prompt]: Epoch 11 / 100: avg data time: 5.76e-02, avg batch time: 0.5013, average train loss: 3.6067
[09/26 13:25:01 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1661, average loss: 3.7047
[09/26 13:25:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.50	top5: 24.50	
[09/26 13:25:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 13:25:08 visual_prompt]: Epoch 12 / 100: avg data time: 6.10e-02, avg batch time: 0.5039, average train loss: 3.3688
[09/26 13:25:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1661, average loss: 3.0206
[09/26 13:25:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 52.00	
[09/26 13:25:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 13:25:17 visual_prompt]: Epoch 13 / 100: avg data time: 5.41e-02, avg batch time: 0.4978, average train loss: 2.3461
[09/26 13:25:18 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1662, average loss: 2.6011
[09/26 13:25:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 64.00	
[09/26 13:25:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 13:25:25 visual_prompt]: Epoch 14 / 100: avg data time: 5.67e-02, avg batch time: 0.5004, average train loss: 1.6754
[09/26 13:25:27 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1663, average loss: 1.5893
[09/26 13:25:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.00	top5: 90.50	
[09/26 13:25:27 visual_prompt]: Best epoch 14: best metric: 0.600
[09/26 13:25:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 13:25:33 visual_prompt]: Epoch 15 / 100: avg data time: 5.80e-02, avg batch time: 0.5008, average train loss: 1.9280
[09/26 13:25:35 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.9212
[09/26 13:25:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.50	top5: 86.00	
[09/26 13:25:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 13:25:42 visual_prompt]: Epoch 16 / 100: avg data time: 6.32e-02, avg batch time: 0.5050, average train loss: 1.3094
[09/26 13:25:44 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1666, average loss: 1.3603
[09/26 13:25:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 13:25:44 visual_prompt]: Best epoch 16: best metric: 0.690
[09/26 13:25:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 13:25:50 visual_prompt]: Epoch 17 / 100: avg data time: 5.15e-02, avg batch time: 0.4959, average train loss: 0.8839
[09/26 13:25:52 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.1197
[09/26 13:25:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 13:25:52 visual_prompt]: Best epoch 17: best metric: 0.745
[09/26 13:25:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 13:25:59 visual_prompt]: Epoch 18 / 100: avg data time: 6.01e-02, avg batch time: 0.5027, average train loss: 0.7016
[09/26 13:26:01 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1664, average loss: 1.1099
[09/26 13:26:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 98.50	
[09/26 13:26:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 13:26:08 visual_prompt]: Epoch 19 / 100: avg data time: 6.22e-02, avg batch time: 0.5044, average train loss: 0.6135
[09/26 13:26:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1663, average loss: 1.1775
[09/26 13:26:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.00	
[09/26 13:26:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 13:26:16 visual_prompt]: Epoch 20 / 100: avg data time: 6.49e-02, avg batch time: 0.5079, average train loss: 0.6145
[09/26 13:26:18 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 1.1101
[09/26 13:26:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.50	
[09/26 13:26:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 13:26:25 visual_prompt]: Epoch 21 / 100: avg data time: 5.36e-02, avg batch time: 0.4974, average train loss: 1.1372
[09/26 13:26:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 2.1608
[09/26 13:26:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.00	top5: 90.00	
[09/26 13:26:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 13:26:33 visual_prompt]: Epoch 22 / 100: avg data time: 6.21e-02, avg batch time: 0.5048, average train loss: 1.3150
[09/26 13:26:35 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.2706
[09/26 13:26:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 97.50	
[09/26 13:26:35 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 13:26:41 visual_prompt]: Epoch 23 / 100: avg data time: 4.94e-02, avg batch time: 0.4944, average train loss: 0.7107
[09/26 13:26:43 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1668, average loss: 0.8768
[09/26 13:26:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 100.00	
[09/26 13:26:43 visual_prompt]: Best epoch 23: best metric: 0.820
[09/26 13:26:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 13:26:50 visual_prompt]: Epoch 24 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 0.5367
[09/26 13:26:51 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 1.2064
[09/26 13:26:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:26:51 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 13:26:58 visual_prompt]: Epoch 25 / 100: avg data time: 5.71e-02, avg batch time: 0.5002, average train loss: 0.6601
[09/26 13:27:00 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1666, average loss: 0.9922
[09/26 13:27:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 99.50	
[09/26 13:27:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 13:27:07 visual_prompt]: Epoch 26 / 100: avg data time: 6.27e-02, avg batch time: 0.5046, average train loss: 0.5686
[09/26 13:27:08 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 0.9982
[09/26 13:27:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 98.00	
[09/26 13:27:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 13:27:15 visual_prompt]: Epoch 27 / 100: avg data time: 6.67e-02, avg batch time: 0.5091, average train loss: 0.4905
[09/26 13:27:17 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 0.8878
[09/26 13:27:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.50	
[09/26 13:27:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 13:27:24 visual_prompt]: Epoch 28 / 100: avg data time: 4.82e-02, avg batch time: 0.4922, average train loss: 0.4311
[09/26 13:27:25 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1667, average loss: 0.8960
[09/26 13:27:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.00	
[09/26 13:27:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 13:27:32 visual_prompt]: Epoch 29 / 100: avg data time: 4.68e-02, avg batch time: 0.4910, average train loss: 1.1360
[09/26 13:27:34 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 1.3452
[09/26 13:27:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 96.00	
[09/26 13:27:34 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 13:27:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.48e-02, avg batch time: 0.4996, average train loss: 0.7396
[09/26 13:27:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.0967
[09/26 13:27:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 98.50	
[09/26 13:27:42 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 13:27:49 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e-02, avg batch time: 0.4992, average train loss: 1.4721
[09/26 13:27:51 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 1.1617
[09/26 13:27:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 96.00	
[09/26 13:27:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 13:27:57 visual_prompt]: Epoch 32 / 100: avg data time: 5.34e-02, avg batch time: 0.4974, average train loss: 1.0728
[09/26 13:27:59 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.6885
[09/26 13:27:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 97.00	
[09/26 13:27:59 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 13:28:06 visual_prompt]: Epoch 33 / 100: avg data time: 5.44e-02, avg batch time: 0.4988, average train loss: 0.6889
[09/26 13:28:07 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 0.9331
[09/26 13:28:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.50	
[09/26 13:28:07 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 13:28:14 visual_prompt]: Epoch 34 / 100: avg data time: 6.44e-02, avg batch time: 0.5061, average train loss: 0.4858
[09/26 13:28:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 0.9544
[09/26 13:28:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 13:28:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 13:28:23 visual_prompt]: Epoch 35 / 100: avg data time: 5.72e-02, avg batch time: 0.5021, average train loss: 1.2130
[09/26 13:28:24 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1664, average loss: 1.4835
[09/26 13:28:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.00	
[09/26 13:28:24 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 13:28:31 visual_prompt]: Epoch 36 / 100: avg data time: 6.15e-02, avg batch time: 0.5055, average train loss: 1.5481
[09/26 13:28:33 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.6048
[09/26 13:28:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 94.00	
[09/26 13:28:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 13:28:40 visual_prompt]: Epoch 37 / 100: avg data time: 5.04e-02, avg batch time: 0.4962, average train loss: 1.8792
[09/26 13:28:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 1.5624
[09/26 13:28:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 94.00	
[09/26 13:28:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 13:28:48 visual_prompt]: Epoch 38 / 100: avg data time: 5.35e-02, avg batch time: 0.4960, average train loss: 0.7868
[09/26 13:28:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.9680
[09/26 13:28:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 13:28:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 13:28:57 visual_prompt]: Epoch 39 / 100: avg data time: 5.89e-02, avg batch time: 0.5005, average train loss: 0.8924
[09/26 13:28:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 1.0387
[09/26 13:28:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:28:58 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 13:29:05 visual_prompt]: Epoch 40 / 100: avg data time: 5.58e-02, avg batch time: 0.4983, average train loss: 0.5169
[09/26 13:29:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.9194
[09/26 13:29:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 13:29:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 13:29:14 visual_prompt]: Epoch 41 / 100: avg data time: 6.31e-02, avg batch time: 0.5044, average train loss: 1.2322
[09/26 13:29:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.1150
[09/26 13:29:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 97.00	
[09/26 13:29:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 13:29:22 visual_prompt]: Epoch 42 / 100: avg data time: 5.03e-02, avg batch time: 0.4926, average train loss: 0.6442
[09/26 13:29:24 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 1.1350
[09/26 13:29:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 13:29:24 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 13:29:31 visual_prompt]: Epoch 43 / 100: avg data time: 5.54e-02, avg batch time: 0.4978, average train loss: 0.6262
[09/26 13:29:32 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 0.9608
[09/26 13:29:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 96.50	
[09/26 13:29:32 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 13:29:39 visual_prompt]: Epoch 44 / 100: avg data time: 5.68e-02, avg batch time: 0.4992, average train loss: 0.7838
[09/26 13:29:41 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.1922
[09/26 13:29:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 96.50	
[09/26 13:29:41 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 13:29:48 visual_prompt]: Epoch 45 / 100: avg data time: 5.86e-02, avg batch time: 0.5013, average train loss: 0.6833
[09/26 13:29:49 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1661, average loss: 1.0019
[09/26 13:29:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:29:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 13:29:56 visual_prompt]: Epoch 46 / 100: avg data time: 5.82e-02, avg batch time: 0.4999, average train loss: 0.4648
[09/26 13:29:58 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 0.8929
[09/26 13:29:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 13:29:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 13:30:04 visual_prompt]: Epoch 47 / 100: avg data time: 5.81e-02, avg batch time: 0.5005, average train loss: 0.5978
[09/26 13:30:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 2.3744
[09/26 13:30:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 44.00	top5: 73.00	
[09/26 13:30:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 13:30:13 visual_prompt]: Epoch 48 / 100: avg data time: 5.50e-02, avg batch time: 0.4981, average train loss: 1.1363
[09/26 13:30:14 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1662, average loss: 1.0859
[09/26 13:30:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 97.00	
[09/26 13:30:14 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 13:30:21 visual_prompt]: Epoch 49 / 100: avg data time: 5.40e-02, avg batch time: 0.4963, average train loss: 0.5651
[09/26 13:30:23 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 0.9790
[09/26 13:30:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 13:30:23 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 13:30:30 visual_prompt]: Epoch 50 / 100: avg data time: 4.91e-02, avg batch time: 0.4926, average train loss: 0.8677
[09/26 13:30:31 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1661, average loss: 1.2383
[09/26 13:30:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 13:30:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 13:30:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.89e-02, avg batch time: 0.4926, average train loss: 0.5477
[09/26 13:30:40 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 0.9434
[09/26 13:30:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 13:30:40 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 13:30:46 visual_prompt]: Epoch 52 / 100: avg data time: 6.06e-02, avg batch time: 0.5023, average train loss: 0.4049
[09/26 13:30:48 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 0.9750
[09/26 13:30:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 13:30:48 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 13:30:55 visual_prompt]: Epoch 53 / 100: avg data time: 5.88e-02, avg batch time: 0.5001, average train loss: 0.3884
[09/26 13:30:56 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 0.8639
[09/26 13:30:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 97.00	
[09/26 13:30:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 13:31:03 visual_prompt]: Epoch 54 / 100: avg data time: 5.15e-02, avg batch time: 0.4937, average train loss: 0.3506
[09/26 13:31:05 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.8842
[09/26 13:31:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 13:31:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 13:31:12 visual_prompt]: Epoch 55 / 100: avg data time: 5.73e-02, avg batch time: 0.5017, average train loss: 1.0413
[09/26 13:31:13 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.0969
[09/26 13:31:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 13:31:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 13:31:20 visual_prompt]: Epoch 56 / 100: avg data time: 5.04e-02, avg batch time: 0.4942, average train loss: 0.5575
[09/26 13:31:22 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1664, average loss: 0.9852
[09/26 13:31:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 97.00	
[09/26 13:31:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 13:31:28 visual_prompt]: Epoch 57 / 100: avg data time: 5.47e-02, avg batch time: 0.4965, average train loss: 0.4029
[09/26 13:31:30 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1661, average loss: 0.8834
[09/26 13:31:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 97.50	
[09/26 13:31:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 13:31:37 visual_prompt]: Epoch 58 / 100: avg data time: 6.03e-02, avg batch time: 0.5032, average train loss: 0.3059
[09/26 13:31:39 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1662, average loss: 0.8556
[09/26 13:31:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 13:31:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 13:31:46 visual_prompt]: Epoch 59 / 100: avg data time: 6.42e-02, avg batch time: 0.5058, average train loss: 0.2483
[09/26 13:31:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.7560
[09/26 13:31:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.00	
[09/26 13:31:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 13:31:54 visual_prompt]: Epoch 60 / 100: avg data time: 6.32e-02, avg batch time: 0.5052, average train loss: 0.2370
[09/26 13:31:56 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1662, average loss: 0.7530
[09/26 13:31:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 84.50	top5: 97.50	
[09/26 13:31:56 visual_prompt]: Best epoch 60: best metric: 0.845
[09/26 13:31:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 13:32:03 visual_prompt]: Epoch 61 / 100: avg data time: 5.85e-02, avg batch time: 0.5013, average train loss: 0.2273
[09/26 13:32:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 0.9021
[09/26 13:32:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 13:32:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 13:32:11 visual_prompt]: Epoch 62 / 100: avg data time: 6.43e-02, avg batch time: 0.5060, average train loss: 0.3534
[09/26 13:32:13 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 0.9583
[09/26 13:32:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 13:32:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 13:32:20 visual_prompt]: Epoch 63 / 100: avg data time: 6.02e-02, avg batch time: 0.5036, average train loss: 0.3229
[09/26 13:32:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 0.8220
[09/26 13:32:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.50	
[09/26 13:32:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 13:32:28 visual_prompt]: Epoch 64 / 100: avg data time: 4.95e-02, avg batch time: 0.4939, average train loss: 0.3755
[09/26 13:32:30 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1668, average loss: 3.6734
[09/26 13:32:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.00	top5: 30.00	
[09/26 13:32:30 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 13:32:37 visual_prompt]: Epoch 65 / 100: avg data time: 4.94e-02, avg batch time: 0.4924, average train loss: 1.1581
[09/26 13:32:38 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1663, average loss: 1.2954
[09/26 13:32:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 97.00	
[09/26 13:32:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 13:32:45 visual_prompt]: Epoch 66 / 100: avg data time: 5.38e-02, avg batch time: 0.4977, average train loss: 0.5891
[09/26 13:32:47 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 0.9003
[09/26 13:32:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 13:32:47 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 13:32:53 visual_prompt]: Epoch 67 / 100: avg data time: 5.74e-02, avg batch time: 0.5011, average train loss: 0.3474
[09/26 13:32:55 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.8892
[09/26 13:32:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.50	
[09/26 13:32:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 13:33:02 visual_prompt]: Epoch 68 / 100: avg data time: 5.27e-02, avg batch time: 0.4979, average train loss: 0.2632
[09/26 13:33:03 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 0.7833
[09/26 13:33:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 13:33:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 13:33:10 visual_prompt]: Epoch 69 / 100: avg data time: 5.32e-02, avg batch time: 0.4974, average train loss: 0.5737
[09/26 13:33:12 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 1.1805
[09/26 13:33:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 94.00	
[09/26 13:33:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 13:33:19 visual_prompt]: Epoch 70 / 100: avg data time: 6.93e-02, avg batch time: 0.5118, average train loss: 0.4800
[09/26 13:33:21 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1662, average loss: 0.8406
[09/26 13:33:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 13:33:21 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 13:33:27 visual_prompt]: Epoch 71 / 100: avg data time: 5.83e-02, avg batch time: 0.5000, average train loss: 0.3147
[09/26 13:33:29 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1663, average loss: 0.7715
[09/26 13:33:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 13:33:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 13:33:36 visual_prompt]: Epoch 72 / 100: avg data time: 5.73e-02, avg batch time: 0.5012, average train loss: 0.2138
[09/26 13:33:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1666, average loss: 0.8175
[09/26 13:33:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.00	
[09/26 13:33:38 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 13:33:45 visual_prompt]: Epoch 73 / 100: avg data time: 6.69e-02, avg batch time: 0.5091, average train loss: 0.1783
[09/26 13:33:46 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 0.7388
[09/26 13:33:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.50	
[09/26 13:33:46 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 13:33:53 visual_prompt]: Epoch 74 / 100: avg data time: 6.20e-02, avg batch time: 0.5050, average train loss: 0.1551
[09/26 13:33:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 0.7266
[09/26 13:33:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.50	
[09/26 13:33:55 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 13:34:02 visual_prompt]: Epoch 75 / 100: avg data time: 5.53e-02, avg batch time: 0.4970, average train loss: 0.1372
[09/26 13:34:03 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1664, average loss: 0.6975
[09/26 13:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 82.00	top5: 98.50	
[09/26 13:34:03 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 13:34:10 visual_prompt]: Epoch 76 / 100: avg data time: 6.14e-02, avg batch time: 0.5033, average train loss: 0.1302
[09/26 13:34:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 0.7143
[09/26 13:34:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.00	
[09/26 13:34:12 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 13:34:19 visual_prompt]: Epoch 77 / 100: avg data time: 5.23e-02, avg batch time: 0.4968, average train loss: 0.1337
[09/26 13:34:20 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 0.7659
[09/26 13:34:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 83.00	top5: 96.50	
[09/26 13:34:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 13:34:27 visual_prompt]: Epoch 78 / 100: avg data time: 6.19e-02, avg batch time: 0.5044, average train loss: 0.1397
[09/26 13:34:29 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.7502
[09/26 13:34:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 13:34:29 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 13:34:36 visual_prompt]: Epoch 79 / 100: avg data time: 6.06e-02, avg batch time: 0.5032, average train loss: 0.1326
[09/26 13:34:37 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 0.7536
[09/26 13:34:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.50	
[09/26 13:34:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 13:34:44 visual_prompt]: Epoch 80 / 100: avg data time: 5.75e-02, avg batch time: 0.5000, average train loss: 0.1259
[09/26 13:34:46 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 0.6690
[09/26 13:34:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 98.50	
[09/26 13:34:46 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 13:34:53 visual_prompt]: Epoch 81 / 100: avg data time: 6.75e-02, avg batch time: 0.5102, average train loss: 0.1180
[09/26 13:34:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.7249
[09/26 13:34:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.50	
[09/26 13:34:54 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 13:35:01 visual_prompt]: Epoch 82 / 100: avg data time: 5.23e-02, avg batch time: 0.4968, average train loss: 0.1128
[09/26 13:35:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 0.7143
[09/26 13:35:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.50	
[09/26 13:35:03 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 13:35:09 visual_prompt]: Epoch 83 / 100: avg data time: 4.76e-02, avg batch time: 0.4917, average train loss: 0.1093
[09/26 13:35:11 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1663, average loss: 0.7015
[09/26 13:35:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.50	
[09/26 13:35:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 13:35:18 visual_prompt]: Epoch 84 / 100: avg data time: 5.11e-02, avg batch time: 0.4940, average train loss: 0.1076
[09/26 13:35:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 0.7013
[09/26 13:35:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.50	
[09/26 13:35:19 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 13:35:26 visual_prompt]: Epoch 85 / 100: avg data time: 7.30e-02, avg batch time: 0.5145, average train loss: 0.1070
[09/26 13:35:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 0.6885
[09/26 13:35:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 13:35:28 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 13:35:35 visual_prompt]: Epoch 86 / 100: avg data time: 5.72e-02, avg batch time: 0.4995, average train loss: 0.1056
[09/26 13:35:36 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1664, average loss: 0.7373
[09/26 13:35:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.00	
[09/26 13:35:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 13:35:43 visual_prompt]: Epoch 87 / 100: avg data time: 5.31e-02, avg batch time: 0.4956, average train loss: 0.1040
[09/26 13:35:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1662, average loss: 0.6935
[09/26 13:35:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.50	
[09/26 13:35:45 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 13:35:52 visual_prompt]: Epoch 88 / 100: avg data time: 5.97e-02, avg batch time: 0.5019, average train loss: 0.1029
[09/26 13:35:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 0.7215
[09/26 13:35:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.50	
[09/26 13:35:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 13:36:00 visual_prompt]: Epoch 89 / 100: avg data time: 6.27e-02, avg batch time: 0.5065, average train loss: 0.1025
[09/26 13:36:02 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1663, average loss: 0.7063
[09/26 13:36:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.50	
[09/26 13:36:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 13:36:09 visual_prompt]: Epoch 90 / 100: avg data time: 5.09e-02, avg batch time: 0.4946, average train loss: 0.1019
[09/26 13:36:10 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 0.7018
[09/26 13:36:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.50	
[09/26 13:36:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 13:36:17 visual_prompt]: Epoch 91 / 100: avg data time: 5.18e-02, avg batch time: 0.4951, average train loss: 0.1018
[09/26 13:36:19 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 0.7147
[09/26 13:36:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 97.00	
[09/26 13:36:19 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 13:36:26 visual_prompt]: Epoch 92 / 100: avg data time: 6.49e-02, avg batch time: 0.5086, average train loss: 0.1013
[09/26 13:36:27 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 0.7223
[09/26 13:36:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 13:36:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 13:36:34 visual_prompt]: Epoch 93 / 100: avg data time: 5.63e-02, avg batch time: 0.4987, average train loss: 0.1011
[09/26 13:36:36 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 0.7059
[09/26 13:36:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 96.00	
[09/26 13:36:36 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 13:36:43 visual_prompt]: Epoch 94 / 100: avg data time: 6.92e-02, avg batch time: 0.5106, average train loss: 0.1008
[09/26 13:36:44 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 0.7169
[09/26 13:36:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.00	
[09/26 13:36:44 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 13:36:51 visual_prompt]: Epoch 95 / 100: avg data time: 5.28e-02, avg batch time: 0.4949, average train loss: 0.1006
[09/26 13:36:53 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1661, average loss: 0.7310
[09/26 13:36:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 13:36:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 13:37:00 visual_prompt]: Epoch 96 / 100: avg data time: 4.98e-02, avg batch time: 0.4930, average train loss: 0.1004
[09/26 13:37:01 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 0.7328
[09/26 13:37:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 13:37:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 13:37:08 visual_prompt]: Epoch 97 / 100: avg data time: 6.05e-02, avg batch time: 0.5020, average train loss: 0.1006
[09/26 13:37:10 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.7316
[09/26 13:37:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 13:37:10 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 13:37:17 visual_prompt]: Epoch 98 / 100: avg data time: 4.87e-02, avg batch time: 0.4929, average train loss: 0.1003
[09/26 13:37:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 0.7302
[09/26 13:37:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 13:37:18 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 13:37:25 visual_prompt]: Epoch 99 / 100: avg data time: 5.48e-02, avg batch time: 0.4976, average train loss: 0.1001
[09/26 13:37:27 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1663, average loss: 0.7303
[09/26 13:37:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 13:37:27 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 13:37:33 visual_prompt]: Epoch 100 / 100: avg data time: 5.30e-02, avg batch time: 0.4949, average train loss: 0.1003
[09/26 13:37:35 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1664, average loss: 0.7303
[09/26 13:37:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 13:37:35 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:37:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:37:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:37:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:37:35 visual_prompt]: Training with config:
[09/26 13:37:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:37:35 visual_prompt]: Loading training data...
[09/26 13:37:35 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:37:36 visual_prompt]: Number of images: 800
[09/26 13:37:36 visual_prompt]: Number of classes: 45 / 45
[09/26 13:37:36 visual_prompt]: Loading validation data...
[09/26 13:37:36 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:37:37 visual_prompt]: Number of images: 200
[09/26 13:37:37 visual_prompt]: Number of classes: 45 / 45
[09/26 13:37:37 visual_prompt]: Constructing models...
[09/26 13:37:39 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 13:37:39 visual_prompt]: tuned percent:0.574
[09/26 13:37:39 visual_prompt]: Device used for model: 0
[09/26 13:37:39 visual_prompt]: Setting up Evaluator...
[09/26 13:37:39 visual_prompt]: Setting up Trainer...
[09/26 13:37:39 visual_prompt]: 	Setting up the optimizer...
[09/26 13:37:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:37:46 visual_prompt]: Epoch 1 / 100: avg data time: 5.91e-02, avg batch time: 0.5019, average train loss: 3.8895
[09/26 13:37:48 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 13:37:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 13:37:48 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 13:37:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 13:37:54 visual_prompt]: Epoch 2 / 100: avg data time: 6.82e-02, avg batch time: 0.5083, average train loss: 3.8095
[09/26 13:37:56 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1658, average loss: 3.7456
[09/26 13:37:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 19.50	
[09/26 13:37:56 visual_prompt]: Best epoch 2: best metric: 0.055
[09/26 13:37:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 13:38:03 visual_prompt]: Epoch 3 / 100: avg data time: 5.79e-02, avg batch time: 0.4998, average train loss: 3.5907
[09/26 13:38:05 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 3.2753
[09/26 13:38:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 43.50	
[09/26 13:38:05 visual_prompt]: Best epoch 3: best metric: 0.110
[09/26 13:38:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 13:38:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.01e-02, avg batch time: 0.4925, average train loss: 3.0463
[09/26 13:38:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1658, average loss: 3.0786
[09/26 13:38:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 42.00	
[09/26 13:38:13 visual_prompt]: Best epoch 4: best metric: 0.155
[09/26 13:38:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 13:38:20 visual_prompt]: Epoch 5 / 100: avg data time: 5.85e-02, avg batch time: 0.5009, average train loss: 2.5910
[09/26 13:38:21 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1660, average loss: 2.6259
[09/26 13:38:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 63.00	
[09/26 13:38:21 visual_prompt]: Best epoch 5: best metric: 0.255
[09/26 13:38:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 13:38:28 visual_prompt]: Epoch 6 / 100: avg data time: 5.82e-02, avg batch time: 0.4998, average train loss: 2.2297
[09/26 13:38:30 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1659, average loss: 2.3141
[09/26 13:38:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 31.50	top5: 72.00	
[09/26 13:38:30 visual_prompt]: Best epoch 6: best metric: 0.315
[09/26 13:38:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 13:38:37 visual_prompt]: Epoch 7 / 100: avg data time: 4.77e-02, avg batch time: 0.4909, average train loss: 1.8771
[09/26 13:38:38 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.9473
[09/26 13:38:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.50	top5: 79.00	
[09/26 13:38:38 visual_prompt]: Best epoch 7: best metric: 0.455
[09/26 13:38:38 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 13:38:45 visual_prompt]: Epoch 8 / 100: avg data time: 4.84e-02, avg batch time: 0.4907, average train loss: 1.3110
[09/26 13:38:46 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1662, average loss: 1.4891
[09/26 13:38:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 88.00	
[09/26 13:38:46 visual_prompt]: Best epoch 8: best metric: 0.570
[09/26 13:38:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 13:38:53 visual_prompt]: Epoch 9 / 100: avg data time: 6.07e-02, avg batch time: 0.5031, average train loss: 1.0546
[09/26 13:38:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1660, average loss: 1.3471
[09/26 13:38:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 92.50	
[09/26 13:38:55 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 13:39:02 visual_prompt]: Epoch 10 / 100: avg data time: 6.14e-02, avg batch time: 0.5046, average train loss: 0.7376
[09/26 13:39:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 1.2716
[09/26 13:39:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 93.00	
[09/26 13:39:03 visual_prompt]: Best epoch 10: best metric: 0.630
[09/26 13:39:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 13:39:10 visual_prompt]: Epoch 11 / 100: avg data time: 6.44e-02, avg batch time: 0.5066, average train loss: 0.5552
[09/26 13:39:12 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.1915
[09/26 13:39:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.00	
[09/26 13:39:12 visual_prompt]: Best epoch 11: best metric: 0.685
[09/26 13:39:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 13:39:19 visual_prompt]: Epoch 12 / 100: avg data time: 5.63e-02, avg batch time: 0.4984, average train loss: 0.4494
[09/26 13:39:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.1682
[09/26 13:39:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 13:39:20 visual_prompt]: Best epoch 12: best metric: 0.690
[09/26 13:39:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 13:39:27 visual_prompt]: Epoch 13 / 100: avg data time: 5.41e-02, avg batch time: 0.4972, average train loss: 0.3200
[09/26 13:39:29 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 1.1540
[09/26 13:39:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 92.50	
[09/26 13:39:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 13:39:36 visual_prompt]: Epoch 14 / 100: avg data time: 5.05e-02, avg batch time: 0.4930, average train loss: 0.1872
[09/26 13:39:37 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 1.0953
[09/26 13:39:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 91.00	
[09/26 13:39:37 visual_prompt]: Best epoch 14: best metric: 0.695
[09/26 13:39:37 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 13:39:44 visual_prompt]: Epoch 15 / 100: avg data time: 5.08e-02, avg batch time: 0.4949, average train loss: 0.1723
[09/26 13:39:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1664, average loss: 1.0559
[09/26 13:39:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 91.50	
[09/26 13:39:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 13:39:52 visual_prompt]: Epoch 16 / 100: avg data time: 5.19e-02, avg batch time: 0.4934, average train loss: 0.1207
[09/26 13:39:54 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1661, average loss: 1.0488
[09/26 13:39:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 13:39:54 visual_prompt]: Best epoch 16: best metric: 0.710
[09/26 13:39:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 13:40:01 visual_prompt]: Epoch 17 / 100: avg data time: 5.33e-02, avg batch time: 0.4966, average train loss: 0.0903
[09/26 13:40:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.0296
[09/26 13:40:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 13:40:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 13:40:09 visual_prompt]: Epoch 18 / 100: avg data time: 5.74e-02, avg batch time: 0.5009, average train loss: 0.0733
[09/26 13:40:11 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.0359
[09/26 13:40:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 96.00	
[09/26 13:40:11 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 13:40:18 visual_prompt]: Epoch 19 / 100: avg data time: 5.09e-02, avg batch time: 0.4947, average train loss: 0.0488
[09/26 13:40:19 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.9738
[09/26 13:40:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 96.00	
[09/26 13:40:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 13:40:26 visual_prompt]: Epoch 20 / 100: avg data time: 5.51e-02, avg batch time: 0.4976, average train loss: 0.0337
[09/26 13:40:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 0.9524
[09/26 13:40:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 96.50	
[09/26 13:40:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 13:40:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.46e-02, avg batch time: 0.4968, average train loss: 0.0281
[09/26 13:40:36 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 0.9695
[09/26 13:40:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.00	
[09/26 13:40:36 visual_prompt]: Best epoch 21: best metric: 0.725
[09/26 13:40:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 13:40:43 visual_prompt]: Epoch 22 / 100: avg data time: 5.83e-02, avg batch time: 0.4995, average train loss: 0.0218
[09/26 13:40:44 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.9321
[09/26 13:40:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 97.50	
[09/26 13:40:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 13:40:51 visual_prompt]: Epoch 23 / 100: avg data time: 5.76e-02, avg batch time: 0.5004, average train loss: 0.0193
[09/26 13:40:53 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 0.8943
[09/26 13:40:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.50	
[09/26 13:40:53 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 13:41:00 visual_prompt]: Epoch 24 / 100: avg data time: 4.85e-02, avg batch time: 0.4915, average train loss: 0.0172
[09/26 13:41:01 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.8851
[09/26 13:41:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 96.50	
[09/26 13:41:01 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 13:41:08 visual_prompt]: Epoch 25 / 100: avg data time: 5.41e-02, avg batch time: 0.4970, average train loss: 0.0168
[09/26 13:41:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 0.8816
[09/26 13:41:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 96.00	
[09/26 13:41:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 13:41:17 visual_prompt]: Epoch 26 / 100: avg data time: 6.25e-02, avg batch time: 0.5044, average train loss: 0.0158
[09/26 13:41:18 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 0.8854
[09/26 13:41:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 97.00	
[09/26 13:41:18 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 13:41:25 visual_prompt]: Epoch 27 / 100: avg data time: 4.87e-02, avg batch time: 0.4920, average train loss: 0.0154
[09/26 13:41:27 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 0.8924
[09/26 13:41:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 96.50	
[09/26 13:41:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 13:41:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.64e-02, avg batch time: 0.4979, average train loss: 0.0153
[09/26 13:41:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 0.8923
[09/26 13:41:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 97.50	
[09/26 13:41:35 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 13:41:42 visual_prompt]: Epoch 29 / 100: avg data time: 6.29e-02, avg batch time: 0.5057, average train loss: 0.0151
[09/26 13:41:44 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1662, average loss: 0.8692
[09/26 13:41:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 97.50	
[09/26 13:41:44 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 13:41:50 visual_prompt]: Epoch 30 / 100: avg data time: 5.30e-02, avg batch time: 0.4958, average train loss: 0.0151
[09/26 13:41:52 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1662, average loss: 0.8865
[09/26 13:41:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.50	
[09/26 13:41:52 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 13:41:59 visual_prompt]: Epoch 31 / 100: avg data time: 5.19e-02, avg batch time: 0.4960, average train loss: 0.0153
[09/26 13:42:00 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.8773
[09/26 13:42:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.50	
[09/26 13:42:00 visual_prompt]: Best epoch 31: best metric: 0.735
[09/26 13:42:00 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 13:42:07 visual_prompt]: Epoch 32 / 100: avg data time: 6.80e-02, avg batch time: 0.5098, average train loss: 0.0151
[09/26 13:42:09 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 0.8938
[09/26 13:42:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 96.00	
[09/26 13:42:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 13:42:16 visual_prompt]: Epoch 33 / 100: avg data time: 5.46e-02, avg batch time: 0.4973, average train loss: 0.0157
[09/26 13:42:17 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 0.8874
[09/26 13:42:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.00	
[09/26 13:42:17 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 13:42:24 visual_prompt]: Epoch 34 / 100: avg data time: 5.38e-02, avg batch time: 0.4979, average train loss: 0.0159
[09/26 13:42:26 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1663, average loss: 0.8872
[09/26 13:42:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 96.00	
[09/26 13:42:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 13:42:33 visual_prompt]: Epoch 35 / 100: avg data time: 5.10e-02, avg batch time: 0.4946, average train loss: 0.0155
[09/26 13:42:34 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 0.9150
[09/26 13:42:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.50	
[09/26 13:42:34 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 13:42:41 visual_prompt]: Epoch 36 / 100: avg data time: 6.30e-02, avg batch time: 0.5058, average train loss: 0.0154
[09/26 13:42:43 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1663, average loss: 0.8904
[09/26 13:42:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.00	
[09/26 13:42:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 13:42:50 visual_prompt]: Epoch 37 / 100: avg data time: 6.16e-02, avg batch time: 0.5027, average train loss: 0.0152
[09/26 13:42:51 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 0.8860
[09/26 13:42:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.50	
[09/26 13:42:51 visual_prompt]: Best epoch 37: best metric: 0.740
[09/26 13:42:51 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 13:42:58 visual_prompt]: Epoch 38 / 100: avg data time: 5.72e-02, avg batch time: 0.4997, average train loss: 0.0149
[09/26 13:42:59 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1661, average loss: 0.8866
[09/26 13:42:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.00	
[09/26 13:42:59 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 13:43:06 visual_prompt]: Epoch 39 / 100: avg data time: 5.23e-02, avg batch time: 0.4944, average train loss: 0.0150
[09/26 13:43:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.8796
[09/26 13:43:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 13:43:08 visual_prompt]: Best epoch 39: best metric: 0.750
[09/26 13:43:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 13:43:15 visual_prompt]: Epoch 40 / 100: avg data time: 6.46e-02, avg batch time: 0.5059, average train loss: 0.0143
[09/26 13:43:16 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 0.8918
[09/26 13:43:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.00	
[09/26 13:43:16 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 13:43:23 visual_prompt]: Epoch 41 / 100: avg data time: 6.32e-02, avg batch time: 0.5041, average train loss: 0.0144
[09/26 13:43:25 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 0.8730
[09/26 13:43:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 13:43:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 13:43:32 visual_prompt]: Epoch 42 / 100: avg data time: 5.43e-02, avg batch time: 0.4971, average train loss: 0.0139
[09/26 13:43:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 0.8535
[09/26 13:43:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 94.50	
[09/26 13:43:33 visual_prompt]: Best epoch 42: best metric: 0.770
[09/26 13:43:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 13:43:40 visual_prompt]: Epoch 43 / 100: avg data time: 5.54e-02, avg batch time: 0.4986, average train loss: 0.0136
[09/26 13:43:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 0.8793
[09/26 13:43:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 94.50	
[09/26 13:43:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 13:43:48 visual_prompt]: Epoch 44 / 100: avg data time: 4.70e-02, avg batch time: 0.4910, average train loss: 0.0136
[09/26 13:43:50 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1664, average loss: 0.8550
[09/26 13:43:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 13:43:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 13:43:57 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e-02, avg batch time: 0.4919, average train loss: 0.0137
[09/26 13:43:58 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 0.9071
[09/26 13:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.00	
[09/26 13:43:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 13:44:05 visual_prompt]: Epoch 46 / 100: avg data time: 4.84e-02, avg batch time: 0.4907, average train loss: 0.0140
[09/26 13:44:07 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1661, average loss: 0.8545
[09/26 13:44:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.50	
[09/26 13:44:07 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 13:44:14 visual_prompt]: Epoch 47 / 100: avg data time: 5.19e-02, avg batch time: 0.4972, average train loss: 0.0139
[09/26 13:44:15 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 0.8586
[09/26 13:44:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 13:44:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 13:44:22 visual_prompt]: Epoch 48 / 100: avg data time: 5.99e-02, avg batch time: 0.5022, average train loss: 0.0134
[09/26 13:44:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1668, average loss: 0.8939
[09/26 13:44:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.50	
[09/26 13:44:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 13:44:31 visual_prompt]: Epoch 49 / 100: avg data time: 4.91e-02, avg batch time: 0.4913, average train loss: 0.0133
[09/26 13:44:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 0.8574
[09/26 13:44:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 13:44:32 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 13:44:39 visual_prompt]: Epoch 50 / 100: avg data time: 5.25e-02, avg batch time: 0.4960, average train loss: 0.0132
[09/26 13:44:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1663, average loss: 0.8644
[09/26 13:44:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 13:44:41 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 13:44:47 visual_prompt]: Epoch 51 / 100: avg data time: 5.89e-02, avg batch time: 0.5003, average train loss: 0.0131
[09/26 13:44:49 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 0.8606
[09/26 13:44:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 13:44:49 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 13:44:56 visual_prompt]: Epoch 52 / 100: avg data time: 5.26e-02, avg batch time: 0.4962, average train loss: 0.0154
[09/26 13:44:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 0.9165
[09/26 13:44:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 94.00	
[09/26 13:44:57 visual_prompt]: Best epoch 52: best metric: 0.780
[09/26 13:44:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 13:45:04 visual_prompt]: Epoch 53 / 100: avg data time: 5.20e-02, avg batch time: 0.4971, average train loss: 0.0181
[09/26 13:45:06 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 0.9056
[09/26 13:45:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.50	
[09/26 13:45:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 13:45:13 visual_prompt]: Epoch 54 / 100: avg data time: 5.07e-02, avg batch time: 0.4930, average train loss: 0.0188
[09/26 13:45:14 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.9703
[09/26 13:45:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 13:45:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 13:45:21 visual_prompt]: Epoch 55 / 100: avg data time: 5.04e-02, avg batch time: 0.4932, average train loss: 0.0236
[09/26 13:45:23 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1665, average loss: 1.0869
[09/26 13:45:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 13:45:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 13:45:30 visual_prompt]: Epoch 56 / 100: avg data time: 5.17e-02, avg batch time: 0.4960, average train loss: 0.0775
[09/26 13:45:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.3509
[09/26 13:45:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 93.00	
[09/26 13:45:31 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 13:45:38 visual_prompt]: Epoch 57 / 100: avg data time: 5.64e-02, avg batch time: 0.4991, average train loss: 0.5337
[09/26 13:45:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 1.7495
[09/26 13:45:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.00	top5: 85.00	
[09/26 13:45:40 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 13:45:47 visual_prompt]: Epoch 58 / 100: avg data time: 5.72e-02, avg batch time: 0.4985, average train loss: 0.7116
[09/26 13:45:48 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 1.2073
[09/26 13:45:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.00	
[09/26 13:45:48 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 13:45:55 visual_prompt]: Epoch 59 / 100: avg data time: 4.98e-02, avg batch time: 0.4918, average train loss: 0.3836
[09/26 13:45:57 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 0.8846
[09/26 13:45:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 13:45:57 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 13:46:03 visual_prompt]: Epoch 60 / 100: avg data time: 5.76e-02, avg batch time: 0.4996, average train loss: 0.2033
[09/26 13:46:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 0.9569
[09/26 13:46:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 97.00	
[09/26 13:46:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 13:46:12 visual_prompt]: Epoch 61 / 100: avg data time: 5.28e-02, avg batch time: 0.4962, average train loss: 0.1352
[09/26 13:46:14 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1664, average loss: 0.8905
[09/26 13:46:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 13:46:14 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 13:46:20 visual_prompt]: Epoch 62 / 100: avg data time: 4.49e-02, avg batch time: 0.4888, average train loss: 0.0810
[09/26 13:46:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 0.9467
[09/26 13:46:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 13:46:22 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 13:46:29 visual_prompt]: Epoch 63 / 100: avg data time: 4.85e-02, avg batch time: 0.4919, average train loss: 0.0526
[09/26 13:46:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 0.8464
[09/26 13:46:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 13:46:30 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 13:46:37 visual_prompt]: Epoch 64 / 100: avg data time: 4.85e-02, avg batch time: 0.4931, average train loss: 0.0429
[09/26 13:46:39 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 0.8573
[09/26 13:46:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 97.00	
[09/26 13:46:39 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 13:46:46 visual_prompt]: Epoch 65 / 100: avg data time: 5.12e-02, avg batch time: 0.4939, average train loss: 0.0311
[09/26 13:46:47 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 0.8997
[09/26 13:46:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.50	
[09/26 13:46:47 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 13:46:54 visual_prompt]: Epoch 66 / 100: avg data time: 5.67e-02, avg batch time: 0.4997, average train loss: 0.0292
[09/26 13:46:56 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 0.8842
[09/26 13:46:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:46:56 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 13:47:02 visual_prompt]: Epoch 67 / 100: avg data time: 5.46e-02, avg batch time: 0.4966, average train loss: 0.0225
[09/26 13:47:04 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 0.8662
[09/26 13:47:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 13:47:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 13:47:11 visual_prompt]: Epoch 68 / 100: avg data time: 6.26e-02, avg batch time: 0.5058, average train loss: 0.0177
[09/26 13:47:13 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 0.8656
[09/26 13:47:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:47:13 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 13:47:19 visual_prompt]: Epoch 69 / 100: avg data time: 5.79e-02, avg batch time: 0.5007, average train loss: 0.0162
[09/26 13:47:21 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 0.8651
[09/26 13:47:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 13:47:21 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 13:47:28 visual_prompt]: Epoch 70 / 100: avg data time: 6.18e-02, avg batch time: 0.5045, average train loss: 0.0151
[09/26 13:47:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 0.8620
[09/26 13:47:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:47:29 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 13:47:36 visual_prompt]: Epoch 71 / 100: avg data time: 5.14e-02, avg batch time: 0.4949, average train loss: 0.0145
[09/26 13:47:38 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 0.8644
[09/26 13:47:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 13:47:38 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 13:47:45 visual_prompt]: Epoch 72 / 100: avg data time: 5.64e-02, avg batch time: 0.4985, average train loss: 0.0141
[09/26 13:47:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 0.8670
[09/26 13:47:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:47:46 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 13:47:53 visual_prompt]: Epoch 73 / 100: avg data time: 5.54e-02, avg batch time: 0.4984, average train loss: 0.0136
[09/26 13:47:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 0.8655
[09/26 13:47:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 13:47:55 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 13:48:01 visual_prompt]: Epoch 74 / 100: avg data time: 5.18e-02, avg batch time: 0.4948, average train loss: 0.0137
[09/26 13:48:03 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1665, average loss: 0.8630
[09/26 13:48:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:48:03 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 13:48:10 visual_prompt]: Epoch 75 / 100: avg data time: 5.71e-02, avg batch time: 0.5007, average train loss: 0.0133
[09/26 13:48:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1665, average loss: 0.8643
[09/26 13:48:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:48:12 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 13:48:18 visual_prompt]: Epoch 76 / 100: avg data time: 4.88e-02, avg batch time: 0.4929, average train loss: 0.0130
[09/26 13:48:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.8661
[09/26 13:48:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 96.00	
[09/26 13:48:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 13:48:27 visual_prompt]: Epoch 77 / 100: avg data time: 5.25e-02, avg batch time: 0.4951, average train loss: 0.0134
[09/26 13:48:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 0.8655
[09/26 13:48:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:48:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 13:48:35 visual_prompt]: Epoch 78 / 100: avg data time: 5.31e-02, avg batch time: 0.4972, average train loss: 0.0130
[09/26 13:48:37 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 0.8621
[09/26 13:48:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:48:37 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 13:48:44 visual_prompt]: Epoch 79 / 100: avg data time: 5.10e-02, avg batch time: 0.4941, average train loss: 0.0129
[09/26 13:48:45 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1665, average loss: 0.8584
[09/26 13:48:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 13:48:45 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 13:48:52 visual_prompt]: Epoch 80 / 100: avg data time: 4.98e-02, avg batch time: 0.4927, average train loss: 0.0128
[09/26 13:48:54 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.8604
[09/26 13:48:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:48:54 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 13:49:00 visual_prompt]: Epoch 81 / 100: avg data time: 5.01e-02, avg batch time: 0.4937, average train loss: 0.0129
[09/26 13:49:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 0.8584
[09/26 13:49:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 13:49:02 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 13:49:09 visual_prompt]: Epoch 82 / 100: avg data time: 6.01e-02, avg batch time: 0.5029, average train loss: 0.0128
[09/26 13:49:10 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 0.8595
[09/26 13:49:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:49:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 13:49:17 visual_prompt]: Epoch 83 / 100: avg data time: 5.32e-02, avg batch time: 0.4974, average train loss: 0.0127
[09/26 13:49:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1665, average loss: 0.8582
[09/26 13:49:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:49:19 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 13:49:26 visual_prompt]: Epoch 84 / 100: avg data time: 6.01e-02, avg batch time: 0.5045, average train loss: 0.0128
[09/26 13:49:27 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.8545
[09/26 13:49:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 13:49:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 13:49:34 visual_prompt]: Epoch 85 / 100: avg data time: 4.97e-02, avg batch time: 0.4930, average train loss: 0.0127
[09/26 13:49:36 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.8544
[09/26 13:49:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:49:36 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 13:49:43 visual_prompt]: Epoch 86 / 100: avg data time: 5.15e-02, avg batch time: 0.4962, average train loss: 0.0125
[09/26 13:49:44 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1661, average loss: 0.8542
[09/26 13:49:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:49:44 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 13:49:51 visual_prompt]: Epoch 87 / 100: avg data time: 5.79e-02, avg batch time: 0.5013, average train loss: 0.0126
[09/26 13:49:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 0.8548
[09/26 13:49:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:49:53 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 13:50:00 visual_prompt]: Epoch 88 / 100: avg data time: 5.53e-02, avg batch time: 0.4997, average train loss: 0.0125
[09/26 13:50:01 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 0.8558
[09/26 13:50:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:01 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 13:50:08 visual_prompt]: Epoch 89 / 100: avg data time: 4.99e-02, avg batch time: 0.4925, average train loss: 0.0127
[09/26 13:50:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 0.8570
[09/26 13:50:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 13:50:16 visual_prompt]: Epoch 90 / 100: avg data time: 5.43e-02, avg batch time: 0.4972, average train loss: 0.0125
[09/26 13:50:18 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 0.8563
[09/26 13:50:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:18 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 13:50:25 visual_prompt]: Epoch 91 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 0.0124
[09/26 13:50:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1662, average loss: 0.8560
[09/26 13:50:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 13:50:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.60e-02, avg batch time: 0.5003, average train loss: 0.0124
[09/26 13:50:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 0.8555
[09/26 13:50:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:35 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 13:50:42 visual_prompt]: Epoch 93 / 100: avg data time: 5.27e-02, avg batch time: 0.4946, average train loss: 0.0124
[09/26 13:50:43 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 0.8551
[09/26 13:50:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 13:50:50 visual_prompt]: Epoch 94 / 100: avg data time: 4.78e-02, avg batch time: 0.4907, average train loss: 0.0125
[09/26 13:50:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 0.8548
[09/26 13:50:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:50:52 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 13:50:58 visual_prompt]: Epoch 95 / 100: avg data time: 5.00e-02, avg batch time: 0.4948, average train loss: 0.0125
[09/26 13:51:00 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8549
[09/26 13:51:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:00 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 13:51:07 visual_prompt]: Epoch 96 / 100: avg data time: 5.24e-02, avg batch time: 0.4955, average train loss: 0.0123
[09/26 13:51:08 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.8549
[09/26 13:51:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 13:51:15 visual_prompt]: Epoch 97 / 100: avg data time: 5.59e-02, avg batch time: 0.4991, average train loss: 0.0126
[09/26 13:51:17 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 0.8548
[09/26 13:51:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 13:51:24 visual_prompt]: Epoch 98 / 100: avg data time: 5.66e-02, avg batch time: 0.4984, average train loss: 0.0128
[09/26 13:51:25 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 0.8548
[09/26 13:51:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 13:51:32 visual_prompt]: Epoch 99 / 100: avg data time: 5.74e-02, avg batch time: 0.4990, average train loss: 0.0123
[09/26 13:51:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1665, average loss: 0.8547
[09/26 13:51:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 13:51:40 visual_prompt]: Epoch 100 / 100: avg data time: 4.92e-02, avg batch time: 0.4916, average train loss: 0.0123
[09/26 13:51:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1663, average loss: 0.8547
[09/26 13:51:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:51:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 13:51:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 13:51:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 13:51:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 13:51:42 visual_prompt]: Training with config:
[09/26 13:51:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 13:51:42 visual_prompt]: Loading training data...
[09/26 13:51:42 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:51:43 visual_prompt]: Number of images: 800
[09/26 13:51:43 visual_prompt]: Number of classes: 45 / 45
[09/26 13:51:43 visual_prompt]: Loading validation data...
[09/26 13:51:43 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 13:51:44 visual_prompt]: Number of images: 200
[09/26 13:51:44 visual_prompt]: Number of classes: 45 / 45
[09/26 13:51:44 visual_prompt]: Constructing models...
[09/26 13:51:46 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 13:51:46 visual_prompt]: tuned percent:0.574
[09/26 13:51:46 visual_prompt]: Device used for model: 0
[09/26 13:51:46 visual_prompt]: Setting up Evaluator...
[09/26 13:51:46 visual_prompt]: Setting up Trainer...
[09/26 13:51:46 visual_prompt]: 	Setting up the optimizer...
[09/26 13:51:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 13:51:53 visual_prompt]: Epoch 1 / 100: avg data time: 6.47e-02, avg batch time: 0.5056, average train loss: 3.9004
[09/26 13:51:55 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 13:51:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 13:51:55 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 13:51:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 13:52:02 visual_prompt]: Epoch 2 / 100: avg data time: 6.30e-02, avg batch time: 0.5049, average train loss: 3.8077
[09/26 13:52:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 3.7586
[09/26 13:52:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 17.00	
[09/26 13:52:04 visual_prompt]: Best epoch 2: best metric: 0.060
[09/26 13:52:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 13:52:11 visual_prompt]: Epoch 3 / 100: avg data time: 6.21e-02, avg batch time: 0.5047, average train loss: 3.6658
[09/26 13:52:12 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1655, average loss: 3.3861
[09/26 13:52:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.00	top5: 38.00	
[09/26 13:52:12 visual_prompt]: Best epoch 3: best metric: 0.100
[09/26 13:52:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 13:52:19 visual_prompt]: Epoch 4 / 100: avg data time: 5.56e-02, avg batch time: 0.4974, average train loss: 3.1572
[09/26 13:52:21 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1659, average loss: 2.9799
[09/26 13:52:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 49.50	
[09/26 13:52:21 visual_prompt]: Best epoch 4: best metric: 0.225
[09/26 13:52:21 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 13:52:28 visual_prompt]: Epoch 5 / 100: avg data time: 5.90e-02, avg batch time: 0.4998, average train loss: 2.7736
[09/26 13:52:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1658, average loss: 2.8017
[09/26 13:52:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 54.50	
[09/26 13:52:29 visual_prompt]: Best epoch 5: best metric: 0.270
[09/26 13:52:29 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 13:52:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.10e-02, avg batch time: 0.4926, average train loss: 2.2574
[09/26 13:52:38 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1658, average loss: 2.1640
[09/26 13:52:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 39.00	top5: 71.50	
[09/26 13:52:38 visual_prompt]: Best epoch 6: best metric: 0.390
[09/26 13:52:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 13:52:45 visual_prompt]: Epoch 7 / 100: avg data time: 6.27e-02, avg batch time: 0.5028, average train loss: 1.8130
[09/26 13:52:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 1.8473
[09/26 13:52:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.50	top5: 78.00	
[09/26 13:52:46 visual_prompt]: Best epoch 7: best metric: 0.475
[09/26 13:52:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 13:52:53 visual_prompt]: Epoch 8 / 100: avg data time: 5.22e-02, avg batch time: 0.4942, average train loss: 1.3933
[09/26 13:52:55 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1660, average loss: 1.6925
[09/26 13:52:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.50	top5: 88.00	
[09/26 13:52:55 visual_prompt]: Best epoch 8: best metric: 0.505
[09/26 13:52:55 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 13:53:02 visual_prompt]: Epoch 9 / 100: avg data time: 6.11e-02, avg batch time: 0.5025, average train loss: 1.0004
[09/26 13:53:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1660, average loss: 1.4663
[09/26 13:53:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.50	top5: 88.50	
[09/26 13:53:03 visual_prompt]: Best epoch 9: best metric: 0.555
[09/26 13:53:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 13:53:10 visual_prompt]: Epoch 10 / 100: avg data time: 6.59e-02, avg batch time: 0.5079, average train loss: 0.7535
[09/26 13:53:12 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1658, average loss: 1.4517
[09/26 13:53:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.00	top5: 87.50	
[09/26 13:53:12 visual_prompt]: Best epoch 10: best metric: 0.600
[09/26 13:53:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 13:53:19 visual_prompt]: Epoch 11 / 100: avg data time: 6.13e-02, avg batch time: 0.5028, average train loss: 0.5522
[09/26 13:53:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1659, average loss: 1.1060
[09/26 13:53:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 94.00	
[09/26 13:53:20 visual_prompt]: Best epoch 11: best metric: 0.655
[09/26 13:53:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 13:53:27 visual_prompt]: Epoch 12 / 100: avg data time: 6.25e-02, avg batch time: 0.5034, average train loss: 0.3749
[09/26 13:53:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1657, average loss: 1.3309
[09/26 13:53:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 88.50	
[09/26 13:53:29 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 13:53:36 visual_prompt]: Epoch 13 / 100: avg data time: 5.84e-02, avg batch time: 0.4993, average train loss: 0.2812
[09/26 13:53:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1659, average loss: 1.1208
[09/26 13:53:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 90.50	
[09/26 13:53:37 visual_prompt]: Best epoch 13: best metric: 0.660
[09/26 13:53:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 13:53:44 visual_prompt]: Epoch 14 / 100: avg data time: 6.70e-02, avg batch time: 0.5072, average train loss: 0.1773
[09/26 13:53:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1658, average loss: 1.0831
[09/26 13:53:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 13:53:46 visual_prompt]: Best epoch 14: best metric: 0.700
[09/26 13:53:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 13:53:53 visual_prompt]: Epoch 15 / 100: avg data time: 7.16e-02, avg batch time: 0.5119, average train loss: 0.1453
[09/26 13:53:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1658, average loss: 1.0387
[09/26 13:53:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.50	
[09/26 13:53:55 visual_prompt]: Best epoch 15: best metric: 0.725
[09/26 13:53:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 13:54:02 visual_prompt]: Epoch 16 / 100: avg data time: 6.76e-02, avg batch time: 0.5087, average train loss: 0.0767
[09/26 13:54:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1656, average loss: 0.9704
[09/26 13:54:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 13:54:03 visual_prompt]: Best epoch 16: best metric: 0.745
[09/26 13:54:03 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 13:54:10 visual_prompt]: Epoch 17 / 100: avg data time: 5.91e-02, avg batch time: 0.5003, average train loss: 0.0404
[09/26 13:54:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1656, average loss: 0.9379
[09/26 13:54:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 13:54:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 13:54:19 visual_prompt]: Epoch 18 / 100: avg data time: 5.33e-02, avg batch time: 0.4950, average train loss: 0.0290
[09/26 13:54:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1657, average loss: 0.8840
[09/26 13:54:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 13:54:20 visual_prompt]: Best epoch 18: best metric: 0.775
[09/26 13:54:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 13:54:27 visual_prompt]: Epoch 19 / 100: avg data time: 6.24e-02, avg batch time: 0.5040, average train loss: 0.0220
[09/26 13:54:29 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1659, average loss: 0.9016
[09/26 13:54:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 95.00	
[09/26 13:54:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 13:54:36 visual_prompt]: Epoch 20 / 100: avg data time: 6.55e-02, avg batch time: 0.5060, average train loss: 0.0205
[09/26 13:54:37 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1661, average loss: 0.8411
[09/26 13:54:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.50	
[09/26 13:54:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 13:54:44 visual_prompt]: Epoch 21 / 100: avg data time: 6.56e-02, avg batch time: 0.5070, average train loss: 0.0119
[09/26 13:54:46 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1660, average loss: 0.8547
[09/26 13:54:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 97.00	
[09/26 13:54:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 13:54:53 visual_prompt]: Epoch 22 / 100: avg data time: 5.33e-02, avg batch time: 0.4946, average train loss: 0.0099
[09/26 13:54:54 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1660, average loss: 0.8974
[09/26 13:54:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 13:54:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 13:55:01 visual_prompt]: Epoch 23 / 100: avg data time: 4.81e-02, avg batch time: 0.4903, average train loss: 0.0078
[09/26 13:55:03 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1660, average loss: 0.8671
[09/26 13:55:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:55:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 13:55:09 visual_prompt]: Epoch 24 / 100: avg data time: 5.15e-02, avg batch time: 0.4929, average train loss: 0.0067
[09/26 13:55:11 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1661, average loss: 0.8458
[09/26 13:55:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:55:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 13:55:18 visual_prompt]: Epoch 25 / 100: avg data time: 5.74e-02, avg batch time: 0.5002, average train loss: 0.0057
[09/26 13:55:19 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 0.8494
[09/26 13:55:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:55:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 13:55:26 visual_prompt]: Epoch 26 / 100: avg data time: 7.00e-02, avg batch time: 0.5116, average train loss: 0.0054
[09/26 13:55:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1660, average loss: 0.8529
[09/26 13:55:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:55:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 13:55:35 visual_prompt]: Epoch 27 / 100: avg data time: 5.26e-02, avg batch time: 0.4935, average train loss: 0.0052
[09/26 13:55:36 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1660, average loss: 0.8650
[09/26 13:55:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:55:36 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 13:55:43 visual_prompt]: Epoch 28 / 100: avg data time: 6.20e-02, avg batch time: 0.5037, average train loss: 0.0052
[09/26 13:55:45 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 0.8645
[09/26 13:55:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 13:55:45 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 13:55:52 visual_prompt]: Epoch 29 / 100: avg data time: 5.00e-02, avg batch time: 0.4912, average train loss: 0.0052
[09/26 13:55:53 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1661, average loss: 0.8754
[09/26 13:55:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 13:55:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 13:56:00 visual_prompt]: Epoch 30 / 100: avg data time: 6.13e-02, avg batch time: 0.5022, average train loss: 0.0046
[09/26 13:56:02 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 0.8709
[09/26 13:56:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 13:56:02 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 13:56:09 visual_prompt]: Epoch 31 / 100: avg data time: 6.40e-02, avg batch time: 0.5056, average train loss: 0.0043
[09/26 13:56:10 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8674
[09/26 13:56:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:56:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 13:56:17 visual_prompt]: Epoch 32 / 100: avg data time: 5.66e-02, avg batch time: 0.4998, average train loss: 0.0045
[09/26 13:56:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1663, average loss: 0.8634
[09/26 13:56:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 13:56:19 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 13:56:26 visual_prompt]: Epoch 33 / 100: avg data time: 5.10e-02, avg batch time: 0.4925, average train loss: 0.0043
[09/26 13:56:27 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 0.8497
[09/26 13:56:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:56:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 13:56:34 visual_prompt]: Epoch 34 / 100: avg data time: 6.97e-02, avg batch time: 0.5113, average train loss: 0.0038
[09/26 13:56:36 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 0.8478
[09/26 13:56:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 13:56:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 13:56:43 visual_prompt]: Epoch 35 / 100: avg data time: 5.50e-02, avg batch time: 0.4970, average train loss: 0.0036
[09/26 13:56:44 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1663, average loss: 0.8494
[09/26 13:56:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 13:56:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 13:56:51 visual_prompt]: Epoch 36 / 100: avg data time: 6.23e-02, avg batch time: 0.5042, average train loss: 0.0038
[09/26 13:56:53 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1662, average loss: 0.8484
[09/26 13:56:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 13:56:53 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 13:57:00 visual_prompt]: Epoch 37 / 100: avg data time: 6.57e-02, avg batch time: 0.5080, average train loss: 0.0036
[09/26 13:57:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 0.8485
[09/26 13:57:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 13:57:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 13:57:08 visual_prompt]: Epoch 38 / 100: avg data time: 5.57e-02, avg batch time: 0.4987, average train loss: 0.0036
[09/26 13:57:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.8491
[09/26 13:57:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 13:57:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 13:57:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.75e-02, avg batch time: 0.4988, average train loss: 0.0035
[09/26 13:57:18 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1663, average loss: 0.8492
[09/26 13:57:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:57:18 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 13:57:25 visual_prompt]: Epoch 40 / 100: avg data time: 6.06e-02, avg batch time: 0.5031, average train loss: 0.0034
[09/26 13:57:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 0.8532
[09/26 13:57:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:57:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 13:57:34 visual_prompt]: Epoch 41 / 100: avg data time: 5.72e-02, avg batch time: 0.4996, average train loss: 0.0035
[09/26 13:57:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 0.8579
[09/26 13:57:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:57:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 13:57:42 visual_prompt]: Epoch 42 / 100: avg data time: 5.41e-02, avg batch time: 0.4957, average train loss: 0.0032
[09/26 13:57:44 visual_prompt]: Inference (val):avg data time: 4.46e-05, avg batch time: 0.1662, average loss: 0.8550
[09/26 13:57:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:57:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 13:57:50 visual_prompt]: Epoch 43 / 100: avg data time: 5.17e-02, avg batch time: 0.4937, average train loss: 0.0032
[09/26 13:57:52 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 0.8505
[09/26 13:57:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:57:52 visual_prompt]: Best epoch 43: best metric: 0.780
[09/26 13:57:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 13:57:59 visual_prompt]: Epoch 44 / 100: avg data time: 5.92e-02, avg batch time: 0.5013, average train loss: 0.0032
[09/26 13:58:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 0.8486
[09/26 13:58:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 13:58:01 visual_prompt]: Best epoch 44: best metric: 0.785
[09/26 13:58:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 13:58:07 visual_prompt]: Epoch 45 / 100: avg data time: 5.42e-02, avg batch time: 0.4962, average train loss: 0.0032
[09/26 13:58:09 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1660, average loss: 0.8489
[09/26 13:58:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:58:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 13:58:16 visual_prompt]: Epoch 46 / 100: avg data time: 5.32e-02, avg batch time: 0.4962, average train loss: 0.0031
[09/26 13:58:17 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1662, average loss: 0.8430
[09/26 13:58:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:58:17 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 13:58:24 visual_prompt]: Epoch 47 / 100: avg data time: 5.03e-02, avg batch time: 0.4941, average train loss: 0.0032
[09/26 13:58:26 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 0.8370
[09/26 13:58:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 13:58:26 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 13:58:33 visual_prompt]: Epoch 48 / 100: avg data time: 6.10e-02, avg batch time: 0.5026, average train loss: 0.0031
[09/26 13:58:34 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.8413
[09/26 13:58:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 13:58:34 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 13:58:41 visual_prompt]: Epoch 49 / 100: avg data time: 4.84e-02, avg batch time: 0.4914, average train loss: 0.0030
[09/26 13:58:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 0.8422
[09/26 13:58:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:58:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 13:58:49 visual_prompt]: Epoch 50 / 100: avg data time: 5.10e-02, avg batch time: 0.4937, average train loss: 0.0029
[09/26 13:58:51 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 0.8461
[09/26 13:58:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:58:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 13:58:58 visual_prompt]: Epoch 51 / 100: avg data time: 5.32e-02, avg batch time: 0.4964, average train loss: 0.0029
[09/26 13:58:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 0.8495
[09/26 13:58:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:58:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 13:59:06 visual_prompt]: Epoch 52 / 100: avg data time: 4.80e-02, avg batch time: 0.4921, average train loss: 0.0028
[09/26 13:59:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1663, average loss: 0.8505
[09/26 13:59:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:59:08 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 13:59:15 visual_prompt]: Epoch 53 / 100: avg data time: 5.97e-02, avg batch time: 0.5012, average train loss: 0.0028
[09/26 13:59:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.8539
[09/26 13:59:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 13:59:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 13:59:23 visual_prompt]: Epoch 54 / 100: avg data time: 5.15e-02, avg batch time: 0.4955, average train loss: 0.0028
[09/26 13:59:24 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 0.8508
[09/26 13:59:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 13:59:24 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 13:59:31 visual_prompt]: Epoch 55 / 100: avg data time: 5.82e-02, avg batch time: 0.5023, average train loss: 0.0028
[09/26 13:59:33 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 0.8457
[09/26 13:59:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 13:59:33 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 13:59:40 visual_prompt]: Epoch 56 / 100: avg data time: 5.68e-02, avg batch time: 0.4983, average train loss: 0.0028
[09/26 13:59:41 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 0.8486
[09/26 13:59:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 13:59:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 13:59:48 visual_prompt]: Epoch 57 / 100: avg data time: 5.51e-02, avg batch time: 0.4967, average train loss: 0.0028
[09/26 13:59:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 0.8460
[09/26 13:59:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:59:50 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 13:59:57 visual_prompt]: Epoch 58 / 100: avg data time: 4.69e-02, avg batch time: 0.4889, average train loss: 0.0027
[09/26 13:59:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 0.8428
[09/26 13:59:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 13:59:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:00:05 visual_prompt]: Epoch 59 / 100: avg data time: 5.68e-02, avg batch time: 0.4993, average train loss: 0.0027
[09/26 14:00:07 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1661, average loss: 0.8402
[09/26 14:00:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:00:07 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:00:13 visual_prompt]: Epoch 60 / 100: avg data time: 5.09e-02, avg batch time: 0.4944, average train loss: 0.0027
[09/26 14:00:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 0.8439
[09/26 14:00:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:00:15 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:00:22 visual_prompt]: Epoch 61 / 100: avg data time: 5.90e-02, avg batch time: 0.5017, average train loss: 0.0027
[09/26 14:00:24 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.8470
[09/26 14:00:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:00:24 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:00:30 visual_prompt]: Epoch 62 / 100: avg data time: 5.49e-02, avg batch time: 0.4978, average train loss: 0.0026
[09/26 14:00:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1662, average loss: 0.8479
[09/26 14:00:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:00:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:00:39 visual_prompt]: Epoch 63 / 100: avg data time: 6.38e-02, avg batch time: 0.5060, average train loss: 0.0027
[09/26 14:00:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 0.8453
[09/26 14:00:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:00:41 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:00:47 visual_prompt]: Epoch 64 / 100: avg data time: 4.96e-02, avg batch time: 0.4924, average train loss: 0.0027
[09/26 14:00:49 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 0.8445
[09/26 14:00:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:00:49 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:00:56 visual_prompt]: Epoch 65 / 100: avg data time: 6.16e-02, avg batch time: 0.5034, average train loss: 0.0026
[09/26 14:00:58 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1662, average loss: 0.8429
[09/26 14:00:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:00:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:01:04 visual_prompt]: Epoch 66 / 100: avg data time: 5.56e-02, avg batch time: 0.4969, average train loss: 0.0026
[09/26 14:01:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.8443
[09/26 14:01:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:01:06 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:01:13 visual_prompt]: Epoch 67 / 100: avg data time: 5.55e-02, avg batch time: 0.4974, average train loss: 0.0026
[09/26 14:01:14 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 0.8450
[09/26 14:01:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:01:14 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:01:21 visual_prompt]: Epoch 68 / 100: avg data time: 4.78e-02, avg batch time: 0.4894, average train loss: 0.0026
[09/26 14:01:23 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1665, average loss: 0.8405
[09/26 14:01:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:01:23 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:01:30 visual_prompt]: Epoch 69 / 100: avg data time: 4.88e-02, avg batch time: 0.4921, average train loss: 0.0024
[09/26 14:01:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 0.8395
[09/26 14:01:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 14:01:31 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:01:38 visual_prompt]: Epoch 70 / 100: avg data time: 4.89e-02, avg batch time: 0.4905, average train loss: 0.0026
[09/26 14:01:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 0.8385
[09/26 14:01:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 14:01:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:01:46 visual_prompt]: Epoch 71 / 100: avg data time: 5.84e-02, avg batch time: 0.5011, average train loss: 0.0025
[09/26 14:01:48 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 0.8363
[09/26 14:01:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 14:01:48 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:01:55 visual_prompt]: Epoch 72 / 100: avg data time: 4.90e-02, avg batch time: 0.4919, average train loss: 0.0025
[09/26 14:01:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 0.8384
[09/26 14:01:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:01:56 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:02:03 visual_prompt]: Epoch 73 / 100: avg data time: 5.06e-02, avg batch time: 0.4955, average train loss: 0.0024
[09/26 14:02:05 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 0.8369
[09/26 14:02:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:05 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:02:12 visual_prompt]: Epoch 74 / 100: avg data time: 5.77e-02, avg batch time: 0.5015, average train loss: 0.0024
[09/26 14:02:13 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 0.8364
[09/26 14:02:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:13 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:02:20 visual_prompt]: Epoch 75 / 100: avg data time: 5.03e-02, avg batch time: 0.4932, average train loss: 0.0024
[09/26 14:02:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 0.8382
[09/26 14:02:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:02:21 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:02:28 visual_prompt]: Epoch 76 / 100: avg data time: 5.28e-02, avg batch time: 0.4962, average train loss: 0.0026
[09/26 14:02:30 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 0.8385
[09/26 14:02:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:30 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:02:37 visual_prompt]: Epoch 77 / 100: avg data time: 4.97e-02, avg batch time: 0.4956, average train loss: 0.0025
[09/26 14:02:38 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1661, average loss: 0.8389
[09/26 14:02:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:38 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:02:45 visual_prompt]: Epoch 78 / 100: avg data time: 4.61e-02, avg batch time: 0.4893, average train loss: 0.0024
[09/26 14:02:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 0.8387
[09/26 14:02:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:47 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:02:53 visual_prompt]: Epoch 79 / 100: avg data time: 5.65e-02, avg batch time: 0.5000, average train loss: 0.0027
[09/26 14:02:55 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 0.8365
[09/26 14:02:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:02:55 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:03:02 visual_prompt]: Epoch 80 / 100: avg data time: 5.88e-02, avg batch time: 0.5006, average train loss: 0.0025
[09/26 14:03:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1664, average loss: 0.8350
[09/26 14:03:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:03:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:03:10 visual_prompt]: Epoch 81 / 100: avg data time: 5.75e-02, avg batch time: 0.5007, average train loss: 0.0024
[09/26 14:03:12 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.8354
[09/26 14:03:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:03:12 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:03:19 visual_prompt]: Epoch 82 / 100: avg data time: 5.89e-02, avg batch time: 0.5015, average train loss: 0.0025
[09/26 14:03:20 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 0.8353
[09/26 14:03:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:03:20 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:03:27 visual_prompt]: Epoch 83 / 100: avg data time: 5.18e-02, avg batch time: 0.4961, average train loss: 0.0026
[09/26 14:03:29 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 0.8361
[09/26 14:03:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 14:03:29 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:03:36 visual_prompt]: Epoch 84 / 100: avg data time: 5.87e-02, avg batch time: 0.5021, average train loss: 0.0024
[09/26 14:03:37 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 0.8369
[09/26 14:03:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:03:37 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:03:44 visual_prompt]: Epoch 85 / 100: avg data time: 5.90e-02, avg batch time: 0.5026, average train loss: 0.0023
[09/26 14:03:46 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 0.8374
[09/26 14:03:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:03:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:03:53 visual_prompt]: Epoch 86 / 100: avg data time: 4.71e-02, avg batch time: 0.4906, average train loss: 0.0024
[09/26 14:03:54 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1661, average loss: 0.8375
[09/26 14:03:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:03:54 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:04:01 visual_prompt]: Epoch 87 / 100: avg data time: 4.87e-02, avg batch time: 0.4908, average train loss: 0.0025
[09/26 14:04:03 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 0.8370
[09/26 14:04:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:04:03 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:04:09 visual_prompt]: Epoch 88 / 100: avg data time: 5.50e-02, avg batch time: 0.4978, average train loss: 0.0025
[09/26 14:04:11 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1662, average loss: 0.8372
[09/26 14:04:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:04:11 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:04:18 visual_prompt]: Epoch 89 / 100: avg data time: 5.65e-02, avg batch time: 0.4991, average train loss: 0.0025
[09/26 14:04:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 0.8371
[09/26 14:04:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:04:20 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:04:26 visual_prompt]: Epoch 90 / 100: avg data time: 6.14e-02, avg batch time: 0.5037, average train loss: 0.0024
[09/26 14:04:28 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.8373
[09/26 14:04:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:04:28 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:04:35 visual_prompt]: Epoch 91 / 100: avg data time: 5.93e-02, avg batch time: 0.5015, average train loss: 0.0025
[09/26 14:04:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 0.8371
[09/26 14:04:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:04:37 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:04:43 visual_prompt]: Epoch 92 / 100: avg data time: 4.79e-02, avg batch time: 0.4900, average train loss: 0.0024
[09/26 14:04:45 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1663, average loss: 0.8371
[09/26 14:04:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:04:45 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:04:52 visual_prompt]: Epoch 93 / 100: avg data time: 5.70e-02, avg batch time: 0.4995, average train loss: 0.0025
[09/26 14:04:53 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 0.8370
[09/26 14:04:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:04:53 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:05:00 visual_prompt]: Epoch 94 / 100: avg data time: 5.06e-02, avg batch time: 0.4946, average train loss: 0.0024
[09/26 14:05:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.8370
[09/26 14:05:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:05:02 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:05:08 visual_prompt]: Epoch 95 / 100: avg data time: 5.31e-02, avg batch time: 0.4965, average train loss: 0.0024
[09/26 14:05:10 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1661, average loss: 0.8370
[09/26 14:05:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:05:10 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:05:17 visual_prompt]: Epoch 96 / 100: avg data time: 4.90e-02, avg batch time: 0.4926, average train loss: 0.0023
[09/26 14:05:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.8370
[09/26 14:05:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:05:18 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:05:25 visual_prompt]: Epoch 97 / 100: avg data time: 5.55e-02, avg batch time: 0.4979, average train loss: 0.0025
[09/26 14:05:27 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1662, average loss: 0.8370
[09/26 14:05:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:05:27 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:05:34 visual_prompt]: Epoch 98 / 100: avg data time: 5.92e-02, avg batch time: 0.5023, average train loss: 0.0024
[09/26 14:05:35 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1661, average loss: 0.8369
[09/26 14:05:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:05:35 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:05:42 visual_prompt]: Epoch 99 / 100: avg data time: 4.95e-02, avg batch time: 0.4942, average train loss: 0.0024
[09/26 14:05:44 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 0.8369
[09/26 14:05:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:05:44 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:05:50 visual_prompt]: Epoch 100 / 100: avg data time: 5.39e-02, avg batch time: 0.4981, average train loss: 0.0024
[09/26 14:05:52 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 0.8369
[09/26 14:05:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:05:52 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:05:52 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:05:52 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:05:52 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:05:52 visual_prompt]: Training with config:
[09/26 14:05:52 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.25_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:05:52 visual_prompt]: Loading training data...
[09/26 14:05:52 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:05:53 visual_prompt]: Number of images: 800
[09/26 14:05:53 visual_prompt]: Number of classes: 45 / 45
[09/26 14:05:53 visual_prompt]: Loading validation data...
[09/26 14:05:53 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:05:54 visual_prompt]: Number of images: 200
[09/26 14:05:54 visual_prompt]: Number of classes: 45 / 45
[09/26 14:05:54 visual_prompt]: Constructing models...
[09/26 14:05:56 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 14:05:56 visual_prompt]: tuned percent:0.574
[09/26 14:05:56 visual_prompt]: Device used for model: 0
[09/26 14:05:56 visual_prompt]: Setting up Evaluator...
[09/26 14:05:56 visual_prompt]: Setting up Trainer...
[09/26 14:05:56 visual_prompt]: 	Setting up the optimizer...
[09/26 14:05:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:06:03 visual_prompt]: Epoch 1 / 100: avg data time: 5.37e-02, avg batch time: 0.4936, average train loss: 3.8935
[09/26 14:06:04 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1656, average loss: 3.9529
[09/26 14:06:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 14:06:04 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 14:06:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[09/26 14:06:11 visual_prompt]: Epoch 2 / 100: avg data time: 4.65e-02, avg batch time: 0.4897, average train loss: 3.7911
[09/26 14:06:13 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1659, average loss: 3.7891
[09/26 14:06:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.50	top5: 13.50	
[09/26 14:06:13 visual_prompt]: Best epoch 2: best metric: 0.035
[09/26 14:06:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[09/26 14:06:20 visual_prompt]: Epoch 3 / 100: avg data time: 5.63e-02, avg batch time: 0.4974, average train loss: 3.6087
[09/26 14:06:21 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1658, average loss: 3.4138
[09/26 14:06:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 9.50	top5: 35.50	
[09/26 14:06:21 visual_prompt]: Best epoch 3: best metric: 0.095
[09/26 14:06:21 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[09/26 14:06:28 visual_prompt]: Epoch 4 / 100: avg data time: 5.49e-02, avg batch time: 0.4977, average train loss: 3.1048
[09/26 14:06:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1659, average loss: 2.8639
[09/26 14:06:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 51.50	
[09/26 14:06:30 visual_prompt]: Best epoch 4: best metric: 0.185
[09/26 14:06:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[09/26 14:06:37 visual_prompt]: Epoch 5 / 100: avg data time: 6.07e-02, avg batch time: 0.5016, average train loss: 2.7227
[09/26 14:06:38 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 2.8359
[09/26 14:06:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.00	top5: 52.50	
[09/26 14:06:38 visual_prompt]: Best epoch 5: best metric: 0.250
[09/26 14:06:38 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[09/26 14:06:45 visual_prompt]: Epoch 6 / 100: avg data time: 6.24e-02, avg batch time: 0.5054, average train loss: 2.2172
[09/26 14:06:47 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 2.3714
[09/26 14:06:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 32.50	top5: 67.50	
[09/26 14:06:47 visual_prompt]: Best epoch 6: best metric: 0.325
[09/26 14:06:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[09/26 14:06:54 visual_prompt]: Epoch 7 / 100: avg data time: 5.98e-02, avg batch time: 0.5031, average train loss: 1.8303
[09/26 14:06:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1660, average loss: 1.9516
[09/26 14:06:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.50	top5: 77.00	
[09/26 14:06:55 visual_prompt]: Best epoch 7: best metric: 0.405
[09/26 14:06:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[09/26 14:07:02 visual_prompt]: Epoch 8 / 100: avg data time: 5.20e-02, avg batch time: 0.4955, average train loss: 1.3045
[09/26 14:07:04 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1662, average loss: 1.5127
[09/26 14:07:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 55.50	top5: 85.50	
[09/26 14:07:04 visual_prompt]: Best epoch 8: best metric: 0.555
[09/26 14:07:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[09/26 14:07:11 visual_prompt]: Epoch 9 / 100: avg data time: 5.75e-02, avg batch time: 0.4986, average train loss: 0.9046
[09/26 14:07:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 1.3799
[09/26 14:07:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 88.50	
[09/26 14:07:12 visual_prompt]: Best epoch 9: best metric: 0.585
[09/26 14:07:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[09/26 14:07:19 visual_prompt]: Epoch 10 / 100: avg data time: 6.92e-02, avg batch time: 0.5108, average train loss: 0.6461
[09/26 14:07:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1659, average loss: 1.3217
[09/26 14:07:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.00	top5: 90.00	
[09/26 14:07:21 visual_prompt]: Best epoch 10: best metric: 0.610
[09/26 14:07:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[09/26 14:07:28 visual_prompt]: Epoch 11 / 100: avg data time: 5.42e-02, avg batch time: 0.4973, average train loss: 0.4597
[09/26 14:07:29 visual_prompt]: Inference (val):avg data time: 4.12e-05, avg batch time: 0.1661, average loss: 1.1622
[09/26 14:07:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 93.50	
[09/26 14:07:29 visual_prompt]: Best epoch 11: best metric: 0.650
[09/26 14:07:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[09/26 14:07:36 visual_prompt]: Epoch 12 / 100: avg data time: 5.07e-02, avg batch time: 0.4924, average train loss: 0.3217
[09/26 14:07:38 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1663, average loss: 0.9774
[09/26 14:07:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 95.00	
[09/26 14:07:38 visual_prompt]: Best epoch 12: best metric: 0.700
[09/26 14:07:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[09/26 14:07:45 visual_prompt]: Epoch 13 / 100: avg data time: 5.75e-02, avg batch time: 0.5006, average train loss: 0.2197
[09/26 14:07:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1661, average loss: 1.0494
[09/26 14:07:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 95.50	
[09/26 14:07:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[09/26 14:07:53 visual_prompt]: Epoch 14 / 100: avg data time: 5.89e-02, avg batch time: 0.5041, average train loss: 0.1476
[09/26 14:07:55 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1660, average loss: 1.0182
[09/26 14:07:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 95.00	
[09/26 14:07:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[09/26 14:08:02 visual_prompt]: Epoch 15 / 100: avg data time: 4.87e-02, avg batch time: 0.4923, average train loss: 0.1084
[09/26 14:08:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 1.0193
[09/26 14:08:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.50	
[09/26 14:08:03 visual_prompt]: Best epoch 15: best metric: 0.730
[09/26 14:08:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[09/26 14:08:10 visual_prompt]: Epoch 16 / 100: avg data time: 6.57e-02, avg batch time: 0.5080, average train loss: 0.0579
[09/26 14:08:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 0.9433
[09/26 14:08:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.00	
[09/26 14:08:12 visual_prompt]: Best epoch 16: best metric: 0.750
[09/26 14:08:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[09/26 14:08:19 visual_prompt]: Epoch 17 / 100: avg data time: 6.24e-02, avg batch time: 0.5041, average train loss: 0.0420
[09/26 14:08:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 0.9757
[09/26 14:08:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 14:08:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[09/26 14:08:27 visual_prompt]: Epoch 18 / 100: avg data time: 6.52e-02, avg batch time: 0.5075, average train loss: 0.0296
[09/26 14:08:29 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1662, average loss: 0.9237
[09/26 14:08:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.50	
[09/26 14:08:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[09/26 14:08:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.41e-02, avg batch time: 0.4959, average train loss: 0.0155
[09/26 14:08:37 visual_prompt]: Inference (val):avg data time: 4.80e-05, avg batch time: 0.1662, average loss: 0.8295
[09/26 14:08:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 14:08:37 visual_prompt]: Best epoch 19: best metric: 0.755
[09/26 14:08:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[09/26 14:08:44 visual_prompt]: Epoch 20 / 100: avg data time: 6.33e-02, avg batch time: 0.5064, average train loss: 0.0129
[09/26 14:08:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1663, average loss: 0.8449
[09/26 14:08:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 14:08:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[09/26 14:08:53 visual_prompt]: Epoch 21 / 100: avg data time: 6.38e-02, avg batch time: 0.5051, average train loss: 0.0087
[09/26 14:08:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 0.8444
[09/26 14:08:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 14:08:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[09/26 14:09:01 visual_prompt]: Epoch 22 / 100: avg data time: 5.17e-02, avg batch time: 0.4942, average train loss: 0.0075
[09/26 14:09:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1663, average loss: 0.8568
[09/26 14:09:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 97.50	
[09/26 14:09:03 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[09/26 14:09:10 visual_prompt]: Epoch 23 / 100: avg data time: 5.26e-02, avg batch time: 0.4957, average train loss: 0.0063
[09/26 14:09:11 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1663, average loss: 0.8622
[09/26 14:09:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 14:09:11 visual_prompt]: Best epoch 23: best metric: 0.760
[09/26 14:09:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[09/26 14:09:18 visual_prompt]: Epoch 24 / 100: avg data time: 6.02e-02, avg batch time: 0.5031, average train loss: 0.0059
[09/26 14:09:20 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1662, average loss: 0.8641
[09/26 14:09:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:09:20 visual_prompt]: Best epoch 24: best metric: 0.770
[09/26 14:09:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[09/26 14:09:27 visual_prompt]: Epoch 25 / 100: avg data time: 5.15e-02, avg batch time: 0.4927, average train loss: 0.0054
[09/26 14:09:28 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 0.8750
[09/26 14:09:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 14:09:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[09/26 14:09:35 visual_prompt]: Epoch 26 / 100: avg data time: 5.08e-02, avg batch time: 0.4932, average train loss: 0.0047
[09/26 14:09:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.8636
[09/26 14:09:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 14:09:37 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[09/26 14:09:44 visual_prompt]: Epoch 27 / 100: avg data time: 6.25e-02, avg batch time: 0.5039, average train loss: 0.0049
[09/26 14:09:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.8598
[09/26 14:09:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 14:09:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[09/26 14:09:52 visual_prompt]: Epoch 28 / 100: avg data time: 6.84e-02, avg batch time: 0.5105, average train loss: 0.0043
[09/26 14:09:54 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 0.8567
[09/26 14:09:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 14:09:54 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[09/26 14:10:01 visual_prompt]: Epoch 29 / 100: avg data time: 5.79e-02, avg batch time: 0.5017, average train loss: 0.0044
[09/26 14:10:02 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 0.8474
[09/26 14:10:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 14:10:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[09/26 14:10:09 visual_prompt]: Epoch 30 / 100: avg data time: 5.12e-02, avg batch time: 0.4940, average train loss: 0.0037
[09/26 14:10:11 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.8485
[09/26 14:10:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 14:10:11 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[09/26 14:10:17 visual_prompt]: Epoch 31 / 100: avg data time: 6.30e-02, avg batch time: 0.5044, average train loss: 0.0035
[09/26 14:10:19 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 0.8600
[09/26 14:10:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 14:10:19 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[09/26 14:10:26 visual_prompt]: Epoch 32 / 100: avg data time: 4.98e-02, avg batch time: 0.4934, average train loss: 0.0035
[09/26 14:10:27 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1665, average loss: 0.8726
[09/26 14:10:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 14:10:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[09/26 14:10:34 visual_prompt]: Epoch 33 / 100: avg data time: 5.93e-02, avg batch time: 0.5009, average train loss: 0.0032
[09/26 14:10:36 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.8651
[09/26 14:10:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 14:10:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[09/26 14:10:43 visual_prompt]: Epoch 34 / 100: avg data time: 5.47e-02, avg batch time: 0.4994, average train loss: 0.0032
[09/26 14:10:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 0.8499
[09/26 14:10:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:10:44 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[09/26 14:10:51 visual_prompt]: Epoch 35 / 100: avg data time: 5.87e-02, avg batch time: 0.5003, average train loss: 0.0031
[09/26 14:10:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 0.8437
[09/26 14:10:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 14:10:53 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[09/26 14:11:00 visual_prompt]: Epoch 36 / 100: avg data time: 6.42e-02, avg batch time: 0.5059, average train loss: 0.0028
[09/26 14:11:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 0.8525
[09/26 14:11:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 14:11:01 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[09/26 14:11:08 visual_prompt]: Epoch 37 / 100: avg data time: 5.19e-02, avg batch time: 0.4949, average train loss: 0.0029
[09/26 14:11:10 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.8568
[09/26 14:11:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 14:11:10 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[09/26 14:11:17 visual_prompt]: Epoch 38 / 100: avg data time: 5.97e-02, avg batch time: 0.5032, average train loss: 0.0028
[09/26 14:11:18 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 0.8573
[09/26 14:11:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 14:11:18 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[09/26 14:11:25 visual_prompt]: Epoch 39 / 100: avg data time: 6.42e-02, avg batch time: 0.5070, average train loss: 0.0027
[09/26 14:11:27 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 0.8647
[09/26 14:11:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 14:11:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[09/26 14:11:34 visual_prompt]: Epoch 40 / 100: avg data time: 6.01e-02, avg batch time: 0.5023, average train loss: 0.0026
[09/26 14:11:35 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 0.8687
[09/26 14:11:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.00	
[09/26 14:11:35 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[09/26 14:11:42 visual_prompt]: Epoch 41 / 100: avg data time: 5.11e-02, avg batch time: 0.4952, average train loss: 0.0026
[09/26 14:11:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.8850
[09/26 14:11:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 14:11:44 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[09/26 14:11:51 visual_prompt]: Epoch 42 / 100: avg data time: 6.22e-02, avg batch time: 0.5043, average train loss: 0.0024
[09/26 14:11:52 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 0.8768
[09/26 14:11:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.00	
[09/26 14:11:52 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[09/26 14:11:59 visual_prompt]: Epoch 43 / 100: avg data time: 6.04e-02, avg batch time: 0.5020, average train loss: 0.0024
[09/26 14:12:01 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 0.8693
[09/26 14:12:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 14:12:01 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[09/26 14:12:08 visual_prompt]: Epoch 44 / 100: avg data time: 4.73e-02, avg batch time: 0.4910, average train loss: 0.0023
[09/26 14:12:09 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.8697
[09/26 14:12:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 96.50	
[09/26 14:12:09 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[09/26 14:12:16 visual_prompt]: Epoch 45 / 100: avg data time: 6.08e-02, avg batch time: 0.5033, average train loss: 0.0020
[09/26 14:12:18 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.8667
[09/26 14:12:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 14:12:18 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[09/26 14:12:24 visual_prompt]: Epoch 46 / 100: avg data time: 5.67e-02, avg batch time: 0.5006, average train loss: 0.0022
[09/26 14:12:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.8636
[09/26 14:12:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:12:26 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[09/26 14:12:33 visual_prompt]: Epoch 47 / 100: avg data time: 5.43e-02, avg batch time: 0.4979, average train loss: 0.0022
[09/26 14:12:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 0.8629
[09/26 14:12:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:12:34 visual_prompt]: Best epoch 47: best metric: 0.775
[09/26 14:12:34 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[09/26 14:12:41 visual_prompt]: Epoch 48 / 100: avg data time: 4.61e-02, avg batch time: 0.4906, average train loss: 0.0022
[09/26 14:12:43 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1663, average loss: 0.8632
[09/26 14:12:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:12:43 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[09/26 14:12:50 visual_prompt]: Epoch 49 / 100: avg data time: 5.43e-02, avg batch time: 0.4961, average train loss: 0.0021
[09/26 14:12:51 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 0.8734
[09/26 14:12:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:12:51 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[09/26 14:12:58 visual_prompt]: Epoch 50 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 0.0021
[09/26 14:13:00 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1664, average loss: 0.8763
[09/26 14:13:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:13:00 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[09/26 14:13:06 visual_prompt]: Epoch 51 / 100: avg data time: 4.92e-02, avg batch time: 0.4920, average train loss: 0.0020
[09/26 14:13:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1664, average loss: 0.8777
[09/26 14:13:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:13:08 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[09/26 14:13:15 visual_prompt]: Epoch 52 / 100: avg data time: 5.94e-02, avg batch time: 0.5017, average train loss: 0.0021
[09/26 14:13:16 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 0.8753
[09/26 14:13:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:13:16 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.1380660579084567
[09/26 14:13:23 visual_prompt]: Epoch 53 / 100: avg data time: 4.86e-02, avg batch time: 0.4954, average train loss: 0.0020
[09/26 14:13:25 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 0.8710
[09/26 14:13:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:13:25 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.13371955921801565
[09/26 14:13:32 visual_prompt]: Epoch 54 / 100: avg data time: 6.12e-02, avg batch time: 0.5035, average train loss: 0.0020
[09/26 14:13:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 0.8660
[09/26 14:13:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.00	
[09/26 14:13:33 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.12936243708781264
[09/26 14:13:40 visual_prompt]: Epoch 55 / 100: avg data time: 4.66e-02, avg batch time: 0.4900, average train loss: 0.0020
[09/26 14:13:42 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 0.8674
[09/26 14:13:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 97.00	
[09/26 14:13:42 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.125
[09/26 14:13:48 visual_prompt]: Epoch 56 / 100: avg data time: 4.60e-02, avg batch time: 0.4904, average train loss: 0.0019
[09/26 14:13:50 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 0.8676
[09/26 14:13:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:13:50 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.12063756291218741
[09/26 14:13:57 visual_prompt]: Epoch 57 / 100: avg data time: 5.07e-02, avg batch time: 0.4926, average train loss: 0.0019
[09/26 14:13:58 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1662, average loss: 0.8689
[09/26 14:13:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:13:58 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.11628044078198434
[09/26 14:14:05 visual_prompt]: Epoch 58 / 100: avg data time: 5.23e-02, avg batch time: 0.4966, average train loss: 0.0017
[09/26 14:14:07 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8689
[09/26 14:14:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:14:07 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.11193394209154334
[09/26 14:14:13 visual_prompt]: Epoch 59 / 100: avg data time: 5.02e-02, avg batch time: 0.4930, average train loss: 0.0017
[09/26 14:14:15 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1660, average loss: 0.8687
[09/26 14:14:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:14:15 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.10760336237999185
[09/26 14:14:22 visual_prompt]: Epoch 60 / 100: avg data time: 5.63e-02, avg batch time: 0.4976, average train loss: 0.0018
[09/26 14:14:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 0.8667
[09/26 14:14:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.00	
[09/26 14:14:23 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.10329397779163371
[09/26 14:14:30 visual_prompt]: Epoch 61 / 100: avg data time: 5.18e-02, avg batch time: 0.4944, average train loss: 0.0019
[09/26 14:14:32 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1660, average loss: 0.8667
[09/26 14:14:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.50	
[09/26 14:14:32 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.0990110386477801
[09/26 14:14:39 visual_prompt]: Epoch 62 / 100: avg data time: 5.43e-02, avg batch time: 0.4969, average train loss: 0.0017
[09/26 14:14:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1659, average loss: 0.8666
[09/26 14:14:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:14:40 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.09475976305004155
[09/26 14:14:47 visual_prompt]: Epoch 63 / 100: avg data time: 4.60e-02, avg batch time: 0.4880, average train loss: 0.0018
[09/26 14:14:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.8665
[09/26 14:14:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:14:48 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.09054533052287511
[09/26 14:14:55 visual_prompt]: Epoch 64 / 100: avg data time: 5.83e-02, avg batch time: 0.5006, average train loss: 0.0017
[09/26 14:14:57 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 0.8669
[09/26 14:14:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:14:57 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.08637287570313158
[09/26 14:15:04 visual_prompt]: Epoch 65 / 100: avg data time: 4.56e-02, avg batch time: 0.4891, average train loss: 0.0018
[09/26 14:15:05 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1661, average loss: 0.8685
[09/26 14:15:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:15:05 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.08224748208429142
[09/26 14:15:12 visual_prompt]: Epoch 66 / 100: avg data time: 5.13e-02, avg batch time: 0.4938, average train loss: 0.0018
[09/26 14:15:14 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1660, average loss: 0.8700
[09/26 14:15:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:15:14 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.07817417582301099
[09/26 14:15:20 visual_prompt]: Epoch 67 / 100: avg data time: 4.82e-02, avg batch time: 0.4920, average train loss: 0.0018
[09/26 14:15:22 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 0.8707
[09/26 14:15:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:15:22 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.074157919615525
[09/26 14:15:29 visual_prompt]: Epoch 68 / 100: avg data time: 5.87e-02, avg batch time: 0.5005, average train loss: 0.0016
[09/26 14:15:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1660, average loss: 0.8698
[09/26 14:15:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:15:30 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.07020360665136531
[09/26 14:15:37 visual_prompt]: Epoch 69 / 100: avg data time: 5.58e-02, avg batch time: 0.4976, average train loss: 0.0016
[09/26 14:15:39 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1659, average loss: 0.8696
[09/26 14:15:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:15:39 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.06631605465176368
[09/26 14:15:46 visual_prompt]: Epoch 70 / 100: avg data time: 5.25e-02, avg batch time: 0.4954, average train loss: 0.0016
[09/26 14:15:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 0.8688
[09/26 14:15:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:15:47 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.06250000000000003
[09/26 14:15:54 visual_prompt]: Epoch 71 / 100: avg data time: 5.69e-02, avg batch time: 0.4983, average train loss: 0.0018
[09/26 14:15:56 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1661, average loss: 0.8690
[09/26 14:15:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:15:56 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.0587600919708494
[09/26 14:16:02 visual_prompt]: Epoch 72 / 100: avg data time: 5.11e-02, avg batch time: 0.4946, average train loss: 0.0016
[09/26 14:16:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1661, average loss: 0.8675
[09/26 14:16:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:16:04 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.055100887066156665
[09/26 14:16:11 visual_prompt]: Epoch 73 / 100: avg data time: 5.37e-02, avg batch time: 0.4967, average train loss: 0.0017
[09/26 14:16:13 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.8665
[09/26 14:16:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:16:13 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.05152684346344087
[09/26 14:16:19 visual_prompt]: Epoch 74 / 100: avg data time: 5.95e-02, avg batch time: 0.5009, average train loss: 0.0017
[09/26 14:16:21 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8654
[09/26 14:16:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:16:21 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.048042315584292714
[09/26 14:16:28 visual_prompt]: Epoch 75 / 100: avg data time: 5.38e-02, avg batch time: 0.4982, average train loss: 0.0015
[09/26 14:16:29 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1661, average loss: 0.8659
[09/26 14:16:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:16:29 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.04465154878918258
[09/26 14:16:36 visual_prompt]: Epoch 76 / 100: avg data time: 5.04e-02, avg batch time: 0.4918, average train loss: 0.0016
[09/26 14:16:38 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 0.8650
[09/26 14:16:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:16:38 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.04135867420514276
[09/26 14:16:44 visual_prompt]: Epoch 77 / 100: avg data time: 4.91e-02, avg batch time: 0.4909, average train loss: 0.0015
[09/26 14:16:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 0.8646
[09/26 14:16:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:16:46 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.03816770369262533
[09/26 14:16:53 visual_prompt]: Epoch 78 / 100: avg data time: 4.68e-02, avg batch time: 0.4894, average train loss: 0.0015
[09/26 14:16:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 0.8651
[09/26 14:16:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:16:54 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.03508252495766863
[09/26 14:17:01 visual_prompt]: Epoch 79 / 100: avg data time: 5.16e-02, avg batch time: 0.4952, average train loss: 0.0016
[09/26 14:17:03 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 0.8659
[09/26 14:17:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:17:03 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.032106896815325706
[09/26 14:17:10 visual_prompt]: Epoch 80 / 100: avg data time: 5.48e-02, avg batch time: 0.4970, average train loss: 0.0016
[09/26 14:17:11 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 0.8667
[09/26 14:17:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:17:11 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.029244444610127762
[09/26 14:17:18 visual_prompt]: Epoch 81 / 100: avg data time: 5.36e-02, avg batch time: 0.4967, average train loss: 0.0016
[09/26 14:17:20 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 0.8669
[09/26 14:17:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:17:20 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.026498655799159762
[09/26 14:17:26 visual_prompt]: Epoch 82 / 100: avg data time: 5.49e-02, avg batch time: 0.4979, average train loss: 0.0015
[09/26 14:17:28 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 0.8671
[09/26 14:17:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:17:28 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.023872875703131582
[09/26 14:17:35 visual_prompt]: Epoch 83 / 100: avg data time: 5.97e-02, avg batch time: 0.5024, average train loss: 0.0016
[09/26 14:17:37 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1661, average loss: 0.8676
[09/26 14:17:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:17:37 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.021370303430619797
[09/26 14:17:43 visual_prompt]: Epoch 84 / 100: avg data time: 4.96e-02, avg batch time: 0.4909, average train loss: 0.0015
[09/26 14:17:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 0.8679
[09/26 14:17:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:17:45 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.018993987980446755
[09/26 14:17:52 visual_prompt]: Epoch 85 / 100: avg data time: 4.98e-02, avg batch time: 0.4930, average train loss: 0.0015
[09/26 14:17:53 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1660, average loss: 0.8681
[09/26 14:17:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:17:53 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.01674682452694516
[09/26 14:18:00 visual_prompt]: Epoch 86 / 100: avg data time: 5.05e-02, avg batch time: 0.4942, average train loss: 0.0014
[09/26 14:18:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1661, average loss: 0.8682
[09/26 14:18:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:02 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.014631550892634126
[09/26 14:18:08 visual_prompt]: Epoch 87 / 100: avg data time: 5.53e-02, avg batch time: 0.4994, average train loss: 0.0016
[09/26 14:18:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 0.8685
[09/26 14:18:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:10 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.012650744212604148
[09/26 14:18:17 visual_prompt]: Epoch 88 / 100: avg data time: 5.19e-02, avg batch time: 0.4946, average train loss: 0.0016
[09/26 14:18:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8686
[09/26 14:18:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:18 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.010806817794674878
[09/26 14:18:25 visual_prompt]: Epoch 89 / 100: avg data time: 5.92e-02, avg batch time: 0.5016, average train loss: 0.0015
[09/26 14:18:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1660, average loss: 0.8688
[09/26 14:18:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:27 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.009102018179151586
[09/26 14:18:34 visual_prompt]: Epoch 90 / 100: avg data time: 5.92e-02, avg batch time: 0.5018, average train loss: 0.0015
[09/26 14:18:36 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 0.8689
[09/26 14:18:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:36 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.00753842240176146
[09/26 14:18:42 visual_prompt]: Epoch 91 / 100: avg data time: 4.62e-02, avg batch time: 0.4892, average train loss: 0.0015
[09/26 14:18:44 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 0.8690
[09/26 14:18:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:44 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.006117935463105809
[09/26 14:18:51 visual_prompt]: Epoch 92 / 100: avg data time: 4.86e-02, avg batch time: 0.4929, average train loss: 0.0016
[09/26 14:18:52 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 0.8691
[09/26 14:18:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:18:52 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.004842288007710138
[09/26 14:18:59 visual_prompt]: Epoch 93 / 100: avg data time: 5.62e-02, avg batch time: 0.4987, average train loss: 0.0015
[09/26 14:19:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1660, average loss: 0.8691
[09/26 14:19:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:01 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.003713034215500441
[09/26 14:19:08 visual_prompt]: Epoch 94 / 100: avg data time: 5.63e-02, avg batch time: 0.4988, average train loss: 0.0015
[09/26 14:19:09 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1658, average loss: 0.8691
[09/26 14:19:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:09 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.002731549908274289
[09/26 14:19:16 visual_prompt]: Epoch 95 / 100: avg data time: 5.51e-02, avg batch time: 0.4967, average train loss: 0.0015
[09/26 14:19:18 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1661, average loss: 0.8691
[09/26 14:19:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:18 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0018990308734739975
[09/26 14:19:24 visual_prompt]: Epoch 96 / 100: avg data time: 5.16e-02, avg batch time: 0.4933, average train loss: 0.0015
[09/26 14:19:26 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1661, average loss: 0.8691
[09/26 14:19:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:26 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.0012164914073037048
[09/26 14:19:33 visual_prompt]: Epoch 97 / 100: avg data time: 4.58e-02, avg batch time: 0.4918, average train loss: 0.0016
[09/26 14:19:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.8691
[09/26 14:19:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:34 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0006847630789658388
[09/26 14:19:41 visual_prompt]: Epoch 98 / 100: avg data time: 4.93e-02, avg batch time: 0.4918, average train loss: 0.0015
[09/26 14:19:43 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1660, average loss: 0.8691
[09/26 14:19:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:43 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0003044937175219753
[09/26 14:19:49 visual_prompt]: Epoch 99 / 100: avg data time: 5.62e-02, avg batch time: 0.5011, average train loss: 0.0015
[09/26 14:19:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1661, average loss: 0.8691
[09/26 14:19:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:51 visual_prompt]: Training 100 / 100 epoch, with learning rate 7.614662261302974e-05
[09/26 14:19:58 visual_prompt]: Epoch 100 / 100: avg data time: 5.06e-02, avg batch time: 0.4928, average train loss: 0.0015
[09/26 14:19:59 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 0.8691
[09/26 14:19:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:19:59 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:19:59 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:19:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:19:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:19:59 visual_prompt]: Training with config:
[09/26 14:19:59 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:19:59 visual_prompt]: Loading training data...
[09/26 14:19:59 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:20:00 visual_prompt]: Number of images: 800
[09/26 14:20:00 visual_prompt]: Number of classes: 45 / 45
[09/26 14:20:00 visual_prompt]: Loading validation data...
[09/26 14:20:00 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:20:01 visual_prompt]: Number of images: 200
[09/26 14:20:01 visual_prompt]: Number of classes: 45 / 45
[09/26 14:20:01 visual_prompt]: Constructing models...
[09/26 14:20:03 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 14:20:03 visual_prompt]: tuned percent:0.574
[09/26 14:20:03 visual_prompt]: Device used for model: 0
[09/26 14:20:03 visual_prompt]: Setting up Evaluator...
[09/26 14:20:03 visual_prompt]: Setting up Trainer...
[09/26 14:20:03 visual_prompt]: 	Setting up the optimizer...
[09/26 14:20:03 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:20:10 visual_prompt]: Epoch 1 / 100: avg data time: 5.98e-02, avg batch time: 0.5009, average train loss: 3.8893
[09/26 14:20:12 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 14:20:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 14:20:12 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 14:20:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 14:20:19 visual_prompt]: Epoch 2 / 100: avg data time: 6.19e-02, avg batch time: 0.5033, average train loss: 3.8275
[09/26 14:20:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 3.8230
[09/26 14:20:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 15.50	
[09/26 14:20:20 visual_prompt]: Best epoch 2: best metric: 0.040
[09/26 14:20:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 14:20:27 visual_prompt]: Epoch 3 / 100: avg data time: 5.86e-02, avg batch time: 0.4994, average train loss: 3.7164
[09/26 14:20:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 3.6541
[09/26 14:20:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.50	top5: 28.50	
[09/26 14:20:29 visual_prompt]: Best epoch 3: best metric: 0.105
[09/26 14:20:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 14:20:36 visual_prompt]: Epoch 4 / 100: avg data time: 7.09e-02, avg batch time: 0.5132, average train loss: 3.5012
[09/26 14:20:37 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 3.2260
[09/26 14:20:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 36.50	
[09/26 14:20:37 visual_prompt]: Best epoch 4: best metric: 0.155
[09/26 14:20:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 14:20:44 visual_prompt]: Epoch 5 / 100: avg data time: 6.57e-02, avg batch time: 0.5071, average train loss: 3.0130
[09/26 14:20:46 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1662, average loss: 2.8191
[09/26 14:20:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 51.50	
[09/26 14:20:46 visual_prompt]: Best epoch 5: best metric: 0.225
[09/26 14:20:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 14:20:53 visual_prompt]: Epoch 6 / 100: avg data time: 6.05e-02, avg batch time: 0.5016, average train loss: 2.4999
[09/26 14:20:55 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 2.5487
[09/26 14:20:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.00	top5: 64.00	
[09/26 14:20:55 visual_prompt]: Best epoch 6: best metric: 0.270
[09/26 14:20:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 14:21:02 visual_prompt]: Epoch 7 / 100: avg data time: 6.84e-02, avg batch time: 0.5094, average train loss: 2.0729
[09/26 14:21:03 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1665, average loss: 1.9951
[09/26 14:21:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 43.50	top5: 79.50	
[09/26 14:21:03 visual_prompt]: Best epoch 7: best metric: 0.435
[09/26 14:21:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 14:21:10 visual_prompt]: Epoch 8 / 100: avg data time: 6.65e-02, avg batch time: 0.5086, average train loss: 1.7268
[09/26 14:21:12 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1662, average loss: 1.8932
[09/26 14:21:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.50	top5: 76.50	
[09/26 14:21:12 visual_prompt]: Best epoch 8: best metric: 0.465
[09/26 14:21:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 14:21:19 visual_prompt]: Epoch 9 / 100: avg data time: 7.01e-02, avg batch time: 0.5111, average train loss: 1.4692
[09/26 14:21:20 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.6879
[09/26 14:21:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.50	top5: 88.50	
[09/26 14:21:20 visual_prompt]: Best epoch 9: best metric: 0.525
[09/26 14:21:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 14:21:27 visual_prompt]: Epoch 10 / 100: avg data time: 6.64e-02, avg batch time: 0.5078, average train loss: 1.1417
[09/26 14:21:29 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1664, average loss: 1.4144
[09/26 14:21:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.50	top5: 87.00	
[09/26 14:21:29 visual_prompt]: Best epoch 10: best metric: 0.605
[09/26 14:21:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 14:21:36 visual_prompt]: Epoch 11 / 100: avg data time: 6.54e-02, avg batch time: 0.5071, average train loss: 0.9442
[09/26 14:21:38 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 1.3311
[09/26 14:21:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 92.00	
[09/26 14:21:38 visual_prompt]: Best epoch 11: best metric: 0.630
[09/26 14:21:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 14:21:45 visual_prompt]: Epoch 12 / 100: avg data time: 6.13e-02, avg batch time: 0.5024, average train loss: 0.8397
[09/26 14:21:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.3681
[09/26 14:21:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 88.50	
[09/26 14:21:46 visual_prompt]: Best epoch 12: best metric: 0.645
[09/26 14:21:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 14:21:53 visual_prompt]: Epoch 13 / 100: avg data time: 6.00e-02, avg batch time: 0.5014, average train loss: 0.6730
[09/26 14:21:55 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.2253
[09/26 14:21:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 89.50	
[09/26 14:21:55 visual_prompt]: Best epoch 13: best metric: 0.690
[09/26 14:21:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 14:22:02 visual_prompt]: Epoch 14 / 100: avg data time: 5.91e-02, avg batch time: 0.5009, average train loss: 0.6023
[09/26 14:22:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.1643
[09/26 14:22:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 14:22:03 visual_prompt]: Best epoch 14: best metric: 0.710
[09/26 14:22:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 14:22:10 visual_prompt]: Epoch 15 / 100: avg data time: 6.71e-02, avg batch time: 0.5079, average train loss: 0.5304
[09/26 14:22:12 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1662, average loss: 1.1761
[09/26 14:22:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.00	
[09/26 14:22:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 14:22:19 visual_prompt]: Epoch 16 / 100: avg data time: 6.59e-02, avg batch time: 0.5072, average train loss: 0.4983
[09/26 14:22:20 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.2252
[09/26 14:22:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 91.50	
[09/26 14:22:20 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 14:22:27 visual_prompt]: Epoch 17 / 100: avg data time: 7.08e-02, avg batch time: 0.5115, average train loss: 0.5433
[09/26 14:22:29 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1661, average loss: 1.1224
[09/26 14:22:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 14:22:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 14:22:36 visual_prompt]: Epoch 18 / 100: avg data time: 6.48e-02, avg batch time: 0.5057, average train loss: 0.4543
[09/26 14:22:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1661, average loss: 1.3775
[09/26 14:22:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 87.50	
[09/26 14:22:38 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 14:22:44 visual_prompt]: Epoch 19 / 100: avg data time: 5.49e-02, avg batch time: 0.4966, average train loss: 0.4322
[09/26 14:22:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 1.0925
[09/26 14:22:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 92.50	
[09/26 14:22:46 visual_prompt]: Best epoch 19: best metric: 0.725
[09/26 14:22:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 14:22:53 visual_prompt]: Epoch 20 / 100: avg data time: 5.80e-02, avg batch time: 0.4988, average train loss: 0.4445
[09/26 14:22:55 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.0593
[09/26 14:22:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 96.00	
[09/26 14:22:55 visual_prompt]: Best epoch 20: best metric: 0.735
[09/26 14:22:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 14:23:01 visual_prompt]: Epoch 21 / 100: avg data time: 6.59e-02, avg batch time: 0.5074, average train loss: 0.4336
[09/26 14:23:03 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 0.9140
[09/26 14:23:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 97.50	
[09/26 14:23:03 visual_prompt]: Best epoch 21: best metric: 0.740
[09/26 14:23:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 14:23:10 visual_prompt]: Epoch 22 / 100: avg data time: 6.00e-02, avg batch time: 0.5028, average train loss: 0.4104
[09/26 14:23:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.0514
[09/26 14:23:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.00	
[09/26 14:23:12 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 14:23:18 visual_prompt]: Epoch 23 / 100: avg data time: 5.67e-02, avg batch time: 0.4983, average train loss: 0.3906
[09/26 14:23:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.9892
[09/26 14:23:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 96.00	
[09/26 14:23:20 visual_prompt]: Best epoch 23: best metric: 0.750
[09/26 14:23:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 14:23:27 visual_prompt]: Epoch 24 / 100: avg data time: 6.16e-02, avg batch time: 0.5033, average train loss: 0.3427
[09/26 14:23:29 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 0.9364
[09/26 14:23:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.00	
[09/26 14:23:29 visual_prompt]: Best epoch 24: best metric: 0.775
[09/26 14:23:29 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 14:23:36 visual_prompt]: Epoch 25 / 100: avg data time: 6.36e-02, avg batch time: 0.5044, average train loss: 0.2576
[09/26 14:23:37 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 0.9568
[09/26 14:23:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 14:23:37 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 14:23:44 visual_prompt]: Epoch 26 / 100: avg data time: 6.19e-02, avg batch time: 0.5041, average train loss: 0.3098
[09/26 14:23:46 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 1.0514
[09/26 14:23:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.00	
[09/26 14:23:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 14:23:53 visual_prompt]: Epoch 27 / 100: avg data time: 6.31e-02, avg batch time: 0.5042, average train loss: 0.4033
[09/26 14:23:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2866
[09/26 14:23:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 14:23:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 14:24:02 visual_prompt]: Epoch 28 / 100: avg data time: 7.16e-02, avg batch time: 0.5127, average train loss: 0.4435
[09/26 14:24:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1662, average loss: 1.1003
[09/26 14:24:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 14:24:03 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 14:24:10 visual_prompt]: Epoch 29 / 100: avg data time: 5.67e-02, avg batch time: 0.4995, average train loss: 0.3802
[09/26 14:24:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 0.9862
[09/26 14:24:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 14:24:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 14:24:19 visual_prompt]: Epoch 30 / 100: avg data time: 6.27e-02, avg batch time: 0.5038, average train loss: 0.2783
[09/26 14:24:20 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 0.9900
[09/26 14:24:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.00	
[09/26 14:24:20 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 14:24:27 visual_prompt]: Epoch 31 / 100: avg data time: 6.38e-02, avg batch time: 0.5057, average train loss: 0.2860
[09/26 14:24:29 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1666, average loss: 0.9907
[09/26 14:24:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.00	
[09/26 14:24:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 14:24:36 visual_prompt]: Epoch 32 / 100: avg data time: 5.86e-02, avg batch time: 0.5017, average train loss: 0.2823
[09/26 14:24:37 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 0.9831
[09/26 14:24:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 97.50	
[09/26 14:24:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 14:24:44 visual_prompt]: Epoch 33 / 100: avg data time: 6.65e-02, avg batch time: 0.5089, average train loss: 0.2601
[09/26 14:24:46 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.9584
[09/26 14:24:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 94.50	
[09/26 14:24:46 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 14:24:53 visual_prompt]: Epoch 34 / 100: avg data time: 6.16e-02, avg batch time: 0.5033, average train loss: 0.2132
[09/26 14:24:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 0.9738
[09/26 14:24:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 14:24:54 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 14:25:01 visual_prompt]: Epoch 35 / 100: avg data time: 5.69e-02, avg batch time: 0.4990, average train loss: 0.2552
[09/26 14:25:03 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 0.9194
[09/26 14:25:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 14:25:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 14:25:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.74e-02, avg batch time: 0.5003, average train loss: 0.3790
[09/26 14:25:11 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 1.1302
[09/26 14:25:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 92.50	
[09/26 14:25:11 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 14:25:18 visual_prompt]: Epoch 37 / 100: avg data time: 6.35e-02, avg batch time: 0.5052, average train loss: 0.3657
[09/26 14:25:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.2508
[09/26 14:25:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.50	
[09/26 14:25:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 14:25:27 visual_prompt]: Epoch 38 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 0.3265
[09/26 14:25:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.0187
[09/26 14:25:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 97.00	
[09/26 14:25:28 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 14:25:35 visual_prompt]: Epoch 39 / 100: avg data time: 6.53e-02, avg batch time: 0.5069, average train loss: 0.2621
[09/26 14:25:37 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 0.9661
[09/26 14:25:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 93.50	
[09/26 14:25:37 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 14:25:44 visual_prompt]: Epoch 40 / 100: avg data time: 4.90e-02, avg batch time: 0.4926, average train loss: 0.2298
[09/26 14:25:45 visual_prompt]: Inference (val):avg data time: 4.49e-05, avg batch time: 0.1666, average loss: 1.0002
[09/26 14:25:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 14:25:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 14:25:52 visual_prompt]: Epoch 41 / 100: avg data time: 4.82e-02, avg batch time: 0.4907, average train loss: 0.2045
[09/26 14:25:54 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 0.9042
[09/26 14:25:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 14:25:54 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 14:26:00 visual_prompt]: Epoch 42 / 100: avg data time: 4.85e-02, avg batch time: 0.4927, average train loss: 0.1658
[09/26 14:26:02 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 0.9696
[09/26 14:26:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.00	
[09/26 14:26:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 14:26:09 visual_prompt]: Epoch 43 / 100: avg data time: 5.15e-02, avg batch time: 0.4968, average train loss: 0.2332
[09/26 14:26:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.0078
[09/26 14:26:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 93.00	
[09/26 14:26:10 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 14:26:17 visual_prompt]: Epoch 44 / 100: avg data time: 4.65e-02, avg batch time: 0.4923, average train loss: 0.2012
[09/26 14:26:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 0.9478
[09/26 14:26:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 98.00	
[09/26 14:26:19 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 14:26:25 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e-02, avg batch time: 0.4938, average train loss: 0.1969
[09/26 14:26:27 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1666, average loss: 1.0366
[09/26 14:26:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.50	
[09/26 14:26:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 14:26:34 visual_prompt]: Epoch 46 / 100: avg data time: 5.12e-02, avg batch time: 0.4947, average train loss: 0.4217
[09/26 14:26:35 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1667, average loss: 1.2453
[09/26 14:26:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 91.00	
[09/26 14:26:35 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 14:26:42 visual_prompt]: Epoch 47 / 100: avg data time: 4.87e-02, avg batch time: 0.4943, average train loss: 0.4230
[09/26 14:26:44 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 1.0540
[09/26 14:26:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 94.00	
[09/26 14:26:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 14:26:51 visual_prompt]: Epoch 48 / 100: avg data time: 4.98e-02, avg batch time: 0.4950, average train loss: 0.3698
[09/26 14:26:52 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 0.9908
[09/26 14:26:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 96.00	
[09/26 14:26:52 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 14:26:59 visual_prompt]: Epoch 49 / 100: avg data time: 5.20e-02, avg batch time: 0.4955, average train loss: 0.2657
[09/26 14:27:01 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1668, average loss: 0.9754
[09/26 14:27:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 14:27:01 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 14:27:08 visual_prompt]: Epoch 50 / 100: avg data time: 6.15e-02, avg batch time: 0.5036, average train loss: 0.1843
[09/26 14:27:09 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1666, average loss: 0.9601
[09/26 14:27:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 96.00	
[09/26 14:27:09 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 14:27:16 visual_prompt]: Epoch 51 / 100: avg data time: 5.22e-02, avg batch time: 0.4952, average train loss: 0.1387
[09/26 14:27:18 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 0.9435
[09/26 14:27:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 98.00	
[09/26 14:27:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 14:27:24 visual_prompt]: Epoch 52 / 100: avg data time: 5.00e-02, avg batch time: 0.4936, average train loss: 0.1106
[09/26 14:27:26 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1667, average loss: 0.9185
[09/26 14:27:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 97.00	
[09/26 14:27:26 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 14:27:33 visual_prompt]: Epoch 53 / 100: avg data time: 5.71e-02, avg batch time: 0.5004, average train loss: 0.1006
[09/26 14:27:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 0.8202
[09/26 14:27:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.00	
[09/26 14:27:35 visual_prompt]: Best epoch 53: best metric: 0.785
[09/26 14:27:35 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 14:27:42 visual_prompt]: Epoch 54 / 100: avg data time: 6.79e-02, avg batch time: 0.5103, average train loss: 0.1123
[09/26 14:27:43 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 0.9548
[09/26 14:27:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 14:27:43 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 14:27:50 visual_prompt]: Epoch 55 / 100: avg data time: 5.06e-02, avg batch time: 0.4948, average train loss: 0.1125
[09/26 14:27:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1668, average loss: 0.9064
[09/26 14:27:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 97.00	
[09/26 14:27:52 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 14:27:58 visual_prompt]: Epoch 56 / 100: avg data time: 5.17e-02, avg batch time: 0.4980, average train loss: 0.1040
[09/26 14:28:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1669, average loss: 0.8947
[09/26 14:28:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:28:00 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 14:28:07 visual_prompt]: Epoch 57 / 100: avg data time: 5.23e-02, avg batch time: 0.4964, average train loss: 0.1014
[09/26 14:28:08 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1668, average loss: 0.8832
[09/26 14:28:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.00	
[09/26 14:28:08 visual_prompt]: Best epoch 57: best metric: 0.800
[09/26 14:28:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 14:28:15 visual_prompt]: Epoch 58 / 100: avg data time: 5.00e-02, avg batch time: 0.4935, average train loss: 0.0968
[09/26 14:28:17 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1668, average loss: 0.9025
[09/26 14:28:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:28:17 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 14:28:24 visual_prompt]: Epoch 59 / 100: avg data time: 5.03e-02, avg batch time: 0.4943, average train loss: 0.0957
[09/26 14:28:25 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1670, average loss: 0.8774
[09/26 14:28:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.00	
[09/26 14:28:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 14:28:32 visual_prompt]: Epoch 60 / 100: avg data time: 4.76e-02, avg batch time: 0.4926, average train loss: 0.0957
[09/26 14:28:34 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1669, average loss: 0.8592
[09/26 14:28:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.50	
[09/26 14:28:34 visual_prompt]: Best epoch 60: best metric: 0.805
[09/26 14:28:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 14:28:40 visual_prompt]: Epoch 61 / 100: avg data time: 5.40e-02, avg batch time: 0.4987, average train loss: 0.0956
[09/26 14:28:42 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1668, average loss: 0.8712
[09/26 14:28:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 14:28:42 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 14:28:49 visual_prompt]: Epoch 62 / 100: avg data time: 5.01e-02, avg batch time: 0.4943, average train loss: 0.0958
[09/26 14:28:50 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1669, average loss: 0.8644
[09/26 14:28:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:28:50 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 14:28:57 visual_prompt]: Epoch 63 / 100: avg data time: 5.09e-02, avg batch time: 0.4941, average train loss: 0.0963
[09/26 14:28:59 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1669, average loss: 0.8412
[09/26 14:28:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 14:28:59 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 14:29:06 visual_prompt]: Epoch 64 / 100: avg data time: 5.32e-02, avg batch time: 0.4968, average train loss: 0.0960
[09/26 14:29:07 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1667, average loss: 0.8725
[09/26 14:29:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 95.50	
[09/26 14:29:07 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 14:29:14 visual_prompt]: Epoch 65 / 100: avg data time: 4.75e-02, avg batch time: 0.4908, average train loss: 0.0958
[09/26 14:29:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 0.8533
[09/26 14:29:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.00	
[09/26 14:29:16 visual_prompt]: Best epoch 65: best metric: 0.810
[09/26 14:29:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 14:29:22 visual_prompt]: Epoch 66 / 100: avg data time: 5.37e-02, avg batch time: 0.4972, average train loss: 0.0957
[09/26 14:29:24 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1666, average loss: 0.8495
[09/26 14:29:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 97.00	
[09/26 14:29:24 visual_prompt]: Best epoch 66: best metric: 0.815
[09/26 14:29:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 14:29:31 visual_prompt]: Epoch 67 / 100: avg data time: 5.27e-02, avg batch time: 0.4957, average train loss: 0.0955
[09/26 14:29:32 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1669, average loss: 0.8569
[09/26 14:29:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.00	
[09/26 14:29:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 14:29:39 visual_prompt]: Epoch 68 / 100: avg data time: 4.97e-02, avg batch time: 0.4952, average train loss: 0.0957
[09/26 14:29:41 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1666, average loss: 0.8652
[09/26 14:29:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 95.00	
[09/26 14:29:41 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 14:29:48 visual_prompt]: Epoch 69 / 100: avg data time: 5.83e-02, avg batch time: 0.5013, average train loss: 0.1400
[09/26 14:29:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1668, average loss: 1.0132
[09/26 14:29:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 94.50	
[09/26 14:29:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 14:29:56 visual_prompt]: Epoch 70 / 100: avg data time: 5.66e-02, avg batch time: 0.4988, average train loss: 0.2415
[09/26 14:29:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.3240
[09/26 14:29:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.50	
[09/26 14:29:58 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 14:30:04 visual_prompt]: Epoch 71 / 100: avg data time: 5.82e-02, avg batch time: 0.5027, average train loss: 0.7707
[09/26 14:30:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1667, average loss: 1.9916
[09/26 14:30:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 83.50	
[09/26 14:30:06 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 14:30:13 visual_prompt]: Epoch 72 / 100: avg data time: 5.27e-02, avg batch time: 0.4949, average train loss: 0.9364
[09/26 14:30:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1667, average loss: 1.2398
[09/26 14:30:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.00	
[09/26 14:30:14 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 14:30:21 visual_prompt]: Epoch 73 / 100: avg data time: 5.14e-02, avg batch time: 0.4948, average train loss: 0.5000
[09/26 14:30:23 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.1409
[09/26 14:30:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 14:30:23 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 14:30:29 visual_prompt]: Epoch 74 / 100: avg data time: 5.22e-02, avg batch time: 0.4966, average train loss: 0.3320
[09/26 14:30:31 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1667, average loss: 0.9789
[09/26 14:30:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 95.50	
[09/26 14:30:31 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 14:30:38 visual_prompt]: Epoch 75 / 100: avg data time: 5.12e-02, avg batch time: 0.4934, average train loss: 0.1974
[09/26 14:30:39 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 0.9139
[09/26 14:30:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 14:30:39 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 14:30:46 visual_prompt]: Epoch 76 / 100: avg data time: 5.65e-02, avg batch time: 0.4986, average train loss: 0.1394
[09/26 14:30:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 0.9160
[09/26 14:30:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:30:48 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 14:30:55 visual_prompt]: Epoch 77 / 100: avg data time: 4.91e-02, avg batch time: 0.4933, average train loss: 0.1146
[09/26 14:30:56 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 0.8133
[09/26 14:30:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.00	
[09/26 14:30:56 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 14:31:03 visual_prompt]: Epoch 78 / 100: avg data time: 5.21e-02, avg batch time: 0.4982, average train loss: 0.1037
[09/26 14:31:05 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 0.8541
[09/26 14:31:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 14:31:05 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 14:31:12 visual_prompt]: Epoch 79 / 100: avg data time: 5.53e-02, avg batch time: 0.4974, average train loss: 0.0964
[09/26 14:31:13 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1667, average loss: 0.8499
[09/26 14:31:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 14:31:13 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 14:31:20 visual_prompt]: Epoch 80 / 100: avg data time: 5.43e-02, avg batch time: 0.4963, average train loss: 0.0931
[09/26 14:31:22 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 0.8541
[09/26 14:31:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:31:22 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 14:31:28 visual_prompt]: Epoch 81 / 100: avg data time: 5.16e-02, avg batch time: 0.4954, average train loss: 0.0913
[09/26 14:31:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1667, average loss: 0.8605
[09/26 14:31:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 96.50	
[09/26 14:31:30 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 14:31:37 visual_prompt]: Epoch 82 / 100: avg data time: 5.07e-02, avg batch time: 0.4943, average train loss: 0.0908
[09/26 14:31:38 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1667, average loss: 0.8513
[09/26 14:31:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.50	
[09/26 14:31:38 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 14:31:45 visual_prompt]: Epoch 83 / 100: avg data time: 5.40e-02, avg batch time: 0.4972, average train loss: 0.0892
[09/26 14:31:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 0.8562
[09/26 14:31:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 14:31:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 14:31:54 visual_prompt]: Epoch 84 / 100: avg data time: 6.16e-02, avg batch time: 0.5049, average train loss: 0.0894
[09/26 14:31:55 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1668, average loss: 0.8640
[09/26 14:31:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:31:55 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 14:32:02 visual_prompt]: Epoch 85 / 100: avg data time: 4.99e-02, avg batch time: 0.4943, average train loss: 0.0891
[09/26 14:32:04 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1669, average loss: 0.8607
[09/26 14:32:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.50	
[09/26 14:32:04 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 14:32:11 visual_prompt]: Epoch 86 / 100: avg data time: 5.95e-02, avg batch time: 0.5030, average train loss: 0.0887
[09/26 14:32:12 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1667, average loss: 0.8644
[09/26 14:32:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 96.50	
[09/26 14:32:12 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 14:32:19 visual_prompt]: Epoch 87 / 100: avg data time: 5.06e-02, avg batch time: 0.4955, average train loss: 0.0882
[09/26 14:32:21 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 0.8576
[09/26 14:32:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 96.50	
[09/26 14:32:21 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 14:32:27 visual_prompt]: Epoch 88 / 100: avg data time: 5.22e-02, avg batch time: 0.4971, average train loss: 0.0877
[09/26 14:32:29 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1668, average loss: 0.8537
[09/26 14:32:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 96.50	
[09/26 14:32:29 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 14:32:36 visual_prompt]: Epoch 89 / 100: avg data time: 5.27e-02, avg batch time: 0.4961, average train loss: 0.0878
[09/26 14:32:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 0.8544
[09/26 14:32:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.00	
[09/26 14:32:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 14:32:44 visual_prompt]: Epoch 90 / 100: avg data time: 5.96e-02, avg batch time: 0.5037, average train loss: 0.0875
[09/26 14:32:46 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 0.8641
[09/26 14:32:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:32:46 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 14:32:53 visual_prompt]: Epoch 91 / 100: avg data time: 6.36e-02, avg batch time: 0.5053, average train loss: 0.0880
[09/26 14:32:55 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 0.8613
[09/26 14:32:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:32:55 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 14:33:01 visual_prompt]: Epoch 92 / 100: avg data time: 5.21e-02, avg batch time: 0.4940, average train loss: 0.0873
[09/26 14:33:03 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1668, average loss: 0.8615
[09/26 14:33:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:03 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 14:33:10 visual_prompt]: Epoch 93 / 100: avg data time: 6.38e-02, avg batch time: 0.5056, average train loss: 0.0879
[09/26 14:33:12 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1666, average loss: 0.8624
[09/26 14:33:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 14:33:18 visual_prompt]: Epoch 94 / 100: avg data time: 5.62e-02, avg batch time: 0.4981, average train loss: 0.0876
[09/26 14:33:20 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1667, average loss: 0.8602
[09/26 14:33:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:20 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 14:33:27 visual_prompt]: Epoch 95 / 100: avg data time: 5.49e-02, avg batch time: 0.4973, average train loss: 0.0871
[09/26 14:33:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1667, average loss: 0.8593
[09/26 14:33:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:29 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 14:33:35 visual_prompt]: Epoch 96 / 100: avg data time: 5.44e-02, avg batch time: 0.4992, average train loss: 0.0881
[09/26 14:33:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 0.8589
[09/26 14:33:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:37 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 14:33:44 visual_prompt]: Epoch 97 / 100: avg data time: 5.97e-02, avg batch time: 0.5044, average train loss: 0.0874
[09/26 14:33:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1665, average loss: 0.8587
[09/26 14:33:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:46 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 14:33:52 visual_prompt]: Epoch 98 / 100: avg data time: 5.90e-02, avg batch time: 0.5022, average train loss: 0.0880
[09/26 14:33:54 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 0.8594
[09/26 14:33:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:33:54 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 14:34:01 visual_prompt]: Epoch 99 / 100: avg data time: 6.50e-02, avg batch time: 0.5093, average train loss: 0.0872
[09/26 14:34:03 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1666, average loss: 0.8596
[09/26 14:34:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:34:03 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 14:34:10 visual_prompt]: Epoch 100 / 100: avg data time: 6.35e-02, avg batch time: 0.5057, average train loss: 0.0872
[09/26 14:34:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1668, average loss: 0.8596
[09/26 14:34:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 14:34:11 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:34:11 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:34:11 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:34:11 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:34:11 visual_prompt]: Training with config:
[09/26 14:34:11 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:34:11 visual_prompt]: Loading training data...
[09/26 14:34:11 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:34:12 visual_prompt]: Number of images: 800
[09/26 14:34:12 visual_prompt]: Number of classes: 45 / 45
[09/26 14:34:12 visual_prompt]: Loading validation data...
[09/26 14:34:12 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:34:13 visual_prompt]: Number of images: 200
[09/26 14:34:13 visual_prompt]: Number of classes: 45 / 45
[09/26 14:34:13 visual_prompt]: Constructing models...
[09/26 14:34:15 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 14:34:15 visual_prompt]: tuned percent:0.574
[09/26 14:34:15 visual_prompt]: Device used for model: 0
[09/26 14:34:15 visual_prompt]: Setting up Evaluator...
[09/26 14:34:15 visual_prompt]: Setting up Trainer...
[09/26 14:34:15 visual_prompt]: 	Setting up the optimizer...
[09/26 14:34:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:34:22 visual_prompt]: Epoch 1 / 100: avg data time: 4.68e-02, avg batch time: 0.4890, average train loss: 3.8945
[09/26 14:34:24 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1659, average loss: 3.9529
[09/26 14:34:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 14:34:24 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 14:34:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 14:34:30 visual_prompt]: Epoch 2 / 100: avg data time: 5.82e-02, avg batch time: 0.5001, average train loss: 3.8328
[09/26 14:34:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1660, average loss: 3.8114
[09/26 14:34:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 11.00	
[09/26 14:34:32 visual_prompt]: Best epoch 2: best metric: 0.030
[09/26 14:34:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 14:34:39 visual_prompt]: Epoch 3 / 100: avg data time: 5.06e-02, avg batch time: 0.4926, average train loss: 3.7147
[09/26 14:34:40 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1660, average loss: 3.6682
[09/26 14:34:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 25.50	
[09/26 14:34:40 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 14:34:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 14:34:47 visual_prompt]: Epoch 4 / 100: avg data time: 5.32e-02, avg batch time: 0.4946, average train loss: 3.4751
[09/26 14:34:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1660, average loss: 3.1017
[09/26 14:34:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 18.50	top5: 46.00	
[09/26 14:34:49 visual_prompt]: Best epoch 4: best metric: 0.185
[09/26 14:34:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 14:34:56 visual_prompt]: Epoch 5 / 100: avg data time: 5.98e-02, avg batch time: 0.5009, average train loss: 2.9496
[09/26 14:34:57 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 2.7115
[09/26 14:34:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 28.00	top5: 62.50	
[09/26 14:34:57 visual_prompt]: Best epoch 5: best metric: 0.280
[09/26 14:34:57 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 14:35:04 visual_prompt]: Epoch 6 / 100: avg data time: 4.82e-02, avg batch time: 0.4902, average train loss: 2.3962
[09/26 14:35:06 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1661, average loss: 2.3679
[09/26 14:35:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.50	top5: 69.00	
[09/26 14:35:06 visual_prompt]: Best epoch 6: best metric: 0.305
[09/26 14:35:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 14:35:13 visual_prompt]: Epoch 7 / 100: avg data time: 5.16e-02, avg batch time: 0.4935, average train loss: 1.9877
[09/26 14:35:14 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1661, average loss: 2.2041
[09/26 14:35:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 40.50	top5: 74.50	
[09/26 14:35:14 visual_prompt]: Best epoch 7: best metric: 0.405
[09/26 14:35:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 14:35:21 visual_prompt]: Epoch 8 / 100: avg data time: 5.16e-02, avg batch time: 0.4939, average train loss: 1.4624
[09/26 14:35:23 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1671, average loss: 1.9061
[09/26 14:35:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 44.00	top5: 78.50	
[09/26 14:35:23 visual_prompt]: Best epoch 8: best metric: 0.440
[09/26 14:35:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 14:35:30 visual_prompt]: Epoch 9 / 100: avg data time: 5.19e-02, avg batch time: 0.4967, average train loss: 1.2756
[09/26 14:35:31 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1662, average loss: 1.8332
[09/26 14:35:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 46.50	top5: 82.50	
[09/26 14:35:31 visual_prompt]: Best epoch 9: best metric: 0.465
[09/26 14:35:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 14:35:38 visual_prompt]: Epoch 10 / 100: avg data time: 5.05e-02, avg batch time: 0.4924, average train loss: 0.9539
[09/26 14:35:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1661, average loss: 1.5789
[09/26 14:35:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.00	top5: 86.50	
[09/26 14:35:39 visual_prompt]: Best epoch 10: best metric: 0.580
[09/26 14:35:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 14:35:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.00e-02, avg batch time: 0.4926, average train loss: 0.8033
[09/26 14:35:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 1.3791
[09/26 14:35:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 85.50	
[09/26 14:35:48 visual_prompt]: Best epoch 11: best metric: 0.640
[09/26 14:35:48 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 14:35:55 visual_prompt]: Epoch 12 / 100: avg data time: 5.46e-02, avg batch time: 0.4967, average train loss: 0.5792
[09/26 14:35:56 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.2106
[09/26 14:35:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.00	
[09/26 14:35:56 visual_prompt]: Best epoch 12: best metric: 0.660
[09/26 14:35:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 14:36:03 visual_prompt]: Epoch 13 / 100: avg data time: 4.92e-02, avg batch time: 0.4935, average train loss: 0.3697
[09/26 14:36:05 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.2298
[09/26 14:36:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.50	top5: 92.50	
[09/26 14:36:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 14:36:12 visual_prompt]: Epoch 14 / 100: avg data time: 6.21e-02, avg batch time: 0.5030, average train loss: 0.3526
[09/26 14:36:13 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1661, average loss: 1.1939
[09/26 14:36:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.00	
[09/26 14:36:13 visual_prompt]: Best epoch 14: best metric: 0.665
[09/26 14:36:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 14:36:20 visual_prompt]: Epoch 15 / 100: avg data time: 5.42e-02, avg batch time: 0.4986, average train loss: 0.2664
[09/26 14:36:22 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 1.1024
[09/26 14:36:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.00	
[09/26 14:36:22 visual_prompt]: Best epoch 15: best metric: 0.685
[09/26 14:36:22 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 14:36:28 visual_prompt]: Epoch 16 / 100: avg data time: 5.04e-02, avg batch time: 0.4919, average train loss: 0.2594
[09/26 14:36:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1662, average loss: 1.1154
[09/26 14:36:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 89.00	
[09/26 14:36:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 14:36:37 visual_prompt]: Epoch 17 / 100: avg data time: 6.08e-02, avg batch time: 0.5031, average train loss: 0.1884
[09/26 14:36:39 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1663, average loss: 1.0949
[09/26 14:36:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 90.50	
[09/26 14:36:39 visual_prompt]: Best epoch 17: best metric: 0.695
[09/26 14:36:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 14:36:45 visual_prompt]: Epoch 18 / 100: avg data time: 4.84e-02, avg batch time: 0.4914, average train loss: 0.1198
[09/26 14:36:47 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.0477
[09/26 14:36:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 91.00	
[09/26 14:36:47 visual_prompt]: Best epoch 18: best metric: 0.700
[09/26 14:36:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 14:36:54 visual_prompt]: Epoch 19 / 100: avg data time: 5.16e-02, avg batch time: 0.4944, average train loss: 0.0936
[09/26 14:36:55 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1665, average loss: 1.0632
[09/26 14:36:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 93.00	
[09/26 14:36:55 visual_prompt]: Best epoch 19: best metric: 0.725
[09/26 14:36:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 14:37:02 visual_prompt]: Epoch 20 / 100: avg data time: 5.09e-02, avg batch time: 0.4944, average train loss: 0.0530
[09/26 14:37:04 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.0693
[09/26 14:37:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 14:37:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 14:37:11 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e-02, avg batch time: 0.4928, average train loss: 0.0379
[09/26 14:37:12 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.9951
[09/26 14:37:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.00	
[09/26 14:37:12 visual_prompt]: Best epoch 21: best metric: 0.730
[09/26 14:37:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 14:37:19 visual_prompt]: Epoch 22 / 100: avg data time: 6.55e-02, avg batch time: 0.5077, average train loss: 0.0404
[09/26 14:37:21 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 0.8975
[09/26 14:37:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 93.50	
[09/26 14:37:21 visual_prompt]: Best epoch 22: best metric: 0.765
[09/26 14:37:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 14:37:28 visual_prompt]: Epoch 23 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 0.0319
[09/26 14:37:29 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 0.9227
[09/26 14:37:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 95.00	
[09/26 14:37:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 14:37:36 visual_prompt]: Epoch 24 / 100: avg data time: 5.21e-02, avg batch time: 0.4956, average train loss: 0.0302
[09/26 14:37:38 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 0.9201
[09/26 14:37:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 94.50	
[09/26 14:37:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 14:37:44 visual_prompt]: Epoch 25 / 100: avg data time: 4.94e-02, avg batch time: 0.4949, average train loss: 0.0242
[09/26 14:37:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 0.8983
[09/26 14:37:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 93.50	
[09/26 14:37:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 14:37:53 visual_prompt]: Epoch 26 / 100: avg data time: 6.03e-02, avg batch time: 0.5039, average train loss: 0.0188
[09/26 14:37:55 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1660, average loss: 0.8960
[09/26 14:37:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 14:37:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 14:38:01 visual_prompt]: Epoch 27 / 100: avg data time: 5.66e-02, avg batch time: 0.4996, average train loss: 0.0165
[09/26 14:38:03 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1662, average loss: 0.8705
[09/26 14:38:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.00	
[09/26 14:38:03 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 14:38:10 visual_prompt]: Epoch 28 / 100: avg data time: 5.00e-02, avg batch time: 0.4917, average train loss: 0.0150
[09/26 14:38:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 0.8686
[09/26 14:38:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 93.50	
[09/26 14:38:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 14:38:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.39e-02, avg batch time: 0.4955, average train loss: 0.0133
[09/26 14:38:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 0.8635
[09/26 14:38:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 93.50	
[09/26 14:38:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 14:38:27 visual_prompt]: Epoch 30 / 100: avg data time: 5.05e-02, avg batch time: 0.4942, average train loss: 0.0133
[09/26 14:38:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 0.8701
[09/26 14:38:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 94.00	
[09/26 14:38:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 14:38:35 visual_prompt]: Epoch 31 / 100: avg data time: 4.86e-02, avg batch time: 0.4913, average train loss: 0.0133
[09/26 14:38:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 0.8843
[09/26 14:38:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 93.50	
[09/26 14:38:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 14:38:44 visual_prompt]: Epoch 32 / 100: avg data time: 5.93e-02, avg batch time: 0.5022, average train loss: 0.0128
[09/26 14:38:45 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1662, average loss: 0.8840
[09/26 14:38:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 93.50	
[09/26 14:38:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 14:38:52 visual_prompt]: Epoch 33 / 100: avg data time: 6.38e-02, avg batch time: 0.5058, average train loss: 0.0125
[09/26 14:38:54 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.8892
[09/26 14:38:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 93.50	
[09/26 14:38:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 14:39:01 visual_prompt]: Epoch 34 / 100: avg data time: 5.31e-02, avg batch time: 0.4956, average train loss: 0.0127
[09/26 14:39:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1665, average loss: 0.8939
[09/26 14:39:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 93.50	
[09/26 14:39:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 14:39:09 visual_prompt]: Epoch 35 / 100: avg data time: 4.99e-02, avg batch time: 0.4924, average train loss: 0.0126
[09/26 14:39:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 0.8918
[09/26 14:39:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 93.50	
[09/26 14:39:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 14:39:17 visual_prompt]: Epoch 36 / 100: avg data time: 5.21e-02, avg batch time: 0.4961, average train loss: 0.0121
[09/26 14:39:19 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 0.9017
[09/26 14:39:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 93.50	
[09/26 14:39:19 visual_prompt]: Best epoch 36: best metric: 0.770
[09/26 14:39:19 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 14:39:26 visual_prompt]: Epoch 37 / 100: avg data time: 4.82e-02, avg batch time: 0.4907, average train loss: 0.0117
[09/26 14:39:27 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 0.8825
[09/26 14:39:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 93.50	
[09/26 14:39:27 visual_prompt]: Best epoch 37: best metric: 0.775
[09/26 14:39:27 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 14:39:34 visual_prompt]: Epoch 38 / 100: avg data time: 5.19e-02, avg batch time: 0.4941, average train loss: 0.0116
[09/26 14:39:36 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 0.8781
[09/26 14:39:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.00	
[09/26 14:39:36 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 14:39:42 visual_prompt]: Epoch 39 / 100: avg data time: 5.12e-02, avg batch time: 0.4954, average train loss: 0.0122
[09/26 14:39:44 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1664, average loss: 0.8759
[09/26 14:39:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.00	
[09/26 14:39:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 14:39:51 visual_prompt]: Epoch 40 / 100: avg data time: 4.89e-02, avg batch time: 0.4924, average train loss: 0.0117
[09/26 14:39:53 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 0.9022
[09/26 14:39:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.00	
[09/26 14:39:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 14:39:59 visual_prompt]: Epoch 41 / 100: avg data time: 6.03e-02, avg batch time: 0.5019, average train loss: 0.0117
[09/26 14:40:01 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 0.9023
[09/26 14:40:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.00	
[09/26 14:40:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 14:40:08 visual_prompt]: Epoch 42 / 100: avg data time: 6.29e-02, avg batch time: 0.5058, average train loss: 0.0118
[09/26 14:40:10 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1663, average loss: 0.9078
[09/26 14:40:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.00	
[09/26 14:40:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 14:40:17 visual_prompt]: Epoch 43 / 100: avg data time: 6.15e-02, avg batch time: 0.5035, average train loss: 0.0118
[09/26 14:40:18 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 0.9180
[09/26 14:40:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:40:18 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 14:40:25 visual_prompt]: Epoch 44 / 100: avg data time: 6.71e-02, avg batch time: 0.5082, average train loss: 0.0113
[09/26 14:40:27 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1664, average loss: 0.8882
[09/26 14:40:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 94.50	
[09/26 14:40:27 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 14:40:34 visual_prompt]: Epoch 45 / 100: avg data time: 7.02e-02, avg batch time: 0.5118, average train loss: 0.0121
[09/26 14:40:35 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1663, average loss: 0.8707
[09/26 14:40:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.50	
[09/26 14:40:35 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 14:40:42 visual_prompt]: Epoch 46 / 100: avg data time: 5.67e-02, avg batch time: 0.4984, average train loss: 0.0114
[09/26 14:40:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 0.8834
[09/26 14:40:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.00	
[09/26 14:40:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 14:40:51 visual_prompt]: Epoch 47 / 100: avg data time: 5.19e-02, avg batch time: 0.4957, average train loss: 0.0113
[09/26 14:40:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1661, average loss: 0.8946
[09/26 14:40:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:40:52 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 14:40:59 visual_prompt]: Epoch 48 / 100: avg data time: 4.96e-02, avg batch time: 0.4945, average train loss: 0.0113
[09/26 14:41:01 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 0.9024
[09/26 14:41:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.00	
[09/26 14:41:01 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 14:41:08 visual_prompt]: Epoch 49 / 100: avg data time: 4.99e-02, avg batch time: 0.4934, average train loss: 0.0116
[09/26 14:41:09 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1664, average loss: 0.8965
[09/26 14:41:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.00	
[09/26 14:41:09 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 14:41:16 visual_prompt]: Epoch 50 / 100: avg data time: 4.69e-02, avg batch time: 0.4903, average train loss: 0.0110
[09/26 14:41:18 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 0.8971
[09/26 14:41:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.00	
[09/26 14:41:18 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 14:41:25 visual_prompt]: Epoch 51 / 100: avg data time: 5.89e-02, avg batch time: 0.5021, average train loss: 0.0109
[09/26 14:41:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 0.9041
[09/26 14:41:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 94.50	
[09/26 14:41:26 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 14:41:33 visual_prompt]: Epoch 52 / 100: avg data time: 5.08e-02, avg batch time: 0.4930, average train loss: 0.0110
[09/26 14:41:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 0.9035
[09/26 14:41:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:41:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 14:41:42 visual_prompt]: Epoch 53 / 100: avg data time: 5.29e-02, avg batch time: 0.4950, average train loss: 0.0109
[09/26 14:41:43 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 0.9068
[09/26 14:41:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:41:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 14:41:50 visual_prompt]: Epoch 54 / 100: avg data time: 5.00e-02, avg batch time: 0.4936, average train loss: 0.0108
[09/26 14:41:52 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1663, average loss: 0.8973
[09/26 14:41:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:41:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 14:41:59 visual_prompt]: Epoch 55 / 100: avg data time: 5.74e-02, avg batch time: 0.4996, average train loss: 0.0110
[09/26 14:42:00 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 0.8931
[09/26 14:42:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:42:00 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 14:42:07 visual_prompt]: Epoch 56 / 100: avg data time: 5.69e-02, avg batch time: 0.5000, average train loss: 0.0108
[09/26 14:42:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 0.8965
[09/26 14:42:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:42:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 14:42:15 visual_prompt]: Epoch 57 / 100: avg data time: 4.71e-02, avg batch time: 0.4914, average train loss: 0.0109
[09/26 14:42:17 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 0.8889
[09/26 14:42:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 14:42:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 14:42:24 visual_prompt]: Epoch 58 / 100: avg data time: 5.21e-02, avg batch time: 0.4974, average train loss: 0.0109
[09/26 14:42:26 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 0.9025
[09/26 14:42:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:42:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 14:42:33 visual_prompt]: Epoch 59 / 100: avg data time: 6.96e-02, avg batch time: 0.5111, average train loss: 0.0111
[09/26 14:42:34 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 0.8802
[09/26 14:42:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 14:42:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 14:42:41 visual_prompt]: Epoch 60 / 100: avg data time: 5.28e-02, avg batch time: 0.4957, average train loss: 0.0106
[09/26 14:42:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 0.8907
[09/26 14:42:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 95.00	
[09/26 14:42:43 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 14:42:50 visual_prompt]: Epoch 61 / 100: avg data time: 6.01e-02, avg batch time: 0.5030, average train loss: 0.0105
[09/26 14:42:51 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 0.8967
[09/26 14:42:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:42:51 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 14:42:58 visual_prompt]: Epoch 62 / 100: avg data time: 5.32e-02, avg batch time: 0.4966, average train loss: 0.0107
[09/26 14:43:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 0.8910
[09/26 14:43:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:00 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 14:43:07 visual_prompt]: Epoch 63 / 100: avg data time: 5.15e-02, avg batch time: 0.4956, average train loss: 0.0112
[09/26 14:43:08 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 0.8864
[09/26 14:43:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:08 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 14:43:15 visual_prompt]: Epoch 64 / 100: avg data time: 6.71e-02, avg batch time: 0.5085, average train loss: 0.0110
[09/26 14:43:17 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1663, average loss: 0.8829
[09/26 14:43:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 14:43:24 visual_prompt]: Epoch 65 / 100: avg data time: 5.06e-02, avg batch time: 0.4924, average train loss: 0.0108
[09/26 14:43:25 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 0.8833
[09/26 14:43:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:25 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 14:43:32 visual_prompt]: Epoch 66 / 100: avg data time: 5.77e-02, avg batch time: 0.5005, average train loss: 0.0107
[09/26 14:43:34 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 0.8874
[09/26 14:43:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:34 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 14:43:41 visual_prompt]: Epoch 67 / 100: avg data time: 5.40e-02, avg batch time: 0.4970, average train loss: 0.0109
[09/26 14:43:42 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 0.8900
[09/26 14:43:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:43:42 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 14:43:49 visual_prompt]: Epoch 68 / 100: avg data time: 6.23e-02, avg batch time: 0.5049, average train loss: 0.0105
[09/26 14:43:51 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1663, average loss: 0.8878
[09/26 14:43:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 14:43:51 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 14:43:58 visual_prompt]: Epoch 69 / 100: avg data time: 5.39e-02, avg batch time: 0.4959, average train loss: 0.0104
[09/26 14:43:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 0.8872
[09/26 14:43:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 14:43:59 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 14:44:06 visual_prompt]: Epoch 70 / 100: avg data time: 6.59e-02, avg batch time: 0.5073, average train loss: 0.0106
[09/26 14:44:08 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1664, average loss: 0.8886
[09/26 14:44:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:44:08 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 14:44:15 visual_prompt]: Epoch 71 / 100: avg data time: 5.73e-02, avg batch time: 0.5002, average train loss: 0.0108
[09/26 14:44:16 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1661, average loss: 0.8862
[09/26 14:44:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:44:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 14:44:23 visual_prompt]: Epoch 72 / 100: avg data time: 6.11e-02, avg batch time: 0.5031, average train loss: 0.0108
[09/26 14:44:25 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 0.8897
[09/26 14:44:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 14:44:25 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 14:44:32 visual_prompt]: Epoch 73 / 100: avg data time: 6.26e-02, avg batch time: 0.5044, average train loss: 0.0106
[09/26 14:44:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 0.8915
[09/26 14:44:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 14:44:33 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 14:44:40 visual_prompt]: Epoch 74 / 100: avg data time: 4.93e-02, avg batch time: 0.4931, average train loss: 0.0106
[09/26 14:44:42 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 0.8841
[09/26 14:44:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:44:42 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 14:44:49 visual_prompt]: Epoch 75 / 100: avg data time: 5.91e-02, avg batch time: 0.5011, average train loss: 0.0107
[09/26 14:44:50 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 0.8866
[09/26 14:44:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:44:50 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 14:44:57 visual_prompt]: Epoch 76 / 100: avg data time: 5.17e-02, avg batch time: 0.4941, average train loss: 0.0108
[09/26 14:44:59 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1665, average loss: 0.8932
[09/26 14:44:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 14:44:59 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 14:45:06 visual_prompt]: Epoch 77 / 100: avg data time: 5.80e-02, avg batch time: 0.5003, average train loss: 0.0107
[09/26 14:45:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 0.8879
[09/26 14:45:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 14:45:07 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 14:45:14 visual_prompt]: Epoch 78 / 100: avg data time: 5.92e-02, avg batch time: 0.5022, average train loss: 0.0108
[09/26 14:45:16 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1664, average loss: 0.8857
[09/26 14:45:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:45:16 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 14:45:22 visual_prompt]: Epoch 79 / 100: avg data time: 5.83e-02, avg batch time: 0.5009, average train loss: 0.0102
[09/26 14:45:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 0.8840
[09/26 14:45:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.00	
[09/26 14:45:24 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 14:45:31 visual_prompt]: Epoch 80 / 100: avg data time: 5.94e-02, avg batch time: 0.5022, average train loss: 0.0107
[09/26 14:45:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 0.8804
[09/26 14:45:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:45:33 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 14:45:39 visual_prompt]: Epoch 81 / 100: avg data time: 5.10e-02, avg batch time: 0.4949, average train loss: 0.0105
[09/26 14:45:41 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1664, average loss: 0.8820
[09/26 14:45:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.50	
[09/26 14:45:41 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 14:45:48 visual_prompt]: Epoch 82 / 100: avg data time: 4.79e-02, avg batch time: 0.4896, average train loss: 0.0105
[09/26 14:45:49 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1666, average loss: 0.8833
[09/26 14:45:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 14:45:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 14:45:56 visual_prompt]: Epoch 83 / 100: avg data time: 5.05e-02, avg batch time: 0.4920, average train loss: 0.0105
[09/26 14:45:58 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 0.8860
[09/26 14:45:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.50	
[09/26 14:45:58 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 14:46:05 visual_prompt]: Epoch 84 / 100: avg data time: 5.00e-02, avg batch time: 0.4935, average train loss: 0.0106
[09/26 14:46:06 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1663, average loss: 0.8877
[09/26 14:46:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:46:06 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 14:46:13 visual_prompt]: Epoch 85 / 100: avg data time: 5.65e-02, avg batch time: 0.4996, average train loss: 0.0106
[09/26 14:46:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1667, average loss: 0.8877
[09/26 14:46:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 94.50	
[09/26 14:46:15 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 14:46:21 visual_prompt]: Epoch 86 / 100: avg data time: 4.71e-02, avg batch time: 0.4917, average train loss: 0.0102
[09/26 14:46:23 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1667, average loss: 0.8863
[09/26 14:46:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 94.50	
[09/26 14:46:23 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 14:46:30 visual_prompt]: Epoch 87 / 100: avg data time: 5.33e-02, avg batch time: 0.4965, average train loss: 0.0104
[09/26 14:46:31 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 0.8855
[09/26 14:46:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:46:31 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 14:46:38 visual_prompt]: Epoch 88 / 100: avg data time: 6.72e-02, avg batch time: 0.5098, average train loss: 0.0103
[09/26 14:46:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 0.8847
[09/26 14:46:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:46:40 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 14:46:47 visual_prompt]: Epoch 89 / 100: avg data time: 6.28e-02, avg batch time: 0.5061, average train loss: 0.0105
[09/26 14:46:49 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 0.8845
[09/26 14:46:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:46:49 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 14:46:55 visual_prompt]: Epoch 90 / 100: avg data time: 4.89e-02, avg batch time: 0.4920, average train loss: 0.0103
[09/26 14:46:57 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 0.8851
[09/26 14:46:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:46:57 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 14:47:04 visual_prompt]: Epoch 91 / 100: avg data time: 5.82e-02, avg batch time: 0.5026, average train loss: 0.0105
[09/26 14:47:05 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1666, average loss: 0.8857
[09/26 14:47:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.00	
[09/26 14:47:05 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 14:47:12 visual_prompt]: Epoch 92 / 100: avg data time: 5.14e-02, avg batch time: 0.4942, average train loss: 0.0105
[09/26 14:47:14 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 0.8851
[09/26 14:47:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:14 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 14:47:21 visual_prompt]: Epoch 93 / 100: avg data time: 4.98e-02, avg batch time: 0.4932, average train loss: 0.0105
[09/26 14:47:22 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 0.8847
[09/26 14:47:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 14:47:29 visual_prompt]: Epoch 94 / 100: avg data time: 5.37e-02, avg batch time: 0.4969, average train loss: 0.0103
[09/26 14:47:31 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1665, average loss: 0.8849
[09/26 14:47:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 14:47:37 visual_prompt]: Epoch 95 / 100: avg data time: 5.63e-02, avg batch time: 0.4991, average train loss: 0.0104
[09/26 14:47:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 0.8850
[09/26 14:47:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:39 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 14:47:46 visual_prompt]: Epoch 96 / 100: avg data time: 5.16e-02, avg batch time: 0.4955, average train loss: 0.0105
[09/26 14:47:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 0.8852
[09/26 14:47:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:47 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 14:47:54 visual_prompt]: Epoch 97 / 100: avg data time: 5.55e-02, avg batch time: 0.4988, average train loss: 0.0106
[09/26 14:47:56 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 0.8851
[09/26 14:47:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:47:56 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 14:48:03 visual_prompt]: Epoch 98 / 100: avg data time: 5.96e-02, avg batch time: 0.5014, average train loss: 0.0106
[09/26 14:48:04 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 0.8851
[09/26 14:48:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:48:04 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 14:48:11 visual_prompt]: Epoch 99 / 100: avg data time: 5.92e-02, avg batch time: 0.5014, average train loss: 0.0105
[09/26 14:48:13 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 0.8851
[09/26 14:48:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:48:13 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 14:48:20 visual_prompt]: Epoch 100 / 100: avg data time: 5.01e-02, avg batch time: 0.4939, average train loss: 0.0106
[09/26 14:48:21 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 0.8851
[09/26 14:48:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 95.00	
[09/26 14:48:21 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 14:48:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 14:48:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 14:48:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 14:48:21 visual_prompt]: Training with config:
[09/26 14:48:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 14:48:21 visual_prompt]: Loading training data...
[09/26 14:48:21 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:48:23 visual_prompt]: Number of images: 800
[09/26 14:48:23 visual_prompt]: Number of classes: 45 / 45
[09/26 14:48:23 visual_prompt]: Loading validation data...
[09/26 14:48:23 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 14:48:23 visual_prompt]: Number of images: 200
[09/26 14:48:23 visual_prompt]: Number of classes: 45 / 45
[09/26 14:48:23 visual_prompt]: Constructing models...
[09/26 14:48:25 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 14:48:25 visual_prompt]: tuned percent:0.574
[09/26 14:48:25 visual_prompt]: Device used for model: 0
[09/26 14:48:25 visual_prompt]: Setting up Evaluator...
[09/26 14:48:25 visual_prompt]: Setting up Trainer...
[09/26 14:48:25 visual_prompt]: 	Setting up the optimizer...
[09/26 14:48:25 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 14:48:32 visual_prompt]: Epoch 1 / 100: avg data time: 6.50e-02, avg batch time: 0.5062, average train loss: 3.8974
[09/26 14:48:34 visual_prompt]: Inference (val):avg data time: 4.51e-05, avg batch time: 0.1660, average loss: 3.9529
[09/26 14:48:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 14:48:34 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 14:48:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 14:48:41 visual_prompt]: Epoch 2 / 100: avg data time: 5.28e-02, avg batch time: 0.4936, average train loss: 3.8330
[09/26 14:48:42 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1662, average loss: 3.8425
[09/26 14:48:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 13.50	
[09/26 14:48:42 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 14:48:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 14:48:49 visual_prompt]: Epoch 3 / 100: avg data time: 5.06e-02, avg batch time: 0.4940, average train loss: 3.7433
[09/26 14:48:51 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 3.6422
[09/26 14:48:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 7.00	top5: 28.50	
[09/26 14:48:51 visual_prompt]: Best epoch 3: best metric: 0.070
[09/26 14:48:51 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 14:48:58 visual_prompt]: Epoch 4 / 100: avg data time: 6.70e-02, avg batch time: 0.5080, average train loss: 3.4886
[09/26 14:49:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1663, average loss: 3.1085
[09/26 14:49:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 20.50	top5: 50.50	
[09/26 14:49:00 visual_prompt]: Best epoch 4: best metric: 0.205
[09/26 14:49:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 14:49:06 visual_prompt]: Epoch 5 / 100: avg data time: 5.06e-02, avg batch time: 0.4938, average train loss: 3.0037
[09/26 14:49:08 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1663, average loss: 2.6604
[09/26 14:49:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.50	top5: 61.00	
[09/26 14:49:08 visual_prompt]: Best epoch 5: best metric: 0.235
[09/26 14:49:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 14:49:15 visual_prompt]: Epoch 6 / 100: avg data time: 6.40e-02, avg batch time: 0.5055, average train loss: 2.5859
[09/26 14:49:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1666, average loss: 2.5457
[09/26 14:49:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.00	top5: 67.50	
[09/26 14:49:17 visual_prompt]: Best epoch 6: best metric: 0.300
[09/26 14:49:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 14:49:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e-02, avg batch time: 0.4935, average train loss: 2.1163
[09/26 14:49:25 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1666, average loss: 2.1860
[09/26 14:49:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 39.00	top5: 72.50	
[09/26 14:49:25 visual_prompt]: Best epoch 7: best metric: 0.390
[09/26 14:49:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 14:49:32 visual_prompt]: Epoch 8 / 100: avg data time: 6.88e-02, avg batch time: 0.5118, average train loss: 1.7724
[09/26 14:49:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.8175
[09/26 14:49:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 45.50	top5: 83.50	
[09/26 14:49:34 visual_prompt]: Best epoch 8: best metric: 0.455
[09/26 14:49:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 14:49:41 visual_prompt]: Epoch 9 / 100: avg data time: 5.31e-02, avg batch time: 0.4980, average train loss: 1.5040
[09/26 14:49:42 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1669, average loss: 1.6792
[09/26 14:49:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 85.00	
[09/26 14:49:42 visual_prompt]: Best epoch 9: best metric: 0.490
[09/26 14:49:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 14:49:49 visual_prompt]: Epoch 10 / 100: avg data time: 6.13e-02, avg batch time: 0.5030, average train loss: 1.0670
[09/26 14:49:51 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1666, average loss: 1.5540
[09/26 14:49:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.00	top5: 89.50	
[09/26 14:49:51 visual_prompt]: Best epoch 10: best metric: 0.500
[09/26 14:49:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 14:49:58 visual_prompt]: Epoch 11 / 100: avg data time: 5.66e-02, avg batch time: 0.5008, average train loss: 0.8167
[09/26 14:49:59 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1667, average loss: 1.2199
[09/26 14:49:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 92.50	
[09/26 14:49:59 visual_prompt]: Best epoch 11: best metric: 0.645
[09/26 14:49:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 14:50:06 visual_prompt]: Epoch 12 / 100: avg data time: 5.89e-02, avg batch time: 0.5033, average train loss: 0.6105
[09/26 14:50:08 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.1831
[09/26 14:50:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 93.50	
[09/26 14:50:08 visual_prompt]: Best epoch 12: best metric: 0.655
[09/26 14:50:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 14:50:15 visual_prompt]: Epoch 13 / 100: avg data time: 5.27e-02, avg batch time: 0.4952, average train loss: 0.4366
[09/26 14:50:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1668, average loss: 1.2321
[09/26 14:50:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 92.50	
[09/26 14:50:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 14:50:23 visual_prompt]: Epoch 14 / 100: avg data time: 5.21e-02, avg batch time: 0.4962, average train loss: 0.2887
[09/26 14:50:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 1.2334
[09/26 14:50:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 92.50	
[09/26 14:50:25 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 14:50:32 visual_prompt]: Epoch 15 / 100: avg data time: 5.99e-02, avg batch time: 0.5034, average train loss: 0.2211
[09/26 14:50:33 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1669, average loss: 1.2811
[09/26 14:50:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 91.00	
[09/26 14:50:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 14:50:40 visual_prompt]: Epoch 16 / 100: avg data time: 5.14e-02, avg batch time: 0.4956, average train loss: 0.1764
[09/26 14:50:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 1.2367
[09/26 14:50:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.00	
[09/26 14:50:42 visual_prompt]: Best epoch 16: best metric: 0.685
[09/26 14:50:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 14:50:49 visual_prompt]: Epoch 17 / 100: avg data time: 5.14e-02, avg batch time: 0.4935, average train loss: 0.1256
[09/26 14:50:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 1.2265
[09/26 14:50:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.50	
[09/26 14:50:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 14:50:57 visual_prompt]: Epoch 18 / 100: avg data time: 5.17e-02, avg batch time: 0.4953, average train loss: 0.0837
[09/26 14:50:59 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1667, average loss: 1.2139
[09/26 14:50:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 91.00	
[09/26 14:50:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 14:51:05 visual_prompt]: Epoch 19 / 100: avg data time: 4.98e-02, avg batch time: 0.4935, average train loss: 0.0456
[09/26 14:51:07 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1667, average loss: 1.1915
[09/26 14:51:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 91.50	
[09/26 14:51:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 14:51:14 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e-02, avg batch time: 0.4944, average train loss: 0.0329
[09/26 14:51:16 visual_prompt]: Inference (val):avg data time: 4.21e-05, avg batch time: 0.1665, average loss: 1.1602
[09/26 14:51:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 91.00	
[09/26 14:51:16 visual_prompt]: Best epoch 20: best metric: 0.705
[09/26 14:51:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 14:51:22 visual_prompt]: Epoch 21 / 100: avg data time: 5.33e-02, avg batch time: 0.4960, average train loss: 0.0307
[09/26 14:51:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1667, average loss: 1.1705
[09/26 14:51:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.00	
[09/26 14:51:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 14:51:31 visual_prompt]: Epoch 22 / 100: avg data time: 5.14e-02, avg batch time: 0.4951, average train loss: 0.0215
[09/26 14:51:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1666, average loss: 1.1252
[09/26 14:51:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 14:51:32 visual_prompt]: Best epoch 22: best metric: 0.710
[09/26 14:51:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 14:51:39 visual_prompt]: Epoch 23 / 100: avg data time: 5.77e-02, avg batch time: 0.5001, average train loss: 0.0189
[09/26 14:51:41 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.2061
[09/26 14:51:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 94.00	
[09/26 14:51:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 14:51:48 visual_prompt]: Epoch 24 / 100: avg data time: 5.78e-02, avg batch time: 0.5007, average train loss: 0.0164
[09/26 14:51:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 1.1535
[09/26 14:51:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 14:51:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 14:51:56 visual_prompt]: Epoch 25 / 100: avg data time: 4.89e-02, avg batch time: 0.4949, average train loss: 0.0135
[09/26 14:51:58 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1666, average loss: 1.1444
[09/26 14:51:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.00	
[09/26 14:51:58 visual_prompt]: Best epoch 25: best metric: 0.715
[09/26 14:51:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 14:52:05 visual_prompt]: Epoch 26 / 100: avg data time: 5.97e-02, avg batch time: 0.5028, average train loss: 0.0129
[09/26 14:52:07 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.1729
[09/26 14:52:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 94.00	
[09/26 14:52:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 14:52:13 visual_prompt]: Epoch 27 / 100: avg data time: 5.05e-02, avg batch time: 0.4949, average train loss: 0.0311
[09/26 14:52:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1667, average loss: 1.1818
[09/26 14:52:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 14:52:15 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 14:52:22 visual_prompt]: Epoch 28 / 100: avg data time: 5.16e-02, avg batch time: 0.4951, average train loss: 0.0239
[09/26 14:52:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.2372
[09/26 14:52:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 14:52:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 14:52:30 visual_prompt]: Epoch 29 / 100: avg data time: 5.86e-02, avg batch time: 0.5009, average train loss: 0.0511
[09/26 14:52:32 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1666, average loss: 1.2853
[09/26 14:52:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 92.00	
[09/26 14:52:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 14:52:39 visual_prompt]: Epoch 30 / 100: avg data time: 5.40e-02, avg batch time: 0.4970, average train loss: 0.0230
[09/26 14:52:41 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1666, average loss: 1.2640
[09/26 14:52:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 93.50	
[09/26 14:52:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 14:52:47 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e-02, avg batch time: 0.4998, average train loss: 0.0182
[09/26 14:52:49 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.2470
[09/26 14:52:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 94.00	
[09/26 14:52:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 14:52:56 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e-02, avg batch time: 0.4949, average train loss: 0.0127
[09/26 14:52:57 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1665, average loss: 1.2412
[09/26 14:52:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.50	
[09/26 14:52:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 14:53:04 visual_prompt]: Epoch 33 / 100: avg data time: 6.15e-02, avg batch time: 0.5043, average train loss: 0.0099
[09/26 14:53:06 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 1.2227
[09/26 14:53:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 94.00	
[09/26 14:53:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 14:53:13 visual_prompt]: Epoch 34 / 100: avg data time: 5.15e-02, avg batch time: 0.4949, average train loss: 0.0088
[09/26 14:53:14 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.2068
[09/26 14:53:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 14:53:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 14:53:21 visual_prompt]: Epoch 35 / 100: avg data time: 5.63e-02, avg batch time: 0.5007, average train loss: 0.0080
[09/26 14:53:23 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.1966
[09/26 14:53:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 14:53:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 14:53:30 visual_prompt]: Epoch 36 / 100: avg data time: 4.93e-02, avg batch time: 0.4938, average train loss: 0.0076
[09/26 14:53:31 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 1.2114
[09/26 14:53:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.50	
[09/26 14:53:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 14:53:38 visual_prompt]: Epoch 37 / 100: avg data time: 4.51e-02, avg batch time: 0.4907, average train loss: 0.0073
[09/26 14:53:40 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1665, average loss: 1.2256
[09/26 14:53:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 14:53:40 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 14:53:46 visual_prompt]: Epoch 38 / 100: avg data time: 5.08e-02, avg batch time: 0.4928, average train loss: 0.0066
[09/26 14:53:48 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1667, average loss: 1.2257
[09/26 14:53:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 14:53:48 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 14:53:55 visual_prompt]: Epoch 39 / 100: avg data time: 5.83e-02, avg batch time: 0.5020, average train loss: 0.0069
[09/26 14:53:57 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1667, average loss: 1.2119
[09/26 14:53:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 14:53:57 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 14:54:03 visual_prompt]: Epoch 40 / 100: avg data time: 5.92e-02, avg batch time: 0.5015, average train loss: 0.0061
[09/26 14:54:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1666, average loss: 1.2114
[09/26 14:54:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:54:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 14:54:12 visual_prompt]: Epoch 41 / 100: avg data time: 5.87e-02, avg batch time: 0.5012, average train loss: 0.0060
[09/26 14:54:14 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.2284
[09/26 14:54:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 14:54:14 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 14:54:20 visual_prompt]: Epoch 42 / 100: avg data time: 5.00e-02, avg batch time: 0.4935, average train loss: 0.0060
[09/26 14:54:22 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 1.2403
[09/26 14:54:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:54:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 14:54:29 visual_prompt]: Epoch 43 / 100: avg data time: 5.97e-02, avg batch time: 0.5030, average train loss: 0.0056
[09/26 14:54:31 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.2449
[09/26 14:54:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 91.50	
[09/26 14:54:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 14:54:37 visual_prompt]: Epoch 44 / 100: avg data time: 5.04e-02, avg batch time: 0.4945, average train loss: 0.0055
[09/26 14:54:39 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1670, average loss: 1.2494
[09/26 14:54:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 91.50	
[09/26 14:54:39 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 14:54:46 visual_prompt]: Epoch 45 / 100: avg data time: 5.29e-02, avg batch time: 0.4950, average train loss: 0.0054
[09/26 14:54:47 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.2474
[09/26 14:54:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 14:54:47 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 14:54:54 visual_prompt]: Epoch 46 / 100: avg data time: 4.92e-02, avg batch time: 0.4913, average train loss: 0.0051
[09/26 14:54:56 visual_prompt]: Inference (val):avg data time: 4.16e-05, avg batch time: 0.1666, average loss: 1.2512
[09/26 14:54:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 14:54:56 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 14:55:03 visual_prompt]: Epoch 47 / 100: avg data time: 6.86e-02, avg batch time: 0.5105, average train loss: 0.0051
[09/26 14:55:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 1.2522
[09/26 14:55:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 91.50	
[09/26 14:55:04 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 14:55:11 visual_prompt]: Epoch 48 / 100: avg data time: 5.76e-02, avg batch time: 0.5006, average train loss: 0.0049
[09/26 14:55:13 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.2504
[09/26 14:55:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 91.50	
[09/26 14:55:13 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 14:55:20 visual_prompt]: Epoch 49 / 100: avg data time: 6.75e-02, avg batch time: 0.5097, average train loss: 0.0048
[09/26 14:55:22 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1663, average loss: 1.2436
[09/26 14:55:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.00	
[09/26 14:55:22 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 14:55:29 visual_prompt]: Epoch 50 / 100: avg data time: 6.96e-02, avg batch time: 0.5108, average train loss: 0.0047
[09/26 14:55:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2497
[09/26 14:55:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.00	
[09/26 14:55:30 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 14:55:37 visual_prompt]: Epoch 51 / 100: avg data time: 7.10e-02, avg batch time: 0.5124, average train loss: 0.0045
[09/26 14:55:39 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.2510
[09/26 14:55:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 14:55:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 14:55:46 visual_prompt]: Epoch 52 / 100: avg data time: 6.31e-02, avg batch time: 0.5043, average train loss: 0.0045
[09/26 14:55:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.2483
[09/26 14:55:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 14:55:47 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 14:55:55 visual_prompt]: Epoch 53 / 100: avg data time: 7.12e-02, avg batch time: 0.5139, average train loss: 0.0042
[09/26 14:55:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 1.2403
[09/26 14:55:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.00	
[09/26 14:55:56 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 14:56:03 visual_prompt]: Epoch 54 / 100: avg data time: 6.01e-02, avg batch time: 0.5021, average train loss: 0.0043
[09/26 14:56:05 visual_prompt]: Inference (val):avg data time: 4.59e-05, avg batch time: 0.1662, average loss: 1.2418
[09/26 14:56:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 14:56:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 14:56:12 visual_prompt]: Epoch 55 / 100: avg data time: 6.36e-02, avg batch time: 0.5062, average train loss: 0.0043
[09/26 14:56:13 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.2483
[09/26 14:56:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 14:56:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 14:56:20 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e-02, avg batch time: 0.4914, average train loss: 0.0045
[09/26 14:56:22 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1664, average loss: 1.2465
[09/26 14:56:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 14:56:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 14:56:29 visual_prompt]: Epoch 57 / 100: avg data time: 5.21e-02, avg batch time: 0.4956, average train loss: 0.0041
[09/26 14:56:30 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.2479
[09/26 14:56:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:56:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 14:56:37 visual_prompt]: Epoch 58 / 100: avg data time: 4.82e-02, avg batch time: 0.4909, average train loss: 0.0042
[09/26 14:56:39 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.2488
[09/26 14:56:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:56:39 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 14:56:45 visual_prompt]: Epoch 59 / 100: avg data time: 5.54e-02, avg batch time: 0.4984, average train loss: 0.0042
[09/26 14:56:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1663, average loss: 1.2538
[09/26 14:56:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.00	
[09/26 14:56:47 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 14:56:54 visual_prompt]: Epoch 60 / 100: avg data time: 5.07e-02, avg batch time: 0.4969, average train loss: 0.0044
[09/26 14:56:56 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1663, average loss: 1.2690
[09/26 14:56:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 14:56:56 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 14:57:03 visual_prompt]: Epoch 61 / 100: avg data time: 6.41e-02, avg batch time: 0.5064, average train loss: 0.0042
[09/26 14:57:04 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.2694
[09/26 14:57:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 91.50	
[09/26 14:57:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 14:57:11 visual_prompt]: Epoch 62 / 100: avg data time: 4.96e-02, avg batch time: 0.4914, average train loss: 0.0040
[09/26 14:57:12 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1663, average loss: 1.2675
[09/26 14:57:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:57:12 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 14:57:19 visual_prompt]: Epoch 63 / 100: avg data time: 5.14e-02, avg batch time: 0.4928, average train loss: 0.0040
[09/26 14:57:21 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.2679
[09/26 14:57:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:57:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 14:57:28 visual_prompt]: Epoch 64 / 100: avg data time: 4.73e-02, avg batch time: 0.4895, average train loss: 0.0038
[09/26 14:57:29 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.2648
[09/26 14:57:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:57:29 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 14:57:36 visual_prompt]: Epoch 65 / 100: avg data time: 5.46e-02, avg batch time: 0.5007, average train loss: 0.0041
[09/26 14:57:38 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 1.2635
[09/26 14:57:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:57:38 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 14:57:45 visual_prompt]: Epoch 66 / 100: avg data time: 6.01e-02, avg batch time: 0.5033, average train loss: 0.0040
[09/26 14:57:46 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1666, average loss: 1.2636
[09/26 14:57:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:57:46 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 14:57:53 visual_prompt]: Epoch 67 / 100: avg data time: 4.80e-02, avg batch time: 0.4904, average train loss: 0.0038
[09/26 14:57:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1662, average loss: 1.2641
[09/26 14:57:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:57:55 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 14:58:02 visual_prompt]: Epoch 68 / 100: avg data time: 5.02e-02, avg batch time: 0.4940, average train loss: 0.0039
[09/26 14:58:03 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1665, average loss: 1.2678
[09/26 14:58:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:58:03 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 14:58:10 visual_prompt]: Epoch 69 / 100: avg data time: 4.97e-02, avg batch time: 0.4924, average train loss: 0.0037
[09/26 14:58:12 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 1.2687
[09/26 14:58:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:58:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 14:58:18 visual_prompt]: Epoch 70 / 100: avg data time: 6.19e-02, avg batch time: 0.5044, average train loss: 0.0038
[09/26 14:58:20 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1663, average loss: 1.2709
[09/26 14:58:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:58:20 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 14:58:27 visual_prompt]: Epoch 71 / 100: avg data time: 5.35e-02, avg batch time: 0.4948, average train loss: 0.0035
[09/26 14:58:29 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.2727
[09/26 14:58:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 14:58:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 14:58:35 visual_prompt]: Epoch 72 / 100: avg data time: 5.60e-02, avg batch time: 0.4985, average train loss: 0.0038
[09/26 14:58:37 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 1.2702
[09/26 14:58:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:58:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 14:58:44 visual_prompt]: Epoch 73 / 100: avg data time: 6.95e-02, avg batch time: 0.5108, average train loss: 0.0039
[09/26 14:58:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1663, average loss: 1.2665
[09/26 14:58:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:58:46 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 14:58:52 visual_prompt]: Epoch 74 / 100: avg data time: 5.53e-02, avg batch time: 0.4984, average train loss: 0.0039
[09/26 14:58:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 1.2646
[09/26 14:58:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:58:54 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 14:59:01 visual_prompt]: Epoch 75 / 100: avg data time: 5.73e-02, avg batch time: 0.4993, average train loss: 0.0036
[09/26 14:59:03 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1663, average loss: 1.2643
[09/26 14:59:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:59:03 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 14:59:09 visual_prompt]: Epoch 76 / 100: avg data time: 4.39e-02, avg batch time: 0.4875, average train loss: 0.0040
[09/26 14:59:11 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1665, average loss: 1.2622
[09/26 14:59:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:59:11 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 14:59:18 visual_prompt]: Epoch 77 / 100: avg data time: 5.73e-02, avg batch time: 0.5002, average train loss: 0.0036
[09/26 14:59:20 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1664, average loss: 1.2625
[09/26 14:59:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:59:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 14:59:26 visual_prompt]: Epoch 78 / 100: avg data time: 6.08e-02, avg batch time: 0.5024, average train loss: 0.0037
[09/26 14:59:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.2649
[09/26 14:59:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:59:28 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 14:59:35 visual_prompt]: Epoch 79 / 100: avg data time: 6.61e-02, avg batch time: 0.5072, average train loss: 0.0035
[09/26 14:59:37 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1663, average loss: 1.2664
[09/26 14:59:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:59:37 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 14:59:44 visual_prompt]: Epoch 80 / 100: avg data time: 5.76e-02, avg batch time: 0.5012, average train loss: 0.0034
[09/26 14:59:45 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 1.2649
[09/26 14:59:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 14:59:45 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 14:59:52 visual_prompt]: Epoch 81 / 100: avg data time: 5.49e-02, avg batch time: 0.4981, average train loss: 0.0037
[09/26 14:59:54 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1663, average loss: 1.2642
[09/26 14:59:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 14:59:54 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:00:01 visual_prompt]: Epoch 82 / 100: avg data time: 6.00e-02, avg batch time: 0.5034, average train loss: 0.0035
[09/26 15:00:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 1.2636
[09/26 15:00:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:02 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:00:09 visual_prompt]: Epoch 83 / 100: avg data time: 5.24e-02, avg batch time: 0.4943, average train loss: 0.0036
[09/26 15:00:11 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1665, average loss: 1.2629
[09/26 15:00:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:11 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:00:17 visual_prompt]: Epoch 84 / 100: avg data time: 4.96e-02, avg batch time: 0.4938, average train loss: 0.0037
[09/26 15:00:19 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.2619
[09/26 15:00:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:19 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:00:26 visual_prompt]: Epoch 85 / 100: avg data time: 4.88e-02, avg batch time: 0.4926, average train loss: 0.0038
[09/26 15:00:27 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1663, average loss: 1.2616
[09/26 15:00:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:00:34 visual_prompt]: Epoch 86 / 100: avg data time: 5.07e-02, avg batch time: 0.4949, average train loss: 0.0037
[09/26 15:00:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.2617
[09/26 15:00:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:36 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:00:43 visual_prompt]: Epoch 87 / 100: avg data time: 4.84e-02, avg batch time: 0.4919, average train loss: 0.0036
[09/26 15:00:44 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1663, average loss: 1.2612
[09/26 15:00:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:44 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:00:51 visual_prompt]: Epoch 88 / 100: avg data time: 5.36e-02, avg batch time: 0.4984, average train loss: 0.0037
[09/26 15:00:53 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 1.2612
[09/26 15:00:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:00:53 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:01:00 visual_prompt]: Epoch 89 / 100: avg data time: 5.25e-02, avg batch time: 0.4960, average train loss: 0.0038
[09/26 15:01:01 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.2610
[09/26 15:01:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:01 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:01:08 visual_prompt]: Epoch 90 / 100: avg data time: 5.05e-02, avg batch time: 0.4932, average train loss: 0.0035
[09/26 15:01:10 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.2606
[09/26 15:01:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:10 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:01:17 visual_prompt]: Epoch 91 / 100: avg data time: 6.05e-02, avg batch time: 0.5035, average train loss: 0.0035
[09/26 15:01:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 1.2605
[09/26 15:01:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:18 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:01:25 visual_prompt]: Epoch 92 / 100: avg data time: 5.31e-02, avg batch time: 0.4960, average train loss: 0.0035
[09/26 15:01:27 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1663, average loss: 1.2602
[09/26 15:01:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:27 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:01:34 visual_prompt]: Epoch 93 / 100: avg data time: 5.93e-02, avg batch time: 0.5008, average train loss: 0.0033
[09/26 15:01:35 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1664, average loss: 1.2602
[09/26 15:01:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:35 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:01:42 visual_prompt]: Epoch 94 / 100: avg data time: 5.82e-02, avg batch time: 0.5007, average train loss: 0.0035
[09/26 15:01:44 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 1.2602
[09/26 15:01:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:44 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:01:50 visual_prompt]: Epoch 95 / 100: avg data time: 4.88e-02, avg batch time: 0.4923, average train loss: 0.0036
[09/26 15:01:52 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1664, average loss: 1.2604
[09/26 15:01:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:01:52 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:01:59 visual_prompt]: Epoch 96 / 100: avg data time: 4.76e-02, avg batch time: 0.4912, average train loss: 0.0035
[09/26 15:02:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 1.2604
[09/26 15:02:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:02:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:02:07 visual_prompt]: Epoch 97 / 100: avg data time: 6.53e-02, avg batch time: 0.5069, average train loss: 0.0036
[09/26 15:02:09 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.2605
[09/26 15:02:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:02:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:02:16 visual_prompt]: Epoch 98 / 100: avg data time: 4.88e-02, avg batch time: 0.4934, average train loss: 0.0035
[09/26 15:02:18 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.2605
[09/26 15:02:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:02:18 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:02:24 visual_prompt]: Epoch 99 / 100: avg data time: 5.83e-02, avg batch time: 0.5008, average train loss: 0.0037
[09/26 15:02:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.2605
[09/26 15:02:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:02:26 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:02:33 visual_prompt]: Epoch 100 / 100: avg data time: 5.79e-02, avg batch time: 0.5007, average train loss: 0.0037
[09/26 15:02:34 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1666, average loss: 1.2605
[09/26 15:02:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:02:34 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:02:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:02:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:02:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:02:34 visual_prompt]: Training with config:
[09/26 15:02:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.1_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:02:34 visual_prompt]: Loading training data...
[09/26 15:02:34 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:02:36 visual_prompt]: Number of images: 800
[09/26 15:02:36 visual_prompt]: Number of classes: 45 / 45
[09/26 15:02:36 visual_prompt]: Loading validation data...
[09/26 15:02:36 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:02:36 visual_prompt]: Number of images: 200
[09/26 15:02:36 visual_prompt]: Number of classes: 45 / 45
[09/26 15:02:36 visual_prompt]: Constructing models...
[09/26 15:02:38 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 15:02:38 visual_prompt]: tuned percent:0.574
[09/26 15:02:38 visual_prompt]: Device used for model: 0
[09/26 15:02:38 visual_prompt]: Setting up Evaluator...
[09/26 15:02:38 visual_prompt]: Setting up Trainer...
[09/26 15:02:38 visual_prompt]: 	Setting up the optimizer...
[09/26 15:02:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:02:45 visual_prompt]: Epoch 1 / 100: avg data time: 6.58e-02, avg batch time: 0.5069, average train loss: 3.8945
[09/26 15:02:47 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 3.9529
[09/26 15:02:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 15:02:47 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 15:02:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:02:54 visual_prompt]: Epoch 2 / 100: avg data time: 5.29e-02, avg batch time: 0.4943, average train loss: 3.8353
[09/26 15:02:55 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1663, average loss: 3.8255
[09/26 15:02:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 3.00	top5: 10.50	
[09/26 15:02:55 visual_prompt]: Best epoch 2: best metric: 0.030
[09/26 15:02:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:03:02 visual_prompt]: Epoch 3 / 100: avg data time: 5.25e-02, avg batch time: 0.4936, average train loss: 3.7608
[09/26 15:03:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1663, average loss: 3.7104
[09/26 15:03:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.00	top5: 26.50	
[09/26 15:03:04 visual_prompt]: Best epoch 3: best metric: 0.060
[09/26 15:03:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[09/26 15:03:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.37e-02, avg batch time: 0.4962, average train loss: 3.5301
[09/26 15:03:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 3.2662
[09/26 15:03:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.00	top5: 41.50	
[09/26 15:03:12 visual_prompt]: Best epoch 4: best metric: 0.150
[09/26 15:03:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:03:19 visual_prompt]: Epoch 5 / 100: avg data time: 6.46e-02, avg batch time: 0.5062, average train loss: 3.0477
[09/26 15:03:21 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1663, average loss: 2.7561
[09/26 15:03:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.00	top5: 54.50	
[09/26 15:03:21 visual_prompt]: Best epoch 5: best metric: 0.220
[09/26 15:03:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[09/26 15:03:28 visual_prompt]: Epoch 6 / 100: avg data time: 5.25e-02, avg batch time: 0.4954, average train loss: 2.5734
[09/26 15:03:29 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1663, average loss: 2.5587
[09/26 15:03:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 27.50	top5: 61.00	
[09/26 15:03:29 visual_prompt]: Best epoch 6: best metric: 0.275
[09/26 15:03:29 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[09/26 15:03:36 visual_prompt]: Epoch 7 / 100: avg data time: 5.95e-02, avg batch time: 0.5024, average train loss: 2.1525
[09/26 15:03:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 2.2649
[09/26 15:03:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 34.00	top5: 71.50	
[09/26 15:03:38 visual_prompt]: Best epoch 7: best metric: 0.340
[09/26 15:03:38 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[09/26 15:03:44 visual_prompt]: Epoch 8 / 100: avg data time: 4.88e-02, avg batch time: 0.4924, average train loss: 1.7001
[09/26 15:03:46 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1662, average loss: 1.8920
[09/26 15:03:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.50	top5: 77.00	
[09/26 15:03:46 visual_prompt]: Best epoch 8: best metric: 0.475
[09/26 15:03:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[09/26 15:03:53 visual_prompt]: Epoch 9 / 100: avg data time: 4.58e-02, avg batch time: 0.4892, average train loss: 1.3338
[09/26 15:03:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.6848
[09/26 15:03:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.50	top5: 86.00	
[09/26 15:03:54 visual_prompt]: Best epoch 9: best metric: 0.505
[09/26 15:03:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[09/26 15:04:01 visual_prompt]: Epoch 10 / 100: avg data time: 5.23e-02, avg batch time: 0.4949, average train loss: 1.0915
[09/26 15:04:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1663, average loss: 1.5080
[09/26 15:04:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 88.00	
[09/26 15:04:03 visual_prompt]: Best epoch 10: best metric: 0.570
[09/26 15:04:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[09/26 15:04:09 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 0.8141
[09/26 15:04:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1664, average loss: 1.3684
[09/26 15:04:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.50	top5: 91.00	
[09/26 15:04:11 visual_prompt]: Best epoch 11: best metric: 0.575
[09/26 15:04:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[09/26 15:04:18 visual_prompt]: Epoch 12 / 100: avg data time: 5.36e-02, avg batch time: 0.4950, average train loss: 0.6708
[09/26 15:04:19 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.3928
[09/26 15:04:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 89.50	
[09/26 15:04:19 visual_prompt]: Best epoch 12: best metric: 0.615
[09/26 15:04:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[09/26 15:04:26 visual_prompt]: Epoch 13 / 100: avg data time: 5.48e-02, avg batch time: 0.4984, average train loss: 0.4609
[09/26 15:04:28 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1665, average loss: 1.4227
[09/26 15:04:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 90.00	
[09/26 15:04:28 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[09/26 15:04:35 visual_prompt]: Epoch 14 / 100: avg data time: 5.17e-02, avg batch time: 0.4962, average train loss: 0.3236
[09/26 15:04:36 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 1.2676
[09/26 15:04:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 92.50	
[09/26 15:04:36 visual_prompt]: Best epoch 14: best metric: 0.660
[09/26 15:04:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[09/26 15:04:43 visual_prompt]: Epoch 15 / 100: avg data time: 5.18e-02, avg batch time: 0.4971, average train loss: 0.2120
[09/26 15:04:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1667, average loss: 1.2172
[09/26 15:04:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 93.50	
[09/26 15:04:45 visual_prompt]: Best epoch 15: best metric: 0.680
[09/26 15:04:45 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[09/26 15:04:52 visual_prompt]: Epoch 16 / 100: avg data time: 5.07e-02, avg batch time: 0.4953, average train loss: 0.1299
[09/26 15:04:53 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 1.2300
[09/26 15:04:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.00	
[09/26 15:04:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[09/26 15:05:00 visual_prompt]: Epoch 17 / 100: avg data time: 5.81e-02, avg batch time: 0.5003, average train loss: 0.0918
[09/26 15:05:02 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 1.1711
[09/26 15:05:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 91.50	
[09/26 15:05:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[09/26 15:05:08 visual_prompt]: Epoch 18 / 100: avg data time: 4.87e-02, avg batch time: 0.4906, average train loss: 0.0631
[09/26 15:05:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1665, average loss: 1.0775
[09/26 15:05:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:05:10 visual_prompt]: Best epoch 18: best metric: 0.715
[09/26 15:05:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[09/26 15:05:17 visual_prompt]: Epoch 19 / 100: avg data time: 4.88e-02, avg batch time: 0.4929, average train loss: 0.0484
[09/26 15:05:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1666, average loss: 1.2092
[09/26 15:05:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:05:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[09/26 15:05:25 visual_prompt]: Epoch 20 / 100: avg data time: 5.65e-02, avg batch time: 0.4988, average train loss: 0.0382
[09/26 15:05:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.2078
[09/26 15:05:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 91.50	
[09/26 15:05:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[09/26 15:05:34 visual_prompt]: Epoch 21 / 100: avg data time: 5.11e-02, avg batch time: 0.4942, average train loss: 0.0339
[09/26 15:05:35 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1668, average loss: 1.2106
[09/26 15:05:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.50	
[09/26 15:05:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[09/26 15:05:42 visual_prompt]: Epoch 22 / 100: avg data time: 6.16e-02, avg batch time: 0.5034, average train loss: 0.0265
[09/26 15:05:44 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1665, average loss: 1.2586
[09/26 15:05:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.50	
[09/26 15:05:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[09/26 15:05:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.93e-02, avg batch time: 0.5007, average train loss: 0.0173
[09/26 15:05:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1665, average loss: 1.2131
[09/26 15:05:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.00	
[09/26 15:05:52 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[09/26 15:05:59 visual_prompt]: Epoch 24 / 100: avg data time: 5.02e-02, avg batch time: 0.4923, average train loss: 0.0152
[09/26 15:06:00 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1664, average loss: 1.2196
[09/26 15:06:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 15:06:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[09/26 15:06:07 visual_prompt]: Epoch 25 / 100: avg data time: 5.00e-02, avg batch time: 0.4933, average train loss: 0.0147
[09/26 15:06:09 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1665, average loss: 1.2187
[09/26 15:06:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:06:09 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[09/26 15:06:16 visual_prompt]: Epoch 26 / 100: avg data time: 5.31e-02, avg batch time: 0.4957, average train loss: 0.0130
[09/26 15:06:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.2322
[09/26 15:06:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 92.50	
[09/26 15:06:17 visual_prompt]: Best epoch 26: best metric: 0.720
[09/26 15:06:17 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[09/26 15:06:24 visual_prompt]: Epoch 27 / 100: avg data time: 5.26e-02, avg batch time: 0.4960, average train loss: 0.0118
[09/26 15:06:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1664, average loss: 1.2597
[09/26 15:06:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.50	
[09/26 15:06:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[09/26 15:06:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.93e-02, avg batch time: 0.5012, average train loss: 0.0113
[09/26 15:06:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 1.2374
[09/26 15:06:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:06:34 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[09/26 15:06:41 visual_prompt]: Epoch 29 / 100: avg data time: 5.39e-02, avg batch time: 0.4965, average train loss: 0.0100
[09/26 15:06:43 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1665, average loss: 1.2251
[09/26 15:06:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 15:06:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[09/26 15:06:49 visual_prompt]: Epoch 30 / 100: avg data time: 4.79e-02, avg batch time: 0.4915, average train loss: 0.0092
[09/26 15:06:51 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1665, average loss: 1.2441
[09/26 15:06:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.50	
[09/26 15:06:51 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[09/26 15:06:58 visual_prompt]: Epoch 31 / 100: avg data time: 4.78e-02, avg batch time: 0.4898, average train loss: 0.0085
[09/26 15:06:59 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1662, average loss: 1.2444
[09/26 15:06:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 91.50	
[09/26 15:06:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[09/26 15:07:06 visual_prompt]: Epoch 32 / 100: avg data time: 5.25e-02, avg batch time: 0.4966, average train loss: 0.0074
[09/26 15:07:08 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.2118
[09/26 15:07:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:07:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[09/26 15:07:15 visual_prompt]: Epoch 33 / 100: avg data time: 5.82e-02, avg batch time: 0.5020, average train loss: 0.0070
[09/26 15:07:16 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1664, average loss: 1.1949
[09/26 15:07:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:07:16 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[09/26 15:07:23 visual_prompt]: Epoch 34 / 100: avg data time: 5.15e-02, avg batch time: 0.4936, average train loss: 0.0066
[09/26 15:07:25 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.2064
[09/26 15:07:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:07:25 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[09/26 15:07:31 visual_prompt]: Epoch 35 / 100: avg data time: 4.79e-02, avg batch time: 0.4911, average train loss: 0.0062
[09/26 15:07:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1664, average loss: 1.2066
[09/26 15:07:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:07:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[09/26 15:07:40 visual_prompt]: Epoch 36 / 100: avg data time: 5.30e-02, avg batch time: 0.4951, average train loss: 0.0065
[09/26 15:07:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.2084
[09/26 15:07:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:07:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[09/26 15:07:48 visual_prompt]: Epoch 37 / 100: avg data time: 5.88e-02, avg batch time: 0.5005, average train loss: 0.0060
[09/26 15:07:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.2040
[09/26 15:07:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:07:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[09/26 15:07:57 visual_prompt]: Epoch 38 / 100: avg data time: 6.30e-02, avg batch time: 0.5045, average train loss: 0.0059
[09/26 15:07:58 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1663, average loss: 1.2061
[09/26 15:07:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:07:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[09/26 15:08:05 visual_prompt]: Epoch 39 / 100: avg data time: 4.89e-02, avg batch time: 0.4915, average train loss: 0.0054
[09/26 15:08:07 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.2122
[09/26 15:08:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:08:07 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[09/26 15:08:14 visual_prompt]: Epoch 40 / 100: avg data time: 4.92e-02, avg batch time: 0.4950, average train loss: 0.0054
[09/26 15:08:15 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 1.2229
[09/26 15:08:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:08:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[09/26 15:08:22 visual_prompt]: Epoch 41 / 100: avg data time: 4.99e-02, avg batch time: 0.4935, average train loss: 0.0056
[09/26 15:08:24 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1663, average loss: 1.2420
[09/26 15:08:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:08:24 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[09/26 15:08:30 visual_prompt]: Epoch 42 / 100: avg data time: 4.91e-02, avg batch time: 0.4932, average train loss: 0.0056
[09/26 15:08:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1662, average loss: 1.2421
[09/26 15:08:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:08:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[09/26 15:08:39 visual_prompt]: Epoch 43 / 100: avg data time: 6.16e-02, avg batch time: 0.5036, average train loss: 0.0055
[09/26 15:08:41 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.2240
[09/26 15:08:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:08:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[09/26 15:08:48 visual_prompt]: Epoch 44 / 100: avg data time: 7.03e-02, avg batch time: 0.5125, average train loss: 0.0046
[09/26 15:08:49 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1665, average loss: 1.2299
[09/26 15:08:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.50	
[09/26 15:08:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[09/26 15:08:56 visual_prompt]: Epoch 45 / 100: avg data time: 6.17e-02, avg batch time: 0.5037, average train loss: 0.0048
[09/26 15:08:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.2358
[09/26 15:08:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:08:58 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[09/26 15:09:05 visual_prompt]: Epoch 46 / 100: avg data time: 6.04e-02, avg batch time: 0.5025, average train loss: 0.0050
[09/26 15:09:06 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 1.2454
[09/26 15:09:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:09:06 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[09/26 15:09:13 visual_prompt]: Epoch 47 / 100: avg data time: 5.71e-02, avg batch time: 0.4988, average train loss: 0.0044
[09/26 15:09:15 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.2405
[09/26 15:09:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:09:15 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[09/26 15:09:21 visual_prompt]: Epoch 48 / 100: avg data time: 4.92e-02, avg batch time: 0.4939, average train loss: 0.0043
[09/26 15:09:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 1.2362
[09/26 15:09:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:09:23 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[09/26 15:09:30 visual_prompt]: Epoch 49 / 100: avg data time: 5.55e-02, avg batch time: 0.4987, average train loss: 0.0043
[09/26 15:09:31 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.2443
[09/26 15:09:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.50	
[09/26 15:09:31 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[09/26 15:09:38 visual_prompt]: Epoch 50 / 100: avg data time: 5.22e-02, avg batch time: 0.4940, average train loss: 0.0041
[09/26 15:09:40 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1663, average loss: 1.2457
[09/26 15:09:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:09:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[09/26 15:09:47 visual_prompt]: Epoch 51 / 100: avg data time: 4.82e-02, avg batch time: 0.4917, average train loss: 0.0042
[09/26 15:09:48 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1666, average loss: 1.2388
[09/26 15:09:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:09:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[09/26 15:09:55 visual_prompt]: Epoch 52 / 100: avg data time: 5.83e-02, avg batch time: 0.5018, average train loss: 0.0042
[09/26 15:09:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 1.2294
[09/26 15:09:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:09:57 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[09/26 15:10:03 visual_prompt]: Epoch 53 / 100: avg data time: 5.19e-02, avg batch time: 0.4962, average train loss: 0.0041
[09/26 15:10:05 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1663, average loss: 1.2181
[09/26 15:10:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:10:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[09/26 15:10:12 visual_prompt]: Epoch 54 / 100: avg data time: 6.32e-02, avg batch time: 0.5057, average train loss: 0.0038
[09/26 15:10:14 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 1.2210
[09/26 15:10:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:10:14 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[09/26 15:10:20 visual_prompt]: Epoch 55 / 100: avg data time: 6.03e-02, avg batch time: 0.5017, average train loss: 0.0039
[09/26 15:10:22 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.2286
[09/26 15:10:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:10:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[09/26 15:10:29 visual_prompt]: Epoch 56 / 100: avg data time: 4.75e-02, avg batch time: 0.4907, average train loss: 0.0040
[09/26 15:10:30 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 1.2334
[09/26 15:10:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:10:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[09/26 15:10:37 visual_prompt]: Epoch 57 / 100: avg data time: 5.26e-02, avg batch time: 0.4958, average train loss: 0.0034
[09/26 15:10:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.2339
[09/26 15:10:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:10:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[09/26 15:10:46 visual_prompt]: Epoch 58 / 100: avg data time: 6.16e-02, avg batch time: 0.5035, average train loss: 0.0036
[09/26 15:10:47 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1664, average loss: 1.2377
[09/26 15:10:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:10:47 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[09/26 15:10:54 visual_prompt]: Epoch 59 / 100: avg data time: 6.06e-02, avg batch time: 0.5019, average train loss: 0.0041
[09/26 15:10:56 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 1.2307
[09/26 15:10:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:10:56 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[09/26 15:11:03 visual_prompt]: Epoch 60 / 100: avg data time: 5.01e-02, avg batch time: 0.4924, average train loss: 0.0036
[09/26 15:11:04 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.2311
[09/26 15:11:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 15:11:04 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[09/26 15:11:11 visual_prompt]: Epoch 61 / 100: avg data time: 5.41e-02, avg batch time: 0.4964, average train loss: 0.0037
[09/26 15:11:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 1.2343
[09/26 15:11:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 15:11:12 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[09/26 15:11:19 visual_prompt]: Epoch 62 / 100: avg data time: 5.16e-02, avg batch time: 0.4946, average train loss: 0.0033
[09/26 15:11:21 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1666, average loss: 1.2360
[09/26 15:11:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:11:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[09/26 15:11:28 visual_prompt]: Epoch 63 / 100: avg data time: 5.29e-02, avg batch time: 0.4962, average train loss: 0.0036
[09/26 15:11:29 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1664, average loss: 1.2414
[09/26 15:11:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 15:11:29 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.036218132209150045
[09/26 15:11:36 visual_prompt]: Epoch 64 / 100: avg data time: 5.20e-02, avg batch time: 0.4949, average train loss: 0.0035
[09/26 15:11:38 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.2405
[09/26 15:11:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 15:11:38 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.03454915028125263
[09/26 15:11:44 visual_prompt]: Epoch 65 / 100: avg data time: 5.54e-02, avg batch time: 0.4982, average train loss: 0.0034
[09/26 15:11:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 1.2337
[09/26 15:11:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:11:46 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.03289899283371657
[09/26 15:11:53 visual_prompt]: Epoch 66 / 100: avg data time: 5.82e-02, avg batch time: 0.5002, average train loss: 0.0035
[09/26 15:11:54 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1663, average loss: 1.2379
[09/26 15:11:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:11:54 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0312696703292044
[09/26 15:12:01 visual_prompt]: Epoch 67 / 100: avg data time: 4.95e-02, avg batch time: 0.4908, average train loss: 0.0036
[09/26 15:12:03 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 1.2464
[09/26 15:12:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.50	
[09/26 15:12:03 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.02966316784621
[09/26 15:12:10 visual_prompt]: Epoch 68 / 100: avg data time: 5.74e-02, avg batch time: 0.5002, average train loss: 0.0033
[09/26 15:12:11 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 1.2499
[09/26 15:12:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.50	
[09/26 15:12:11 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.028081442660546126
[09/26 15:12:18 visual_prompt]: Epoch 69 / 100: avg data time: 5.14e-02, avg batch time: 0.4952, average train loss: 0.0035
[09/26 15:12:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.2510
[09/26 15:12:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 15:12:20 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.026526421860705474
[09/26 15:12:27 visual_prompt]: Epoch 70 / 100: avg data time: 6.23e-02, avg batch time: 0.5043, average train loss: 0.0035
[09/26 15:12:28 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.2474
[09/26 15:12:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:12:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.025000000000000012
[09/26 15:12:35 visual_prompt]: Epoch 71 / 100: avg data time: 5.12e-02, avg batch time: 0.4932, average train loss: 0.0035
[09/26 15:12:37 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 1.2437
[09/26 15:12:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:12:37 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.02350403678833976
[09/26 15:12:43 visual_prompt]: Epoch 72 / 100: avg data time: 5.11e-02, avg batch time: 0.4940, average train loss: 0.0031
[09/26 15:12:45 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 1.2439
[09/26 15:12:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:12:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.022040354826462667
[09/26 15:12:52 visual_prompt]: Epoch 73 / 100: avg data time: 4.96e-02, avg batch time: 0.4938, average train loss: 0.0032
[09/26 15:12:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.2452
[09/26 15:12:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:12:53 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.02061073738537635
[09/26 15:13:00 visual_prompt]: Epoch 74 / 100: avg data time: 5.21e-02, avg batch time: 0.4960, average train loss: 0.0030
[09/26 15:13:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.2437
[09/26 15:13:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:13:02 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.019216926233717086
[09/26 15:13:09 visual_prompt]: Epoch 75 / 100: avg data time: 6.27e-02, avg batch time: 0.5059, average train loss: 0.0033
[09/26 15:13:10 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1661, average loss: 1.2429
[09/26 15:13:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:13:10 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.017860619515673033
[09/26 15:13:17 visual_prompt]: Epoch 76 / 100: avg data time: 4.81e-02, avg batch time: 0.4915, average train loss: 0.0032
[09/26 15:13:19 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1664, average loss: 1.2423
[09/26 15:13:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:13:19 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.016543469682057107
[09/26 15:13:25 visual_prompt]: Epoch 77 / 100: avg data time: 5.09e-02, avg batch time: 0.4942, average train loss: 0.0033
[09/26 15:13:27 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.2449
[09/26 15:13:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 15:13:27 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.015267081477050132
[09/26 15:13:34 visual_prompt]: Epoch 78 / 100: avg data time: 7.10e-02, avg batch time: 0.5131, average train loss: 0.0032
[09/26 15:13:36 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1662, average loss: 1.2440
[09/26 15:13:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:13:36 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.014033009983067453
[09/26 15:13:43 visual_prompt]: Epoch 79 / 100: avg data time: 6.79e-02, avg batch time: 0.5097, average train loss: 0.0032
[09/26 15:13:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 1.2407
[09/26 15:13:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:13:44 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.012842758726130284
[09/26 15:13:51 visual_prompt]: Epoch 80 / 100: avg data time: 4.91e-02, avg batch time: 0.4919, average train loss: 0.0030
[09/26 15:13:53 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 1.2407
[09/26 15:13:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:13:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.011697777844051106
[09/26 15:13:59 visual_prompt]: Epoch 81 / 100: avg data time: 5.27e-02, avg batch time: 0.4981, average train loss: 0.0032
[09/26 15:14:01 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1664, average loss: 1.2412
[09/26 15:14:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:01 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.010599462319663905
[09/26 15:14:08 visual_prompt]: Epoch 82 / 100: avg data time: 6.34e-02, avg batch time: 0.5058, average train loss: 0.0030
[09/26 15:14:10 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 1.2415
[09/26 15:14:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.009549150281252633
[09/26 15:14:16 visual_prompt]: Epoch 83 / 100: avg data time: 5.89e-02, avg batch time: 0.5014, average train loss: 0.0032
[09/26 15:14:18 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1664, average loss: 1.2410
[09/26 15:14:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:18 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.008548121372247919
[09/26 15:14:25 visual_prompt]: Epoch 84 / 100: avg data time: 6.04e-02, avg batch time: 0.5027, average train loss: 0.0033
[09/26 15:14:27 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.2411
[09/26 15:14:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.007597595192178702
[09/26 15:14:33 visual_prompt]: Epoch 85 / 100: avg data time: 5.26e-02, avg batch time: 0.4948, average train loss: 0.0031
[09/26 15:14:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1663, average loss: 1.2427
[09/26 15:14:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:35 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.006698729810778065
[09/26 15:14:42 visual_prompt]: Epoch 86 / 100: avg data time: 5.06e-02, avg batch time: 0.4933, average train loss: 0.0028
[09/26 15:14:43 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1663, average loss: 1.2436
[09/26 15:14:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:43 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.005852620357053651
[09/26 15:14:50 visual_prompt]: Epoch 87 / 100: avg data time: 5.73e-02, avg batch time: 0.4992, average train loss: 0.0030
[09/26 15:14:52 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1667, average loss: 1.2443
[09/26 15:14:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:14:52 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00506029768504166
[09/26 15:14:59 visual_prompt]: Epoch 88 / 100: avg data time: 6.44e-02, avg batch time: 0.5068, average train loss: 0.0032
[09/26 15:15:00 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1662, average loss: 1.2443
[09/26 15:15:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.004322727117869951
[09/26 15:15:07 visual_prompt]: Epoch 89 / 100: avg data time: 5.95e-02, avg batch time: 0.5014, average train loss: 0.0034
[09/26 15:15:09 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1662, average loss: 1.2446
[09/26 15:15:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:09 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0036408072716606343
[09/26 15:15:16 visual_prompt]: Epoch 90 / 100: avg data time: 5.75e-02, avg batch time: 0.5002, average train loss: 0.0029
[09/26 15:15:17 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1663, average loss: 1.2443
[09/26 15:15:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:17 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0030153689607045845
[09/26 15:15:24 visual_prompt]: Epoch 91 / 100: avg data time: 6.43e-02, avg batch time: 0.5053, average train loss: 0.0030
[09/26 15:15:26 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 1.2440
[09/26 15:15:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:26 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0024471741852423235
[09/26 15:15:33 visual_prompt]: Epoch 92 / 100: avg data time: 5.51e-02, avg batch time: 0.4986, average train loss: 0.0028
[09/26 15:15:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 1.2435
[09/26 15:15:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:34 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0019369152030840554
[09/26 15:15:41 visual_prompt]: Epoch 93 / 100: avg data time: 6.42e-02, avg batch time: 0.5064, average train loss: 0.0029
[09/26 15:15:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1661, average loss: 1.2433
[09/26 15:15:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:43 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0014852136862001765
[09/26 15:15:50 visual_prompt]: Epoch 94 / 100: avg data time: 5.34e-02, avg batch time: 0.4954, average train loss: 0.0031
[09/26 15:15:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 1.2432
[09/26 15:15:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:15:51 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0010926199633097156
[09/26 15:15:58 visual_prompt]: Epoch 95 / 100: avg data time: 5.00e-02, avg batch time: 0.4923, average train loss: 0.0031
[09/26 15:16:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1662, average loss: 1.2431
[09/26 15:16:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:00 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.0007596123493895991
[09/26 15:16:06 visual_prompt]: Epoch 96 / 100: avg data time: 5.62e-02, avg batch time: 0.4972, average train loss: 0.0029
[09/26 15:16:08 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.2432
[09/26 15:16:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:08 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00048659656292148194
[09/26 15:16:15 visual_prompt]: Epoch 97 / 100: avg data time: 6.36e-02, avg batch time: 0.5052, average train loss: 0.0030
[09/26 15:16:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1662, average loss: 1.2432
[09/26 15:16:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:17 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.0002739052315863355
[09/26 15:16:23 visual_prompt]: Epoch 98 / 100: avg data time: 4.87e-02, avg batch time: 0.4920, average train loss: 0.0030
[09/26 15:16:25 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.2433
[09/26 15:16:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:25 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.00012179748700879012
[09/26 15:16:32 visual_prompt]: Epoch 99 / 100: avg data time: 5.70e-02, avg batch time: 0.4983, average train loss: 0.0032
[09/26 15:16:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1662, average loss: 1.2433
[09/26 15:16:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:33 visual_prompt]: Training 100 / 100 epoch, with learning rate 3.0458649045211895e-05
[09/26 15:16:40 visual_prompt]: Epoch 100 / 100: avg data time: 5.02e-02, avg batch time: 0.4919, average train loss: 0.0033
[09/26 15:16:42 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.2433
[09/26 15:16:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:16:42 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:16:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:16:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:16:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:16:42 visual_prompt]: Training with config:
[09/26 15:16:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.01/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:16:42 visual_prompt]: Loading training data...
[09/26 15:16:42 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:16:43 visual_prompt]: Number of images: 800
[09/26 15:16:43 visual_prompt]: Number of classes: 45 / 45
[09/26 15:16:43 visual_prompt]: Loading validation data...
[09/26 15:16:43 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:16:43 visual_prompt]: Number of images: 200
[09/26 15:16:43 visual_prompt]: Number of classes: 45 / 45
[09/26 15:16:43 visual_prompt]: Constructing models...
[09/26 15:16:46 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 15:16:46 visual_prompt]: tuned percent:0.574
[09/26 15:16:46 visual_prompt]: Device used for model: 0
[09/26 15:16:46 visual_prompt]: Setting up Evaluator...
[09/26 15:16:46 visual_prompt]: Setting up Trainer...
[09/26 15:16:46 visual_prompt]: 	Setting up the optimizer...
[09/26 15:16:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:16:53 visual_prompt]: Epoch 1 / 100: avg data time: 5.84e-02, avg batch time: 0.4984, average train loss: 3.8896
[09/26 15:16:54 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1658, average loss: 3.9529
[09/26 15:16:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 15:16:54 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 15:16:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 15:17:01 visual_prompt]: Epoch 2 / 100: avg data time: 5.68e-02, avg batch time: 0.4990, average train loss: 3.8444
[09/26 15:17:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1662, average loss: 3.8691
[09/26 15:17:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 7.50	
[09/26 15:17:03 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 15:17:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:17:10 visual_prompt]: Epoch 3 / 100: avg data time: 5.19e-02, avg batch time: 0.4944, average train loss: 3.7590
[09/26 15:17:11 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 3.7385
[09/26 15:17:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.00	top5: 21.00	
[09/26 15:17:11 visual_prompt]: Best epoch 3: best metric: 0.040
[09/26 15:17:11 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 15:17:18 visual_prompt]: Epoch 4 / 100: avg data time: 5.20e-02, avg batch time: 0.4947, average train loss: 3.6587
[09/26 15:17:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1661, average loss: 3.5214
[09/26 15:17:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.50	top5: 39.50	
[09/26 15:17:20 visual_prompt]: Best epoch 4: best metric: 0.135
[09/26 15:17:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:17:26 visual_prompt]: Epoch 5 / 100: avg data time: 5.03e-02, avg batch time: 0.4929, average train loss: 3.3572
[09/26 15:17:28 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 3.1562
[09/26 15:17:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.00	top5: 43.50	
[09/26 15:17:28 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 15:17:35 visual_prompt]: Epoch 6 / 100: avg data time: 5.84e-02, avg batch time: 0.4996, average train loss: 2.8688
[09/26 15:17:36 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 2.6768
[09/26 15:17:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.00	top5: 61.00	
[09/26 15:17:36 visual_prompt]: Best epoch 6: best metric: 0.230
[09/26 15:17:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 15:17:43 visual_prompt]: Epoch 7 / 100: avg data time: 6.03e-02, avg batch time: 0.5015, average train loss: 2.4899
[09/26 15:17:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 2.2899
[09/26 15:17:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 35.50	top5: 71.00	
[09/26 15:17:45 visual_prompt]: Best epoch 7: best metric: 0.355
[09/26 15:17:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 15:17:52 visual_prompt]: Epoch 8 / 100: avg data time: 6.30e-02, avg batch time: 0.5060, average train loss: 2.0582
[09/26 15:17:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1662, average loss: 2.1479
[09/26 15:17:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 39.50	top5: 75.50	
[09/26 15:17:53 visual_prompt]: Best epoch 8: best metric: 0.395
[09/26 15:17:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:18:00 visual_prompt]: Epoch 9 / 100: avg data time: 5.70e-02, avg batch time: 0.4996, average train loss: 1.6994
[09/26 15:18:02 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 1.6757
[09/26 15:18:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.50	top5: 82.00	
[09/26 15:18:02 visual_prompt]: Best epoch 9: best metric: 0.535
[09/26 15:18:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 15:18:09 visual_prompt]: Epoch 10 / 100: avg data time: 4.78e-02, avg batch time: 0.4921, average train loss: 1.4287
[09/26 15:18:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.6722
[09/26 15:18:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 51.50	top5: 84.50	
[09/26 15:18:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 15:18:17 visual_prompt]: Epoch 11 / 100: avg data time: 5.25e-02, avg batch time: 0.4963, average train loss: 1.2640
[09/26 15:18:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1662, average loss: 1.4870
[09/26 15:18:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 89.00	
[09/26 15:18:19 visual_prompt]: Best epoch 11: best metric: 0.585
[09/26 15:18:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 15:18:25 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e-02, avg batch time: 0.4933, average train loss: 1.0035
[09/26 15:18:27 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1663, average loss: 1.3848
[09/26 15:18:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 60.50	top5: 89.50	
[09/26 15:18:27 visual_prompt]: Best epoch 12: best metric: 0.605
[09/26 15:18:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 15:18:34 visual_prompt]: Epoch 13 / 100: avg data time: 5.25e-02, avg batch time: 0.4941, average train loss: 0.7817
[09/26 15:18:35 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1663, average loss: 1.3026
[09/26 15:18:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 94.50	
[09/26 15:18:35 visual_prompt]: Best epoch 13: best metric: 0.630
[09/26 15:18:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 15:18:42 visual_prompt]: Epoch 14 / 100: avg data time: 5.34e-02, avg batch time: 0.4957, average train loss: 0.6125
[09/26 15:18:44 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.1849
[09/26 15:18:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 93.00	
[09/26 15:18:44 visual_prompt]: Best epoch 14: best metric: 0.655
[09/26 15:18:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 15:18:51 visual_prompt]: Epoch 15 / 100: avg data time: 6.67e-02, avg batch time: 0.5091, average train loss: 0.5396
[09/26 15:18:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.1470
[09/26 15:18:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.50	
[09/26 15:18:53 visual_prompt]: Best epoch 15: best metric: 0.665
[09/26 15:18:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 15:18:59 visual_prompt]: Epoch 16 / 100: avg data time: 5.83e-02, avg batch time: 0.5004, average train loss: 0.4834
[09/26 15:19:01 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1665, average loss: 1.1279
[09/26 15:19:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 94.50	
[09/26 15:19:01 visual_prompt]: Best epoch 16: best metric: 0.680
[09/26 15:19:01 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 15:19:08 visual_prompt]: Epoch 17 / 100: avg data time: 5.15e-02, avg batch time: 0.4940, average train loss: 0.4069
[09/26 15:19:09 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.0616
[09/26 15:19:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 15:19:09 visual_prompt]: Best epoch 17: best metric: 0.700
[09/26 15:19:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 15:19:16 visual_prompt]: Epoch 18 / 100: avg data time: 5.79e-02, avg batch time: 0.4996, average train loss: 0.3182
[09/26 15:19:18 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 0.9530
[09/26 15:19:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 15:19:18 visual_prompt]: Best epoch 18: best metric: 0.755
[09/26 15:19:18 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 15:19:25 visual_prompt]: Epoch 19 / 100: avg data time: 6.50e-02, avg batch time: 0.5074, average train loss: 0.2609
[09/26 15:19:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1663, average loss: 0.9987
[09/26 15:19:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 96.00	
[09/26 15:19:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 15:19:33 visual_prompt]: Epoch 20 / 100: avg data time: 5.07e-02, avg batch time: 0.4942, average train loss: 0.2537
[09/26 15:19:35 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1665, average loss: 0.9474
[09/26 15:19:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 93.00	
[09/26 15:19:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 15:19:42 visual_prompt]: Epoch 21 / 100: avg data time: 6.49e-02, avg batch time: 0.5080, average train loss: 0.2536
[09/26 15:19:43 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 0.9927
[09/26 15:19:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 15:19:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 15:19:50 visual_prompt]: Epoch 22 / 100: avg data time: 4.69e-02, avg batch time: 0.4908, average train loss: 0.2478
[09/26 15:19:52 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1668, average loss: 1.0532
[09/26 15:19:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:19:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 15:19:59 visual_prompt]: Epoch 23 / 100: avg data time: 5.66e-02, avg batch time: 0.4983, average train loss: 0.2152
[09/26 15:20:00 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 0.9271
[09/26 15:20:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 94.50	
[09/26 15:20:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 15:20:07 visual_prompt]: Epoch 24 / 100: avg data time: 5.95e-02, avg batch time: 0.5022, average train loss: 0.2132
[09/26 15:20:09 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1667, average loss: 1.0687
[09/26 15:20:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 96.00	
[09/26 15:20:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 15:20:15 visual_prompt]: Epoch 25 / 100: avg data time: 4.82e-02, avg batch time: 0.4920, average train loss: 0.2374
[09/26 15:20:17 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1665, average loss: 0.9707
[09/26 15:20:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.00	top5: 93.50	
[09/26 15:20:17 visual_prompt]: Best epoch 25: best metric: 0.760
[09/26 15:20:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 15:20:24 visual_prompt]: Epoch 26 / 100: avg data time: 5.78e-02, avg batch time: 0.5019, average train loss: 0.2597
[09/26 15:20:26 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 1.1267
[09/26 15:20:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:20:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 15:20:32 visual_prompt]: Epoch 27 / 100: avg data time: 5.05e-02, avg batch time: 0.4943, average train loss: 0.2617
[09/26 15:20:34 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 0.9858
[09/26 15:20:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 95.00	
[09/26 15:20:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 15:20:41 visual_prompt]: Epoch 28 / 100: avg data time: 4.71e-02, avg batch time: 0.4917, average train loss: 0.2227
[09/26 15:20:42 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1668, average loss: 1.0334
[09/26 15:20:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.50	
[09/26 15:20:42 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 15:20:49 visual_prompt]: Epoch 29 / 100: avg data time: 6.02e-02, avg batch time: 0.5036, average train loss: 0.2271
[09/26 15:20:51 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.0658
[09/26 15:20:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 95.00	
[09/26 15:20:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 15:20:58 visual_prompt]: Epoch 30 / 100: avg data time: 5.29e-02, avg batch time: 0.4976, average train loss: 0.2305
[09/26 15:20:59 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 0.9400
[09/26 15:20:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.50	
[09/26 15:20:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 15:21:06 visual_prompt]: Epoch 31 / 100: avg data time: 5.47e-02, avg batch time: 0.4988, average train loss: 0.2631
[09/26 15:21:08 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 0.9971
[09/26 15:21:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 95.00	
[09/26 15:21:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 15:21:15 visual_prompt]: Epoch 32 / 100: avg data time: 7.02e-02, avg batch time: 0.5122, average train loss: 0.2332
[09/26 15:21:16 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1664, average loss: 0.9964
[09/26 15:21:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.00	top5: 93.50	
[09/26 15:21:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 15:21:23 visual_prompt]: Epoch 33 / 100: avg data time: 6.26e-02, avg batch time: 0.5049, average train loss: 0.1898
[09/26 15:21:25 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 0.9268
[09/26 15:21:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 98.00	
[09/26 15:21:25 visual_prompt]: Best epoch 33: best metric: 0.800
[09/26 15:21:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 15:21:32 visual_prompt]: Epoch 34 / 100: avg data time: 4.93e-02, avg batch time: 0.4932, average train loss: 0.1772
[09/26 15:21:33 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1663, average loss: 0.9137
[09/26 15:21:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 96.00	
[09/26 15:21:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 15:21:40 visual_prompt]: Epoch 35 / 100: avg data time: 5.03e-02, avg batch time: 0.4933, average train loss: 0.1562
[09/26 15:21:42 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.9076
[09/26 15:21:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.00	top5: 95.50	
[09/26 15:21:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 15:21:48 visual_prompt]: Epoch 36 / 100: avg data time: 4.86e-02, avg batch time: 0.4918, average train loss: 0.1397
[09/26 15:21:50 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 0.9101
[09/26 15:21:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 76.50	top5: 95.50	
[09/26 15:21:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 15:21:57 visual_prompt]: Epoch 37 / 100: avg data time: 6.46e-02, avg batch time: 0.5080, average train loss: 0.1256
[09/26 15:21:59 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1666, average loss: 0.8766
[09/26 15:21:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 15:21:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 15:22:05 visual_prompt]: Epoch 38 / 100: avg data time: 4.36e-02, avg batch time: 0.4883, average train loss: 0.1077
[09/26 15:22:07 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1663, average loss: 0.7811
[09/26 15:22:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 96.00	
[09/26 15:22:07 visual_prompt]: Best epoch 38: best metric: 0.810
[09/26 15:22:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 15:22:14 visual_prompt]: Epoch 39 / 100: avg data time: 4.94e-02, avg batch time: 0.4928, average train loss: 0.0968
[09/26 15:22:15 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.8547
[09/26 15:22:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 94.50	
[09/26 15:22:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 15:22:22 visual_prompt]: Epoch 40 / 100: avg data time: 6.42e-02, avg batch time: 0.5058, average train loss: 0.0981
[09/26 15:22:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.8466
[09/26 15:22:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 95.50	
[09/26 15:22:24 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 15:22:31 visual_prompt]: Epoch 41 / 100: avg data time: 5.30e-02, avg batch time: 0.4949, average train loss: 0.0925
[09/26 15:22:33 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1662, average loss: 0.8296
[09/26 15:22:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 95.50	
[09/26 15:22:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 15:22:39 visual_prompt]: Epoch 42 / 100: avg data time: 5.75e-02, avg batch time: 0.5001, average train loss: 0.0922
[09/26 15:22:41 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1662, average loss: 0.8304
[09/26 15:22:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 95.50	
[09/26 15:22:41 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 15:22:48 visual_prompt]: Epoch 43 / 100: avg data time: 5.89e-02, avg batch time: 0.4999, average train loss: 0.0935
[09/26 15:22:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1664, average loss: 0.8345
[09/26 15:22:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.50	
[09/26 15:22:50 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 15:22:57 visual_prompt]: Epoch 44 / 100: avg data time: 5.13e-02, avg batch time: 0.4959, average train loss: 0.0953
[09/26 15:22:58 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1665, average loss: 0.8040
[09/26 15:22:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 15:22:58 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 15:23:05 visual_prompt]: Epoch 45 / 100: avg data time: 6.43e-02, avg batch time: 0.5056, average train loss: 0.0960
[09/26 15:23:07 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1665, average loss: 0.7883
[09/26 15:23:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 95.50	
[09/26 15:23:07 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 15:23:14 visual_prompt]: Epoch 46 / 100: avg data time: 5.60e-02, avg batch time: 0.4991, average train loss: 0.0974
[09/26 15:23:15 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 0.8676
[09/26 15:23:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 95.50	
[09/26 15:23:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 15:23:22 visual_prompt]: Epoch 47 / 100: avg data time: 5.54e-02, avg batch time: 0.4977, average train loss: 0.0972
[09/26 15:23:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 0.8275
[09/26 15:23:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 96.00	
[09/26 15:23:24 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 15:23:30 visual_prompt]: Epoch 48 / 100: avg data time: 5.17e-02, avg batch time: 0.4955, average train loss: 0.0978
[09/26 15:23:32 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 0.8323
[09/26 15:23:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 15:23:32 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 15:23:39 visual_prompt]: Epoch 49 / 100: avg data time: 5.83e-02, avg batch time: 0.5007, average train loss: 0.0976
[09/26 15:23:41 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.8184
[09/26 15:23:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 96.50	
[09/26 15:23:41 visual_prompt]: Best epoch 49: best metric: 0.815
[09/26 15:23:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 15:23:48 visual_prompt]: Epoch 50 / 100: avg data time: 5.02e-02, avg batch time: 0.4951, average train loss: 0.0977
[09/26 15:23:49 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 0.8006
[09/26 15:23:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.50	top5: 96.50	
[09/26 15:23:49 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 15:23:56 visual_prompt]: Epoch 51 / 100: avg data time: 6.23e-02, avg batch time: 0.5048, average train loss: 0.0986
[09/26 15:23:58 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1663, average loss: 0.8159
[09/26 15:23:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 97.00	
[09/26 15:23:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 15:24:05 visual_prompt]: Epoch 52 / 100: avg data time: 5.37e-02, avg batch time: 0.4958, average train loss: 0.1000
[09/26 15:24:06 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 0.8249
[09/26 15:24:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 95.50	
[09/26 15:24:06 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 15:24:13 visual_prompt]: Epoch 53 / 100: avg data time: 4.94e-02, avg batch time: 0.4922, average train loss: 0.1012
[09/26 15:24:15 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 0.8560
[09/26 15:24:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 15:24:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 15:24:21 visual_prompt]: Epoch 54 / 100: avg data time: 4.96e-02, avg batch time: 0.4929, average train loss: 0.2085
[09/26 15:24:23 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1666, average loss: 3.1405
[09/26 15:24:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 22.50	top5: 50.00	
[09/26 15:24:23 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 15:24:30 visual_prompt]: Epoch 55 / 100: avg data time: 6.05e-02, avg batch time: 0.5038, average train loss: 1.9583
[09/26 15:24:32 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1666, average loss: 1.8956
[09/26 15:24:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 54.50	top5: 89.00	
[09/26 15:24:32 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 15:24:38 visual_prompt]: Epoch 56 / 100: avg data time: 5.25e-02, avg batch time: 0.4951, average train loss: 1.3379
[09/26 15:24:40 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.5220
[09/26 15:24:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 92.00	
[09/26 15:24:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 15:24:47 visual_prompt]: Epoch 57 / 100: avg data time: 5.01e-02, avg batch time: 0.4928, average train loss: 0.8444
[09/26 15:24:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1668, average loss: 1.0970
[09/26 15:24:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 96.50	
[09/26 15:24:48 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 15:24:55 visual_prompt]: Epoch 58 / 100: avg data time: 5.99e-02, avg batch time: 0.5032, average train loss: 0.5654
[09/26 15:24:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1665, average loss: 0.9686
[09/26 15:24:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 74.50	top5: 96.00	
[09/26 15:24:57 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 15:25:04 visual_prompt]: Epoch 59 / 100: avg data time: 5.23e-02, avg batch time: 0.4956, average train loss: 0.3576
[09/26 15:25:05 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.9692
[09/26 15:25:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 97.50	
[09/26 15:25:05 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 15:25:12 visual_prompt]: Epoch 60 / 100: avg data time: 5.19e-02, avg batch time: 0.4957, average train loss: 0.2565
[09/26 15:25:14 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 0.8620
[09/26 15:25:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.00	top5: 95.50	
[09/26 15:25:14 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 15:25:21 visual_prompt]: Epoch 61 / 100: avg data time: 5.29e-02, avg batch time: 0.4960, average train loss: 0.1934
[09/26 15:25:22 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.9280
[09/26 15:25:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 95.50	
[09/26 15:25:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 15:25:29 visual_prompt]: Epoch 62 / 100: avg data time: 4.67e-02, avg batch time: 0.4907, average train loss: 0.1576
[09/26 15:25:31 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1668, average loss: 0.8523
[09/26 15:25:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.00	
[09/26 15:25:31 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 15:25:37 visual_prompt]: Epoch 63 / 100: avg data time: 4.57e-02, avg batch time: 0.4906, average train loss: 0.1336
[09/26 15:25:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 0.8674
[09/26 15:25:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 75.50	top5: 96.50	
[09/26 15:25:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 15:25:46 visual_prompt]: Epoch 64 / 100: avg data time: 5.03e-02, avg batch time: 0.4939, average train loss: 0.1192
[09/26 15:25:48 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 0.8385
[09/26 15:25:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.00	
[09/26 15:25:48 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 15:25:54 visual_prompt]: Epoch 65 / 100: avg data time: 5.85e-02, avg batch time: 0.5008, average train loss: 0.1097
[09/26 15:25:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.8122
[09/26 15:25:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 96.00	
[09/26 15:25:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 15:26:03 visual_prompt]: Epoch 66 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 0.1032
[09/26 15:26:04 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 0.8218
[09/26 15:26:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 15:26:04 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 15:26:11 visual_prompt]: Epoch 67 / 100: avg data time: 5.26e-02, avg batch time: 0.4975, average train loss: 0.1024
[09/26 15:26:13 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 0.8155
[09/26 15:26:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 96.50	
[09/26 15:26:13 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 15:26:20 visual_prompt]: Epoch 68 / 100: avg data time: 5.30e-02, avg batch time: 0.4965, average train loss: 0.0996
[09/26 15:26:21 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1665, average loss: 0.8189
[09/26 15:26:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 15:26:21 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 15:26:28 visual_prompt]: Epoch 69 / 100: avg data time: 5.15e-02, avg batch time: 0.4943, average train loss: 0.0979
[09/26 15:26:30 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 0.8216
[09/26 15:26:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 15:26:30 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 15:26:37 visual_prompt]: Epoch 70 / 100: avg data time: 6.25e-02, avg batch time: 0.5042, average train loss: 0.0977
[09/26 15:26:38 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 0.8130
[09/26 15:26:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 77.50	top5: 97.50	
[09/26 15:26:38 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 15:26:45 visual_prompt]: Epoch 71 / 100: avg data time: 5.09e-02, avg batch time: 0.4932, average train loss: 0.0967
[09/26 15:26:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1665, average loss: 0.8114
[09/26 15:26:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 15:26:47 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 15:26:53 visual_prompt]: Epoch 72 / 100: avg data time: 5.72e-02, avg batch time: 0.5015, average train loss: 0.0954
[09/26 15:26:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1666, average loss: 0.8139
[09/26 15:26:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 15:26:55 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 15:27:02 visual_prompt]: Epoch 73 / 100: avg data time: 4.91e-02, avg batch time: 0.4930, average train loss: 0.0952
[09/26 15:27:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 0.8078
[09/26 15:27:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 15:27:03 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 15:27:10 visual_prompt]: Epoch 74 / 100: avg data time: 5.44e-02, avg batch time: 0.4972, average train loss: 0.0951
[09/26 15:27:12 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1666, average loss: 0.8048
[09/26 15:27:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 15:27:12 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 15:27:19 visual_prompt]: Epoch 75 / 100: avg data time: 5.11e-02, avg batch time: 0.4940, average train loss: 0.0943
[09/26 15:27:20 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1668, average loss: 0.8115
[09/26 15:27:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 15:27:20 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 15:27:27 visual_prompt]: Epoch 76 / 100: avg data time: 6.17e-02, avg batch time: 0.5033, average train loss: 0.0941
[09/26 15:27:29 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1665, average loss: 0.8048
[09/26 15:27:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.00	top5: 97.50	
[09/26 15:27:29 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 15:27:36 visual_prompt]: Epoch 77 / 100: avg data time: 5.13e-02, avg batch time: 0.4939, average train loss: 0.0943
[09/26 15:27:37 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 0.8116
[09/26 15:27:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 15:27:37 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 15:27:44 visual_prompt]: Epoch 78 / 100: avg data time: 4.90e-02, avg batch time: 0.4929, average train loss: 0.0942
[09/26 15:27:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 0.8260
[09/26 15:27:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 15:27:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 15:27:52 visual_prompt]: Epoch 79 / 100: avg data time: 4.47e-02, avg batch time: 0.4890, average train loss: 0.0940
[09/26 15:27:54 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 0.8132
[09/26 15:27:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 15:27:54 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 15:28:01 visual_prompt]: Epoch 80 / 100: avg data time: 4.89e-02, avg batch time: 0.4907, average train loss: 0.0937
[09/26 15:28:02 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 0.8074
[09/26 15:28:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.00	top5: 97.50	
[09/26 15:28:02 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 15:28:09 visual_prompt]: Epoch 81 / 100: avg data time: 5.92e-02, avg batch time: 0.5022, average train loss: 0.0938
[09/26 15:28:11 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1665, average loss: 0.8086
[09/26 15:28:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 15:28:11 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 15:28:18 visual_prompt]: Epoch 82 / 100: avg data time: 5.84e-02, avg batch time: 0.5005, average train loss: 0.0936
[09/26 15:28:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 0.8062
[09/26 15:28:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 97.50	
[09/26 15:28:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 15:28:26 visual_prompt]: Epoch 83 / 100: avg data time: 5.94e-02, avg batch time: 0.5020, average train loss: 0.0933
[09/26 15:28:28 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 0.8098
[09/26 15:28:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 97.50	
[09/26 15:28:28 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 15:28:35 visual_prompt]: Epoch 84 / 100: avg data time: 5.38e-02, avg batch time: 0.4963, average train loss: 0.0939
[09/26 15:28:36 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 0.8157
[09/26 15:28:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 15:28:36 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 15:28:43 visual_prompt]: Epoch 85 / 100: avg data time: 5.06e-02, avg batch time: 0.4947, average train loss: 0.0935
[09/26 15:28:45 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1662, average loss: 0.8160
[09/26 15:28:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 78.50	top5: 98.00	
[09/26 15:28:45 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 15:28:51 visual_prompt]: Epoch 86 / 100: avg data time: 5.13e-02, avg batch time: 0.4946, average train loss: 0.0935
[09/26 15:28:53 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1663, average loss: 0.8126
[09/26 15:28:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 97.50	
[09/26 15:28:53 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 15:29:00 visual_prompt]: Epoch 87 / 100: avg data time: 5.25e-02, avg batch time: 0.4954, average train loss: 0.0933
[09/26 15:29:02 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 0.8070
[09/26 15:29:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.00	top5: 98.00	
[09/26 15:29:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 15:29:08 visual_prompt]: Epoch 88 / 100: avg data time: 5.07e-02, avg batch time: 0.4940, average train loss: 0.0943
[09/26 15:29:10 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1663, average loss: 0.8061
[09/26 15:29:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 15:29:10 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 15:29:17 visual_prompt]: Epoch 89 / 100: avg data time: 5.04e-02, avg batch time: 0.4929, average train loss: 0.0936
[09/26 15:29:18 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 0.8068
[09/26 15:29:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 15:29:18 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 15:29:25 visual_prompt]: Epoch 90 / 100: avg data time: 5.28e-02, avg batch time: 0.4970, average train loss: 0.0935
[09/26 15:29:27 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1663, average loss: 0.8081
[09/26 15:29:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 79.50	top5: 98.00	
[09/26 15:29:27 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 15:29:34 visual_prompt]: Epoch 91 / 100: avg data time: 4.89e-02, avg batch time: 0.4916, average train loss: 0.0933
[09/26 15:29:35 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1664, average loss: 0.8082
[09/26 15:29:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 81.00	top5: 98.00	
[09/26 15:29:35 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 15:29:42 visual_prompt]: Epoch 92 / 100: avg data time: 4.99e-02, avg batch time: 0.4935, average train loss: 0.0929
[09/26 15:29:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1662, average loss: 0.8068
[09/26 15:29:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:29:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 15:29:50 visual_prompt]: Epoch 93 / 100: avg data time: 5.92e-02, avg batch time: 0.5015, average train loss: 0.0933
[09/26 15:29:52 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 0.8065
[09/26 15:29:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:29:52 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 15:29:59 visual_prompt]: Epoch 94 / 100: avg data time: 5.24e-02, avg batch time: 0.4958, average train loss: 0.0940
[09/26 15:30:00 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 0.8064
[09/26 15:30:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:00 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 15:30:07 visual_prompt]: Epoch 95 / 100: avg data time: 5.08e-02, avg batch time: 0.4944, average train loss: 0.0935
[09/26 15:30:09 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1663, average loss: 0.8067
[09/26 15:30:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:09 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 15:30:16 visual_prompt]: Epoch 96 / 100: avg data time: 5.86e-02, avg batch time: 0.5020, average train loss: 0.0933
[09/26 15:30:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1667, average loss: 0.8077
[09/26 15:30:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:17 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 15:30:24 visual_prompt]: Epoch 97 / 100: avg data time: 5.29e-02, avg batch time: 0.4961, average train loss: 0.0938
[09/26 15:30:26 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1664, average loss: 0.8079
[09/26 15:30:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:26 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 15:30:33 visual_prompt]: Epoch 98 / 100: avg data time: 5.10e-02, avg batch time: 0.4951, average train loss: 0.0932
[09/26 15:30:34 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 0.8078
[09/26 15:30:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:34 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 15:30:41 visual_prompt]: Epoch 99 / 100: avg data time: 5.22e-02, avg batch time: 0.4940, average train loss: 0.0932
[09/26 15:30:42 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 0.8079
[09/26 15:30:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:42 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 15:30:49 visual_prompt]: Epoch 100 / 100: avg data time: 5.80e-02, avg batch time: 0.5007, average train loss: 0.0932
[09/26 15:30:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1667, average loss: 0.8079
[09/26 15:30:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 80.50	top5: 98.00	
[09/26 15:30:51 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:30:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:30:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:30:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:30:51 visual_prompt]: Training with config:
[09/26 15:30:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:30:51 visual_prompt]: Loading training data...
[09/26 15:30:51 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:30:52 visual_prompt]: Number of images: 800
[09/26 15:30:52 visual_prompt]: Number of classes: 45 / 45
[09/26 15:30:52 visual_prompt]: Loading validation data...
[09/26 15:30:52 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:30:52 visual_prompt]: Number of images: 200
[09/26 15:30:52 visual_prompt]: Number of classes: 45 / 45
[09/26 15:30:52 visual_prompt]: Constructing models...
[09/26 15:30:55 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 15:30:55 visual_prompt]: tuned percent:0.574
[09/26 15:30:55 visual_prompt]: Device used for model: 0
[09/26 15:30:55 visual_prompt]: Setting up Evaluator...
[09/26 15:30:55 visual_prompt]: Setting up Trainer...
[09/26 15:30:55 visual_prompt]: 	Setting up the optimizer...
[09/26 15:30:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:31:02 visual_prompt]: Epoch 1 / 100: avg data time: 5.37e-02, avg batch time: 0.4951, average train loss: 3.8926
[09/26 15:31:03 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1662, average loss: 3.9529
[09/26 15:31:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 15:31:03 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 15:31:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 15:31:10 visual_prompt]: Epoch 2 / 100: avg data time: 4.98e-02, avg batch time: 0.4936, average train loss: 3.8436
[09/26 15:31:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1662, average loss: 3.8606
[09/26 15:31:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 11.50	
[09/26 15:31:12 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 15:31:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:31:19 visual_prompt]: Epoch 3 / 100: avg data time: 5.34e-02, avg batch time: 0.4943, average train loss: 3.7590
[09/26 15:31:20 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1662, average loss: 3.7586
[09/26 15:31:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 6.50	top5: 22.50	
[09/26 15:31:20 visual_prompt]: Best epoch 3: best metric: 0.065
[09/26 15:31:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 15:31:27 visual_prompt]: Epoch 4 / 100: avg data time: 5.57e-02, avg batch time: 0.4977, average train loss: 3.6809
[09/26 15:31:29 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 3.6397
[09/26 15:31:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 8.00	top5: 32.00	
[09/26 15:31:29 visual_prompt]: Best epoch 4: best metric: 0.080
[09/26 15:31:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:31:35 visual_prompt]: Epoch 5 / 100: avg data time: 5.05e-02, avg batch time: 0.4933, average train loss: 3.4288
[09/26 15:31:37 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1664, average loss: 3.0802
[09/26 15:31:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 23.00	top5: 46.00	
[09/26 15:31:37 visual_prompt]: Best epoch 5: best metric: 0.230
[09/26 15:31:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 15:31:44 visual_prompt]: Epoch 6 / 100: avg data time: 4.90e-02, avg batch time: 0.4925, average train loss: 2.9804
[09/26 15:31:45 visual_prompt]: Inference (val):avg data time: 5.05e-05, avg batch time: 0.1665, average loss: 2.6987
[09/26 15:31:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 29.00	top5: 59.00	
[09/26 15:31:45 visual_prompt]: Best epoch 6: best metric: 0.290
[09/26 15:31:45 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 15:31:52 visual_prompt]: Epoch 7 / 100: avg data time: 6.14e-02, avg batch time: 0.5043, average train loss: 2.4996
[09/26 15:31:54 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1666, average loss: 2.2451
[09/26 15:31:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 31.50	top5: 75.00	
[09/26 15:31:54 visual_prompt]: Best epoch 7: best metric: 0.315
[09/26 15:31:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 15:32:01 visual_prompt]: Epoch 8 / 100: avg data time: 5.75e-02, avg batch time: 0.4999, average train loss: 2.0763
[09/26 15:32:03 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.9412
[09/26 15:32:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 47.50	top5: 78.50	
[09/26 15:32:03 visual_prompt]: Best epoch 8: best metric: 0.475
[09/26 15:32:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:32:09 visual_prompt]: Epoch 9 / 100: avg data time: 4.92e-02, avg batch time: 0.4918, average train loss: 1.6931
[09/26 15:32:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.8315
[09/26 15:32:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.00	top5: 75.50	
[09/26 15:32:11 visual_prompt]: Best epoch 9: best metric: 0.490
[09/26 15:32:11 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 15:32:18 visual_prompt]: Epoch 10 / 100: avg data time: 5.80e-02, avg batch time: 0.4997, average train loss: 1.5464
[09/26 15:32:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1664, average loss: 1.6408
[09/26 15:32:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.00	top5: 84.00	
[09/26 15:32:19 visual_prompt]: Best epoch 10: best metric: 0.520
[09/26 15:32:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 15:32:26 visual_prompt]: Epoch 11 / 100: avg data time: 6.70e-02, avg batch time: 0.5103, average train loss: 1.1384
[09/26 15:32:28 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1664, average loss: 1.7502
[09/26 15:32:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 51.50	top5: 80.00	
[09/26 15:32:28 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 15:32:35 visual_prompt]: Epoch 12 / 100: avg data time: 5.16e-02, avg batch time: 0.4944, average train loss: 1.0018
[09/26 15:32:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1666, average loss: 1.4138
[09/26 15:32:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.50	top5: 91.50	
[09/26 15:32:36 visual_prompt]: Best epoch 12: best metric: 0.525
[09/26 15:32:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 15:32:43 visual_prompt]: Epoch 13 / 100: avg data time: 4.92e-02, avg batch time: 0.4920, average train loss: 0.7086
[09/26 15:32:45 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 1.3447
[09/26 15:32:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 57.00	top5: 89.00	
[09/26 15:32:45 visual_prompt]: Best epoch 13: best metric: 0.570
[09/26 15:32:45 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 15:32:52 visual_prompt]: Epoch 14 / 100: avg data time: 5.07e-02, avg batch time: 0.4949, average train loss: 0.5155
[09/26 15:32:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 1.2378
[09/26 15:32:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 90.00	
[09/26 15:32:53 visual_prompt]: Best epoch 14: best metric: 0.640
[09/26 15:32:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 15:33:00 visual_prompt]: Epoch 15 / 100: avg data time: 5.34e-02, avg batch time: 0.4961, average train loss: 0.4163
[09/26 15:33:02 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 1.3046
[09/26 15:33:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.00	top5: 93.00	
[09/26 15:33:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 15:33:08 visual_prompt]: Epoch 16 / 100: avg data time: 4.62e-02, avg batch time: 0.4892, average train loss: 0.3407
[09/26 15:33:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 1.1838
[09/26 15:33:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 89.50	
[09/26 15:33:10 visual_prompt]: Best epoch 16: best metric: 0.675
[09/26 15:33:10 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 15:33:17 visual_prompt]: Epoch 17 / 100: avg data time: 5.18e-02, avg batch time: 0.4934, average train loss: 0.3000
[09/26 15:33:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1663, average loss: 1.2257
[09/26 15:33:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 92.00	
[09/26 15:33:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 15:33:25 visual_prompt]: Epoch 18 / 100: avg data time: 5.17e-02, avg batch time: 0.4951, average train loss: 0.2464
[09/26 15:33:27 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.0963
[09/26 15:33:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.50	
[09/26 15:33:27 visual_prompt]: Best epoch 18: best metric: 0.690
[09/26 15:33:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 15:33:34 visual_prompt]: Epoch 19 / 100: avg data time: 5.00e-02, avg batch time: 0.4945, average train loss: 0.2003
[09/26 15:33:35 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 1.2141
[09/26 15:33:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 94.00	
[09/26 15:33:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 15:33:42 visual_prompt]: Epoch 20 / 100: avg data time: 6.37e-02, avg batch time: 0.5070, average train loss: 0.1472
[09/26 15:33:44 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1665, average loss: 1.1018
[09/26 15:33:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.00	
[09/26 15:33:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 15:33:50 visual_prompt]: Epoch 21 / 100: avg data time: 5.44e-02, avg batch time: 0.4975, average train loss: 0.0972
[09/26 15:33:52 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 1.1552
[09/26 15:33:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.00	
[09/26 15:33:52 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 15:33:59 visual_prompt]: Epoch 22 / 100: avg data time: 6.46e-02, avg batch time: 0.5060, average train loss: 0.0814
[09/26 15:34:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 1.1032
[09/26 15:34:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 94.00	
[09/26 15:34:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 15:34:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.66e-02, avg batch time: 0.4991, average train loss: 0.0618
[09/26 15:34:09 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1666, average loss: 1.1009
[09/26 15:34:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.00	
[09/26 15:34:09 visual_prompt]: Best epoch 23: best metric: 0.705
[09/26 15:34:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 15:34:16 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e-02, avg batch time: 0.4959, average train loss: 0.0506
[09/26 15:34:17 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.1198
[09/26 15:34:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 93.50	
[09/26 15:34:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 15:34:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.04e-02, avg batch time: 0.4937, average train loss: 0.0352
[09/26 15:34:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 1.1382
[09/26 15:34:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 15:34:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 15:34:33 visual_prompt]: Epoch 26 / 100: avg data time: 5.86e-02, avg batch time: 0.4999, average train loss: 0.0300
[09/26 15:34:34 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1664, average loss: 1.0528
[09/26 15:34:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 15:34:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 15:34:41 visual_prompt]: Epoch 27 / 100: avg data time: 5.38e-02, avg batch time: 0.4972, average train loss: 0.0260
[09/26 15:34:43 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1668, average loss: 1.1238
[09/26 15:34:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.50	
[09/26 15:34:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 15:34:50 visual_prompt]: Epoch 28 / 100: avg data time: 5.18e-02, avg batch time: 0.4952, average train loss: 0.0234
[09/26 15:34:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 1.1060
[09/26 15:34:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:34:51 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 15:34:58 visual_prompt]: Epoch 29 / 100: avg data time: 4.81e-02, avg batch time: 0.4906, average train loss: 0.0236
[09/26 15:34:59 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 1.1196
[09/26 15:34:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:34:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 15:35:06 visual_prompt]: Epoch 30 / 100: avg data time: 6.11e-02, avg batch time: 0.5039, average train loss: 0.0222
[09/26 15:35:08 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1666, average loss: 1.0837
[09/26 15:35:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.50	
[09/26 15:35:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 15:35:15 visual_prompt]: Epoch 31 / 100: avg data time: 5.13e-02, avg batch time: 0.4943, average train loss: 0.0194
[09/26 15:35:16 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1665, average loss: 1.1313
[09/26 15:35:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.00	
[09/26 15:35:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 15:35:23 visual_prompt]: Epoch 32 / 100: avg data time: 4.79e-02, avg batch time: 0.4906, average train loss: 0.0177
[09/26 15:35:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 1.1107
[09/26 15:35:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 93.50	
[09/26 15:35:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 15:35:32 visual_prompt]: Epoch 33 / 100: avg data time: 6.49e-02, avg batch time: 0.5070, average train loss: 0.0166
[09/26 15:35:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 1.1030
[09/26 15:35:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:35:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 15:35:40 visual_prompt]: Epoch 34 / 100: avg data time: 5.73e-02, avg batch time: 0.5007, average train loss: 0.0160
[09/26 15:35:42 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1667, average loss: 1.1020
[09/26 15:35:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 91.50	
[09/26 15:35:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 15:35:49 visual_prompt]: Epoch 35 / 100: avg data time: 5.45e-02, avg batch time: 0.4981, average train loss: 0.0161
[09/26 15:35:51 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1665, average loss: 1.0876
[09/26 15:35:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 15:35:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 15:35:57 visual_prompt]: Epoch 36 / 100: avg data time: 5.21e-02, avg batch time: 0.4947, average train loss: 0.0163
[09/26 15:35:59 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1666, average loss: 1.1152
[09/26 15:35:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:35:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 15:36:06 visual_prompt]: Epoch 37 / 100: avg data time: 5.29e-02, avg batch time: 0.4965, average train loss: 0.0156
[09/26 15:36:07 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.1301
[09/26 15:36:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 92.00	
[09/26 15:36:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 15:36:14 visual_prompt]: Epoch 38 / 100: avg data time: 5.95e-02, avg batch time: 0.5018, average train loss: 0.0156
[09/26 15:36:16 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.1237
[09/26 15:36:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.50	
[09/26 15:36:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 15:36:23 visual_prompt]: Epoch 39 / 100: avg data time: 4.84e-02, avg batch time: 0.4909, average train loss: 0.0144
[09/26 15:36:24 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.1094
[09/26 15:36:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 94.50	
[09/26 15:36:24 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 15:36:31 visual_prompt]: Epoch 40 / 100: avg data time: 5.77e-02, avg batch time: 0.5000, average train loss: 0.0144
[09/26 15:36:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 1.1007
[09/26 15:36:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 92.50	
[09/26 15:36:33 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 15:36:39 visual_prompt]: Epoch 41 / 100: avg data time: 5.20e-02, avg batch time: 0.4941, average train loss: 0.0140
[09/26 15:36:41 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 1.0855
[09/26 15:36:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.00	top5: 93.00	
[09/26 15:36:41 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 15:36:48 visual_prompt]: Epoch 42 / 100: avg data time: 5.07e-02, avg batch time: 0.4940, average train loss: 0.0140
[09/26 15:36:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1665, average loss: 1.1169
[09/26 15:36:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 68.50	top5: 93.00	
[09/26 15:36:49 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 15:36:56 visual_prompt]: Epoch 43 / 100: avg data time: 6.73e-02, avg batch time: 0.5095, average train loss: 0.0132
[09/26 15:36:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 1.1215
[09/26 15:36:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 93.50	
[09/26 15:36:58 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 15:37:05 visual_prompt]: Epoch 44 / 100: avg data time: 5.88e-02, avg batch time: 0.5012, average train loss: 0.0122
[09/26 15:37:06 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1665, average loss: 1.0952
[09/26 15:37:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 92.00	
[09/26 15:37:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 15:37:13 visual_prompt]: Epoch 45 / 100: avg data time: 4.93e-02, avg batch time: 0.4932, average train loss: 0.0133
[09/26 15:37:15 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1667, average loss: 1.0746
[09/26 15:37:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 92.00	
[09/26 15:37:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 15:37:22 visual_prompt]: Epoch 46 / 100: avg data time: 4.93e-02, avg batch time: 0.4941, average train loss: 0.0124
[09/26 15:37:23 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1667, average loss: 1.0946
[09/26 15:37:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:37:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 15:37:30 visual_prompt]: Epoch 47 / 100: avg data time: 4.88e-02, avg batch time: 0.4925, average train loss: 0.0124
[09/26 15:37:31 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1664, average loss: 1.1077
[09/26 15:37:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 15:37:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 15:37:38 visual_prompt]: Epoch 48 / 100: avg data time: 5.96e-02, avg batch time: 0.5052, average train loss: 0.0118
[09/26 15:37:40 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1665, average loss: 1.0864
[09/26 15:37:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:37:40 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 15:37:47 visual_prompt]: Epoch 49 / 100: avg data time: 4.99e-02, avg batch time: 0.4930, average train loss: 0.0128
[09/26 15:37:48 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 1.0901
[09/26 15:37:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:37:48 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 15:37:55 visual_prompt]: Epoch 50 / 100: avg data time: 4.52e-02, avg batch time: 0.4894, average train loss: 0.0120
[09/26 15:37:57 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1665, average loss: 1.0853
[09/26 15:37:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.50	
[09/26 15:37:57 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 15:38:03 visual_prompt]: Epoch 51 / 100: avg data time: 5.35e-02, avg batch time: 0.4969, average train loss: 0.0124
[09/26 15:38:05 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1666, average loss: 1.0887
[09/26 15:38:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:38:05 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 15:38:12 visual_prompt]: Epoch 52 / 100: avg data time: 5.13e-02, avg batch time: 0.4957, average train loss: 0.0123
[09/26 15:38:14 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1666, average loss: 1.0850
[09/26 15:38:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:38:14 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 15:38:20 visual_prompt]: Epoch 53 / 100: avg data time: 4.91e-02, avg batch time: 0.4914, average train loss: 0.0121
[09/26 15:38:22 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1664, average loss: 1.0792
[09/26 15:38:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:38:22 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 15:38:29 visual_prompt]: Epoch 54 / 100: avg data time: 5.30e-02, avg batch time: 0.4957, average train loss: 0.0119
[09/26 15:38:30 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1666, average loss: 1.0695
[09/26 15:38:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:38:30 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 15:38:37 visual_prompt]: Epoch 55 / 100: avg data time: 4.70e-02, avg batch time: 0.4915, average train loss: 0.0117
[09/26 15:38:39 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1668, average loss: 1.0677
[09/26 15:38:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:38:39 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 15:38:46 visual_prompt]: Epoch 56 / 100: avg data time: 6.11e-02, avg batch time: 0.5046, average train loss: 0.0113
[09/26 15:38:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 1.0651
[09/26 15:38:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:38:47 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 15:38:54 visual_prompt]: Epoch 57 / 100: avg data time: 4.70e-02, avg batch time: 0.4894, average train loss: 0.0115
[09/26 15:38:55 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1667, average loss: 1.0540
[09/26 15:38:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.50	
[09/26 15:38:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 15:39:02 visual_prompt]: Epoch 58 / 100: avg data time: 6.79e-02, avg batch time: 0.5102, average train loss: 0.0121
[09/26 15:39:04 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1667, average loss: 1.0654
[09/26 15:39:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:39:04 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 15:39:11 visual_prompt]: Epoch 59 / 100: avg data time: 5.21e-02, avg batch time: 0.4943, average train loss: 0.0107
[09/26 15:39:12 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1668, average loss: 1.0761
[09/26 15:39:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 92.00	
[09/26 15:39:12 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 15:39:19 visual_prompt]: Epoch 60 / 100: avg data time: 5.21e-02, avg batch time: 0.4969, average train loss: 0.0112
[09/26 15:39:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1668, average loss: 1.0726
[09/26 15:39:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 15:39:21 visual_prompt]: Best epoch 60: best metric: 0.710
[09/26 15:39:21 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 15:39:28 visual_prompt]: Epoch 61 / 100: avg data time: 5.60e-02, avg batch time: 0.4983, average train loss: 0.0111
[09/26 15:39:29 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.0723
[09/26 15:39:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:39:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 15:39:36 visual_prompt]: Epoch 62 / 100: avg data time: 4.97e-02, avg batch time: 0.4928, average train loss: 0.0112
[09/26 15:39:38 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1663, average loss: 1.0706
[09/26 15:39:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:39:38 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 15:39:44 visual_prompt]: Epoch 63 / 100: avg data time: 4.87e-02, avg batch time: 0.4932, average train loss: 0.0111
[09/26 15:39:46 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1665, average loss: 1.0621
[09/26 15:39:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 15:39:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 15:39:53 visual_prompt]: Epoch 64 / 100: avg data time: 5.22e-02, avg batch time: 0.4945, average train loss: 0.0112
[09/26 15:39:54 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.0619
[09/26 15:39:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:39:54 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 15:40:01 visual_prompt]: Epoch 65 / 100: avg data time: 5.11e-02, avg batch time: 0.4959, average train loss: 0.0108
[09/26 15:40:03 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.0672
[09/26 15:40:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:40:03 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 15:40:10 visual_prompt]: Epoch 66 / 100: avg data time: 4.95e-02, avg batch time: 0.4921, average train loss: 0.0104
[09/26 15:40:11 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1665, average loss: 1.0631
[09/26 15:40:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:40:11 visual_prompt]: Best epoch 66: best metric: 0.715
[09/26 15:40:11 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 15:40:18 visual_prompt]: Epoch 67 / 100: avg data time: 5.87e-02, avg batch time: 0.5030, average train loss: 0.0112
[09/26 15:40:20 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1667, average loss: 1.0541
[09/26 15:40:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.00	
[09/26 15:40:20 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 15:40:27 visual_prompt]: Epoch 68 / 100: avg data time: 5.38e-02, avg batch time: 0.4975, average train loss: 0.0109
[09/26 15:40:28 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1664, average loss: 1.0562
[09/26 15:40:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.00	
[09/26 15:40:28 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 15:40:35 visual_prompt]: Epoch 69 / 100: avg data time: 5.43e-02, avg batch time: 0.4965, average train loss: 0.0102
[09/26 15:40:37 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1665, average loss: 1.0683
[09/26 15:40:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 15:40:37 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 15:40:43 visual_prompt]: Epoch 70 / 100: avg data time: 4.91e-02, avg batch time: 0.4934, average train loss: 0.0102
[09/26 15:40:45 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1666, average loss: 1.0653
[09/26 15:40:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:40:45 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 15:40:52 visual_prompt]: Epoch 71 / 100: avg data time: 5.24e-02, avg batch time: 0.4967, average train loss: 0.0107
[09/26 15:40:53 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1664, average loss: 1.0685
[09/26 15:40:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:40:53 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 15:41:00 visual_prompt]: Epoch 72 / 100: avg data time: 5.60e-02, avg batch time: 0.4991, average train loss: 0.0109
[09/26 15:41:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 1.0699
[09/26 15:41:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:41:02 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 15:41:09 visual_prompt]: Epoch 73 / 100: avg data time: 5.32e-02, avg batch time: 0.4976, average train loss: 0.0110
[09/26 15:41:10 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1666, average loss: 1.0677
[09/26 15:41:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:41:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 15:41:17 visual_prompt]: Epoch 74 / 100: avg data time: 5.28e-02, avg batch time: 0.4962, average train loss: 0.0110
[09/26 15:41:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.0616
[09/26 15:41:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 15:41:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 15:41:26 visual_prompt]: Epoch 75 / 100: avg data time: 5.20e-02, avg batch time: 0.4967, average train loss: 0.0107
[09/26 15:41:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 1.0588
[09/26 15:41:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.50	
[09/26 15:41:27 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 15:41:34 visual_prompt]: Epoch 76 / 100: avg data time: 5.77e-02, avg batch time: 0.4996, average train loss: 0.0105
[09/26 15:41:36 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1669, average loss: 1.0626
[09/26 15:41:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.00	
[09/26 15:41:36 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 15:41:42 visual_prompt]: Epoch 77 / 100: avg data time: 5.13e-02, avg batch time: 0.4937, average train loss: 0.0099
[09/26 15:41:44 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 1.0617
[09/26 15:41:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 15:41:44 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 15:41:51 visual_prompt]: Epoch 78 / 100: avg data time: 4.81e-02, avg batch time: 0.4930, average train loss: 0.0108
[09/26 15:41:52 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 1.0626
[09/26 15:41:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:41:52 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 15:41:59 visual_prompt]: Epoch 79 / 100: avg data time: 6.51e-02, avg batch time: 0.5071, average train loss: 0.0106
[09/26 15:42:01 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1669, average loss: 1.0600
[09/26 15:42:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:42:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 15:42:08 visual_prompt]: Epoch 80 / 100: avg data time: 5.05e-02, avg batch time: 0.4924, average train loss: 0.0103
[09/26 15:42:09 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1665, average loss: 1.0583
[09/26 15:42:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:42:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 15:42:16 visual_prompt]: Epoch 81 / 100: avg data time: 4.65e-02, avg batch time: 0.4904, average train loss: 0.0109
[09/26 15:42:18 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 1.0579
[09/26 15:42:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:42:18 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 15:42:24 visual_prompt]: Epoch 82 / 100: avg data time: 5.33e-02, avg batch time: 0.4980, average train loss: 0.0102
[09/26 15:42:26 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 1.0572
[09/26 15:42:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:42:26 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 15:42:33 visual_prompt]: Epoch 83 / 100: avg data time: 4.87e-02, avg batch time: 0.4914, average train loss: 0.0105
[09/26 15:42:34 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1666, average loss: 1.0595
[09/26 15:42:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:42:34 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 15:42:41 visual_prompt]: Epoch 84 / 100: avg data time: 4.84e-02, avg batch time: 0.4917, average train loss: 0.0103
[09/26 15:42:43 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1666, average loss: 1.0622
[09/26 15:42:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:42:43 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 15:42:49 visual_prompt]: Epoch 85 / 100: avg data time: 4.96e-02, avg batch time: 0.4916, average train loss: 0.0103
[09/26 15:42:51 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1669, average loss: 1.0626
[09/26 15:42:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 92.50	
[09/26 15:42:51 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 15:42:58 visual_prompt]: Epoch 86 / 100: avg data time: 5.33e-02, avg batch time: 0.4952, average train loss: 0.0102
[09/26 15:42:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.0630
[09/26 15:42:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:42:59 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 15:43:06 visual_prompt]: Epoch 87 / 100: avg data time: 5.02e-02, avg batch time: 0.4947, average train loss: 0.0100
[09/26 15:43:08 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 1.0634
[09/26 15:43:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 15:43:15 visual_prompt]: Epoch 88 / 100: avg data time: 5.20e-02, avg batch time: 0.4963, average train loss: 0.0103
[09/26 15:43:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 1.0639
[09/26 15:43:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:16 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 15:43:23 visual_prompt]: Epoch 89 / 100: avg data time: 4.77e-02, avg batch time: 0.4908, average train loss: 0.0100
[09/26 15:43:25 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 1.0657
[09/26 15:43:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 15:43:31 visual_prompt]: Epoch 90 / 100: avg data time: 5.23e-02, avg batch time: 0.4953, average train loss: 0.0101
[09/26 15:43:33 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1667, average loss: 1.0650
[09/26 15:43:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:33 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 15:43:40 visual_prompt]: Epoch 91 / 100: avg data time: 5.13e-02, avg batch time: 0.4937, average train loss: 0.0102
[09/26 15:43:42 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1668, average loss: 1.0641
[09/26 15:43:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:42 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 15:43:48 visual_prompt]: Epoch 92 / 100: avg data time: 5.47e-02, avg batch time: 0.4998, average train loss: 0.0104
[09/26 15:43:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1666, average loss: 1.0632
[09/26 15:43:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 15:43:57 visual_prompt]: Epoch 93 / 100: avg data time: 4.83e-02, avg batch time: 0.4918, average train loss: 0.0105
[09/26 15:43:58 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1672, average loss: 1.0627
[09/26 15:43:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:43:58 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 15:44:05 visual_prompt]: Epoch 94 / 100: avg data time: 5.08e-02, avg batch time: 0.4953, average train loss: 0.0104
[09/26 15:44:07 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1667, average loss: 1.0625
[09/26 15:44:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:07 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 15:44:14 visual_prompt]: Epoch 95 / 100: avg data time: 6.09e-02, avg batch time: 0.5038, average train loss: 0.0102
[09/26 15:44:15 visual_prompt]: Inference (val):avg data time: 4.68e-05, avg batch time: 0.1666, average loss: 1.0624
[09/26 15:44:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:15 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 15:44:22 visual_prompt]: Epoch 96 / 100: avg data time: 5.73e-02, avg batch time: 0.5006, average train loss: 0.0103
[09/26 15:44:24 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 1.0622
[09/26 15:44:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 15:44:31 visual_prompt]: Epoch 97 / 100: avg data time: 5.03e-02, avg batch time: 0.4944, average train loss: 0.0104
[09/26 15:44:32 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 1.0621
[09/26 15:44:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:32 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 15:44:39 visual_prompt]: Epoch 98 / 100: avg data time: 5.00e-02, avg batch time: 0.4956, average train loss: 0.0105
[09/26 15:44:40 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1665, average loss: 1.0622
[09/26 15:44:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:40 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 15:44:47 visual_prompt]: Epoch 99 / 100: avg data time: 4.92e-02, avg batch time: 0.4933, average train loss: 0.0104
[09/26 15:44:49 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1666, average loss: 1.0623
[09/26 15:44:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:49 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 15:44:56 visual_prompt]: Epoch 100 / 100: avg data time: 6.11e-02, avg batch time: 0.5041, average train loss: 0.0105
[09/26 15:44:57 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1667, average loss: 1.0623
[09/26 15:44:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 15:44:57 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:44:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:44:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:44:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:44:57 visual_prompt]: Training with config:
[09/26 15:44:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:44:57 visual_prompt]: Loading training data...
[09/26 15:44:57 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:44:58 visual_prompt]: Number of images: 800
[09/26 15:44:58 visual_prompt]: Number of classes: 45 / 45
[09/26 15:44:58 visual_prompt]: Loading validation data...
[09/26 15:44:58 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:44:59 visual_prompt]: Number of images: 200
[09/26 15:44:59 visual_prompt]: Number of classes: 45 / 45
[09/26 15:44:59 visual_prompt]: Constructing models...
[09/26 15:45:01 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 15:45:01 visual_prompt]: tuned percent:0.574
[09/26 15:45:01 visual_prompt]: Device used for model: 0
[09/26 15:45:01 visual_prompt]: Setting up Evaluator...
[09/26 15:45:01 visual_prompt]: Setting up Trainer...
[09/26 15:45:01 visual_prompt]: 	Setting up the optimizer...
[09/26 15:45:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:45:08 visual_prompt]: Epoch 1 / 100: avg data time: 5.79e-02, avg batch time: 0.4985, average train loss: 3.8908
[09/26 15:45:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1659, average loss: 3.9529
[09/26 15:45:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 15:45:10 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 15:45:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 15:45:17 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e-02, avg batch time: 0.4909, average train loss: 3.8506
[09/26 15:45:18 visual_prompt]: Inference (val):avg data time: 4.31e-05, avg batch time: 0.1662, average loss: 3.8631
[09/26 15:45:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.50	top5: 9.50	
[09/26 15:45:18 visual_prompt]: Best epoch 2: best metric: 0.025
[09/26 15:45:18 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:45:25 visual_prompt]: Epoch 3 / 100: avg data time: 5.63e-02, avg batch time: 0.4996, average train loss: 3.7717
[09/26 15:45:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1663, average loss: 3.7717
[09/26 15:45:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 4.50	top5: 18.50	
[09/26 15:45:27 visual_prompt]: Best epoch 3: best metric: 0.045
[09/26 15:45:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 15:45:34 visual_prompt]: Epoch 4 / 100: avg data time: 5.87e-02, avg batch time: 0.4998, average train loss: 3.6999
[09/26 15:45:35 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 3.6543
[09/26 15:45:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 11.50	top5: 31.50	
[09/26 15:45:35 visual_prompt]: Best epoch 4: best metric: 0.115
[09/26 15:45:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:45:42 visual_prompt]: Epoch 5 / 100: avg data time: 5.93e-02, avg batch time: 0.5030, average train loss: 3.5122
[09/26 15:45:44 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1661, average loss: 3.1818
[09/26 15:45:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 15.50	top5: 44.50	
[09/26 15:45:44 visual_prompt]: Best epoch 5: best metric: 0.155
[09/26 15:45:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 15:45:51 visual_prompt]: Epoch 6 / 100: avg data time: 5.21e-02, avg batch time: 0.4944, average train loss: 2.9927
[09/26 15:45:52 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 2.5586
[09/26 15:45:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 30.50	top5: 64.00	
[09/26 15:45:52 visual_prompt]: Best epoch 6: best metric: 0.305
[09/26 15:45:52 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 15:45:59 visual_prompt]: Epoch 7 / 100: avg data time: 5.44e-02, avg batch time: 0.4979, average train loss: 2.5026
[09/26 15:46:01 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1663, average loss: 2.4075
[09/26 15:46:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 35.00	top5: 69.00	
[09/26 15:46:01 visual_prompt]: Best epoch 7: best metric: 0.350
[09/26 15:46:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 15:46:08 visual_prompt]: Epoch 8 / 100: avg data time: 6.20e-02, avg batch time: 0.5034, average train loss: 2.0687
[09/26 15:46:09 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.9158
[09/26 15:46:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.50	top5: 78.00	
[09/26 15:46:09 visual_prompt]: Best epoch 8: best metric: 0.495
[09/26 15:46:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 15:46:16 visual_prompt]: Epoch 9 / 100: avg data time: 6.19e-02, avg batch time: 0.5039, average train loss: 1.6616
[09/26 15:46:18 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1663, average loss: 1.8812
[09/26 15:46:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 44.00	top5: 82.50	
[09/26 15:46:18 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 15:46:25 visual_prompt]: Epoch 10 / 100: avg data time: 5.08e-02, avg batch time: 0.4929, average train loss: 1.4570
[09/26 15:46:26 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.7746
[09/26 15:46:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.50	top5: 80.50	
[09/26 15:46:26 visual_prompt]: Best epoch 10: best metric: 0.505
[09/26 15:46:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 15:46:33 visual_prompt]: Epoch 11 / 100: avg data time: 5.94e-02, avg batch time: 0.5013, average train loss: 1.2211
[09/26 15:46:35 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1662, average loss: 1.5516
[09/26 15:46:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 53.50	top5: 85.00	
[09/26 15:46:35 visual_prompt]: Best epoch 11: best metric: 0.535
[09/26 15:46:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 15:46:42 visual_prompt]: Epoch 12 / 100: avg data time: 6.13e-02, avg batch time: 0.5031, average train loss: 0.9961
[09/26 15:46:43 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1662, average loss: 1.4393
[09/26 15:46:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 58.50	top5: 89.00	
[09/26 15:46:43 visual_prompt]: Best epoch 12: best metric: 0.585
[09/26 15:46:43 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 15:46:50 visual_prompt]: Epoch 13 / 100: avg data time: 4.85e-02, avg batch time: 0.4913, average train loss: 0.7195
[09/26 15:46:52 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1664, average loss: 1.2775
[09/26 15:46:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.50	top5: 91.00	
[09/26 15:46:52 visual_prompt]: Best epoch 13: best metric: 0.625
[09/26 15:46:52 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 15:46:58 visual_prompt]: Epoch 14 / 100: avg data time: 5.02e-02, avg batch time: 0.4929, average train loss: 0.5539
[09/26 15:47:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1662, average loss: 1.2974
[09/26 15:47:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 63.50	top5: 87.50	
[09/26 15:47:00 visual_prompt]: Best epoch 14: best metric: 0.635
[09/26 15:47:00 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 15:47:07 visual_prompt]: Epoch 15 / 100: avg data time: 5.48e-02, avg batch time: 0.4968, average train loss: 0.4515
[09/26 15:47:09 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1662, average loss: 1.2658
[09/26 15:47:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 62.00	top5: 93.00	
[09/26 15:47:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 15:47:16 visual_prompt]: Epoch 16 / 100: avg data time: 5.47e-02, avg batch time: 0.4959, average train loss: 0.3340
[09/26 15:47:17 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1663, average loss: 1.1061
[09/26 15:47:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 92.00	
[09/26 15:47:17 visual_prompt]: Best epoch 16: best metric: 0.675
[09/26 15:47:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 15:47:24 visual_prompt]: Epoch 17 / 100: avg data time: 5.21e-02, avg batch time: 0.4950, average train loss: 0.2264
[09/26 15:47:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1663, average loss: 1.1720
[09/26 15:47:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 92.50	
[09/26 15:47:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 15:47:33 visual_prompt]: Epoch 18 / 100: avg data time: 6.15e-02, avg batch time: 0.5053, average train loss: 0.1470
[09/26 15:47:34 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1663, average loss: 1.1639
[09/26 15:47:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.00	top5: 94.00	
[09/26 15:47:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 15:47:41 visual_prompt]: Epoch 19 / 100: avg data time: 5.34e-02, avg batch time: 0.4961, average train loss: 0.1178
[09/26 15:47:43 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1663, average loss: 1.1314
[09/26 15:47:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.00	top5: 94.00	
[09/26 15:47:43 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 15:47:49 visual_prompt]: Epoch 20 / 100: avg data time: 5.35e-02, avg batch time: 0.4960, average train loss: 0.0852
[09/26 15:47:51 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1661, average loss: 1.1134
[09/26 15:47:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 93.50	
[09/26 15:47:51 visual_prompt]: Best epoch 20: best metric: 0.695
[09/26 15:47:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 15:47:58 visual_prompt]: Epoch 21 / 100: avg data time: 4.79e-02, avg batch time: 0.4903, average train loss: 0.0677
[09/26 15:48:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.1008
[09/26 15:48:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 15:48:00 visual_prompt]: Best epoch 21: best metric: 0.715
[09/26 15:48:00 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 15:48:06 visual_prompt]: Epoch 22 / 100: avg data time: 5.07e-02, avg batch time: 0.4927, average train loss: 0.0482
[09/26 15:48:08 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1667, average loss: 1.1321
[09/26 15:48:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 93.50	
[09/26 15:48:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 15:48:15 visual_prompt]: Epoch 23 / 100: avg data time: 5.29e-02, avg batch time: 0.4968, average train loss: 0.0450
[09/26 15:48:16 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1662, average loss: 1.1022
[09/26 15:48:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 15:48:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 15:48:23 visual_prompt]: Epoch 24 / 100: avg data time: 5.28e-02, avg batch time: 0.4975, average train loss: 0.0341
[09/26 15:48:25 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1663, average loss: 1.1372
[09/26 15:48:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:48:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 15:48:32 visual_prompt]: Epoch 25 / 100: avg data time: 6.60e-02, avg batch time: 0.5069, average train loss: 0.0284
[09/26 15:48:34 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1662, average loss: 1.0993
[09/26 15:48:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.00	
[09/26 15:48:34 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 15:48:40 visual_prompt]: Epoch 26 / 100: avg data time: 6.01e-02, avg batch time: 0.5020, average train loss: 0.0247
[09/26 15:48:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.0977
[09/26 15:48:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:48:42 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 15:48:49 visual_prompt]: Epoch 27 / 100: avg data time: 5.02e-02, avg batch time: 0.4916, average train loss: 0.0248
[09/26 15:48:50 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1664, average loss: 1.1106
[09/26 15:48:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 95.00	
[09/26 15:48:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 15:48:57 visual_prompt]: Epoch 28 / 100: avg data time: 5.31e-02, avg batch time: 0.4964, average train loss: 0.0211
[09/26 15:48:59 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1666, average loss: 1.0940
[09/26 15:48:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 15:48:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 15:49:06 visual_prompt]: Epoch 29 / 100: avg data time: 4.70e-02, avg batch time: 0.4907, average train loss: 0.0185
[09/26 15:49:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1663, average loss: 1.1011
[09/26 15:49:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 15:49:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 15:49:14 visual_prompt]: Epoch 30 / 100: avg data time: 4.85e-02, avg batch time: 0.4920, average train loss: 0.0160
[09/26 15:49:16 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1664, average loss: 1.1006
[09/26 15:49:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.00	
[09/26 15:49:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 15:49:23 visual_prompt]: Epoch 31 / 100: avg data time: 4.84e-02, avg batch time: 0.4920, average train loss: 0.0176
[09/26 15:49:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1664, average loss: 1.1623
[09/26 15:49:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 15:49:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 15:49:31 visual_prompt]: Epoch 32 / 100: avg data time: 4.87e-02, avg batch time: 0.4926, average train loss: 0.0158
[09/26 15:49:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.0873
[09/26 15:49:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.50	
[09/26 15:49:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 15:49:39 visual_prompt]: Epoch 33 / 100: avg data time: 4.93e-02, avg batch time: 0.4927, average train loss: 0.0139
[09/26 15:49:41 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1663, average loss: 1.0962
[09/26 15:49:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 15:49:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 15:49:48 visual_prompt]: Epoch 34 / 100: avg data time: 6.14e-02, avg batch time: 0.5031, average train loss: 0.0127
[09/26 15:49:50 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.1285
[09/26 15:49:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 94.50	
[09/26 15:49:50 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 15:49:56 visual_prompt]: Epoch 35 / 100: avg data time: 4.90e-02, avg batch time: 0.4933, average train loss: 0.0121
[09/26 15:49:58 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.1042
[09/26 15:49:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.00	
[09/26 15:49:58 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 15:50:05 visual_prompt]: Epoch 36 / 100: avg data time: 5.49e-02, avg batch time: 0.4991, average train loss: 0.0118
[09/26 15:50:06 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 1.1087
[09/26 15:50:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 15:50:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 15:50:13 visual_prompt]: Epoch 37 / 100: avg data time: 5.90e-02, avg batch time: 0.5008, average train loss: 0.0114
[09/26 15:50:15 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1665, average loss: 1.1165
[09/26 15:50:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 15:50:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 15:50:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.29e-02, avg batch time: 0.4959, average train loss: 0.0103
[09/26 15:50:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.0806
[09/26 15:50:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 15:50:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 15:50:30 visual_prompt]: Epoch 39 / 100: avg data time: 6.37e-02, avg batch time: 0.5054, average train loss: 0.0101
[09/26 15:50:32 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 1.1049
[09/26 15:50:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 94.00	
[09/26 15:50:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 15:50:39 visual_prompt]: Epoch 40 / 100: avg data time: 5.65e-02, avg batch time: 0.4983, average train loss: 0.0090
[09/26 15:50:40 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.0947
[09/26 15:50:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 15:50:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 15:50:47 visual_prompt]: Epoch 41 / 100: avg data time: 5.41e-02, avg batch time: 0.4958, average train loss: 0.0098
[09/26 15:50:49 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 1.0796
[09/26 15:50:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 15:50:49 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 15:50:56 visual_prompt]: Epoch 42 / 100: avg data time: 5.36e-02, avg batch time: 0.4950, average train loss: 0.0083
[09/26 15:50:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1665, average loss: 1.0830
[09/26 15:50:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.00	
[09/26 15:50:57 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 15:51:04 visual_prompt]: Epoch 43 / 100: avg data time: 5.38e-02, avg batch time: 0.4967, average train loss: 0.0091
[09/26 15:51:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1667, average loss: 1.0799
[09/26 15:51:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 15:51:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 15:51:12 visual_prompt]: Epoch 44 / 100: avg data time: 5.28e-02, avg batch time: 0.4945, average train loss: 0.0086
[09/26 15:51:14 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1665, average loss: 1.0848
[09/26 15:51:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 15:51:14 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 15:51:21 visual_prompt]: Epoch 45 / 100: avg data time: 5.81e-02, avg batch time: 0.5006, average train loss: 0.0079
[09/26 15:51:22 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1666, average loss: 1.1018
[09/26 15:51:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 15:51:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 15:51:29 visual_prompt]: Epoch 46 / 100: avg data time: 4.72e-02, avg batch time: 0.4892, average train loss: 0.0079
[09/26 15:51:31 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1665, average loss: 1.1002
[09/26 15:51:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 15:51:31 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 15:51:37 visual_prompt]: Epoch 47 / 100: avg data time: 5.09e-02, avg batch time: 0.4938, average train loss: 0.0079
[09/26 15:51:39 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1665, average loss: 1.0904
[09/26 15:51:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 15:51:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 15:51:46 visual_prompt]: Epoch 48 / 100: avg data time: 6.09e-02, avg batch time: 0.5030, average train loss: 0.0075
[09/26 15:51:48 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1665, average loss: 1.1146
[09/26 15:51:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 15:51:48 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 15:51:54 visual_prompt]: Epoch 49 / 100: avg data time: 5.25e-02, avg batch time: 0.4957, average train loss: 0.0074
[09/26 15:51:56 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1664, average loss: 1.1238
[09/26 15:51:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 15:51:56 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 15:52:03 visual_prompt]: Epoch 50 / 100: avg data time: 5.47e-02, avg batch time: 0.4987, average train loss: 0.0079
[09/26 15:52:05 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 1.1004
[09/26 15:52:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:52:05 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 15:52:11 visual_prompt]: Epoch 51 / 100: avg data time: 5.11e-02, avg batch time: 0.4946, average train loss: 0.0071
[09/26 15:52:13 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1666, average loss: 1.0846
[09/26 15:52:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:52:13 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 15:52:20 visual_prompt]: Epoch 52 / 100: avg data time: 5.43e-02, avg batch time: 0.4968, average train loss: 0.0070
[09/26 15:52:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1666, average loss: 1.0733
[09/26 15:52:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 15:52:22 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 15:52:28 visual_prompt]: Epoch 53 / 100: avg data time: 6.00e-02, avg batch time: 0.5015, average train loss: 0.0068
[09/26 15:52:30 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1662, average loss: 1.0845
[09/26 15:52:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 15:52:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 15:52:37 visual_prompt]: Epoch 54 / 100: avg data time: 6.07e-02, avg batch time: 0.5022, average train loss: 0.0077
[09/26 15:52:39 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1666, average loss: 1.0940
[09/26 15:52:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 95.50	
[09/26 15:52:39 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 15:52:45 visual_prompt]: Epoch 55 / 100: avg data time: 5.03e-02, avg batch time: 0.4946, average train loss: 0.0072
[09/26 15:52:47 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1665, average loss: 1.0958
[09/26 15:52:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.00	
[09/26 15:52:47 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 15:52:54 visual_prompt]: Epoch 56 / 100: avg data time: 5.03e-02, avg batch time: 0.4933, average train loss: 0.0066
[09/26 15:52:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.0841
[09/26 15:52:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 15:52:55 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 15:53:02 visual_prompt]: Epoch 57 / 100: avg data time: 5.06e-02, avg batch time: 0.4949, average train loss: 0.0066
[09/26 15:53:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1665, average loss: 1.0869
[09/26 15:53:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.50	
[09/26 15:53:04 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 15:53:11 visual_prompt]: Epoch 58 / 100: avg data time: 5.09e-02, avg batch time: 0.4950, average train loss: 0.0064
[09/26 15:53:12 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1667, average loss: 1.0884
[09/26 15:53:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 95.50	
[09/26 15:53:12 visual_prompt]: Best epoch 58: best metric: 0.720
[09/26 15:53:12 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 15:53:19 visual_prompt]: Epoch 59 / 100: avg data time: 5.80e-02, avg batch time: 0.5006, average train loss: 0.0061
[09/26 15:53:21 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1667, average loss: 1.0849
[09/26 15:53:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:53:21 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 15:53:28 visual_prompt]: Epoch 60 / 100: avg data time: 5.04e-02, avg batch time: 0.4960, average train loss: 0.0061
[09/26 15:53:29 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 1.0861
[09/26 15:53:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:53:29 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 15:53:36 visual_prompt]: Epoch 61 / 100: avg data time: 5.39e-02, avg batch time: 0.4977, average train loss: 0.0059
[09/26 15:53:38 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1667, average loss: 1.0926
[09/26 15:53:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:53:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 15:53:45 visual_prompt]: Epoch 62 / 100: avg data time: 5.58e-02, avg batch time: 0.4995, average train loss: 0.0055
[09/26 15:53:46 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1666, average loss: 1.0982
[09/26 15:53:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:53:46 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 15:53:53 visual_prompt]: Epoch 63 / 100: avg data time: 5.23e-02, avg batch time: 0.4950, average train loss: 0.0063
[09/26 15:53:55 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1669, average loss: 1.0979
[09/26 15:53:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:53:55 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 15:54:01 visual_prompt]: Epoch 64 / 100: avg data time: 4.61e-02, avg batch time: 0.4892, average train loss: 0.0056
[09/26 15:54:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1665, average loss: 1.0938
[09/26 15:54:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 15:54:03 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 15:54:10 visual_prompt]: Epoch 65 / 100: avg data time: 4.69e-02, avg batch time: 0.4912, average train loss: 0.0055
[09/26 15:54:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1662, average loss: 1.0910
[09/26 15:54:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:54:11 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 15:54:18 visual_prompt]: Epoch 66 / 100: avg data time: 6.68e-02, avg batch time: 0.5086, average train loss: 0.0056
[09/26 15:54:20 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1668, average loss: 1.0903
[09/26 15:54:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:54:20 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 15:54:27 visual_prompt]: Epoch 67 / 100: avg data time: 4.70e-02, avg batch time: 0.4911, average train loss: 0.0051
[09/26 15:54:28 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1665, average loss: 1.0909
[09/26 15:54:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:54:28 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 15:54:35 visual_prompt]: Epoch 68 / 100: avg data time: 6.22e-02, avg batch time: 0.5052, average train loss: 0.0058
[09/26 15:54:37 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1666, average loss: 1.0891
[09/26 15:54:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:54:37 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 15:54:44 visual_prompt]: Epoch 69 / 100: avg data time: 5.35e-02, avg batch time: 0.4976, average train loss: 0.0052
[09/26 15:54:45 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1665, average loss: 1.0856
[09/26 15:54:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 95.00	
[09/26 15:54:45 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 15:54:52 visual_prompt]: Epoch 70 / 100: avg data time: 5.31e-02, avg batch time: 0.4946, average train loss: 0.0057
[09/26 15:54:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1666, average loss: 1.0888
[09/26 15:54:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 15:54:54 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 15:55:01 visual_prompt]: Epoch 71 / 100: avg data time: 5.05e-02, avg batch time: 0.4939, average train loss: 0.0055
[09/26 15:55:02 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.0897
[09/26 15:55:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 96.00	
[09/26 15:55:02 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 15:55:09 visual_prompt]: Epoch 72 / 100: avg data time: 5.70e-02, avg batch time: 0.5003, average train loss: 0.0057
[09/26 15:55:11 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1666, average loss: 1.0857
[09/26 15:55:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:55:11 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 15:55:18 visual_prompt]: Epoch 73 / 100: avg data time: 5.89e-02, avg batch time: 0.5011, average train loss: 0.0056
[09/26 15:55:19 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1666, average loss: 1.0854
[09/26 15:55:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 15:55:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 15:55:26 visual_prompt]: Epoch 74 / 100: avg data time: 5.20e-02, avg batch time: 0.4960, average train loss: 0.0058
[09/26 15:55:28 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1664, average loss: 1.0858
[09/26 15:55:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:55:28 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 15:55:34 visual_prompt]: Epoch 75 / 100: avg data time: 5.20e-02, avg batch time: 0.4970, average train loss: 0.0051
[09/26 15:55:36 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1666, average loss: 1.0882
[09/26 15:55:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 96.00	
[09/26 15:55:36 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 15:55:43 visual_prompt]: Epoch 76 / 100: avg data time: 4.84e-02, avg batch time: 0.4930, average train loss: 0.0052
[09/26 15:55:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.0894
[09/26 15:55:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:55:45 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 15:55:51 visual_prompt]: Epoch 77 / 100: avg data time: 5.15e-02, avg batch time: 0.4957, average train loss: 0.0051
[09/26 15:55:53 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1663, average loss: 1.0865
[09/26 15:55:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:55:53 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 15:56:00 visual_prompt]: Epoch 78 / 100: avg data time: 4.83e-02, avg batch time: 0.4917, average train loss: 0.0050
[09/26 15:56:01 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1665, average loss: 1.0860
[09/26 15:56:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:56:01 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 15:56:08 visual_prompt]: Epoch 79 / 100: avg data time: 5.32e-02, avg batch time: 0.4965, average train loss: 0.0050
[09/26 15:56:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1667, average loss: 1.0873
[09/26 15:56:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:56:10 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 15:56:17 visual_prompt]: Epoch 80 / 100: avg data time: 5.11e-02, avg batch time: 0.4952, average train loss: 0.0050
[09/26 15:56:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1664, average loss: 1.0872
[09/26 15:56:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 96.00	
[09/26 15:56:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 15:56:25 visual_prompt]: Epoch 81 / 100: avg data time: 5.11e-02, avg batch time: 0.4957, average train loss: 0.0052
[09/26 15:56:27 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 1.0868
[09/26 15:56:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:56:27 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 15:56:34 visual_prompt]: Epoch 82 / 100: avg data time: 6.39e-02, avg batch time: 0.5065, average train loss: 0.0056
[09/26 15:56:35 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1665, average loss: 1.0876
[09/26 15:56:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 15:56:35 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 15:56:42 visual_prompt]: Epoch 83 / 100: avg data time: 5.00e-02, avg batch time: 0.4943, average train loss: 0.0052
[09/26 15:56:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1664, average loss: 1.0897
[09/26 15:56:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:56:44 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 15:56:50 visual_prompt]: Epoch 84 / 100: avg data time: 5.16e-02, avg batch time: 0.4952, average train loss: 0.0054
[09/26 15:56:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1667, average loss: 1.0893
[09/26 15:56:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:56:52 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 15:56:59 visual_prompt]: Epoch 85 / 100: avg data time: 5.36e-02, avg batch time: 0.4968, average train loss: 0.0054
[09/26 15:57:01 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.0895
[09/26 15:57:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:57:01 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 15:57:07 visual_prompt]: Epoch 86 / 100: avg data time: 4.98e-02, avg batch time: 0.4932, average train loss: 0.0052
[09/26 15:57:09 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.0897
[09/26 15:57:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 15:57:09 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 15:57:16 visual_prompt]: Epoch 87 / 100: avg data time: 5.25e-02, avg batch time: 0.4966, average train loss: 0.0050
[09/26 15:57:17 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 1.0905
[09/26 15:57:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 95.50	
[09/26 15:57:17 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 15:57:24 visual_prompt]: Epoch 88 / 100: avg data time: 5.37e-02, avg batch time: 0.4958, average train loss: 0.0054
[09/26 15:57:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1668, average loss: 1.0910
[09/26 15:57:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:57:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 15:57:33 visual_prompt]: Epoch 89 / 100: avg data time: 5.04e-02, avg batch time: 0.4927, average train loss: 0.0052
[09/26 15:57:34 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1664, average loss: 1.0909
[09/26 15:57:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:57:34 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 15:57:41 visual_prompt]: Epoch 90 / 100: avg data time: 5.38e-02, avg batch time: 0.4978, average train loss: 0.0052
[09/26 15:57:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1665, average loss: 1.0912
[09/26 15:57:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:57:43 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 15:57:50 visual_prompt]: Epoch 91 / 100: avg data time: 6.36e-02, avg batch time: 0.5052, average train loss: 0.0051
[09/26 15:57:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1664, average loss: 1.0914
[09/26 15:57:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:57:51 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 15:57:58 visual_prompt]: Epoch 92 / 100: avg data time: 4.50e-02, avg batch time: 0.4890, average train loss: 0.0055
[09/26 15:58:00 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1665, average loss: 1.0919
[09/26 15:58:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:00 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 15:58:07 visual_prompt]: Epoch 93 / 100: avg data time: 6.17e-02, avg batch time: 0.5034, average train loss: 0.0047
[09/26 15:58:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1666, average loss: 1.0920
[09/26 15:58:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:08 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 15:58:15 visual_prompt]: Epoch 94 / 100: avg data time: 5.15e-02, avg batch time: 0.4963, average train loss: 0.0051
[09/26 15:58:17 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.0922
[09/26 15:58:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:17 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 15:58:24 visual_prompt]: Epoch 95 / 100: avg data time: 6.43e-02, avg batch time: 0.5052, average train loss: 0.0049
[09/26 15:58:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1664, average loss: 1.0923
[09/26 15:58:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:25 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 15:58:32 visual_prompt]: Epoch 96 / 100: avg data time: 5.34e-02, avg batch time: 0.4963, average train loss: 0.0049
[09/26 15:58:34 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1664, average loss: 1.0923
[09/26 15:58:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:34 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 15:58:41 visual_prompt]: Epoch 97 / 100: avg data time: 6.34e-02, avg batch time: 0.5049, average train loss: 0.0050
[09/26 15:58:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1662, average loss: 1.0923
[09/26 15:58:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:42 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 15:58:49 visual_prompt]: Epoch 98 / 100: avg data time: 6.56e-02, avg batch time: 0.5067, average train loss: 0.0050
[09/26 15:58:51 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1665, average loss: 1.0923
[09/26 15:58:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:58:51 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 15:58:58 visual_prompt]: Epoch 99 / 100: avg data time: 6.68e-02, avg batch time: 0.5078, average train loss: 0.0051
[09/26 15:59:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.0923
[09/26 15:59:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:59:00 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 15:59:07 visual_prompt]: Epoch 100 / 100: avg data time: 6.28e-02, avg batch time: 0.5042, average train loss: 0.0049
[09/26 15:59:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.0923
[09/26 15:59:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.50	
[09/26 15:59:08 visual_prompt]: Rank of current process: 0. World size: 1
[09/26 15:59:08 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/26 15:59:08 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/26 15:59:08 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/26 15:59:08 visual_prompt]: Training with config:
[09/26 15:59:08 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-resisc45/sup_vitb16_imagenet21k/prompt50/crop224/val/seed0/lr0.05_wd0.0/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-resisc45', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 45, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/26 15:59:08 visual_prompt]: Loading training data...
[09/26 15:59:08 visual_prompt]: Constructing vtab-resisc45 dataset train...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[:800], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:59:09 visual_prompt]: Number of images: 800
[09/26 15:59:09 visual_prompt]: Number of classes: 45 / 45
[09/26 15:59:09 visual_prompt]: Loading validation data...
[09/26 15:59:09 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/26 15:59:10 visual_prompt]: Number of images: 200
[09/26 15:59:10 visual_prompt]: Number of classes: 45 / 45
[09/26 15:59:10 visual_prompt]: Constructing models...
[09/26 15:59:12 visual_prompt]: Total Parameters: 86294061	 Gradient Parameters: 495405
[09/26 15:59:12 visual_prompt]: tuned percent:0.574
[09/26 15:59:12 visual_prompt]: Device used for model: 0
[09/26 15:59:12 visual_prompt]: Setting up Evaluator...
[09/26 15:59:12 visual_prompt]: Setting up Trainer...
[09/26 15:59:12 visual_prompt]: 	Setting up the optimizer...
[09/26 15:59:12 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/26 15:59:19 visual_prompt]: Epoch 1 / 100: avg data time: 5.00e-02, avg batch time: 0.4904, average train loss: 3.8958
[09/26 15:59:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1657, average loss: 3.9529
[09/26 15:59:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 7.00	
[09/26 15:59:21 visual_prompt]: Best epoch 1: best metric: 0.020
[09/26 15:59:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[09/26 15:59:27 visual_prompt]: Epoch 2 / 100: avg data time: 5.64e-02, avg batch time: 0.4973, average train loss: 3.8467
[09/26 15:59:29 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1660, average loss: 3.8522
[09/26 15:59:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 2.00	top5: 9.50	
[09/26 15:59:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[09/26 15:59:36 visual_prompt]: Epoch 3 / 100: avg data time: 5.00e-02, avg batch time: 0.4917, average train loss: 3.7552
[09/26 15:59:37 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1663, average loss: 3.7366
[09/26 15:59:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 5.50	top5: 24.50	
[09/26 15:59:37 visual_prompt]: Best epoch 3: best metric: 0.055
[09/26 15:59:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[09/26 15:59:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.09e-02, avg batch time: 0.4938, average train loss: 3.6209
[09/26 15:59:46 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1663, average loss: 3.4913
[09/26 15:59:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 10.00	top5: 37.00	
[09/26 15:59:46 visual_prompt]: Best epoch 4: best metric: 0.100
[09/26 15:59:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[09/26 15:59:53 visual_prompt]: Epoch 5 / 100: avg data time: 5.02e-02, avg batch time: 0.4919, average train loss: 3.2572
[09/26 15:59:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1661, average loss: 3.0842
[09/26 15:59:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 13.00	top5: 44.50	
[09/26 15:59:54 visual_prompt]: Best epoch 5: best metric: 0.130
[09/26 15:59:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[09/26 16:00:01 visual_prompt]: Epoch 6 / 100: avg data time: 4.74e-02, avg batch time: 0.4891, average train loss: 2.7617
[09/26 16:00:03 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 2.6549
[09/26 16:00:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 25.50	top5: 61.00	
[09/26 16:00:03 visual_prompt]: Best epoch 6: best metric: 0.255
[09/26 16:00:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[09/26 16:00:09 visual_prompt]: Epoch 7 / 100: avg data time: 5.99e-02, avg batch time: 0.5019, average train loss: 2.3717
[09/26 16:00:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1662, average loss: 2.5212
[09/26 16:00:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 32.00	top5: 63.00	
[09/26 16:00:11 visual_prompt]: Best epoch 7: best metric: 0.320
[09/26 16:00:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[09/26 16:00:18 visual_prompt]: Epoch 8 / 100: avg data time: 4.68e-02, avg batch time: 0.4898, average train loss: 2.0427
[09/26 16:00:19 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1662, average loss: 1.9924
[09/26 16:00:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 39.00	top5: 78.00	
[09/26 16:00:19 visual_prompt]: Best epoch 8: best metric: 0.390
[09/26 16:00:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[09/26 16:00:26 visual_prompt]: Epoch 9 / 100: avg data time: 5.12e-02, avg batch time: 0.4957, average train loss: 1.6481
[09/26 16:00:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.7892
[09/26 16:00:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 50.00	top5: 79.00	
[09/26 16:00:28 visual_prompt]: Best epoch 9: best metric: 0.500
[09/26 16:00:28 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[09/26 16:00:35 visual_prompt]: Epoch 10 / 100: avg data time: 5.61e-02, avg batch time: 0.4989, average train loss: 1.3476
[09/26 16:00:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.6472
[09/26 16:00:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 49.50	top5: 85.50	
[09/26 16:00:36 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[09/26 16:00:43 visual_prompt]: Epoch 11 / 100: avg data time: 4.83e-02, avg batch time: 0.4913, average train loss: 1.0704
[09/26 16:00:45 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1663, average loss: 1.5116
[09/26 16:00:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 52.50	top5: 87.00	
[09/26 16:00:45 visual_prompt]: Best epoch 11: best metric: 0.525
[09/26 16:00:45 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[09/26 16:00:51 visual_prompt]: Epoch 12 / 100: avg data time: 5.05e-02, avg batch time: 0.4942, average train loss: 0.8858
[09/26 16:00:53 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1663, average loss: 1.2433
[09/26 16:00:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.50	top5: 89.00	
[09/26 16:00:53 visual_prompt]: Best epoch 12: best metric: 0.645
[09/26 16:00:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[09/26 16:01:00 visual_prompt]: Epoch 13 / 100: avg data time: 5.66e-02, avg batch time: 0.4984, average train loss: 0.6798
[09/26 16:01:01 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1662, average loss: 1.2701
[09/26 16:01:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 61.50	top5: 92.50	
[09/26 16:01:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[09/26 16:01:08 visual_prompt]: Epoch 14 / 100: avg data time: 5.26e-02, avg batch time: 0.4953, average train loss: 0.4976
[09/26 16:01:10 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1663, average loss: 1.1701
[09/26 16:01:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 91.50	
[09/26 16:01:10 visual_prompt]: Best epoch 14: best metric: 0.665
[09/26 16:01:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[09/26 16:01:17 visual_prompt]: Epoch 15 / 100: avg data time: 4.76e-02, avg batch time: 0.4910, average train loss: 0.3936
[09/26 16:01:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1663, average loss: 1.2162
[09/26 16:01:18 visual_prompt]: Classification results with val_vtab-resisc45: top1: 64.00	top5: 90.50	
[09/26 16:01:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[09/26 16:01:25 visual_prompt]: Epoch 16 / 100: avg data time: 5.62e-02, avg batch time: 0.4985, average train loss: 0.2794
[09/26 16:01:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.2253
[09/26 16:01:27 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.00	top5: 92.50	
[09/26 16:01:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[09/26 16:01:34 visual_prompt]: Epoch 17 / 100: avg data time: 5.28e-02, avg batch time: 0.4967, average train loss: 0.2686
[09/26 16:01:35 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1663, average loss: 1.2013
[09/26 16:01:35 visual_prompt]: Classification results with val_vtab-resisc45: top1: 65.50	top5: 91.50	
[09/26 16:01:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[09/26 16:01:42 visual_prompt]: Epoch 18 / 100: avg data time: 4.90e-02, avg batch time: 0.4907, average train loss: 0.2077
[09/26 16:01:44 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.0736
[09/26 16:01:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 66.50	top5: 93.50	
[09/26 16:01:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[09/26 16:01:51 visual_prompt]: Epoch 19 / 100: avg data time: 5.22e-02, avg batch time: 0.4939, average train loss: 0.1539
[09/26 16:01:52 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.1060
[09/26 16:01:52 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.00	
[09/26 16:01:52 visual_prompt]: Best epoch 19: best metric: 0.705
[09/26 16:01:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[09/26 16:01:59 visual_prompt]: Epoch 20 / 100: avg data time: 5.11e-02, avg batch time: 0.4925, average train loss: 0.1017
[09/26 16:02:00 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1666, average loss: 1.1240
[09/26 16:02:00 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.50	top5: 92.00	
[09/26 16:02:00 visual_prompt]: Best epoch 20: best metric: 0.735
[09/26 16:02:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[09/26 16:02:07 visual_prompt]: Epoch 21 / 100: avg data time: 4.91e-02, avg batch time: 0.4923, average train loss: 0.0654
[09/26 16:02:09 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1664, average loss: 1.0519
[09/26 16:02:09 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 93.00	
[09/26 16:02:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[09/26 16:02:16 visual_prompt]: Epoch 22 / 100: avg data time: 4.93e-02, avg batch time: 0.4922, average train loss: 0.0452
[09/26 16:02:17 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 1.0516
[09/26 16:02:17 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 92.50	
[09/26 16:02:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[09/26 16:02:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.21e-02, avg batch time: 0.4945, average train loss: 0.0440
[09/26 16:02:26 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1661, average loss: 1.0824
[09/26 16:02:26 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 92.50	
[09/26 16:02:26 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[09/26 16:02:33 visual_prompt]: Epoch 24 / 100: avg data time: 5.18e-02, avg batch time: 0.4986, average train loss: 0.0406
[09/26 16:02:34 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1664, average loss: 1.1353
[09/26 16:02:34 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.50	top5: 94.00	
[09/26 16:02:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[09/26 16:02:41 visual_prompt]: Epoch 25 / 100: avg data time: 4.83e-02, avg batch time: 0.4917, average train loss: 0.0348
[09/26 16:02:43 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1664, average loss: 1.0702
[09/26 16:02:43 visual_prompt]: Classification results with val_vtab-resisc45: top1: 67.50	top5: 94.00	
[09/26 16:02:43 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[09/26 16:02:49 visual_prompt]: Epoch 26 / 100: avg data time: 5.57e-02, avg batch time: 0.4983, average train loss: 0.0258
[09/26 16:02:51 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1662, average loss: 1.0691
[09/26 16:02:51 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 16:02:51 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[09/26 16:02:58 visual_prompt]: Epoch 27 / 100: avg data time: 4.87e-02, avg batch time: 0.4922, average train loss: 0.0224
[09/26 16:02:59 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 1.1028
[09/26 16:02:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 69.00	top5: 95.00	
[09/26 16:02:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[09/26 16:03:06 visual_prompt]: Epoch 28 / 100: avg data time: 5.70e-02, avg batch time: 0.4998, average train loss: 0.0199
[09/26 16:03:08 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1663, average loss: 1.0601
[09/26 16:03:08 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 16:03:08 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[09/26 16:03:15 visual_prompt]: Epoch 29 / 100: avg data time: 5.26e-02, avg batch time: 0.4976, average train loss: 0.0173
[09/26 16:03:16 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.0578
[09/26 16:03:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 16:03:16 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[09/26 16:03:23 visual_prompt]: Epoch 30 / 100: avg data time: 6.92e-02, avg batch time: 0.5107, average train loss: 0.0151
[09/26 16:03:25 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.0360
[09/26 16:03:25 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 95.00	
[09/26 16:03:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[09/26 16:03:32 visual_prompt]: Epoch 31 / 100: avg data time: 4.97e-02, avg batch time: 0.4914, average train loss: 0.0154
[09/26 16:03:33 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1663, average loss: 1.0495
[09/26 16:03:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.00	
[09/26 16:03:33 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[09/26 16:03:40 visual_prompt]: Epoch 32 / 100: avg data time: 6.07e-02, avg batch time: 0.5021, average train loss: 0.0130
[09/26 16:03:42 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1662, average loss: 1.0381
[09/26 16:03:42 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 16:03:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[09/26 16:03:49 visual_prompt]: Epoch 33 / 100: avg data time: 5.28e-02, avg batch time: 0.4955, average train loss: 0.0129
[09/26 16:03:50 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1662, average loss: 1.0330
[09/26 16:03:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.00	
[09/26 16:03:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[09/26 16:03:57 visual_prompt]: Epoch 34 / 100: avg data time: 5.19e-02, avg batch time: 0.4946, average train loss: 0.0108
[09/26 16:03:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1661, average loss: 1.0458
[09/26 16:03:59 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 16:03:59 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[09/26 16:04:06 visual_prompt]: Epoch 35 / 100: avg data time: 5.70e-02, avg batch time: 0.5016, average train loss: 0.0118
[09/26 16:04:07 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1664, average loss: 1.0222
[09/26 16:04:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 16:04:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[09/26 16:04:14 visual_prompt]: Epoch 36 / 100: avg data time: 6.13e-02, avg batch time: 0.5036, average train loss: 0.0107
[09/26 16:04:16 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1663, average loss: 1.0406
[09/26 16:04:16 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.00	
[09/26 16:04:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[09/26 16:04:22 visual_prompt]: Epoch 37 / 100: avg data time: 4.91e-02, avg batch time: 0.4918, average train loss: 0.0109
[09/26 16:04:24 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1664, average loss: 1.0256
[09/26 16:04:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 73.00	top5: 93.50	
[09/26 16:04:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[09/26 16:04:31 visual_prompt]: Epoch 38 / 100: avg data time: 6.77e-02, avg batch time: 0.5093, average train loss: 0.0093
[09/26 16:04:33 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1664, average loss: 1.0183
[09/26 16:04:33 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.50	
[09/26 16:04:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[09/26 16:04:40 visual_prompt]: Epoch 39 / 100: avg data time: 4.98e-02, avg batch time: 0.4941, average train loss: 0.0094
[09/26 16:04:41 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1664, average loss: 1.0295
[09/26 16:04:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 16:04:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[09/26 16:04:48 visual_prompt]: Epoch 40 / 100: avg data time: 4.86e-02, avg batch time: 0.4913, average train loss: 0.0090
[09/26 16:04:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1664, average loss: 1.0440
[09/26 16:04:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 16:04:50 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[09/26 16:04:57 visual_prompt]: Epoch 41 / 100: avg data time: 6.51e-02, avg batch time: 0.5080, average train loss: 0.0086
[09/26 16:04:58 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1664, average loss: 1.0440
[09/26 16:04:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.50	
[09/26 16:04:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[09/26 16:05:05 visual_prompt]: Epoch 42 / 100: avg data time: 5.44e-02, avg batch time: 0.4971, average train loss: 0.0086
[09/26 16:05:07 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1665, average loss: 1.0365
[09/26 16:05:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.50	
[09/26 16:05:07 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[09/26 16:05:14 visual_prompt]: Epoch 43 / 100: avg data time: 6.01e-02, avg batch time: 0.5020, average train loss: 0.0078
[09/26 16:05:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1667, average loss: 1.0453
[09/26 16:05:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 93.50	
[09/26 16:05:15 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[09/26 16:05:22 visual_prompt]: Epoch 44 / 100: avg data time: 5.33e-02, avg batch time: 0.4958, average train loss: 0.0076
[09/26 16:05:24 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1665, average loss: 1.0497
[09/26 16:05:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:05:24 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[09/26 16:05:31 visual_prompt]: Epoch 45 / 100: avg data time: 5.07e-02, avg batch time: 0.4957, average train loss: 0.0078
[09/26 16:05:32 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1665, average loss: 1.0505
[09/26 16:05:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:05:32 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[09/26 16:05:39 visual_prompt]: Epoch 46 / 100: avg data time: 5.62e-02, avg batch time: 0.5002, average train loss: 0.0072
[09/26 16:05:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.0437
[09/26 16:05:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:05:41 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[09/26 16:05:48 visual_prompt]: Epoch 47 / 100: avg data time: 5.97e-02, avg batch time: 0.5015, average train loss: 0.0066
[09/26 16:05:50 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1664, average loss: 1.0456
[09/26 16:05:50 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:05:50 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[09/26 16:05:56 visual_prompt]: Epoch 48 / 100: avg data time: 5.83e-02, avg batch time: 0.5014, average train loss: 0.0072
[09/26 16:05:58 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1662, average loss: 1.0600
[09/26 16:05:58 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 16:05:58 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[09/26 16:06:05 visual_prompt]: Epoch 49 / 100: avg data time: 5.43e-02, avg batch time: 0.4982, average train loss: 0.0065
[09/26 16:06:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.0577
[09/26 16:06:07 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 93.50	
[09/26 16:06:07 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[09/26 16:06:13 visual_prompt]: Epoch 50 / 100: avg data time: 5.15e-02, avg batch time: 0.4943, average train loss: 0.0062
[09/26 16:06:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1664, average loss: 1.0558
[09/26 16:06:15 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 16:06:15 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[09/26 16:06:22 visual_prompt]: Epoch 51 / 100: avg data time: 6.20e-02, avg batch time: 0.5051, average train loss: 0.0065
[09/26 16:06:24 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.0509
[09/26 16:06:24 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 16:06:24 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[09/26 16:06:30 visual_prompt]: Epoch 52 / 100: avg data time: 5.91e-02, avg batch time: 0.5019, average train loss: 0.0060
[09/26 16:06:32 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 1.0514
[09/26 16:06:32 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:06:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[09/26 16:06:39 visual_prompt]: Epoch 53 / 100: avg data time: 5.17e-02, avg batch time: 0.4953, average train loss: 0.0062
[09/26 16:06:41 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1661, average loss: 1.0523
[09/26 16:06:41 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.00	
[09/26 16:06:41 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[09/26 16:06:47 visual_prompt]: Epoch 54 / 100: avg data time: 5.11e-02, avg batch time: 0.4954, average train loss: 0.0061
[09/26 16:06:49 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1662, average loss: 1.0461
[09/26 16:06:49 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.00	top5: 94.50	
[09/26 16:06:49 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[09/26 16:06:56 visual_prompt]: Epoch 55 / 100: avg data time: 5.07e-02, avg batch time: 0.4934, average train loss: 0.0059
[09/26 16:06:57 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.0457
[09/26 16:06:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 16:06:57 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[09/26 16:07:04 visual_prompt]: Epoch 56 / 100: avg data time: 5.31e-02, avg batch time: 0.4957, average train loss: 0.0055
[09/26 16:07:06 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1662, average loss: 1.0426
[09/26 16:07:06 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.50	
[09/26 16:07:06 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[09/26 16:07:13 visual_prompt]: Epoch 57 / 100: avg data time: 5.91e-02, avg batch time: 0.5018, average train loss: 0.0061
[09/26 16:07:14 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1663, average loss: 1.0477
[09/26 16:07:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:07:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[09/26 16:07:21 visual_prompt]: Epoch 58 / 100: avg data time: 5.35e-02, avg batch time: 0.4969, average train loss: 0.0062
[09/26 16:07:23 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1662, average loss: 1.0523
[09/26 16:07:23 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.00	
[09/26 16:07:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[09/26 16:07:30 visual_prompt]: Epoch 59 / 100: avg data time: 6.30e-02, avg batch time: 0.5057, average train loss: 0.0061
[09/26 16:07:31 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1662, average loss: 1.0509
[09/26 16:07:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 94.00	
[09/26 16:07:31 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[09/26 16:07:38 visual_prompt]: Epoch 60 / 100: avg data time: 5.20e-02, avg batch time: 0.4940, average train loss: 0.0056
[09/26 16:07:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1663, average loss: 1.0500
[09/26 16:07:40 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 94.50	
[09/26 16:07:40 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[09/26 16:07:47 visual_prompt]: Epoch 61 / 100: avg data time: 5.93e-02, avg batch time: 0.5019, average train loss: 0.0058
[09/26 16:07:48 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1664, average loss: 1.0503
[09/26 16:07:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 16:07:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.019802207729556022
[09/26 16:07:55 visual_prompt]: Epoch 62 / 100: avg data time: 5.10e-02, avg batch time: 0.4941, average train loss: 0.0055
[09/26 16:07:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1664, average loss: 1.0523
[09/26 16:07:57 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.50	
[09/26 16:07:57 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.018951952610008312
[09/26 16:08:04 visual_prompt]: Epoch 63 / 100: avg data time: 4.88e-02, avg batch time: 0.4934, average train loss: 0.0054
[09/26 16:08:05 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1663, average loss: 1.0494
[09/26 16:08:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:08:05 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.018109066104575022
[09/26 16:08:12 visual_prompt]: Epoch 64 / 100: avg data time: 4.66e-02, avg batch time: 0.4923, average train loss: 0.0052
[09/26 16:08:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1664, average loss: 1.0504
[09/26 16:08:14 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:08:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.017274575140626316
[09/26 16:08:21 visual_prompt]: Epoch 65 / 100: avg data time: 5.84e-02, avg batch time: 0.5009, average train loss: 0.0057
[09/26 16:08:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.0541
[09/26 16:08:22 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:08:22 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.016449496416858285
[09/26 16:08:29 visual_prompt]: Epoch 66 / 100: avg data time: 4.62e-02, avg batch time: 0.4879, average train loss: 0.0049
[09/26 16:08:31 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1663, average loss: 1.0599
[09/26 16:08:31 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:08:31 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.0156348351646022
[09/26 16:08:37 visual_prompt]: Epoch 67 / 100: avg data time: 4.68e-02, avg batch time: 0.4909, average train loss: 0.0051
[09/26 16:08:39 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1661, average loss: 1.0604
[09/26 16:08:39 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:08:39 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.014831583923105
[09/26 16:08:46 visual_prompt]: Epoch 68 / 100: avg data time: 6.57e-02, avg batch time: 0.5071, average train loss: 0.0052
[09/26 16:08:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 1.0597
[09/26 16:08:48 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:08:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.014040721330273063
[09/26 16:08:54 visual_prompt]: Epoch 69 / 100: avg data time: 5.50e-02, avg batch time: 0.4973, average train loss: 0.0049
[09/26 16:08:56 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1663, average loss: 1.0598
[09/26 16:08:56 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:08:56 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.013263210930352737
[09/26 16:09:03 visual_prompt]: Epoch 70 / 100: avg data time: 5.90e-02, avg batch time: 0.5010, average train loss: 0.0052
[09/26 16:09:05 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1664, average loss: 1.0558
[09/26 16:09:05 visual_prompt]: Classification results with val_vtab-resisc45: top1: 70.50	top5: 94.00	
[09/26 16:09:05 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.012500000000000006
[09/26 16:09:11 visual_prompt]: Epoch 71 / 100: avg data time: 5.07e-02, avg batch time: 0.4943, average train loss: 0.0046
[09/26 16:09:13 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1663, average loss: 1.0554
[09/26 16:09:13 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 16:09:13 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.01175201839416988
[09/26 16:09:20 visual_prompt]: Epoch 72 / 100: avg data time: 5.05e-02, avg batch time: 0.4957, average train loss: 0.0048
[09/26 16:09:21 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1664, average loss: 1.0569
[09/26 16:09:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 16:09:21 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.011020177413231334
[09/26 16:09:28 visual_prompt]: Epoch 73 / 100: avg data time: 5.10e-02, avg batch time: 0.4934, average train loss: 0.0051
[09/26 16:09:30 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.0589
[09/26 16:09:30 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:09:30 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.010305368692688175
[09/26 16:09:37 visual_prompt]: Epoch 74 / 100: avg data time: 5.54e-02, avg batch time: 0.4979, average train loss: 0.0049
[09/26 16:09:38 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1664, average loss: 1.0620
[09/26 16:09:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:09:38 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.009608463116858543
[09/26 16:09:45 visual_prompt]: Epoch 75 / 100: avg data time: 5.99e-02, avg batch time: 0.5031, average train loss: 0.0051
[09/26 16:09:47 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1665, average loss: 1.0621
[09/26 16:09:47 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 94.00	
[09/26 16:09:47 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.008930309757836517
[09/26 16:09:54 visual_prompt]: Epoch 76 / 100: avg data time: 4.95e-02, avg batch time: 0.4936, average train loss: 0.0047
[09/26 16:09:55 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.0637
[09/26 16:09:55 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.00	top5: 93.50	
[09/26 16:09:55 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.008271734841028553
[09/26 16:10:02 visual_prompt]: Epoch 77 / 100: avg data time: 6.20e-02, avg batch time: 0.5048, average train loss: 0.0050
[09/26 16:10:04 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1663, average loss: 1.0656
[09/26 16:10:04 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:10:04 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.007633540738525066
[09/26 16:10:11 visual_prompt]: Epoch 78 / 100: avg data time: 6.81e-02, avg batch time: 0.5115, average train loss: 0.0050
[09/26 16:10:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.0672
[09/26 16:10:12 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:10:12 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.0070165049915337264
[09/26 16:10:19 visual_prompt]: Epoch 79 / 100: avg data time: 5.00e-02, avg batch time: 0.4914, average train loss: 0.0047
[09/26 16:10:21 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1667, average loss: 1.0683
[09/26 16:10:21 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:10:21 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.006421379363065142
[09/26 16:10:28 visual_prompt]: Epoch 80 / 100: avg data time: 5.69e-02, avg batch time: 0.4991, average train loss: 0.0050
[09/26 16:10:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.0684
[09/26 16:10:29 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:10:29 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.005848888922025553
[09/26 16:10:36 visual_prompt]: Epoch 81 / 100: avg data time: 5.75e-02, avg batch time: 0.5005, average train loss: 0.0043
[09/26 16:10:38 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1663, average loss: 1.0679
[09/26 16:10:38 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.50	top5: 93.50	
[09/26 16:10:38 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.005299731159831953
[09/26 16:10:44 visual_prompt]: Epoch 82 / 100: avg data time: 5.14e-02, avg batch time: 0.4960, average train loss: 0.0045
[09/26 16:10:46 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1690, average loss: 1.0668
[09/26 16:10:46 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:10:46 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.004774575140626317
[09/26 16:10:53 visual_prompt]: Epoch 83 / 100: avg data time: 4.87e-02, avg batch time: 0.4914, average train loss: 0.0046
[09/26 16:10:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.0653
[09/26 16:10:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:10:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.004274060686123959
[09/26 16:11:01 visual_prompt]: Epoch 84 / 100: avg data time: 5.93e-02, avg batch time: 0.5024, average train loss: 0.0045
[09/26 16:11:03 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1665, average loss: 1.0640
[09/26 16:11:03 visual_prompt]: Classification results with val_vtab-resisc45: top1: 71.50	top5: 93.50	
[09/26 16:11:03 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.003798797596089351
[09/26 16:11:10 visual_prompt]: Epoch 85 / 100: avg data time: 5.25e-02, avg batch time: 0.4950, average train loss: 0.0046
[09/26 16:11:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1664, average loss: 1.0635
[09/26 16:11:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:11 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.0033493649053890325
[09/26 16:11:18 visual_prompt]: Epoch 86 / 100: avg data time: 5.72e-02, avg batch time: 0.4996, average train loss: 0.0046
[09/26 16:11:20 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.0638
[09/26 16:11:20 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:20 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.0029263101785268254
[09/26 16:11:27 visual_prompt]: Epoch 87 / 100: avg data time: 5.12e-02, avg batch time: 0.4959, average train loss: 0.0046
[09/26 16:11:28 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1665, average loss: 1.0643
[09/26 16:11:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:28 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.00253014884252083
[09/26 16:11:35 visual_prompt]: Epoch 88 / 100: avg data time: 5.25e-02, avg batch time: 0.4953, average train loss: 0.0048
[09/26 16:11:37 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.0649
[09/26 16:11:37 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.0021613635589349755
[09/26 16:11:44 visual_prompt]: Epoch 89 / 100: avg data time: 6.13e-02, avg batch time: 0.5031, average train loss: 0.0045
[09/26 16:11:45 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1662, average loss: 1.0648
[09/26 16:11:45 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:45 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.0018204036358303172
[09/26 16:11:52 visual_prompt]: Epoch 90 / 100: avg data time: 5.98e-02, avg batch time: 0.5008, average train loss: 0.0046
[09/26 16:11:54 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1663, average loss: 1.0645
[09/26 16:11:54 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:11:54 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0015076844803522923
[09/26 16:12:01 visual_prompt]: Epoch 91 / 100: avg data time: 4.94e-02, avg batch time: 0.4933, average train loss: 0.0052
[09/26 16:12:02 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1663, average loss: 1.0648
[09/26 16:12:02 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:02 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.0012235870926211618
[09/26 16:12:09 visual_prompt]: Epoch 92 / 100: avg data time: 5.19e-02, avg batch time: 0.4944, average train loss: 0.0045
[09/26 16:12:11 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1663, average loss: 1.0647
[09/26 16:12:11 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:11 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.0009684576015420277
[09/26 16:12:18 visual_prompt]: Epoch 93 / 100: avg data time: 5.90e-02, avg batch time: 0.5012, average train loss: 0.0050
[09/26 16:12:19 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1664, average loss: 1.0644
[09/26 16:12:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:19 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.0007426068431000883
[09/26 16:12:26 visual_prompt]: Epoch 94 / 100: avg data time: 4.85e-02, avg batch time: 0.4903, average train loss: 0.0047
[09/26 16:12:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1663, average loss: 1.0642
[09/26 16:12:28 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:28 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.0005463099816548578
[09/26 16:12:34 visual_prompt]: Epoch 95 / 100: avg data time: 5.34e-02, avg batch time: 0.4972, average train loss: 0.0046
[09/26 16:12:36 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1662, average loss: 1.0642
[09/26 16:12:36 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:36 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00037980617469479954
[09/26 16:12:43 visual_prompt]: Epoch 96 / 100: avg data time: 5.35e-02, avg batch time: 0.4952, average train loss: 0.0048
[09/26 16:12:44 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1663, average loss: 1.0641
[09/26 16:12:44 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:44 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.00024329828146074097
[09/26 16:12:51 visual_prompt]: Epoch 97 / 100: avg data time: 5.26e-02, avg batch time: 0.4975, average train loss: 0.0049
[09/26 16:12:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1663, average loss: 1.0641
[09/26 16:12:53 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:12:53 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.00013695261579316776
[09/26 16:13:00 visual_prompt]: Epoch 98 / 100: avg data time: 5.41e-02, avg batch time: 0.4962, average train loss: 0.0043
[09/26 16:13:01 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1664, average loss: 1.0640
[09/26 16:13:01 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:13:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 6.089874350439506e-05
[09/26 16:13:08 visual_prompt]: Epoch 99 / 100: avg data time: 5.91e-02, avg batch time: 0.5013, average train loss: 0.0049
[09/26 16:13:10 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1661, average loss: 1.0640
[09/26 16:13:10 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
[09/26 16:13:10 visual_prompt]: Training 100 / 100 epoch, with learning rate 1.5229324522605948e-05
[09/26 16:13:17 visual_prompt]: Epoch 100 / 100: avg data time: 5.81e-02, avg batch time: 0.5018, average train loss: 0.0044
[09/26 16:13:19 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1662, average loss: 1.0640
[09/26 16:13:19 visual_prompt]: Classification results with val_vtab-resisc45: top1: 72.00	top5: 93.50	
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 289, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 284, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 113, in train
    seed(cfg)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_vtab.py", line 136, in seed
    torch.manual_seed(SEED)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/torch/random.py", line 36, in manual_seed
    seed = int(seed)
           ^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'tuple'
