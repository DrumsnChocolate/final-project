/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/30 20:49:49 visual_prompt]: Rank of current process: 0. World size: 1
[09/30 20:49:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/30 20:49:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/30 20:49:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/30 20:49:53 visual_prompt]: Training with config:
[09/30 20:49:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dmlab/sup_vitb16_imagenet21k/prompt50/crop224/test/seed9805/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dmlab', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 6, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/30 20:49:53 visual_prompt]: Loading training data...
2023-09-30 20:49:55.527763: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-30 20:49:58.887424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-30 20:50:19.861149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/30 20:51:07 visual_prompt]: Constructing vtab-dmlab dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 20:51:14 visual_prompt]: Number of images: 1000
[09/30 20:51:14 visual_prompt]: Number of classes: 6 / 6
[09/30 20:51:14 visual_prompt]: Loading validation data...
[09/30 20:51:14 visual_prompt]: Constructing vtab-dmlab dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 20:51:15 visual_prompt]: Number of images: 200
[09/30 20:51:15 visual_prompt]: Number of classes: 6 / 6
[09/30 20:51:15 visual_prompt]: Loading test data...
[09/30 20:51:15 visual_prompt]: Constructing vtab-dmlab dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split test, from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 20:52:22 visual_prompt]: Number of images: 22735
[09/30 20:52:22 visual_prompt]: Number of classes: 6 / 6
[09/30 20:52:22 visual_prompt]: Constructing models...
[09/30 20:52:25 visual_prompt]: Total Parameters: 86264070	 Gradient Parameters: 465414
[09/30 20:52:25 visual_prompt]: tuned percent:0.540
[09/30 20:52:43 visual_prompt]: Device used for model: 0
[09/30 20:52:43 visual_prompt]: Setting up Evaluator...
[09/30 20:52:43 visual_prompt]: Setting up Trainer...
[09/30 20:52:43 visual_prompt]: 	Setting up the optimizer...
[09/30 20:52:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/30 20:53:16 visual_prompt]: Epoch 1 / 100: avg data time: 2.89e-01, avg batch time: 1.9477, average train loss: 3.9087
[09/30 20:53:20 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.3403, average loss: 4.1446
[09/30 20:53:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 83.50	
[09/30 20:53:43 visual_prompt]: 	Test 100/356. loss: 3.801, 0.2167 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 20:54:05 visual_prompt]: 	Test 200/356. loss: 3.977, 0.2195 s / batch. (data: 2.81e-05)max mem: 7.80404 GB 
[09/30 20:54:27 visual_prompt]: 	Test 300/356. loss: 3.833, 0.2217 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 20:54:41 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2184, average loss: 3.9739
[09/30 20:54:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 87.97	
[09/30 20:54:41 visual_prompt]: Best epoch 1: best metric: 0.145
[09/30 20:54:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/30 20:54:51 visual_prompt]: Epoch 2 / 100: avg data time: 1.01e-01, avg batch time: 0.5618, average train loss: 4.1669
[09/30 20:54:55 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1705, average loss: 3.7951
[09/30 20:54:55 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[09/30 20:55:18 visual_prompt]: 	Test 100/356. loss: 4.564, 0.2175 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 20:55:40 visual_prompt]: 	Test 200/356. loss: 3.097, 0.2178 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 20:56:02 visual_prompt]: 	Test 300/356. loss: 4.302, 0.2184 s / batch. (data: 8.37e-05)max mem: 7.80404 GB 
[09/30 20:56:15 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2180, average loss: 3.8351
[09/30 20:56:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.67	
[09/30 20:56:15 visual_prompt]: Best epoch 2: best metric: 0.155
[09/30 20:56:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/30 20:56:26 visual_prompt]: Epoch 3 / 100: avg data time: 1.05e-01, avg batch time: 0.5600, average train loss: 2.5929
[09/30 20:56:29 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1683, average loss: 1.8694
[09/30 20:56:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.50	top5: 85.50	
[09/30 20:56:52 visual_prompt]: 	Test 100/356. loss: 1.935, 0.2155 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 20:57:14 visual_prompt]: 	Test 200/356. loss: 1.737, 0.2153 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 20:57:35 visual_prompt]: 	Test 300/356. loss: 1.856, 0.2150 s / batch. (data: 2.96e-05)max mem: 7.80404 GB 
[09/30 20:57:49 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2149, average loss: 1.8456
[09/30 20:57:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 20.70	top5: 84.68	
[09/30 20:57:49 visual_prompt]: Best epoch 3: best metric: 0.215
[09/30 20:57:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/30 20:57:59 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e-01, avg batch time: 0.5551, average train loss: 1.8905
[09/30 20:58:02 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1668, average loss: 1.8145
[09/30 20:58:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 85.50	
[09/30 20:58:25 visual_prompt]: 	Test 100/356. loss: 1.834, 0.2141 s / batch. (data: 7.06e-05)max mem: 7.80404 GB 
[09/30 20:58:47 visual_prompt]: 	Test 200/356. loss: 1.813, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 20:59:08 visual_prompt]: 	Test 300/356. loss: 1.847, 0.2148 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 20:59:22 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2138, average loss: 1.8205
[09/30 20:59:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 14.60	top5: 84.67	
[09/30 20:59:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/30 20:59:32 visual_prompt]: Epoch 5 / 100: avg data time: 9.64e-02, avg batch time: 0.5462, average train loss: 1.8284
[09/30 20:59:35 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1667, average loss: 1.8017
[09/30 20:59:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.50	top5: 85.50	
[09/30 20:59:58 visual_prompt]: 	Test 100/356. loss: 1.815, 0.2134 s / batch. (data: 3.22e-05)max mem: 7.80404 GB 
[09/30 21:00:20 visual_prompt]: 	Test 200/356. loss: 1.730, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 21:00:41 visual_prompt]: 	Test 300/356. loss: 1.762, 0.2150 s / batch. (data: 2.81e-05)max mem: 7.80404 GB 
[09/30 21:00:54 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2137, average loss: 1.7776
[09/30 21:00:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.88	top5: 84.28	
[09/30 21:00:55 visual_prompt]: Best epoch 5: best metric: 0.255
[09/30 21:00:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/30 21:01:05 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e-01, avg batch time: 0.5558, average train loss: 1.8168
[09/30 21:01:08 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1667, average loss: 1.8474
[09/30 21:01:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 90.00	
[09/30 21:01:31 visual_prompt]: 	Test 100/356. loss: 1.802, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 21:01:53 visual_prompt]: 	Test 200/356. loss: 1.744, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:02:14 visual_prompt]: 	Test 300/356. loss: 1.758, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:02:27 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2137, average loss: 1.7929
[09/30 21:02:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.42	top5: 90.42	
[09/30 21:02:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/30 21:02:38 visual_prompt]: Epoch 7 / 100: avg data time: 1.09e-01, avg batch time: 0.5586, average train loss: 1.7856
[09/30 21:02:41 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1666, average loss: 1.7275
[09/30 21:02:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 89.50	
[09/30 21:03:04 visual_prompt]: 	Test 100/356. loss: 1.693, 0.2137 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 21:03:25 visual_prompt]: 	Test 200/356. loss: 1.824, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 21:03:47 visual_prompt]: 	Test 300/356. loss: 1.691, 0.2145 s / batch. (data: 2.31e-05)max mem: 7.80404 GB 
[09/30 21:04:00 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2136, average loss: 1.7278
[09/30 21:04:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.25	top5: 89.28	
[09/30 21:04:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/30 21:04:10 visual_prompt]: Epoch 8 / 100: avg data time: 1.05e-01, avg batch time: 0.5533, average train loss: 1.6811
[09/30 21:04:14 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1667, average loss: 2.1412
[09/30 21:04:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 87.00	
[09/30 21:04:37 visual_prompt]: 	Test 100/356. loss: 2.058, 0.2136 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:04:58 visual_prompt]: 	Test 200/356. loss: 1.933, 0.2145 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 21:05:20 visual_prompt]: 	Test 300/356. loss: 2.153, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:05:33 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2138, average loss: 2.0547
[09/30 21:05:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 87.47	
[09/30 21:05:33 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/30 21:05:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e-01, avg batch time: 0.5545, average train loss: 1.8819
[09/30 21:05:47 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1667, average loss: 1.7367
[09/30 21:05:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 19.50	top5: 94.00	
[09/30 21:06:10 visual_prompt]: 	Test 100/356. loss: 1.716, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 21:06:31 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2141 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:06:53 visual_prompt]: 	Test 300/356. loss: 1.596, 0.2144 s / batch. (data: 2.96e-05)max mem: 7.80404 GB 
[09/30 21:07:06 visual_prompt]: Inference (test):avg data time: 1.10e-04, avg batch time: 0.2137, average loss: 1.6871
[09/30 21:07:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 24.96	top5: 93.22	
[09/30 21:07:06 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/30 21:07:16 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e-01, avg batch time: 0.5612, average train loss: 1.8123
[09/30 21:07:20 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1667, average loss: 1.9829
[09/30 21:07:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 83.50	
[09/30 21:07:43 visual_prompt]: 	Test 100/356. loss: 1.902, 0.2137 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:08:04 visual_prompt]: 	Test 200/356. loss: 1.690, 0.2141 s / batch. (data: 2.41e-05)max mem: 7.80404 GB 
[09/30 21:08:26 visual_prompt]: 	Test 300/356. loss: 1.824, 0.2146 s / batch. (data: 2.38e-05)max mem: 7.80404 GB 
[09/30 21:08:39 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2137, average loss: 1.8675
[09/30 21:08:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 86.52	
[09/30 21:08:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/30 21:08:49 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e-01, avg batch time: 0.5542, average train loss: 1.8723
[09/30 21:08:53 visual_prompt]: Inference (val):avg data time: 1.89e-05, avg batch time: 0.1667, average loss: 1.9585
[09/30 21:08:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[09/30 21:09:16 visual_prompt]: 	Test 100/356. loss: 1.928, 0.2135 s / batch. (data: 2.41e-05)max mem: 7.80404 GB 
[09/30 21:09:37 visual_prompt]: 	Test 200/356. loss: 1.773, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:09:59 visual_prompt]: 	Test 300/356. loss: 1.937, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:10:12 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2136, average loss: 1.9004
[09/30 21:10:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.67	
[09/30 21:10:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/30 21:10:22 visual_prompt]: Epoch 12 / 100: avg data time: 9.92e-02, avg batch time: 0.5494, average train loss: 2.0391
[09/30 21:10:25 visual_prompt]: Inference (val):avg data time: 1.61e-05, avg batch time: 0.1662, average loss: 2.0283
[09/30 21:10:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 82.50	
[09/30 21:10:49 visual_prompt]: 	Test 100/356. loss: 1.951, 0.2134 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 21:11:10 visual_prompt]: 	Test 200/356. loss: 1.784, 0.2135 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:11:31 visual_prompt]: 	Test 300/356. loss: 1.848, 0.2137 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:11:45 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2132, average loss: 1.9239
[09/30 21:11:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 82.27	
[09/30 21:11:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/30 21:11:55 visual_prompt]: Epoch 13 / 100: avg data time: 1.03e-01, avg batch time: 0.5531, average train loss: 1.9465
[09/30 21:11:59 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1661, average loss: 1.9070
[09/30 21:11:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.50	
[09/30 21:12:21 visual_prompt]: 	Test 100/356. loss: 1.904, 0.2136 s / batch. (data: 2.46e-05)max mem: 7.80404 GB 
[09/30 21:12:43 visual_prompt]: 	Test 200/356. loss: 2.073, 0.2135 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:13:04 visual_prompt]: 	Test 300/356. loss: 1.953, 0.2137 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:13:18 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2132, average loss: 1.9511
[09/30 21:13:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 77.81	
[09/30 21:13:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/30 21:13:28 visual_prompt]: Epoch 14 / 100: avg data time: 1.09e-01, avg batch time: 0.5576, average train loss: 1.8770
[09/30 21:13:31 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1663, average loss: 1.9353
[09/30 21:13:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[09/30 21:13:54 visual_prompt]: 	Test 100/356. loss: 1.891, 0.2140 s / batch. (data: 2.38e-05)max mem: 7.80404 GB 
[09/30 21:14:16 visual_prompt]: 	Test 200/356. loss: 1.707, 0.2139 s / batch. (data: 3.12e-05)max mem: 7.80404 GB 
[09/30 21:14:37 visual_prompt]: 	Test 300/356. loss: 1.863, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 21:14:51 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2133, average loss: 1.8508
[09/30 21:14:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.67	
[09/30 21:14:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/30 21:15:01 visual_prompt]: Epoch 15 / 100: avg data time: 9.76e-02, avg batch time: 0.5476, average train loss: 2.0258
[09/30 21:15:04 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1664, average loss: 1.9765
[09/30 21:15:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.50	
[09/30 21:15:27 visual_prompt]: 	Test 100/356. loss: 2.007, 0.2132 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 21:15:48 visual_prompt]: 	Test 200/356. loss: 2.133, 0.2140 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 21:16:10 visual_prompt]: 	Test 300/356. loss: 2.030, 0.2141 s / batch. (data: 7.72e-05)max mem: 7.80404 GB 
[09/30 21:16:23 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2135, average loss: 2.0280
[09/30 21:16:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 77.81	
[09/30 21:16:23 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/30 21:16:34 visual_prompt]: Epoch 16 / 100: avg data time: 1.14e-01, avg batch time: 0.5635, average train loss: 1.9610
[09/30 21:16:37 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1664, average loss: 1.8774
[09/30 21:16:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[09/30 21:17:00 visual_prompt]: 	Test 100/356. loss: 1.857, 0.2132 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:17:22 visual_prompt]: 	Test 200/356. loss: 1.765, 0.2140 s / batch. (data: 2.41e-05)max mem: 7.80404 GB 
[09/30 21:17:43 visual_prompt]: 	Test 300/356. loss: 1.876, 0.2145 s / batch. (data: 2.31e-05)max mem: 7.80404 GB 
[09/30 21:17:56 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2135, average loss: 1.8401
[09/30 21:17:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.67	
[09/30 21:17:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/30 21:18:06 visual_prompt]: Epoch 17 / 100: avg data time: 9.69e-02, avg batch time: 0.5481, average train loss: 1.9103
[09/30 21:18:10 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1663, average loss: 1.9082
[09/30 21:18:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 79.50	
[09/30 21:18:33 visual_prompt]: 	Test 100/356. loss: 1.828, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 21:18:54 visual_prompt]: 	Test 200/356. loss: 1.795, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:19:16 visual_prompt]: 	Test 300/356. loss: 1.817, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:19:29 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2134, average loss: 1.8529
[09/30 21:19:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 81.44	
[09/30 21:19:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/30 21:19:39 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e-01, avg batch time: 0.5569, average train loss: 2.0285
[09/30 21:19:43 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1665, average loss: 1.9429
[09/30 21:19:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 82.50	
[09/30 21:20:06 visual_prompt]: 	Test 100/356. loss: 1.960, 0.2134 s / batch. (data: 7.89e-05)max mem: 7.80404 GB 
[09/30 21:20:27 visual_prompt]: 	Test 200/356. loss: 1.823, 0.2137 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:20:49 visual_prompt]: 	Test 300/356. loss: 1.856, 0.2148 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:21:02 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2134, average loss: 1.9155
[09/30 21:21:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 82.27	
[09/30 21:21:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/30 21:21:12 visual_prompt]: Epoch 19 / 100: avg data time: 9.68e-02, avg batch time: 0.5456, average train loss: 1.9604
[09/30 21:21:16 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1664, average loss: 1.8891
[09/30 21:21:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 86.00	
[09/30 21:21:38 visual_prompt]: 	Test 100/356. loss: 1.806, 0.2135 s / batch. (data: 3.03e-05)max mem: 7.80404 GB 
[09/30 21:22:00 visual_prompt]: 	Test 200/356. loss: 1.732, 0.2138 s / batch. (data: 3.08e-05)max mem: 7.80404 GB 
[09/30 21:22:21 visual_prompt]: 	Test 300/356. loss: 1.785, 0.2139 s / batch. (data: 2.98e-05)max mem: 7.80404 GB 
[09/30 21:22:35 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2133, average loss: 1.8164
[09/30 21:22:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 86.28	
[09/30 21:22:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/30 21:22:45 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e-01, avg batch time: 0.5580, average train loss: 1.9360
[09/30 21:22:48 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1665, average loss: 2.5197
[09/30 21:22:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.00	
[09/30 21:23:11 visual_prompt]: 	Test 100/356. loss: 2.526, 0.2134 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:23:33 visual_prompt]: 	Test 200/356. loss: 2.062, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:23:54 visual_prompt]: 	Test 300/356. loss: 2.369, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 21:24:08 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2135, average loss: 2.3736
[09/30 21:24:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 85.40	
[09/30 21:24:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[09/30 21:24:18 visual_prompt]: Epoch 21 / 100: avg data time: 1.11e-01, avg batch time: 0.5605, average train loss: 2.0246
[09/30 21:24:21 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1665, average loss: 2.0127
[09/30 21:24:21 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[09/30 21:24:44 visual_prompt]: 	Test 100/356. loss: 1.888, 0.2136 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:25:06 visual_prompt]: 	Test 200/356. loss: 1.777, 0.2146 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 21:25:27 visual_prompt]: 	Test 300/356. loss: 1.931, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:25:41 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2136, average loss: 1.9047
[09/30 21:25:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[09/30 21:25:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[09/30 21:25:51 visual_prompt]: Epoch 22 / 100: avg data time: 1.10e-01, avg batch time: 0.5607, average train loss: 1.9467
[09/30 21:25:54 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1665, average loss: 2.1309
[09/30 21:25:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 83.00	
[09/30 21:26:17 visual_prompt]: 	Test 100/356. loss: 1.981, 0.2134 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:26:39 visual_prompt]: 	Test 200/356. loss: 1.872, 0.2144 s / batch. (data: 7.32e-05)max mem: 7.80404 GB 
[09/30 21:27:00 visual_prompt]: 	Test 300/356. loss: 1.916, 0.2143 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 21:27:14 visual_prompt]: Inference (test):avg data time: 7.64e-05, avg batch time: 0.2135, average loss: 2.0061
[09/30 21:27:14 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.14	
[09/30 21:27:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[09/30 21:27:24 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e-01, avg batch time: 0.5536, average train loss: 1.9372
[09/30 21:27:27 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1666, average loss: 1.8686
[09/30 21:27:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.50	
[09/30 21:27:50 visual_prompt]: 	Test 100/356. loss: 1.872, 0.2133 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:28:12 visual_prompt]: 	Test 200/356. loss: 2.045, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:28:33 visual_prompt]: 	Test 300/356. loss: 1.986, 0.2142 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:28:47 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2134, average loss: 1.9273
[09/30 21:28:47 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 77.81	
[09/30 21:28:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[09/30 21:28:57 visual_prompt]: Epoch 24 / 100: avg data time: 9.96e-02, avg batch time: 0.5491, average train loss: 1.8275
[09/30 21:29:00 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1665, average loss: 1.9279
[09/30 21:29:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 95.00	
[09/30 21:29:23 visual_prompt]: 	Test 100/356. loss: 1.778, 0.2132 s / batch. (data: 3.10e-05)max mem: 7.80404 GB 
[09/30 21:29:45 visual_prompt]: 	Test 200/356. loss: 1.944, 0.2144 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:30:06 visual_prompt]: 	Test 300/356. loss: 1.833, 0.2144 s / batch. (data: 3.39e-05)max mem: 7.80404 GB 
[09/30 21:30:19 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2134, average loss: 1.8905
[09/30 21:30:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.68	top5: 91.19	
[09/30 21:30:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[09/30 21:30:29 visual_prompt]: Epoch 25 / 100: avg data time: 1.00e-01, avg batch time: 0.5501, average train loss: 1.8003
[09/30 21:30:33 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1666, average loss: 1.8640
[09/30 21:30:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.50	top5: 84.50	
[09/30 21:30:56 visual_prompt]: 	Test 100/356. loss: 1.816, 0.2135 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:31:17 visual_prompt]: 	Test 200/356. loss: 1.703, 0.2141 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 21:31:39 visual_prompt]: 	Test 300/356. loss: 1.678, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:31:52 visual_prompt]: Inference (test):avg data time: 3.95e-05, avg batch time: 0.2137, average loss: 1.7901
[09/30 21:31:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.42	top5: 84.55	
[09/30 21:31:52 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[09/30 21:32:02 visual_prompt]: Epoch 26 / 100: avg data time: 1.10e-01, avg batch time: 0.5595, average train loss: 1.7674
[09/30 21:32:06 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1665, average loss: 2.0786
[09/30 21:32:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.00	
[09/30 21:32:29 visual_prompt]: 	Test 100/356. loss: 2.005, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:32:50 visual_prompt]: 	Test 200/356. loss: 1.664, 0.2140 s / batch. (data: 2.91e-05)max mem: 7.80404 GB 
[09/30 21:33:12 visual_prompt]: 	Test 300/356. loss: 1.894, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:33:25 visual_prompt]: Inference (test):avg data time: 4.72e-05, avg batch time: 0.2137, average loss: 1.9460
[09/30 21:33:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.15	
[09/30 21:33:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[09/30 21:33:35 visual_prompt]: Epoch 27 / 100: avg data time: 1.03e-01, avg batch time: 0.5535, average train loss: 1.6679
[09/30 21:33:39 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1666, average loss: 1.5599
[09/30 21:33:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 99.00	
[09/30 21:34:02 visual_prompt]: 	Test 100/356. loss: 1.540, 0.2136 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:34:23 visual_prompt]: 	Test 200/356. loss: 1.468, 0.2141 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:34:45 visual_prompt]: 	Test 300/356. loss: 1.489, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 21:34:58 visual_prompt]: Inference (test):avg data time: 4.32e-05, avg batch time: 0.2136, average loss: 1.5293
[09/30 21:34:58 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.04	top5: 96.95	
[09/30 21:34:58 visual_prompt]: Best epoch 27: best metric: 0.325
[09/30 21:34:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[09/30 21:35:08 visual_prompt]: Epoch 28 / 100: avg data time: 1.02e-01, avg batch time: 0.5526, average train loss: 1.5382
[09/30 21:35:12 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1667, average loss: 1.5553
[09/30 21:35:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 97.50	
[09/30 21:35:35 visual_prompt]: 	Test 100/356. loss: 1.495, 0.2139 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:35:56 visual_prompt]: 	Test 200/356. loss: 1.429, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:36:18 visual_prompt]: 	Test 300/356. loss: 1.486, 0.2145 s / batch. (data: 2.86e-05)max mem: 7.80404 GB 
[09/30 21:36:31 visual_prompt]: Inference (test):avg data time: 5.79e-05, avg batch time: 0.2137, average loss: 1.5144
[09/30 21:36:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.48	top5: 97.13	
[09/30 21:36:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[09/30 21:36:41 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e-01, avg batch time: 0.5572, average train loss: 1.5317
[09/30 21:36:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1667, average loss: 1.6998
[09/30 21:36:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.00	top5: 98.00	
[09/30 21:37:08 visual_prompt]: 	Test 100/356. loss: 1.716, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:37:29 visual_prompt]: 	Test 200/356. loss: 1.727, 0.2138 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:37:51 visual_prompt]: 	Test 300/356. loss: 1.674, 0.2147 s / batch. (data: 2.46e-05)max mem: 7.80404 GB 
[09/30 21:38:04 visual_prompt]: Inference (test):avg data time: 5.43e-05, avg batch time: 0.2136, average loss: 1.7082
[09/30 21:38:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 21.75	top5: 95.55	
[09/30 21:38:04 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[09/30 21:38:15 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e-01, avg batch time: 0.5567, average train loss: 1.5814
[09/30 21:38:18 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1664, average loss: 1.5641
[09/30 21:38:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.00	top5: 97.00	
[09/30 21:38:41 visual_prompt]: 	Test 100/356. loss: 1.667, 0.2139 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 21:39:03 visual_prompt]: 	Test 200/356. loss: 1.792, 0.2138 s / batch. (data: 3.17e-05)max mem: 7.80404 GB 
[09/30 21:39:24 visual_prompt]: 	Test 300/356. loss: 1.590, 0.2143 s / batch. (data: 3.15e-05)max mem: 7.80404 GB 
[09/30 21:39:37 visual_prompt]: Inference (test):avg data time: 6.22e-05, avg batch time: 0.2137, average loss: 1.6670
[09/30 21:39:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.37	top5: 95.14	
[09/30 21:39:37 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[09/30 21:39:47 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e-01, avg batch time: 0.5533, average train loss: 1.5087
[09/30 21:39:51 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1667, average loss: 1.4904
[09/30 21:39:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.00	top5: 97.50	
[09/30 21:40:14 visual_prompt]: 	Test 100/356. loss: 1.398, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 21:40:35 visual_prompt]: 	Test 200/356. loss: 1.575, 0.2140 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:40:57 visual_prompt]: 	Test 300/356. loss: 1.384, 0.2139 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 21:41:10 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2135, average loss: 1.5011
[09/30 21:41:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.43	top5: 97.06	
[09/30 21:41:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[09/30 21:41:20 visual_prompt]: Epoch 32 / 100: avg data time: 1.01e-01, avg batch time: 0.5511, average train loss: 1.4288
[09/30 21:41:24 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1679, average loss: 1.4444
[09/30 21:41:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.00	top5: 99.00	
[09/30 21:41:47 visual_prompt]: 	Test 100/356. loss: 1.315, 0.2137 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 21:42:08 visual_prompt]: 	Test 200/356. loss: 1.514, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:42:30 visual_prompt]: 	Test 300/356. loss: 1.374, 0.2143 s / batch. (data: 2.34e-05)max mem: 7.80404 GB 
[09/30 21:42:43 visual_prompt]: Inference (test):avg data time: 4.39e-05, avg batch time: 0.2135, average loss: 1.4544
[09/30 21:42:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.06	top5: 97.59	
[09/30 21:42:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[09/30 21:42:53 visual_prompt]: Epoch 33 / 100: avg data time: 1.10e-01, avg batch time: 0.5593, average train loss: 1.4741
[09/30 21:42:57 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1667, average loss: 1.5935
[09/30 21:42:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 93.50	
[09/30 21:43:20 visual_prompt]: 	Test 100/356. loss: 1.655, 0.2141 s / batch. (data: 2.91e-05)max mem: 7.80404 GB 
[09/30 21:43:41 visual_prompt]: 	Test 200/356. loss: 1.845, 0.2146 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 21:44:03 visual_prompt]: 	Test 300/356. loss: 1.574, 0.2146 s / batch. (data: 7.01e-05)max mem: 7.80404 GB 
[09/30 21:44:16 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2138, average loss: 1.6708
[09/30 21:44:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.12	top5: 93.14	
[09/30 21:44:16 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[09/30 21:44:26 visual_prompt]: Epoch 34 / 100: avg data time: 9.88e-02, avg batch time: 0.5484, average train loss: 1.4604
[09/30 21:44:30 visual_prompt]: Inference (val):avg data time: 1.52e-05, avg batch time: 0.1667, average loss: 1.5189
[09/30 21:44:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.50	top5: 98.00	
[09/30 21:44:53 visual_prompt]: 	Test 100/356. loss: 1.507, 0.2137 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:45:14 visual_prompt]: 	Test 200/356. loss: 1.566, 0.2142 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 21:45:36 visual_prompt]: 	Test 300/356. loss: 1.480, 0.2148 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:45:49 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2138, average loss: 1.5498
[09/30 21:45:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.77	top5: 94.23	
[09/30 21:45:49 visual_prompt]: Best epoch 34: best metric: 0.345
[09/30 21:45:49 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[09/30 21:45:59 visual_prompt]: Epoch 35 / 100: avg data time: 9.85e-02, avg batch time: 0.5493, average train loss: 1.4581
[09/30 21:46:03 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1667, average loss: 1.5625
[09/30 21:46:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 28.50	top5: 96.50	
[09/30 21:46:26 visual_prompt]: 	Test 100/356. loss: 1.647, 0.2141 s / batch. (data: 3.15e-05)max mem: 7.80404 GB 
[09/30 21:46:47 visual_prompt]: 	Test 200/356. loss: 1.745, 0.2141 s / batch. (data: 6.39e-05)max mem: 7.80404 GB 
[09/30 21:47:08 visual_prompt]: 	Test 300/356. loss: 1.531, 0.2142 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 21:47:22 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2137, average loss: 1.6184
[09/30 21:47:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.49	top5: 94.55	
[09/30 21:47:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[09/30 21:47:32 visual_prompt]: Epoch 36 / 100: avg data time: 1.03e-01, avg batch time: 0.5581, average train loss: 1.5685
[09/30 21:47:36 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1668, average loss: 1.7044
[09/30 21:47:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 26.50	top5: 92.00	
[09/30 21:47:59 visual_prompt]: 	Test 100/356. loss: 1.738, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:48:20 visual_prompt]: 	Test 200/356. loss: 2.092, 0.2139 s / batch. (data: 2.46e-05)max mem: 7.80404 GB 
[09/30 21:48:41 visual_prompt]: 	Test 300/356. loss: 1.882, 0.2146 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 21:48:55 visual_prompt]: Inference (test):avg data time: 2.86e-05, avg batch time: 0.2136, average loss: 1.8334
[09/30 21:48:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.76	top5: 89.30	
[09/30 21:48:55 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[09/30 21:49:05 visual_prompt]: Epoch 37 / 100: avg data time: 1.10e-01, avg batch time: 0.5598, average train loss: 1.5525
[09/30 21:49:09 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1668, average loss: 1.4336
[09/30 21:49:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.00	top5: 98.00	
[09/30 21:49:32 visual_prompt]: 	Test 100/356. loss: 1.463, 0.2135 s / batch. (data: 2.81e-05)max mem: 7.80404 GB 
[09/30 21:49:53 visual_prompt]: 	Test 200/356. loss: 1.584, 0.2147 s / batch. (data: 1.00e-04)max mem: 7.80404 GB 
[09/30 21:50:14 visual_prompt]: 	Test 300/356. loss: 1.418, 0.2142 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:50:28 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2137, average loss: 1.5068
[09/30 21:50:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.15	top5: 96.93	
[09/30 21:50:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[09/30 21:50:38 visual_prompt]: Epoch 38 / 100: avg data time: 1.04e-01, avg batch time: 0.5544, average train loss: 1.4199
[09/30 21:50:42 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1667, average loss: 1.5737
[09/30 21:50:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 31.00	top5: 97.50	
[09/30 21:51:05 visual_prompt]: 	Test 100/356. loss: 1.585, 0.2143 s / batch. (data: 2.31e-05)max mem: 7.80404 GB 
[09/30 21:51:26 visual_prompt]: 	Test 200/356. loss: 1.618, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 21:51:47 visual_prompt]: 	Test 300/356. loss: 1.489, 0.2145 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 21:52:01 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2137, average loss: 1.5988
[09/30 21:52:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.13	top5: 97.04	
[09/30 21:52:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[09/30 21:52:11 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e-01, avg batch time: 0.5561, average train loss: 1.4702
[09/30 21:52:14 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1670, average loss: 1.8260
[09/30 21:52:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.50	top5: 85.50	
[09/30 21:52:38 visual_prompt]: 	Test 100/356. loss: 1.859, 0.2139 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 21:52:59 visual_prompt]: 	Test 200/356. loss: 1.619, 0.2141 s / batch. (data: 2.46e-05)max mem: 7.80404 GB 
[09/30 21:53:20 visual_prompt]: 	Test 300/356. loss: 1.835, 0.2147 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 21:53:34 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2137, average loss: 1.8018
[09/30 21:53:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.65	top5: 84.67	
[09/30 21:53:34 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[09/30 21:53:44 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e-01, avg batch time: 0.5576, average train loss: 1.5152
[09/30 21:53:47 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1666, average loss: 1.8774
[09/30 21:53:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 84.00	
[09/30 21:54:11 visual_prompt]: 	Test 100/356. loss: 1.749, 0.2137 s / batch. (data: 2.86e-05)max mem: 7.80404 GB 
[09/30 21:54:32 visual_prompt]: 	Test 200/356. loss: 1.564, 0.2192 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:54:53 visual_prompt]: 	Test 300/356. loss: 1.764, 0.2143 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 21:55:07 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2137, average loss: 1.7796
[09/30 21:55:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.87	top5: 88.42	
[09/30 21:55:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[09/30 21:55:17 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e-01, avg batch time: 0.5550, average train loss: 1.4671
[09/30 21:55:20 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1668, average loss: 1.5546
[09/30 21:55:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 27.00	top5: 96.00	
[09/30 21:55:43 visual_prompt]: 	Test 100/356. loss: 1.519, 0.2136 s / batch. (data: 2.36e-05)max mem: 7.80404 GB 
[09/30 21:56:05 visual_prompt]: 	Test 200/356. loss: 1.608, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 21:56:26 visual_prompt]: 	Test 300/356. loss: 1.516, 0.2140 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 21:56:40 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2136, average loss: 1.5425
[09/30 21:56:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.91	top5: 95.82	
[09/30 21:56:40 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[09/30 21:56:50 visual_prompt]: Epoch 42 / 100: avg data time: 1.03e-01, avg batch time: 0.5523, average train loss: 1.4323
[09/30 21:56:53 visual_prompt]: Inference (val):avg data time: 1.59e-05, avg batch time: 0.1666, average loss: 1.5850
[09/30 21:56:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 98.00	
[09/30 21:57:16 visual_prompt]: 	Test 100/356. loss: 1.599, 0.2135 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 21:57:38 visual_prompt]: 	Test 200/356. loss: 1.735, 0.2139 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:57:59 visual_prompt]: 	Test 300/356. loss: 1.468, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:58:13 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2138, average loss: 1.6166
[09/30 21:58:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.83	top5: 97.07	
[09/30 21:58:13 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[09/30 21:58:23 visual_prompt]: Epoch 43 / 100: avg data time: 1.01e-01, avg batch time: 0.5508, average train loss: 1.5100
[09/30 21:58:26 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1668, average loss: 1.4078
[09/30 21:58:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 27.00	top5: 99.00	
[09/30 21:58:49 visual_prompt]: 	Test 100/356. loss: 1.393, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 21:59:11 visual_prompt]: 	Test 200/356. loss: 1.435, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 21:59:32 visual_prompt]: 	Test 300/356. loss: 1.371, 0.2147 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 21:59:45 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2138, average loss: 1.4193
[09/30 21:59:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.77	top5: 97.20	
[09/30 21:59:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[09/30 21:59:56 visual_prompt]: Epoch 44 / 100: avg data time: 1.10e-01, avg batch time: 0.5609, average train loss: 1.5595
[09/30 21:59:59 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1669, average loss: 1.6275
[09/30 21:59:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 31.50	top5: 96.00	
[09/30 22:00:22 visual_prompt]: 	Test 100/356. loss: 1.643, 0.2139 s / batch. (data: 7.96e-05)max mem: 7.80404 GB 
[09/30 22:00:44 visual_prompt]: 	Test 200/356. loss: 1.617, 0.2148 s / batch. (data: 7.87e-05)max mem: 7.80404 GB 
[09/30 22:01:05 visual_prompt]: 	Test 300/356. loss: 1.639, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 22:01:18 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2139, average loss: 1.6524
[09/30 22:01:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.17	top5: 95.75	
[09/30 22:01:18 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[09/30 22:01:29 visual_prompt]: Epoch 45 / 100: avg data time: 9.91e-02, avg batch time: 0.5504, average train loss: 1.5039
[09/30 22:01:32 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1667, average loss: 1.3414
[09/30 22:01:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 99.00	
[09/30 22:01:55 visual_prompt]: 	Test 100/356. loss: 1.331, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:02:17 visual_prompt]: 	Test 200/356. loss: 1.558, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 22:02:38 visual_prompt]: 	Test 300/356. loss: 1.379, 0.2147 s / batch. (data: 2.86e-05)max mem: 7.80404 GB 
[09/30 22:02:51 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2137, average loss: 1.4214
[09/30 22:02:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.92	top5: 97.23	
[09/30 22:02:51 visual_prompt]: Best epoch 45: best metric: 0.390
[09/30 22:02:51 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[09/30 22:03:02 visual_prompt]: Epoch 46 / 100: avg data time: 1.01e-01, avg batch time: 0.5514, average train loss: 1.4047
[09/30 22:03:05 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1665, average loss: 1.5856
[09/30 22:03:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.50	top5: 92.50	
[09/30 22:03:28 visual_prompt]: 	Test 100/356. loss: 1.552, 0.2134 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 22:03:49 visual_prompt]: 	Test 200/356. loss: 1.668, 0.2141 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:04:11 visual_prompt]: 	Test 300/356. loss: 1.609, 0.2143 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:04:24 visual_prompt]: Inference (test):avg data time: 4.41e-05, avg batch time: 0.2137, average loss: 1.5906
[09/30 22:04:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.55	top5: 94.61	
[09/30 22:04:24 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[09/30 22:04:34 visual_prompt]: Epoch 47 / 100: avg data time: 9.85e-02, avg batch time: 0.5495, average train loss: 1.4126
[09/30 22:04:38 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1667, average loss: 1.2699
[09/30 22:04:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 99.50	
[09/30 22:05:01 visual_prompt]: 	Test 100/356. loss: 1.309, 0.2140 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:05:22 visual_prompt]: 	Test 200/356. loss: 1.522, 0.2140 s / batch. (data: 3.00e-05)max mem: 7.80404 GB 
[09/30 22:05:44 visual_prompt]: 	Test 300/356. loss: 1.380, 0.2147 s / batch. (data: 9.35e-05)max mem: 7.80404 GB 
[09/30 22:05:57 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2137, average loss: 1.4057
[09/30 22:05:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.35	top5: 97.64	
[09/30 22:05:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[09/30 22:06:07 visual_prompt]: Epoch 48 / 100: avg data time: 1.08e-01, avg batch time: 0.5578, average train loss: 1.3719
[09/30 22:06:11 visual_prompt]: Inference (val):avg data time: 1.68e-05, avg batch time: 0.1668, average loss: 1.2870
[09/30 22:06:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.00	
[09/30 22:06:34 visual_prompt]: 	Test 100/356. loss: 1.195, 0.2140 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 22:06:56 visual_prompt]: 	Test 200/356. loss: 1.517, 0.2139 s / batch. (data: 3.03e-05)max mem: 7.80404 GB 
[09/30 22:07:17 visual_prompt]: 	Test 300/356. loss: 1.283, 0.2148 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 22:07:30 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2136, average loss: 1.3621
[09/30 22:07:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.14	top5: 97.95	
[09/30 22:07:31 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[09/30 22:07:41 visual_prompt]: Epoch 49 / 100: avg data time: 1.00e-01, avg batch time: 0.5502, average train loss: 1.4275
[09/30 22:07:44 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1666, average loss: 1.4490
[09/30 22:07:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.00	top5: 98.00	
[09/30 22:08:07 visual_prompt]: 	Test 100/356. loss: 1.399, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:08:29 visual_prompt]: 	Test 200/356. loss: 1.416, 0.2146 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 22:08:50 visual_prompt]: 	Test 300/356. loss: 1.329, 0.2144 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:09:03 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2138, average loss: 1.4459
[09/30 22:09:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.08	top5: 97.25	
[09/30 22:09:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[09/30 22:09:13 visual_prompt]: Epoch 50 / 100: avg data time: 9.99e-02, avg batch time: 0.5509, average train loss: 1.3439
[09/30 22:09:17 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1668, average loss: 1.3273
[09/30 22:09:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 98.50	
[09/30 22:09:40 visual_prompt]: 	Test 100/356. loss: 1.265, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:10:01 visual_prompt]: 	Test 200/356. loss: 1.600, 0.2142 s / batch. (data: 2.19e-05)max mem: 7.80404 GB 
[09/30 22:10:23 visual_prompt]: 	Test 300/356. loss: 1.281, 0.2147 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:10:36 visual_prompt]: Inference (test):avg data time: 6.83e-05, avg batch time: 0.2138, average loss: 1.4022
[09/30 22:10:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.77	top5: 98.06	
[09/30 22:10:36 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[09/30 22:10:47 visual_prompt]: Epoch 51 / 100: avg data time: 9.96e-02, avg batch time: 0.5520, average train loss: 1.2988
[09/30 22:10:50 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1668, average loss: 1.3122
[09/30 22:10:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 99.00	
[09/30 22:11:13 visual_prompt]: 	Test 100/356. loss: 1.399, 0.2137 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:11:35 visual_prompt]: 	Test 200/356. loss: 1.520, 0.2143 s / batch. (data: 8.56e-05)max mem: 7.80404 GB 
[09/30 22:11:56 visual_prompt]: 	Test 300/356. loss: 1.331, 0.2145 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 22:12:09 visual_prompt]: Inference (test):avg data time: 4.23e-05, avg batch time: 0.2139, average loss: 1.4063
[09/30 22:12:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.76	top5: 98.01	
[09/30 22:12:09 visual_prompt]: Best epoch 51: best metric: 0.410
[09/30 22:12:09 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[09/30 22:12:20 visual_prompt]: Epoch 52 / 100: avg data time: 1.05e-01, avg batch time: 0.5550, average train loss: 1.2432
[09/30 22:12:23 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1669, average loss: 1.2128
[09/30 22:12:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 98.50	
[09/30 22:12:46 visual_prompt]: 	Test 100/356. loss: 1.291, 0.2142 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 22:13:08 visual_prompt]: 	Test 200/356. loss: 1.461, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:13:29 visual_prompt]: 	Test 300/356. loss: 1.334, 0.2147 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 22:13:43 visual_prompt]: Inference (test):avg data time: 7.78e-05, avg batch time: 0.2138, average loss: 1.3556
[09/30 22:13:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.24	top5: 97.69	
[09/30 22:13:43 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[09/30 22:13:53 visual_prompt]: Epoch 53 / 100: avg data time: 9.76e-02, avg batch time: 0.5485, average train loss: 1.2103
[09/30 22:13:56 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1668, average loss: 1.2110
[09/30 22:13:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.50	top5: 99.00	
[09/30 22:14:19 visual_prompt]: 	Test 100/356. loss: 1.293, 0.2136 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:14:41 visual_prompt]: 	Test 200/356. loss: 1.495, 0.2146 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:15:02 visual_prompt]: 	Test 300/356. loss: 1.207, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 22:15:16 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2137, average loss: 1.3534
[09/30 22:15:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.88	top5: 97.46	
[09/30 22:15:16 visual_prompt]: Best epoch 53: best metric: 0.435
[09/30 22:15:16 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[09/30 22:15:26 visual_prompt]: Epoch 54 / 100: avg data time: 9.96e-02, avg batch time: 0.5506, average train loss: 1.2369
[09/30 22:15:29 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1665, average loss: 1.2489
[09/30 22:15:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 99.00	
[09/30 22:15:52 visual_prompt]: 	Test 100/356. loss: 1.398, 0.2135 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:16:14 visual_prompt]: 	Test 200/356. loss: 1.410, 0.2139 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:16:35 visual_prompt]: 	Test 300/356. loss: 1.302, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:16:48 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2138, average loss: 1.4145
[09/30 22:16:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.80	top5: 97.54	
[09/30 22:16:49 visual_prompt]: Best epoch 54: best metric: 0.465
[09/30 22:16:49 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[09/30 22:16:59 visual_prompt]: Epoch 55 / 100: avg data time: 1.12e-01, avg batch time: 0.5627, average train loss: 1.2448
[09/30 22:17:02 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1668, average loss: 1.2688
[09/30 22:17:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 98.00	
[09/30 22:17:25 visual_prompt]: 	Test 100/356. loss: 1.289, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:17:47 visual_prompt]: 	Test 200/356. loss: 1.628, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 22:18:08 visual_prompt]: 	Test 300/356. loss: 1.295, 0.2147 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 22:18:21 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2138, average loss: 1.4082
[09/30 22:18:21 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.71	top5: 97.63	
[09/30 22:18:21 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[09/30 22:18:32 visual_prompt]: Epoch 56 / 100: avg data time: 1.11e-01, avg batch time: 0.5614, average train loss: 1.2196
[09/30 22:18:35 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1668, average loss: 1.1312
[09/30 22:18:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 99.00	
[09/30 22:18:58 visual_prompt]: 	Test 100/356. loss: 1.222, 0.2135 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:19:20 visual_prompt]: 	Test 200/356. loss: 1.584, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:19:41 visual_prompt]: 	Test 300/356. loss: 1.195, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:19:54 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2138, average loss: 1.3351
[09/30 22:19:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.24	top5: 97.44	
[09/30 22:19:55 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[09/30 22:20:05 visual_prompt]: Epoch 57 / 100: avg data time: 1.01e-01, avg batch time: 0.5514, average train loss: 1.1949
[09/30 22:20:08 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1668, average loss: 1.1023
[09/30 22:20:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[09/30 22:20:31 visual_prompt]: 	Test 100/356. loss: 1.187, 0.2139 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:20:53 visual_prompt]: 	Test 200/356. loss: 1.387, 0.2144 s / batch. (data: 6.32e-05)max mem: 7.80404 GB 
[09/30 22:21:14 visual_prompt]: 	Test 300/356. loss: 1.272, 0.2148 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 22:21:28 visual_prompt]: Inference (test):avg data time: 9.19e-05, avg batch time: 0.2139, average loss: 1.3051
[09/30 22:21:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.29	top5: 97.99	
[09/30 22:21:28 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[09/30 22:21:38 visual_prompt]: Epoch 58 / 100: avg data time: 9.67e-02, avg batch time: 0.5473, average train loss: 1.2259
[09/30 22:21:41 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1667, average loss: 1.4130
[09/30 22:21:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.00	top5: 97.50	
[09/30 22:22:04 visual_prompt]: 	Test 100/356. loss: 1.411, 0.2138 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 22:22:26 visual_prompt]: 	Test 200/356. loss: 1.457, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 22:22:47 visual_prompt]: 	Test 300/356. loss: 1.383, 0.2145 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:23:00 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2136, average loss: 1.5106
[09/30 22:23:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.66	top5: 96.53	
[09/30 22:23:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[09/30 22:23:11 visual_prompt]: Epoch 59 / 100: avg data time: 1.03e-01, avg batch time: 0.5538, average train loss: 1.2920
[09/30 22:23:14 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1666, average loss: 1.3562
[09/30 22:23:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 99.00	
[09/30 22:23:37 visual_prompt]: 	Test 100/356. loss: 1.338, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:23:59 visual_prompt]: 	Test 200/356. loss: 1.572, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:24:20 visual_prompt]: 	Test 300/356. loss: 1.412, 0.2142 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:24:33 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2137, average loss: 1.4842
[09/30 22:24:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.44	top5: 98.29	
[09/30 22:24:34 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[09/30 22:24:44 visual_prompt]: Epoch 60 / 100: avg data time: 1.09e-01, avg batch time: 0.5601, average train loss: 1.2127
[09/30 22:24:47 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1667, average loss: 1.1503
[09/30 22:24:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 54.00	top5: 98.50	
[09/30 22:25:10 visual_prompt]: 	Test 100/356. loss: 1.204, 0.2142 s / batch. (data: 7.68e-05)max mem: 7.80404 GB 
[09/30 22:25:32 visual_prompt]: 	Test 200/356. loss: 1.495, 0.2135 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:25:53 visual_prompt]: 	Test 300/356. loss: 1.244, 0.2144 s / batch. (data: 3.58e-05)max mem: 7.80404 GB 
[09/30 22:26:07 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2137, average loss: 1.3337
[09/30 22:26:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.63	top5: 97.70	
[09/30 22:26:07 visual_prompt]: Best epoch 60: best metric: 0.540
[09/30 22:26:07 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[09/30 22:26:17 visual_prompt]: Epoch 61 / 100: avg data time: 1.01e-01, avg batch time: 0.5512, average train loss: 1.1413
[09/30 22:26:20 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1667, average loss: 1.1402
[09/30 22:26:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.00	
[09/30 22:26:43 visual_prompt]: 	Test 100/356. loss: 1.323, 0.2139 s / batch. (data: 8.89e-05)max mem: 7.80404 GB 
[09/30 22:27:05 visual_prompt]: 	Test 200/356. loss: 1.634, 0.2143 s / batch. (data: 8.54e-05)max mem: 7.80404 GB 
[09/30 22:27:26 visual_prompt]: 	Test 300/356. loss: 1.185, 0.2144 s / batch. (data: 9.42e-05)max mem: 7.80404 GB 
[09/30 22:27:40 visual_prompt]: Inference (test):avg data time: 4.50e-05, avg batch time: 0.2138, average loss: 1.3897
[09/30 22:27:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.67	top5: 97.97	
[09/30 22:27:40 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[09/30 22:27:50 visual_prompt]: Epoch 62 / 100: avg data time: 1.11e-01, avg batch time: 0.5619, average train loss: 1.1154
[09/30 22:27:53 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1667, average loss: 1.3353
[09/30 22:27:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 37.00	top5: 99.00	
[09/30 22:28:16 visual_prompt]: 	Test 100/356. loss: 1.367, 0.2137 s / batch. (data: 2.41e-05)max mem: 7.80404 GB 
[09/30 22:28:38 visual_prompt]: 	Test 200/356. loss: 1.770, 0.2144 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 22:28:59 visual_prompt]: 	Test 300/356. loss: 1.383, 0.2145 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 22:29:13 visual_prompt]: Inference (test):avg data time: 9.64e-05, avg batch time: 0.2140, average loss: 1.6303
[09/30 22:29:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.51	top5: 96.30	
[09/30 22:29:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[09/30 22:29:23 visual_prompt]: Epoch 63 / 100: avg data time: 1.04e-01, avg batch time: 0.5537, average train loss: 1.1572
[09/30 22:29:26 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1668, average loss: 1.1508
[09/30 22:29:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 99.50	
[09/30 22:29:49 visual_prompt]: 	Test 100/356. loss: 1.244, 0.2141 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:30:11 visual_prompt]: 	Test 200/356. loss: 1.451, 0.2146 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:30:32 visual_prompt]: 	Test 300/356. loss: 1.205, 0.2145 s / batch. (data: 7.89e-05)max mem: 7.80404 GB 
[09/30 22:30:45 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2138, average loss: 1.3404
[09/30 22:30:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.72	top5: 97.86	
[09/30 22:30:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[09/30 22:30:56 visual_prompt]: Epoch 64 / 100: avg data time: 1.05e-01, avg batch time: 0.5554, average train loss: 1.1328
[09/30 22:30:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1667, average loss: 1.1834
[09/30 22:30:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 99.50	
[09/30 22:31:22 visual_prompt]: 	Test 100/356. loss: 1.331, 0.2137 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:31:44 visual_prompt]: 	Test 200/356. loss: 1.369, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:32:05 visual_prompt]: 	Test 300/356. loss: 1.293, 0.2145 s / batch. (data: 3.10e-05)max mem: 7.80404 GB 
[09/30 22:32:19 visual_prompt]: Inference (test):avg data time: 7.01e-05, avg batch time: 0.2138, average loss: 1.4211
[09/30 22:32:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.66	top5: 97.93	
[09/30 22:32:19 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[09/30 22:32:29 visual_prompt]: Epoch 65 / 100: avg data time: 9.72e-02, avg batch time: 0.5474, average train loss: 1.1145
[09/30 22:32:32 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1669, average loss: 1.4406
[09/30 22:32:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.50	
[09/30 22:32:55 visual_prompt]: 	Test 100/356. loss: 1.491, 0.2134 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:33:17 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2146 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 22:33:38 visual_prompt]: 	Test 300/356. loss: 1.229, 0.2142 s / batch. (data: 7.80e-05)max mem: 7.80404 GB 
[09/30 22:33:51 visual_prompt]: Inference (test):avg data time: 4.17e-05, avg batch time: 0.2137, average loss: 1.5676
[09/30 22:33:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.07	top5: 98.14	
[09/30 22:33:52 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[09/30 22:34:02 visual_prompt]: Epoch 66 / 100: avg data time: 9.90e-02, avg batch time: 0.5509, average train loss: 1.0967
[09/30 22:34:05 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1668, average loss: 1.1066
[09/30 22:34:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 99.50	
[09/30 22:34:28 visual_prompt]: 	Test 100/356. loss: 1.388, 0.2137 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 22:34:50 visual_prompt]: 	Test 200/356. loss: 1.378, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:35:11 visual_prompt]: 	Test 300/356. loss: 1.200, 0.2143 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:35:25 visual_prompt]: Inference (test):avg data time: 7.13e-05, avg batch time: 0.2138, average loss: 1.3467
[09/30 22:35:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.43	top5: 97.69	
[09/30 22:35:25 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[09/30 22:35:35 visual_prompt]: Epoch 67 / 100: avg data time: 1.01e-01, avg batch time: 0.5525, average train loss: 1.0862
[09/30 22:35:38 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1666, average loss: 1.0614
[09/30 22:35:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 51.50	top5: 100.00	
[09/30 22:36:01 visual_prompt]: 	Test 100/356. loss: 1.330, 0.2134 s / batch. (data: 6.37e-05)max mem: 7.80404 GB 
[09/30 22:36:23 visual_prompt]: 	Test 200/356. loss: 1.359, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 22:36:44 visual_prompt]: 	Test 300/356. loss: 1.168, 0.2149 s / batch. (data: 3.10e-05)max mem: 7.80404 GB 
[09/30 22:36:58 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2137, average loss: 1.3818
[09/30 22:36:58 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.85	top5: 98.22	
[09/30 22:36:58 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[09/30 22:37:08 visual_prompt]: Epoch 68 / 100: avg data time: 1.06e-01, avg batch time: 0.5548, average train loss: 1.0621
[09/30 22:37:11 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1668, average loss: 1.0651
[09/30 22:37:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 53.50	top5: 99.50	
[09/30 22:37:35 visual_prompt]: 	Test 100/356. loss: 1.376, 0.2136 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:37:56 visual_prompt]: 	Test 200/356. loss: 1.607, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:38:18 visual_prompt]: 	Test 300/356. loss: 1.276, 0.2149 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:38:31 visual_prompt]: Inference (test):avg data time: 6.24e-05, avg batch time: 0.2137, average loss: 1.4368
[09/30 22:38:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.06	top5: 97.39	
[09/30 22:38:31 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[09/30 22:38:41 visual_prompt]: Epoch 69 / 100: avg data time: 1.03e-01, avg batch time: 0.5531, average train loss: 1.1524
[09/30 22:38:45 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1666, average loss: 0.9809
[09/30 22:38:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 57.00	top5: 100.00	
[09/30 22:39:08 visual_prompt]: 	Test 100/356. loss: 1.224, 0.2141 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 22:39:29 visual_prompt]: 	Test 200/356. loss: 1.534, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 22:39:51 visual_prompt]: 	Test 300/356. loss: 1.213, 0.2148 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 22:40:04 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2137, average loss: 1.3266
[09/30 22:40:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.08	top5: 98.05	
[09/30 22:40:04 visual_prompt]: Best epoch 69: best metric: 0.570
[09/30 22:40:04 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[09/30 22:40:14 visual_prompt]: Epoch 70 / 100: avg data time: 1.01e-01, avg batch time: 0.5502, average train loss: 1.0596
[09/30 22:40:18 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1666, average loss: 1.1918
[09/30 22:40:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.50	top5: 99.50	
[09/30 22:40:41 visual_prompt]: 	Test 100/356. loss: 1.296, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:41:02 visual_prompt]: 	Test 200/356. loss: 1.468, 0.2138 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:41:24 visual_prompt]: 	Test 300/356. loss: 1.402, 0.2143 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:41:37 visual_prompt]: Inference (test):avg data time: 4.25e-05, avg batch time: 0.2136, average loss: 1.4948
[09/30 22:41:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.82	top5: 97.19	
[09/30 22:41:37 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[09/30 22:41:47 visual_prompt]: Epoch 71 / 100: avg data time: 1.02e-01, avg batch time: 0.5525, average train loss: 0.9817
[09/30 22:41:50 visual_prompt]: Inference (val):avg data time: 1.74e-05, avg batch time: 0.1666, average loss: 0.9879
[09/30 22:41:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 55.50	top5: 99.50	
[09/30 22:42:14 visual_prompt]: 	Test 100/356. loss: 1.369, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:42:35 visual_prompt]: 	Test 200/356. loss: 1.853, 0.2142 s / batch. (data: 2.22e-05)max mem: 7.80404 GB 
[09/30 22:42:57 visual_prompt]: 	Test 300/356. loss: 1.514, 0.2143 s / batch. (data: 2.41e-05)max mem: 7.80404 GB 
[09/30 22:43:10 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2136, average loss: 1.5700
[09/30 22:43:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.10	top5: 96.33	
[09/30 22:43:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[09/30 22:43:20 visual_prompt]: Epoch 72 / 100: avg data time: 1.05e-01, avg batch time: 0.5554, average train loss: 0.8991
[09/30 22:43:24 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1666, average loss: 0.8613
[09/30 22:43:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.00	top5: 99.50	
[09/30 22:43:47 visual_prompt]: 	Test 100/356. loss: 1.496, 0.2139 s / batch. (data: 7.89e-05)max mem: 7.80404 GB 
[09/30 22:44:08 visual_prompt]: 	Test 200/356. loss: 1.452, 0.2141 s / batch. (data: 8.15e-05)max mem: 7.80404 GB 
[09/30 22:44:30 visual_prompt]: 	Test 300/356. loss: 1.308, 0.2148 s / batch. (data: 2.96e-05)max mem: 7.80404 GB 
[09/30 22:44:43 visual_prompt]: Inference (test):avg data time: 4.13e-05, avg batch time: 0.2137, average loss: 1.4848
[09/30 22:44:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.53	top5: 97.76	
[09/30 22:44:43 visual_prompt]: Best epoch 72: best metric: 0.580
[09/30 22:44:43 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[09/30 22:44:53 visual_prompt]: Epoch 73 / 100: avg data time: 1.16e-01, avg batch time: 0.5652, average train loss: 0.8909
[09/30 22:44:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1665, average loss: 0.9101
[09/30 22:44:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 56.00	top5: 99.50	
[09/30 22:45:20 visual_prompt]: 	Test 100/356. loss: 1.598, 0.2139 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:45:41 visual_prompt]: 	Test 200/356. loss: 1.441, 0.2139 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 22:46:03 visual_prompt]: 	Test 300/356. loss: 1.402, 0.2146 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 22:46:16 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2137, average loss: 1.5906
[09/30 22:46:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.17	top5: 98.03	
[09/30 22:46:16 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[09/30 22:46:26 visual_prompt]: Epoch 74 / 100: avg data time: 1.02e-01, avg batch time: 0.5519, average train loss: 0.8249
[09/30 22:46:30 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1664, average loss: 0.8775
[09/30 22:46:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 62.00	top5: 99.50	
[09/30 22:46:53 visual_prompt]: 	Test 100/356. loss: 1.554, 0.2139 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:47:14 visual_prompt]: 	Test 200/356. loss: 1.541, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.80404 GB 
[09/30 22:47:36 visual_prompt]: 	Test 300/356. loss: 1.413, 0.2145 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:47:49 visual_prompt]: Inference (test):avg data time: 5.78e-05, avg batch time: 0.2136, average loss: 1.4946
[09/30 22:47:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.29	top5: 97.77	
[09/30 22:47:49 visual_prompt]: Best epoch 74: best metric: 0.620
[09/30 22:47:49 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[09/30 22:47:59 visual_prompt]: Epoch 75 / 100: avg data time: 9.79e-02, avg batch time: 0.5481, average train loss: 0.8534
[09/30 22:48:03 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1666, average loss: 0.7770
[09/30 22:48:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 64.50	top5: 99.50	
[09/30 22:48:26 visual_prompt]: 	Test 100/356. loss: 1.471, 0.2140 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 22:48:47 visual_prompt]: 	Test 200/356. loss: 1.532, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:49:09 visual_prompt]: 	Test 300/356. loss: 1.435, 0.2139 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 22:49:22 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2136, average loss: 1.5218
[09/30 22:49:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.61	top5: 97.84	
[09/30 22:49:22 visual_prompt]: Best epoch 75: best metric: 0.645
[09/30 22:49:22 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[09/30 22:49:32 visual_prompt]: Epoch 76 / 100: avg data time: 1.07e-01, avg batch time: 0.5579, average train loss: 0.8310
[09/30 22:49:36 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1666, average loss: 0.6814
[09/30 22:49:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 69.00	top5: 100.00	
[09/30 22:49:59 visual_prompt]: 	Test 100/356. loss: 1.366, 0.2142 s / batch. (data: 2.62e-05)max mem: 7.80404 GB 
[09/30 22:50:20 visual_prompt]: 	Test 200/356. loss: 1.442, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.80404 GB 
[09/30 22:50:42 visual_prompt]: 	Test 300/356. loss: 1.333, 0.2148 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 22:50:55 visual_prompt]: Inference (test):avg data time: 5.54e-05, avg batch time: 0.2137, average loss: 1.4935
[09/30 22:50:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.88	top5: 97.99	
[09/30 22:50:55 visual_prompt]: Best epoch 76: best metric: 0.690
[09/30 22:50:55 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[09/30 22:51:06 visual_prompt]: Epoch 77 / 100: avg data time: 1.08e-01, avg batch time: 0.5573, average train loss: 0.7714
[09/30 22:51:09 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1667, average loss: 0.8321
[09/30 22:51:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 60.50	top5: 100.00	
[09/30 22:51:32 visual_prompt]: 	Test 100/356. loss: 1.375, 0.2137 s / batch. (data: 3.12e-05)max mem: 7.80404 GB 
[09/30 22:51:54 visual_prompt]: 	Test 200/356. loss: 1.304, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:52:15 visual_prompt]: 	Test 300/356. loss: 1.384, 0.2142 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 22:52:29 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2136, average loss: 1.5278
[09/30 22:52:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.76	top5: 97.99	
[09/30 22:52:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[09/30 22:52:39 visual_prompt]: Epoch 78 / 100: avg data time: 1.03e-01, avg batch time: 0.5529, average train loss: 0.7828
[09/30 22:52:42 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1666, average loss: 0.7380
[09/30 22:52:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 61.00	top5: 100.00	
[09/30 22:53:05 visual_prompt]: 	Test 100/356. loss: 1.571, 0.2137 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:53:27 visual_prompt]: 	Test 200/356. loss: 1.731, 0.2140 s / batch. (data: 3.74e-05)max mem: 7.80404 GB 
[09/30 22:53:48 visual_prompt]: 	Test 300/356. loss: 1.438, 0.2143 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 22:54:02 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2136, average loss: 1.6100
[09/30 22:54:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.37	top5: 97.86	
[09/30 22:54:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[09/30 22:54:12 visual_prompt]: Epoch 79 / 100: avg data time: 1.03e-01, avg batch time: 0.5535, average train loss: 0.6731
[09/30 22:54:15 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1665, average loss: 0.6323
[09/30 22:54:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 69.50	top5: 100.00	
[09/30 22:54:38 visual_prompt]: 	Test 100/356. loss: 1.968, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 22:55:00 visual_prompt]: 	Test 200/356. loss: 1.549, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 22:55:21 visual_prompt]: 	Test 300/356. loss: 1.811, 0.2147 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 22:55:35 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2136, average loss: 1.8783
[09/30 22:55:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.10	top5: 97.76	
[09/30 22:55:35 visual_prompt]: Best epoch 79: best metric: 0.695
[09/30 22:55:35 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[09/30 22:55:45 visual_prompt]: Epoch 80 / 100: avg data time: 1.01e-01, avg batch time: 0.5510, average train loss: 0.6275
[09/30 22:55:48 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1666, average loss: 0.6806
[09/30 22:55:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 68.50	top5: 100.00	
[09/30 22:56:11 visual_prompt]: 	Test 100/356. loss: 1.892, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:56:33 visual_prompt]: 	Test 200/356. loss: 1.622, 0.2144 s / batch. (data: 7.72e-05)max mem: 7.80404 GB 
[09/30 22:56:54 visual_prompt]: 	Test 300/356. loss: 1.614, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 22:57:08 visual_prompt]: Inference (test):avg data time: 5.95e-05, avg batch time: 0.2137, average loss: 1.9298
[09/30 22:57:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.71	top5: 97.99	
[09/30 22:57:08 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[09/30 22:57:18 visual_prompt]: Epoch 81 / 100: avg data time: 1.07e-01, avg batch time: 0.5573, average train loss: 0.6386
[09/30 22:57:21 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1677, average loss: 0.6177
[09/30 22:57:21 visual_prompt]: Classification results with val_vtab-dmlab: top1: 69.50	top5: 100.00	
[09/30 22:57:44 visual_prompt]: 	Test 100/356. loss: 1.710, 0.2138 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 22:58:06 visual_prompt]: 	Test 200/356. loss: 2.128, 0.2145 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:58:27 visual_prompt]: 	Test 300/356. loss: 1.839, 0.2147 s / batch. (data: 2.57e-05)max mem: 7.80404 GB 
[09/30 22:58:41 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2137, average loss: 1.7836
[09/30 22:58:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.38	top5: 96.92	
[09/30 22:58:41 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[09/30 22:58:51 visual_prompt]: Epoch 82 / 100: avg data time: 1.02e-01, avg batch time: 0.5539, average train loss: 0.5743
[09/30 22:58:54 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1667, average loss: 0.4729
[09/30 22:58:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 82.50	top5: 100.00	
[09/30 22:59:17 visual_prompt]: 	Test 100/356. loss: 2.173, 0.2137 s / batch. (data: 2.50e-05)max mem: 7.80404 GB 
[09/30 22:59:39 visual_prompt]: 	Test 200/356. loss: 2.387, 0.2137 s / batch. (data: 2.31e-05)max mem: 7.80404 GB 
[09/30 23:00:00 visual_prompt]: 	Test 300/356. loss: 2.028, 0.2139 s / batch. (data: 2.43e-05)max mem: 7.80404 GB 
[09/30 23:00:14 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.2137, average loss: 2.1165
[09/30 23:00:14 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.43	top5: 96.60	
[09/30 23:00:14 visual_prompt]: Best epoch 82: best metric: 0.825
[09/30 23:00:14 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[09/30 23:00:24 visual_prompt]: Epoch 83 / 100: avg data time: 9.92e-02, avg batch time: 0.5488, average train loss: 0.4664
[09/30 23:00:27 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1666, average loss: 0.4208
[09/30 23:00:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 84.00	top5: 100.00	
[09/30 23:00:50 visual_prompt]: 	Test 100/356. loss: 2.475, 0.2134 s / batch. (data: 3.74e-05)max mem: 7.80404 GB 
[09/30 23:01:12 visual_prompt]: 	Test 200/356. loss: 2.214, 0.2146 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 23:01:33 visual_prompt]: 	Test 300/356. loss: 2.169, 0.2148 s / batch. (data: 3.19e-05)max mem: 7.80404 GB 
[09/30 23:01:47 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2136, average loss: 2.1891
[09/30 23:01:47 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.30	top5: 97.13	
[09/30 23:01:47 visual_prompt]: Best epoch 83: best metric: 0.840
[09/30 23:01:47 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[09/30 23:01:57 visual_prompt]: Epoch 84 / 100: avg data time: 1.10e-01, avg batch time: 0.5619, average train loss: 0.4295
[09/30 23:02:01 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1668, average loss: 0.5381
[09/30 23:02:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 73.00	top5: 100.00	
[09/30 23:02:24 visual_prompt]: 	Test 100/356. loss: 2.633, 0.2135 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 23:02:45 visual_prompt]: 	Test 200/356. loss: 2.130, 0.2142 s / batch. (data: 8.87e-05)max mem: 7.80404 GB 
[09/30 23:03:07 visual_prompt]: 	Test 300/356. loss: 2.130, 0.2143 s / batch. (data: 6.63e-05)max mem: 7.80404 GB 
[09/30 23:03:20 visual_prompt]: Inference (test):avg data time: 1.10e-04, avg batch time: 0.2138, average loss: 2.3687
[09/30 23:03:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.23	top5: 97.59	
[09/30 23:03:20 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[09/30 23:03:30 visual_prompt]: Epoch 85 / 100: avg data time: 1.02e-01, avg batch time: 0.5514, average train loss: 0.4726
[09/30 23:03:34 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1666, average loss: 0.5379
[09/30 23:03:34 visual_prompt]: Classification results with val_vtab-dmlab: top1: 77.50	top5: 100.00	
[09/30 23:03:57 visual_prompt]: 	Test 100/356. loss: 2.314, 0.2139 s / batch. (data: 2.17e-05)max mem: 7.80404 GB 
[09/30 23:04:18 visual_prompt]: 	Test 200/356. loss: 2.333, 0.2143 s / batch. (data: 7.08e-05)max mem: 7.80404 GB 
[09/30 23:04:40 visual_prompt]: 	Test 300/356. loss: 1.888, 0.2147 s / batch. (data: 6.46e-05)max mem: 7.80404 GB 
[09/30 23:04:53 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2136, average loss: 2.2512
[09/30 23:04:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.80	top5: 97.44	
[09/30 23:04:53 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[09/30 23:05:03 visual_prompt]: Epoch 86 / 100: avg data time: 1.07e-01, avg batch time: 0.5568, average train loss: 0.4576
[09/30 23:05:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1665, average loss: 0.4378
[09/30 23:05:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 77.00	top5: 100.00	
[09/30 23:05:30 visual_prompt]: 	Test 100/356. loss: 2.086, 0.2136 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 23:05:51 visual_prompt]: 	Test 200/356. loss: 2.401, 0.2144 s / batch. (data: 3.74e-05)max mem: 7.80404 GB 
[09/30 23:06:13 visual_prompt]: 	Test 300/356. loss: 2.108, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 23:06:26 visual_prompt]: Inference (test):avg data time: 9.63e-05, avg batch time: 0.2138, average loss: 2.3126
[09/30 23:06:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.17	top5: 97.57	
[09/30 23:06:26 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[09/30 23:06:36 visual_prompt]: Epoch 87 / 100: avg data time: 1.08e-01, avg batch time: 0.5573, average train loss: 0.4157
[09/30 23:06:40 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1667, average loss: 0.2905
[09/30 23:06:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 89.00	top5: 100.00	
[09/30 23:07:03 visual_prompt]: 	Test 100/356. loss: 2.133, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 23:07:24 visual_prompt]: 	Test 200/356. loss: 2.704, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 23:07:46 visual_prompt]: 	Test 300/356. loss: 2.366, 0.2145 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 23:07:59 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2138, average loss: 2.4090
[09/30 23:07:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.64	top5: 96.81	
[09/30 23:07:59 visual_prompt]: Best epoch 87: best metric: 0.890
[09/30 23:07:59 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[09/30 23:08:09 visual_prompt]: Epoch 88 / 100: avg data time: 1.01e-01, avg batch time: 0.5506, average train loss: 0.3137
[09/30 23:08:12 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1668, average loss: 0.3216
[09/30 23:08:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 85.50	top5: 100.00	
[09/30 23:08:36 visual_prompt]: 	Test 100/356. loss: 2.542, 0.2135 s / batch. (data: 2.93e-05)max mem: 7.80404 GB 
[09/30 23:08:57 visual_prompt]: 	Test 200/356. loss: 2.708, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 23:09:19 visual_prompt]: 	Test 300/356. loss: 2.385, 0.2145 s / batch. (data: 8.44e-05)max mem: 7.80404 GB 
[09/30 23:09:32 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2137, average loss: 2.5313
[09/30 23:09:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.68	top5: 97.25	
[09/30 23:09:32 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[09/30 23:09:42 visual_prompt]: Epoch 89 / 100: avg data time: 1.01e-01, avg batch time: 0.5514, average train loss: 0.2706
[09/30 23:09:46 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1668, average loss: 0.2833
[09/30 23:09:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 84.50	top5: 100.00	
[09/30 23:10:09 visual_prompt]: 	Test 100/356. loss: 2.698, 0.2137 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 23:10:30 visual_prompt]: 	Test 200/356. loss: 2.628, 0.2149 s / batch. (data: 8.18e-05)max mem: 7.80404 GB 
[09/30 23:10:52 visual_prompt]: 	Test 300/356. loss: 2.535, 0.2143 s / batch. (data: 3.36e-05)max mem: 7.80404 GB 
[09/30 23:11:05 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2137, average loss: 2.6680
[09/30 23:11:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.85	top5: 97.67	
[09/30 23:11:05 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[09/30 23:11:15 visual_prompt]: Epoch 90 / 100: avg data time: 1.04e-01, avg batch time: 0.5547, average train loss: 0.2241
[09/30 23:11:19 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1667, average loss: 0.2024
[09/30 23:11:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 90.50	top5: 100.00	
[09/30 23:11:42 visual_prompt]: 	Test 100/356. loss: 2.693, 0.2138 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 23:12:03 visual_prompt]: 	Test 200/356. loss: 2.956, 0.2144 s / batch. (data: 7.94e-05)max mem: 7.80404 GB 
[09/30 23:12:25 visual_prompt]: 	Test 300/356. loss: 2.634, 0.2150 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 23:12:38 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2137, average loss: 2.7057
[09/30 23:12:38 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.60	top5: 96.96	
[09/30 23:12:38 visual_prompt]: Best epoch 90: best metric: 0.905
[09/30 23:12:38 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[09/30 23:12:48 visual_prompt]: Epoch 91 / 100: avg data time: 1.14e-01, avg batch time: 0.5655, average train loss: 0.1968
[09/30 23:12:52 visual_prompt]: Inference (val):avg data time: 1.92e-05, avg batch time: 0.1668, average loss: 0.1871
[09/30 23:12:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 92.50	top5: 100.00	
[09/30 23:13:15 visual_prompt]: 	Test 100/356. loss: 2.748, 0.2137 s / batch. (data: 2.46e-05)max mem: 7.80404 GB 
[09/30 23:13:36 visual_prompt]: 	Test 200/356. loss: 3.013, 0.2138 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 23:13:58 visual_prompt]: 	Test 300/356. loss: 2.844, 0.2145 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 23:14:11 visual_prompt]: Inference (test):avg data time: 4.78e-05, avg batch time: 0.2137, average loss: 2.7632
[09/30 23:14:11 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.78	top5: 96.93	
[09/30 23:14:11 visual_prompt]: Best epoch 91: best metric: 0.925
[09/30 23:14:11 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[09/30 23:14:21 visual_prompt]: Epoch 92 / 100: avg data time: 1.04e-01, avg batch time: 0.5532, average train loss: 0.1684
[09/30 23:14:25 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1672, average loss: 0.1503
[09/30 23:14:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.50	top5: 100.00	
[09/30 23:14:48 visual_prompt]: 	Test 100/356. loss: 3.098, 0.2136 s / batch. (data: 2.84e-05)max mem: 7.80404 GB 
[09/30 23:15:09 visual_prompt]: 	Test 200/356. loss: 2.843, 0.2145 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 23:15:31 visual_prompt]: 	Test 300/356. loss: 2.761, 0.2144 s / batch. (data: 2.55e-05)max mem: 7.80404 GB 
[09/30 23:15:44 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2137, average loss: 2.8967
[09/30 23:15:44 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.74	top5: 97.29	
[09/30 23:15:44 visual_prompt]: Best epoch 92: best metric: 0.935
[09/30 23:15:44 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[09/30 23:15:54 visual_prompt]: Epoch 93 / 100: avg data time: 1.12e-01, avg batch time: 0.5614, average train loss: 0.1544
[09/30 23:15:58 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1669, average loss: 0.1869
[09/30 23:15:58 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.50	top5: 100.00	
[09/30 23:16:21 visual_prompt]: 	Test 100/356. loss: 3.203, 0.2136 s / batch. (data: 2.88e-05)max mem: 7.80404 GB 
[09/30 23:16:42 visual_prompt]: 	Test 200/356. loss: 3.078, 0.2144 s / batch. (data: 3.05e-05)max mem: 7.80404 GB 
[09/30 23:17:03 visual_prompt]: 	Test 300/356. loss: 2.798, 0.2145 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 23:17:17 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2136, average loss: 2.9699
[09/30 23:17:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.20	top5: 97.24	
[09/30 23:17:17 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[09/30 23:17:27 visual_prompt]: Epoch 94 / 100: avg data time: 9.78e-02, avg batch time: 0.5470, average train loss: 0.1413
[09/30 23:17:31 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1667, average loss: 0.1883
[09/30 23:17:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.00	top5: 100.00	
[09/30 23:17:54 visual_prompt]: 	Test 100/356. loss: 3.054, 0.2136 s / batch. (data: 7.46e-05)max mem: 7.80404 GB 
[09/30 23:18:15 visual_prompt]: 	Test 200/356. loss: 3.142, 0.2143 s / batch. (data: 7.51e-05)max mem: 7.80404 GB 
[09/30 23:18:36 visual_prompt]: 	Test 300/356. loss: 2.725, 0.2146 s / batch. (data: 6.29e-05)max mem: 7.80404 GB 
[09/30 23:18:50 visual_prompt]: Inference (test):avg data time: 4.97e-05, avg batch time: 0.2137, average loss: 2.9599
[09/30 23:18:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.36	top5: 96.97	
[09/30 23:18:50 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[09/30 23:19:00 visual_prompt]: Epoch 95 / 100: avg data time: 1.02e-01, avg batch time: 0.5524, average train loss: 0.1278
[09/30 23:19:04 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1668, average loss: 0.1702
[09/30 23:19:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.00	top5: 100.00	
[09/30 23:19:27 visual_prompt]: 	Test 100/356. loss: 3.081, 0.2138 s / batch. (data: 7.96e-05)max mem: 7.80404 GB 
[09/30 23:19:48 visual_prompt]: 	Test 200/356. loss: 3.080, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.80404 GB 
[09/30 23:20:10 visual_prompt]: 	Test 300/356. loss: 2.753, 0.2149 s / batch. (data: 6.37e-05)max mem: 7.80404 GB 
[09/30 23:20:23 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2136, average loss: 2.9332
[09/30 23:20:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.92	top5: 97.15	
[09/30 23:20:23 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[09/30 23:20:33 visual_prompt]: Epoch 96 / 100: avg data time: 1.06e-01, avg batch time: 0.5558, average train loss: 0.1181
[09/30 23:20:37 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1668, average loss: 0.1391
[09/30 23:20:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.50	top5: 100.00	
[09/30 23:21:00 visual_prompt]: 	Test 100/356. loss: 3.120, 0.2138 s / batch. (data: 2.53e-05)max mem: 7.80404 GB 
[09/30 23:21:21 visual_prompt]: 	Test 200/356. loss: 3.120, 0.2149 s / batch. (data: 8.56e-05)max mem: 7.80404 GB 
[09/30 23:21:43 visual_prompt]: 	Test 300/356. loss: 2.820, 0.2148 s / batch. (data: 2.60e-05)max mem: 7.80404 GB 
[09/30 23:21:56 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2138, average loss: 2.9718
[09/30 23:21:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.87	top5: 97.10	
[09/30 23:21:56 visual_prompt]: Best epoch 96: best metric: 0.945
[09/30 23:21:56 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[09/30 23:22:06 visual_prompt]: Epoch 97 / 100: avg data time: 1.10e-01, avg batch time: 0.5592, average train loss: 0.1126
[09/30 23:22:10 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1667, average loss: 0.1447
[09/30 23:22:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 92.50	top5: 100.00	
[09/30 23:22:33 visual_prompt]: 	Test 100/356. loss: 3.109, 0.2141 s / batch. (data: 2.72e-05)max mem: 7.80404 GB 
[09/30 23:22:54 visual_prompt]: 	Test 200/356. loss: 3.190, 0.2144 s / batch. (data: 2.48e-05)max mem: 7.80404 GB 
[09/30 23:23:16 visual_prompt]: 	Test 300/356. loss: 2.826, 0.2150 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 23:23:29 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2137, average loss: 2.9931
[09/30 23:23:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.80	top5: 97.02	
[09/30 23:23:29 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[09/30 23:23:40 visual_prompt]: Epoch 98 / 100: avg data time: 1.09e-01, avg batch time: 0.5584, average train loss: 0.1020
[09/30 23:23:43 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1668, average loss: 0.1351
[09/30 23:23:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.50	top5: 100.00	
[09/30 23:24:06 visual_prompt]: 	Test 100/356. loss: 3.165, 0.2137 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 23:24:28 visual_prompt]: 	Test 200/356. loss: 3.166, 0.2144 s / batch. (data: 6.75e-05)max mem: 7.80404 GB 
[09/30 23:24:49 visual_prompt]: 	Test 300/356. loss: 2.866, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 23:25:02 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2137, average loss: 3.0062
[09/30 23:25:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.76	top5: 97.05	
[09/30 23:25:02 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[09/30 23:25:13 visual_prompt]: Epoch 99 / 100: avg data time: 1.01e-01, avg batch time: 0.5516, average train loss: 0.1051
[09/30 23:25:16 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.1669, average loss: 0.1352
[09/30 23:25:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.50	top5: 100.00	
[09/30 23:25:39 visual_prompt]: 	Test 100/356. loss: 3.181, 0.2139 s / batch. (data: 2.79e-05)max mem: 7.80404 GB 
[09/30 23:26:01 visual_prompt]: 	Test 200/356. loss: 3.161, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.80404 GB 
[09/30 23:26:22 visual_prompt]: 	Test 300/356. loss: 2.865, 0.2147 s / batch. (data: 2.77e-05)max mem: 7.80404 GB 
[09/30 23:26:35 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2138, average loss: 3.0124
[09/30 23:26:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.82	top5: 97.07	
[09/30 23:26:36 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[09/30 23:26:46 visual_prompt]: Epoch 100 / 100: avg data time: 1.08e-01, avg batch time: 0.5570, average train loss: 0.1120
[09/30 23:26:49 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1666, average loss: 0.1362
[09/30 23:26:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.50	top5: 100.00	
[09/30 23:27:12 visual_prompt]: 	Test 100/356. loss: 3.185, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.80404 GB 
[09/30 23:27:34 visual_prompt]: 	Test 200/356. loss: 3.164, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.80404 GB 
[09/30 23:27:55 visual_prompt]: 	Test 300/356. loss: 2.861, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.80404 GB 
[09/30 23:28:09 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2137, average loss: 3.0160
[09/30 23:28:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.85	top5: 97.06	
[09/30 23:28:09 visual_prompt]: Rank of current process: 0. World size: 1
[09/30 23:28:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/30 23:28:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/30 23:28:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/30 23:28:09 visual_prompt]: Training with config:
[09/30 23:28:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dmlab/sup_vitb16_imagenet21k/prompt50/crop224/test/seed875/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 875, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dmlab', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 6, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/30 23:28:09 visual_prompt]: Loading training data...
[09/30 23:28:09 visual_prompt]: Constructing vtab-dmlab dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 23:28:10 visual_prompt]: Number of images: 1000
[09/30 23:28:10 visual_prompt]: Number of classes: 6 / 6
[09/30 23:28:10 visual_prompt]: Loading validation data...
[09/30 23:28:10 visual_prompt]: Constructing vtab-dmlab dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 23:28:11 visual_prompt]: Number of images: 200
[09/30 23:28:11 visual_prompt]: Number of classes: 6 / 6
[09/30 23:28:11 visual_prompt]: Loading test data...
[09/30 23:28:11 visual_prompt]: Constructing vtab-dmlab dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split test, from visual_prompt_tuning/data_path/dmlab/2.0.1
[09/30 23:28:45 visual_prompt]: Number of images: 22735
[09/30 23:28:45 visual_prompt]: Number of classes: 6 / 6
[09/30 23:28:45 visual_prompt]: Constructing models...
[09/30 23:28:48 visual_prompt]: Total Parameters: 86264070	 Gradient Parameters: 465414
[09/30 23:28:48 visual_prompt]: tuned percent:0.540
[09/30 23:28:48 visual_prompt]: Device used for model: 0
[09/30 23:28:48 visual_prompt]: Setting up Evaluator...
[09/30 23:28:48 visual_prompt]: Setting up Trainer...
[09/30 23:28:48 visual_prompt]: 	Setting up the optimizer...
[09/30 23:28:48 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/30 23:28:58 visual_prompt]: Epoch 1 / 100: avg data time: 1.04e-01, avg batch time: 0.5488, average train loss: 2.2580
[09/30 23:29:01 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1648, average loss: 2.2543
[09/30 23:29:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 81.00	
[09/30 23:29:24 visual_prompt]: 	Test 100/356. loss: 2.156, 0.2118 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[09/30 23:29:46 visual_prompt]: 	Test 200/356. loss: 2.215, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[09/30 23:30:07 visual_prompt]: 	Test 300/356. loss: 2.147, 0.2137 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[09/30 23:30:20 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.2126, average loss: 2.2353
[09/30 23:30:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 14.32	top5: 82.07	
[09/30 23:30:20 visual_prompt]: Best epoch 1: best metric: 0.145
[09/30 23:30:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[09/30 23:30:31 visual_prompt]: Epoch 2 / 100: avg data time: 1.01e-01, avg batch time: 0.5508, average train loss: 2.3211
[09/30 23:30:34 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1663, average loss: 1.9878
[09/30 23:30:34 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.00	
[09/30 23:30:57 visual_prompt]: 	Test 100/356. loss: 1.928, 0.2137 s / batch. (data: 8.11e-05)max mem: 7.81207 GB 
[09/30 23:31:19 visual_prompt]: 	Test 200/356. loss: 2.028, 0.2140 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[09/30 23:31:40 visual_prompt]: 	Test 300/356. loss: 1.919, 0.2145 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[09/30 23:31:53 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2135, average loss: 1.9830
[09/30 23:31:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 84.80	
[09/30 23:31:54 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[09/30 23:32:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e-01, avg batch time: 0.5543, average train loss: 1.8614
[09/30 23:32:07 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1668, average loss: 1.8933
[09/30 23:32:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.00	
[09/30 23:32:30 visual_prompt]: 	Test 100/356. loss: 1.801, 0.2141 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[09/30 23:32:52 visual_prompt]: 	Test 200/356. loss: 1.802, 0.2144 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:33:13 visual_prompt]: 	Test 300/356. loss: 1.783, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[09/30 23:33:27 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2137, average loss: 1.8347
[09/30 23:33:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.36	top5: 85.30	
[09/30 23:33:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[09/30 23:33:37 visual_prompt]: Epoch 4 / 100: avg data time: 1.09e-01, avg batch time: 0.5580, average train loss: 1.8005
[09/30 23:33:40 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1666, average loss: 1.8559
[09/30 23:33:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.50	
[09/30 23:34:04 visual_prompt]: 	Test 100/356. loss: 1.798, 0.2142 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[09/30 23:34:25 visual_prompt]: 	Test 200/356. loss: 1.680, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[09/30 23:34:46 visual_prompt]: 	Test 300/356. loss: 1.748, 0.2142 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[09/30 23:35:00 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2138, average loss: 1.7756
[09/30 23:35:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.86	
[09/30 23:35:00 visual_prompt]: Best epoch 4: best metric: 0.155
[09/30 23:35:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[09/30 23:35:10 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e-01, avg batch time: 0.5541, average train loss: 1.7770
[09/30 23:35:13 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1668, average loss: 1.8237
[09/30 23:35:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.00	top5: 84.00	
[09/30 23:35:37 visual_prompt]: 	Test 100/356. loss: 1.818, 0.2142 s / batch. (data: 1.25e-04)max mem: 7.81207 GB 
[09/30 23:35:58 visual_prompt]: 	Test 200/356. loss: 1.756, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[09/30 23:36:20 visual_prompt]: 	Test 300/356. loss: 1.788, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:36:33 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2138, average loss: 1.7810
[09/30 23:36:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.88	top5: 88.42	
[09/30 23:36:33 visual_prompt]: Best epoch 5: best metric: 0.240
[09/30 23:36:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[09/30 23:36:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e-01, avg batch time: 0.5667, average train loss: 1.7902
[09/30 23:36:47 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1668, average loss: 1.7728
[09/30 23:36:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.00	top5: 92.50	
[09/30 23:37:10 visual_prompt]: 	Test 100/356. loss: 1.735, 0.2133 s / batch. (data: 4.20e-05)max mem: 7.81207 GB 
[09/30 23:37:31 visual_prompt]: 	Test 200/356. loss: 1.609, 0.2141 s / batch. (data: 3.10e-05)max mem: 7.81207 GB 
[09/30 23:37:53 visual_prompt]: 	Test 300/356. loss: 1.647, 0.2148 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[09/30 23:38:06 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2137, average loss: 1.6822
[09/30 23:38:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.15	top5: 93.56	
[09/30 23:38:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[09/30 23:38:16 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e-01, avg batch time: 0.5507, average train loss: 1.8943
[09/30 23:38:20 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1665, average loss: 1.8210
[09/30 23:38:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.00	top5: 84.00	
[09/30 23:38:43 visual_prompt]: 	Test 100/356. loss: 1.776, 0.2136 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[09/30 23:39:05 visual_prompt]: 	Test 200/356. loss: 1.751, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[09/30 23:39:26 visual_prompt]: 	Test 300/356. loss: 1.707, 0.2144 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[09/30 23:39:40 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2137, average loss: 1.7787
[09/30 23:39:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.18	top5: 84.55	
[09/30 23:39:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[09/30 23:39:50 visual_prompt]: Epoch 8 / 100: avg data time: 1.08e-01, avg batch time: 0.5574, average train loss: 1.8169
[09/30 23:39:53 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1666, average loss: 1.8182
[09/30 23:39:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.50	top5: 84.00	
[09/30 23:40:17 visual_prompt]: 	Test 100/356. loss: 1.736, 0.2138 s / batch. (data: 8.56e-05)max mem: 7.81207 GB 
[09/30 23:40:38 visual_prompt]: 	Test 200/356. loss: 1.737, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[09/30 23:41:00 visual_prompt]: 	Test 300/356. loss: 1.609, 0.2143 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[09/30 23:41:13 visual_prompt]: Inference (test):avg data time: 7.69e-05, avg batch time: 0.2137, average loss: 1.7493
[09/30 23:41:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.14	top5: 85.40	
[09/30 23:41:13 visual_prompt]: Best epoch 8: best metric: 0.245
[09/30 23:41:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[09/30 23:41:23 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e-01, avg batch time: 0.5559, average train loss: 1.7731
[09/30 23:41:27 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1667, average loss: 1.7314
[09/30 23:41:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.50	top5: 84.00	
[09/30 23:41:50 visual_prompt]: 	Test 100/356. loss: 1.604, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[09/30 23:42:11 visual_prompt]: 	Test 200/356. loss: 1.551, 0.2146 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[09/30 23:42:33 visual_prompt]: 	Test 300/356. loss: 1.635, 0.2147 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[09/30 23:42:46 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2137, average loss: 1.6315
[09/30 23:42:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.93	top5: 88.45	
[09/30 23:42:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[09/30 23:42:56 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e-01, avg batch time: 0.5586, average train loss: 1.8648
[09/30 23:43:00 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.1665, average loss: 1.9213
[09/30 23:43:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 89.00	
[09/30 23:43:23 visual_prompt]: 	Test 100/356. loss: 1.957, 0.2139 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[09/30 23:43:44 visual_prompt]: 	Test 200/356. loss: 2.013, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[09/30 23:44:06 visual_prompt]: 	Test 300/356. loss: 1.832, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[09/30 23:44:19 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2136, average loss: 1.9274
[09/30 23:44:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.98	top5: 89.08	
[09/30 23:44:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[09/30 23:44:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e-01, avg batch time: 0.5559, average train loss: 1.7510
[09/30 23:44:33 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1665, average loss: 1.7681
[09/30 23:44:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 19.00	top5: 93.00	
[09/30 23:44:56 visual_prompt]: 	Test 100/356. loss: 1.733, 0.2135 s / batch. (data: 1.10e-04)max mem: 7.81207 GB 
[09/30 23:45:18 visual_prompt]: 	Test 200/356. loss: 1.689, 0.2141 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[09/30 23:45:39 visual_prompt]: 	Test 300/356. loss: 1.693, 0.2147 s / batch. (data: 8.46e-05)max mem: 7.81207 GB 
[09/30 23:45:53 visual_prompt]: Inference (test):avg data time: 3.75e-05, avg batch time: 0.2137, average loss: 1.7267
[09/30 23:45:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.06	top5: 92.87	
[09/30 23:45:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[09/30 23:46:03 visual_prompt]: Epoch 12 / 100: avg data time: 9.97e-02, avg batch time: 0.5502, average train loss: 1.6965
[09/30 23:46:06 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1665, average loss: 2.3851
[09/30 23:46:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 88.00	
[09/30 23:46:29 visual_prompt]: 	Test 100/356. loss: 2.291, 0.2135 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:46:51 visual_prompt]: 	Test 200/356. loss: 1.968, 0.2143 s / batch. (data: 7.82e-05)max mem: 7.81207 GB 
[09/30 23:47:12 visual_prompt]: 	Test 300/356. loss: 2.150, 0.2148 s / batch. (data: 8.27e-05)max mem: 7.81207 GB 
[09/30 23:47:26 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2136, average loss: 2.2481
[09/30 23:47:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.93	top5: 87.79	
[09/30 23:47:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[09/30 23:47:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.12e-01, avg batch time: 0.5624, average train loss: 1.6413
[09/30 23:47:40 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1664, average loss: 1.4498
[09/30 23:47:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 35.00	top5: 98.00	
[09/30 23:48:03 visual_prompt]: 	Test 100/356. loss: 1.374, 0.2137 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[09/30 23:48:24 visual_prompt]: 	Test 200/356. loss: 1.566, 0.2144 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[09/30 23:48:46 visual_prompt]: 	Test 300/356. loss: 1.388, 0.2145 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[09/30 23:48:59 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2137, average loss: 1.4450
[09/30 23:48:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.34	top5: 97.48	
[09/30 23:48:59 visual_prompt]: Best epoch 13: best metric: 0.350
[09/30 23:48:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[09/30 23:49:09 visual_prompt]: Epoch 14 / 100: avg data time: 1.13e-01, avg batch time: 0.5638, average train loss: 1.9144
[09/30 23:49:13 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1666, average loss: 1.8884
[09/30 23:49:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.00	top5: 84.00	
[09/30 23:49:36 visual_prompt]: 	Test 100/356. loss: 1.809, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[09/30 23:49:57 visual_prompt]: 	Test 200/356. loss: 1.701, 0.2139 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[09/30 23:50:19 visual_prompt]: 	Test 300/356. loss: 1.747, 0.2146 s / batch. (data: 3.27e-05)max mem: 7.81207 GB 
[09/30 23:50:32 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2137, average loss: 1.8187
[09/30 23:50:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.59	top5: 85.40	
[09/30 23:50:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[09/30 23:50:42 visual_prompt]: Epoch 15 / 100: avg data time: 9.85e-02, avg batch time: 0.5481, average train loss: 1.6012
[09/30 23:50:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1667, average loss: 1.8648
[09/30 23:50:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 28.00	top5: 97.50	
[09/30 23:51:09 visual_prompt]: 	Test 100/356. loss: 1.908, 0.2133 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[09/30 23:51:30 visual_prompt]: 	Test 200/356. loss: 1.566, 0.2147 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:51:52 visual_prompt]: 	Test 300/356. loss: 1.751, 0.2144 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[09/30 23:52:05 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2137, average loss: 1.8064
[09/30 23:52:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.99	top5: 96.19	
[09/30 23:52:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[09/30 23:52:15 visual_prompt]: Epoch 16 / 100: avg data time: 9.64e-02, avg batch time: 0.5465, average train loss: 1.5543
[09/30 23:52:19 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1669, average loss: 1.4608
[09/30 23:52:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.50	top5: 97.00	
[09/30 23:52:42 visual_prompt]: 	Test 100/356. loss: 1.415, 0.2141 s / batch. (data: 3.29e-05)max mem: 7.81207 GB 
[09/30 23:53:03 visual_prompt]: 	Test 200/356. loss: 1.671, 0.2140 s / batch. (data: 2.36e-05)max mem: 7.81207 GB 
[09/30 23:53:25 visual_prompt]: 	Test 300/356. loss: 1.431, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:53:38 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2136, average loss: 1.4893
[09/30 23:53:38 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.66	top5: 96.70	
[09/30 23:53:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[09/30 23:53:48 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e-01, avg batch time: 0.5518, average train loss: 1.5197
[09/30 23:53:52 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1665, average loss: 1.6141
[09/30 23:53:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.00	top5: 96.50	
[09/30 23:54:15 visual_prompt]: 	Test 100/356. loss: 1.565, 0.2139 s / batch. (data: 8.92e-05)max mem: 7.81207 GB 
[09/30 23:54:37 visual_prompt]: 	Test 200/356. loss: 1.821, 0.2140 s / batch. (data: 8.51e-05)max mem: 7.81207 GB 
[09/30 23:54:58 visual_prompt]: 	Test 300/356. loss: 1.522, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[09/30 23:55:12 visual_prompt]: Inference (test):avg data time: 6.84e-05, avg batch time: 0.2136, average loss: 1.6140
[09/30 23:55:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.72	top5: 95.28	
[09/30 23:55:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[09/30 23:55:22 visual_prompt]: Epoch 18 / 100: avg data time: 1.01e-01, avg batch time: 0.5526, average train loss: 1.4949
[09/30 23:55:25 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1665, average loss: 1.6139
[09/30 23:55:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 96.00	
[09/30 23:55:48 visual_prompt]: 	Test 100/356. loss: 1.715, 0.2151 s / batch. (data: 7.96e-05)max mem: 7.81207 GB 
[09/30 23:56:10 visual_prompt]: 	Test 200/356. loss: 1.821, 0.2138 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[09/30 23:56:31 visual_prompt]: 	Test 300/356. loss: 1.564, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[09/30 23:56:44 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2136, average loss: 1.6552
[09/30 23:56:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.40	top5: 93.97	
[09/30 23:56:45 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[09/30 23:56:55 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e-01, avg batch time: 0.5571, average train loss: 1.5639
[09/30 23:56:59 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1694, average loss: 1.4024
[09/30 23:56:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 99.50	
[09/30 23:57:22 visual_prompt]: 	Test 100/356. loss: 1.390, 0.2134 s / batch. (data: 6.20e-05)max mem: 7.81207 GB 
[09/30 23:57:43 visual_prompt]: 	Test 200/356. loss: 1.377, 0.2144 s / batch. (data: 7.30e-05)max mem: 7.81207 GB 
[09/30 23:58:04 visual_prompt]: 	Test 300/356. loss: 1.302, 0.2150 s / batch. (data: 6.72e-05)max mem: 7.81207 GB 
[09/30 23:58:18 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2136, average loss: 1.4023
[09/30 23:58:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.10	top5: 97.99	
[09/30 23:58:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[09/30 23:58:28 visual_prompt]: Epoch 20 / 100: avg data time: 1.01e-01, avg batch time: 0.5521, average train loss: 1.4647
[09/30 23:58:31 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 1.5902
[09/30 23:58:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 98.50	
[09/30 23:58:55 visual_prompt]: 	Test 100/356. loss: 1.527, 0.2140 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[09/30 23:59:16 visual_prompt]: 	Test 200/356. loss: 1.439, 0.2144 s / batch. (data: 3.29e-05)max mem: 7.81207 GB 
[09/30 23:59:37 visual_prompt]: 	Test 300/356. loss: 1.476, 0.2143 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[09/30 23:59:51 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2137, average loss: 1.6510
[09/30 23:59:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.67	top5: 97.39	
[09/30 23:59:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/01 00:00:01 visual_prompt]: Epoch 21 / 100: avg data time: 1.11e-01, avg batch time: 0.5608, average train loss: 1.4934
[10/01 00:00:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1668, average loss: 1.4580
[10/01 00:00:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 31.50	top5: 96.50	
[10/01 00:00:28 visual_prompt]: 	Test 100/356. loss: 1.358, 0.2136 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 00:00:49 visual_prompt]: 	Test 200/356. loss: 1.376, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:01:10 visual_prompt]: 	Test 300/356. loss: 1.361, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 00:01:24 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2136, average loss: 1.4521
[10/01 00:01:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.14	top5: 97.30	
[10/01 00:01:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/01 00:01:34 visual_prompt]: Epoch 22 / 100: avg data time: 1.10e-01, avg batch time: 0.5592, average train loss: 1.4397
[10/01 00:01:38 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1676, average loss: 1.4810
[10/01 00:01:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.50	top5: 97.50	
[10/01 00:02:01 visual_prompt]: 	Test 100/356. loss: 1.385, 0.2134 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 00:02:22 visual_prompt]: 	Test 200/356. loss: 1.448, 0.2141 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 00:02:44 visual_prompt]: 	Test 300/356. loss: 1.383, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:02:57 visual_prompt]: Inference (test):avg data time: 9.70e-05, avg batch time: 0.2139, average loss: 1.4516
[10/01 00:02:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.51	top5: 96.93	
[10/01 00:02:57 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/01 00:03:07 visual_prompt]: Epoch 23 / 100: avg data time: 1.01e-01, avg batch time: 0.5513, average train loss: 1.5471
[10/01 00:03:11 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1675, average loss: 1.5707
[10/01 00:03:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 26.50	top5: 96.00	
[10/01 00:03:34 visual_prompt]: 	Test 100/356. loss: 1.489, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:03:55 visual_prompt]: 	Test 200/356. loss: 1.624, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:04:17 visual_prompt]: 	Test 300/356. loss: 1.490, 0.2139 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:04:30 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2139, average loss: 1.5454
[10/01 00:04:30 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.48	top5: 94.95	
[10/01 00:04:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/01 00:04:40 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e-01, avg batch time: 0.5555, average train loss: 1.5231
[10/01 00:04:44 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1677, average loss: 1.3073
[10/01 00:04:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.00	top5: 100.00	
[10/01 00:05:07 visual_prompt]: 	Test 100/356. loss: 1.282, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 00:05:29 visual_prompt]: 	Test 200/356. loss: 1.367, 0.2137 s / batch. (data: 7.68e-05)max mem: 7.81207 GB 
[10/01 00:05:50 visual_prompt]: 	Test 300/356. loss: 1.304, 0.2142 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 00:06:03 visual_prompt]: Inference (test):avg data time: 5.13e-05, avg batch time: 0.2138, average loss: 1.3749
[10/01 00:06:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.28	top5: 97.54	
[10/01 00:06:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/01 00:06:14 visual_prompt]: Epoch 25 / 100: avg data time: 1.10e-01, avg batch time: 0.5590, average train loss: 1.4293
[10/01 00:06:18 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 1.5203
[10/01 00:06:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.00	top5: 97.00	
[10/01 00:06:41 visual_prompt]: 	Test 100/356. loss: 1.433, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 00:07:02 visual_prompt]: 	Test 200/356. loss: 1.482, 0.2134 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:07:24 visual_prompt]: 	Test 300/356. loss: 1.375, 0.2148 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:07:37 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2139, average loss: 1.4949
[10/01 00:07:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.29	top5: 96.50	
[10/01 00:07:37 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/01 00:07:47 visual_prompt]: Epoch 26 / 100: avg data time: 1.00e-01, avg batch time: 0.5521, average train loss: 1.4509
[10/01 00:07:51 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 2.0185
[10/01 00:07:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.00	top5: 90.50	
[10/01 00:08:14 visual_prompt]: 	Test 100/356. loss: 1.965, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:08:35 visual_prompt]: 	Test 200/356. loss: 2.408, 0.2142 s / batch. (data: 3.74e-05)max mem: 7.81207 GB 
[10/01 00:08:57 visual_prompt]: 	Test 300/356. loss: 1.967, 0.2148 s / batch. (data: 6.84e-05)max mem: 7.81207 GB 
[10/01 00:09:10 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2138, average loss: 2.0878
[10/01 00:09:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.38	top5: 87.15	
[10/01 00:09:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/01 00:09:20 visual_prompt]: Epoch 27 / 100: avg data time: 1.10e-01, avg batch time: 0.5602, average train loss: 1.4456
[10/01 00:09:24 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1673, average loss: 1.4325
[10/01 00:09:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 96.50	
[10/01 00:09:47 visual_prompt]: 	Test 100/356. loss: 1.365, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 00:10:08 visual_prompt]: 	Test 200/356. loss: 1.361, 0.2144 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:10:30 visual_prompt]: 	Test 300/356. loss: 1.287, 0.2148 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:10:43 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2138, average loss: 1.3925
[10/01 00:10:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.73	top5: 97.78	
[10/01 00:10:43 visual_prompt]: Best epoch 27: best metric: 0.380
[10/01 00:10:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/01 00:10:54 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e-01, avg batch time: 0.5588, average train loss: 1.4101
[10/01 00:10:57 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1673, average loss: 1.2590
[10/01 00:10:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[10/01 00:11:20 visual_prompt]: 	Test 100/356. loss: 1.253, 0.2137 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 00:11:42 visual_prompt]: 	Test 200/356. loss: 1.368, 0.2136 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 00:12:03 visual_prompt]: 	Test 300/356. loss: 1.347, 0.2141 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:12:17 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2137, average loss: 1.3349
[10/01 00:12:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.70	top5: 98.21	
[10/01 00:12:17 visual_prompt]: Best epoch 28: best metric: 0.445
[10/01 00:12:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/01 00:12:27 visual_prompt]: Epoch 29 / 100: avg data time: 1.15e-01, avg batch time: 0.5639, average train loss: 1.4129
[10/01 00:12:30 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1673, average loss: 1.6101
[10/01 00:12:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 96.50	
[10/01 00:12:54 visual_prompt]: 	Test 100/356. loss: 1.530, 0.2135 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:13:15 visual_prompt]: 	Test 200/356. loss: 1.960, 0.2142 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:13:37 visual_prompt]: 	Test 300/356. loss: 1.692, 0.2147 s / batch. (data: 7.72e-05)max mem: 7.81207 GB 
[10/01 00:13:50 visual_prompt]: Inference (test):avg data time: 3.77e-05, avg batch time: 0.2137, average loss: 1.6885
[10/01 00:13:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.30	top5: 94.67	
[10/01 00:13:50 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/01 00:14:00 visual_prompt]: Epoch 30 / 100: avg data time: 1.01e-01, avg batch time: 0.5519, average train loss: 1.4281
[10/01 00:14:04 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1676, average loss: 1.4412
[10/01 00:14:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 35.50	top5: 96.00	
[10/01 00:14:27 visual_prompt]: 	Test 100/356. loss: 1.323, 0.2137 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 00:14:48 visual_prompt]: 	Test 200/356. loss: 1.378, 0.2146 s / batch. (data: 9.68e-05)max mem: 7.81207 GB 
[10/01 00:15:10 visual_prompt]: 	Test 300/356. loss: 1.440, 0.2141 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:15:23 visual_prompt]: Inference (test):avg data time: 3.85e-05, avg batch time: 0.2139, average loss: 1.4423
[10/01 00:15:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.09	top5: 96.45	
[10/01 00:15:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/01 00:15:33 visual_prompt]: Epoch 31 / 100: avg data time: 1.13e-01, avg batch time: 0.5634, average train loss: 1.4400
[10/01 00:15:37 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1672, average loss: 1.3099
[10/01 00:15:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 98.50	
[10/01 00:16:00 visual_prompt]: 	Test 100/356. loss: 1.299, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 00:16:21 visual_prompt]: 	Test 200/356. loss: 1.520, 0.2141 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:16:43 visual_prompt]: 	Test 300/356. loss: 1.285, 0.2147 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:16:56 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.2138, average loss: 1.3564
[10/01 00:16:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.70	top5: 97.43	
[10/01 00:16:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/01 00:17:07 visual_prompt]: Epoch 32 / 100: avg data time: 1.14e-01, avg batch time: 0.5644, average train loss: 1.4458
[10/01 00:17:10 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1673, average loss: 1.5244
[10/01 00:17:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 95.00	
[10/01 00:17:33 visual_prompt]: 	Test 100/356. loss: 1.388, 0.2136 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 00:17:55 visual_prompt]: 	Test 200/356. loss: 1.545, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 00:18:16 visual_prompt]: 	Test 300/356. loss: 1.560, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 00:18:29 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2137, average loss: 1.5485
[10/01 00:18:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.22	top5: 95.87	
[10/01 00:18:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/01 00:18:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.03e-01, avg batch time: 0.5542, average train loss: 1.5812
[10/01 00:18:43 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1674, average loss: 1.5452
[10/01 00:18:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 26.50	top5: 98.00	
[10/01 00:19:06 visual_prompt]: 	Test 100/356. loss: 1.514, 0.2132 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:19:28 visual_prompt]: 	Test 200/356. loss: 1.639, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 00:19:49 visual_prompt]: 	Test 300/356. loss: 1.571, 0.2142 s / batch. (data: 3.43e-05)max mem: 7.81207 GB 
[10/01 00:20:02 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2137, average loss: 1.5645
[10/01 00:20:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.65	top5: 95.64	
[10/01 00:20:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/01 00:20:13 visual_prompt]: Epoch 34 / 100: avg data time: 1.02e-01, avg batch time: 0.5542, average train loss: 1.4774
[10/01 00:20:16 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1674, average loss: 1.4628
[10/01 00:20:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.50	top5: 96.00	
[10/01 00:20:39 visual_prompt]: 	Test 100/356. loss: 1.375, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:21:01 visual_prompt]: 	Test 200/356. loss: 1.333, 0.2138 s / batch. (data: 3.70e-05)max mem: 7.81207 GB 
[10/01 00:21:22 visual_prompt]: 	Test 300/356. loss: 1.343, 0.2144 s / batch. (data: 4.86e-05)max mem: 7.81207 GB 
[10/01 00:21:36 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2136, average loss: 1.4234
[10/01 00:21:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.26	top5: 97.38	
[10/01 00:21:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/01 00:21:46 visual_prompt]: Epoch 35 / 100: avg data time: 1.10e-01, avg batch time: 0.5599, average train loss: 1.3818
[10/01 00:21:49 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1673, average loss: 1.2852
[10/01 00:21:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.00	
[10/01 00:22:13 visual_prompt]: 	Test 100/356. loss: 1.330, 0.2134 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:22:34 visual_prompt]: 	Test 200/356. loss: 1.309, 0.2142 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 00:22:55 visual_prompt]: 	Test 300/356. loss: 1.287, 0.2149 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:23:09 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2137, average loss: 1.3510
[10/01 00:23:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.35	top5: 97.69	
[10/01 00:23:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[10/01 00:23:19 visual_prompt]: Epoch 36 / 100: avg data time: 1.10e-01, avg batch time: 0.5590, average train loss: 1.2933
[10/01 00:23:23 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1674, average loss: 1.2167
[10/01 00:23:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.00	top5: 98.50	
[10/01 00:23:46 visual_prompt]: 	Test 100/356. loss: 1.196, 0.2140 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 00:24:07 visual_prompt]: 	Test 200/356. loss: 1.270, 0.2139 s / batch. (data: 8.01e-05)max mem: 7.81207 GB 
[10/01 00:24:29 visual_prompt]: 	Test 300/356. loss: 1.273, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:24:42 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2137, average loss: 1.2788
[10/01 00:24:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.06	top5: 98.28	
[10/01 00:24:42 visual_prompt]: Best epoch 36: best metric: 0.470
[10/01 00:24:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[10/01 00:24:52 visual_prompt]: Epoch 37 / 100: avg data time: 1.03e-01, avg batch time: 0.5523, average train loss: 1.2783
[10/01 00:24:56 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1675, average loss: 1.2462
[10/01 00:24:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 99.50	
[10/01 00:25:19 visual_prompt]: 	Test 100/356. loss: 1.292, 0.2139 s / batch. (data: 3.70e-05)max mem: 7.81207 GB 
[10/01 00:25:40 visual_prompt]: 	Test 200/356. loss: 1.563, 0.2143 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 00:26:02 visual_prompt]: 	Test 300/356. loss: 1.329, 0.2142 s / batch. (data: 6.87e-05)max mem: 7.81207 GB 
[10/01 00:26:15 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2138, average loss: 1.3762
[10/01 00:26:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.80	top5: 98.21	
[10/01 00:26:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[10/01 00:26:26 visual_prompt]: Epoch 38 / 100: avg data time: 1.02e-01, avg batch time: 0.5515, average train loss: 1.3541
[10/01 00:26:29 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1674, average loss: 1.6821
[10/01 00:26:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.00	top5: 96.50	
[10/01 00:26:52 visual_prompt]: 	Test 100/356. loss: 1.537, 0.2138 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 00:27:14 visual_prompt]: 	Test 200/356. loss: 1.459, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 00:27:35 visual_prompt]: 	Test 300/356. loss: 1.530, 0.2143 s / batch. (data: 7.25e-05)max mem: 7.81207 GB 
[10/01 00:27:49 visual_prompt]: Inference (test):avg data time: 4.82e-05, avg batch time: 0.2137, average loss: 1.5819
[10/01 00:27:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.54	top5: 96.52	
[10/01 00:27:49 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[10/01 00:27:59 visual_prompt]: Epoch 39 / 100: avg data time: 9.96e-02, avg batch time: 0.5499, average train loss: 1.3616
[10/01 00:28:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1672, average loss: 1.3912
[10/01 00:28:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 35.00	top5: 99.00	
[10/01 00:28:25 visual_prompt]: 	Test 100/356. loss: 1.493, 0.2135 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 00:28:47 visual_prompt]: 	Test 200/356. loss: 1.711, 0.2142 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 00:29:08 visual_prompt]: 	Test 300/356. loss: 1.562, 0.2140 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 00:29:22 visual_prompt]: Inference (test):avg data time: 6.48e-05, avg batch time: 0.2137, average loss: 1.5294
[10/01 00:29:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.47	top5: 97.82	
[10/01 00:29:22 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[10/01 00:29:32 visual_prompt]: Epoch 40 / 100: avg data time: 1.00e-01, avg batch time: 0.5513, average train loss: 1.4133
[10/01 00:29:35 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1675, average loss: 1.1608
[10/01 00:29:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 99.00	
[10/01 00:29:59 visual_prompt]: 	Test 100/356. loss: 1.184, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 00:30:20 visual_prompt]: 	Test 200/356. loss: 1.395, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 00:30:41 visual_prompt]: 	Test 300/356. loss: 1.279, 0.2140 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:30:55 visual_prompt]: Inference (test):avg data time: 8.49e-05, avg batch time: 0.2137, average loss: 1.3135
[10/01 00:30:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.12	top5: 97.87	
[10/01 00:30:55 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[10/01 00:31:05 visual_prompt]: Epoch 41 / 100: avg data time: 1.07e-01, avg batch time: 0.5575, average train loss: 1.4700
[10/01 00:31:09 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1674, average loss: 1.3261
[10/01 00:31:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 97.50	
[10/01 00:31:32 visual_prompt]: 	Test 100/356. loss: 1.235, 0.2134 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 00:31:53 visual_prompt]: 	Test 200/356. loss: 1.250, 0.2144 s / batch. (data: 2.36e-05)max mem: 7.81207 GB 
[10/01 00:32:15 visual_prompt]: 	Test 300/356. loss: 1.267, 0.2145 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:32:28 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2137, average loss: 1.3126
[10/01 00:32:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.03	top5: 98.14	
[10/01 00:32:28 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[10/01 00:32:39 visual_prompt]: Epoch 42 / 100: avg data time: 1.17e-01, avg batch time: 0.5666, average train loss: 1.3588
[10/01 00:32:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 1.3486
[10/01 00:32:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 100.00	
[10/01 00:33:05 visual_prompt]: 	Test 100/356. loss: 1.347, 0.2138 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 00:33:27 visual_prompt]: 	Test 200/356. loss: 1.571, 0.2139 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 00:33:48 visual_prompt]: 	Test 300/356. loss: 1.277, 0.2146 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 00:34:02 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2137, average loss: 1.4035
[10/01 00:34:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.81	top5: 98.19	
[10/01 00:34:02 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[10/01 00:34:12 visual_prompt]: Epoch 43 / 100: avg data time: 1.02e-01, avg batch time: 0.5528, average train loss: 1.3015
[10/01 00:34:15 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 1.2789
[10/01 00:34:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 99.00	
[10/01 00:34:39 visual_prompt]: 	Test 100/356. loss: 1.334, 0.2132 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:35:00 visual_prompt]: 	Test 200/356. loss: 1.505, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 00:35:22 visual_prompt]: 	Test 300/356. loss: 1.291, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 00:35:35 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2137, average loss: 1.3727
[10/01 00:35:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.94	top5: 97.42	
[10/01 00:35:35 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[10/01 00:35:45 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e-01, avg batch time: 0.5547, average train loss: 1.2777
[10/01 00:35:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1674, average loss: 1.2645
[10/01 00:35:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.50	top5: 98.50	
[10/01 00:36:12 visual_prompt]: 	Test 100/356. loss: 1.293, 0.2142 s / batch. (data: 6.79e-05)max mem: 7.81207 GB 
[10/01 00:36:33 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2138 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 00:36:55 visual_prompt]: 	Test 300/356. loss: 1.283, 0.2142 s / batch. (data: 6.56e-05)max mem: 7.81207 GB 
[10/01 00:37:08 visual_prompt]: Inference (test):avg data time: 1.02e-04, avg batch time: 0.2138, average loss: 1.3653
[10/01 00:37:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.39	top5: 97.78	
[10/01 00:37:08 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[10/01 00:37:19 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e-01, avg batch time: 0.5557, average train loss: 1.2912
[10/01 00:37:22 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1672, average loss: 1.3467
[10/01 00:37:22 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 98.50	
[10/01 00:37:45 visual_prompt]: 	Test 100/356. loss: 1.353, 0.2132 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:38:07 visual_prompt]: 	Test 200/356. loss: 1.679, 0.2139 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 00:38:28 visual_prompt]: 	Test 300/356. loss: 1.319, 0.2141 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:38:41 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2137, average loss: 1.4442
[10/01 00:38:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.18	top5: 96.87	
[10/01 00:38:41 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[10/01 00:38:52 visual_prompt]: Epoch 46 / 100: avg data time: 1.11e-01, avg batch time: 0.5597, average train loss: 1.3050
[10/01 00:38:55 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1674, average loss: 1.2265
[10/01 00:38:55 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.00	top5: 99.00	
[10/01 00:39:18 visual_prompt]: 	Test 100/356. loss: 1.355, 0.2136 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 00:39:40 visual_prompt]: 	Test 200/356. loss: 1.615, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 00:40:01 visual_prompt]: 	Test 300/356. loss: 1.382, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:40:15 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2135, average loss: 1.3836
[10/01 00:40:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.47	top5: 96.70	
[10/01 00:40:15 visual_prompt]: Best epoch 46: best metric: 0.490
[10/01 00:40:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[10/01 00:40:25 visual_prompt]: Epoch 47 / 100: avg data time: 1.08e-01, avg batch time: 0.5575, average train loss: 1.2307
[10/01 00:40:28 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1675, average loss: 1.2920
[10/01 00:40:28 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.50	top5: 98.50	
[10/01 00:40:52 visual_prompt]: 	Test 100/356. loss: 1.390, 0.2134 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 00:41:13 visual_prompt]: 	Test 200/356. loss: 1.442, 0.2142 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[10/01 00:41:34 visual_prompt]: 	Test 300/356. loss: 1.332, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 00:41:48 visual_prompt]: Inference (test):avg data time: 5.04e-05, avg batch time: 0.2136, average loss: 1.3974
[10/01 00:41:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.38	top5: 98.09	
[10/01 00:41:48 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[10/01 00:41:58 visual_prompt]: Epoch 48 / 100: avg data time: 1.12e-01, avg batch time: 0.5621, average train loss: 1.2747
[10/01 00:42:02 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1673, average loss: 1.2697
[10/01 00:42:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 98.50	
[10/01 00:42:25 visual_prompt]: 	Test 100/356. loss: 1.210, 0.2139 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 00:42:46 visual_prompt]: 	Test 200/356. loss: 1.431, 0.2140 s / batch. (data: 2.19e-05)max mem: 7.81207 GB 
[10/01 00:43:08 visual_prompt]: 	Test 300/356. loss: 1.250, 0.2142 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[10/01 00:43:21 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2136, average loss: 1.3543
[10/01 00:43:21 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.85	top5: 97.73	
[10/01 00:43:21 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[10/01 00:43:31 visual_prompt]: Epoch 49 / 100: avg data time: 1.12e-01, avg batch time: 0.5619, average train loss: 1.1723
[10/01 00:43:35 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1674, average loss: 1.0946
[10/01 00:43:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 100.00	
[10/01 00:43:58 visual_prompt]: 	Test 100/356. loss: 1.199, 0.2138 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:44:19 visual_prompt]: 	Test 200/356. loss: 1.395, 0.2142 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 00:44:41 visual_prompt]: 	Test 300/356. loss: 1.189, 0.2146 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 00:44:54 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2136, average loss: 1.3129
[10/01 00:44:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.13	top5: 97.92	
[10/01 00:44:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[10/01 00:45:04 visual_prompt]: Epoch 50 / 100: avg data time: 9.91e-02, avg batch time: 0.5498, average train loss: 1.1687
[10/01 00:45:08 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1674, average loss: 1.3192
[10/01 00:45:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.00	
[10/01 00:45:31 visual_prompt]: 	Test 100/356. loss: 1.363, 0.2133 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 00:45:52 visual_prompt]: 	Test 200/356. loss: 1.462, 0.2139 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 00:46:14 visual_prompt]: 	Test 300/356. loss: 1.463, 0.2148 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 00:46:27 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2137, average loss: 1.4702
[10/01 00:46:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.54	top5: 96.68	
[10/01 00:46:27 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[10/01 00:46:37 visual_prompt]: Epoch 51 / 100: avg data time: 1.01e-01, avg batch time: 0.5516, average train loss: 1.2585
[10/01 00:46:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1682, average loss: 1.1560
[10/01 00:46:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.50	top5: 99.50	
[10/01 00:47:04 visual_prompt]: 	Test 100/356. loss: 1.230, 0.2137 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 00:47:25 visual_prompt]: 	Test 200/356. loss: 1.414, 0.2146 s / batch. (data: 6.58e-05)max mem: 7.81207 GB 
[10/01 00:47:47 visual_prompt]: 	Test 300/356. loss: 1.612, 0.2143 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 00:48:00 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.2137, average loss: 1.4474
[10/01 00:48:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.14	top5: 97.92	
[10/01 00:48:00 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[10/01 00:48:11 visual_prompt]: Epoch 52 / 100: avg data time: 1.15e-01, avg batch time: 0.5642, average train loss: 1.2555
[10/01 00:48:14 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1673, average loss: 1.1216
[10/01 00:48:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.00	
[10/01 00:48:37 visual_prompt]: 	Test 100/356. loss: 1.176, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 00:48:59 visual_prompt]: 	Test 200/356. loss: 1.560, 0.2141 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 00:49:20 visual_prompt]: 	Test 300/356. loss: 1.225, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 00:49:33 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2138, average loss: 1.3164
[10/01 00:49:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.58	top5: 98.19	
[10/01 00:49:34 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[10/01 00:49:44 visual_prompt]: Epoch 53 / 100: avg data time: 1.00e-01, avg batch time: 0.5504, average train loss: 1.2333
[10/01 00:49:47 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.1672, average loss: 1.1932
[10/01 00:49:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 99.50	
[10/01 00:50:10 visual_prompt]: 	Test 100/356. loss: 1.247, 0.2142 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 00:50:32 visual_prompt]: 	Test 200/356. loss: 1.404, 0.2145 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 00:50:53 visual_prompt]: 	Test 300/356. loss: 1.314, 0.2144 s / batch. (data: 9.75e-05)max mem: 7.81207 GB 
[10/01 00:51:07 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2137, average loss: 1.3151
[10/01 00:51:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.96	top5: 98.15	
[10/01 00:51:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[10/01 00:51:17 visual_prompt]: Epoch 54 / 100: avg data time: 1.06e-01, avg batch time: 0.5584, average train loss: 1.1699
[10/01 00:51:20 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1673, average loss: 1.2047
[10/01 00:51:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 99.00	
[10/01 00:51:44 visual_prompt]: 	Test 100/356. loss: 1.398, 0.2140 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 00:52:05 visual_prompt]: 	Test 200/356. loss: 1.549, 0.2140 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 00:52:26 visual_prompt]: 	Test 300/356. loss: 1.540, 0.2145 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 00:52:40 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2137, average loss: 1.4974
[10/01 00:52:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.16	top5: 96.96	
[10/01 00:52:40 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[10/01 00:52:50 visual_prompt]: Epoch 55 / 100: avg data time: 1.05e-01, avg batch time: 0.5546, average train loss: 1.1585
[10/01 00:52:54 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1674, average loss: 1.0863
[10/01 00:52:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.50	top5: 100.00	
[10/01 00:53:17 visual_prompt]: 	Test 100/356. loss: 1.198, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:53:38 visual_prompt]: 	Test 200/356. loss: 1.322, 0.2143 s / batch. (data: 1.05e-04)max mem: 7.81207 GB 
[10/01 00:54:00 visual_prompt]: 	Test 300/356. loss: 1.372, 0.2139 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:54:13 visual_prompt]: Inference (test):avg data time: 4.09e-05, avg batch time: 0.2137, average loss: 1.3203
[10/01 00:54:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.25	top5: 97.69	
[10/01 00:54:13 visual_prompt]: Best epoch 55: best metric: 0.495
[10/01 00:54:13 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[10/01 00:54:23 visual_prompt]: Epoch 56 / 100: avg data time: 1.00e-01, avg batch time: 0.5497, average train loss: 1.1439
[10/01 00:54:27 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1673, average loss: 1.0128
[10/01 00:54:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 99.50	
[10/01 00:54:50 visual_prompt]: 	Test 100/356. loss: 1.306, 0.2133 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 00:55:11 visual_prompt]: 	Test 200/356. loss: 1.337, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 00:55:33 visual_prompt]: 	Test 300/356. loss: 1.304, 0.2140 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 00:55:46 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2137, average loss: 1.3922
[10/01 00:55:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.00	top5: 97.87	
[10/01 00:55:46 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[10/01 00:55:56 visual_prompt]: Epoch 57 / 100: avg data time: 1.02e-01, avg batch time: 0.5534, average train loss: 1.0823
[10/01 00:56:00 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1675, average loss: 1.1165
[10/01 00:56:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[10/01 00:56:23 visual_prompt]: 	Test 100/356. loss: 1.187, 0.2137 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 00:56:44 visual_prompt]: 	Test 200/356. loss: 1.358, 0.2140 s / batch. (data: 7.87e-05)max mem: 7.81207 GB 
[10/01 00:57:06 visual_prompt]: 	Test 300/356. loss: 1.537, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 00:57:19 visual_prompt]: Inference (test):avg data time: 4.07e-05, avg batch time: 0.2146, average loss: 1.4246
[10/01 00:57:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.56	top5: 96.53	
[10/01 00:57:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[10/01 00:57:30 visual_prompt]: Epoch 58 / 100: avg data time: 1.06e-01, avg batch time: 0.5561, average train loss: 1.1237
[10/01 00:57:33 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1675, average loss: 1.1433
[10/01 00:57:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.00	top5: 99.00	
[10/01 00:57:57 visual_prompt]: 	Test 100/356. loss: 1.229, 0.2136 s / batch. (data: 3.43e-05)max mem: 7.81207 GB 
[10/01 00:58:18 visual_prompt]: 	Test 200/356. loss: 1.548, 0.2142 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 00:58:39 visual_prompt]: 	Test 300/356. loss: 1.310, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 00:58:53 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2139, average loss: 1.3363
[10/01 00:58:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.38	top5: 97.65	
[10/01 00:58:53 visual_prompt]: Best epoch 58: best metric: 0.520
[10/01 00:58:53 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[10/01 00:59:03 visual_prompt]: Epoch 59 / 100: avg data time: 1.02e-01, avg batch time: 0.5533, average train loss: 1.1469
[10/01 00:59:07 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1677, average loss: 1.1371
[10/01 00:59:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 98.50	
[10/01 00:59:30 visual_prompt]: 	Test 100/356. loss: 1.424, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 00:59:51 visual_prompt]: 	Test 200/356. loss: 1.966, 0.2142 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 01:00:13 visual_prompt]: 	Test 300/356. loss: 1.378, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:00:26 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2139, average loss: 1.5470
[10/01 01:00:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.72	top5: 96.38	
[10/01 01:00:26 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[10/01 01:00:36 visual_prompt]: Epoch 60 / 100: avg data time: 1.01e-01, avg batch time: 0.5513, average train loss: 1.1590
[10/01 01:00:40 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1674, average loss: 1.1699
[10/01 01:00:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.00	top5: 99.50	
[10/01 01:01:03 visual_prompt]: 	Test 100/356. loss: 1.335, 0.2143 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 01:01:24 visual_prompt]: 	Test 200/356. loss: 1.685, 0.2147 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 01:01:46 visual_prompt]: 	Test 300/356. loss: 1.369, 0.2149 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:01:59 visual_prompt]: Inference (test):avg data time: 6.51e-05, avg batch time: 0.2140, average loss: 1.4544
[10/01 01:01:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.63	top5: 97.66	
[10/01 01:01:59 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[10/01 01:02:09 visual_prompt]: Epoch 61 / 100: avg data time: 1.09e-01, avg batch time: 0.5597, average train loss: 1.1600
[10/01 01:02:13 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1675, average loss: 1.1382
[10/01 01:02:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.00	top5: 99.50	
[10/01 01:02:36 visual_prompt]: 	Test 100/356. loss: 1.274, 0.2135 s / batch. (data: 9.27e-05)max mem: 7.81207 GB 
[10/01 01:02:58 visual_prompt]: 	Test 200/356. loss: 1.761, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:03:19 visual_prompt]: 	Test 300/356. loss: 1.334, 0.2143 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 01:03:32 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2138, average loss: 1.4060
[10/01 01:03:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.57	top5: 97.59	
[10/01 01:03:32 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[10/01 01:03:43 visual_prompt]: Epoch 62 / 100: avg data time: 9.93e-02, avg batch time: 0.5509, average train loss: 1.1273
[10/01 01:03:46 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1673, average loss: 0.9917
[10/01 01:03:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 50.50	top5: 100.00	
[10/01 01:04:09 visual_prompt]: 	Test 100/356. loss: 1.249, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:04:31 visual_prompt]: 	Test 200/356. loss: 1.724, 0.2145 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 01:04:52 visual_prompt]: 	Test 300/356. loss: 1.275, 0.2145 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:05:05 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2138, average loss: 1.3330
[10/01 01:05:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.46	top5: 97.71	
[10/01 01:05:05 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[10/01 01:05:16 visual_prompt]: Epoch 63 / 100: avg data time: 1.04e-01, avg batch time: 0.5539, average train loss: 1.1170
[10/01 01:05:19 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 0.9740
[10/01 01:05:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.00	top5: 100.00	
[10/01 01:05:42 visual_prompt]: 	Test 100/356. loss: 1.187, 0.2137 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 01:06:04 visual_prompt]: 	Test 200/356. loss: 1.675, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:06:25 visual_prompt]: 	Test 300/356. loss: 1.302, 0.2147 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 01:06:38 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2137, average loss: 1.3947
[10/01 01:06:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.27	top5: 98.21	
[10/01 01:06:39 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[10/01 01:06:49 visual_prompt]: Epoch 64 / 100: avg data time: 1.10e-01, avg batch time: 0.5591, average train loss: 1.0758
[10/01 01:06:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 0.9432
[10/01 01:06:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 50.00	top5: 100.00	
[10/01 01:07:15 visual_prompt]: 	Test 100/356. loss: 1.212, 0.2134 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 01:07:37 visual_prompt]: 	Test 200/356. loss: 1.517, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 01:07:58 visual_prompt]: 	Test 300/356. loss: 1.264, 0.2143 s / batch. (data: 3.10e-05)max mem: 7.81207 GB 
[10/01 01:08:12 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2138, average loss: 1.3573
[10/01 01:08:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.60	top5: 97.66	
[10/01 01:08:12 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[10/01 01:08:22 visual_prompt]: Epoch 65 / 100: avg data time: 1.07e-01, avg batch time: 0.5559, average train loss: 1.0716
[10/01 01:08:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1677, average loss: 1.0703
[10/01 01:08:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 54.00	top5: 99.50	
[10/01 01:08:48 visual_prompt]: 	Test 100/356. loss: 1.354, 0.2135 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:09:10 visual_prompt]: 	Test 200/356. loss: 1.413, 0.2140 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:09:31 visual_prompt]: 	Test 300/356. loss: 1.295, 0.2144 s / batch. (data: 5.08e-05)max mem: 7.81207 GB 
[10/01 01:09:45 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2138, average loss: 1.3684
[10/01 01:09:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.43	top5: 98.04	
[10/01 01:09:45 visual_prompt]: Best epoch 65: best metric: 0.540
[10/01 01:09:45 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[10/01 01:09:55 visual_prompt]: Epoch 66 / 100: avg data time: 1.03e-01, avg batch time: 0.5525, average train loss: 1.1072
[10/01 01:09:58 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1674, average loss: 1.1513
[10/01 01:09:58 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 100.00	
[10/01 01:10:21 visual_prompt]: 	Test 100/356. loss: 1.334, 0.2131 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:10:43 visual_prompt]: 	Test 200/356. loss: 1.643, 0.2141 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 01:11:04 visual_prompt]: 	Test 300/356. loss: 1.380, 0.2147 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 01:11:18 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2139, average loss: 1.4691
[10/01 01:11:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.27	top5: 97.19	
[10/01 01:11:18 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[10/01 01:11:28 visual_prompt]: Epoch 67 / 100: avg data time: 1.06e-01, avg batch time: 0.5577, average train loss: 1.0708
[10/01 01:11:32 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1673, average loss: 0.9614
[10/01 01:11:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 55.00	top5: 100.00	
[10/01 01:11:55 visual_prompt]: 	Test 100/356. loss: 1.195, 0.2139 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 01:12:16 visual_prompt]: 	Test 200/356. loss: 1.515, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:12:38 visual_prompt]: 	Test 300/356. loss: 1.380, 0.2145 s / batch. (data: 9.66e-05)max mem: 7.81207 GB 
[10/01 01:12:51 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.2137, average loss: 1.3632
[10/01 01:12:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.83	top5: 98.08	
[10/01 01:12:51 visual_prompt]: Best epoch 67: best metric: 0.550
[10/01 01:12:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[10/01 01:13:01 visual_prompt]: Epoch 68 / 100: avg data time: 1.10e-01, avg batch time: 0.5596, average train loss: 0.9543
[10/01 01:13:05 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1694, average loss: 1.0683
[10/01 01:13:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.50	top5: 99.50	
[10/01 01:13:28 visual_prompt]: 	Test 100/356. loss: 1.319, 0.2139 s / batch. (data: 7.18e-05)max mem: 7.81207 GB 
[10/01 01:13:49 visual_prompt]: 	Test 200/356. loss: 1.642, 0.2143 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 01:14:11 visual_prompt]: 	Test 300/356. loss: 1.355, 0.2147 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:14:24 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2137, average loss: 1.4771
[10/01 01:14:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.74	top5: 97.26	
[10/01 01:14:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[10/01 01:14:34 visual_prompt]: Epoch 69 / 100: avg data time: 1.03e-01, avg batch time: 0.5537, average train loss: 0.9999
[10/01 01:14:38 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1676, average loss: 0.9672
[10/01 01:14:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 54.50	top5: 100.00	
[10/01 01:15:01 visual_prompt]: 	Test 100/356. loss: 1.187, 0.2135 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:15:22 visual_prompt]: 	Test 200/356. loss: 1.826, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:15:44 visual_prompt]: 	Test 300/356. loss: 1.289, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:15:57 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2136, average loss: 1.4438
[10/01 01:15:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.78	top5: 97.19	
[10/01 01:15:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[10/01 01:16:08 visual_prompt]: Epoch 70 / 100: avg data time: 1.04e-01, avg batch time: 0.5533, average train loss: 0.9276
[10/01 01:16:11 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1675, average loss: 0.8943
[10/01 01:16:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 50.00	top5: 100.00	
[10/01 01:16:34 visual_prompt]: 	Test 100/356. loss: 1.250, 0.2140 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:16:56 visual_prompt]: 	Test 200/356. loss: 1.550, 0.2142 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 01:17:17 visual_prompt]: 	Test 300/356. loss: 1.133, 0.2146 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:17:31 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2138, average loss: 1.4695
[10/01 01:17:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.39	top5: 97.87	
[10/01 01:17:31 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[10/01 01:17:41 visual_prompt]: Epoch 71 / 100: avg data time: 1.21e-01, avg batch time: 0.5713, average train loss: 1.0805
[10/01 01:17:45 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1675, average loss: 1.0076
[10/01 01:17:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 53.50	top5: 100.00	
[10/01 01:18:08 visual_prompt]: 	Test 100/356. loss: 1.204, 0.2140 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 01:18:29 visual_prompt]: 	Test 200/356. loss: 1.515, 0.2143 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:18:51 visual_prompt]: 	Test 300/356. loss: 1.202, 0.2144 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 01:19:04 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2138, average loss: 1.3394
[10/01 01:19:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.73	top5: 97.92	
[10/01 01:19:04 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[10/01 01:19:14 visual_prompt]: Epoch 72 / 100: avg data time: 1.03e-01, avg batch time: 0.5525, average train loss: 1.0112
[10/01 01:19:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 0.9735
[10/01 01:19:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 56.50	top5: 100.00	
[10/01 01:19:41 visual_prompt]: 	Test 100/356. loss: 1.479, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:20:02 visual_prompt]: 	Test 200/356. loss: 1.500, 0.2139 s / batch. (data: 2.36e-05)max mem: 7.81207 GB 
[10/01 01:20:24 visual_prompt]: 	Test 300/356. loss: 1.394, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 01:20:37 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2139, average loss: 1.4656
[10/01 01:20:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.23	top5: 98.02	
[10/01 01:20:37 visual_prompt]: Best epoch 72: best metric: 0.565
[10/01 01:20:37 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[10/01 01:20:47 visual_prompt]: Epoch 73 / 100: avg data time: 1.03e-01, avg batch time: 0.5533, average train loss: 0.9125
[10/01 01:20:51 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1677, average loss: 0.9369
[10/01 01:20:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 51.00	top5: 99.50	
[10/01 01:21:14 visual_prompt]: 	Test 100/356. loss: 1.564, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:21:35 visual_prompt]: 	Test 200/356. loss: 1.579, 0.2142 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:21:57 visual_prompt]: 	Test 300/356. loss: 1.581, 0.2148 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 01:22:10 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2139, average loss: 1.6051
[10/01 01:22:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.36	top5: 97.66	
[10/01 01:22:10 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[10/01 01:22:20 visual_prompt]: Epoch 74 / 100: avg data time: 1.03e-01, avg batch time: 0.5530, average train loss: 0.8648
[10/01 01:22:24 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 0.9321
[10/01 01:22:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 54.00	top5: 99.50	
[10/01 01:22:47 visual_prompt]: 	Test 100/356. loss: 1.632, 0.2137 s / batch. (data: 3.29e-05)max mem: 7.81207 GB 
[10/01 01:23:09 visual_prompt]: 	Test 200/356. loss: 1.721, 0.2141 s / batch. (data: 6.84e-05)max mem: 7.81207 GB 
[10/01 01:23:30 visual_prompt]: 	Test 300/356. loss: 1.675, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 01:23:43 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2138, average loss: 1.6979
[10/01 01:23:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.61	top5: 97.86	
[10/01 01:23:43 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[10/01 01:23:54 visual_prompt]: Epoch 75 / 100: avg data time: 1.05e-01, avg batch time: 0.5564, average train loss: 0.8314
[10/01 01:23:57 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1674, average loss: 0.8303
[10/01 01:23:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 60.50	top5: 99.00	
[10/01 01:24:20 visual_prompt]: 	Test 100/356. loss: 1.384, 0.2142 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:24:42 visual_prompt]: 	Test 200/356. loss: 1.587, 0.2140 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 01:25:03 visual_prompt]: 	Test 300/356. loss: 1.272, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:25:17 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2138, average loss: 1.4531
[10/01 01:25:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.34	top5: 97.40	
[10/01 01:25:17 visual_prompt]: Best epoch 75: best metric: 0.605
[10/01 01:25:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[10/01 01:25:27 visual_prompt]: Epoch 76 / 100: avg data time: 1.05e-01, avg batch time: 0.5549, average train loss: 0.8372
[10/01 01:25:30 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1675, average loss: 0.7178
[10/01 01:25:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 68.00	top5: 100.00	
[10/01 01:25:54 visual_prompt]: 	Test 100/356. loss: 1.441, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 01:26:15 visual_prompt]: 	Test 200/356. loss: 1.649, 0.2145 s / batch. (data: 8.37e-05)max mem: 7.81207 GB 
[10/01 01:26:37 visual_prompt]: 	Test 300/356. loss: 1.487, 0.2142 s / batch. (data: 3.50e-05)max mem: 7.81207 GB 
[10/01 01:26:50 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.2139, average loss: 1.6454
[10/01 01:26:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.93	top5: 98.28	
[10/01 01:26:50 visual_prompt]: Best epoch 76: best metric: 0.680
[10/01 01:26:50 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[10/01 01:27:00 visual_prompt]: Epoch 77 / 100: avg data time: 1.05e-01, avg batch time: 0.5570, average train loss: 0.7427
[10/01 01:27:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1676, average loss: 0.8759
[10/01 01:27:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 60.50	top5: 98.50	
[10/01 01:27:27 visual_prompt]: 	Test 100/356. loss: 2.230, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:27:48 visual_prompt]: 	Test 200/356. loss: 1.780, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 01:28:10 visual_prompt]: 	Test 300/356. loss: 1.704, 0.2146 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 01:28:23 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2138, average loss: 1.9316
[10/01 01:28:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.31	top5: 97.43	
[10/01 01:28:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[10/01 01:28:33 visual_prompt]: Epoch 78 / 100: avg data time: 1.03e-01, avg batch time: 0.5528, average train loss: 0.7560
[10/01 01:28:37 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1674, average loss: 0.7212
[10/01 01:28:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 68.00	top5: 100.00	
[10/01 01:29:00 visual_prompt]: 	Test 100/356. loss: 1.564, 0.2146 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 01:29:21 visual_prompt]: 	Test 200/356. loss: 1.687, 0.2143 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:29:43 visual_prompt]: 	Test 300/356. loss: 1.656, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 01:29:56 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2139, average loss: 1.6709
[10/01 01:29:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.16	top5: 98.28	
[10/01 01:29:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[10/01 01:30:06 visual_prompt]: Epoch 79 / 100: avg data time: 1.03e-01, avg batch time: 0.5538, average train loss: 0.7214
[10/01 01:30:10 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1692, average loss: 1.0203
[10/01 01:30:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 55.50	top5: 97.50	
[10/01 01:30:33 visual_prompt]: 	Test 100/356. loss: 1.942, 0.2141 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 01:30:55 visual_prompt]: 	Test 200/356. loss: 1.904, 0.2143 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 01:31:16 visual_prompt]: 	Test 300/356. loss: 1.885, 0.2142 s / batch. (data: 7.65e-05)max mem: 7.81207 GB 
[10/01 01:31:30 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2139, average loss: 2.0175
[10/01 01:31:30 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.56	top5: 96.05	
[10/01 01:31:30 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[10/01 01:31:40 visual_prompt]: Epoch 80 / 100: avg data time: 1.06e-01, avg batch time: 0.5559, average train loss: 0.7908
[10/01 01:31:44 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1675, average loss: 0.6354
[10/01 01:31:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 72.50	top5: 100.00	
[10/01 01:32:07 visual_prompt]: 	Test 100/356. loss: 1.811, 0.2137 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 01:32:28 visual_prompt]: 	Test 200/356. loss: 1.855, 0.2139 s / batch. (data: 7.63e-05)max mem: 7.81207 GB 
[10/01 01:32:50 visual_prompt]: 	Test 300/356. loss: 1.545, 0.2146 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 01:33:03 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2139, average loss: 1.7211
[10/01 01:33:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.72	top5: 97.92	
[10/01 01:33:03 visual_prompt]: Best epoch 80: best metric: 0.725
[10/01 01:33:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[10/01 01:33:14 visual_prompt]: Epoch 81 / 100: avg data time: 1.14e-01, avg batch time: 0.5643, average train loss: 0.6213
[10/01 01:33:17 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1675, average loss: 0.7894
[10/01 01:33:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 64.00	top5: 100.00	
[10/01 01:33:40 visual_prompt]: 	Test 100/356. loss: 2.273, 0.2139 s / batch. (data: 8.46e-05)max mem: 7.81207 GB 
[10/01 01:34:01 visual_prompt]: 	Test 200/356. loss: 1.879, 0.2145 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[10/01 01:34:23 visual_prompt]: 	Test 300/356. loss: 1.868, 0.2147 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 01:34:36 visual_prompt]: Inference (test):avg data time: 5.09e-05, avg batch time: 0.2138, average loss: 2.1243
[10/01 01:34:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.80	top5: 97.93	
[10/01 01:34:36 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[10/01 01:34:47 visual_prompt]: Epoch 82 / 100: avg data time: 1.01e-01, avg batch time: 0.5532, average train loss: 0.6763
[10/01 01:34:50 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1708, average loss: 0.6580
[10/01 01:34:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 72.00	top5: 100.00	
[10/01 01:35:13 visual_prompt]: 	Test 100/356. loss: 2.170, 0.2137 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 01:35:35 visual_prompt]: 	Test 200/356. loss: 2.773, 0.2141 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:35:56 visual_prompt]: 	Test 300/356. loss: 2.298, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 01:36:10 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2139, average loss: 2.3004
[10/01 01:36:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.15	top5: 97.36	
[10/01 01:36:10 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[10/01 01:36:20 visual_prompt]: Epoch 83 / 100: avg data time: 1.02e-01, avg batch time: 0.5546, average train loss: 0.6983
[10/01 01:36:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1675, average loss: 0.6122
[10/01 01:36:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 75.50	top5: 100.00	
[10/01 01:36:47 visual_prompt]: 	Test 100/356. loss: 1.696, 0.2142 s / batch. (data: 7.89e-05)max mem: 7.81207 GB 
[10/01 01:37:08 visual_prompt]: 	Test 200/356. loss: 1.743, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 01:37:30 visual_prompt]: 	Test 300/356. loss: 1.715, 0.2148 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:37:43 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2138, average loss: 1.7210
[10/01 01:37:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.67	top5: 98.22	
[10/01 01:37:43 visual_prompt]: Best epoch 83: best metric: 0.755
[10/01 01:37:43 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[10/01 01:37:53 visual_prompt]: Epoch 84 / 100: avg data time: 1.10e-01, avg batch time: 0.5614, average train loss: 0.6146
[10/01 01:37:57 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1674, average loss: 0.8139
[10/01 01:37:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 69.00	top5: 100.00	
[10/01 01:38:20 visual_prompt]: 	Test 100/356. loss: 2.098, 0.2137 s / batch. (data: 8.87e-05)max mem: 7.81207 GB 
[10/01 01:38:41 visual_prompt]: 	Test 200/356. loss: 1.946, 0.2145 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 01:39:03 visual_prompt]: 	Test 300/356. loss: 1.953, 0.2143 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 01:39:16 visual_prompt]: Inference (test):avg data time: 8.78e-05, avg batch time: 0.2138, average loss: 2.1381
[10/01 01:39:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.89	top5: 97.95	
[10/01 01:39:16 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[10/01 01:39:27 visual_prompt]: Epoch 85 / 100: avg data time: 1.13e-01, avg batch time: 0.5621, average train loss: 0.5429
[10/01 01:39:30 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1676, average loss: 0.5909
[10/01 01:39:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 72.00	top5: 100.00	
[10/01 01:39:53 visual_prompt]: 	Test 100/356. loss: 2.351, 0.2139 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 01:40:15 visual_prompt]: 	Test 200/356. loss: 2.244, 0.2140 s / batch. (data: 8.63e-05)max mem: 7.81207 GB 
[10/01 01:40:36 visual_prompt]: 	Test 300/356. loss: 2.297, 0.2141 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 01:40:50 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2138, average loss: 2.2070
[10/01 01:40:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.71	top5: 98.21	
[10/01 01:40:50 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[10/01 01:41:00 visual_prompt]: Epoch 86 / 100: avg data time: 1.04e-01, avg batch time: 0.5548, average train loss: 0.4598
[10/01 01:41:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1676, average loss: 0.5001
[10/01 01:41:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 79.50	top5: 100.00	
[10/01 01:41:27 visual_prompt]: 	Test 100/356. loss: 2.327, 0.2139 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 01:41:48 visual_prompt]: 	Test 200/356. loss: 2.279, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 01:42:09 visual_prompt]: 	Test 300/356. loss: 2.299, 0.2146 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:42:23 visual_prompt]: Inference (test):avg data time: 9.73e-05, avg batch time: 0.2139, average loss: 2.3970
[10/01 01:42:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.80	top5: 97.73	
[10/01 01:42:23 visual_prompt]: Best epoch 86: best metric: 0.795
[10/01 01:42:23 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[10/01 01:42:33 visual_prompt]: Epoch 87 / 100: avg data time: 1.02e-01, avg batch time: 0.5526, average train loss: 0.4960
[10/01 01:42:36 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1676, average loss: 0.4636
[10/01 01:42:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 79.00	top5: 100.00	
[10/01 01:43:00 visual_prompt]: 	Test 100/356. loss: 1.576, 0.2140 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 01:43:21 visual_prompt]: 	Test 200/356. loss: 1.800, 0.2142 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:43:42 visual_prompt]: 	Test 300/356. loss: 1.999, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 01:43:56 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2140, average loss: 2.0091
[10/01 01:43:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.25	top5: 97.78	
[10/01 01:43:56 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[10/01 01:44:06 visual_prompt]: Epoch 88 / 100: avg data time: 1.04e-01, avg batch time: 0.5547, average train loss: 0.4253
[10/01 01:44:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1679, average loss: 0.4145
[10/01 01:44:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 82.00	top5: 100.00	
[10/01 01:44:33 visual_prompt]: 	Test 100/356. loss: 1.919, 0.2141 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 01:44:54 visual_prompt]: 	Test 200/356. loss: 2.125, 0.2146 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 01:45:16 visual_prompt]: 	Test 300/356. loss: 2.254, 0.2147 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 01:45:29 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2139, average loss: 2.1784
[10/01 01:45:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.24	top5: 98.06	
[10/01 01:45:29 visual_prompt]: Best epoch 88: best metric: 0.820
[10/01 01:45:29 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[10/01 01:45:39 visual_prompt]: Epoch 89 / 100: avg data time: 1.03e-01, avg batch time: 0.5554, average train loss: 0.3411
[10/01 01:45:43 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1674, average loss: 0.3418
[10/01 01:45:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 84.00	top5: 100.00	
[10/01 01:46:06 visual_prompt]: 	Test 100/356. loss: 1.862, 0.2137 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 01:46:27 visual_prompt]: 	Test 200/356. loss: 2.182, 0.2140 s / batch. (data: 3.10e-05)max mem: 7.81207 GB 
[10/01 01:46:49 visual_prompt]: 	Test 300/356. loss: 2.373, 0.2148 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 01:47:02 visual_prompt]: Inference (test):avg data time: 5.27e-05, avg batch time: 0.2139, average loss: 2.2896
[10/01 01:47:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.11	top5: 97.65	
[10/01 01:47:02 visual_prompt]: Best epoch 89: best metric: 0.840
[10/01 01:47:02 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[10/01 01:47:12 visual_prompt]: Epoch 90 / 100: avg data time: 1.03e-01, avg batch time: 0.5549, average train loss: 0.2945
[10/01 01:47:16 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1675, average loss: 0.2703
[10/01 01:47:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 89.50	top5: 100.00	
[10/01 01:47:39 visual_prompt]: 	Test 100/356. loss: 1.942, 0.2140 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 01:48:00 visual_prompt]: 	Test 200/356. loss: 2.323, 0.2141 s / batch. (data: 3.79e-05)max mem: 7.81207 GB 
[10/01 01:48:22 visual_prompt]: 	Test 300/356. loss: 2.424, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 01:48:35 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2140, average loss: 2.3967
[10/01 01:48:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.07	top5: 97.87	
[10/01 01:48:35 visual_prompt]: Best epoch 90: best metric: 0.895
[10/01 01:48:35 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[10/01 01:48:45 visual_prompt]: Epoch 91 / 100: avg data time: 1.02e-01, avg batch time: 0.5530, average train loss: 0.2593
[10/01 01:48:49 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1676, average loss: 0.2289
[10/01 01:48:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 90.50	top5: 100.00	
[10/01 01:49:12 visual_prompt]: 	Test 100/356. loss: 2.297, 0.2137 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 01:49:34 visual_prompt]: 	Test 200/356. loss: 2.479, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 01:49:55 visual_prompt]: 	Test 300/356. loss: 2.580, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 01:50:08 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2139, average loss: 2.5317
[10/01 01:50:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.31	top5: 97.81	
[10/01 01:50:08 visual_prompt]: Best epoch 91: best metric: 0.905
[10/01 01:50:08 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[10/01 01:50:19 visual_prompt]: Epoch 92 / 100: avg data time: 1.04e-01, avg batch time: 0.5555, average train loss: 0.2343
[10/01 01:50:22 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1677, average loss: 0.3117
[10/01 01:50:22 visual_prompt]: Classification results with val_vtab-dmlab: top1: 87.00	top5: 100.00	
[10/01 01:50:45 visual_prompt]: 	Test 100/356. loss: 2.231, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 01:51:07 visual_prompt]: 	Test 200/356. loss: 2.479, 0.2145 s / batch. (data: 8.08e-05)max mem: 7.81207 GB 
[10/01 01:51:28 visual_prompt]: 	Test 300/356. loss: 2.669, 0.2143 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 01:51:42 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2139, average loss: 2.5312
[10/01 01:51:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.61	top5: 97.90	
[10/01 01:51:42 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[10/01 01:51:52 visual_prompt]: Epoch 93 / 100: avg data time: 9.76e-02, avg batch time: 0.5485, average train loss: 0.2072
[10/01 01:51:55 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1674, average loss: 0.2246
[10/01 01:51:55 visual_prompt]: Classification results with val_vtab-dmlab: top1: 92.50	top5: 100.00	
[10/01 01:52:18 visual_prompt]: 	Test 100/356. loss: 2.189, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 01:52:40 visual_prompt]: 	Test 200/356. loss: 2.484, 0.2139 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 01:53:01 visual_prompt]: 	Test 300/356. loss: 2.707, 0.2148 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 01:53:15 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2141, average loss: 2.5738
[10/01 01:53:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.54	top5: 97.78	
[10/01 01:53:15 visual_prompt]: Best epoch 93: best metric: 0.925
[10/01 01:53:15 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[10/01 01:53:25 visual_prompt]: Epoch 94 / 100: avg data time: 1.11e-01, avg batch time: 0.5610, average train loss: 0.1820
[10/01 01:53:29 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1675, average loss: 0.2756
[10/01 01:53:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 88.50	top5: 100.00	
[10/01 01:53:52 visual_prompt]: 	Test 100/356. loss: 2.591, 0.2142 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 01:54:13 visual_prompt]: 	Test 200/356. loss: 2.725, 0.2142 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:54:35 visual_prompt]: 	Test 300/356. loss: 2.918, 0.2144 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 01:54:48 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2139, average loss: 2.7615
[10/01 01:54:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.90	top5: 97.89	
[10/01 01:54:48 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[10/01 01:54:58 visual_prompt]: Epoch 95 / 100: avg data time: 1.05e-01, avg batch time: 0.5559, average train loss: 0.1601
[10/01 01:55:02 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1711, average loss: 0.2202
[10/01 01:55:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 89.50	top5: 100.00	
[10/01 01:55:25 visual_prompt]: 	Test 100/356. loss: 2.382, 0.2137 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:55:47 visual_prompt]: 	Test 200/356. loss: 2.715, 0.2141 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 01:56:08 visual_prompt]: 	Test 300/356. loss: 2.819, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 01:56:22 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2139, average loss: 2.6995
[10/01 01:56:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.58	top5: 97.79	
[10/01 01:56:22 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[10/01 01:56:32 visual_prompt]: Epoch 96 / 100: avg data time: 1.05e-01, avg batch time: 0.5553, average train loss: 0.1451
[10/01 01:56:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1674, average loss: 0.1559
[10/01 01:56:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.00	top5: 100.00	
[10/01 01:56:59 visual_prompt]: 	Test 100/356. loss: 2.520, 0.2134 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 01:57:20 visual_prompt]: 	Test 200/356. loss: 2.820, 0.2143 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:57:41 visual_prompt]: 	Test 300/356. loss: 2.832, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 01:57:55 visual_prompt]: Inference (test):avg data time: 1.20e-04, avg batch time: 0.2139, average loss: 2.7597
[10/01 01:57:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.55	top5: 97.67	
[10/01 01:57:55 visual_prompt]: Best epoch 96: best metric: 0.940
[10/01 01:57:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[10/01 01:58:05 visual_prompt]: Epoch 97 / 100: avg data time: 1.04e-01, avg batch time: 0.5556, average train loss: 0.1265
[10/01 01:58:09 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1676, average loss: 0.1669
[10/01 01:58:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.00	top5: 100.00	
[10/01 01:58:32 visual_prompt]: 	Test 100/356. loss: 2.564, 0.2133 s / batch. (data: 8.44e-05)max mem: 7.81207 GB 
[10/01 01:58:53 visual_prompt]: 	Test 200/356. loss: 2.888, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:59:15 visual_prompt]: 	Test 300/356. loss: 2.915, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 01:59:28 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2138, average loss: 2.8057
[10/01 01:59:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.68	top5: 97.72	
[10/01 01:59:28 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[10/01 01:59:38 visual_prompt]: Epoch 98 / 100: avg data time: 1.06e-01, avg batch time: 0.5573, average train loss: 0.1289
[10/01 01:59:42 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1674, average loss: 0.1352
[10/01 01:59:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 02:00:05 visual_prompt]: 	Test 100/356. loss: 2.618, 0.2140 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:00:26 visual_prompt]: 	Test 200/356. loss: 2.887, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 02:00:48 visual_prompt]: 	Test 300/356. loss: 2.911, 0.2148 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 02:01:01 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2138, average loss: 2.8162
[10/01 02:01:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.48	top5: 97.69	
[10/01 02:01:01 visual_prompt]: Best epoch 98: best metric: 0.955
[10/01 02:01:01 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[10/01 02:01:11 visual_prompt]: Epoch 99 / 100: avg data time: 9.89e-02, avg batch time: 0.5500, average train loss: 0.1142
[10/01 02:01:15 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1675, average loss: 0.1413
[10/01 02:01:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.00	top5: 100.00	
[10/01 02:01:38 visual_prompt]: 	Test 100/356. loss: 2.626, 0.2133 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:01:59 visual_prompt]: 	Test 200/356. loss: 2.882, 0.2141 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 02:02:21 visual_prompt]: 	Test 300/356. loss: 2.942, 0.2147 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:02:34 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2138, average loss: 2.8297
[10/01 02:02:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.60	top5: 97.68	
[10/01 02:02:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[10/01 02:02:45 visual_prompt]: Epoch 100 / 100: avg data time: 1.10e-01, avg batch time: 0.5599, average train loss: 0.1272
[10/01 02:02:48 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1675, average loss: 0.1369
[10/01 02:02:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.00	top5: 100.00	
[10/01 02:03:12 visual_prompt]: 	Test 100/356. loss: 2.626, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 02:03:33 visual_prompt]: 	Test 200/356. loss: 2.881, 0.2137 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 02:03:54 visual_prompt]: 	Test 300/356. loss: 2.941, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 02:04:08 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2137, average loss: 2.8311
[10/01 02:04:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.58	top5: 97.68	
[10/01 02:04:08 visual_prompt]: Rank of current process: 0. World size: 1
[10/01 02:04:08 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/01 02:04:08 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[10/01 02:04:08 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/01 02:04:08 visual_prompt]: Training with config:
[10/01 02:04:08 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dmlab/sup_vitb16_imagenet21k/prompt50/crop224/test/seed4536/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 4536, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dmlab', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 6, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/01 02:04:08 visual_prompt]: Loading training data...
[10/01 02:04:08 visual_prompt]: Constructing vtab-dmlab dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 02:04:10 visual_prompt]: Number of images: 1000
[10/01 02:04:10 visual_prompt]: Number of classes: 6 / 6
[10/01 02:04:10 visual_prompt]: Loading validation data...
[10/01 02:04:10 visual_prompt]: Constructing vtab-dmlab dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 02:04:10 visual_prompt]: Number of images: 200
[10/01 02:04:10 visual_prompt]: Number of classes: 6 / 6
[10/01 02:04:10 visual_prompt]: Loading test data...
[10/01 02:04:10 visual_prompt]: Constructing vtab-dmlab dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split test, from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 02:04:44 visual_prompt]: Number of images: 22735
[10/01 02:04:44 visual_prompt]: Number of classes: 6 / 6
[10/01 02:04:44 visual_prompt]: Constructing models...
[10/01 02:04:47 visual_prompt]: Total Parameters: 86264070	 Gradient Parameters: 465414
[10/01 02:04:47 visual_prompt]: tuned percent:0.540
[10/01 02:04:47 visual_prompt]: Device used for model: 0
[10/01 02:04:47 visual_prompt]: Setting up Evaluator...
[10/01 02:04:47 visual_prompt]: Setting up Trainer...
[10/01 02:04:47 visual_prompt]: 	Setting up the optimizer...
[10/01 02:04:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/01 02:04:57 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e-01, avg batch time: 0.5539, average train loss: 2.1531
[10/01 02:05:01 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1668, average loss: 2.1367
[10/01 02:05:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 13.50	top5: 83.00	
[10/01 02:05:24 visual_prompt]: 	Test 100/356. loss: 2.088, 0.2135 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:05:45 visual_prompt]: 	Test 200/356. loss: 2.186, 0.2145 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 02:06:06 visual_prompt]: 	Test 300/356. loss: 1.986, 0.2136 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 02:06:20 visual_prompt]: Inference (test):avg data time: 6.77e-05, avg batch time: 0.2131, average loss: 2.0971
[10/01 02:06:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 16.21	top5: 82.97	
[10/01 02:06:20 visual_prompt]: Best epoch 1: best metric: 0.135
[10/01 02:06:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/01 02:06:30 visual_prompt]: Epoch 2 / 100: avg data time: 1.02e-01, avg batch time: 0.5526, average train loss: 2.1165
[10/01 02:06:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1671, average loss: 1.8533
[10/01 02:06:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 02:06:57 visual_prompt]: 	Test 100/356. loss: 1.823, 0.2147 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 02:07:18 visual_prompt]: 	Test 200/356. loss: 1.783, 0.2141 s / batch. (data: 6.22e-05)max mem: 7.81207 GB 
[10/01 02:07:39 visual_prompt]: 	Test 300/356. loss: 1.762, 0.2143 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 02:07:53 visual_prompt]: Inference (test):avg data time: 6.00e-05, avg batch time: 0.2138, average loss: 1.8155
[10/01 02:07:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.76	top5: 85.40	
[10/01 02:07:53 visual_prompt]: Best epoch 2: best metric: 0.155
[10/01 02:07:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/01 02:08:03 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e-01, avg batch time: 0.5602, average train loss: 1.8527
[10/01 02:08:07 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1675, average loss: 1.9071
[10/01 02:08:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 02:08:30 visual_prompt]: 	Test 100/356. loss: 1.881, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 02:08:51 visual_prompt]: 	Test 200/356. loss: 1.707, 0.2143 s / batch. (data: 8.70e-05)max mem: 7.81207 GB 
[10/01 02:09:12 visual_prompt]: 	Test 300/356. loss: 1.811, 0.2139 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 02:09:26 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2135, average loss: 1.8276
[10/01 02:09:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.05	top5: 88.42	
[10/01 02:09:26 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/01 02:09:36 visual_prompt]: Epoch 4 / 100: avg data time: 1.12e-01, avg batch time: 0.5616, average train loss: 1.8949
[10/01 02:09:40 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1665, average loss: 1.8005
[10/01 02:09:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 87.50	
[10/01 02:10:03 visual_prompt]: 	Test 100/356. loss: 1.846, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 02:10:24 visual_prompt]: 	Test 200/356. loss: 1.829, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 02:10:46 visual_prompt]: 	Test 300/356. loss: 1.839, 0.2146 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 02:10:59 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2137, average loss: 1.8142
[10/01 02:10:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 89.35	
[10/01 02:10:59 visual_prompt]: Best epoch 4: best metric: 0.205
[10/01 02:10:59 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/01 02:11:09 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e-01, avg batch time: 0.5526, average train loss: 1.8016
[10/01 02:11:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1665, average loss: 1.8803
[10/01 02:11:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.00	top5: 85.50	
[10/01 02:11:36 visual_prompt]: 	Test 100/356. loss: 1.927, 0.2133 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:11:58 visual_prompt]: 	Test 200/356. loss: 2.048, 0.2141 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:12:19 visual_prompt]: 	Test 300/356. loss: 1.995, 0.2146 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:12:32 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2136, average loss: 1.9352
[10/01 02:12:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 21.49	top5: 78.29	
[10/01 02:12:32 visual_prompt]: Best epoch 5: best metric: 0.240
[10/01 02:12:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/01 02:12:43 visual_prompt]: Epoch 6 / 100: avg data time: 1.10e-01, avg batch time: 0.5595, average train loss: 1.8554
[10/01 02:12:46 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1679, average loss: 1.8303
[10/01 02:12:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 89.00	
[10/01 02:13:09 visual_prompt]: 	Test 100/356. loss: 1.869, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:13:31 visual_prompt]: 	Test 200/356. loss: 1.920, 0.2143 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 02:13:52 visual_prompt]: 	Test 300/356. loss: 1.849, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:14:06 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2136, average loss: 1.8560
[10/01 02:14:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 88.38	
[10/01 02:14:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/01 02:14:16 visual_prompt]: Epoch 7 / 100: avg data time: 1.03e-01, avg batch time: 0.5541, average train loss: 1.7899
[10/01 02:14:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1666, average loss: 1.7895
[10/01 02:14:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.50	top5: 93.50	
[10/01 02:14:43 visual_prompt]: 	Test 100/356. loss: 1.824, 0.2138 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 02:15:04 visual_prompt]: 	Test 200/356. loss: 1.622, 0.2141 s / batch. (data: 3.24e-05)max mem: 7.81207 GB 
[10/01 02:15:26 visual_prompt]: 	Test 300/356. loss: 1.645, 0.2145 s / batch. (data: 6.51e-05)max mem: 7.81207 GB 
[10/01 02:15:39 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2138, average loss: 1.7284
[10/01 02:15:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.99	top5: 93.36	
[10/01 02:15:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/01 02:15:49 visual_prompt]: Epoch 8 / 100: avg data time: 1.02e-01, avg batch time: 0.5535, average train loss: 1.6962
[10/01 02:15:53 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1665, average loss: 1.6324
[10/01 02:15:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.50	top5: 94.00	
[10/01 02:16:16 visual_prompt]: 	Test 100/356. loss: 1.584, 0.2135 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 02:16:37 visual_prompt]: 	Test 200/356. loss: 1.630, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 02:16:59 visual_prompt]: 	Test 300/356. loss: 1.565, 0.2145 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 02:17:12 visual_prompt]: Inference (test):avg data time: 6.92e-05, avg batch time: 0.2137, average loss: 1.5951
[10/01 02:17:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.49	top5: 94.47	
[10/01 02:17:12 visual_prompt]: Best epoch 8: best metric: 0.245
[10/01 02:17:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/01 02:17:22 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e-01, avg batch time: 0.5580, average train loss: 1.6933
[10/01 02:17:26 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1668, average loss: 1.8558
[10/01 02:17:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.00	top5: 96.50	
[10/01 02:17:49 visual_prompt]: 	Test 100/356. loss: 1.961, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 02:18:10 visual_prompt]: 	Test 200/356. loss: 1.931, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:18:32 visual_prompt]: 	Test 300/356. loss: 1.825, 0.2145 s / batch. (data: 9.85e-05)max mem: 7.81207 GB 
[10/01 02:18:45 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2138, average loss: 1.8713
[10/01 02:18:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 19.75	top5: 97.25	
[10/01 02:18:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/01 02:18:55 visual_prompt]: Epoch 10 / 100: avg data time: 1.04e-01, avg batch time: 0.5543, average train loss: 1.7677
[10/01 02:18:59 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.5264
[10/01 02:18:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.00	top5: 96.50	
[10/01 02:19:22 visual_prompt]: 	Test 100/356. loss: 1.468, 0.2137 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:19:43 visual_prompt]: 	Test 200/356. loss: 1.565, 0.2139 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 02:20:05 visual_prompt]: 	Test 300/356. loss: 1.412, 0.2140 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 02:20:18 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2137, average loss: 1.4949
[10/01 02:20:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.38	top5: 95.81	
[10/01 02:20:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/01 02:20:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e-01, avg batch time: 0.5527, average train loss: 1.6738
[10/01 02:20:32 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1667, average loss: 1.7649
[10/01 02:20:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 28.50	top5: 92.00	
[10/01 02:20:55 visual_prompt]: 	Test 100/356. loss: 1.696, 0.2136 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 02:21:17 visual_prompt]: 	Test 200/356. loss: 1.624, 0.2145 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 02:21:38 visual_prompt]: 	Test 300/356. loss: 1.554, 0.2139 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 02:21:51 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2137, average loss: 1.6974
[10/01 02:21:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.66	top5: 90.47	
[10/01 02:21:51 visual_prompt]: Best epoch 11: best metric: 0.285
[10/01 02:21:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/01 02:22:02 visual_prompt]: Epoch 12 / 100: avg data time: 1.10e-01, avg batch time: 0.5621, average train loss: 1.5288
[10/01 02:22:05 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1665, average loss: 1.5668
[10/01 02:22:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.00	top5: 98.50	
[10/01 02:22:28 visual_prompt]: 	Test 100/356. loss: 1.611, 0.2137 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 02:22:50 visual_prompt]: 	Test 200/356. loss: 1.715, 0.2139 s / batch. (data: 7.77e-05)max mem: 7.81207 GB 
[10/01 02:23:11 visual_prompt]: 	Test 300/356. loss: 1.560, 0.2143 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:23:24 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2137, average loss: 1.6175
[10/01 02:23:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.42	top5: 96.92	
[10/01 02:23:24 visual_prompt]: Best epoch 12: best metric: 0.340
[10/01 02:23:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/01 02:23:35 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e-01, avg batch time: 0.5548, average train loss: 1.6495
[10/01 02:23:38 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1667, average loss: 1.4847
[10/01 02:23:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.00	top5: 99.00	
[10/01 02:24:01 visual_prompt]: 	Test 100/356. loss: 1.466, 0.2146 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 02:24:22 visual_prompt]: 	Test 200/356. loss: 1.536, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 02:24:44 visual_prompt]: 	Test 300/356. loss: 1.436, 0.2145 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 02:24:57 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2137, average loss: 1.4962
[10/01 02:24:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.47	top5: 97.73	
[10/01 02:24:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/01 02:25:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e-01, avg batch time: 0.5535, average train loss: 1.5523
[10/01 02:25:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1667, average loss: 1.8857
[10/01 02:25:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 27.00	top5: 95.00	
[10/01 02:25:34 visual_prompt]: 	Test 100/356. loss: 1.644, 0.2143 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:25:56 visual_prompt]: 	Test 200/356. loss: 1.480, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 02:26:17 visual_prompt]: 	Test 300/356. loss: 1.646, 0.2147 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:26:31 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2137, average loss: 1.7511
[10/01 02:26:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.35	top5: 96.26	
[10/01 02:26:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/01 02:26:41 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e-01, avg batch time: 0.5547, average train loss: 1.5779
[10/01 02:26:44 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1666, average loss: 1.6328
[10/01 02:26:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 98.50	
[10/01 02:27:08 visual_prompt]: 	Test 100/356. loss: 1.432, 0.2137 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:27:29 visual_prompt]: 	Test 200/356. loss: 1.898, 0.2140 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 02:27:50 visual_prompt]: 	Test 300/356. loss: 1.640, 0.2147 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:28:04 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.2137, average loss: 1.6468
[10/01 02:28:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.20	top5: 96.90	
[10/01 02:28:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/01 02:28:14 visual_prompt]: Epoch 16 / 100: avg data time: 1.05e-01, avg batch time: 0.5542, average train loss: 1.4695
[10/01 02:28:17 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1667, average loss: 1.4707
[10/01 02:28:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.50	top5: 98.50	
[10/01 02:28:41 visual_prompt]: 	Test 100/356. loss: 1.312, 0.2138 s / batch. (data: 7.77e-05)max mem: 7.81207 GB 
[10/01 02:29:02 visual_prompt]: 	Test 200/356. loss: 1.614, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:29:23 visual_prompt]: 	Test 300/356. loss: 1.419, 0.2146 s / batch. (data: 7.63e-05)max mem: 7.81207 GB 
[10/01 02:29:37 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2137, average loss: 1.4740
[10/01 02:29:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.98	top5: 98.20	
[10/01 02:29:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/01 02:29:47 visual_prompt]: Epoch 17 / 100: avg data time: 1.08e-01, avg batch time: 0.5579, average train loss: 1.3969
[10/01 02:29:51 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1669, average loss: 1.5056
[10/01 02:29:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 97.00	
[10/01 02:30:14 visual_prompt]: 	Test 100/356. loss: 1.427, 0.2135 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 02:30:35 visual_prompt]: 	Test 200/356. loss: 1.297, 0.2140 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:30:57 visual_prompt]: 	Test 300/356. loss: 1.380, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:31:10 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2138, average loss: 1.4892
[10/01 02:31:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.82	top5: 96.99	
[10/01 02:31:10 visual_prompt]: Best epoch 17: best metric: 0.380
[10/01 02:31:10 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/01 02:31:20 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e-01, avg batch time: 0.5588, average train loss: 1.3211
[10/01 02:31:24 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.2456
[10/01 02:31:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.00	top5: 98.00	
[10/01 02:31:47 visual_prompt]: 	Test 100/356. loss: 1.234, 0.2138 s / batch. (data: 8.94e-05)max mem: 7.81207 GB 
[10/01 02:32:08 visual_prompt]: 	Test 200/356. loss: 1.481, 0.2142 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:32:30 visual_prompt]: 	Test 300/356. loss: 1.334, 0.2143 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 02:32:43 visual_prompt]: Inference (test):avg data time: 4.18e-05, avg batch time: 0.2138, average loss: 1.3431
[10/01 02:32:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.66	top5: 98.08	
[10/01 02:32:43 visual_prompt]: Best epoch 18: best metric: 0.420
[10/01 02:32:43 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/01 02:32:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e-01, avg batch time: 0.5564, average train loss: 1.3292
[10/01 02:32:57 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1666, average loss: 1.6346
[10/01 02:32:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.00	top5: 84.00	
[10/01 02:33:20 visual_prompt]: 	Test 100/356. loss: 1.530, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 02:33:42 visual_prompt]: 	Test 200/356. loss: 1.462, 0.2142 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:34:03 visual_prompt]: 	Test 300/356. loss: 1.528, 0.2142 s / batch. (data: 8.06e-05)max mem: 7.81207 GB 
[10/01 02:34:17 visual_prompt]: Inference (test):avg data time: 4.28e-05, avg batch time: 0.2137, average loss: 1.6097
[10/01 02:34:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.06	top5: 88.42	
[10/01 02:34:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/01 02:34:27 visual_prompt]: Epoch 20 / 100: avg data time: 1.01e-01, avg batch time: 0.5506, average train loss: 1.4273
[10/01 02:34:30 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.7607
[10/01 02:34:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.50	top5: 90.50	
[10/01 02:34:53 visual_prompt]: 	Test 100/356. loss: 1.730, 0.2140 s / batch. (data: 7.99e-05)max mem: 7.81207 GB 
[10/01 02:35:15 visual_prompt]: 	Test 200/356. loss: 2.114, 0.2145 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:35:36 visual_prompt]: 	Test 300/356. loss: 1.736, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:35:50 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2137, average loss: 1.7896
[10/01 02:35:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.36	top5: 88.85	
[10/01 02:35:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/01 02:36:00 visual_prompt]: Epoch 21 / 100: avg data time: 1.02e-01, avg batch time: 0.5512, average train loss: 1.5537
[10/01 02:36:03 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1667, average loss: 1.4550
[10/01 02:36:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 96.00	
[10/01 02:36:26 visual_prompt]: 	Test 100/356. loss: 1.416, 0.2142 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 02:36:48 visual_prompt]: 	Test 200/356. loss: 1.937, 0.2144 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:37:09 visual_prompt]: 	Test 300/356. loss: 1.473, 0.2150 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:37:23 visual_prompt]: Inference (test):avg data time: 4.42e-05, avg batch time: 0.2139, average loss: 1.5757
[10/01 02:37:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.28	top5: 93.35	
[10/01 02:37:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/01 02:37:33 visual_prompt]: Epoch 22 / 100: avg data time: 9.93e-02, avg batch time: 0.5506, average train loss: 1.4141
[10/01 02:37:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1667, average loss: 1.3838
[10/01 02:37:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.00	top5: 98.50	
[10/01 02:38:00 visual_prompt]: 	Test 100/356. loss: 1.314, 0.2134 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 02:38:21 visual_prompt]: 	Test 200/356. loss: 1.360, 0.2142 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:38:43 visual_prompt]: 	Test 300/356. loss: 1.304, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:38:56 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2137, average loss: 1.3872
[10/01 02:38:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.63	top5: 97.25	
[10/01 02:38:56 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/01 02:39:06 visual_prompt]: Epoch 23 / 100: avg data time: 9.92e-02, avg batch time: 0.5507, average train loss: 1.2991
[10/01 02:39:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1668, average loss: 1.2923
[10/01 02:39:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 37.00	top5: 99.00	
[10/01 02:39:33 visual_prompt]: 	Test 100/356. loss: 1.219, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 02:39:54 visual_prompt]: 	Test 200/356. loss: 1.400, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:40:16 visual_prompt]: 	Test 300/356. loss: 1.326, 0.2147 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:40:29 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2140, average loss: 1.3553
[10/01 02:40:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.70	top5: 98.59	
[10/01 02:40:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/01 02:40:40 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e-01, avg batch time: 0.5547, average train loss: 1.3643
[10/01 02:40:43 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1668, average loss: 1.4363
[10/01 02:40:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 97.50	
[10/01 02:41:06 visual_prompt]: 	Test 100/356. loss: 1.244, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 02:41:28 visual_prompt]: 	Test 200/356. loss: 1.506, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 02:41:49 visual_prompt]: 	Test 300/356. loss: 1.525, 0.2148 s / batch. (data: 3.65e-05)max mem: 7.81207 GB 
[10/01 02:42:03 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2138, average loss: 1.4730
[10/01 02:42:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.87	top5: 97.25	
[10/01 02:42:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/01 02:42:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e-01, avg batch time: 0.5549, average train loss: 1.4457
[10/01 02:42:16 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 1.3070
[10/01 02:42:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.50	top5: 99.50	
[10/01 02:42:40 visual_prompt]: 	Test 100/356. loss: 1.395, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 02:43:01 visual_prompt]: 	Test 200/356. loss: 1.368, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 02:43:22 visual_prompt]: 	Test 300/356. loss: 1.324, 0.2146 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 02:43:36 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2136, average loss: 1.3601
[10/01 02:43:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.53	top5: 98.58	
[10/01 02:43:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/01 02:43:46 visual_prompt]: Epoch 26 / 100: avg data time: 1.11e-01, avg batch time: 0.5602, average train loss: 1.3988
[10/01 02:43:50 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1668, average loss: 1.3514
[10/01 02:43:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 98.00	
[10/01 02:44:13 visual_prompt]: 	Test 100/356. loss: 1.254, 0.2137 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 02:44:34 visual_prompt]: 	Test 200/356. loss: 1.279, 0.2139 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 02:44:56 visual_prompt]: 	Test 300/356. loss: 1.264, 0.2144 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 02:45:09 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2138, average loss: 1.3670
[10/01 02:45:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.65	top5: 98.13	
[10/01 02:45:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/01 02:45:19 visual_prompt]: Epoch 27 / 100: avg data time: 9.66e-02, avg batch time: 0.5481, average train loss: 1.3852
[10/01 02:45:23 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1668, average loss: 1.2398
[10/01 02:45:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.00	top5: 99.50	
[10/01 02:45:46 visual_prompt]: 	Test 100/356. loss: 1.289, 0.2138 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 02:46:07 visual_prompt]: 	Test 200/356. loss: 1.464, 0.2145 s / batch. (data: 1.05e-04)max mem: 7.81207 GB 
[10/01 02:46:29 visual_prompt]: 	Test 300/356. loss: 1.318, 0.2146 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:46:42 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2138, average loss: 1.3464
[10/01 02:46:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.04	top5: 97.50	
[10/01 02:46:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/01 02:46:52 visual_prompt]: Epoch 28 / 100: avg data time: 1.01e-01, avg batch time: 0.5513, average train loss: 1.2928
[10/01 02:46:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1667, average loss: 1.3384
[10/01 02:46:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 37.00	top5: 99.00	
[10/01 02:47:19 visual_prompt]: 	Test 100/356. loss: 1.352, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 02:47:40 visual_prompt]: 	Test 200/356. loss: 1.330, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 02:48:02 visual_prompt]: 	Test 300/356. loss: 1.292, 0.2151 s / batch. (data: 3.55e-05)max mem: 7.81207 GB 
[10/01 02:48:15 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2138, average loss: 1.3754
[10/01 02:48:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.54	top5: 97.69	
[10/01 02:48:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/01 02:48:25 visual_prompt]: Epoch 29 / 100: avg data time: 1.01e-01, avg batch time: 0.5514, average train loss: 1.2501
[10/01 02:48:29 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1668, average loss: 1.2543
[10/01 02:48:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 37.50	top5: 99.50	
[10/01 02:48:52 visual_prompt]: 	Test 100/356. loss: 1.418, 0.2136 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 02:49:13 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2145 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 02:49:35 visual_prompt]: 	Test 300/356. loss: 1.318, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:49:48 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2138, average loss: 1.3832
[10/01 02:49:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.96	top5: 97.78	
[10/01 02:49:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/01 02:49:59 visual_prompt]: Epoch 30 / 100: avg data time: 1.12e-01, avg batch time: 0.5621, average train loss: 1.3233
[10/01 02:50:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1667, average loss: 1.2773
[10/01 02:50:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.50	top5: 99.00	
[10/01 02:50:25 visual_prompt]: 	Test 100/356. loss: 1.270, 0.2135 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 02:50:47 visual_prompt]: 	Test 200/356. loss: 1.332, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 02:51:08 visual_prompt]: 	Test 300/356. loss: 1.321, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 02:51:22 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2137, average loss: 1.3810
[10/01 02:51:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.70	top5: 98.35	
[10/01 02:51:22 visual_prompt]: Best epoch 30: best metric: 0.435
[10/01 02:51:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/01 02:51:32 visual_prompt]: Epoch 31 / 100: avg data time: 1.04e-01, avg batch time: 0.5546, average train loss: 1.2589
[10/01 02:51:36 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1670, average loss: 1.2669
[10/01 02:51:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 99.00	
[10/01 02:51:59 visual_prompt]: 	Test 100/356. loss: 1.341, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 02:52:20 visual_prompt]: 	Test 200/356. loss: 1.452, 0.2150 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 02:52:42 visual_prompt]: 	Test 300/356. loss: 1.444, 0.2143 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 02:52:55 visual_prompt]: Inference (test):avg data time: 1.29e-04, avg batch time: 0.2138, average loss: 1.4461
[10/01 02:52:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.13	top5: 97.20	
[10/01 02:52:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/01 02:53:05 visual_prompt]: Epoch 32 / 100: avg data time: 1.08e-01, avg batch time: 0.5579, average train loss: 1.2544
[10/01 02:53:09 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1669, average loss: 1.4117
[10/01 02:53:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 96.50	
[10/01 02:53:32 visual_prompt]: 	Test 100/356. loss: 1.473, 0.2139 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 02:53:53 visual_prompt]: 	Test 200/356. loss: 1.602, 0.2142 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 02:54:15 visual_prompt]: 	Test 300/356. loss: 1.415, 0.2149 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:54:28 visual_prompt]: Inference (test):avg data time: 4.30e-05, avg batch time: 0.2138, average loss: 1.5014
[10/01 02:54:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.40	top5: 97.46	
[10/01 02:54:28 visual_prompt]: Best epoch 32: best metric: 0.440
[10/01 02:54:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/01 02:54:38 visual_prompt]: Epoch 33 / 100: avg data time: 1.12e-01, avg batch time: 0.5629, average train loss: 1.3512
[10/01 02:54:42 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1668, average loss: 1.4505
[10/01 02:54:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 97.50	
[10/01 02:55:05 visual_prompt]: 	Test 100/356. loss: 1.466, 0.2139 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 02:55:26 visual_prompt]: 	Test 200/356. loss: 1.289, 0.2144 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 02:55:48 visual_prompt]: 	Test 300/356. loss: 1.470, 0.2144 s / batch. (data: 7.18e-05)max mem: 7.81207 GB 
[10/01 02:56:01 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2137, average loss: 1.4910
[10/01 02:56:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.85	top5: 96.91	
[10/01 02:56:01 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/01 02:56:11 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e-01, avg batch time: 0.5558, average train loss: 1.3553
[10/01 02:56:15 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1666, average loss: 1.4268
[10/01 02:56:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.00	top5: 99.00	
[10/01 02:56:38 visual_prompt]: 	Test 100/356. loss: 1.321, 0.2138 s / batch. (data: 3.60e-05)max mem: 7.81207 GB 
[10/01 02:57:00 visual_prompt]: 	Test 200/356. loss: 1.633, 0.2144 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 02:57:21 visual_prompt]: 	Test 300/356. loss: 1.523, 0.2149 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 02:57:34 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2137, average loss: 1.4809
[10/01 02:57:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.20	top5: 97.84	
[10/01 02:57:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/01 02:57:45 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e-01, avg batch time: 0.5574, average train loss: 1.2981
[10/01 02:57:48 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1666, average loss: 1.5824
[10/01 02:57:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 35.00	top5: 99.00	
[10/01 02:58:11 visual_prompt]: 	Test 100/356. loss: 1.596, 0.2141 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 02:58:33 visual_prompt]: 	Test 200/356. loss: 1.716, 0.2144 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 02:58:54 visual_prompt]: 	Test 300/356. loss: 1.494, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 02:59:08 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2139, average loss: 1.6983
[10/01 02:59:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.44	top5: 97.08	
[10/01 02:59:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[10/01 02:59:18 visual_prompt]: Epoch 36 / 100: avg data time: 1.00e-01, avg batch time: 0.5524, average train loss: 1.2632
[10/01 02:59:21 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1667, average loss: 1.2428
[10/01 02:59:21 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.50	top5: 98.50	
[10/01 02:59:44 visual_prompt]: 	Test 100/356. loss: 1.379, 0.2139 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 03:00:06 visual_prompt]: 	Test 200/356. loss: 1.656, 0.2145 s / batch. (data: 6.96e-05)max mem: 7.81207 GB 
[10/01 03:00:27 visual_prompt]: 	Test 300/356. loss: 1.409, 0.2144 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 03:00:41 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2138, average loss: 1.4208
[10/01 03:00:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.62	top5: 97.22	
[10/01 03:00:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[10/01 03:00:51 visual_prompt]: Epoch 37 / 100: avg data time: 1.03e-01, avg batch time: 0.5544, average train loss: 1.2582
[10/01 03:00:54 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1678, average loss: 1.2684
[10/01 03:00:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 98.50	
[10/01 03:01:18 visual_prompt]: 	Test 100/356. loss: 1.435, 0.2140 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 03:01:39 visual_prompt]: 	Test 200/356. loss: 1.434, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:02:00 visual_prompt]: 	Test 300/356. loss: 1.365, 0.2145 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 03:02:14 visual_prompt]: Inference (test):avg data time: 4.79e-05, avg batch time: 0.2139, average loss: 1.3826
[10/01 03:02:14 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.13	top5: 97.85	
[10/01 03:02:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[10/01 03:02:24 visual_prompt]: Epoch 38 / 100: avg data time: 1.03e-01, avg batch time: 0.5534, average train loss: 1.2836
[10/01 03:02:28 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 1.3864
[10/01 03:02:28 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.00	top5: 100.00	
[10/01 03:02:51 visual_prompt]: 	Test 100/356. loss: 1.337, 0.2140 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 03:03:12 visual_prompt]: 	Test 200/356. loss: 1.539, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 03:03:34 visual_prompt]: 	Test 300/356. loss: 1.293, 0.2145 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 03:03:47 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2138, average loss: 1.4413
[10/01 03:03:47 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.99	top5: 97.68	
[10/01 03:03:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[10/01 03:03:57 visual_prompt]: Epoch 39 / 100: avg data time: 1.01e-01, avg batch time: 0.5525, average train loss: 1.2546
[10/01 03:04:01 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1668, average loss: 1.2270
[10/01 03:04:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[10/01 03:04:24 visual_prompt]: 	Test 100/356. loss: 1.259, 0.2138 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 03:04:45 visual_prompt]: 	Test 200/356. loss: 1.599, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:05:07 visual_prompt]: 	Test 300/356. loss: 1.351, 0.2145 s / batch. (data: 3.96e-05)max mem: 7.81207 GB 
[10/01 03:05:20 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2138, average loss: 1.3525
[10/01 03:05:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.97	top5: 97.70	
[10/01 03:05:20 visual_prompt]: Best epoch 39: best metric: 0.445
[10/01 03:05:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[10/01 03:05:31 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e-01, avg batch time: 0.5549, average train loss: 1.3490
[10/01 03:05:34 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1688, average loss: 1.3809
[10/01 03:05:34 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.50	top5: 99.00	
[10/01 03:05:57 visual_prompt]: 	Test 100/356. loss: 1.457, 0.2134 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 03:06:19 visual_prompt]: 	Test 200/356. loss: 1.333, 0.2142 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 03:06:40 visual_prompt]: 	Test 300/356. loss: 1.361, 0.2148 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 03:06:54 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2137, average loss: 1.4405
[10/01 03:06:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.44	top5: 96.60	
[10/01 03:06:54 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[10/01 03:07:04 visual_prompt]: Epoch 41 / 100: avg data time: 9.49e-02, avg batch time: 0.5468, average train loss: 1.3068
[10/01 03:07:07 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.4542
[10/01 03:07:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 98.50	
[10/01 03:07:30 visual_prompt]: 	Test 100/356. loss: 1.496, 0.2138 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 03:07:52 visual_prompt]: 	Test 200/356. loss: 1.460, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:08:13 visual_prompt]: 	Test 300/356. loss: 1.386, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:08:27 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2139, average loss: 1.4598
[10/01 03:08:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.82	top5: 97.27	
[10/01 03:08:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[10/01 03:08:37 visual_prompt]: Epoch 42 / 100: avg data time: 1.10e-01, avg batch time: 0.5585, average train loss: 1.2649
[10/01 03:08:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1667, average loss: 1.1487
[10/01 03:08:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 98.50	
[10/01 03:09:03 visual_prompt]: 	Test 100/356. loss: 1.204, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:09:25 visual_prompt]: 	Test 200/356. loss: 1.260, 0.2146 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 03:09:46 visual_prompt]: 	Test 300/356. loss: 1.273, 0.2148 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 03:10:00 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2137, average loss: 1.3025
[10/01 03:10:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.81	top5: 97.94	
[10/01 03:10:00 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[10/01 03:10:10 visual_prompt]: Epoch 43 / 100: avg data time: 1.17e-01, avg batch time: 0.5667, average train loss: 1.1877
[10/01 03:10:14 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 1.1595
[10/01 03:10:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 99.00	
[10/01 03:10:37 visual_prompt]: 	Test 100/356. loss: 1.383, 0.2140 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 03:10:58 visual_prompt]: 	Test 200/356. loss: 1.228, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 03:11:20 visual_prompt]: 	Test 300/356. loss: 1.142, 0.2145 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:11:33 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2138, average loss: 1.3178
[10/01 03:11:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.67	top5: 98.33	
[10/01 03:11:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[10/01 03:11:43 visual_prompt]: Epoch 44 / 100: avg data time: 1.10e-01, avg batch time: 0.5593, average train loss: 1.1972
[10/01 03:11:47 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1670, average loss: 1.1542
[10/01 03:11:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 99.50	
[10/01 03:12:10 visual_prompt]: 	Test 100/356. loss: 1.312, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 03:12:31 visual_prompt]: 	Test 200/356. loss: 1.532, 0.2169 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:12:53 visual_prompt]: 	Test 300/356. loss: 1.322, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:13:06 visual_prompt]: Inference (test):avg data time: 4.23e-05, avg batch time: 0.2139, average loss: 1.3400
[10/01 03:13:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.86	top5: 97.92	
[10/01 03:13:06 visual_prompt]: Best epoch 44: best metric: 0.465
[10/01 03:13:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[10/01 03:13:16 visual_prompt]: Epoch 45 / 100: avg data time: 1.01e-01, avg batch time: 0.5517, average train loss: 1.1412
[10/01 03:13:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1669, average loss: 1.2358
[10/01 03:13:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 99.50	
[10/01 03:13:43 visual_prompt]: 	Test 100/356. loss: 1.420, 0.2142 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:14:04 visual_prompt]: 	Test 200/356. loss: 1.358, 0.2145 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 03:14:26 visual_prompt]: 	Test 300/356. loss: 1.139, 0.2148 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:14:39 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2138, average loss: 1.3625
[10/01 03:14:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.70	top5: 98.16	
[10/01 03:14:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[10/01 03:14:50 visual_prompt]: Epoch 46 / 100: avg data time: 1.01e-01, avg batch time: 0.5527, average train loss: 1.1562
[10/01 03:14:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1666, average loss: 1.4256
[10/01 03:14:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 97.50	
[10/01 03:15:16 visual_prompt]: 	Test 100/356. loss: 1.462, 0.2138 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 03:15:38 visual_prompt]: 	Test 200/356. loss: 1.923, 0.2142 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 03:15:59 visual_prompt]: 	Test 300/356. loss: 1.484, 0.2150 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 03:16:12 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2138, average loss: 1.5987
[10/01 03:16:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.46	top5: 97.01	
[10/01 03:16:13 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[10/01 03:16:23 visual_prompt]: Epoch 47 / 100: avg data time: 1.03e-01, avg batch time: 0.5538, average train loss: 1.1489
[10/01 03:16:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.0861
[10/01 03:16:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 99.50	
[10/01 03:16:49 visual_prompt]: 	Test 100/356. loss: 1.423, 0.2142 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 03:17:11 visual_prompt]: 	Test 200/356. loss: 1.356, 0.2149 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 03:17:32 visual_prompt]: 	Test 300/356. loss: 1.166, 0.2145 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 03:17:46 visual_prompt]: Inference (test):avg data time: 5.52e-05, avg batch time: 0.2138, average loss: 1.3633
[10/01 03:17:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.79	top5: 98.70	
[10/01 03:17:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[10/01 03:17:56 visual_prompt]: Epoch 48 / 100: avg data time: 1.07e-01, avg batch time: 0.5576, average train loss: 1.2098
[10/01 03:18:00 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.0779
[10/01 03:18:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 99.00	
[10/01 03:18:23 visual_prompt]: 	Test 100/356. loss: 1.243, 0.2136 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 03:18:44 visual_prompt]: 	Test 200/356. loss: 1.451, 0.2140 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 03:19:06 visual_prompt]: 	Test 300/356. loss: 1.262, 0.2145 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 03:19:19 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2136, average loss: 1.3442
[10/01 03:19:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.33	top5: 97.76	
[10/01 03:19:19 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[10/01 03:19:29 visual_prompt]: Epoch 49 / 100: avg data time: 1.05e-01, avg batch time: 0.5578, average train loss: 1.2531
[10/01 03:19:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1666, average loss: 1.3816
[10/01 03:19:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 99.50	
[10/01 03:19:56 visual_prompt]: 	Test 100/356. loss: 1.374, 0.2141 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:20:17 visual_prompt]: 	Test 200/356. loss: 1.397, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:20:39 visual_prompt]: 	Test 300/356. loss: 1.477, 0.2147 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:20:52 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2137, average loss: 1.5077
[10/01 03:20:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.66	top5: 96.67	
[10/01 03:20:52 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[10/01 03:21:02 visual_prompt]: Epoch 50 / 100: avg data time: 1.05e-01, avg batch time: 0.5545, average train loss: 1.2072
[10/01 03:21:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 1.1161
[10/01 03:21:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 99.50	
[10/01 03:21:29 visual_prompt]: 	Test 100/356. loss: 1.257, 0.2136 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 03:21:51 visual_prompt]: 	Test 200/356. loss: 1.555, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:22:12 visual_prompt]: 	Test 300/356. loss: 1.347, 0.2141 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 03:22:26 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2137, average loss: 1.3785
[10/01 03:22:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.68	top5: 97.17	
[10/01 03:22:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[10/01 03:22:36 visual_prompt]: Epoch 51 / 100: avg data time: 9.93e-02, avg batch time: 0.5497, average train loss: 1.1443
[10/01 03:22:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1667, average loss: 1.1603
[10/01 03:22:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 98.00	
[10/01 03:23:03 visual_prompt]: 	Test 100/356. loss: 1.380, 0.2136 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:23:24 visual_prompt]: 	Test 200/356. loss: 1.501, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:23:45 visual_prompt]: 	Test 300/356. loss: 1.399, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 03:23:59 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2139, average loss: 1.4314
[10/01 03:23:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.36	top5: 97.87	
[10/01 03:23:59 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[10/01 03:24:09 visual_prompt]: Epoch 52 / 100: avg data time: 1.02e-01, avg batch time: 0.5522, average train loss: 1.1264
[10/01 03:24:13 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1668, average loss: 1.1472
[10/01 03:24:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.50	top5: 99.00	
[10/01 03:24:36 visual_prompt]: 	Test 100/356. loss: 1.200, 0.2135 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 03:24:57 visual_prompt]: 	Test 200/356. loss: 1.340, 0.2145 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 03:25:19 visual_prompt]: 	Test 300/356. loss: 1.279, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:25:32 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2138, average loss: 1.4141
[10/01 03:25:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.17	top5: 97.96	
[10/01 03:25:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[10/01 03:25:42 visual_prompt]: Epoch 53 / 100: avg data time: 1.01e-01, avg batch time: 0.5519, average train loss: 1.0441
[10/01 03:25:46 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1668, average loss: 1.0754
[10/01 03:25:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 99.50	
[10/01 03:26:09 visual_prompt]: 	Test 100/356. loss: 1.379, 0.2141 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 03:26:30 visual_prompt]: 	Test 200/356. loss: 1.661, 0.2145 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 03:26:52 visual_prompt]: 	Test 300/356. loss: 1.481, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 03:27:05 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2138, average loss: 1.5145
[10/01 03:27:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.64	top5: 97.54	
[10/01 03:27:05 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[10/01 03:27:15 visual_prompt]: Epoch 54 / 100: avg data time: 1.02e-01, avg batch time: 0.5515, average train loss: 1.1128
[10/01 03:27:19 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1666, average loss: 1.0656
[10/01 03:27:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 98.50	
[10/01 03:27:42 visual_prompt]: 	Test 100/356. loss: 1.226, 0.2143 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 03:28:03 visual_prompt]: 	Test 200/356. loss: 1.282, 0.2146 s / batch. (data: 3.36e-05)max mem: 7.81207 GB 
[10/01 03:28:25 visual_prompt]: 	Test 300/356. loss: 1.286, 0.2146 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:28:38 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2137, average loss: 1.3151
[10/01 03:28:38 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.01	top5: 97.86	
[10/01 03:28:38 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[10/01 03:28:49 visual_prompt]: Epoch 55 / 100: avg data time: 1.14e-01, avg batch time: 0.5639, average train loss: 1.0880
[10/01 03:28:52 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1669, average loss: 1.0962
[10/01 03:28:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.00	top5: 98.50	
[10/01 03:29:15 visual_prompt]: 	Test 100/356. loss: 1.247, 0.2134 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 03:29:37 visual_prompt]: 	Test 200/356. loss: 1.333, 0.2141 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 03:29:58 visual_prompt]: 	Test 300/356. loss: 1.141, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:30:12 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2138, average loss: 1.3124
[10/01 03:30:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.50	top5: 97.98	
[10/01 03:30:12 visual_prompt]: Best epoch 55: best metric: 0.470
[10/01 03:30:12 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[10/01 03:30:22 visual_prompt]: Epoch 56 / 100: avg data time: 9.92e-02, avg batch time: 0.5492, average train loss: 1.0872
[10/01 03:30:25 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.1990
[10/01 03:30:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 99.00	
[10/01 03:30:48 visual_prompt]: 	Test 100/356. loss: 1.451, 0.2139 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 03:31:10 visual_prompt]: 	Test 200/356. loss: 1.888, 0.2141 s / batch. (data: 3.46e-05)max mem: 7.81207 GB 
[10/01 03:31:31 visual_prompt]: 	Test 300/356. loss: 1.505, 0.2147 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 03:31:45 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2138, average loss: 1.5293
[10/01 03:31:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.85	top5: 94.22	
[10/01 03:31:45 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[10/01 03:31:55 visual_prompt]: Epoch 57 / 100: avg data time: 1.07e-01, avg batch time: 0.5562, average train loss: 1.2379
[10/01 03:31:58 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 1.0820
[10/01 03:31:58 visual_prompt]: Classification results with val_vtab-dmlab: top1: 54.00	top5: 100.00	
[10/01 03:32:22 visual_prompt]: 	Test 100/356. loss: 1.455, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 03:32:43 visual_prompt]: 	Test 200/356. loss: 1.428, 0.2148 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 03:33:05 visual_prompt]: 	Test 300/356. loss: 1.417, 0.2145 s / batch. (data: 8.25e-05)max mem: 7.81207 GB 
[10/01 03:33:18 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2137, average loss: 1.4094
[10/01 03:33:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.13	top5: 98.21	
[10/01 03:33:18 visual_prompt]: Best epoch 57: best metric: 0.540
[10/01 03:33:18 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[10/01 03:33:28 visual_prompt]: Epoch 58 / 100: avg data time: 1.05e-01, avg batch time: 0.5542, average train loss: 1.1973
[10/01 03:33:32 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1668, average loss: 1.1676
[10/01 03:33:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.50	top5: 99.50	
[10/01 03:33:55 visual_prompt]: 	Test 100/356. loss: 1.517, 0.2143 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 03:34:16 visual_prompt]: 	Test 200/356. loss: 1.358, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 03:34:38 visual_prompt]: 	Test 300/356. loss: 1.469, 0.2144 s / batch. (data: 9.85e-05)max mem: 7.81207 GB 
[10/01 03:34:51 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2138, average loss: 1.4669
[10/01 03:34:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.47	top5: 97.06	
[10/01 03:34:51 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[10/01 03:35:01 visual_prompt]: Epoch 59 / 100: avg data time: 1.10e-01, avg batch time: 0.5594, average train loss: 1.1083
[10/01 03:35:05 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1666, average loss: 1.0469
[10/01 03:35:05 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.00	top5: 100.00	
[10/01 03:35:28 visual_prompt]: 	Test 100/356. loss: 1.375, 0.2139 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 03:35:50 visual_prompt]: 	Test 200/356. loss: 1.465, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 03:36:11 visual_prompt]: 	Test 300/356. loss: 1.419, 0.2143 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 03:36:24 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2137, average loss: 1.4266
[10/01 03:36:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.65	top5: 97.34	
[10/01 03:36:24 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[10/01 03:36:35 visual_prompt]: Epoch 60 / 100: avg data time: 1.13e-01, avg batch time: 0.5634, average train loss: 1.0082
[10/01 03:36:38 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 0.9604
[10/01 03:36:38 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.00	
[10/01 03:37:01 visual_prompt]: 	Test 100/356. loss: 1.234, 0.2137 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 03:37:23 visual_prompt]: 	Test 200/356. loss: 1.367, 0.2142 s / batch. (data: 6.82e-05)max mem: 7.81207 GB 
[10/01 03:37:44 visual_prompt]: 	Test 300/356. loss: 1.317, 0.2147 s / batch. (data: 3.17e-05)max mem: 7.81207 GB 
[10/01 03:37:58 visual_prompt]: Inference (test):avg data time: 5.80e-05, avg batch time: 0.2137, average loss: 1.3254
[10/01 03:37:58 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.01	top5: 98.28	
[10/01 03:37:58 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[10/01 03:38:08 visual_prompt]: Epoch 61 / 100: avg data time: 1.03e-01, avg batch time: 0.5534, average train loss: 1.0004
[10/01 03:38:12 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1668, average loss: 0.9176
[10/01 03:38:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 99.50	
[10/01 03:38:35 visual_prompt]: 	Test 100/356. loss: 1.216, 0.2135 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:38:56 visual_prompt]: 	Test 200/356. loss: 1.599, 0.2143 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:39:18 visual_prompt]: 	Test 300/356. loss: 1.305, 0.2144 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 03:39:31 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2137, average loss: 1.4025
[10/01 03:39:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.33	top5: 98.39	
[10/01 03:39:31 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[10/01 03:39:41 visual_prompt]: Epoch 62 / 100: avg data time: 9.92e-02, avg batch time: 0.5490, average train loss: 1.0571
[10/01 03:39:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 1.4335
[10/01 03:39:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 96.00	
[10/01 03:40:08 visual_prompt]: 	Test 100/356. loss: 1.671, 0.2143 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 03:40:29 visual_prompt]: 	Test 200/356. loss: 1.907, 0.2144 s / batch. (data: 6.56e-05)max mem: 7.81207 GB 
[10/01 03:40:51 visual_prompt]: 	Test 300/356. loss: 1.639, 0.2154 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 03:41:04 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2137, average loss: 1.7991
[10/01 03:41:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.00	top5: 96.03	
[10/01 03:41:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[10/01 03:41:14 visual_prompt]: Epoch 63 / 100: avg data time: 1.03e-01, avg batch time: 0.5536, average train loss: 1.2040
[10/01 03:41:18 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1667, average loss: 1.1059
[10/01 03:41:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.00	top5: 100.00	
[10/01 03:41:41 visual_prompt]: 	Test 100/356. loss: 1.356, 0.2137 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:42:03 visual_prompt]: 	Test 200/356. loss: 1.605, 0.2141 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 03:42:24 visual_prompt]: 	Test 300/356. loss: 1.295, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:42:37 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2137, average loss: 1.4586
[10/01 03:42:38 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.33	top5: 97.64	
[10/01 03:42:38 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[10/01 03:42:48 visual_prompt]: Epoch 64 / 100: avg data time: 1.10e-01, avg batch time: 0.5595, average train loss: 1.0590
[10/01 03:42:51 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 0.9426
[10/01 03:42:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 55.00	top5: 100.00	
[10/01 03:43:14 visual_prompt]: 	Test 100/356. loss: 1.302, 0.2139 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 03:43:36 visual_prompt]: 	Test 200/356. loss: 1.657, 0.2141 s / batch. (data: 7.89e-05)max mem: 7.81207 GB 
[10/01 03:43:57 visual_prompt]: 	Test 300/356. loss: 1.317, 0.2149 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 03:44:11 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2137, average loss: 1.3756
[10/01 03:44:11 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.30	top5: 97.26	
[10/01 03:44:11 visual_prompt]: Best epoch 64: best metric: 0.550
[10/01 03:44:11 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[10/01 03:44:21 visual_prompt]: Epoch 65 / 100: avg data time: 1.13e-01, avg batch time: 0.5631, average train loss: 0.9512
[10/01 03:44:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 0.9543
[10/01 03:44:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 51.50	top5: 100.00	
[10/01 03:44:48 visual_prompt]: 	Test 100/356. loss: 1.538, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:45:09 visual_prompt]: 	Test 200/356. loss: 1.574, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:45:31 visual_prompt]: 	Test 300/356. loss: 1.426, 0.2145 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:45:44 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2137, average loss: 1.5138
[10/01 03:45:44 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.74	top5: 98.01	
[10/01 03:45:44 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[10/01 03:45:55 visual_prompt]: Epoch 66 / 100: avg data time: 1.13e-01, avg batch time: 0.5625, average train loss: 0.8872
[10/01 03:45:58 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1666, average loss: 0.8608
[10/01 03:45:58 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.50	top5: 99.50	
[10/01 03:46:21 visual_prompt]: 	Test 100/356. loss: 1.411, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 03:46:43 visual_prompt]: 	Test 200/356. loss: 1.416, 0.2138 s / batch. (data: 7.63e-05)max mem: 7.81207 GB 
[10/01 03:47:04 visual_prompt]: 	Test 300/356. loss: 1.343, 0.2146 s / batch. (data: 3.17e-05)max mem: 7.81207 GB 
[10/01 03:47:18 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2138, average loss: 1.4640
[10/01 03:47:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.76	top5: 98.30	
[10/01 03:47:18 visual_prompt]: Best epoch 66: best metric: 0.585
[10/01 03:47:18 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[10/01 03:47:28 visual_prompt]: Epoch 67 / 100: avg data time: 9.88e-02, avg batch time: 0.5494, average train loss: 0.9215
[10/01 03:47:31 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1669, average loss: 0.8916
[10/01 03:47:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 59.00	top5: 100.00	
[10/01 03:47:54 visual_prompt]: 	Test 100/356. loss: 1.361, 0.2134 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 03:48:16 visual_prompt]: 	Test 200/356. loss: 1.292, 0.2140 s / batch. (data: 9.18e-05)max mem: 7.81207 GB 
[10/01 03:48:37 visual_prompt]: 	Test 300/356. loss: 1.384, 0.2143 s / batch. (data: 3.34e-05)max mem: 7.81207 GB 
[10/01 03:48:51 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2137, average loss: 1.4283
[10/01 03:48:51 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.89	top5: 97.32	
[10/01 03:48:51 visual_prompt]: Best epoch 67: best metric: 0.590
[10/01 03:48:51 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[10/01 03:49:01 visual_prompt]: Epoch 68 / 100: avg data time: 9.96e-02, avg batch time: 0.5500, average train loss: 0.9179
[10/01 03:49:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1668, average loss: 0.8762
[10/01 03:49:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.00	top5: 100.00	
[10/01 03:49:27 visual_prompt]: 	Test 100/356. loss: 1.374, 0.2143 s / batch. (data: 6.75e-05)max mem: 7.81207 GB 
[10/01 03:49:49 visual_prompt]: 	Test 200/356. loss: 1.498, 0.2138 s / batch. (data: 7.32e-05)max mem: 7.81207 GB 
[10/01 03:50:10 visual_prompt]: 	Test 300/356. loss: 1.386, 0.2142 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 03:50:24 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2138, average loss: 1.4930
[10/01 03:50:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.83	top5: 97.98	
[10/01 03:50:24 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[10/01 03:50:34 visual_prompt]: Epoch 69 / 100: avg data time: 1.04e-01, avg batch time: 0.5560, average train loss: 0.9379
[10/01 03:50:37 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1668, average loss: 0.8057
[10/01 03:50:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.50	top5: 100.00	
[10/01 03:51:00 visual_prompt]: 	Test 100/356. loss: 1.328, 0.2133 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 03:51:22 visual_prompt]: 	Test 200/356. loss: 1.668, 0.2144 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 03:51:43 visual_prompt]: 	Test 300/356. loss: 1.415, 0.2147 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 03:51:57 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2137, average loss: 1.5287
[10/01 03:51:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.48	top5: 97.66	
[10/01 03:51:57 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[10/01 03:52:07 visual_prompt]: Epoch 70 / 100: avg data time: 9.96e-02, avg batch time: 0.5501, average train loss: 0.9346
[10/01 03:52:11 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 0.7969
[10/01 03:52:11 visual_prompt]: Classification results with val_vtab-dmlab: top1: 61.50	top5: 99.50	
[10/01 03:52:34 visual_prompt]: 	Test 100/356. loss: 1.382, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 03:52:55 visual_prompt]: 	Test 200/356. loss: 1.536, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 03:53:16 visual_prompt]: 	Test 300/356. loss: 1.482, 0.2145 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:53:30 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2137, average loss: 1.5433
[10/01 03:53:30 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.18	top5: 97.75	
[10/01 03:53:30 visual_prompt]: Best epoch 70: best metric: 0.615
[10/01 03:53:30 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[10/01 03:53:40 visual_prompt]: Epoch 71 / 100: avg data time: 1.13e-01, avg batch time: 0.5624, average train loss: 0.9065
[10/01 03:53:44 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1666, average loss: 0.8558
[10/01 03:53:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.50	top5: 99.50	
[10/01 03:54:07 visual_prompt]: 	Test 100/356. loss: 1.500, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:54:28 visual_prompt]: 	Test 200/356. loss: 1.448, 0.2141 s / batch. (data: 8.85e-05)max mem: 7.81207 GB 
[10/01 03:54:50 visual_prompt]: 	Test 300/356. loss: 1.427, 0.2151 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 03:55:03 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2140, average loss: 1.4813
[10/01 03:55:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.13	top5: 97.62	
[10/01 03:55:03 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[10/01 03:55:13 visual_prompt]: Epoch 72 / 100: avg data time: 1.02e-01, avg batch time: 0.5534, average train loss: 0.8124
[10/01 03:55:17 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1666, average loss: 0.7709
[10/01 03:55:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 65.50	top5: 100.00	
[10/01 03:55:40 visual_prompt]: 	Test 100/356. loss: 1.531, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:56:01 visual_prompt]: 	Test 200/356. loss: 1.717, 0.2144 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 03:56:23 visual_prompt]: 	Test 300/356. loss: 1.641, 0.2149 s / batch. (data: 7.87e-05)max mem: 7.81207 GB 
[10/01 03:56:36 visual_prompt]: Inference (test):avg data time: 5.05e-05, avg batch time: 0.2137, average loss: 1.6727
[10/01 03:56:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.02	top5: 97.31	
[10/01 03:56:36 visual_prompt]: Best epoch 72: best metric: 0.655
[10/01 03:56:36 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[10/01 03:56:46 visual_prompt]: Epoch 73 / 100: avg data time: 1.02e-01, avg batch time: 0.5543, average train loss: 0.7949
[10/01 03:56:50 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1667, average loss: 0.8785
[10/01 03:56:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 55.00	top5: 100.00	
[10/01 03:57:13 visual_prompt]: 	Test 100/356. loss: 1.582, 0.2135 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:57:34 visual_prompt]: 	Test 200/356. loss: 1.498, 0.2140 s / batch. (data: 7.77e-05)max mem: 7.81207 GB 
[10/01 03:57:56 visual_prompt]: 	Test 300/356. loss: 1.713, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 03:58:09 visual_prompt]: Inference (test):avg data time: 4.50e-05, avg batch time: 0.2137, average loss: 1.6474
[10/01 03:58:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.23	top5: 97.99	
[10/01 03:58:09 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[10/01 03:58:20 visual_prompt]: Epoch 74 / 100: avg data time: 1.07e-01, avg batch time: 0.5557, average train loss: 0.7681
[10/01 03:58:23 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 0.7732
[10/01 03:58:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 67.00	top5: 100.00	
[10/01 03:58:46 visual_prompt]: 	Test 100/356. loss: 1.457, 0.2135 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 03:59:08 visual_prompt]: 	Test 200/356. loss: 1.701, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 03:59:29 visual_prompt]: 	Test 300/356. loss: 1.892, 0.2145 s / batch. (data: 3.24e-05)max mem: 7.81207 GB 
[10/01 03:59:43 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2137, average loss: 1.7525
[10/01 03:59:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.49	top5: 97.08	
[10/01 03:59:43 visual_prompt]: Best epoch 74: best metric: 0.670
[10/01 03:59:43 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[10/01 03:59:53 visual_prompt]: Epoch 75 / 100: avg data time: 1.03e-01, avg batch time: 0.5533, average train loss: 0.7068
[10/01 03:59:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1684, average loss: 0.7663
[10/01 03:59:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 65.00	top5: 100.00	
[10/01 04:00:20 visual_prompt]: 	Test 100/356. loss: 1.705, 0.2137 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 04:00:41 visual_prompt]: 	Test 200/356. loss: 1.526, 0.2151 s / batch. (data: 9.25e-05)max mem: 7.81207 GB 
[10/01 04:01:02 visual_prompt]: 	Test 300/356. loss: 1.919, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:01:16 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2137, average loss: 1.8145
[10/01 04:01:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.87	top5: 97.96	
[10/01 04:01:16 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[10/01 04:01:26 visual_prompt]: Epoch 76 / 100: avg data time: 1.11e-01, avg batch time: 0.5611, average train loss: 0.7262
[10/01 04:01:30 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 0.6704
[10/01 04:01:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 65.00	top5: 100.00	
[10/01 04:01:53 visual_prompt]: 	Test 100/356. loss: 1.686, 0.2140 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 04:02:14 visual_prompt]: 	Test 200/356. loss: 1.636, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:02:36 visual_prompt]: 	Test 300/356. loss: 1.866, 0.2144 s / batch. (data: 3.84e-05)max mem: 7.81207 GB 
[10/01 04:02:49 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2137, average loss: 1.7630
[10/01 04:02:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.15	top5: 98.19	
[10/01 04:02:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[10/01 04:02:59 visual_prompt]: Epoch 77 / 100: avg data time: 1.07e-01, avg batch time: 0.5574, average train loss: 0.6776
[10/01 04:03:03 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1666, average loss: 0.5811
[10/01 04:03:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 71.50	top5: 100.00	
[10/01 04:03:26 visual_prompt]: 	Test 100/356. loss: 1.697, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:03:48 visual_prompt]: 	Test 200/356. loss: 1.943, 0.2142 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 04:04:09 visual_prompt]: 	Test 300/356. loss: 1.770, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 04:04:23 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2138, average loss: 1.8085
[10/01 04:04:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.52	top5: 97.66	
[10/01 04:04:23 visual_prompt]: Best epoch 77: best metric: 0.715
[10/01 04:04:23 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[10/01 04:04:33 visual_prompt]: Epoch 78 / 100: avg data time: 1.07e-01, avg batch time: 0.5596, average train loss: 0.6793
[10/01 04:04:37 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 1.1212
[10/01 04:04:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.50	top5: 99.50	
[10/01 04:05:00 visual_prompt]: 	Test 100/356. loss: 2.156, 0.2137 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 04:05:21 visual_prompt]: 	Test 200/356. loss: 2.025, 0.2143 s / batch. (data: 6.91e-05)max mem: 7.81207 GB 
[10/01 04:05:42 visual_prompt]: 	Test 300/356. loss: 2.179, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 04:05:56 visual_prompt]: Inference (test):avg data time: 8.50e-05, avg batch time: 0.2138, average loss: 2.1506
[10/01 04:05:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.97	top5: 97.73	
[10/01 04:05:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[10/01 04:06:06 visual_prompt]: Epoch 79 / 100: avg data time: 1.21e-01, avg batch time: 0.5700, average train loss: 0.7666
[10/01 04:06:10 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1664, average loss: 0.6250
[10/01 04:06:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 70.00	top5: 100.00	
[10/01 04:06:33 visual_prompt]: 	Test 100/356. loss: 1.463, 0.2137 s / batch. (data: 7.58e-05)max mem: 7.81207 GB 
[10/01 04:06:55 visual_prompt]: 	Test 200/356. loss: 2.061, 0.2140 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 04:07:16 visual_prompt]: 	Test 300/356. loss: 1.604, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:07:29 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2136, average loss: 1.7604
[10/01 04:07:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.99	top5: 97.86	
[10/01 04:07:29 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[10/01 04:07:40 visual_prompt]: Epoch 80 / 100: avg data time: 1.13e-01, avg batch time: 0.5621, average train loss: 0.6607
[10/01 04:07:43 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 0.5947
[10/01 04:07:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 70.00	top5: 100.00	
[10/01 04:08:06 visual_prompt]: 	Test 100/356. loss: 1.671, 0.2134 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 04:08:28 visual_prompt]: 	Test 200/356. loss: 1.880, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:08:49 visual_prompt]: 	Test 300/356. loss: 1.955, 0.2149 s / batch. (data: 7.94e-05)max mem: 7.81207 GB 
[10/01 04:09:03 visual_prompt]: Inference (test):avg data time: 6.17e-05, avg batch time: 0.2138, average loss: 1.8961
[10/01 04:09:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.89	top5: 97.79	
[10/01 04:09:03 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[10/01 04:09:13 visual_prompt]: Epoch 81 / 100: avg data time: 1.04e-01, avg batch time: 0.5536, average train loss: 0.6015
[10/01 04:09:16 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1667, average loss: 0.5561
[10/01 04:09:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 74.00	top5: 99.50	
[10/01 04:09:39 visual_prompt]: 	Test 100/356. loss: 1.505, 0.2139 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 04:10:01 visual_prompt]: 	Test 200/356. loss: 1.991, 0.2143 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 04:10:22 visual_prompt]: 	Test 300/356. loss: 1.846, 0.2149 s / batch. (data: 6.34e-05)max mem: 7.81207 GB 
[10/01 04:10:36 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2137, average loss: 1.8487
[10/01 04:10:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.76	top5: 96.90	
[10/01 04:10:36 visual_prompt]: Best epoch 81: best metric: 0.740
[10/01 04:10:36 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[10/01 04:10:46 visual_prompt]: Epoch 82 / 100: avg data time: 1.00e-01, avg batch time: 0.5502, average train loss: 0.5530
[10/01 04:10:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1688, average loss: 0.4865
[10/01 04:10:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 76.00	top5: 100.00	
[10/01 04:11:12 visual_prompt]: 	Test 100/356. loss: 1.548, 0.2134 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 04:11:34 visual_prompt]: 	Test 200/356. loss: 2.106, 0.2140 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 04:11:55 visual_prompt]: 	Test 300/356. loss: 1.844, 0.2147 s / batch. (data: 1.07e-04)max mem: 7.81207 GB 
[10/01 04:12:09 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2138, average loss: 2.0426
[10/01 04:12:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.78	top5: 98.06	
[10/01 04:12:09 visual_prompt]: Best epoch 82: best metric: 0.760
[10/01 04:12:09 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[10/01 04:12:19 visual_prompt]: Epoch 83 / 100: avg data time: 1.19e-01, avg batch time: 0.5674, average train loss: 0.4255
[10/01 04:12:23 visual_prompt]: Inference (val):avg data time: 4.67e-05, avg batch time: 0.1668, average loss: 0.6088
[10/01 04:12:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 72.50	top5: 100.00	
[10/01 04:12:46 visual_prompt]: 	Test 100/356. loss: 1.680, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 04:13:07 visual_prompt]: 	Test 200/356. loss: 2.772, 0.2137 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:13:29 visual_prompt]: 	Test 300/356. loss: 2.489, 0.2146 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 04:13:42 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2136, average loss: 2.6940
[10/01 04:13:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.12	top5: 98.02	
[10/01 04:13:42 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[10/01 04:13:52 visual_prompt]: Epoch 84 / 100: avg data time: 1.02e-01, avg batch time: 0.5523, average train loss: 0.4882
[10/01 04:13:56 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1666, average loss: 0.5783
[10/01 04:13:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 73.00	top5: 100.00	
[10/01 04:14:19 visual_prompt]: 	Test 100/356. loss: 1.731, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:14:40 visual_prompt]: 	Test 200/356. loss: 2.215, 0.2140 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:15:02 visual_prompt]: 	Test 300/356. loss: 2.008, 0.2148 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:15:15 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2137, average loss: 2.1462
[10/01 04:15:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.65	top5: 97.98	
[10/01 04:15:15 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[10/01 04:15:25 visual_prompt]: Epoch 85 / 100: avg data time: 9.96e-02, avg batch time: 0.5509, average train loss: 0.3913
[10/01 04:15:29 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1671, average loss: 0.4868
[10/01 04:15:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 73.00	top5: 100.00	
[10/01 04:15:52 visual_prompt]: 	Test 100/356. loss: 1.878, 0.2153 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 04:16:13 visual_prompt]: 	Test 200/356. loss: 2.567, 0.2141 s / batch. (data: 7.65e-05)max mem: 7.81207 GB 
[10/01 04:16:35 visual_prompt]: 	Test 300/356. loss: 2.215, 0.2142 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:16:48 visual_prompt]: Inference (test):avg data time: 6.27e-05, avg batch time: 0.2137, average loss: 2.4620
[10/01 04:16:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.17	top5: 97.44	
[10/01 04:16:48 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[10/01 04:16:59 visual_prompt]: Epoch 86 / 100: avg data time: 1.03e-01, avg batch time: 0.5538, average train loss: 0.3798
[10/01 04:17:02 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1666, average loss: 0.3000
[10/01 04:17:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 87.00	top5: 100.00	
[10/01 04:17:25 visual_prompt]: 	Test 100/356. loss: 2.098, 0.2136 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 04:17:47 visual_prompt]: 	Test 200/356. loss: 2.909, 0.2143 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:18:08 visual_prompt]: 	Test 300/356. loss: 2.799, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 04:18:22 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2138, average loss: 2.6659
[10/01 04:18:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.86	top5: 96.89	
[10/01 04:18:22 visual_prompt]: Best epoch 86: best metric: 0.870
[10/01 04:18:22 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[10/01 04:18:32 visual_prompt]: Epoch 87 / 100: avg data time: 1.07e-01, avg batch time: 0.5573, average train loss: 0.3825
[10/01 04:18:35 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1667, average loss: 0.5093
[10/01 04:18:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 78.50	top5: 100.00	
[10/01 04:18:59 visual_prompt]: 	Test 100/356. loss: 2.270, 0.2138 s / batch. (data: 9.73e-05)max mem: 7.81207 GB 
[10/01 04:19:20 visual_prompt]: 	Test 200/356. loss: 2.238, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 04:19:41 visual_prompt]: 	Test 300/356. loss: 2.172, 0.2143 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 04:19:55 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2137, average loss: 2.6027
[10/01 04:19:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.83	top5: 97.62	
[10/01 04:19:55 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[10/01 04:20:05 visual_prompt]: Epoch 88 / 100: avg data time: 1.11e-01, avg batch time: 0.5603, average train loss: 0.2705
[10/01 04:20:09 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1667, average loss: 0.3702
[10/01 04:20:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 81.50	top5: 100.00	
[10/01 04:20:32 visual_prompt]: 	Test 100/356. loss: 2.524, 0.2139 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 04:20:53 visual_prompt]: 	Test 200/356. loss: 2.861, 0.2142 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:21:15 visual_prompt]: 	Test 300/356. loss: 2.519, 0.2145 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 04:21:28 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2137, average loss: 2.8165
[10/01 04:21:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.18	top5: 97.73	
[10/01 04:21:28 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[10/01 04:21:38 visual_prompt]: Epoch 89 / 100: avg data time: 1.05e-01, avg batch time: 0.5566, average train loss: 0.2867
[10/01 04:21:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1668, average loss: 0.3201
[10/01 04:21:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 87.00	top5: 100.00	
[10/01 04:22:05 visual_prompt]: 	Test 100/356. loss: 2.313, 0.2137 s / batch. (data: 3.53e-05)max mem: 7.81207 GB 
[10/01 04:22:26 visual_prompt]: 	Test 200/356. loss: 2.398, 0.2143 s / batch. (data: 3.36e-05)max mem: 7.81207 GB 
[10/01 04:22:48 visual_prompt]: 	Test 300/356. loss: 2.513, 0.2145 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:23:01 visual_prompt]: Inference (test):avg data time: 2.90e-05, avg batch time: 0.2137, average loss: 2.7538
[10/01 04:23:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.01	top5: 97.44	
[10/01 04:23:01 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[10/01 04:23:11 visual_prompt]: Epoch 90 / 100: avg data time: 1.12e-01, avg batch time: 0.5617, average train loss: 0.2554
[10/01 04:23:15 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1668, average loss: 0.2597
[10/01 04:23:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 88.50	top5: 100.00	
[10/01 04:23:38 visual_prompt]: 	Test 100/356. loss: 2.478, 0.2144 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 04:24:00 visual_prompt]: 	Test 200/356. loss: 2.375, 0.2144 s / batch. (data: 3.36e-05)max mem: 7.81207 GB 
[10/01 04:24:21 visual_prompt]: 	Test 300/356. loss: 2.470, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:24:35 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2137, average loss: 2.8030
[10/01 04:24:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.24	top5: 97.62	
[10/01 04:24:35 visual_prompt]: Best epoch 90: best metric: 0.885
[10/01 04:24:35 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[10/01 04:24:45 visual_prompt]: Epoch 91 / 100: avg data time: 1.04e-01, avg batch time: 0.5534, average train loss: 0.2184
[10/01 04:24:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1668, average loss: 0.2434
[10/01 04:24:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 91.50	top5: 100.00	
[10/01 04:25:11 visual_prompt]: 	Test 100/356. loss: 2.535, 0.2142 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 04:25:33 visual_prompt]: 	Test 200/356. loss: 2.531, 0.2145 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 04:25:54 visual_prompt]: 	Test 300/356. loss: 2.542, 0.2145 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:26:08 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2138, average loss: 2.8079
[10/01 04:26:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.81	top5: 97.71	
[10/01 04:26:08 visual_prompt]: Best epoch 91: best metric: 0.915
[10/01 04:26:08 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[10/01 04:26:18 visual_prompt]: Epoch 92 / 100: avg data time: 1.06e-01, avg batch time: 0.5564, average train loss: 0.1887
[10/01 04:26:22 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1668, average loss: 0.1298
[10/01 04:26:22 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 04:26:45 visual_prompt]: 	Test 100/356. loss: 2.468, 0.2137 s / batch. (data: 8.39e-05)max mem: 7.81207 GB 
[10/01 04:27:06 visual_prompt]: 	Test 200/356. loss: 2.525, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:27:28 visual_prompt]: 	Test 300/356. loss: 2.616, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:27:41 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2138, average loss: 2.8520
[10/01 04:27:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.14	top5: 97.21	
[10/01 04:27:41 visual_prompt]: Best epoch 92: best metric: 0.955
[10/01 04:27:41 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[10/01 04:27:51 visual_prompt]: Epoch 93 / 100: avg data time: 1.10e-01, avg batch time: 0.5597, average train loss: 0.1818
[10/01 04:27:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1666, average loss: 0.1819
[10/01 04:27:55 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 04:28:18 visual_prompt]: 	Test 100/356. loss: 2.689, 0.2138 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:28:39 visual_prompt]: 	Test 200/356. loss: 2.681, 0.2146 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:29:01 visual_prompt]: 	Test 300/356. loss: 2.550, 0.2142 s / batch. (data: 7.10e-05)max mem: 7.81207 GB 
[10/01 04:29:14 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2138, average loss: 2.9110
[10/01 04:29:14 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.50	top5: 97.53	
[10/01 04:29:14 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[10/01 04:29:24 visual_prompt]: Epoch 94 / 100: avg data time: 1.02e-01, avg batch time: 0.5536, average train loss: 0.1726
[10/01 04:29:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1667, average loss: 0.2252
[10/01 04:29:28 visual_prompt]: Classification results with val_vtab-dmlab: top1: 92.50	top5: 100.00	
[10/01 04:29:51 visual_prompt]: 	Test 100/356. loss: 2.599, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 04:30:13 visual_prompt]: 	Test 200/356. loss: 2.947, 0.2139 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 04:30:34 visual_prompt]: 	Test 300/356. loss: 2.593, 0.2147 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:30:47 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2137, average loss: 2.9574
[10/01 04:30:47 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.81	top5: 97.37	
[10/01 04:30:47 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[10/01 04:30:58 visual_prompt]: Epoch 95 / 100: avg data time: 1.02e-01, avg batch time: 0.5518, average train loss: 0.1550
[10/01 04:31:01 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1666, average loss: 0.1492
[10/01 04:31:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 94.50	top5: 100.00	
[10/01 04:31:24 visual_prompt]: 	Test 100/356. loss: 2.444, 0.2140 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 04:31:46 visual_prompt]: 	Test 200/356. loss: 2.839, 0.2180 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:32:07 visual_prompt]: 	Test 300/356. loss: 2.600, 0.2144 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 04:32:20 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2137, average loss: 2.9375
[10/01 04:32:21 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.86	top5: 97.30	
[10/01 04:32:21 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[10/01 04:32:31 visual_prompt]: Epoch 96 / 100: avg data time: 1.08e-01, avg batch time: 0.5589, average train loss: 0.1271
[10/01 04:32:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1686, average loss: 0.1089
[10/01 04:32:34 visual_prompt]: Classification results with val_vtab-dmlab: top1: 97.00	top5: 100.00	
[10/01 04:32:57 visual_prompt]: 	Test 100/356. loss: 2.539, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 04:33:19 visual_prompt]: 	Test 200/356. loss: 2.876, 0.2145 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 04:33:40 visual_prompt]: 	Test 300/356. loss: 2.613, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 04:33:54 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2138, average loss: 2.9896
[10/01 04:33:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.58	top5: 97.40	
[10/01 04:33:54 visual_prompt]: Best epoch 96: best metric: 0.970
[10/01 04:33:54 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[10/01 04:34:04 visual_prompt]: Epoch 97 / 100: avg data time: 1.20e-01, avg batch time: 0.5687, average train loss: 0.1196
[10/01 04:34:08 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 0.1574
[10/01 04:34:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 93.00	top5: 100.00	
[10/01 04:34:31 visual_prompt]: 	Test 100/356. loss: 2.604, 0.2137 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:34:52 visual_prompt]: 	Test 200/356. loss: 2.872, 0.2140 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:35:14 visual_prompt]: 	Test 300/356. loss: 2.578, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:35:27 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2137, average loss: 3.0266
[10/01 04:35:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.79	top5: 97.43	
[10/01 04:35:27 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[10/01 04:35:37 visual_prompt]: Epoch 98 / 100: avg data time: 1.14e-01, avg batch time: 0.5644, average train loss: 0.1120
[10/01 04:35:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1669, average loss: 0.1230
[10/01 04:35:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 04:36:04 visual_prompt]: 	Test 100/356. loss: 2.626, 0.2136 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:36:25 visual_prompt]: 	Test 200/356. loss: 2.932, 0.2144 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 04:36:47 visual_prompt]: 	Test 300/356. loss: 2.593, 0.2145 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 04:37:00 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2137, average loss: 3.0269
[10/01 04:37:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.75	top5: 97.44	
[10/01 04:37:00 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[10/01 04:37:11 visual_prompt]: Epoch 99 / 100: avg data time: 1.05e-01, avg batch time: 0.5560, average train loss: 0.1068
[10/01 04:37:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1669, average loss: 0.1161
[10/01 04:37:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.00	top5: 100.00	
[10/01 04:37:37 visual_prompt]: 	Test 100/356. loss: 2.623, 0.2137 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 04:37:59 visual_prompt]: 	Test 200/356. loss: 2.967, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 04:38:20 visual_prompt]: 	Test 300/356. loss: 2.607, 0.2144 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 04:38:34 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2137, average loss: 3.0329
[10/01 04:38:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.70	top5: 97.46	
[10/01 04:38:34 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[10/01 04:38:44 visual_prompt]: Epoch 100 / 100: avg data time: 1.12e-01, avg batch time: 0.5623, average train loss: 0.1081
[10/01 04:38:48 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1666, average loss: 0.1163
[10/01 04:38:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.00	top5: 100.00	
[10/01 04:39:11 visual_prompt]: 	Test 100/356. loss: 2.624, 0.2138 s / batch. (data: 8.89e-05)max mem: 7.81207 GB 
[10/01 04:39:32 visual_prompt]: 	Test 200/356. loss: 2.972, 0.2191 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 04:39:54 visual_prompt]: 	Test 300/356. loss: 2.609, 0.2142 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 04:40:07 visual_prompt]: Inference (test):avg data time: 4.73e-05, avg batch time: 0.2137, average loss: 3.0354
[10/01 04:40:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.72	top5: 97.46	
[10/01 04:40:07 visual_prompt]: Rank of current process: 0. World size: 1
[10/01 04:40:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/01 04:40:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[10/01 04:40:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/01 04:40:07 visual_prompt]: Training with config:
[10/01 04:40:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dmlab/sup_vitb16_imagenet21k/prompt50/crop224/test/seed3172/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 3172, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dmlab', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 6, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/01 04:40:07 visual_prompt]: Loading training data...
[10/01 04:40:07 visual_prompt]: Constructing vtab-dmlab dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 04:40:09 visual_prompt]: Number of images: 1000
[10/01 04:40:09 visual_prompt]: Number of classes: 6 / 6
[10/01 04:40:09 visual_prompt]: Loading validation data...
[10/01 04:40:09 visual_prompt]: Constructing vtab-dmlab dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 04:40:09 visual_prompt]: Number of images: 200
[10/01 04:40:09 visual_prompt]: Number of classes: 6 / 6
[10/01 04:40:09 visual_prompt]: Loading test data...
[10/01 04:40:09 visual_prompt]: Constructing vtab-dmlab dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split test, from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 04:40:45 visual_prompt]: Number of images: 22735
[10/01 04:40:45 visual_prompt]: Number of classes: 6 / 6
[10/01 04:40:45 visual_prompt]: Constructing models...
[10/01 04:40:47 visual_prompt]: Total Parameters: 86264070	 Gradient Parameters: 465414
[10/01 04:40:47 visual_prompt]: tuned percent:0.540
[10/01 04:40:47 visual_prompt]: Device used for model: 0
[10/01 04:40:47 visual_prompt]: Setting up Evaluator...
[10/01 04:40:47 visual_prompt]: Setting up Trainer...
[10/01 04:40:47 visual_prompt]: 	Setting up the optimizer...
[10/01 04:40:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/01 04:40:58 visual_prompt]: Epoch 1 / 100: avg data time: 1.16e-01, avg batch time: 0.5613, average train loss: 2.2754
[10/01 04:41:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1651, average loss: 2.4462
[10/01 04:41:01 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.00	
[10/01 04:41:24 visual_prompt]: 	Test 100/356. loss: 2.319, 0.2126 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 04:41:46 visual_prompt]: 	Test 200/356. loss: 1.943, 0.2134 s / batch. (data: 7.96e-05)max mem: 7.81207 GB 
[10/01 04:42:07 visual_prompt]: 	Test 300/356. loss: 2.201, 0.2141 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 04:42:20 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2128, average loss: 2.2324
[10/01 04:42:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 24.54	top5: 88.43	
[10/01 04:42:20 visual_prompt]: Best epoch 1: best metric: 0.175
[10/01 04:42:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/01 04:42:30 visual_prompt]: Epoch 2 / 100: avg data time: 1.03e-01, avg batch time: 0.5517, average train loss: 3.1525
[10/01 04:42:34 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1674, average loss: 2.0277
[10/01 04:42:34 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 04:42:57 visual_prompt]: 	Test 100/356. loss: 1.918, 0.2136 s / batch. (data: 6.89e-05)max mem: 7.81207 GB 
[10/01 04:43:19 visual_prompt]: 	Test 200/356. loss: 1.750, 0.2137 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 04:43:40 visual_prompt]: 	Test 300/356. loss: 1.865, 0.2151 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 04:43:54 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2135, average loss: 1.9076
[10/01 04:43:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.44	
[10/01 04:43:54 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/01 04:44:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.13e-01, avg batch time: 0.5635, average train loss: 1.9242
[10/01 04:44:08 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1671, average loss: 1.8549
[10/01 04:44:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 18.50	top5: 85.50	
[10/01 04:44:31 visual_prompt]: 	Test 100/356. loss: 1.902, 0.2136 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:44:52 visual_prompt]: 	Test 200/356. loss: 1.742, 0.2139 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 04:45:14 visual_prompt]: 	Test 300/356. loss: 1.866, 0.2147 s / batch. (data: 9.20e-05)max mem: 7.81207 GB 
[10/01 04:45:27 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2138, average loss: 1.8344
[10/01 04:45:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.96	top5: 84.67	
[10/01 04:45:27 visual_prompt]: Best epoch 3: best metric: 0.185
[10/01 04:45:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/01 04:45:37 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e-01, avg batch time: 0.5578, average train loss: 1.8165
[10/01 04:45:41 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1679, average loss: 1.8928
[10/01 04:45:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[10/01 04:46:04 visual_prompt]: 	Test 100/356. loss: 1.897, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 04:46:25 visual_prompt]: 	Test 200/356. loss: 1.686, 0.2143 s / batch. (data: 3.39e-05)max mem: 7.81207 GB 
[10/01 04:46:47 visual_prompt]: 	Test 300/356. loss: 1.819, 0.2147 s / batch. (data: 3.39e-05)max mem: 7.81207 GB 
[10/01 04:47:00 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2137, average loss: 1.8267
[10/01 04:47:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.23	top5: 84.67	
[10/01 04:47:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/01 04:47:10 visual_prompt]: Epoch 5 / 100: avg data time: 1.01e-01, avg batch time: 0.5515, average train loss: 1.8245
[10/01 04:47:14 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1666, average loss: 1.8886
[10/01 04:47:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.00	
[10/01 04:47:37 visual_prompt]: 	Test 100/356. loss: 1.848, 0.2138 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 04:47:59 visual_prompt]: 	Test 200/356. loss: 1.932, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:48:20 visual_prompt]: 	Test 300/356. loss: 1.868, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 04:48:33 visual_prompt]: Inference (test):avg data time: 3.77e-05, avg batch time: 0.2138, average loss: 1.8767
[10/01 04:48:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.39	top5: 88.42	
[10/01 04:48:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/01 04:48:44 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e-01, avg batch time: 0.5554, average train loss: 1.7655
[10/01 04:48:47 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1667, average loss: 1.7192
[10/01 04:48:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.50	top5: 91.00	
[10/01 04:49:10 visual_prompt]: 	Test 100/356. loss: 1.815, 0.2143 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 04:49:32 visual_prompt]: 	Test 200/356. loss: 1.871, 0.2142 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 04:49:53 visual_prompt]: 	Test 300/356. loss: 1.841, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 04:50:07 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2138, average loss: 1.7793
[10/01 04:50:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.27	top5: 85.31	
[10/01 04:50:07 visual_prompt]: Best epoch 6: best metric: 0.245
[10/01 04:50:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/01 04:50:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.02e-01, avg batch time: 0.5536, average train loss: 1.8491
[10/01 04:50:20 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1668, average loss: 1.8298
[10/01 04:50:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 92.50	
[10/01 04:50:44 visual_prompt]: 	Test 100/356. loss: 1.933, 0.2138 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 04:51:05 visual_prompt]: 	Test 200/356. loss: 1.972, 0.2146 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 04:51:27 visual_prompt]: 	Test 300/356. loss: 1.947, 0.2149 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 04:51:40 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2138, average loss: 1.9040
[10/01 04:51:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 16.07	top5: 92.11	
[10/01 04:51:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/01 04:51:50 visual_prompt]: Epoch 8 / 100: avg data time: 1.12e-01, avg batch time: 0.5620, average train loss: 1.7628
[10/01 04:51:54 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1666, average loss: 1.7192
[10/01 04:51:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 91.50	
[10/01 04:52:17 visual_prompt]: 	Test 100/356. loss: 1.638, 0.2138 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 04:52:38 visual_prompt]: 	Test 200/356. loss: 1.648, 0.2144 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 04:53:00 visual_prompt]: 	Test 300/356. loss: 1.635, 0.2146 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 04:53:13 visual_prompt]: Inference (test):avg data time: 4.93e-05, avg batch time: 0.2138, average loss: 1.6552
[10/01 04:53:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.33	top5: 93.38	
[10/01 04:53:13 visual_prompt]: Best epoch 8: best metric: 0.250
[10/01 04:53:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/01 04:53:24 visual_prompt]: Epoch 9 / 100: avg data time: 1.13e-01, avg batch time: 0.5622, average train loss: 1.8115
[10/01 04:53:27 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 1.9713
[10/01 04:53:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 79.50	
[10/01 04:53:50 visual_prompt]: 	Test 100/356. loss: 1.914, 0.2144 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 04:54:12 visual_prompt]: 	Test 200/356. loss: 1.804, 0.2141 s / batch. (data: 9.23e-05)max mem: 7.81207 GB 
[10/01 04:54:33 visual_prompt]: 	Test 300/356. loss: 1.840, 0.2145 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 04:54:46 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2139, average loss: 1.9078
[10/01 04:54:47 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 81.44	
[10/01 04:54:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/01 04:54:57 visual_prompt]: Epoch 10 / 100: avg data time: 9.91e-02, avg batch time: 0.5501, average train loss: 1.8304
[10/01 04:55:00 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 1.7267
[10/01 04:55:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 27.50	top5: 84.00	
[10/01 04:55:23 visual_prompt]: 	Test 100/356. loss: 1.576, 0.2148 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 04:55:45 visual_prompt]: 	Test 200/356. loss: 1.563, 0.2145 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 04:56:06 visual_prompt]: 	Test 300/356. loss: 1.636, 0.2148 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 04:56:20 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2138, average loss: 1.6433
[10/01 04:56:20 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.13	top5: 89.84	
[10/01 04:56:20 visual_prompt]: Best epoch 10: best metric: 0.275
[10/01 04:56:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/01 04:56:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.03e-01, avg batch time: 0.5545, average train loss: 1.8288
[10/01 04:56:33 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1670, average loss: 1.7992
[10/01 04:56:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 84.00	
[10/01 04:56:57 visual_prompt]: 	Test 100/356. loss: 1.799, 0.2137 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 04:57:18 visual_prompt]: 	Test 200/356. loss: 1.765, 0.2145 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 04:57:40 visual_prompt]: 	Test 300/356. loss: 1.759, 0.2143 s / batch. (data: 7.06e-05)max mem: 7.81207 GB 
[10/01 04:57:53 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2138, average loss: 1.7793
[10/01 04:57:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 20.72	top5: 85.40	
[10/01 04:57:53 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/01 04:58:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.04e-01, avg batch time: 0.5537, average train loss: 1.8005
[10/01 04:58:07 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 2.3523
[10/01 04:58:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 87.50	
[10/01 04:58:30 visual_prompt]: 	Test 100/356. loss: 2.262, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 04:58:51 visual_prompt]: 	Test 200/356. loss: 1.829, 0.2149 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 04:59:13 visual_prompt]: 	Test 300/356. loss: 2.138, 0.2142 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 04:59:26 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2140, average loss: 2.1815
[10/01 04:59:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.41	top5: 89.28	
[10/01 04:59:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/01 04:59:37 visual_prompt]: Epoch 13 / 100: avg data time: 1.12e-01, avg batch time: 0.5614, average train loss: 1.8553
[10/01 04:59:40 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1666, average loss: 2.0912
[10/01 04:59:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.00	top5: 84.00	
[10/01 05:00:04 visual_prompt]: 	Test 100/356. loss: 1.914, 0.2139 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 05:00:25 visual_prompt]: 	Test 200/356. loss: 1.673, 0.2144 s / batch. (data: 6.75e-05)max mem: 7.81207 GB 
[10/01 05:00:47 visual_prompt]: 	Test 300/356. loss: 1.784, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 05:01:00 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2137, average loss: 1.9017
[10/01 05:01:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.40	top5: 88.42	
[10/01 05:01:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/01 05:01:10 visual_prompt]: Epoch 14 / 100: avg data time: 1.09e-01, avg batch time: 0.5580, average train loss: 1.6118
[10/01 05:01:14 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1667, average loss: 1.5948
[10/01 05:01:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 27.00	top5: 91.50	
[10/01 05:01:37 visual_prompt]: 	Test 100/356. loss: 1.433, 0.2140 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:01:58 visual_prompt]: 	Test 200/356. loss: 1.518, 0.2139 s / batch. (data: 3.24e-05)max mem: 7.81207 GB 
[10/01 05:02:20 visual_prompt]: 	Test 300/356. loss: 1.432, 0.2147 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:02:33 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2138, average loss: 1.5200
[10/01 05:02:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.47	top5: 94.66	
[10/01 05:02:33 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/01 05:02:43 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e-01, avg batch time: 0.5571, average train loss: 1.5030
[10/01 05:02:47 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1668, average loss: 1.6126
[10/01 05:02:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.00	top5: 88.00	
[10/01 05:03:10 visual_prompt]: 	Test 100/356. loss: 1.619, 0.2140 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:03:31 visual_prompt]: 	Test 200/356. loss: 1.591, 0.2144 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:03:53 visual_prompt]: 	Test 300/356. loss: 1.532, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 05:04:06 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2138, average loss: 1.5779
[10/01 05:04:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.98	top5: 90.31	
[10/01 05:04:06 visual_prompt]: Best epoch 15: best metric: 0.320
[10/01 05:04:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/01 05:04:17 visual_prompt]: Epoch 16 / 100: avg data time: 1.04e-01, avg batch time: 0.5544, average train loss: 1.5182
[10/01 05:04:20 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1667, average loss: 1.5223
[10/01 05:04:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 97.00	
[10/01 05:04:43 visual_prompt]: 	Test 100/356. loss: 1.387, 0.2141 s / batch. (data: 1.02e-04)max mem: 7.81207 GB 
[10/01 05:05:05 visual_prompt]: 	Test 200/356. loss: 1.391, 0.2138 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 05:05:26 visual_prompt]: 	Test 300/356. loss: 1.346, 0.2152 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:05:40 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2138, average loss: 1.4594
[10/01 05:05:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.08	top5: 97.34	
[10/01 05:05:40 visual_prompt]: Best epoch 16: best metric: 0.400
[10/01 05:05:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/01 05:05:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e-01, avg batch time: 0.5544, average train loss: 1.7836
[10/01 05:05:53 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1668, average loss: 2.3743
[10/01 05:05:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 79.50	
[10/01 05:06:16 visual_prompt]: 	Test 100/356. loss: 2.230, 0.2137 s / batch. (data: 7.39e-05)max mem: 7.81207 GB 
[10/01 05:06:38 visual_prompt]: 	Test 200/356. loss: 2.042, 0.2147 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 05:06:59 visual_prompt]: 	Test 300/356. loss: 2.217, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:07:13 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2139, average loss: 2.2366
[10/01 05:07:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 81.44	
[10/01 05:07:13 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/01 05:07:23 visual_prompt]: Epoch 18 / 100: avg data time: 1.01e-01, avg batch time: 0.5515, average train loss: 1.9693
[10/01 05:07:26 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1669, average loss: 1.8247
[10/01 05:07:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 84.50	
[10/01 05:07:50 visual_prompt]: 	Test 100/356. loss: 1.861, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:08:11 visual_prompt]: 	Test 200/356. loss: 1.832, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:08:33 visual_prompt]: 	Test 300/356. loss: 1.850, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:08:46 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2138, average loss: 1.8399
[10/01 05:08:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 11.58	top5: 85.58	
[10/01 05:08:46 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/01 05:08:56 visual_prompt]: Epoch 19 / 100: avg data time: 1.00e-01, avg batch time: 0.5516, average train loss: 1.9801
[10/01 05:09:00 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1668, average loss: 1.8914
[10/01 05:09:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 82.50	
[10/01 05:09:23 visual_prompt]: 	Test 100/356. loss: 1.880, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:09:44 visual_prompt]: 	Test 200/356. loss: 1.760, 0.2142 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 05:10:06 visual_prompt]: 	Test 300/356. loss: 1.817, 0.2150 s / batch. (data: 8.58e-05)max mem: 7.81207 GB 
[10/01 05:10:19 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2139, average loss: 1.8442
[10/01 05:10:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 82.27	
[10/01 05:10:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/01 05:10:29 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e-01, avg batch time: 0.5533, average train loss: 2.0061
[10/01 05:10:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1667, average loss: 1.7932
[10/01 05:10:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 85.00	
[10/01 05:10:56 visual_prompt]: 	Test 100/356. loss: 1.807, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:11:18 visual_prompt]: 	Test 200/356. loss: 1.831, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:11:39 visual_prompt]: 	Test 300/356. loss: 1.819, 0.2147 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:11:53 visual_prompt]: Inference (test):avg data time: 7.96e-05, avg batch time: 0.2139, average loss: 1.8045
[10/01 05:11:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 89.28	
[10/01 05:11:53 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/01 05:12:03 visual_prompt]: Epoch 21 / 100: avg data time: 9.81e-02, avg batch time: 0.5493, average train loss: 1.8798
[10/01 05:12:06 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1671, average loss: 2.0231
[10/01 05:12:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 85.50	
[10/01 05:12:29 visual_prompt]: 	Test 100/356. loss: 1.986, 0.2143 s / batch. (data: 7.72e-05)max mem: 7.81207 GB 
[10/01 05:12:51 visual_prompt]: 	Test 200/356. loss: 1.735, 0.2146 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:13:12 visual_prompt]: 	Test 300/356. loss: 1.897, 0.2150 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:13:26 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2140, average loss: 1.9283
[10/01 05:13:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 84.67	
[10/01 05:13:26 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/01 05:13:36 visual_prompt]: Epoch 22 / 100: avg data time: 1.18e-01, avg batch time: 0.5672, average train loss: 1.9201
[10/01 05:13:40 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 1.9893
[10/01 05:13:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 24.00	top5: 82.50	
[10/01 05:14:03 visual_prompt]: 	Test 100/356. loss: 2.031, 0.2140 s / batch. (data: 7.70e-05)max mem: 7.81207 GB 
[10/01 05:14:24 visual_prompt]: 	Test 200/356. loss: 1.847, 0.2146 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 05:14:46 visual_prompt]: 	Test 300/356. loss: 1.883, 0.2146 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 05:14:59 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2139, average loss: 1.9479
[10/01 05:14:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.48	top5: 82.27	
[10/01 05:14:59 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/01 05:15:10 visual_prompt]: Epoch 23 / 100: avg data time: 1.10e-01, avg batch time: 0.5594, average train loss: 1.8689
[10/01 05:15:13 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1669, average loss: 1.8097
[10/01 05:15:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 18.50	top5: 84.50	
[10/01 05:15:36 visual_prompt]: 	Test 100/356. loss: 1.835, 0.2136 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 05:15:58 visual_prompt]: 	Test 200/356. loss: 1.983, 0.2144 s / batch. (data: 3.17e-05)max mem: 7.81207 GB 
[10/01 05:16:19 visual_prompt]: 	Test 300/356. loss: 1.843, 0.2145 s / batch. (data: 6.79e-05)max mem: 7.81207 GB 
[10/01 05:16:32 visual_prompt]: Inference (test):avg data time: 4.87e-05, avg batch time: 0.2140, average loss: 1.8562
[10/01 05:16:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 20.36	top5: 84.74	
[10/01 05:16:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/01 05:16:43 visual_prompt]: Epoch 24 / 100: avg data time: 1.03e-01, avg batch time: 0.5546, average train loss: 1.7071
[10/01 05:16:46 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1667, average loss: 1.6362
[10/01 05:16:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.00	top5: 89.50	
[10/01 05:17:09 visual_prompt]: 	Test 100/356. loss: 1.648, 0.2140 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 05:17:31 visual_prompt]: 	Test 200/356. loss: 1.712, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:17:52 visual_prompt]: 	Test 300/356. loss: 1.575, 0.2144 s / batch. (data: 3.36e-05)max mem: 7.81207 GB 
[10/01 05:18:06 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2138, average loss: 1.6294
[10/01 05:18:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.21	top5: 90.94	
[10/01 05:18:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/01 05:18:16 visual_prompt]: Epoch 25 / 100: avg data time: 1.09e-01, avg batch time: 0.5581, average train loss: 1.6687
[10/01 05:18:20 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1702, average loss: 1.5151
[10/01 05:18:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 33.00	top5: 98.00	
[10/01 05:18:43 visual_prompt]: 	Test 100/356. loss: 1.547, 0.2139 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 05:19:04 visual_prompt]: 	Test 200/356. loss: 1.648, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:19:26 visual_prompt]: 	Test 300/356. loss: 1.514, 0.2142 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 05:19:39 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2138, average loss: 1.5387
[10/01 05:19:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.96	top5: 96.18	
[10/01 05:19:39 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/01 05:19:49 visual_prompt]: Epoch 26 / 100: avg data time: 9.77e-02, avg batch time: 0.5486, average train loss: 1.6255
[10/01 05:19:53 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1668, average loss: 2.1717
[10/01 05:19:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 97.50	
[10/01 05:20:16 visual_prompt]: 	Test 100/356. loss: 2.095, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 05:20:38 visual_prompt]: 	Test 200/356. loss: 2.339, 0.2147 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:20:59 visual_prompt]: 	Test 300/356. loss: 2.136, 0.2149 s / batch. (data: 7.89e-05)max mem: 7.81207 GB 
[10/01 05:21:13 visual_prompt]: Inference (test):avg data time: 6.56e-05, avg batch time: 0.2139, average loss: 2.1677
[10/01 05:21:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.57	top5: 96.12	
[10/01 05:21:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/01 05:21:23 visual_prompt]: Epoch 27 / 100: avg data time: 9.98e-02, avg batch time: 0.5538, average train loss: 1.7665
[10/01 05:21:26 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1667, average loss: 1.5764
[10/01 05:21:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.50	top5: 97.00	
[10/01 05:21:50 visual_prompt]: 	Test 100/356. loss: 1.533, 0.2137 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 05:22:11 visual_prompt]: 	Test 200/356. loss: 1.698, 0.2143 s / batch. (data: 3.27e-05)max mem: 7.81207 GB 
[10/01 05:22:32 visual_prompt]: 	Test 300/356. loss: 1.522, 0.2149 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:22:46 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2138, average loss: 1.5632
[10/01 05:22:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.92	top5: 95.36	
[10/01 05:22:46 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/01 05:22:56 visual_prompt]: Epoch 28 / 100: avg data time: 9.95e-02, avg batch time: 0.5509, average train loss: 1.5483
[10/01 05:22:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1669, average loss: 1.7517
[10/01 05:22:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.50	top5: 91.50	
[10/01 05:23:23 visual_prompt]: 	Test 100/356. loss: 1.767, 0.2138 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:23:44 visual_prompt]: 	Test 200/356. loss: 2.030, 0.2137 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:24:06 visual_prompt]: 	Test 300/356. loss: 1.781, 0.2151 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 05:24:19 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2139, average loss: 1.8253
[10/01 05:24:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.22	top5: 89.21	
[10/01 05:24:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/01 05:24:29 visual_prompt]: Epoch 29 / 100: avg data time: 1.03e-01, avg batch time: 0.5526, average train loss: 1.4814
[10/01 05:24:33 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1669, average loss: 1.7198
[10/01 05:24:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 92.00	
[10/01 05:24:56 visual_prompt]: 	Test 100/356. loss: 1.606, 0.2138 s / batch. (data: 6.46e-05)max mem: 7.81207 GB 
[10/01 05:25:17 visual_prompt]: 	Test 200/356. loss: 1.419, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 05:25:39 visual_prompt]: 	Test 300/356. loss: 1.661, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 05:25:52 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2139, average loss: 1.6296
[10/01 05:25:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.24	top5: 94.05	
[10/01 05:25:52 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/01 05:26:03 visual_prompt]: Epoch 30 / 100: avg data time: 1.09e-01, avg batch time: 0.5581, average train loss: 1.4737
[10/01 05:26:06 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 1.4141
[10/01 05:26:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.50	top5: 99.00	
[10/01 05:26:29 visual_prompt]: 	Test 100/356. loss: 1.357, 0.2140 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 05:26:51 visual_prompt]: 	Test 200/356. loss: 1.662, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:27:12 visual_prompt]: 	Test 300/356. loss: 1.397, 0.2150 s / batch. (data: 7.15e-05)max mem: 7.81207 GB 
[10/01 05:27:26 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2138, average loss: 1.4873
[10/01 05:27:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.72	top5: 97.35	
[10/01 05:27:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/01 05:27:36 visual_prompt]: Epoch 31 / 100: avg data time: 1.11e-01, avg batch time: 0.5612, average train loss: 1.4363
[10/01 05:27:40 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1669, average loss: 1.6816
[10/01 05:27:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 28.50	top5: 93.50	
[10/01 05:28:03 visual_prompt]: 	Test 100/356. loss: 1.709, 0.2139 s / batch. (data: 7.72e-05)max mem: 7.81207 GB 
[10/01 05:28:24 visual_prompt]: 	Test 200/356. loss: 1.699, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 05:28:46 visual_prompt]: 	Test 300/356. loss: 1.687, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:28:59 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2139, average loss: 1.7120
[10/01 05:28:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.20	top5: 95.41	
[10/01 05:28:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/01 05:29:09 visual_prompt]: Epoch 32 / 100: avg data time: 1.03e-01, avg batch time: 0.5534, average train loss: 1.3849
[10/01 05:29:13 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1667, average loss: 1.4162
[10/01 05:29:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.00	top5: 97.50	
[10/01 05:29:36 visual_prompt]: 	Test 100/356. loss: 1.481, 0.2135 s / batch. (data: 2.31e-05)max mem: 7.81207 GB 
[10/01 05:29:57 visual_prompt]: 	Test 200/356. loss: 1.535, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:30:19 visual_prompt]: 	Test 300/356. loss: 1.349, 0.2151 s / batch. (data: 6.72e-05)max mem: 7.81207 GB 
[10/01 05:30:32 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2139, average loss: 1.4791
[10/01 05:30:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.02	top5: 96.93	
[10/01 05:30:32 visual_prompt]: Best epoch 32: best metric: 0.410
[10/01 05:30:32 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/01 05:30:43 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e-01, avg batch time: 0.5562, average train loss: 1.5015
[10/01 05:30:46 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 1.4719
[10/01 05:30:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.00	top5: 98.50	
[10/01 05:31:09 visual_prompt]: 	Test 100/356. loss: 1.296, 0.2142 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 05:31:31 visual_prompt]: 	Test 200/356. loss: 1.615, 0.2149 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:31:52 visual_prompt]: 	Test 300/356. loss: 1.328, 0.2144 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 05:32:06 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2139, average loss: 1.4852
[10/01 05:32:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.51	top5: 97.51	
[10/01 05:32:06 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/01 05:32:16 visual_prompt]: Epoch 34 / 100: avg data time: 1.00e-01, avg batch time: 0.5522, average train loss: 1.5744
[10/01 05:32:19 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1670, average loss: 1.2629
[10/01 05:32:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 99.00	
[10/01 05:32:43 visual_prompt]: 	Test 100/356. loss: 1.257, 0.2140 s / batch. (data: 3.17e-05)max mem: 7.81207 GB 
[10/01 05:33:04 visual_prompt]: 	Test 200/356. loss: 1.365, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 05:33:25 visual_prompt]: 	Test 300/356. loss: 1.237, 0.2144 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:33:39 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2139, average loss: 1.3113
[10/01 05:33:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.33	top5: 98.07	
[10/01 05:33:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/01 05:33:49 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e-01, avg batch time: 0.5566, average train loss: 1.3348
[10/01 05:33:53 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 1.2726
[10/01 05:33:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.00	top5: 99.00	
[10/01 05:34:16 visual_prompt]: 	Test 100/356. loss: 1.246, 0.2138 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 05:34:37 visual_prompt]: 	Test 200/356. loss: 1.427, 0.2145 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:34:59 visual_prompt]: 	Test 300/356. loss: 1.171, 0.2148 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 05:35:12 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2139, average loss: 1.3354
[10/01 05:35:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.98	top5: 98.24	
[10/01 05:35:12 visual_prompt]: Best epoch 35: best metric: 0.420
[10/01 05:35:12 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[10/01 05:35:23 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e-01, avg batch time: 0.5598, average train loss: 1.2561
[10/01 05:35:26 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1668, average loss: 1.3094
[10/01 05:35:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.50	top5: 99.50	
[10/01 05:35:49 visual_prompt]: 	Test 100/356. loss: 1.352, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:36:11 visual_prompt]: 	Test 200/356. loss: 1.451, 0.2146 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:36:32 visual_prompt]: 	Test 300/356. loss: 1.291, 0.2148 s / batch. (data: 8.73e-05)max mem: 7.81207 GB 
[10/01 05:36:46 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2138, average loss: 1.4546
[10/01 05:36:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.70	top5: 98.37	
[10/01 05:36:46 visual_prompt]: Best epoch 36: best metric: 0.425
[10/01 05:36:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[10/01 05:36:56 visual_prompt]: Epoch 37 / 100: avg data time: 1.04e-01, avg batch time: 0.5543, average train loss: 1.2806
[10/01 05:37:00 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 1.4540
[10/01 05:37:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 98.00	
[10/01 05:37:23 visual_prompt]: 	Test 100/356. loss: 1.353, 0.2138 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 05:37:44 visual_prompt]: 	Test 200/356. loss: 1.460, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:38:06 visual_prompt]: 	Test 300/356. loss: 1.439, 0.2147 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 05:38:19 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2139, average loss: 1.4771
[10/01 05:38:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.17	top5: 97.15	
[10/01 05:38:19 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[10/01 05:38:29 visual_prompt]: Epoch 38 / 100: avg data time: 1.17e-01, avg batch time: 0.5660, average train loss: 1.3474
[10/01 05:38:33 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1668, average loss: 1.2238
[10/01 05:38:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 99.50	
[10/01 05:38:56 visual_prompt]: 	Test 100/356. loss: 1.293, 0.2138 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 05:39:18 visual_prompt]: 	Test 200/356. loss: 1.502, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:39:39 visual_prompt]: 	Test 300/356. loss: 1.322, 0.2146 s / batch. (data: 6.91e-05)max mem: 7.81207 GB 
[10/01 05:39:53 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2138, average loss: 1.3810
[10/01 05:39:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.62	top5: 97.64	
[10/01 05:39:53 visual_prompt]: Best epoch 38: best metric: 0.465
[10/01 05:39:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[10/01 05:40:03 visual_prompt]: Epoch 39 / 100: avg data time: 9.96e-02, avg batch time: 0.5503, average train loss: 1.3384
[10/01 05:40:06 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.4657
[10/01 05:40:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 96.00	
[10/01 05:40:30 visual_prompt]: 	Test 100/356. loss: 1.507, 0.2134 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:40:51 visual_prompt]: 	Test 200/356. loss: 1.523, 0.2141 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 05:41:12 visual_prompt]: 	Test 300/356. loss: 1.580, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:41:26 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2138, average loss: 1.5302
[10/01 05:41:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.77	top5: 96.01	
[10/01 05:41:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[10/01 05:41:36 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e-01, avg batch time: 0.5593, average train loss: 1.3013
[10/01 05:41:40 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1669, average loss: 1.3448
[10/01 05:41:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 98.50	
[10/01 05:42:03 visual_prompt]: 	Test 100/356. loss: 1.470, 0.2142 s / batch. (data: 7.15e-05)max mem: 7.81207 GB 
[10/01 05:42:24 visual_prompt]: 	Test 200/356. loss: 1.435, 0.2144 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 05:42:46 visual_prompt]: 	Test 300/356. loss: 1.285, 0.2149 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:42:59 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2139, average loss: 1.4341
[10/01 05:42:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.42	top5: 97.88	
[10/01 05:42:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[10/01 05:43:10 visual_prompt]: Epoch 41 / 100: avg data time: 1.02e-01, avg batch time: 0.5527, average train loss: 1.3474
[10/01 05:43:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1668, average loss: 1.3229
[10/01 05:43:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 98.00	
[10/01 05:43:36 visual_prompt]: 	Test 100/356. loss: 1.347, 0.2133 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 05:43:58 visual_prompt]: 	Test 200/356. loss: 1.366, 0.2149 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:44:19 visual_prompt]: 	Test 300/356. loss: 1.348, 0.2144 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 05:44:33 visual_prompt]: Inference (test):avg data time: 3.75e-05, avg batch time: 0.2137, average loss: 1.3746
[10/01 05:44:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.27	top5: 97.44	
[10/01 05:44:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[10/01 05:44:43 visual_prompt]: Epoch 42 / 100: avg data time: 1.10e-01, avg batch time: 0.5603, average train loss: 1.2337
[10/01 05:44:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1670, average loss: 1.2066
[10/01 05:44:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 100.00	
[10/01 05:45:10 visual_prompt]: 	Test 100/356. loss: 1.269, 0.2139 s / batch. (data: 3.39e-05)max mem: 7.81207 GB 
[10/01 05:45:31 visual_prompt]: 	Test 200/356. loss: 1.448, 0.2144 s / batch. (data: 8.85e-05)max mem: 7.81207 GB 
[10/01 05:45:53 visual_prompt]: 	Test 300/356. loss: 1.393, 0.2149 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:46:06 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2139, average loss: 1.4065
[10/01 05:46:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.36	top5: 98.17	
[10/01 05:46:06 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[10/01 05:46:16 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e-01, avg batch time: 0.5562, average train loss: 1.2251
[10/01 05:46:20 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 1.1004
[10/01 05:46:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 56.50	top5: 99.00	
[10/01 05:46:43 visual_prompt]: 	Test 100/356. loss: 1.221, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 05:47:04 visual_prompt]: 	Test 200/356. loss: 1.310, 0.2145 s / batch. (data: 7.51e-05)max mem: 7.81207 GB 
[10/01 05:47:26 visual_prompt]: 	Test 300/356. loss: 1.208, 0.2150 s / batch. (data: 1.22e-04)max mem: 7.81207 GB 
[10/01 05:47:39 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2138, average loss: 1.2677
[10/01 05:47:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.02	top5: 98.29	
[10/01 05:47:39 visual_prompt]: Best epoch 43: best metric: 0.565
[10/01 05:47:39 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[10/01 05:47:49 visual_prompt]: Epoch 44 / 100: avg data time: 1.04e-01, avg batch time: 0.5539, average train loss: 1.1767
[10/01 05:47:53 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1670, average loss: 1.2129
[10/01 05:47:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.50	top5: 99.00	
[10/01 05:48:16 visual_prompt]: 	Test 100/356. loss: 1.431, 0.2135 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:48:37 visual_prompt]: 	Test 200/356. loss: 1.628, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 05:48:59 visual_prompt]: 	Test 300/356. loss: 1.383, 0.2151 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:49:12 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2141, average loss: 1.4383
[10/01 05:49:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.52	top5: 97.79	
[10/01 05:49:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[10/01 05:49:23 visual_prompt]: Epoch 45 / 100: avg data time: 1.05e-01, avg batch time: 0.5560, average train loss: 1.1534
[10/01 05:49:26 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 1.2007
[10/01 05:49:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.50	top5: 98.50	
[10/01 05:49:49 visual_prompt]: 	Test 100/356. loss: 1.483, 0.2141 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 05:50:11 visual_prompt]: 	Test 200/356. loss: 1.297, 0.2145 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:50:32 visual_prompt]: 	Test 300/356. loss: 1.443, 0.2149 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 05:50:46 visual_prompt]: Inference (test):avg data time: 4.65e-05, avg batch time: 0.2139, average loss: 1.4339
[10/01 05:50:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.77	top5: 97.55	
[10/01 05:50:46 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[10/01 05:50:56 visual_prompt]: Epoch 46 / 100: avg data time: 1.07e-01, avg batch time: 0.5566, average train loss: 1.4401
[10/01 05:51:00 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1667, average loss: 1.7239
[10/01 05:51:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 31.00	top5: 88.00	
[10/01 05:51:23 visual_prompt]: 	Test 100/356. loss: 1.763, 0.2133 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 05:51:45 visual_prompt]: 	Test 200/356. loss: 1.770, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 05:52:06 visual_prompt]: 	Test 300/356. loss: 1.639, 0.2146 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:52:19 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2138, average loss: 1.7208
[10/01 05:52:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.19	top5: 89.22	
[10/01 05:52:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[10/01 05:52:30 visual_prompt]: Epoch 47 / 100: avg data time: 1.07e-01, avg batch time: 0.5568, average train loss: 1.4118
[10/01 05:52:33 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1668, average loss: 1.2476
[10/01 05:52:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.50	top5: 99.50	
[10/01 05:52:56 visual_prompt]: 	Test 100/356. loss: 1.232, 0.2139 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 05:53:18 visual_prompt]: 	Test 200/356. loss: 1.506, 0.2145 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[10/01 05:53:39 visual_prompt]: 	Test 300/356. loss: 1.306, 0.2146 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:53:53 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2139, average loss: 1.3980
[10/01 05:53:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.21	top5: 97.85	
[10/01 05:53:53 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[10/01 05:54:03 visual_prompt]: Epoch 48 / 100: avg data time: 1.20e-01, avg batch time: 0.5690, average train loss: 1.2419
[10/01 05:54:07 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 1.2653
[10/01 05:54:07 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.00	top5: 99.00	
[10/01 05:54:30 visual_prompt]: 	Test 100/356. loss: 1.468, 0.2143 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 05:54:51 visual_prompt]: 	Test 200/356. loss: 1.779, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:55:13 visual_prompt]: 	Test 300/356. loss: 1.487, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 05:55:26 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2138, average loss: 1.5142
[10/01 05:55:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.60	top5: 97.51	
[10/01 05:55:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[10/01 05:55:36 visual_prompt]: Epoch 49 / 100: avg data time: 9.82e-02, avg batch time: 0.5480, average train loss: 1.2323
[10/01 05:55:40 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1668, average loss: 1.2930
[10/01 05:55:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 99.50	
[10/01 05:56:03 visual_prompt]: 	Test 100/356. loss: 1.378, 0.2141 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 05:56:24 visual_prompt]: 	Test 200/356. loss: 1.420, 0.2144 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 05:56:46 visual_prompt]: 	Test 300/356. loss: 1.352, 0.2147 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 05:56:59 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2138, average loss: 1.4170
[10/01 05:56:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.49	top5: 98.36	
[10/01 05:56:59 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[10/01 05:57:09 visual_prompt]: Epoch 50 / 100: avg data time: 1.01e-01, avg batch time: 0.5518, average train loss: 1.2292
[10/01 05:57:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1667, average loss: 1.5359
[10/01 05:57:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 34.00	top5: 96.50	
[10/01 05:57:36 visual_prompt]: 	Test 100/356. loss: 1.550, 0.2142 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 05:57:58 visual_prompt]: 	Test 200/356. loss: 1.717, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 05:58:19 visual_prompt]: 	Test 300/356. loss: 1.422, 0.2151 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 05:58:33 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2138, average loss: 1.6061
[10/01 05:58:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 30.93	top5: 95.58	
[10/01 05:58:33 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[10/01 05:58:43 visual_prompt]: Epoch 51 / 100: avg data time: 1.05e-01, avg batch time: 0.5555, average train loss: 1.2408
[10/01 05:58:46 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1668, average loss: 1.1457
[10/01 05:58:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.50	top5: 99.00	
[10/01 05:59:09 visual_prompt]: 	Test 100/356. loss: 1.220, 0.2141 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 05:59:31 visual_prompt]: 	Test 200/356. loss: 1.312, 0.2149 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 05:59:52 visual_prompt]: 	Test 300/356. loss: 1.152, 0.2147 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 06:00:06 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2139, average loss: 1.2858
[10/01 06:00:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.66	top5: 98.31	
[10/01 06:00:06 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[10/01 06:00:16 visual_prompt]: Epoch 52 / 100: avg data time: 1.05e-01, avg batch time: 0.5547, average train loss: 1.2170
[10/01 06:00:20 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1669, average loss: 1.1683
[10/01 06:00:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.50	top5: 99.50	
[10/01 06:00:43 visual_prompt]: 	Test 100/356. loss: 1.274, 0.2137 s / batch. (data: 9.23e-05)max mem: 7.81207 GB 
[10/01 06:01:04 visual_prompt]: 	Test 200/356. loss: 1.510, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 06:01:26 visual_prompt]: 	Test 300/356. loss: 1.214, 0.2144 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 06:01:39 visual_prompt]: Inference (test):avg data time: 4.99e-05, avg batch time: 0.2137, average loss: 1.3321
[10/01 06:01:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.80	top5: 97.73	
[10/01 06:01:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[10/01 06:01:49 visual_prompt]: Epoch 53 / 100: avg data time: 1.14e-01, avg batch time: 0.5635, average train loss: 1.1350
[10/01 06:01:53 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1666, average loss: 1.2658
[10/01 06:01:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 99.50	
[10/01 06:02:16 visual_prompt]: 	Test 100/356. loss: 1.387, 0.2138 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 06:02:38 visual_prompt]: 	Test 200/356. loss: 1.706, 0.2143 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 06:02:59 visual_prompt]: 	Test 300/356. loss: 1.620, 0.2146 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:03:13 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2137, average loss: 1.5149
[10/01 06:03:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.59	top5: 97.58	
[10/01 06:03:13 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[10/01 06:03:23 visual_prompt]: Epoch 54 / 100: avg data time: 1.09e-01, avg batch time: 0.5586, average train loss: 1.1893
[10/01 06:03:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1669, average loss: 1.1845
[10/01 06:03:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.50	top5: 99.00	
[10/01 06:03:50 visual_prompt]: 	Test 100/356. loss: 1.222, 0.2137 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 06:04:11 visual_prompt]: 	Test 200/356. loss: 1.351, 0.2144 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 06:04:33 visual_prompt]: 	Test 300/356. loss: 1.248, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:04:46 visual_prompt]: Inference (test):avg data time: 6.21e-05, avg batch time: 0.2138, average loss: 1.3462
[10/01 06:04:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.69	top5: 98.10	
[10/01 06:04:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[10/01 06:04:56 visual_prompt]: Epoch 55 / 100: avg data time: 1.07e-01, avg batch time: 0.5574, average train loss: 1.2088
[10/01 06:05:00 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1669, average loss: 1.1693
[10/01 06:05:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.00	top5: 99.00	
[10/01 06:05:23 visual_prompt]: 	Test 100/356. loss: 1.210, 0.2138 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 06:05:44 visual_prompt]: 	Test 200/356. loss: 1.663, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 06:06:06 visual_prompt]: 	Test 300/356. loss: 1.438, 0.2145 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:06:19 visual_prompt]: Inference (test):avg data time: 5.65e-05, avg batch time: 0.2139, average loss: 1.4853
[10/01 06:06:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.18	top5: 96.20	
[10/01 06:06:19 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[10/01 06:06:30 visual_prompt]: Epoch 56 / 100: avg data time: 1.17e-01, avg batch time: 0.5665, average train loss: 1.2037
[10/01 06:06:33 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1667, average loss: 1.4008
[10/01 06:06:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.50	
[10/01 06:06:56 visual_prompt]: 	Test 100/356. loss: 1.460, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:07:18 visual_prompt]: 	Test 200/356. loss: 1.399, 0.2139 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 06:07:39 visual_prompt]: 	Test 300/356. loss: 1.484, 0.2148 s / batch. (data: 7.70e-05)max mem: 7.81207 GB 
[10/01 06:07:53 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2140, average loss: 1.5005
[10/01 06:07:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.75	top5: 97.07	
[10/01 06:07:53 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[10/01 06:08:03 visual_prompt]: Epoch 57 / 100: avg data time: 1.04e-01, avg batch time: 0.5542, average train loss: 1.1382
[10/01 06:08:06 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1668, average loss: 1.1458
[10/01 06:08:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.50	
[10/01 06:08:30 visual_prompt]: 	Test 100/356. loss: 1.288, 0.2145 s / batch. (data: 7.56e-05)max mem: 7.81207 GB 
[10/01 06:08:51 visual_prompt]: 	Test 200/356. loss: 1.539, 0.2147 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 06:09:13 visual_prompt]: 	Test 300/356. loss: 1.226, 0.2148 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 06:09:26 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2139, average loss: 1.3558
[10/01 06:09:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.03	top5: 97.97	
[10/01 06:09:26 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[10/01 06:09:36 visual_prompt]: Epoch 58 / 100: avg data time: 1.08e-01, avg batch time: 0.5592, average train loss: 1.0854
[10/01 06:09:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1669, average loss: 1.1650
[10/01 06:09:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 98.50	
[10/01 06:10:03 visual_prompt]: 	Test 100/356. loss: 1.415, 0.2137 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:10:24 visual_prompt]: 	Test 200/356. loss: 1.607, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 06:10:46 visual_prompt]: 	Test 300/356. loss: 1.376, 0.2144 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 06:10:59 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2138, average loss: 1.4741
[10/01 06:10:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.26	top5: 97.72	
[10/01 06:10:59 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[10/01 06:11:10 visual_prompt]: Epoch 59 / 100: avg data time: 1.02e-01, avg batch time: 0.5514, average train loss: 1.1248
[10/01 06:11:13 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1670, average loss: 1.5014
[10/01 06:11:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 92.00	
[10/01 06:11:36 visual_prompt]: 	Test 100/356. loss: 1.683, 0.2140 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:11:58 visual_prompt]: 	Test 200/356. loss: 1.392, 0.2145 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:12:19 visual_prompt]: 	Test 300/356. loss: 1.671, 0.2149 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 06:12:33 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2138, average loss: 1.6629
[10/01 06:12:33 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.74	top5: 95.26	
[10/01 06:12:33 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[10/01 06:12:43 visual_prompt]: Epoch 60 / 100: avg data time: 1.11e-01, avg batch time: 0.5607, average train loss: 1.2134
[10/01 06:12:47 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1669, average loss: 1.0881
[10/01 06:12:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 50.50	top5: 99.50	
[10/01 06:13:10 visual_prompt]: 	Test 100/356. loss: 1.345, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:13:31 visual_prompt]: 	Test 200/356. loss: 1.830, 0.2143 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:13:53 visual_prompt]: 	Test 300/356. loss: 1.357, 0.2145 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:14:06 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2138, average loss: 1.5246
[10/01 06:14:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.51	top5: 96.70	
[10/01 06:14:06 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[10/01 06:14:16 visual_prompt]: Epoch 61 / 100: avg data time: 1.12e-01, avg batch time: 0.5611, average train loss: 1.1748
[10/01 06:14:20 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1668, average loss: 1.2377
[10/01 06:14:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[10/01 06:14:43 visual_prompt]: 	Test 100/356. loss: 1.481, 0.2137 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 06:15:04 visual_prompt]: 	Test 200/356. loss: 1.678, 0.2142 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 06:15:26 visual_prompt]: 	Test 300/356. loss: 1.291, 0.2144 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 06:15:39 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2139, average loss: 1.4779
[10/01 06:15:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.92	top5: 98.06	
[10/01 06:15:39 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[10/01 06:15:50 visual_prompt]: Epoch 62 / 100: avg data time: 1.10e-01, avg batch time: 0.5596, average train loss: 1.1873
[10/01 06:15:53 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1670, average loss: 1.2666
[10/01 06:15:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 99.50	
[10/01 06:16:16 visual_prompt]: 	Test 100/356. loss: 1.566, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:16:38 visual_prompt]: 	Test 200/356. loss: 1.441, 0.2133 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 06:16:59 visual_prompt]: 	Test 300/356. loss: 1.451, 0.2144 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:17:13 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2140, average loss: 1.5402
[10/01 06:17:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.30	top5: 98.37	
[10/01 06:17:13 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[10/01 06:17:23 visual_prompt]: Epoch 63 / 100: avg data time: 1.02e-01, avg batch time: 0.5521, average train loss: 1.2406
[10/01 06:17:26 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1669, average loss: 1.1501
[10/01 06:17:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 99.50	
[10/01 06:17:50 visual_prompt]: 	Test 100/356. loss: 1.186, 0.2139 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:18:11 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2147 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:18:33 visual_prompt]: 	Test 300/356. loss: 1.252, 0.2145 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 06:18:46 visual_prompt]: Inference (test):avg data time: 2.91e-05, avg batch time: 0.2138, average loss: 1.3381
[10/01 06:18:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.01	top5: 97.27	
[10/01 06:18:46 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[10/01 06:18:56 visual_prompt]: Epoch 64 / 100: avg data time: 1.04e-01, avg batch time: 0.5534, average train loss: 1.1512
[10/01 06:19:00 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1669, average loss: 1.1603
[10/01 06:19:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.50	
[10/01 06:19:23 visual_prompt]: 	Test 100/356. loss: 1.342, 0.2140 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 06:19:44 visual_prompt]: 	Test 200/356. loss: 1.613, 0.2148 s / batch. (data: 3.22e-05)max mem: 7.81207 GB 
[10/01 06:20:06 visual_prompt]: 	Test 300/356. loss: 1.294, 0.2142 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 06:20:19 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2139, average loss: 1.4487
[10/01 06:20:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.59	top5: 97.15	
[10/01 06:20:19 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[10/01 06:20:30 visual_prompt]: Epoch 65 / 100: avg data time: 1.05e-01, avg batch time: 0.5554, average train loss: 1.0883
[10/01 06:20:33 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1669, average loss: 1.1020
[10/01 06:20:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 50.00	top5: 99.50	
[10/01 06:20:56 visual_prompt]: 	Test 100/356. loss: 1.294, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:21:18 visual_prompt]: 	Test 200/356. loss: 1.346, 0.2147 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:21:39 visual_prompt]: 	Test 300/356. loss: 1.240, 0.2148 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 06:21:52 visual_prompt]: Inference (test):avg data time: 5.88e-05, avg batch time: 0.2138, average loss: 1.3622
[10/01 06:21:53 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.80	top5: 98.33	
[10/01 06:21:53 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[10/01 06:22:03 visual_prompt]: Epoch 66 / 100: avg data time: 1.03e-01, avg batch time: 0.5530, average train loss: 1.0168
[10/01 06:22:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1669, average loss: 1.1536
[10/01 06:22:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 45.50	top5: 99.00	
[10/01 06:22:29 visual_prompt]: 	Test 100/356. loss: 1.370, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 06:22:51 visual_prompt]: 	Test 200/356. loss: 1.547, 0.2142 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 06:23:12 visual_prompt]: 	Test 300/356. loss: 1.271, 0.2148 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 06:23:26 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2138, average loss: 1.4894
[10/01 06:23:26 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.82	top5: 97.78	
[10/01 06:23:26 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[10/01 06:23:36 visual_prompt]: Epoch 67 / 100: avg data time: 1.17e-01, avg batch time: 0.5658, average train loss: 1.0363
[10/01 06:23:40 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.1668, average loss: 1.1684
[10/01 06:23:40 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.00	
[10/01 06:24:03 visual_prompt]: 	Test 100/356. loss: 1.350, 0.2139 s / batch. (data: 8.85e-05)max mem: 7.81207 GB 
[10/01 06:24:24 visual_prompt]: 	Test 200/356. loss: 1.270, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 06:24:46 visual_prompt]: 	Test 300/356. loss: 1.379, 0.2151 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:24:59 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.2139, average loss: 1.4334
[10/01 06:24:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.69	top5: 97.88	
[10/01 06:24:59 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[10/01 06:25:09 visual_prompt]: Epoch 68 / 100: avg data time: 1.04e-01, avg batch time: 0.5539, average train loss: 1.0584
[10/01 06:25:13 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1667, average loss: 1.0172
[10/01 06:25:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 52.00	top5: 100.00	
[10/01 06:25:36 visual_prompt]: 	Test 100/356. loss: 1.269, 0.2140 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:25:57 visual_prompt]: 	Test 200/356. loss: 1.517, 0.2143 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 06:26:19 visual_prompt]: 	Test 300/356. loss: 1.271, 0.2148 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 06:26:32 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2138, average loss: 1.4130
[10/01 06:26:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.97	top5: 98.07	
[10/01 06:26:32 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[10/01 06:26:42 visual_prompt]: Epoch 69 / 100: avg data time: 1.10e-01, avg batch time: 0.5620, average train loss: 1.0098
[10/01 06:26:46 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1668, average loss: 1.0540
[10/01 06:26:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 99.50	
[10/01 06:27:09 visual_prompt]: 	Test 100/356. loss: 1.250, 0.2139 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:27:30 visual_prompt]: 	Test 200/356. loss: 1.458, 0.2145 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 06:27:52 visual_prompt]: 	Test 300/356. loss: 1.286, 0.2144 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 06:28:05 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2139, average loss: 1.4366
[10/01 06:28:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.14	top5: 98.35	
[10/01 06:28:05 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[10/01 06:28:15 visual_prompt]: Epoch 70 / 100: avg data time: 9.75e-02, avg batch time: 0.5487, average train loss: 0.9729
[10/01 06:28:19 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1668, average loss: 1.0018
[10/01 06:28:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.00	top5: 99.50	
[10/01 06:28:42 visual_prompt]: 	Test 100/356. loss: 1.346, 0.2139 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:29:04 visual_prompt]: 	Test 200/356. loss: 1.446, 0.2144 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:29:25 visual_prompt]: 	Test 300/356. loss: 1.289, 0.2145 s / batch. (data: 1.24e-04)max mem: 7.81207 GB 
[10/01 06:29:38 visual_prompt]: Inference (test):avg data time: 4.55e-05, avg batch time: 0.2140, average loss: 1.4057
[10/01 06:29:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.73	top5: 98.27	
[10/01 06:29:39 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[10/01 06:29:49 visual_prompt]: Epoch 71 / 100: avg data time: 1.17e-01, avg batch time: 0.5661, average train loss: 0.9390
[10/01 06:29:52 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1670, average loss: 1.0066
[10/01 06:29:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 100.00	
[10/01 06:30:16 visual_prompt]: 	Test 100/356. loss: 1.503, 0.2153 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:30:37 visual_prompt]: 	Test 200/356. loss: 1.536, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:30:59 visual_prompt]: 	Test 300/356. loss: 1.340, 0.2145 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:31:12 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2138, average loss: 1.4601
[10/01 06:31:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 44.11	top5: 98.32	
[10/01 06:31:12 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[10/01 06:31:22 visual_prompt]: Epoch 72 / 100: avg data time: 1.04e-01, avg batch time: 0.5551, average train loss: 0.9780
[10/01 06:31:26 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1670, average loss: 1.0318
[10/01 06:31:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 56.50	top5: 99.00	
[10/01 06:31:49 visual_prompt]: 	Test 100/356. loss: 1.381, 0.2147 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:32:10 visual_prompt]: 	Test 200/356. loss: 1.523, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:32:32 visual_prompt]: 	Test 300/356. loss: 1.482, 0.2146 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:32:45 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2140, average loss: 1.5238
[10/01 06:32:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.73	top5: 98.25	
[10/01 06:32:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[10/01 06:32:56 visual_prompt]: Epoch 73 / 100: avg data time: 1.06e-01, avg batch time: 0.5572, average train loss: 0.9404
[10/01 06:32:59 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1668, average loss: 0.9524
[10/01 06:32:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 51.00	top5: 99.50	
[10/01 06:33:22 visual_prompt]: 	Test 100/356. loss: 1.447, 0.2143 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 06:33:44 visual_prompt]: 	Test 200/356. loss: 1.717, 0.2196 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 06:34:05 visual_prompt]: 	Test 300/356. loss: 1.335, 0.2143 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:34:19 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2140, average loss: 1.4999
[10/01 06:34:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.10	top5: 98.24	
[10/01 06:34:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[10/01 06:34:29 visual_prompt]: Epoch 74 / 100: avg data time: 1.07e-01, avg batch time: 0.5576, average train loss: 0.9086
[10/01 06:34:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 0.8672
[10/01 06:34:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 59.50	top5: 99.50	
[10/01 06:34:56 visual_prompt]: 	Test 100/356. loss: 1.294, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:35:17 visual_prompt]: 	Test 200/356. loss: 1.684, 0.2142 s / batch. (data: 8.39e-05)max mem: 7.81207 GB 
[10/01 06:35:39 visual_prompt]: 	Test 300/356. loss: 1.236, 0.2148 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 06:35:52 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2138, average loss: 1.4338
[10/01 06:35:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.07	top5: 97.56	
[10/01 06:35:52 visual_prompt]: Best epoch 74: best metric: 0.595
[10/01 06:35:52 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[10/01 06:36:02 visual_prompt]: Epoch 75 / 100: avg data time: 1.14e-01, avg batch time: 0.5638, average train loss: 0.8450
[10/01 06:36:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1668, average loss: 0.7842
[10/01 06:36:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 66.50	top5: 100.00	
[10/01 06:36:29 visual_prompt]: 	Test 100/356. loss: 1.441, 0.2137 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:36:51 visual_prompt]: 	Test 200/356. loss: 1.792, 0.2142 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 06:37:12 visual_prompt]: 	Test 300/356. loss: 1.350, 0.2147 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 06:37:25 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2139, average loss: 1.5477
[10/01 06:37:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.11	top5: 97.84	
[10/01 06:37:25 visual_prompt]: Best epoch 75: best metric: 0.665
[10/01 06:37:25 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[10/01 06:37:36 visual_prompt]: Epoch 76 / 100: avg data time: 1.09e-01, avg batch time: 0.5580, average train loss: 0.8073
[10/01 06:37:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1667, average loss: 0.7711
[10/01 06:37:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 61.50	top5: 99.50	
[10/01 06:38:02 visual_prompt]: 	Test 100/356. loss: 1.549, 0.2138 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:38:24 visual_prompt]: 	Test 200/356. loss: 1.769, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:38:45 visual_prompt]: 	Test 300/356. loss: 1.454, 0.2151 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:38:59 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2138, average loss: 1.6550
[10/01 06:38:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.39	top5: 97.64	
[10/01 06:38:59 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[10/01 06:39:09 visual_prompt]: Epoch 77 / 100: avg data time: 1.05e-01, avg batch time: 0.5547, average train loss: 0.8229
[10/01 06:39:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1668, average loss: 0.8606
[10/01 06:39:13 visual_prompt]: Classification results with val_vtab-dmlab: top1: 58.50	top5: 100.00	
[10/01 06:39:36 visual_prompt]: 	Test 100/356. loss: 1.426, 0.2141 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:39:57 visual_prompt]: 	Test 200/356. loss: 1.579, 0.2146 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:40:19 visual_prompt]: 	Test 300/356. loss: 1.414, 0.2145 s / batch. (data: 3.17e-05)max mem: 7.81207 GB 
[10/01 06:40:32 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2138, average loss: 1.5341
[10/01 06:40:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 37.37	top5: 98.04	
[10/01 06:40:32 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[10/01 06:40:42 visual_prompt]: Epoch 78 / 100: avg data time: 1.04e-01, avg batch time: 0.5548, average train loss: 0.8244
[10/01 06:40:46 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1669, average loss: 0.7663
[10/01 06:40:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 65.00	top5: 99.00	
[10/01 06:41:09 visual_prompt]: 	Test 100/356. loss: 1.578, 0.2140 s / batch. (data: 8.75e-05)max mem: 7.81207 GB 
[10/01 06:41:30 visual_prompt]: 	Test 200/356. loss: 1.770, 0.2145 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:41:52 visual_prompt]: 	Test 300/356. loss: 1.544, 0.2146 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:42:05 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2139, average loss: 1.6384
[10/01 06:42:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.93	top5: 97.61	
[10/01 06:42:05 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[10/01 06:42:15 visual_prompt]: Epoch 79 / 100: avg data time: 1.06e-01, avg batch time: 0.5551, average train loss: 0.7660
[10/01 06:42:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1670, average loss: 0.7137
[10/01 06:42:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 64.50	top5: 100.00	
[10/01 06:42:42 visual_prompt]: 	Test 100/356. loss: 1.660, 0.2141 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 06:43:04 visual_prompt]: 	Test 200/356. loss: 1.875, 0.2143 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 06:43:25 visual_prompt]: 	Test 300/356. loss: 1.562, 0.2146 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:43:39 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2139, average loss: 1.7232
[10/01 06:43:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.66	top5: 96.91	
[10/01 06:43:39 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[10/01 06:43:49 visual_prompt]: Epoch 80 / 100: avg data time: 1.12e-01, avg batch time: 0.5618, average train loss: 0.6997
[10/01 06:43:53 visual_prompt]: Inference (val):avg data time: 4.44e-04, avg batch time: 0.1670, average loss: 0.6898
[10/01 06:43:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 66.00	top5: 99.50	
[10/01 06:44:16 visual_prompt]: 	Test 100/356. loss: 1.565, 0.2141 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 06:44:37 visual_prompt]: 	Test 200/356. loss: 1.817, 0.2148 s / batch. (data: 7.06e-05)max mem: 7.81207 GB 
[10/01 06:44:59 visual_prompt]: 	Test 300/356. loss: 1.534, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 06:45:12 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2139, average loss: 1.7057
[10/01 06:45:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.28	top5: 97.63	
[10/01 06:45:12 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[10/01 06:45:22 visual_prompt]: Epoch 81 / 100: avg data time: 1.05e-01, avg batch time: 0.5545, average train loss: 0.6560
[10/01 06:45:26 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1670, average loss: 0.6869
[10/01 06:45:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 66.00	top5: 100.00	
[10/01 06:45:49 visual_prompt]: 	Test 100/356. loss: 1.912, 0.2143 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 06:46:10 visual_prompt]: 	Test 200/356. loss: 2.226, 0.2144 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 06:46:32 visual_prompt]: 	Test 300/356. loss: 1.802, 0.2144 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:46:45 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2139, average loss: 1.8969
[10/01 06:46:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.78	top5: 97.09	
[10/01 06:46:45 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[10/01 06:46:55 visual_prompt]: Epoch 82 / 100: avg data time: 1.11e-01, avg batch time: 0.5606, average train loss: 0.6901
[10/01 06:46:59 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1670, average loss: 0.7103
[10/01 06:46:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 59.50	top5: 100.00	
[10/01 06:47:22 visual_prompt]: 	Test 100/356. loss: 1.670, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 06:47:44 visual_prompt]: 	Test 200/356. loss: 2.258, 0.2147 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 06:48:05 visual_prompt]: 	Test 300/356. loss: 1.685, 0.2149 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 06:48:19 visual_prompt]: Inference (test):avg data time: 9.44e-05, avg batch time: 0.2140, average loss: 1.8586
[10/01 06:48:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.55	top5: 97.24	
[10/01 06:48:19 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[10/01 06:48:29 visual_prompt]: Epoch 83 / 100: avg data time: 1.05e-01, avg batch time: 0.5572, average train loss: 0.6300
[10/01 06:48:32 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1667, average loss: 0.6372
[10/01 06:48:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 68.50	top5: 100.00	
[10/01 06:48:55 visual_prompt]: 	Test 100/356. loss: 1.635, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 06:49:17 visual_prompt]: 	Test 200/356. loss: 2.391, 0.2148 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 06:49:38 visual_prompt]: 	Test 300/356. loss: 1.854, 0.2151 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 06:49:52 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2139, average loss: 2.0073
[10/01 06:49:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.36	top5: 96.93	
[10/01 06:49:52 visual_prompt]: Best epoch 83: best metric: 0.685
[10/01 06:49:52 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[10/01 06:50:02 visual_prompt]: Epoch 84 / 100: avg data time: 1.16e-01, avg batch time: 0.5651, average train loss: 0.5641
[10/01 06:50:06 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1668, average loss: 0.6921
[10/01 06:50:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 61.50	top5: 100.00	
[10/01 06:50:29 visual_prompt]: 	Test 100/356. loss: 2.203, 0.2140 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 06:50:50 visual_prompt]: 	Test 200/356. loss: 2.552, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:51:12 visual_prompt]: 	Test 300/356. loss: 1.782, 0.2147 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 06:51:25 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2138, average loss: 2.1033
[10/01 06:51:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.62	top5: 97.51	
[10/01 06:51:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[10/01 06:51:36 visual_prompt]: Epoch 85 / 100: avg data time: 1.11e-01, avg batch time: 0.5606, average train loss: 0.5347
[10/01 06:51:39 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1669, average loss: 0.6072
[10/01 06:51:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 69.00	top5: 100.00	
[10/01 06:52:02 visual_prompt]: 	Test 100/356. loss: 2.492, 0.2136 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:52:24 visual_prompt]: 	Test 200/356. loss: 2.204, 0.2150 s / batch. (data: 3.39e-05)max mem: 7.81207 GB 
[10/01 06:52:45 visual_prompt]: 	Test 300/356. loss: 1.957, 0.2146 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 06:52:59 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2139, average loss: 2.2661
[10/01 06:52:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.13	top5: 96.73	
[10/01 06:52:59 visual_prompt]: Best epoch 85: best metric: 0.690
[10/01 06:52:59 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[10/01 06:53:09 visual_prompt]: Epoch 86 / 100: avg data time: 1.02e-01, avg batch time: 0.5523, average train loss: 0.5314
[10/01 06:53:12 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1668, average loss: 0.5349
[10/01 06:53:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 73.00	top5: 100.00	
[10/01 06:53:36 visual_prompt]: 	Test 100/356. loss: 2.331, 0.2136 s / batch. (data: 3.74e-05)max mem: 7.81207 GB 
[10/01 06:53:57 visual_prompt]: 	Test 200/356. loss: 2.417, 0.2144 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 06:54:19 visual_prompt]: 	Test 300/356. loss: 2.061, 0.2149 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 06:54:32 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2138, average loss: 2.2372
[10/01 06:54:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.82	top5: 96.42	
[10/01 06:54:32 visual_prompt]: Best epoch 86: best metric: 0.730
[10/01 06:54:32 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[10/01 06:54:42 visual_prompt]: Epoch 87 / 100: avg data time: 1.12e-01, avg batch time: 0.5613, average train loss: 0.4959
[10/01 06:54:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1669, average loss: 0.4443
[10/01 06:54:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 77.50	top5: 100.00	
[10/01 06:55:09 visual_prompt]: 	Test 100/356. loss: 2.130, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 06:55:30 visual_prompt]: 	Test 200/356. loss: 2.766, 0.2145 s / batch. (data: 7.39e-05)max mem: 7.81207 GB 
[10/01 06:55:52 visual_prompt]: 	Test 300/356. loss: 2.103, 0.2147 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 06:56:05 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2139, average loss: 2.2978
[10/01 06:56:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.83	top5: 95.76	
[10/01 06:56:05 visual_prompt]: Best epoch 87: best metric: 0.775
[10/01 06:56:05 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[10/01 06:56:16 visual_prompt]: Epoch 88 / 100: avg data time: 1.02e-01, avg batch time: 0.5526, average train loss: 0.4406
[10/01 06:56:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1669, average loss: 0.4344
[10/01 06:56:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 81.00	top5: 100.00	
[10/01 06:56:42 visual_prompt]: 	Test 100/356. loss: 2.527, 0.2141 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 06:57:04 visual_prompt]: 	Test 200/356. loss: 2.486, 0.2147 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 06:57:25 visual_prompt]: 	Test 300/356. loss: 2.213, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 06:57:39 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2139, average loss: 2.4201
[10/01 06:57:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.48	top5: 96.57	
[10/01 06:57:39 visual_prompt]: Best epoch 88: best metric: 0.810
[10/01 06:57:39 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[10/01 06:57:49 visual_prompt]: Epoch 89 / 100: avg data time: 1.05e-01, avg batch time: 0.5558, average train loss: 0.3651
[10/01 06:57:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1668, average loss: 0.4548
[10/01 06:57:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 77.50	top5: 100.00	
[10/01 06:58:16 visual_prompt]: 	Test 100/356. loss: 2.722, 0.2140 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 06:58:37 visual_prompt]: 	Test 200/356. loss: 2.658, 0.2146 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 06:58:59 visual_prompt]: 	Test 300/356. loss: 2.312, 0.2151 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 06:59:12 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2139, average loss: 2.6323
[10/01 06:59:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 43.06	top5: 96.45	
[10/01 06:59:12 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[10/01 06:59:22 visual_prompt]: Epoch 90 / 100: avg data time: 1.04e-01, avg batch time: 0.5539, average train loss: 0.3375
[10/01 06:59:26 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1672, average loss: 0.4797
[10/01 06:59:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 78.50	top5: 100.00	
[10/01 06:59:49 visual_prompt]: 	Test 100/356. loss: 2.632, 0.2145 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 07:00:10 visual_prompt]: 	Test 200/356. loss: 3.516, 0.2149 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 07:00:32 visual_prompt]: 	Test 300/356. loss: 2.671, 0.2147 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 07:00:45 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2140, average loss: 2.7776
[10/01 07:00:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.53	top5: 94.85	
[10/01 07:00:45 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[10/01 07:00:56 visual_prompt]: Epoch 91 / 100: avg data time: 1.11e-01, avg batch time: 0.5615, average train loss: 0.3019
[10/01 07:00:59 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1670, average loss: 0.3323
[10/01 07:00:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 85.00	top5: 100.00	
[10/01 07:01:22 visual_prompt]: 	Test 100/356. loss: 2.900, 0.2139 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 07:01:44 visual_prompt]: 	Test 200/356. loss: 2.770, 0.2147 s / batch. (data: 3.34e-05)max mem: 7.81207 GB 
[10/01 07:02:05 visual_prompt]: 	Test 300/356. loss: 2.597, 0.2146 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 07:02:19 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2139, average loss: 2.7526
[10/01 07:02:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.45	top5: 95.90	
[10/01 07:02:19 visual_prompt]: Best epoch 91: best metric: 0.850
[10/01 07:02:19 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[10/01 07:02:29 visual_prompt]: Epoch 92 / 100: avg data time: 1.11e-01, avg batch time: 0.5620, average train loss: 0.2750
[10/01 07:02:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1669, average loss: 0.3746
[10/01 07:02:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 81.50	top5: 100.00	
[10/01 07:02:56 visual_prompt]: 	Test 100/356. loss: 3.032, 0.2140 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 07:03:17 visual_prompt]: 	Test 200/356. loss: 3.081, 0.2144 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:03:39 visual_prompt]: 	Test 300/356. loss: 2.730, 0.2144 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:03:52 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2139, average loss: 2.8451
[10/01 07:03:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.32	top5: 95.03	
[10/01 07:03:52 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[10/01 07:04:02 visual_prompt]: Epoch 93 / 100: avg data time: 1.02e-01, avg batch time: 0.5522, average train loss: 0.2904
[10/01 07:04:06 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1667, average loss: 0.3839
[10/01 07:04:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 83.00	top5: 100.00	
[10/01 07:04:29 visual_prompt]: 	Test 100/356. loss: 2.812, 0.2138 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 07:04:50 visual_prompt]: 	Test 200/356. loss: 2.953, 0.2141 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 07:05:12 visual_prompt]: 	Test 300/356. loss: 2.708, 0.2144 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:05:25 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2139, average loss: 2.7880
[10/01 07:05:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 42.41	top5: 95.66	
[10/01 07:05:25 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[10/01 07:05:36 visual_prompt]: Epoch 94 / 100: avg data time: 1.05e-01, avg batch time: 0.5554, average train loss: 0.2440
[10/01 07:05:39 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 0.2591
[10/01 07:05:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 88.00	top5: 100.00	
[10/01 07:06:02 visual_prompt]: 	Test 100/356. loss: 2.851, 0.2159 s / batch. (data: 3.39e-05)max mem: 7.81207 GB 
[10/01 07:06:24 visual_prompt]: 	Test 200/356. loss: 3.194, 0.2147 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:06:45 visual_prompt]: 	Test 300/356. loss: 2.742, 0.2145 s / batch. (data: 3.72e-05)max mem: 7.81207 GB 
[10/01 07:06:59 visual_prompt]: Inference (test):avg data time: 4.64e-05, avg batch time: 0.2140, average loss: 2.8928
[10/01 07:06:59 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.99	top5: 95.30	
[10/01 07:06:59 visual_prompt]: Best epoch 94: best metric: 0.880
[10/01 07:06:59 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[10/01 07:07:09 visual_prompt]: Epoch 95 / 100: avg data time: 1.07e-01, avg batch time: 0.5569, average train loss: 0.2150
[10/01 07:07:12 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1671, average loss: 0.2291
[10/01 07:07:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 89.50	top5: 100.00	
[10/01 07:07:36 visual_prompt]: 	Test 100/356. loss: 2.910, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:07:57 visual_prompt]: 	Test 200/356. loss: 3.166, 0.2141 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 07:08:19 visual_prompt]: 	Test 300/356. loss: 2.774, 0.2148 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:08:32 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2139, average loss: 2.9464
[10/01 07:08:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.81	top5: 95.11	
[10/01 07:08:32 visual_prompt]: Best epoch 95: best metric: 0.895
[10/01 07:08:32 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[10/01 07:08:42 visual_prompt]: Epoch 96 / 100: avg data time: 1.19e-01, avg batch time: 0.5691, average train loss: 0.1729
[10/01 07:08:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1668, average loss: 0.1603
[10/01 07:08:46 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 07:09:09 visual_prompt]: 	Test 100/356. loss: 2.912, 0.2141 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 07:09:31 visual_prompt]: 	Test 200/356. loss: 3.131, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 07:09:52 visual_prompt]: 	Test 300/356. loss: 2.841, 0.2150 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:10:05 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2140, average loss: 2.9670
[10/01 07:10:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.38	top5: 94.99	
[10/01 07:10:06 visual_prompt]: Best epoch 96: best metric: 0.955
[10/01 07:10:06 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[10/01 07:10:16 visual_prompt]: Epoch 97 / 100: avg data time: 1.12e-01, avg batch time: 0.5611, average train loss: 0.1603
[10/01 07:10:19 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1670, average loss: 0.1521
[10/01 07:10:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.00	top5: 100.00	
[10/01 07:10:42 visual_prompt]: 	Test 100/356. loss: 3.029, 0.2137 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:11:04 visual_prompt]: 	Test 200/356. loss: 3.255, 0.2146 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 07:11:25 visual_prompt]: 	Test 300/356. loss: 2.882, 0.2146 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 07:11:39 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2140, average loss: 3.0262
[10/01 07:11:39 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.05	top5: 95.14	
[10/01 07:11:39 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[10/01 07:11:49 visual_prompt]: Epoch 98 / 100: avg data time: 1.01e-01, avg batch time: 0.5511, average train loss: 0.1489
[10/01 07:11:52 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1670, average loss: 0.1484
[10/01 07:11:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.00	top5: 100.00	
[10/01 07:12:16 visual_prompt]: 	Test 100/356. loss: 3.079, 0.2140 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 07:12:37 visual_prompt]: 	Test 200/356. loss: 3.307, 0.2146 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 07:12:59 visual_prompt]: 	Test 300/356. loss: 2.942, 0.2149 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 07:13:12 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2139, average loss: 3.0627
[10/01 07:13:12 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.99	top5: 95.21	
[10/01 07:13:12 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[10/01 07:13:22 visual_prompt]: Epoch 99 / 100: avg data time: 1.08e-01, avg batch time: 0.5580, average train loss: 0.1473
[10/01 07:13:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1668, average loss: 0.1485
[10/01 07:13:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 07:13:49 visual_prompt]: 	Test 100/356. loss: 3.097, 0.2140 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:14:10 visual_prompt]: 	Test 200/356. loss: 3.305, 0.2142 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:14:32 visual_prompt]: 	Test 300/356. loss: 2.984, 0.2150 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 07:14:45 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2138, average loss: 3.1074
[10/01 07:14:45 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.03	top5: 95.28	
[10/01 07:14:45 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[10/01 07:14:55 visual_prompt]: Epoch 100 / 100: avg data time: 9.94e-02, avg batch time: 0.5494, average train loss: 0.1342
[10/01 07:14:59 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1668, average loss: 0.1496
[10/01 07:14:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 95.50	top5: 100.00	
[10/01 07:15:22 visual_prompt]: 	Test 100/356. loss: 3.089, 0.2139 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:15:43 visual_prompt]: 	Test 200/356. loss: 3.292, 0.2148 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 07:16:05 visual_prompt]: 	Test 300/356. loss: 2.985, 0.2147 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:16:18 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2138, average loss: 3.1022
[10/01 07:16:18 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.01	top5: 95.28	
[10/01 07:16:18 visual_prompt]: Rank of current process: 0. World size: 1
[10/01 07:16:18 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[10/01 07:16:18 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dmlab', 'DATA.NUMBER_CLASSES', '6', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[10/01 07:16:18 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[10/01 07:16:18 visual_prompt]: Training with config:
[10/01 07:16:18 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dmlab/sup_vitb16_imagenet21k/prompt50/crop224/test/seed8393/lr1.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8393, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dmlab', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 6, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[10/01 07:16:18 visual_prompt]: Loading training data...
[10/01 07:16:18 visual_prompt]: Constructing vtab-dmlab dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 07:16:20 visual_prompt]: Number of images: 1000
[10/01 07:16:20 visual_prompt]: Number of classes: 6 / 6
[10/01 07:16:20 visual_prompt]: Loading validation data...
[10/01 07:16:20 visual_prompt]: Constructing vtab-dmlab dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split validation[:200], from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 07:16:21 visual_prompt]: Number of images: 200
[10/01 07:16:21 visual_prompt]: Number of classes: 6 / 6
[10/01 07:16:21 visual_prompt]: Loading test data...
[10/01 07:16:21 visual_prompt]: Constructing vtab-dmlab dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dmlab/2.0.1
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dmlab for split test, from visual_prompt_tuning/data_path/dmlab/2.0.1
[10/01 07:16:55 visual_prompt]: Number of images: 22735
[10/01 07:16:55 visual_prompt]: Number of classes: 6 / 6
[10/01 07:16:56 visual_prompt]: Constructing models...
[10/01 07:16:58 visual_prompt]: Total Parameters: 86264070	 Gradient Parameters: 465414
[10/01 07:16:58 visual_prompt]: tuned percent:0.540
[10/01 07:16:58 visual_prompt]: Device used for model: 0
[10/01 07:16:58 visual_prompt]: Setting up Evaluator...
[10/01 07:16:58 visual_prompt]: Setting up Trainer...
[10/01 07:16:58 visual_prompt]: 	Setting up the optimizer...
[10/01 07:16:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[10/01 07:17:08 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e-01, avg batch time: 0.5507, average train loss: 2.1155
[10/01 07:17:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1648, average loss: 2.0045
[10/01 07:17:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 18.00	top5: 84.50	
[10/01 07:17:35 visual_prompt]: 	Test 100/356. loss: 2.114, 0.2124 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:17:56 visual_prompt]: 	Test 200/356. loss: 2.300, 0.2138 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 07:18:18 visual_prompt]: 	Test 300/356. loss: 2.192, 0.2133 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:18:31 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2125, average loss: 2.1302
[10/01 07:18:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.89	top5: 77.83	
[10/01 07:18:31 visual_prompt]: Best epoch 1: best metric: 0.180
[10/01 07:18:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[10/01 07:18:41 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e-01, avg batch time: 0.5564, average train loss: 2.2950
[10/01 07:18:45 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1667, average loss: 1.8685
[10/01 07:18:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.50	
[10/01 07:19:08 visual_prompt]: 	Test 100/356. loss: 1.826, 0.2138 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 07:19:29 visual_prompt]: 	Test 200/356. loss: 1.763, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 07:19:50 visual_prompt]: 	Test 300/356. loss: 1.814, 0.2142 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:20:04 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2134, average loss: 1.8205
[10/01 07:20:04 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.92	top5: 88.22	
[10/01 07:20:04 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[10/01 07:20:14 visual_prompt]: Epoch 3 / 100: avg data time: 1.12e-01, avg batch time: 0.5616, average train loss: 1.8141
[10/01 07:20:18 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1669, average loss: 1.8026
[10/01 07:20:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 85.50	
[10/01 07:20:41 visual_prompt]: 	Test 100/356. loss: 1.820, 0.2139 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 07:21:02 visual_prompt]: 	Test 200/356. loss: 1.775, 0.2137 s / batch. (data: 3.03e-05)max mem: 7.81207 GB 
[10/01 07:21:24 visual_prompt]: 	Test 300/356. loss: 1.841, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:21:37 visual_prompt]: Inference (test):avg data time: 1.05e-04, avg batch time: 0.2136, average loss: 1.7986
[10/01 07:21:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 21.11	top5: 84.54	
[10/01 07:21:37 visual_prompt]: Best epoch 3: best metric: 0.250
[10/01 07:21:37 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[10/01 07:21:47 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e-01, avg batch time: 0.5569, average train loss: 1.7979
[10/01 07:21:51 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1667, average loss: 1.9009
[10/01 07:21:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 84.00	
[10/01 07:22:14 visual_prompt]: 	Test 100/356. loss: 1.860, 0.2133 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 07:22:35 visual_prompt]: 	Test 200/356. loss: 1.702, 0.2149 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 07:22:57 visual_prompt]: 	Test 300/356. loss: 1.803, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:23:10 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2138, average loss: 1.8271
[10/01 07:23:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.40	
[10/01 07:23:10 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[10/01 07:23:20 visual_prompt]: Epoch 5 / 100: avg data time: 1.03e-01, avg batch time: 0.5548, average train loss: 1.7843
[10/01 07:23:24 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1671, average loss: 1.7528
[10/01 07:23:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 19.00	top5: 88.00	
[10/01 07:23:47 visual_prompt]: 	Test 100/356. loss: 1.744, 0.2135 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:24:09 visual_prompt]: 	Test 200/356. loss: 1.637, 0.2143 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 07:24:30 visual_prompt]: 	Test 300/356. loss: 1.718, 0.2147 s / batch. (data: 3.41e-05)max mem: 7.81207 GB 
[10/01 07:24:44 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2136, average loss: 1.7074
[10/01 07:24:44 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.08	top5: 87.78	
[10/01 07:24:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[10/01 07:24:54 visual_prompt]: Epoch 6 / 100: avg data time: 1.03e-01, avg batch time: 0.5536, average train loss: 1.7983
[10/01 07:24:57 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1668, average loss: 1.7676
[10/01 07:24:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 91.50	
[10/01 07:25:21 visual_prompt]: 	Test 100/356. loss: 1.789, 0.2138 s / batch. (data: 7.15e-05)max mem: 7.81207 GB 
[10/01 07:25:42 visual_prompt]: 	Test 200/356. loss: 1.906, 0.2143 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 07:26:04 visual_prompt]: 	Test 300/356. loss: 1.759, 0.2149 s / batch. (data: 6.99e-05)max mem: 7.81207 GB 
[10/01 07:26:17 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2136, average loss: 1.7931
[10/01 07:26:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 24.46	top5: 88.66	
[10/01 07:26:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[10/01 07:26:27 visual_prompt]: Epoch 7 / 100: avg data time: 1.00e-01, avg batch time: 0.5503, average train loss: 1.6887
[10/01 07:26:31 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1671, average loss: 2.0726
[10/01 07:26:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:26:54 visual_prompt]: 	Test 100/356. loss: 2.102, 0.2137 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:27:15 visual_prompt]: 	Test 200/356. loss: 2.031, 0.2137 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 07:27:37 visual_prompt]: 	Test 300/356. loss: 2.003, 0.2144 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 07:27:50 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2136, average loss: 2.0456
[10/01 07:27:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 85.48	
[10/01 07:27:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[10/01 07:28:00 visual_prompt]: Epoch 8 / 100: avg data time: 1.13e-01, avg batch time: 0.5623, average train loss: 2.0061
[10/01 07:28:04 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1669, average loss: 1.9069
[10/01 07:28:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 30.50	top5: 84.00	
[10/01 07:28:27 visual_prompt]: 	Test 100/356. loss: 1.779, 0.2137 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:28:48 visual_prompt]: 	Test 200/356. loss: 1.716, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 07:29:10 visual_prompt]: 	Test 300/356. loss: 1.799, 0.2148 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:29:23 visual_prompt]: Inference (test):avg data time: 7.61e-05, avg batch time: 0.2137, average loss: 1.7929
[10/01 07:29:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 28.96	top5: 88.42	
[10/01 07:29:23 visual_prompt]: Best epoch 8: best metric: 0.305
[10/01 07:29:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[10/01 07:29:34 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e-01, avg batch time: 0.5564, average train loss: 1.6890
[10/01 07:29:37 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1671, average loss: 1.8450
[10/01 07:29:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 18.00	top5: 85.50	
[10/01 07:30:00 visual_prompt]: 	Test 100/356. loss: 1.784, 0.2141 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 07:30:22 visual_prompt]: 	Test 200/356. loss: 1.798, 0.2145 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:30:43 visual_prompt]: 	Test 300/356. loss: 1.764, 0.2144 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:30:57 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2138, average loss: 1.8051
[10/01 07:30:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.22	top5: 87.32	
[10/01 07:30:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[10/01 07:31:07 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e-01, avg batch time: 0.5577, average train loss: 1.9454
[10/01 07:31:10 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1665, average loss: 1.9681
[10/01 07:31:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 87.50	
[10/01 07:31:34 visual_prompt]: 	Test 100/356. loss: 1.960, 0.2128 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:31:55 visual_prompt]: 	Test 200/356. loss: 2.058, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:32:16 visual_prompt]: 	Test 300/356. loss: 2.004, 0.2135 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 07:32:30 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2129, average loss: 1.9859
[10/01 07:32:30 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 79.60	
[10/01 07:32:30 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[10/01 07:32:40 visual_prompt]: Epoch 11 / 100: avg data time: 1.04e-01, avg batch time: 0.5522, average train loss: 2.0027
[10/01 07:32:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1663, average loss: 2.1734
[10/01 07:32:44 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:33:07 visual_prompt]: 	Test 100/356. loss: 2.144, 0.2126 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:33:28 visual_prompt]: 	Test 200/356. loss: 1.881, 0.2132 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 07:33:49 visual_prompt]: 	Test 300/356. loss: 2.014, 0.2136 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 07:34:03 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2130, average loss: 2.0618
[10/01 07:34:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 88.42	
[10/01 07:34:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[10/01 07:34:13 visual_prompt]: Epoch 12 / 100: avg data time: 1.13e-01, avg batch time: 0.5605, average train loss: 1.8858
[10/01 07:34:17 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1664, average loss: 2.1733
[10/01 07:34:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 79.50	
[10/01 07:34:40 visual_prompt]: 	Test 100/356. loss: 2.034, 0.2130 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:35:01 visual_prompt]: 	Test 200/356. loss: 2.126, 0.2136 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:35:22 visual_prompt]: 	Test 300/356. loss: 2.162, 0.2135 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 07:35:36 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2130, average loss: 2.1229
[10/01 07:35:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 81.44	
[10/01 07:35:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[10/01 07:35:46 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e-01, avg batch time: 0.5542, average train loss: 1.9745
[10/01 07:35:50 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1667, average loss: 1.8698
[10/01 07:35:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.50	top5: 84.00	
[10/01 07:36:13 visual_prompt]: 	Test 100/356. loss: 1.792, 0.2130 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 07:36:34 visual_prompt]: 	Test 200/356. loss: 1.780, 0.2131 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:36:55 visual_prompt]: 	Test 300/356. loss: 1.795, 0.2137 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 07:37:09 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2130, average loss: 1.8131
[10/01 07:37:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.40	top5: 88.42	
[10/01 07:37:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[10/01 07:37:19 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e-01, avg batch time: 0.5553, average train loss: 1.8423
[10/01 07:37:23 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1666, average loss: 1.7955
[10/01 07:37:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 87.00	
[10/01 07:37:46 visual_prompt]: 	Test 100/356. loss: 1.866, 0.2131 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:38:07 visual_prompt]: 	Test 200/356. loss: 1.887, 0.2135 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 07:38:29 visual_prompt]: 	Test 300/356. loss: 1.814, 0.2146 s / batch. (data: 8.85e-05)max mem: 7.81207 GB 
[10/01 07:38:42 visual_prompt]: Inference (test):avg data time: 4.51e-05, avg batch time: 0.2131, average loss: 1.8371
[10/01 07:38:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.59	top5: 87.01	
[10/01 07:38:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[10/01 07:38:52 visual_prompt]: Epoch 15 / 100: avg data time: 1.09e-01, avg batch time: 0.5579, average train loss: 2.0213
[10/01 07:38:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1667, average loss: 2.2326
[10/01 07:38:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:39:19 visual_prompt]: 	Test 100/356. loss: 2.229, 0.2134 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:39:41 visual_prompt]: 	Test 200/356. loss: 1.973, 0.2139 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 07:40:02 visual_prompt]: 	Test 300/356. loss: 2.166, 0.2140 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 07:40:15 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2132, average loss: 2.1429
[10/01 07:40:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 88.42	
[10/01 07:40:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[10/01 07:40:26 visual_prompt]: Epoch 16 / 100: avg data time: 1.10e-01, avg batch time: 0.5604, average train loss: 1.9756
[10/01 07:40:29 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1669, average loss: 1.9268
[10/01 07:40:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 82.50	
[10/01 07:40:52 visual_prompt]: 	Test 100/356. loss: 1.916, 0.2134 s / batch. (data: 9.68e-05)max mem: 7.81207 GB 
[10/01 07:41:14 visual_prompt]: 	Test 200/356. loss: 1.971, 0.2141 s / batch. (data: 6.68e-05)max mem: 7.81207 GB 
[10/01 07:41:35 visual_prompt]: 	Test 300/356. loss: 1.886, 0.2136 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:41:48 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2130, average loss: 1.9340
[10/01 07:41:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 82.27	
[10/01 07:41:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[10/01 07:41:59 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e-01, avg batch time: 0.5587, average train loss: 1.9782
[10/01 07:42:02 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1665, average loss: 2.1455
[10/01 07:42:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.00	
[10/01 07:42:25 visual_prompt]: 	Test 100/356. loss: 2.084, 0.2134 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 07:42:47 visual_prompt]: 	Test 200/356. loss: 1.966, 0.2137 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 07:43:08 visual_prompt]: 	Test 300/356. loss: 1.922, 0.2136 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 07:43:21 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2132, average loss: 2.0671
[10/01 07:43:21 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 85.40	
[10/01 07:43:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[10/01 07:43:32 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e-01, avg batch time: 0.5596, average train loss: 1.8568
[10/01 07:43:35 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1664, average loss: 1.8087
[10/01 07:43:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:43:58 visual_prompt]: 	Test 100/356. loss: 1.854, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:44:20 visual_prompt]: 	Test 200/356. loss: 1.770, 0.2135 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:44:41 visual_prompt]: 	Test 300/356. loss: 1.805, 0.2143 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:44:54 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2132, average loss: 1.8066
[10/01 07:44:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 85.40	
[10/01 07:44:55 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[10/01 07:45:05 visual_prompt]: Epoch 19 / 100: avg data time: 1.09e-01, avg batch time: 0.5592, average train loss: 1.8393
[10/01 07:45:08 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1665, average loss: 1.8968
[10/01 07:45:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 07:45:31 visual_prompt]: 	Test 100/356. loss: 1.809, 0.2137 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 07:45:53 visual_prompt]: 	Test 200/356. loss: 1.748, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 07:46:14 visual_prompt]: 	Test 300/356. loss: 1.835, 0.2143 s / batch. (data: 3.24e-05)max mem: 7.81207 GB 
[10/01 07:46:27 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2132, average loss: 1.8249
[10/01 07:46:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[10/01 07:46:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[10/01 07:46:38 visual_prompt]: Epoch 20 / 100: avg data time: 1.11e-01, avg batch time: 0.5603, average train loss: 1.8746
[10/01 07:46:41 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.9812
[10/01 07:46:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 07:47:04 visual_prompt]: 	Test 100/356. loss: 1.883, 0.2132 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:47:26 visual_prompt]: 	Test 200/356. loss: 1.746, 0.2139 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:47:47 visual_prompt]: 	Test 300/356. loss: 1.888, 0.2139 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:48:00 visual_prompt]: Inference (test):avg data time: 4.66e-05, avg batch time: 0.2131, average loss: 1.8776
[10/01 07:48:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[10/01 07:48:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[10/01 07:48:11 visual_prompt]: Epoch 21 / 100: avg data time: 1.15e-01, avg batch time: 0.5627, average train loss: 1.8398
[10/01 07:48:14 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1666, average loss: 1.7948
[10/01 07:48:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 86.50	
[10/01 07:48:38 visual_prompt]: 	Test 100/356. loss: 1.833, 0.2130 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 07:48:59 visual_prompt]: 	Test 200/356. loss: 1.826, 0.2133 s / batch. (data: 3.12e-05)max mem: 7.81207 GB 
[10/01 07:49:20 visual_prompt]: 	Test 300/356. loss: 1.832, 0.2145 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:49:34 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2133, average loss: 1.8132
[10/01 07:49:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 81.07	
[10/01 07:49:34 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[10/01 07:49:44 visual_prompt]: Epoch 22 / 100: avg data time: 1.14e-01, avg batch time: 0.5631, average train loss: 1.8172
[10/01 07:49:48 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1664, average loss: 1.8238
[10/01 07:49:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 86.00	
[10/01 07:50:11 visual_prompt]: 	Test 100/356. loss: 1.889, 0.2132 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:50:32 visual_prompt]: 	Test 200/356. loss: 1.844, 0.2134 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 07:50:53 visual_prompt]: 	Test 300/356. loss: 1.855, 0.2138 s / batch. (data: 3.29e-05)max mem: 7.81207 GB 
[10/01 07:51:07 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2131, average loss: 1.8464
[10/01 07:51:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 84.60	
[10/01 07:51:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[10/01 07:51:17 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e-01, avg batch time: 0.5573, average train loss: 1.8332
[10/01 07:51:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1664, average loss: 1.8738
[10/01 07:51:21 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.00	
[10/01 07:51:44 visual_prompt]: 	Test 100/356. loss: 1.890, 0.2134 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 07:52:05 visual_prompt]: 	Test 200/356. loss: 1.791, 0.2135 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 07:52:27 visual_prompt]: 	Test 300/356. loss: 1.850, 0.2140 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 07:52:40 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2131, average loss: 1.8490
[10/01 07:52:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 85.40	
[10/01 07:52:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[10/01 07:52:50 visual_prompt]: Epoch 24 / 100: avg data time: 1.02e-01, avg batch time: 0.5511, average train loss: 1.8196
[10/01 07:52:54 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1664, average loss: 1.8069
[10/01 07:52:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:53:17 visual_prompt]: 	Test 100/356. loss: 1.801, 0.2133 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:53:38 visual_prompt]: 	Test 200/356. loss: 1.771, 0.2134 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:53:59 visual_prompt]: 	Test 300/356. loss: 1.770, 0.2138 s / batch. (data: 7.34e-05)max mem: 7.81207 GB 
[10/01 07:54:13 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2132, average loss: 1.7902
[10/01 07:54:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 85.40	
[10/01 07:54:13 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[10/01 07:54:23 visual_prompt]: Epoch 25 / 100: avg data time: 1.05e-01, avg batch time: 0.5536, average train loss: 1.8238
[10/01 07:54:27 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1666, average loss: 1.9464
[10/01 07:54:27 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 07:54:50 visual_prompt]: 	Test 100/356. loss: 1.864, 0.2133 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 07:55:11 visual_prompt]: 	Test 200/356. loss: 1.744, 0.2137 s / batch. (data: 7.08e-05)max mem: 7.81207 GB 
[10/01 07:55:33 visual_prompt]: 	Test 300/356. loss: 1.825, 0.2135 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 07:55:46 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2131, average loss: 1.8503
[10/01 07:55:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[10/01 07:55:46 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[10/01 07:55:56 visual_prompt]: Epoch 26 / 100: avg data time: 1.04e-01, avg batch time: 0.5531, average train loss: 1.8374
[10/01 07:56:00 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 1.8233
[10/01 07:56:00 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 84.50	
[10/01 07:56:23 visual_prompt]: 	Test 100/356. loss: 1.827, 0.2136 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:56:44 visual_prompt]: 	Test 200/356. loss: 1.915, 0.2140 s / batch. (data: 2.29e-05)max mem: 7.81207 GB 
[10/01 07:57:06 visual_prompt]: 	Test 300/356. loss: 1.870, 0.2140 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 07:57:19 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2131, average loss: 1.8495
[10/01 07:57:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 14.60	top5: 77.81	
[10/01 07:57:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[10/01 07:57:29 visual_prompt]: Epoch 27 / 100: avg data time: 1.02e-01, avg batch time: 0.5521, average train loss: 1.8400
[10/01 07:57:33 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1662, average loss: 1.8259
[10/01 07:57:33 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 82.50	
[10/01 07:57:56 visual_prompt]: 	Test 100/356. loss: 1.830, 0.2131 s / batch. (data: 6.99e-05)max mem: 7.81207 GB 
[10/01 07:58:17 visual_prompt]: 	Test 200/356. loss: 1.725, 0.2135 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 07:58:39 visual_prompt]: 	Test 300/356. loss: 1.779, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 07:58:52 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2131, average loss: 1.7949
[10/01 07:58:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 82.27	
[10/01 07:58:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[10/01 07:59:02 visual_prompt]: Epoch 28 / 100: avg data time: 1.15e-01, avg batch time: 0.5629, average train loss: 1.8147
[10/01 07:59:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1661, average loss: 1.8325
[10/01 07:59:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 07:59:29 visual_prompt]: 	Test 100/356. loss: 1.813, 0.2133 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 07:59:50 visual_prompt]: 	Test 200/356. loss: 1.779, 0.2135 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 08:00:12 visual_prompt]: 	Test 300/356. loss: 1.789, 0.2134 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 08:00:25 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2130, average loss: 1.8051
[10/01 08:00:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 85.40	
[10/01 08:00:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[10/01 08:00:35 visual_prompt]: Epoch 29 / 100: avg data time: 1.03e-01, avg batch time: 0.5518, average train loss: 1.8370
[10/01 08:00:39 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1663, average loss: 1.9049
[10/01 08:00:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 85.50	
[10/01 08:01:02 visual_prompt]: 	Test 100/356. loss: 1.898, 0.2131 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 08:01:23 visual_prompt]: 	Test 200/356. loss: 1.790, 0.2139 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 08:01:45 visual_prompt]: 	Test 300/356. loss: 1.928, 0.2139 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 08:01:58 visual_prompt]: Inference (test):avg data time: 2.89e-05, avg batch time: 0.2130, average loss: 1.8686
[10/01 08:01:58 visual_prompt]: Classification results with test_vtab-dmlab: top1: 14.60	top5: 84.67	
[10/01 08:01:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[10/01 08:02:08 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e-01, avg batch time: 0.5543, average train loss: 1.8525
[10/01 08:02:12 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1663, average loss: 1.8150
[10/01 08:02:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:02:35 visual_prompt]: 	Test 100/356. loss: 1.795, 0.2130 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:02:56 visual_prompt]: 	Test 200/356. loss: 1.721, 0.2136 s / batch. (data: 7.49e-05)max mem: 7.81207 GB 
[10/01 08:03:18 visual_prompt]: 	Test 300/356. loss: 1.772, 0.2139 s / batch. (data: 9.61e-05)max mem: 7.81207 GB 
[10/01 08:03:31 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2133, average loss: 1.7772
[10/01 08:03:31 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[10/01 08:03:31 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[10/01 08:03:41 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e-01, avg batch time: 0.5537, average train loss: 1.8071
[10/01 08:03:45 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.8218
[10/01 08:03:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.00	top5: 84.00	
[10/01 08:04:08 visual_prompt]: 	Test 100/356. loss: 1.819, 0.2131 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:04:30 visual_prompt]: 	Test 200/356. loss: 1.740, 0.2138 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 08:04:51 visual_prompt]: 	Test 300/356. loss: 1.790, 0.2139 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 08:05:04 visual_prompt]: Inference (test):avg data time: 1.19e-04, avg batch time: 0.2132, average loss: 1.7914
[10/01 08:05:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 20.00	top5: 88.42	
[10/01 08:05:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[10/01 08:05:15 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e-01, avg batch time: 0.5565, average train loss: 1.8269
[10/01 08:05:18 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1666, average loss: 1.8603
[10/01 08:05:18 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 82.50	
[10/01 08:05:41 visual_prompt]: 	Test 100/356. loss: 1.866, 0.2132 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 08:06:03 visual_prompt]: 	Test 200/356. loss: 1.807, 0.2138 s / batch. (data: 7.27e-05)max mem: 7.81207 GB 
[10/01 08:06:24 visual_prompt]: 	Test 300/356. loss: 1.813, 0.2143 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 08:06:37 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2136, average loss: 1.8445
[10/01 08:06:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 82.27	
[10/01 08:06:37 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[10/01 08:06:48 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e-01, avg batch time: 0.5562, average train loss: 1.8444
[10/01 08:06:51 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1676, average loss: 1.8707
[10/01 08:06:51 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.00	
[10/01 08:07:14 visual_prompt]: 	Test 100/356. loss: 1.807, 0.2135 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 08:07:36 visual_prompt]: 	Test 200/356. loss: 1.857, 0.2138 s / batch. (data: 7.68e-05)max mem: 7.81207 GB 
[10/01 08:07:57 visual_prompt]: 	Test 300/356. loss: 1.870, 0.2137 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 08:08:10 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2131, average loss: 1.8441
[10/01 08:08:11 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 88.42	
[10/01 08:08:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[10/01 08:08:21 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e-01, avg batch time: 0.5562, average train loss: 1.8505
[10/01 08:08:24 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1665, average loss: 1.7979
[10/01 08:08:24 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 85.50	
[10/01 08:08:47 visual_prompt]: 	Test 100/356. loss: 1.823, 0.2135 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:09:09 visual_prompt]: 	Test 200/356. loss: 1.747, 0.2143 s / batch. (data: 3.60e-05)max mem: 7.81207 GB 
[10/01 08:09:30 visual_prompt]: 	Test 300/356. loss: 1.782, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 08:09:43 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2131, average loss: 1.7894
[10/01 08:09:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 21.36	top5: 84.67	
[10/01 08:09:43 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[10/01 08:09:54 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e-01, avg batch time: 0.5556, average train loss: 1.8114
[10/01 08:09:57 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1667, average loss: 1.8043
[10/01 08:09:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.50	
[10/01 08:10:20 visual_prompt]: 	Test 100/356. loss: 1.860, 0.2129 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 08:10:42 visual_prompt]: 	Test 200/356. loss: 1.892, 0.2133 s / batch. (data: 2.31e-05)max mem: 7.81207 GB 
[10/01 08:11:03 visual_prompt]: 	Test 300/356. loss: 1.857, 0.2139 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:11:16 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2132, average loss: 1.8464
[10/01 08:11:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 77.81	
[10/01 08:11:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[10/01 08:11:27 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e-01, avg batch time: 0.5589, average train loss: 1.8095
[10/01 08:11:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1667, average loss: 1.8118
[10/01 08:11:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:11:53 visual_prompt]: 	Test 100/356. loss: 1.791, 0.2131 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:12:15 visual_prompt]: 	Test 200/356. loss: 1.741, 0.2134 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 08:12:36 visual_prompt]: 	Test 300/356. loss: 1.757, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 08:12:50 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2133, average loss: 1.7808
[10/01 08:12:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.20	top5: 88.42	
[10/01 08:12:50 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[10/01 08:13:00 visual_prompt]: Epoch 37 / 100: avg data time: 9.79e-02, avg batch time: 0.5472, average train loss: 1.8140
[10/01 08:13:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1666, average loss: 1.8095
[10/01 08:13:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 84.50	
[10/01 08:13:26 visual_prompt]: 	Test 100/356. loss: 1.858, 0.2129 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 08:13:48 visual_prompt]: 	Test 200/356. loss: 1.893, 0.2138 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 08:14:09 visual_prompt]: 	Test 300/356. loss: 1.868, 0.2136 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:14:23 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2132, average loss: 1.8506
[10/01 08:14:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 11.58	top5: 77.81	
[10/01 08:14:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[10/01 08:14:33 visual_prompt]: Epoch 38 / 100: avg data time: 1.01e-01, avg batch time: 0.5499, average train loss: 1.8309
[10/01 08:14:36 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1671, average loss: 1.8034
[10/01 08:14:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.50	
[10/01 08:14:59 visual_prompt]: 	Test 100/356. loss: 1.831, 0.2134 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:15:21 visual_prompt]: 	Test 200/356. loss: 1.896, 0.2146 s / batch. (data: 3.08e-05)max mem: 7.81207 GB 
[10/01 08:15:42 visual_prompt]: 	Test 300/356. loss: 1.842, 0.2144 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:15:56 visual_prompt]: Inference (test):avg data time: 5.70e-05, avg batch time: 0.2136, average loss: 1.8382
[10/01 08:15:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 77.81	
[10/01 08:15:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[10/01 08:16:06 visual_prompt]: Epoch 39 / 100: avg data time: 1.13e-01, avg batch time: 0.5624, average train loss: 1.8182
[10/01 08:16:10 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1667, average loss: 1.8894
[10/01 08:16:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 84.00	
[10/01 08:16:33 visual_prompt]: 	Test 100/356. loss: 1.835, 0.2136 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:16:54 visual_prompt]: 	Test 200/356. loss: 1.838, 0.2136 s / batch. (data: 3.15e-05)max mem: 7.81207 GB 
[10/01 08:17:16 visual_prompt]: 	Test 300/356. loss: 1.857, 0.2139 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 08:17:29 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2132, average loss: 1.8550
[10/01 08:17:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 85.40	
[10/01 08:17:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[10/01 08:17:39 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e-01, avg batch time: 0.5557, average train loss: 1.8423
[10/01 08:17:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1667, average loss: 1.8325
[10/01 08:17:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.00	top5: 84.00	
[10/01 08:18:06 visual_prompt]: 	Test 100/356. loss: 1.826, 0.2137 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:18:27 visual_prompt]: 	Test 200/356. loss: 1.716, 0.2140 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 08:18:49 visual_prompt]: 	Test 300/356. loss: 1.767, 0.2141 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 08:19:02 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2135, average loss: 1.7901
[10/01 08:19:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.33	top5: 85.40	
[10/01 08:19:02 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[10/01 08:19:12 visual_prompt]: Epoch 41 / 100: avg data time: 1.01e-01, avg batch time: 0.5519, average train loss: 1.7865
[10/01 08:19:16 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1671, average loss: 1.8699
[10/01 08:19:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:19:39 visual_prompt]: 	Test 100/356. loss: 1.832, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 08:20:00 visual_prompt]: 	Test 200/356. loss: 1.666, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:20:22 visual_prompt]: 	Test 300/356. loss: 1.750, 0.2145 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 08:20:35 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2135, average loss: 1.7943
[10/01 08:20:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.40	
[10/01 08:20:35 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[10/01 08:20:46 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e-01, avg batch time: 0.5556, average train loss: 1.8090
[10/01 08:20:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1669, average loss: 1.8284
[10/01 08:20:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 83.00	
[10/01 08:21:12 visual_prompt]: 	Test 100/356. loss: 1.834, 0.2132 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:21:34 visual_prompt]: 	Test 200/356. loss: 1.761, 0.2140 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 08:21:55 visual_prompt]: 	Test 300/356. loss: 1.826, 0.2139 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:22:09 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2135, average loss: 1.8070
[10/01 08:22:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 87.57	
[10/01 08:22:09 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[10/01 08:22:19 visual_prompt]: Epoch 43 / 100: avg data time: 1.11e-01, avg batch time: 0.5607, average train loss: 1.7929
[10/01 08:22:23 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1667, average loss: 1.8875
[10/01 08:22:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.00	top5: 84.00	
[10/01 08:22:46 visual_prompt]: 	Test 100/356. loss: 1.846, 0.2131 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 08:23:07 visual_prompt]: 	Test 200/356. loss: 1.870, 0.2141 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:23:29 visual_prompt]: 	Test 300/356. loss: 1.827, 0.2141 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 08:23:42 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2134, average loss: 1.8628
[10/01 08:23:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.31	top5: 85.40	
[10/01 08:23:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[10/01 08:23:52 visual_prompt]: Epoch 44 / 100: avg data time: 1.12e-01, avg batch time: 0.5624, average train loss: 1.8182
[10/01 08:23:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1664, average loss: 1.8262
[10/01 08:23:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 85.50	
[10/01 08:24:19 visual_prompt]: 	Test 100/356. loss: 1.860, 0.2135 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 08:24:40 visual_prompt]: 	Test 200/356. loss: 1.791, 0.2137 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 08:25:02 visual_prompt]: 	Test 300/356. loss: 1.849, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 08:25:15 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2131, average loss: 1.8223
[10/01 08:25:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 84.67	
[10/01 08:25:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[10/01 08:25:25 visual_prompt]: Epoch 45 / 100: avg data time: 9.74e-02, avg batch time: 0.5467, average train loss: 1.8075
[10/01 08:25:29 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1661, average loss: 1.8162
[10/01 08:25:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 08:25:52 visual_prompt]: 	Test 100/356. loss: 1.830, 0.2135 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:26:13 visual_prompt]: 	Test 200/356. loss: 1.763, 0.2137 s / batch. (data: 7.13e-05)max mem: 7.81207 GB 
[10/01 08:26:35 visual_prompt]: 	Test 300/356. loss: 1.789, 0.2140 s / batch. (data: 5.94e-05)max mem: 7.81207 GB 
[10/01 08:26:48 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2130, average loss: 1.7989
[10/01 08:26:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 85.37	
[10/01 08:26:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[10/01 08:26:58 visual_prompt]: Epoch 46 / 100: avg data time: 1.03e-01, avg batch time: 0.5532, average train loss: 1.8065
[10/01 08:27:02 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1660, average loss: 1.8087
[10/01 08:27:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 16.00	top5: 84.00	
[10/01 08:27:25 visual_prompt]: 	Test 100/356. loss: 1.787, 0.2134 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 08:27:46 visual_prompt]: 	Test 200/356. loss: 1.791, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 08:28:08 visual_prompt]: 	Test 300/356. loss: 1.790, 0.2140 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:28:21 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2130, average loss: 1.7945
[10/01 08:28:21 visual_prompt]: Classification results with test_vtab-dmlab: top1: 14.60	top5: 88.42	
[10/01 08:28:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[10/01 08:28:31 visual_prompt]: Epoch 47 / 100: avg data time: 1.10e-01, avg batch time: 0.5601, average train loss: 1.8091
[10/01 08:28:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1663, average loss: 1.8151
[10/01 08:28:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.00	
[10/01 08:28:58 visual_prompt]: 	Test 100/356. loss: 1.769, 0.2130 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:29:19 visual_prompt]: 	Test 200/356. loss: 1.783, 0.2134 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 08:29:41 visual_prompt]: 	Test 300/356. loss: 1.783, 0.2137 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 08:29:54 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2131, average loss: 1.7907
[10/01 08:29:54 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.33	top5: 88.42	
[10/01 08:29:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[10/01 08:30:04 visual_prompt]: Epoch 48 / 100: avg data time: 1.08e-01, avg batch time: 0.5558, average train loss: 1.8064
[10/01 08:30:08 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1662, average loss: 1.8319
[10/01 08:30:08 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:30:31 visual_prompt]: 	Test 100/356. loss: 1.784, 0.2133 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 08:30:52 visual_prompt]: 	Test 200/356. loss: 1.762, 0.2136 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:31:14 visual_prompt]: 	Test 300/356. loss: 1.784, 0.2140 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 08:31:27 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2132, average loss: 1.7951
[10/01 08:31:27 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 88.42	
[10/01 08:31:27 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[10/01 08:31:37 visual_prompt]: Epoch 49 / 100: avg data time: 1.08e-01, avg batch time: 0.5565, average train loss: 1.7944
[10/01 08:31:41 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1665, average loss: 1.8012
[10/01 08:31:41 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.50	
[10/01 08:32:04 visual_prompt]: 	Test 100/356. loss: 1.831, 0.2134 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 08:32:26 visual_prompt]: 	Test 200/356. loss: 1.845, 0.2138 s / batch. (data: 8.39e-05)max mem: 7.81207 GB 
[10/01 08:32:47 visual_prompt]: 	Test 300/356. loss: 1.811, 0.2140 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:33:00 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2133, average loss: 1.8202
[10/01 08:33:00 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 77.81	
[10/01 08:33:00 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[10/01 08:33:11 visual_prompt]: Epoch 50 / 100: avg data time: 1.14e-01, avg batch time: 0.5628, average train loss: 1.8155
[10/01 08:33:14 visual_prompt]: Inference (val):avg data time: 4.60e-05, avg batch time: 0.1663, average loss: 1.8293
[10/01 08:33:14 visual_prompt]: Classification results with val_vtab-dmlab: top1: 17.50	top5: 79.50	
[10/01 08:33:37 visual_prompt]: 	Test 100/356. loss: 1.780, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:33:59 visual_prompt]: 	Test 200/356. loss: 1.780, 0.2135 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:34:20 visual_prompt]: 	Test 300/356. loss: 1.797, 0.2138 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 08:34:34 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2132, average loss: 1.8003
[10/01 08:34:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 17.73	top5: 81.44	
[10/01 08:34:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[10/01 08:34:44 visual_prompt]: Epoch 51 / 100: avg data time: 9.84e-02, avg batch time: 0.5496, average train loss: 1.7915
[10/01 08:34:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1664, average loss: 1.7948
[10/01 08:34:47 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:35:10 visual_prompt]: 	Test 100/356. loss: 1.796, 0.2137 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 08:35:32 visual_prompt]: 	Test 200/356. loss: 1.760, 0.2135 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 08:35:53 visual_prompt]: 	Test 300/356. loss: 1.775, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 08:36:06 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2132, average loss: 1.7842
[10/01 08:36:06 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.40	
[10/01 08:36:06 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[10/01 08:36:17 visual_prompt]: Epoch 52 / 100: avg data time: 1.13e-01, avg batch time: 0.5626, average train loss: 1.7898
[10/01 08:36:20 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1662, average loss: 1.8414
[10/01 08:36:20 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 82.50	
[10/01 08:36:43 visual_prompt]: 	Test 100/356. loss: 1.832, 0.2140 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:37:05 visual_prompt]: 	Test 200/356. loss: 1.776, 0.2136 s / batch. (data: 2.48e-05)max mem: 7.81207 GB 
[10/01 08:37:26 visual_prompt]: 	Test 300/356. loss: 1.778, 0.2136 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 08:37:39 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2132, average loss: 1.8134
[10/01 08:37:40 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 82.27	
[10/01 08:37:40 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[10/01 08:37:50 visual_prompt]: Epoch 53 / 100: avg data time: 1.12e-01, avg batch time: 0.5602, average train loss: 1.8145
[10/01 08:37:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1661, average loss: 1.8661
[10/01 08:37:53 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:38:16 visual_prompt]: 	Test 100/356. loss: 1.871, 0.2132 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 08:38:38 visual_prompt]: 	Test 200/356. loss: 1.709, 0.2134 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:38:59 visual_prompt]: 	Test 300/356. loss: 1.784, 0.2137 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 08:39:12 visual_prompt]: Inference (test):avg data time: 8.13e-05, avg batch time: 0.2132, average loss: 1.8154
[10/01 08:39:13 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.40	
[10/01 08:39:13 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[10/01 08:39:23 visual_prompt]: Epoch 54 / 100: avg data time: 1.15e-01, avg batch time: 0.5642, average train loss: 1.8026
[10/01 08:39:26 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1660, average loss: 1.8349
[10/01 08:39:26 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.00	
[10/01 08:39:49 visual_prompt]: 	Test 100/356. loss: 1.843, 0.2130 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 08:40:11 visual_prompt]: 	Test 200/356. loss: 1.717, 0.2136 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 08:40:32 visual_prompt]: 	Test 300/356. loss: 1.755, 0.2141 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:40:46 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2134, average loss: 1.7987
[10/01 08:40:46 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.40	
[10/01 08:40:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[10/01 08:40:56 visual_prompt]: Epoch 55 / 100: avg data time: 9.98e-02, avg batch time: 0.5498, average train loss: 1.7778
[10/01 08:40:59 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1690, average loss: 1.7693
[10/01 08:40:59 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.00	top5: 88.50	
[10/01 08:41:22 visual_prompt]: 	Test 100/356. loss: 1.718, 0.2139 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 08:41:44 visual_prompt]: 	Test 200/356. loss: 1.700, 0.2140 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:42:05 visual_prompt]: 	Test 300/356. loss: 1.682, 0.2144 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 08:42:19 visual_prompt]: Inference (test):avg data time: 4.17e-05, avg batch time: 0.2136, average loss: 1.7320
[10/01 08:42:19 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.33	top5: 90.04	
[10/01 08:42:19 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[10/01 08:42:29 visual_prompt]: Epoch 56 / 100: avg data time: 1.03e-01, avg batch time: 0.5511, average train loss: 1.7810
[10/01 08:42:32 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1668, average loss: 1.7747
[10/01 08:42:32 visual_prompt]: Classification results with val_vtab-dmlab: top1: 23.00	top5: 84.00	
[10/01 08:42:56 visual_prompt]: 	Test 100/356. loss: 1.774, 0.2135 s / batch. (data: 6.87e-05)max mem: 7.81207 GB 
[10/01 08:43:17 visual_prompt]: 	Test 200/356. loss: 1.740, 0.2138 s / batch. (data: 2.96e-05)max mem: 7.81207 GB 
[10/01 08:43:39 visual_prompt]: 	Test 300/356. loss: 1.753, 0.2132 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:43:52 visual_prompt]: Inference (test):avg data time: 7.04e-05, avg batch time: 0.2135, average loss: 1.7617
[10/01 08:43:52 visual_prompt]: Classification results with test_vtab-dmlab: top1: 20.06	top5: 88.42	
[10/01 08:43:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[10/01 08:44:02 visual_prompt]: Epoch 57 / 100: avg data time: 1.11e-01, avg batch time: 0.5608, average train loss: 1.7928
[10/01 08:44:06 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1664, average loss: 1.8790
[10/01 08:44:06 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 08:44:29 visual_prompt]: 	Test 100/356. loss: 1.856, 0.2132 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:44:50 visual_prompt]: 	Test 200/356. loss: 1.844, 0.2145 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:45:12 visual_prompt]: 	Test 300/356. loss: 1.821, 0.2146 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 08:45:25 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2136, average loss: 1.8524
[10/01 08:45:25 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.56	top5: 88.42	
[10/01 08:45:25 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[10/01 08:45:35 visual_prompt]: Epoch 58 / 100: avg data time: 9.96e-02, avg batch time: 0.5519, average train loss: 1.7830
[10/01 08:45:39 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.8270
[10/01 08:45:39 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.50	top5: 83.50	
[10/01 08:46:02 visual_prompt]: 	Test 100/356. loss: 1.796, 0.2138 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 08:46:24 visual_prompt]: 	Test 200/356. loss: 1.721, 0.2142 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 08:46:45 visual_prompt]: 	Test 300/356. loss: 1.731, 0.2150 s / batch. (data: 1.31e-04)max mem: 7.81207 GB 
[10/01 08:46:58 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2137, average loss: 1.7790
[10/01 08:46:58 visual_prompt]: Classification results with test_vtab-dmlab: top1: 23.92	top5: 88.56	
[10/01 08:46:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[10/01 08:47:09 visual_prompt]: Epoch 59 / 100: avg data time: 1.05e-01, avg batch time: 0.5540, average train loss: 1.7729
[10/01 08:47:12 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1664, average loss: 1.8260
[10/01 08:47:12 visual_prompt]: Classification results with val_vtab-dmlab: top1: 20.50	top5: 84.00	
[10/01 08:47:35 visual_prompt]: 	Test 100/356. loss: 1.786, 0.2133 s / batch. (data: 8.54e-05)max mem: 7.81207 GB 
[10/01 08:47:57 visual_prompt]: 	Test 200/356. loss: 1.760, 0.2140 s / batch. (data: 3.00e-05)max mem: 7.81207 GB 
[10/01 08:48:18 visual_prompt]: 	Test 300/356. loss: 1.782, 0.2142 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:48:31 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2133, average loss: 1.7881
[10/01 08:48:32 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.68	top5: 88.42	
[10/01 08:48:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[10/01 08:48:42 visual_prompt]: Epoch 60 / 100: avg data time: 1.10e-01, avg batch time: 0.5588, average train loss: 1.8301
[10/01 08:48:45 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1664, average loss: 1.8152
[10/01 08:48:45 visual_prompt]: Classification results with val_vtab-dmlab: top1: 21.00	top5: 84.00	
[10/01 08:49:08 visual_prompt]: 	Test 100/356. loss: 1.801, 0.2147 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 08:49:30 visual_prompt]: 	Test 200/356. loss: 1.720, 0.2142 s / batch. (data: 2.41e-05)max mem: 7.81207 GB 
[10/01 08:49:51 visual_prompt]: 	Test 300/356. loss: 1.762, 0.2140 s / batch. (data: 7.82e-05)max mem: 7.81207 GB 
[10/01 08:50:04 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2134, average loss: 1.7767
[10/01 08:50:05 visual_prompt]: Classification results with test_vtab-dmlab: top1: 19.47	top5: 88.42	
[10/01 08:50:05 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[10/01 08:50:15 visual_prompt]: Epoch 61 / 100: avg data time: 1.14e-01, avg batch time: 0.5623, average train loss: 1.7987
[10/01 08:50:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1665, average loss: 1.7831
[10/01 08:50:19 visual_prompt]: Classification results with val_vtab-dmlab: top1: 19.00	top5: 84.50	
[10/01 08:50:42 visual_prompt]: 	Test 100/356. loss: 1.757, 0.2133 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 08:51:03 visual_prompt]: 	Test 200/356. loss: 1.738, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 08:51:25 visual_prompt]: 	Test 300/356. loss: 1.713, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 08:51:38 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2133, average loss: 1.7598
[10/01 08:51:38 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.73	top5: 85.93	
[10/01 08:51:38 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[10/01 08:51:48 visual_prompt]: Epoch 62 / 100: avg data time: 1.06e-01, avg batch time: 0.5548, average train loss: 1.7958
[10/01 08:51:52 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1666, average loss: 1.8532
[10/01 08:51:52 visual_prompt]: Classification results with val_vtab-dmlab: top1: 15.50	top5: 84.50	
[10/01 08:52:15 visual_prompt]: 	Test 100/356. loss: 1.819, 0.2137 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 08:52:36 visual_prompt]: 	Test 200/356. loss: 1.724, 0.2135 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 08:52:58 visual_prompt]: 	Test 300/356. loss: 1.803, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:53:11 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2135, average loss: 1.8049
[10/01 08:53:11 visual_prompt]: Classification results with test_vtab-dmlab: top1: 22.19	top5: 85.57	
[10/01 08:53:11 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[10/01 08:53:21 visual_prompt]: Epoch 63 / 100: avg data time: 1.05e-01, avg batch time: 0.5559, average train loss: 1.7800
[10/01 08:53:25 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1668, average loss: 1.7484
[10/01 08:53:25 visual_prompt]: Classification results with val_vtab-dmlab: top1: 18.50	top5: 86.00	
[10/01 08:53:48 visual_prompt]: 	Test 100/356. loss: 1.742, 0.2133 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 08:54:09 visual_prompt]: 	Test 200/356. loss: 1.713, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 08:54:31 visual_prompt]: 	Test 300/356. loss: 1.717, 0.2141 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:54:44 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2136, average loss: 1.7303
[10/01 08:54:44 visual_prompt]: Classification results with test_vtab-dmlab: top1: 18.48	top5: 87.52	
[10/01 08:54:44 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[10/01 08:54:54 visual_prompt]: Epoch 64 / 100: avg data time: 1.11e-01, avg batch time: 0.5604, average train loss: 1.7087
[10/01 08:54:58 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1663, average loss: 1.9376
[10/01 08:54:58 visual_prompt]: Classification results with val_vtab-dmlab: top1: 14.50	top5: 84.50	
[10/01 08:55:21 visual_prompt]: 	Test 100/356. loss: 1.988, 0.2138 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 08:55:42 visual_prompt]: 	Test 200/356. loss: 2.171, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 08:56:04 visual_prompt]: 	Test 300/356. loss: 1.977, 0.2141 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 08:56:17 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2134, average loss: 2.0138
[10/01 08:56:17 visual_prompt]: Classification results with test_vtab-dmlab: top1: 15.34	top5: 77.81	
[10/01 08:56:17 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[10/01 08:56:27 visual_prompt]: Epoch 65 / 100: avg data time: 9.74e-02, avg batch time: 0.5461, average train loss: 1.7595
[10/01 08:56:31 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1667, average loss: 1.7210
[10/01 08:56:31 visual_prompt]: Classification results with val_vtab-dmlab: top1: 26.00	top5: 92.00	
[10/01 08:56:54 visual_prompt]: 	Test 100/356. loss: 1.742, 0.2136 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 08:57:15 visual_prompt]: 	Test 200/356. loss: 1.743, 0.2140 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 08:57:37 visual_prompt]: 	Test 300/356. loss: 1.653, 0.2142 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 08:57:50 visual_prompt]: Inference (test):avg data time: 5.22e-05, avg batch time: 0.2136, average loss: 1.7080
[10/01 08:57:50 visual_prompt]: Classification results with test_vtab-dmlab: top1: 25.79	top5: 91.75	
[10/01 08:57:50 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[10/01 08:58:01 visual_prompt]: Epoch 66 / 100: avg data time: 1.03e-01, avg batch time: 0.5532, average train loss: 1.6360
[10/01 08:58:04 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1664, average loss: 1.7742
[10/01 08:58:04 visual_prompt]: Classification results with val_vtab-dmlab: top1: 22.50	top5: 90.50	
[10/01 08:58:27 visual_prompt]: 	Test 100/356. loss: 1.709, 0.2138 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 08:58:49 visual_prompt]: 	Test 200/356. loss: 1.608, 0.2138 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 08:59:10 visual_prompt]: 	Test 300/356. loss: 1.590, 0.2146 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 08:59:24 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2135, average loss: 1.7126
[10/01 08:59:24 visual_prompt]: Classification results with test_vtab-dmlab: top1: 27.75	top5: 91.77	
[10/01 08:59:24 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.31269670329204396
[10/01 08:59:34 visual_prompt]: Epoch 67 / 100: avg data time: 9.95e-02, avg batch time: 0.5486, average train loss: 1.6029
[10/01 08:59:37 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1664, average loss: 1.6248
[10/01 08:59:37 visual_prompt]: Classification results with val_vtab-dmlab: top1: 29.00	top5: 93.50	
[10/01 09:00:00 visual_prompt]: 	Test 100/356. loss: 1.700, 0.2134 s / batch. (data: 2.38e-05)max mem: 7.81207 GB 
[10/01 09:00:22 visual_prompt]: 	Test 200/356. loss: 1.727, 0.2142 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 09:00:43 visual_prompt]: 	Test 300/356. loss: 1.503, 0.2144 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 09:00:56 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2134, average loss: 1.5800
[10/01 09:00:57 visual_prompt]: Classification results with test_vtab-dmlab: top1: 32.67	top5: 92.34	
[10/01 09:00:57 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.2966316784621
[10/01 09:01:07 visual_prompt]: Epoch 68 / 100: avg data time: 1.10e-01, avg batch time: 0.5586, average train loss: 1.5309
[10/01 09:01:10 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1665, average loss: 1.6709
[10/01 09:01:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.50	top5: 94.50	
[10/01 09:01:33 visual_prompt]: 	Test 100/356. loss: 1.589, 0.2136 s / batch. (data: 7.87e-05)max mem: 7.81207 GB 
[10/01 09:01:55 visual_prompt]: 	Test 200/356. loss: 1.457, 0.2138 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:02:16 visual_prompt]: 	Test 300/356. loss: 1.535, 0.2141 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:02:29 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2135, average loss: 1.6185
[10/01 09:02:30 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.59	top5: 94.32	
[10/01 09:02:30 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.28081442660546124
[10/01 09:02:40 visual_prompt]: Epoch 69 / 100: avg data time: 1.03e-01, avg batch time: 0.5526, average train loss: 1.4967
[10/01 09:02:43 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1668, average loss: 1.5064
[10/01 09:02:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 95.00	
[10/01 09:03:06 visual_prompt]: 	Test 100/356. loss: 1.459, 0.2132 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 09:03:28 visual_prompt]: 	Test 200/356. loss: 1.453, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:03:49 visual_prompt]: 	Test 300/356. loss: 1.410, 0.2144 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:04:03 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2136, average loss: 1.4662
[10/01 09:04:03 visual_prompt]: Classification results with test_vtab-dmlab: top1: 35.25	top5: 96.72	
[10/01 09:04:03 visual_prompt]: Best epoch 69: best metric: 0.325
[10/01 09:04:03 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.26526421860705474
[10/01 09:04:13 visual_prompt]: Epoch 70 / 100: avg data time: 1.22e-01, avg batch time: 0.5717, average train loss: 1.4424
[10/01 09:04:17 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1666, average loss: 1.5115
[10/01 09:04:17 visual_prompt]: Classification results with val_vtab-dmlab: top1: 31.50	top5: 96.00	
[10/01 09:04:40 visual_prompt]: 	Test 100/356. loss: 1.399, 0.2138 s / batch. (data: 6.72e-05)max mem: 7.81207 GB 
[10/01 09:05:02 visual_prompt]: 	Test 200/356. loss: 1.499, 0.2140 s / batch. (data: 8.82e-05)max mem: 7.81207 GB 
[10/01 09:05:23 visual_prompt]: 	Test 300/356. loss: 1.461, 0.2147 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 09:05:36 visual_prompt]: Inference (test):avg data time: 4.48e-05, avg batch time: 0.2136, average loss: 1.5203
[10/01 09:05:37 visual_prompt]: Classification results with test_vtab-dmlab: top1: 29.70	top5: 96.47	
[10/01 09:05:37 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.2500000000000001
[10/01 09:05:47 visual_prompt]: Epoch 71 / 100: avg data time: 1.03e-01, avg batch time: 0.5535, average train loss: 1.4266
[10/01 09:05:50 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1667, average loss: 1.4295
[10/01 09:05:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 28.50	top5: 98.00	
[10/01 09:06:13 visual_prompt]: 	Test 100/356. loss: 1.429, 0.2136 s / batch. (data: 2.43e-05)max mem: 7.81207 GB 
[10/01 09:06:35 visual_prompt]: 	Test 200/356. loss: 1.452, 0.2141 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 09:06:56 visual_prompt]: 	Test 300/356. loss: 1.430, 0.2143 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:07:10 visual_prompt]: Inference (test):avg data time: 1.84e-04, avg batch time: 0.2138, average loss: 1.4989
[10/01 09:07:10 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.00	top5: 96.62	
[10/01 09:07:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.2350403678833976
[10/01 09:07:20 visual_prompt]: Epoch 72 / 100: avg data time: 1.10e-01, avg batch time: 0.5598, average train loss: 1.4261
[10/01 09:07:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 1.3514
[10/01 09:07:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 36.00	top5: 98.00	
[10/01 09:07:46 visual_prompt]: 	Test 100/356. loss: 1.365, 0.2141 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 09:08:08 visual_prompt]: 	Test 200/356. loss: 1.383, 0.2143 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 09:08:29 visual_prompt]: 	Test 300/356. loss: 1.301, 0.2143 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:08:43 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2136, average loss: 1.3923
[10/01 09:08:43 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.72	top5: 96.77	
[10/01 09:08:43 visual_prompt]: Best epoch 72: best metric: 0.360
[10/01 09:08:43 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.22040354826462666
[10/01 09:08:53 visual_prompt]: Epoch 73 / 100: avg data time: 1.08e-01, avg batch time: 0.5583, average train loss: 1.4058
[10/01 09:08:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1677, average loss: 1.6210
[10/01 09:08:57 visual_prompt]: Classification results with val_vtab-dmlab: top1: 25.50	top5: 96.50	
[10/01 09:09:20 visual_prompt]: 	Test 100/356. loss: 1.537, 0.2138 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 09:09:41 visual_prompt]: 	Test 200/356. loss: 1.932, 0.2143 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 09:10:03 visual_prompt]: 	Test 300/356. loss: 1.500, 0.2143 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 09:10:16 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2136, average loss: 1.6537
[10/01 09:10:16 visual_prompt]: Classification results with test_vtab-dmlab: top1: 26.78	top5: 93.60	
[10/01 09:10:16 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.2061073738537635
[10/01 09:10:26 visual_prompt]: Epoch 74 / 100: avg data time: 1.11e-01, avg batch time: 0.5603, average train loss: 1.4408
[10/01 09:10:30 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1663, average loss: 1.5138
[10/01 09:10:30 visual_prompt]: Classification results with val_vtab-dmlab: top1: 32.50	top5: 96.00	
[10/01 09:10:53 visual_prompt]: 	Test 100/356. loss: 1.520, 0.2140 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:11:15 visual_prompt]: 	Test 200/356. loss: 1.694, 0.2142 s / batch. (data: 4.74e-05)max mem: 7.81207 GB 
[10/01 09:11:36 visual_prompt]: 	Test 300/356. loss: 1.424, 0.2145 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:11:49 visual_prompt]: Inference (test):avg data time: 6.21e-05, avg batch time: 0.2135, average loss: 1.5651
[10/01 09:11:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 31.50	top5: 94.46	
[10/01 09:11:49 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.19216926233717085
[10/01 09:12:00 visual_prompt]: Epoch 75 / 100: avg data time: 1.11e-01, avg batch time: 0.5611, average train loss: 1.4184
[10/01 09:12:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1666, average loss: 1.3194
[10/01 09:12:03 visual_prompt]: Classification results with val_vtab-dmlab: top1: 39.00	top5: 99.00	
[10/01 09:12:26 visual_prompt]: 	Test 100/356. loss: 1.362, 0.2138 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 09:12:48 visual_prompt]: 	Test 200/356. loss: 1.506, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:13:09 visual_prompt]: 	Test 300/356. loss: 1.460, 0.2146 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:13:23 visual_prompt]: Inference (test):avg data time: 5.15e-05, avg batch time: 0.2136, average loss: 1.4179
[10/01 09:13:23 visual_prompt]: Classification results with test_vtab-dmlab: top1: 33.51	top5: 96.87	
[10/01 09:13:23 visual_prompt]: Best epoch 75: best metric: 0.390
[10/01 09:13:23 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.17860619515673032
[10/01 09:13:33 visual_prompt]: Epoch 76 / 100: avg data time: 1.02e-01, avg batch time: 0.5521, average train loss: 1.4060
[10/01 09:13:36 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1665, average loss: 1.4190
[10/01 09:13:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.00	top5: 97.50	
[10/01 09:13:59 visual_prompt]: 	Test 100/356. loss: 1.386, 0.2138 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 09:14:21 visual_prompt]: 	Test 200/356. loss: 1.658, 0.2139 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 09:14:42 visual_prompt]: 	Test 300/356. loss: 1.564, 0.2142 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:14:56 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2135, average loss: 1.4894
[10/01 09:14:56 visual_prompt]: Classification results with test_vtab-dmlab: top1: 34.80	top5: 96.10	
[10/01 09:14:56 visual_prompt]: Best epoch 76: best metric: 0.400
[10/01 09:14:56 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.16543469682057105
[10/01 09:15:06 visual_prompt]: Epoch 77 / 100: avg data time: 1.13e-01, avg batch time: 0.5631, average train loss: 1.3248
[10/01 09:15:10 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1665, average loss: 1.2960
[10/01 09:15:10 visual_prompt]: Classification results with val_vtab-dmlab: top1: 37.50	top5: 99.50	
[10/01 09:15:33 visual_prompt]: 	Test 100/356. loss: 1.256, 0.2138 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:15:54 visual_prompt]: 	Test 200/356. loss: 1.432, 0.2141 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 09:16:16 visual_prompt]: 	Test 300/356. loss: 1.340, 0.2148 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:16:29 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2137, average loss: 1.3692
[10/01 09:16:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 38.63	top5: 97.09	
[10/01 09:16:29 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.15267081477050132
[10/01 09:16:39 visual_prompt]: Epoch 78 / 100: avg data time: 9.89e-02, avg batch time: 0.5497, average train loss: 1.3256
[10/01 09:16:43 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1667, average loss: 1.2961
[10/01 09:16:43 visual_prompt]: Classification results with val_vtab-dmlab: top1: 38.50	top5: 99.00	
[10/01 09:17:06 visual_prompt]: 	Test 100/356. loss: 1.328, 0.2135 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:17:27 visual_prompt]: 	Test 200/356. loss: 1.420, 0.2139 s / batch. (data: 2.46e-05)max mem: 7.81207 GB 
[10/01 09:17:49 visual_prompt]: 	Test 300/356. loss: 1.324, 0.2145 s / batch. (data: 6.68e-05)max mem: 7.81207 GB 
[10/01 09:18:02 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2135, average loss: 1.4179
[10/01 09:18:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.12	top5: 97.35	
[10/01 09:18:02 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.14033009983067452
[10/01 09:18:13 visual_prompt]: Epoch 79 / 100: avg data time: 1.13e-01, avg batch time: 0.5623, average train loss: 1.2849
[10/01 09:18:16 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1666, average loss: 1.2412
[10/01 09:18:16 visual_prompt]: Classification results with val_vtab-dmlab: top1: 41.50	top5: 98.50	
[10/01 09:18:39 visual_prompt]: 	Test 100/356. loss: 1.250, 0.2132 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 09:19:01 visual_prompt]: 	Test 200/356. loss: 1.469, 0.2138 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 09:19:22 visual_prompt]: 	Test 300/356. loss: 1.360, 0.2146 s / batch. (data: 7.89e-05)max mem: 7.81207 GB 
[10/01 09:19:36 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2136, average loss: 1.3911
[10/01 09:19:36 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.82	top5: 97.15	
[10/01 09:19:36 visual_prompt]: Best epoch 79: best metric: 0.415
[10/01 09:19:36 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.12842758726130282
[10/01 09:19:46 visual_prompt]: Epoch 80 / 100: avg data time: 1.06e-01, avg batch time: 0.5565, average train loss: 1.2193
[10/01 09:19:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1667, average loss: 1.2289
[10/01 09:19:50 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.00	top5: 99.00	
[10/01 09:20:13 visual_prompt]: 	Test 100/356. loss: 1.336, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 09:20:34 visual_prompt]: 	Test 200/356. loss: 1.454, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 09:20:56 visual_prompt]: 	Test 300/356. loss: 1.349, 0.2140 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 09:21:09 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2137, average loss: 1.3922
[10/01 09:21:09 visual_prompt]: Classification results with test_vtab-dmlab: top1: 36.25	top5: 97.54	
[10/01 09:21:09 visual_prompt]: Best epoch 80: best metric: 0.430
[10/01 09:21:09 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.11697777844051105
[10/01 09:21:19 visual_prompt]: Epoch 81 / 100: avg data time: 1.01e-01, avg batch time: 0.5511, average train loss: 1.2137
[10/01 09:21:23 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 1.1781
[10/01 09:21:23 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.00	top5: 99.50	
[10/01 09:21:46 visual_prompt]: 	Test 100/356. loss: 1.359, 0.2136 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 09:22:07 visual_prompt]: 	Test 200/356. loss: 1.467, 0.2146 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 09:22:29 visual_prompt]: 	Test 300/356. loss: 1.441, 0.2144 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:22:42 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2137, average loss: 1.4379
[10/01 09:22:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.84	top5: 96.96	
[10/01 09:22:42 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.10599462319663905
[10/01 09:22:52 visual_prompt]: Epoch 82 / 100: avg data time: 1.09e-01, avg batch time: 0.5592, average train loss: 1.1797
[10/01 09:22:56 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1668, average loss: 1.3195
[10/01 09:22:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 40.50	top5: 99.50	
[10/01 09:23:19 visual_prompt]: 	Test 100/356. loss: 1.296, 0.2136 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:23:40 visual_prompt]: 	Test 200/356. loss: 1.491, 0.2143 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 09:24:02 visual_prompt]: 	Test 300/356. loss: 1.281, 0.2145 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:24:15 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2136, average loss: 1.4729
[10/01 09:24:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.58	top5: 97.43	
[10/01 09:24:15 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.09549150281252633
[10/01 09:24:26 visual_prompt]: Epoch 83 / 100: avg data time: 1.06e-01, avg batch time: 0.5562, average train loss: 1.2075
[10/01 09:24:29 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1667, average loss: 1.1752
[10/01 09:24:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 43.50	top5: 99.50	
[10/01 09:24:52 visual_prompt]: 	Test 100/356. loss: 1.332, 0.2141 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 09:25:14 visual_prompt]: 	Test 200/356. loss: 1.331, 0.2147 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:25:35 visual_prompt]: 	Test 300/356. loss: 1.236, 0.2145 s / batch. (data: 8.89e-05)max mem: 7.81207 GB 
[10/01 09:25:49 visual_prompt]: Inference (test):avg data time: 6.39e-05, avg batch time: 0.2137, average loss: 1.3965
[10/01 09:25:49 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.16	top5: 96.97	
[10/01 09:25:49 visual_prompt]: Best epoch 83: best metric: 0.435
[10/01 09:25:49 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.08548121372247919
[10/01 09:25:59 visual_prompt]: Epoch 84 / 100: avg data time: 1.03e-01, avg batch time: 0.5536, average train loss: 1.1348
[10/01 09:26:02 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1668, average loss: 1.1204
[10/01 09:26:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.50	
[10/01 09:26:25 visual_prompt]: 	Test 100/356. loss: 1.331, 0.2139 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 09:26:47 visual_prompt]: 	Test 200/356. loss: 1.375, 0.2147 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 09:27:08 visual_prompt]: 	Test 300/356. loss: 1.238, 0.2149 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 09:27:22 visual_prompt]: Inference (test):avg data time: 4.38e-05, avg batch time: 0.2136, average loss: 1.4262
[10/01 09:27:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.67	top5: 97.53	
[10/01 09:27:22 visual_prompt]: Best epoch 84: best metric: 0.445
[10/01 09:27:22 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.07597595192178702
[10/01 09:27:32 visual_prompt]: Epoch 85 / 100: avg data time: 1.03e-01, avg batch time: 0.5525, average train loss: 1.0888
[10/01 09:27:36 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1667, average loss: 1.0673
[10/01 09:27:36 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.00	top5: 99.50	
[10/01 09:27:59 visual_prompt]: 	Test 100/356. loss: 1.244, 0.2144 s / batch. (data: 4.41e-05)max mem: 7.81207 GB 
[10/01 09:28:20 visual_prompt]: 	Test 200/356. loss: 1.673, 0.2144 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 09:28:42 visual_prompt]: 	Test 300/356. loss: 1.331, 0.2143 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 09:28:55 visual_prompt]: Inference (test):avg data time: 5.96e-05, avg batch time: 0.2138, average loss: 1.4258
[10/01 09:28:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.52	top5: 96.91	
[10/01 09:28:55 visual_prompt]: Best epoch 85: best metric: 0.480
[10/01 09:28:55 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.06698729810778065
[10/01 09:29:05 visual_prompt]: Epoch 86 / 100: avg data time: 1.11e-01, avg batch time: 0.5616, average train loss: 1.1057
[10/01 09:29:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1666, average loss: 1.0431
[10/01 09:29:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 44.50	top5: 99.50	
[10/01 09:29:32 visual_prompt]: 	Test 100/356. loss: 1.312, 0.2139 s / batch. (data: 7.80e-05)max mem: 7.81207 GB 
[10/01 09:29:54 visual_prompt]: 	Test 200/356. loss: 1.515, 0.2144 s / batch. (data: 2.55e-05)max mem: 7.81207 GB 
[10/01 09:30:15 visual_prompt]: 	Test 300/356. loss: 1.249, 0.2148 s / batch. (data: 9.75e-05)max mem: 7.81207 GB 
[10/01 09:30:28 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2137, average loss: 1.4344
[10/01 09:30:29 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.09	top5: 97.42	
[10/01 09:30:29 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.058526203570536506
[10/01 09:30:39 visual_prompt]: Epoch 87 / 100: avg data time: 1.05e-01, avg batch time: 0.5555, average train loss: 1.0444
[10/01 09:30:42 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1687, average loss: 0.9936
[10/01 09:30:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.00	top5: 99.50	
[10/01 09:31:05 visual_prompt]: 	Test 100/356. loss: 1.410, 0.2141 s / batch. (data: 2.74e-05)max mem: 7.81207 GB 
[10/01 09:31:27 visual_prompt]: 	Test 200/356. loss: 1.519, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 09:31:48 visual_prompt]: 	Test 300/356. loss: 1.382, 0.2144 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 09:32:02 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2137, average loss: 1.4893
[10/01 09:32:02 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.73	top5: 97.42	
[10/01 09:32:02 visual_prompt]: Best epoch 87: best metric: 0.490
[10/01 09:32:02 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.05060297685041659
[10/01 09:32:12 visual_prompt]: Epoch 88 / 100: avg data time: 1.05e-01, avg batch time: 0.5556, average train loss: 1.0176
[10/01 09:32:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1667, average loss: 1.2472
[10/01 09:32:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 42.50	top5: 99.50	
[10/01 09:32:39 visual_prompt]: 	Test 100/356. loss: 1.542, 0.2138 s / batch. (data: 3.05e-05)max mem: 7.81207 GB 
[10/01 09:33:00 visual_prompt]: 	Test 200/356. loss: 1.574, 0.2140 s / batch. (data: 2.93e-05)max mem: 7.81207 GB 
[10/01 09:33:21 visual_prompt]: 	Test 300/356. loss: 1.519, 0.2147 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:33:35 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2137, average loss: 1.6493
[10/01 09:33:35 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.82	top5: 97.03	
[10/01 09:33:35 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.04322727117869951
[10/01 09:33:45 visual_prompt]: Epoch 89 / 100: avg data time: 1.08e-01, avg batch time: 0.5581, average train loss: 1.0283
[10/01 09:33:49 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1666, average loss: 1.0594
[10/01 09:33:49 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.00	top5: 99.50	
[10/01 09:34:12 visual_prompt]: 	Test 100/356. loss: 1.406, 0.2137 s / batch. (data: 3.31e-05)max mem: 7.81207 GB 
[10/01 09:34:33 visual_prompt]: 	Test 200/356. loss: 1.913, 0.2141 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 09:34:55 visual_prompt]: 	Test 300/356. loss: 1.411, 0.2143 s / batch. (data: 9.11e-05)max mem: 7.81207 GB 
[10/01 09:35:08 visual_prompt]: Inference (test):avg data time: 6.23e-05, avg batch time: 0.2137, average loss: 1.5827
[10/01 09:35:08 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.78	top5: 96.44	
[10/01 09:35:08 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.03640807271660634
[10/01 09:35:19 visual_prompt]: Epoch 90 / 100: avg data time: 1.10e-01, avg batch time: 0.5608, average train loss: 1.0326
[10/01 09:35:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1664, average loss: 1.0251
[10/01 09:35:22 visual_prompt]: Classification results with val_vtab-dmlab: top1: 46.00	top5: 99.50	
[10/01 09:35:45 visual_prompt]: 	Test 100/356. loss: 1.467, 0.2140 s / batch. (data: 2.72e-05)max mem: 7.81207 GB 
[10/01 09:36:07 visual_prompt]: 	Test 200/356. loss: 1.559, 0.2141 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 09:36:28 visual_prompt]: 	Test 300/356. loss: 1.355, 0.2143 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 09:36:42 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2136, average loss: 1.5546
[10/01 09:36:42 visual_prompt]: Classification results with test_vtab-dmlab: top1: 41.03	top5: 97.20	
[10/01 09:36:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.03015368960704584
[10/01 09:36:52 visual_prompt]: Epoch 91 / 100: avg data time: 1.11e-01, avg batch time: 0.5627, average train loss: 0.9822
[10/01 09:36:56 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1667, average loss: 0.9590
[10/01 09:36:56 visual_prompt]: Classification results with val_vtab-dmlab: top1: 51.00	top5: 99.50	
[10/01 09:37:19 visual_prompt]: 	Test 100/356. loss: 1.404, 0.2139 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 09:37:40 visual_prompt]: 	Test 200/356. loss: 1.554, 0.2137 s / batch. (data: 3.19e-05)max mem: 7.81207 GB 
[10/01 09:38:02 visual_prompt]: 	Test 300/356. loss: 1.318, 0.2145 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 09:38:15 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2136, average loss: 1.5076
[10/01 09:38:15 visual_prompt]: Classification results with test_vtab-dmlab: top1: 39.94	top5: 97.35	
[10/01 09:38:15 visual_prompt]: Best epoch 91: best metric: 0.510
[10/01 09:38:15 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.024471741852423234
[10/01 09:38:25 visual_prompt]: Epoch 92 / 100: avg data time: 1.10e-01, avg batch time: 0.5594, average train loss: 0.9555
[10/01 09:38:29 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1668, average loss: 0.9625
[10/01 09:38:29 visual_prompt]: Classification results with val_vtab-dmlab: top1: 47.50	top5: 99.50	
[10/01 09:38:52 visual_prompt]: 	Test 100/356. loss: 1.357, 0.2137 s / batch. (data: 2.91e-05)max mem: 7.81207 GB 
[10/01 09:39:13 visual_prompt]: 	Test 200/356. loss: 1.725, 0.2140 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 09:39:35 visual_prompt]: 	Test 300/356. loss: 1.365, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:39:48 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2137, average loss: 1.5677
[10/01 09:39:48 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.82	top5: 97.03	
[10/01 09:39:48 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.019369152030840553
[10/01 09:39:58 visual_prompt]: Epoch 93 / 100: avg data time: 1.03e-01, avg batch time: 0.5525, average train loss: 0.9127
[10/01 09:40:02 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1665, average loss: 0.9398
[10/01 09:40:02 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.50	top5: 99.50	
[10/01 09:40:25 visual_prompt]: 	Test 100/356. loss: 1.473, 0.2136 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 09:40:47 visual_prompt]: 	Test 200/356. loss: 1.654, 0.2143 s / batch. (data: 7.61e-05)max mem: 7.81207 GB 
[10/01 09:41:08 visual_prompt]: 	Test 300/356. loss: 1.289, 0.2147 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:41:22 visual_prompt]: Inference (test):avg data time: 4.23e-05, avg batch time: 0.2137, average loss: 1.6036
[10/01 09:41:22 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.69	top5: 97.11	
[10/01 09:41:22 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.014852136862001764
[10/01 09:41:32 visual_prompt]: Epoch 94 / 100: avg data time: 1.05e-01, avg batch time: 0.5555, average train loss: 0.8967
[10/01 09:41:35 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1667, average loss: 0.9087
[10/01 09:41:35 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.50	
[10/01 09:41:58 visual_prompt]: 	Test 100/356. loss: 1.506, 0.2138 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 09:42:20 visual_prompt]: 	Test 200/356. loss: 1.618, 0.2144 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 09:42:41 visual_prompt]: 	Test 300/356. loss: 1.365, 0.2148 s / batch. (data: 2.88e-05)max mem: 7.81207 GB 
[10/01 09:42:55 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2137, average loss: 1.6373
[10/01 09:42:55 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.78	top5: 97.13	
[10/01 09:42:55 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.010926199633097156
[10/01 09:43:05 visual_prompt]: Epoch 95 / 100: avg data time: 1.06e-01, avg batch time: 0.5570, average train loss: 0.8809
[10/01 09:43:09 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1667, average loss: 0.9202
[10/01 09:43:09 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.50	
[10/01 09:43:32 visual_prompt]: 	Test 100/356. loss: 1.632, 0.2137 s / batch. (data: 2.86e-05)max mem: 7.81207 GB 
[10/01 09:43:53 visual_prompt]: 	Test 200/356. loss: 1.633, 0.2141 s / batch. (data: 2.53e-05)max mem: 7.81207 GB 
[10/01 09:44:15 visual_prompt]: 	Test 300/356. loss: 1.377, 0.2141 s / batch. (data: 2.79e-05)max mem: 7.81207 GB 
[10/01 09:44:28 visual_prompt]: Inference (test):avg data time: 4.84e-05, avg batch time: 0.2136, average loss: 1.6992
[10/01 09:44:28 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.58	top5: 97.18	
[10/01 09:44:28 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.00759612349389599
[10/01 09:44:38 visual_prompt]: Epoch 96 / 100: avg data time: 1.13e-01, avg batch time: 0.5629, average train loss: 0.8861
[10/01 09:44:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1665, average loss: 0.8928
[10/01 09:44:42 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.50	top5: 99.50	
[10/01 09:45:05 visual_prompt]: 	Test 100/356. loss: 1.476, 0.2136 s / batch. (data: 2.60e-05)max mem: 7.81207 GB 
[10/01 09:45:26 visual_prompt]: 	Test 200/356. loss: 1.751, 0.2147 s / batch. (data: 2.65e-05)max mem: 7.81207 GB 
[10/01 09:45:48 visual_prompt]: 	Test 300/356. loss: 1.426, 0.2143 s / batch. (data: 2.50e-05)max mem: 7.81207 GB 
[10/01 09:46:01 visual_prompt]: Inference (test):avg data time: 4.77e-05, avg batch time: 0.2136, average loss: 1.6736
[10/01 09:46:01 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.51	top5: 97.01	
[10/01 09:46:01 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.004865965629214819
[10/01 09:46:11 visual_prompt]: Epoch 97 / 100: avg data time: 1.03e-01, avg batch time: 0.5539, average train loss: 0.8516
[10/01 09:46:15 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1666, average loss: 0.8990
[10/01 09:46:15 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.00	top5: 99.50	
[10/01 09:46:38 visual_prompt]: 	Test 100/356. loss: 1.535, 0.2135 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:47:00 visual_prompt]: 	Test 200/356. loss: 1.666, 0.2146 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:47:21 visual_prompt]: 	Test 300/356. loss: 1.389, 0.2143 s / batch. (data: 2.67e-05)max mem: 7.81207 GB 
[10/01 09:47:34 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2136, average loss: 1.7025
[10/01 09:47:34 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.79	top5: 97.17	
[10/01 09:47:34 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.002739052315863355
[10/01 09:47:45 visual_prompt]: Epoch 98 / 100: avg data time: 1.01e-01, avg batch time: 0.5520, average train loss: 0.8448
[10/01 09:47:48 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1666, average loss: 0.8862
[10/01 09:47:48 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.50	top5: 99.50	
[10/01 09:48:11 visual_prompt]: 	Test 100/356. loss: 1.535, 0.2138 s / batch. (data: 2.81e-05)max mem: 7.81207 GB 
[10/01 09:48:33 visual_prompt]: 	Test 200/356. loss: 1.710, 0.2140 s / batch. (data: 2.69e-05)max mem: 7.81207 GB 
[10/01 09:48:54 visual_prompt]: 	Test 300/356. loss: 1.441, 0.2146 s / batch. (data: 2.84e-05)max mem: 7.81207 GB 
[10/01 09:49:07 visual_prompt]: Inference (test):avg data time: 4.67e-05, avg batch time: 0.2136, average loss: 1.6945
[10/01 09:49:07 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.41	top5: 97.14	
[10/01 09:49:07 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.0012179748700879012
[10/01 09:49:18 visual_prompt]: Epoch 99 / 100: avg data time: 1.07e-01, avg batch time: 0.5562, average train loss: 0.8479
[10/01 09:49:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1666, average loss: 0.8999
[10/01 09:49:21 visual_prompt]: Classification results with val_vtab-dmlab: top1: 48.50	top5: 99.50	
[10/01 09:49:44 visual_prompt]: 	Test 100/356. loss: 1.580, 0.2141 s / batch. (data: 7.13e-05)max mem: 7.81207 GB 
[10/01 09:50:06 visual_prompt]: 	Test 200/356. loss: 1.678, 0.2141 s / batch. (data: 6.77e-05)max mem: 7.81207 GB 
[10/01 09:50:27 visual_prompt]: 	Test 300/356. loss: 1.418, 0.2141 s / batch. (data: 2.98e-05)max mem: 7.81207 GB 
[10/01 09:50:41 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2137, average loss: 1.7124
[10/01 09:50:41 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.72	top5: 97.18	
[10/01 09:50:41 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.00030458649045211894
[10/01 09:50:51 visual_prompt]: Epoch 100 / 100: avg data time: 1.03e-01, avg batch time: 0.5534, average train loss: 0.8482
[10/01 09:50:54 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1667, average loss: 0.8969
[10/01 09:50:54 visual_prompt]: Classification results with val_vtab-dmlab: top1: 49.00	top5: 99.50	
[10/01 09:51:17 visual_prompt]: 	Test 100/356. loss: 1.578, 0.2137 s / batch. (data: 2.62e-05)max mem: 7.81207 GB 
[10/01 09:51:39 visual_prompt]: 	Test 200/356. loss: 1.678, 0.2142 s / batch. (data: 2.77e-05)max mem: 7.81207 GB 
[10/01 09:52:00 visual_prompt]: 	Test 300/356. loss: 1.421, 0.2148 s / batch. (data: 2.57e-05)max mem: 7.81207 GB 
[10/01 09:52:14 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2136, average loss: 1.7118
[10/01 09:52:14 visual_prompt]: Classification results with test_vtab-dmlab: top1: 40.65	top5: 97.19	
