[09/15 17:05:59 visual_prompt]: Rank of current process: 0. World size: 1
[09/15 17:05:59 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2,3
GPU 0,1              NVIDIA TITAN X (Pascal)
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/15 17:05:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed42'], train_type='')
[09/15 17:05:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/15 17:05:59 visual_prompt]: Training with config:
[09/15 17:05:59 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-resisc45',
          'NO_TEST': False,
          'NUMBER_CLASSES': 45,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed42/vtab-resisc45/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/15 17:05:59 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-15 17:05:59.359785: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-15 17:06:00.706480: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:06:00.706612: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:06:00.706629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-15 17:06:03.543556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:06:03.543712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:06:03.543740: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/15 17:06:03 visual_prompt]: Constructing vtab-resisc45 dataset trainval...
2023-09-15 17:06:03.602440: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with "NOT_FOUND: Could not locate the credentials file.". Retrieving token from GCE failed with "FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata".
[INFO: dataset_info.py:  675]: Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: resisc45/3.0.0
[INFO: dataset_info.py:  566]: Load dataset info from /tmp/tmp7x5ofjc0tfds
[INFO: dataset_info.py:  647]: Field info.splits from disk and from code do not match. Keeping the one from code.
[INFO: dataset_info.py:  647]: Field info.supervised_keys from disk and from code do not match. Keeping the one from code.
[INFO: dataset_info.py:  647]: Field info.module_name from disk and from code do not match. Keeping the one from code.
[INFO: dataset_builder.py:  575]: Generating dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to visual_prompt_tuning/data_path/resisc45/3.0.0...
Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]
Generating train examples...:   0%|          | 0/31500 [00:00<?, ? examples/s][A
Generating train examples...:   0%|          | 1/31500 [00:00<5:19:59,  1.64 examples/s][A
Generating train examples...:   0%|          | 100/31500 [00:00<02:46, 189.08 examples/s][A
Generating train examples...:   1%|          | 183/31500 [00:00<01:36, 325.39 examples/s][A
Generating train examples...:   1%|          | 269/31500 [00:00<01:10, 442.14 examples/s][A
Generating train examples...:   1%|1         | 343/31500 [00:01<01:17, 404.43 examples/s][A
Generating train examples...:   1%|1         | 415/31500 [00:01<01:05, 472.04 examples/s][A
Generating train examples...:   2%|1         | 530/31500 [00:01<00:49, 631.82 examples/s][A
Generating train examples...:   2%|2         | 641/31500 [00:01<00:41, 752.02 examples/s][A
Generating train examples...:   2%|2         | 732/31500 [00:01<01:03, 482.22 examples/s][A
Generating train examples...:   3%|2         | 803/31500 [00:02<01:38, 312.87 examples/s][A
Generating train examples...:   3%|2         | 857/31500 [00:02<02:29, 204.74 examples/s][A
Generating train examples...:   3%|2         | 897/31500 [00:03<02:59, 170.43 examples/s][A
Generating train examples...:   3%|2         | 928/31500 [00:03<03:40, 138.94 examples/s][A
Generating train examples...:   3%|3         | 952/31500 [00:03<03:44, 136.02 examples/s][A
Generating train examples...:   3%|3         | 973/31500 [00:04<03:53, 130.49 examples/s][A
Generating train examples...:   3%|3         | 991/31500 [00:04<03:51, 131.85 examples/s][A
Generating train examples...:   3%|3         | 1008/31500 [00:04<03:52, 131.19 examples/s][A
Generating train examples...:   3%|3         | 1024/31500 [00:04<03:53, 130.56 examples/s][A
Generating train examples...:   3%|3         | 1039/31500 [00:04<04:02, 125.64 examples/s][A
Generating train examples...:   3%|3         | 1053/31500 [00:04<04:43, 107.52 examples/s][A
Generating train examples...:   3%|3         | 1065/31500 [00:04<04:58, 102.02 examples/s][A
Generating train examples...:   3%|3         | 1078/31500 [00:05<04:45, 106.57 examples/s][A
Generating train examples...:   3%|3         | 1092/31500 [00:05<04:34, 110.93 examples/s][A
Generating train examples...:   4%|3         | 1104/31500 [00:05<04:29, 112.76 examples/s][A
Generating train examples...:   4%|3         | 1116/31500 [00:05<04:34, 110.88 examples/s][A
Generating train examples...:   4%|3         | 1128/31500 [00:05<04:28, 113.12 examples/s][A
Generating train examples...:   4%|3         | 1156/31500 [00:05<03:11, 158.06 examples/s][A
Generating train examples...:   4%|3         | 1178/31500 [00:05<02:53, 175.22 examples/s][A
Generating train examples...:   4%|3         | 1229/31500 [00:05<01:52, 269.86 examples/s][A
Generating train examples...:   4%|3         | 1257/31500 [00:05<01:55, 262.12 examples/s][A
Generating train examples...:   4%|4         | 1284/31500 [00:05<02:02, 245.68 examples/s][A
Generating train examples...:   4%|4         | 1320/31500 [00:06<01:49, 276.69 examples/s][A
Generating train examples...:   4%|4         | 1349/31500 [00:06<01:47, 280.20 examples/s][A
Generating train examples...:   4%|4         | 1378/31500 [00:06<01:52, 267.27 examples/s][A
Generating train examples...:   4%|4         | 1406/31500 [00:06<02:03, 244.37 examples/s][A
Generating train examples...:   5%|4         | 1497/31500 [00:06<01:11, 420.07 examples/s][A
Generating train examples...:   5%|5         | 1597/31500 [00:06<00:51, 575.46 examples/s][A
Generating train examples...:   5%|5         | 1705/31500 [00:06<00:42, 702.59 examples/s][A
Generating train examples...:   6%|5         | 1783/31500 [00:06<00:41, 723.94 examples/s][A
Generating train examples...:   6%|6         | 1894/31500 [00:06<00:35, 834.25 examples/s][A
Generating train examples...:   6%|6         | 1980/31500 [00:07<00:41, 715.31 examples/s][A
Generating train examples...:   7%|6         | 2056/31500 [00:07<00:46, 629.99 examples/s][A
Generating train examples...:   7%|6         | 2124/31500 [00:07<01:25, 344.82 examples/s][A
Generating train examples...:   7%|6         | 2186/31500 [00:07<01:15, 387.93 examples/s][A
Generating train examples...:   7%|7         | 2275/31500 [00:07<01:00, 479.65 examples/s][A
Generating train examples...:   8%|7         | 2391/31500 [00:08<00:46, 620.86 examples/s][A
Generating train examples...:   8%|7         | 2482/31500 [00:08<00:42, 686.29 examples/s][A
Generating train examples...:   8%|8         | 2566/31500 [00:08<00:47, 606.76 examples/s][A
Generating train examples...:   8%|8         | 2651/31500 [00:08<00:43, 662.09 examples/s][A
Generating train examples...:   9%|8         | 2750/31500 [00:08<00:38, 741.72 examples/s][A
Generating train examples...:   9%|8         | 2833/31500 [00:08<01:05, 440.29 examples/s][A
Generating train examples...:   9%|9         | 2898/31500 [00:09<01:06, 432.33 examples/s][A
Generating train examples...:   9%|9         | 2956/31500 [00:09<01:20, 356.43 examples/s][A
Generating train examples...:  10%|9         | 3003/31500 [00:09<01:19, 356.36 examples/s][A
Generating train examples...:  10%|9         | 3047/31500 [00:09<01:20, 352.91 examples/s][A
Generating train examples...:  10%|9         | 3088/31500 [00:09<01:27, 325.80 examples/s][A
Generating train examples...:  10%|9         | 3125/31500 [00:09<01:42, 277.18 examples/s][A
Generating train examples...:  10%|#         | 3156/31500 [00:10<01:52, 252.87 examples/s][A
Generating train examples...:  10%|#         | 3194/31500 [00:10<01:42, 275.48 examples/s][A
Generating train examples...:  10%|#         | 3225/31500 [00:10<01:57, 240.39 examples/s][A
Generating train examples...:  10%|#         | 3252/31500 [00:10<02:00, 234.57 examples/s][A
Generating train examples...:  10%|#         | 3277/31500 [00:10<02:06, 222.37 examples/s][A
Generating train examples...:  10%|#         | 3305/31500 [00:10<01:59, 235.32 examples/s][A
Generating train examples...:  11%|#         | 3337/31500 [00:10<01:50, 255.38 examples/s][A
Generating train examples...:  11%|#         | 3364/31500 [00:10<01:50, 255.61 examples/s][A
Generating train examples...:  11%|#         | 3397/31500 [00:11<01:42, 275.03 examples/s][A
Generating train examples...:  11%|#         | 3426/31500 [00:11<01:55, 242.93 examples/s][A
Generating train examples...:  11%|#         | 3456/31500 [00:11<01:49, 257.19 examples/s][A
Generating train examples...:  11%|#1        | 3483/31500 [00:11<01:50, 253.09 examples/s][A
Generating train examples...:  11%|#1        | 3510/31500 [00:11<02:19, 201.15 examples/s][A
Generating train examples...:  11%|#1        | 3611/31500 [00:11<01:11, 388.44 examples/s][A
Generating train examples...:  12%|#1        | 3676/31500 [00:11<01:01, 452.60 examples/s][A
Generating train examples...:  12%|#1        | 3728/31500 [00:12<01:31, 303.96 examples/s][A
Generating train examples...:  12%|#1        | 3770/31500 [00:12<01:50, 250.83 examples/s][A
Generating train examples...:  12%|#2        | 3804/31500 [00:12<02:02, 226.35 examples/s][A
Generating train examples...:  12%|#2        | 3833/31500 [00:12<02:17, 200.64 examples/s][A
Generating train examples...:  12%|#2        | 3860/31500 [00:12<02:10, 212.18 examples/s][A
Generating train examples...:  12%|#2        | 3885/31500 [00:13<02:22, 193.89 examples/s][A
Generating train examples...:  12%|#2        | 3907/31500 [00:13<02:39, 173.29 examples/s][A
Generating train examples...:  12%|#2        | 3927/31500 [00:13<02:35, 177.59 examples/s][A
Generating train examples...:  13%|#2        | 3947/31500 [00:13<02:38, 174.10 examples/s][A
Generating train examples...:  13%|#2        | 3966/31500 [00:13<02:39, 172.28 examples/s][A
Generating train examples...:  13%|#2        | 3984/31500 [00:13<02:50, 161.11 examples/s][A
Generating train examples...:  13%|#2        | 4001/31500 [00:13<03:14, 141.28 examples/s][A
Generating train examples...:  13%|#2        | 4016/31500 [00:14<03:50, 118.98 examples/s][A
Generating train examples...:  13%|#2        | 4029/31500 [00:14<04:04, 112.31 examples/s][A
Generating train examples...:  13%|#2        | 4041/31500 [00:14<04:49, 94.96 examples/s] [A
Generating train examples...:  13%|#2        | 4052/31500 [00:14<05:06, 89.52 examples/s][A
Generating train examples...:  13%|#2        | 4062/31500 [00:14<05:12, 87.69 examples/s][A
Generating train examples...:  13%|#2        | 4071/31500 [00:14<05:42, 80.12 examples/s][A
Generating train examples...:  13%|#2        | 4080/31500 [00:14<05:56, 76.81 examples/s][A
Generating train examples...:  13%|#2        | 4088/31500 [00:15<06:26, 70.93 examples/s][A
Generating train examples...:  13%|#3        | 4098/31500 [00:15<05:58, 76.49 examples/s][A
Generating train examples...:  13%|#3        | 4106/31500 [00:15<06:20, 72.06 examples/s][A
Generating train examples...:  13%|#3        | 4115/31500 [00:15<06:11, 73.74 examples/s][A
Generating train examples...:  13%|#3        | 4125/31500 [00:15<05:53, 77.46 examples/s][A
Generating train examples...:  13%|#3        | 4133/31500 [00:15<06:12, 73.39 examples/s][A
Generating train examples...:  13%|#3        | 4148/31500 [00:15<04:55, 92.43 examples/s][A
Generating train examples...:  13%|#3        | 4165/31500 [00:15<04:06, 111.10 examples/s][A
Generating train examples...:  13%|#3        | 4177/31500 [00:15<04:15, 106.91 examples/s][A
Generating train examples...:  13%|#3        | 4188/31500 [00:16<04:23, 103.83 examples/s][A
Generating train examples...:  13%|#3        | 4201/31500 [00:16<05:16, 86.16 examples/s] [A
Generating train examples...:  14%|#3        | 4297/31500 [00:16<01:34, 287.45 examples/s][A
Generating train examples...:  14%|#3        | 4373/31500 [00:16<01:08, 396.62 examples/s][A
Generating train examples...:  14%|#4        | 4419/31500 [00:16<01:12, 375.12 examples/s][A
Generating train examples...:  14%|#4        | 4476/31500 [00:16<01:03, 423.55 examples/s][A
Generating train examples...:  14%|#4        | 4563/31500 [00:16<00:49, 540.51 examples/s][A
Generating train examples...:  15%|#4        | 4622/31500 [00:16<00:49, 547.35 examples/s][A
Generating train examples...:  15%|#4        | 4695/31500 [00:17<00:44, 597.68 examples/s][A
Generating train examples...:  15%|#5        | 4762/31500 [00:17<00:43, 617.83 examples/s][A
Generating train examples...:  15%|#5        | 4843/31500 [00:17<00:39, 672.26 examples/s][A
Generating train examples...:  16%|#5        | 4912/31500 [00:17<01:02, 422.21 examples/s][A
Generating train examples...:  16%|#5        | 4967/31500 [00:17<01:17, 340.93 examples/s][A
Generating train examples...:  16%|#5        | 5012/31500 [00:17<01:14, 357.03 examples/s][A
Generating train examples...:  16%|#6        | 5057/31500 [00:18<01:18, 336.52 examples/s][A
Generating train examples...:  16%|#6        | 5097/31500 [00:18<02:01, 216.73 examples/s][A
Generating train examples...:  16%|#6        | 5128/31500 [00:18<02:12, 199.24 examples/s][A
Generating train examples...:  16%|#6        | 5155/31500 [00:18<02:14, 196.22 examples/s][A
Generating train examples...:  16%|#6        | 5193/31500 [00:18<01:55, 228.51 examples/s][A
Generating train examples...:  17%|#6        | 5242/31500 [00:19<01:33, 280.40 examples/s][A
Generating train examples...:  17%|#6        | 5293/31500 [00:19<01:19, 327.70 examples/s][A
Generating train examples...:  17%|#6        | 5332/31500 [00:19<01:18, 331.93 examples/s][A
Generating train examples...:  17%|#7        | 5370/31500 [00:19<01:17, 336.37 examples/s][A
Generating train examples...:  17%|#7        | 5407/31500 [00:19<01:25, 304.43 examples/s][A
Generating train examples...:  17%|#7        | 5472/31500 [00:19<01:06, 388.60 examples/s][A
Generating train examples...:  18%|#7        | 5519/31500 [00:19<01:03, 408.80 examples/s][A
Generating train examples...:  18%|#7        | 5563/31500 [00:19<01:21, 320.11 examples/s][A
Generating train examples...:  18%|#7        | 5600/31500 [00:20<01:37, 265.17 examples/s][A
Generating train examples...:  18%|#7        | 5632/31500 [00:20<02:57, 145.66 examples/s][A
Generating train examples...:  18%|#7        | 5656/31500 [00:20<02:57, 145.64 examples/s][A
Generating train examples...:  18%|#8        | 5685/31500 [00:20<02:34, 167.30 examples/s][A
Generating train examples...:  18%|#8        | 5709/31500 [00:21<02:24, 177.92 examples/s][A
Generating train examples...:  18%|#8        | 5733/31500 [00:21<02:54, 147.25 examples/s][A
Generating train examples...:  18%|#8        | 5753/31500 [00:21<02:47, 153.48 examples/s][A
Generating train examples...:  18%|#8        | 5772/31500 [00:21<03:03, 140.56 examples/s][A
Generating train examples...:  18%|#8        | 5790/31500 [00:21<02:53, 148.42 examples/s][A
Generating train examples...:  18%|#8        | 5807/31500 [00:21<02:50, 150.29 examples/s][A
Generating train examples...:  19%|#8        | 5831/31500 [00:21<02:30, 170.01 examples/s][A
Generating train examples...:  19%|#8        | 5850/31500 [00:21<02:30, 170.55 examples/s][A
Generating train examples...:  19%|#8        | 5877/31500 [00:22<02:13, 192.46 examples/s][A
Generating train examples...:  19%|#8        | 5898/31500 [00:22<02:12, 192.71 examples/s][A
Generating train examples...:  19%|#8        | 5921/31500 [00:22<02:06, 202.55 examples/s][A
Generating train examples...:  19%|#8        | 5943/31500 [00:22<02:03, 207.23 examples/s][A
Generating train examples...:  19%|#8        | 5965/31500 [00:22<02:02, 207.65 examples/s][A
Generating train examples...:  19%|#9        | 5987/31500 [00:22<02:01, 210.13 examples/s][A
Generating train examples...:  19%|#9        | 6009/31500 [00:22<02:30, 168.87 examples/s][A
Generating train examples...:  19%|#9        | 6028/31500 [00:22<02:50, 149.38 examples/s][A
Generating train examples...:  19%|#9        | 6045/31500 [00:23<02:50, 148.87 examples/s][A
Generating train examples...:  19%|#9        | 6061/31500 [00:23<03:10, 133.53 examples/s][A
Generating train examples...:  19%|#9        | 6083/31500 [00:23<02:48, 150.98 examples/s][A
Generating train examples...:  19%|#9        | 6105/31500 [00:23<02:31, 167.77 examples/s][A
Generating train examples...:  19%|#9        | 6123/31500 [00:23<02:44, 154.38 examples/s][A
Generating train examples...:  20%|#9        | 6144/31500 [00:23<02:37, 161.14 examples/s][A
Generating train examples...:  20%|#9        | 6169/31500 [00:23<02:24, 175.39 examples/s][A
Generating train examples...:  20%|#9        | 6188/31500 [00:23<02:32, 165.92 examples/s][A
Generating train examples...:  20%|#9        | 6219/31500 [00:24<02:13, 189.45 examples/s][A
Generating train examples...:  20%|#9        | 6250/31500 [00:24<01:55, 218.40 examples/s][A
Generating train examples...:  20%|#9        | 6279/31500 [00:24<01:46, 237.18 examples/s][A
Generating train examples...:  20%|##        | 6304/31500 [00:24<02:44, 153.63 examples/s][A
Generating train examples...:  20%|##        | 6331/31500 [00:24<02:23, 175.15 examples/s][A
Generating train examples...:  20%|##        | 6353/31500 [00:24<03:06, 134.97 examples/s][A
Generating train examples...:  20%|##        | 6371/31500 [00:25<04:02, 103.48 examples/s][A
Generating train examples...:  20%|##        | 6385/31500 [00:25<05:33, 75.30 examples/s] [A
Generating train examples...:  20%|##        | 6396/31500 [00:25<05:52, 71.22 examples/s][A
Generating train examples...:  20%|##        | 6406/31500 [00:26<06:06, 68.44 examples/s][A
Generating train examples...:  20%|##        | 6415/31500 [00:26<06:35, 63.40 examples/s][A
Generating train examples...:  20%|##        | 6432/31500 [00:26<05:13, 80.01 examples/s][A
Generating train examples...:  21%|##        | 6464/31500 [00:26<03:19, 125.66 examples/s][A
Generating train examples...:  21%|##        | 6532/31500 [00:26<01:42, 244.35 examples/s][A
Generating train examples...:  21%|##1       | 6645/31500 [00:26<00:55, 451.58 examples/s][A
Generating train examples...:  21%|##1       | 6756/31500 [00:26<00:40, 615.77 examples/s][A
Generating train examples...:  22%|##1       | 6834/31500 [00:26<00:37, 658.13 examples/s][A
Generating train examples...:  22%|##2       | 6943/31500 [00:26<00:31, 775.09 examples/s][A
Generating train examples...:  22%|##2       | 7028/31500 [00:27<00:52, 470.22 examples/s][A
Generating train examples...:  23%|##2       | 7095/31500 [00:27<01:05, 370.15 examples/s][A
Generating train examples...:  23%|##2       | 7149/31500 [00:27<01:20, 303.72 examples/s][A
Generating train examples...:  23%|##2       | 7192/31500 [00:28<01:21, 298.27 examples/s][A
Generating train examples...:  23%|##2       | 7233/31500 [00:28<01:16, 317.01 examples/s][A
Generating train examples...:  23%|##3       | 7346/31500 [00:28<00:50, 474.21 examples/s][A
Generating train examples...:  24%|##3       | 7430/31500 [00:28<00:45, 524.25 examples/s][A
Generating train examples...:  24%|##3       | 7493/31500 [00:28<00:46, 515.39 examples/s][A
Generating train examples...:  24%|##3       | 7552/31500 [00:28<00:46, 509.73 examples/s][A
Generating train examples...:  24%|##4       | 7663/31500 [00:28<00:36, 653.90 examples/s][A
Generating train examples...:  25%|##4       | 7736/31500 [00:28<00:51, 465.63 examples/s][A
Generating train examples...:  25%|##4       | 7795/31500 [00:29<00:55, 427.11 examples/s][A
Generating train examples...:  25%|##5       | 7878/31500 [00:29<00:47, 501.71 examples/s][A
Generating train examples...:  25%|##5       | 7985/31500 [00:29<00:37, 625.97 examples/s][A
Generating train examples...:  26%|##5       | 8069/31500 [00:29<00:34, 676.89 examples/s][A
Generating train examples...:  26%|##5       | 8152/31500 [00:29<00:32, 712.62 examples/s][A
Generating train examples...:  26%|##6       | 8230/31500 [00:29<00:34, 678.87 examples/s][A
Generating train examples...:  27%|##6       | 8350/31500 [00:29<00:28, 814.73 examples/s][A
Generating train examples...:  27%|##6       | 8437/31500 [00:30<00:38, 599.01 examples/s][A
Generating train examples...:  27%|##7       | 8550/31500 [00:30<00:32, 714.41 examples/s][A
Generating train examples...:  27%|##7       | 8660/31500 [00:30<00:28, 805.47 examples/s][A
Generating train examples...:  28%|##7       | 8777/31500 [00:30<00:25, 896.63 examples/s][A
Generating train examples...:  28%|##8       | 8884/31500 [00:30<00:24, 935.82 examples/s][A
Generating train examples...:  29%|##8       | 8985/31500 [00:30<00:25, 883.74 examples/s][A
Generating train examples...:  29%|##8       | 9098/31500 [00:30<00:23, 947.78 examples/s][A
Generating train examples...:  29%|##9       | 9198/31500 [00:31<00:49, 448.98 examples/s][A
Generating train examples...:  29%|##9       | 9274/31500 [00:31<00:51, 430.82 examples/s][A
Generating train examples...:  30%|##9       | 9339/31500 [00:31<00:47, 465.72 examples/s][A
Generating train examples...:  30%|##9       | 9404/31500 [00:31<00:48, 458.22 examples/s][A
Generating train examples...:  30%|###       | 9463/31500 [00:31<00:54, 401.35 examples/s][A
Generating train examples...:  30%|###       | 9513/31500 [00:32<01:04, 342.90 examples/s][A
Generating train examples...:  30%|###       | 9601/31500 [00:32<00:49, 439.26 examples/s][A
Generating train examples...:  31%|###       | 9657/31500 [00:32<00:51, 427.44 examples/s][A
Generating train examples...:  31%|###       | 9708/31500 [00:32<01:03, 341.81 examples/s][A
Generating train examples...:  31%|###       | 9750/31500 [00:32<01:06, 326.18 examples/s][A
Generating train examples...:  31%|###1      | 9788/31500 [00:32<01:07, 321.98 examples/s][A
Generating train examples...:  31%|###1      | 9824/31500 [00:33<01:24, 255.08 examples/s][A
Generating train examples...:  32%|###1      | 9928/31500 [00:33<00:53, 403.97 examples/s][A
Generating train examples...:  32%|###1      | 10030/31500 [00:33<00:40, 534.89 examples/s][A
Generating train examples...:  32%|###2      | 10124/31500 [00:33<00:33, 629.10 examples/s][A
Generating train examples...:  32%|###2      | 10231/31500 [00:33<00:28, 738.50 examples/s][A
Generating train examples...:  33%|###2      | 10331/31500 [00:33<00:26, 805.97 examples/s][A
Generating train examples...:  33%|###3      | 10441/31500 [00:33<00:23, 884.72 examples/s][A
Generating train examples...:  33%|###3      | 10536/31500 [00:33<00:39, 526.98 examples/s][A
Generating train examples...:  34%|###3      | 10611/31500 [00:34<00:38, 536.68 examples/s][A
Generating train examples...:  34%|###3      | 10681/31500 [00:34<00:41, 507.48 examples/s][A
Generating train examples...:  34%|###4      | 10748/31500 [00:34<00:38, 539.72 examples/s][A
Generating train examples...:  34%|###4      | 10812/31500 [00:34<00:36, 561.42 examples/s][A
Generating train examples...:  35%|###4      | 10876/31500 [00:34<00:41, 497.73 examples/s][A
Generating train examples...:  35%|###4      | 10947/31500 [00:34<00:37, 546.12 examples/s][A
Generating train examples...:  35%|###4      | 11008/31500 [00:34<00:39, 516.99 examples/s][A
Generating train examples...:  35%|###5      | 11064/31500 [00:34<00:40, 503.85 examples/s][A
Generating train examples...:  35%|###5      | 11118/31500 [00:35<00:49, 413.02 examples/s][A
Generating train examples...:  35%|###5      | 11164/31500 [00:35<00:49, 407.52 examples/s][A
Generating train examples...:  36%|###5      | 11208/31500 [00:35<01:05, 309.12 examples/s][A
Generating train examples...:  36%|###5      | 11299/31500 [00:35<00:47, 429.39 examples/s][A
Generating train examples...:  36%|###6      | 11361/31500 [00:35<00:42, 468.76 examples/s][A
Generating train examples...:  36%|###6      | 11471/31500 [00:35<00:32, 619.87 examples/s][A
Generating train examples...:  37%|###6      | 11543/31500 [00:35<00:33, 591.34 examples/s][A
Generating train examples...:  37%|###6      | 11642/31500 [00:36<00:28, 690.89 examples/s][A
Generating train examples...:  37%|###7      | 11728/31500 [00:36<00:26, 735.30 examples/s][A
Generating train examples...:  38%|###7      | 11831/31500 [00:36<00:24, 801.05 examples/s][A
Generating train examples...:  38%|###7      | 11916/31500 [00:36<00:40, 482.09 examples/s][A
Generating train examples...:  38%|###8      | 11983/31500 [00:37<01:04, 302.84 examples/s][A
Generating train examples...:  38%|###8      | 12034/31500 [00:37<01:11, 272.93 examples/s][A
Generating train examples...:  38%|###8      | 12076/31500 [00:37<01:18, 247.86 examples/s][A
Generating train examples...:  38%|###8      | 12111/31500 [00:37<01:21, 237.61 examples/s][A
Generating train examples...:  39%|###8      | 12142/31500 [00:38<01:33, 206.98 examples/s][A
Generating train examples...:  39%|###8      | 12168/31500 [00:38<01:33, 206.12 examples/s][A
Generating train examples...:  39%|###8      | 12198/31500 [00:38<01:27, 220.26 examples/s][A
Generating train examples...:  39%|###8      | 12224/31500 [00:38<01:30, 213.67 examples/s][A
Generating train examples...:  39%|###8      | 12249/31500 [00:38<01:28, 217.12 examples/s][A
Generating train examples...:  39%|###8      | 12283/31500 [00:38<01:19, 241.21 examples/s][A
Generating train examples...:  39%|###9      | 12309/31500 [00:38<01:29, 215.21 examples/s][A
Generating train examples...:  39%|###9      | 12332/31500 [00:38<01:45, 181.81 examples/s][A
Generating train examples...:  39%|###9      | 12357/31500 [00:39<01:37, 196.05 examples/s][A
Generating train examples...:  39%|###9      | 12389/31500 [00:39<01:25, 223.21 examples/s][A
Generating train examples...:  39%|###9      | 12414/31500 [00:39<01:25, 224.22 examples/s][A
Generating train examples...:  39%|###9      | 12438/31500 [00:39<01:23, 227.46 examples/s][A
Generating train examples...:  40%|###9      | 12479/31500 [00:39<01:09, 275.59 examples/s][A
Generating train examples...:  40%|###9      | 12508/31500 [00:39<01:08, 275.53 examples/s][A
Generating train examples...:  40%|###9      | 12560/31500 [00:39<00:55, 343.02 examples/s][A
Generating train examples...:  40%|###9      | 12596/31500 [00:39<01:04, 292.61 examples/s][A
Generating train examples...:  40%|####      | 12628/31500 [00:40<01:20, 234.39 examples/s][A
Generating train examples...:  40%|####      | 12747/31500 [00:40<00:42, 445.86 examples/s][A
Generating train examples...:  41%|####      | 12863/31500 [00:40<00:30, 616.34 examples/s][A
Generating train examples...:  41%|####1     | 12958/31500 [00:40<00:26, 700.18 examples/s][A
Generating train examples...:  41%|####1     | 13037/31500 [00:40<00:27, 681.27 examples/s][A
Generating train examples...:  42%|####1     | 13149/31500 [00:40<00:23, 795.77 examples/s][A
Generating train examples...:  42%|####2     | 13267/31500 [00:40<00:20, 899.62 examples/s][A
Generating train examples...:  42%|####2     | 13363/31500 [00:41<00:37, 486.03 examples/s][A
Generating train examples...:  43%|####2     | 13437/31500 [00:41<00:39, 456.07 examples/s][A
Generating train examples...:  43%|####2     | 13500/31500 [00:41<00:44, 400.25 examples/s][A
Generating train examples...:  43%|####3     | 13553/31500 [00:41<00:50, 358.76 examples/s][A
Generating train examples...:  43%|####3     | 13606/31500 [00:41<00:46, 387.63 examples/s][A
Generating train examples...:  43%|####3     | 13665/31500 [00:41<00:41, 427.60 examples/s][A
Generating train examples...:  44%|####3     | 13716/31500 [00:42<00:40, 434.52 examples/s][A
Generating train examples...:  44%|####3     | 13766/31500 [00:42<00:39, 447.04 examples/s][A
Generating train examples...:  44%|####3     | 13815/31500 [00:42<00:42, 419.02 examples/s][A
Generating train examples...:  44%|####4     | 13901/31500 [00:42<00:33, 524.41 examples/s][A
Generating train examples...:  44%|####4     | 13959/31500 [00:42<00:33, 519.61 examples/s][A
Generating train examples...:  44%|####4     | 14014/31500 [00:42<00:49, 350.81 examples/s][A
Generating train examples...:  45%|####4     | 14059/31500 [00:42<00:51, 335.66 examples/s][A
Generating train examples...:  45%|####4     | 14099/31500 [00:43<01:04, 269.87 examples/s][A
Generating train examples...:  45%|####4     | 14132/31500 [00:43<01:15, 230.81 examples/s][A
Generating train examples...:  45%|####4     | 14160/31500 [00:43<01:15, 229.47 examples/s][A
Generating train examples...:  45%|####5     | 14186/31500 [00:43<01:15, 229.42 examples/s][A
Generating train examples...:  45%|####5     | 14212/31500 [00:43<01:29, 193.99 examples/s][A
Generating train examples...:  45%|####5     | 14234/31500 [00:43<01:32, 186.63 examples/s][A
Generating train examples...:  45%|####5     | 14254/31500 [00:44<01:37, 177.69 examples/s][A
Generating train examples...:  45%|####5     | 14302/31500 [00:44<01:10, 243.83 examples/s][A
Generating train examples...:  46%|####5     | 14339/31500 [00:44<01:04, 265.34 examples/s][A
Generating train examples...:  46%|####5     | 14373/31500 [00:44<01:01, 277.23 examples/s][A
Generating train examples...:  46%|####5     | 14404/31500 [00:44<01:01, 279.71 examples/s][A
Generating train examples...:  46%|####5     | 14470/31500 [00:44<00:44, 380.42 examples/s][A
Generating train examples...:  46%|####6     | 14528/31500 [00:44<00:40, 421.37 examples/s][A
Generating train examples...:  46%|####6     | 14572/31500 [00:44<00:42, 397.48 examples/s][A
Generating train examples...:  46%|####6     | 14621/31500 [00:44<00:39, 422.20 examples/s][A
Generating train examples...:  47%|####6     | 14665/31500 [00:45<00:51, 326.39 examples/s][A
Generating train examples...:  47%|####6     | 14702/31500 [00:45<01:07, 247.58 examples/s][A
Generating train examples...:  47%|####6     | 14792/31500 [00:45<00:44, 374.98 examples/s][A
Generating train examples...:  47%|####7     | 14897/31500 [00:45<00:31, 521.71 examples/s][A
Generating train examples...:  48%|####7     | 15003/31500 [00:45<00:25, 649.16 examples/s][A
Generating train examples...:  48%|####7     | 15115/31500 [00:45<00:21, 767.10 examples/s][A
Generating train examples...:  48%|####8     | 15226/31500 [00:45<00:18, 857.46 examples/s][A
Generating train examples...:  49%|####8     | 15338/31500 [00:46<00:17, 929.08 examples/s][A
Generating train examples...:  49%|####9     | 15438/31500 [00:46<00:38, 419.15 examples/s][A
Generating train examples...:  49%|####9     | 15514/31500 [00:47<00:52, 304.61 examples/s][A
Generating train examples...:  49%|####9     | 15572/31500 [00:47<00:57, 275.70 examples/s][A
Generating train examples...:  50%|####9     | 15619/31500 [00:47<00:59, 267.36 examples/s][A
Generating train examples...:  50%|####9     | 15659/31500 [00:47<01:05, 242.33 examples/s][A
Generating train examples...:  50%|####9     | 15695/31500 [00:47<01:01, 256.95 examples/s][A
Generating train examples...:  50%|####9     | 15729/31500 [00:47<00:59, 267.21 examples/s][A
Generating train examples...:  50%|#####     | 15762/31500 [00:48<01:01, 257.24 examples/s][A
Generating train examples...:  50%|#####     | 15792/31500 [00:48<01:04, 241.72 examples/s][A
Generating train examples...:  50%|#####     | 15819/31500 [00:48<01:07, 233.39 examples/s][A
Generating train examples...:  50%|#####     | 15855/31500 [00:48<01:00, 259.56 examples/s][A
Generating train examples...:  50%|#####     | 15884/31500 [00:48<00:58, 265.39 examples/s][A
Generating train examples...:  51%|#####     | 15913/31500 [00:48<01:00, 256.14 examples/s][A
Generating train examples...:  51%|#####     | 15940/31500 [00:48<01:03, 245.64 examples/s][A
Generating train examples...:  51%|#####     | 15970/31500 [00:48<01:01, 252.33 examples/s][A
Generating train examples...:  51%|#####     | 15996/31500 [00:49<01:07, 228.23 examples/s][A
Generating train examples...:  51%|#####     | 16041/31500 [00:49<00:55, 278.21 examples/s][A
Generating train examples...:  51%|#####1    | 16070/31500 [00:49<00:55, 277.28 examples/s][A
Generating train examples...:  51%|#####1    | 16099/31500 [00:49<01:14, 207.60 examples/s][A
Generating train examples...:  51%|#####1    | 16123/31500 [00:49<01:32, 165.54 examples/s][A
Generating train examples...:  52%|#####1    | 16224/31500 [00:49<00:46, 329.95 examples/s][A
Generating train examples...:  52%|#####1    | 16324/31500 [00:49<00:31, 475.47 examples/s][A
Generating train examples...:  52%|#####2    | 16385/31500 [00:50<00:30, 499.79 examples/s][A
Generating train examples...:  52%|#####2    | 16490/31500 [00:50<00:23, 629.13 examples/s][A
Generating train examples...:  53%|#####2    | 16562/31500 [00:50<00:25, 592.92 examples/s][A
Generating train examples...:  53%|#####2    | 16632/31500 [00:50<00:24, 619.29 examples/s][A
Generating train examples...:  53%|#####3    | 16753/31500 [00:50<00:19, 775.33 examples/s][A
Generating train examples...:  53%|#####3    | 16837/31500 [00:50<00:34, 423.30 examples/s][A
Generating train examples...:  54%|#####3    | 16902/31500 [00:51<00:33, 439.02 examples/s][A
Generating train examples...:  54%|#####3    | 16962/31500 [00:51<00:33, 428.57 examples/s][A
Generating train examples...:  54%|#####4    | 17016/31500 [00:51<00:34, 424.60 examples/s][A
Generating train examples...:  54%|#####4    | 17108/31500 [00:51<00:27, 528.05 examples/s][A
Generating train examples...:  55%|#####4    | 17196/31500 [00:51<00:23, 608.47 examples/s][A
Generating train examples...:  55%|#####4    | 17266/31500 [00:51<00:30, 464.86 examples/s][A
Generating train examples...:  55%|#####4    | 17324/31500 [00:51<00:30, 466.99 examples/s][A
Generating train examples...:  55%|#####5    | 17398/31500 [00:52<00:26, 526.74 examples/s][A
Generating train examples...:  55%|#####5    | 17459/31500 [00:52<00:31, 448.39 examples/s][A
Generating train examples...:  56%|#####5    | 17511/31500 [00:52<00:38, 366.37 examples/s][A
Generating train examples...:  56%|#####5    | 17555/31500 [00:52<01:04, 216.82 examples/s][A
Generating train examples...:  56%|#####5    | 17589/31500 [00:53<01:26, 161.67 examples/s][A
Generating train examples...:  56%|#####5    | 17615/31500 [00:53<01:27, 158.26 examples/s][A
Generating train examples...:  56%|#####6    | 17680/31500 [00:53<01:01, 224.83 examples/s][A
Generating train examples...:  56%|#####6    | 17762/31500 [00:53<00:42, 321.00 examples/s][A
Generating train examples...:  57%|#####6    | 17811/31500 [00:53<00:39, 350.52 examples/s][A
Generating train examples...:  57%|#####6    | 17861/31500 [00:53<00:36, 372.81 examples/s][A
Generating train examples...:  57%|#####6    | 17933/31500 [00:54<00:30, 451.38 examples/s][A
Generating train examples...:  57%|#####7    | 17998/31500 [00:54<00:27, 499.92 examples/s][A
Generating train examples...:  57%|#####7    | 18072/31500 [00:54<00:23, 561.23 examples/s][A
Generating train examples...:  58%|#####7    | 18135/31500 [00:54<00:23, 560.85 examples/s][A
Generating train examples...:  58%|#####7    | 18201/31500 [00:54<00:31, 428.11 examples/s][A
Generating train examples...:  58%|#####7    | 18252/31500 [00:54<00:38, 340.48 examples/s][A
Generating train examples...:  58%|#####8    | 18294/31500 [00:55<00:46, 281.20 examples/s][A
Generating train examples...:  58%|#####8    | 18376/31500 [00:55<00:34, 375.90 examples/s][A
Generating train examples...:  59%|#####8    | 18429/31500 [00:55<00:32, 400.49 examples/s][A
Generating train examples...:  59%|#####8    | 18479/31500 [00:55<00:30, 420.23 examples/s][A
Generating train examples...:  59%|#####8    | 18532/31500 [00:55<00:29, 433.59 examples/s][A
Generating train examples...:  59%|#####9    | 18589/31500 [00:55<00:28, 460.20 examples/s][A
Generating train examples...:  59%|#####9    | 18639/31500 [00:55<00:27, 466.73 examples/s][A
Generating train examples...:  59%|#####9    | 18689/31500 [00:55<00:33, 378.88 examples/s][A
Generating train examples...:  59%|#####9    | 18732/31500 [00:56<00:32, 390.15 examples/s][A
Generating train examples...:  60%|#####9    | 18796/31500 [00:56<00:29, 437.84 examples/s][A
Generating train examples...:  60%|#####9    | 18845/31500 [00:56<00:28, 451.05 examples/s][A
Generating train examples...:  60%|#####9    | 18893/31500 [00:56<00:32, 389.05 examples/s][A
Generating train examples...:  60%|######    | 18935/31500 [00:56<00:58, 214.61 examples/s][A
Generating train examples...:  60%|######    | 18968/31500 [00:57<01:10, 177.20 examples/s][A
Generating train examples...:  60%|######    | 18994/31500 [00:57<01:10, 178.30 examples/s][A
Generating train examples...:  60%|######    | 19018/31500 [00:57<01:10, 175.81 examples/s][A
Generating train examples...:  60%|######    | 19040/31500 [00:57<01:10, 177.65 examples/s][A
Generating train examples...:  61%|######    | 19067/31500 [00:57<01:03, 195.59 examples/s][A
Generating train examples...:  61%|######    | 19090/31500 [00:57<01:22, 149.73 examples/s][A
Generating train examples...:  61%|######    | 19109/31500 [00:58<01:27, 142.01 examples/s][A
Generating train examples...:  61%|######    | 19126/31500 [00:58<01:28, 140.45 examples/s][A
Generating train examples...:  61%|######    | 19142/31500 [00:58<01:29, 137.65 examples/s][A
Generating train examples...:  61%|######    | 19167/31500 [00:58<01:16, 160.25 examples/s][A
Generating train examples...:  61%|######    | 19194/31500 [00:58<01:06, 185.38 examples/s][A
Generating train examples...:  61%|######1   | 19245/31500 [00:58<00:45, 267.18 examples/s][A
Generating train examples...:  61%|######1   | 19275/31500 [00:58<00:45, 269.62 examples/s][A
Generating train examples...:  61%|######1   | 19307/31500 [00:58<00:43, 277.75 examples/s][A
Generating train examples...:  61%|######1   | 19337/31500 [00:58<00:43, 281.39 examples/s][A
Generating train examples...:  62%|######1   | 19383/31500 [00:59<00:37, 324.81 examples/s][A
Generating train examples...:  62%|######1   | 19421/31500 [00:59<00:37, 323.75 examples/s][A
Generating train examples...:  62%|######1   | 19460/31500 [00:59<00:35, 341.86 examples/s][A
Generating train examples...:  62%|######1   | 19510/31500 [00:59<00:31, 379.72 examples/s][A
Generating train examples...:  62%|######2   | 19549/31500 [00:59<00:32, 370.83 examples/s][A
Generating train examples...:  62%|######2   | 19601/31500 [00:59<00:34, 349.68 examples/s][A
Generating train examples...:  63%|######2   | 19719/31500 [00:59<00:21, 560.77 examples/s][A
Generating train examples...:  63%|######2   | 19842/31500 [00:59<00:15, 738.97 examples/s][A
Generating train examples...:  63%|######3   | 19966/31500 [00:59<00:13, 875.04 examples/s][A
Generating train examples...:  64%|######3   | 20088/31500 [01:00<00:11, 970.74 examples/s][A
Generating train examples...:  64%|######4   | 20208/31500 [01:00<00:10, 1034.25 examples/s][A
Generating train examples...:  64%|######4   | 20315/31500 [01:00<00:12, 869.65 examples/s] [A
Generating train examples...:  65%|######4   | 20439/31500 [01:00<00:11, 963.98 examples/s][A
Generating train examples...:  65%|######5   | 20562/31500 [01:00<00:10, 1034.77 examples/s][A
Generating train examples...:  66%|######5   | 20682/31500 [01:00<00:10, 1078.56 examples/s][A
Generating train examples...:  66%|######6   | 20803/31500 [01:00<00:09, 1113.30 examples/s][A
Generating train examples...:  66%|######6   | 20925/31500 [01:00<00:09, 1142.42 examples/s][A
Generating train examples...:  67%|######6   | 21042/31500 [01:01<00:13, 767.70 examples/s] [A
Generating train examples...:  67%|######7   | 21137/31500 [01:01<00:14, 702.52 examples/s][A
Generating train examples...:  67%|######7   | 21220/31500 [01:01<00:16, 641.63 examples/s][A
Generating train examples...:  68%|######7   | 21294/31500 [01:01<00:16, 637.70 examples/s][A
Generating train examples...:  68%|######7   | 21365/31500 [01:01<00:18, 557.70 examples/s][A
Generating train examples...:  68%|######8   | 21427/31500 [01:01<00:18, 531.57 examples/s][A
Generating train examples...:  68%|######8   | 21484/31500 [01:01<00:20, 495.68 examples/s][A
Generating train examples...:  68%|######8   | 21536/31500 [01:02<00:25, 394.71 examples/s][A
Generating train examples...:  69%|######8   | 21585/31500 [01:02<00:23, 413.47 examples/s][A
Generating train examples...:  69%|######8   | 21631/31500 [01:02<00:23, 423.05 examples/s][A
Generating train examples...:  69%|######8   | 21677/31500 [01:02<00:24, 401.70 examples/s][A
Generating train examples...:  69%|######8   | 21720/31500 [01:02<00:25, 387.74 examples/s][A
Generating train examples...:  69%|######9   | 21788/31500 [01:02<00:21, 460.23 examples/s][A
Generating train examples...:  69%|######9   | 21880/31500 [01:02<00:16, 579.75 examples/s][A
Generating train examples...:  70%|######9   | 21969/31500 [01:02<00:15, 632.98 examples/s][A
Generating train examples...:  70%|#######   | 22071/31500 [01:03<00:12, 736.87 examples/s][A
Generating train examples...:  70%|#######   | 22151/31500 [01:03<00:12, 752.81 examples/s][A
Generating train examples...:  71%|#######   | 22259/31500 [01:03<00:10, 843.79 examples/s][A
Generating train examples...:  71%|#######   | 22350/31500 [01:03<00:10, 855.33 examples/s][A
Generating train examples...:  71%|#######1  | 22437/31500 [01:03<00:22, 406.17 examples/s][A
Generating train examples...:  71%|#######1  | 22504/31500 [01:04<00:28, 311.97 examples/s][A
Generating train examples...:  72%|#######1  | 22556/31500 [01:04<00:29, 306.44 examples/s][A
Generating train examples...:  72%|#######1  | 22601/31500 [01:04<00:32, 276.69 examples/s][A
Generating train examples...:  72%|#######1  | 22642/31500 [01:04<00:30, 286.58 examples/s][A
Generating train examples...:  72%|#######2  | 22683/31500 [01:04<00:29, 300.40 examples/s][A
Generating train examples...:  72%|#######2  | 22719/31500 [01:05<00:29, 294.82 examples/s][A
Generating train examples...:  72%|#######2  | 22753/31500 [01:05<00:30, 285.72 examples/s][A
Generating train examples...:  72%|#######2  | 22785/31500 [01:05<00:30, 289.11 examples/s][A
Generating train examples...:  72%|#######2  | 22821/31500 [01:05<00:28, 304.82 examples/s][A
Generating train examples...:  73%|#######2  | 22854/31500 [01:05<00:31, 278.39 examples/s][A
Generating train examples...:  73%|#######2  | 22884/31500 [01:05<00:36, 232.95 examples/s][A
Generating train examples...:  73%|#######2  | 22910/31500 [01:05<00:36, 237.40 examples/s][A
Generating train examples...:  73%|#######2  | 22941/31500 [01:05<00:33, 254.14 examples/s][A
Generating train examples...:  73%|#######2  | 22989/31500 [01:05<00:27, 311.05 examples/s][A
Generating train examples...:  73%|#######3  | 23023/31500 [01:06<00:29, 289.88 examples/s][A
Generating train examples...:  73%|#######3  | 23064/31500 [01:06<00:27, 311.54 examples/s][A
Generating train examples...:  73%|#######3  | 23101/31500 [01:06<00:37, 224.11 examples/s][A
Generating train examples...:  73%|#######3  | 23128/31500 [01:06<00:45, 184.61 examples/s][A
Generating train examples...:  73%|#######3  | 23151/31500 [01:06<00:46, 180.88 examples/s][A
Generating train examples...:  74%|#######3  | 23172/31500 [01:07<00:53, 156.37 examples/s][A
Generating train examples...:  74%|#######3  | 23190/31500 [01:07<00:56, 146.81 examples/s][A
Generating train examples...:  74%|#######3  | 23209/31500 [01:07<00:53, 154.12 examples/s][A
Generating train examples...:  74%|#######3  | 23228/31500 [01:07<00:51, 160.61 examples/s][A
Generating train examples...:  74%|#######3  | 23246/31500 [01:07<00:53, 154.59 examples/s][A
Generating train examples...:  74%|#######3  | 23263/31500 [01:07<00:56, 146.71 examples/s][A
Generating train examples...:  74%|#######3  | 23279/31500 [01:07<00:56, 145.97 examples/s][A
Generating train examples...:  74%|#######3  | 23294/31500 [01:07<01:00, 134.76 examples/s][A
Generating train examples...:  74%|#######3  | 23308/31500 [01:08<01:00, 135.75 examples/s][A
Generating train examples...:  74%|#######4  | 23328/31500 [01:08<00:53, 152.15 examples/s][A
Generating train examples...:  74%|#######4  | 23344/31500 [01:08<01:08, 119.71 examples/s][A
Generating train examples...:  74%|#######4  | 23366/31500 [01:08<00:57, 142.64 examples/s][A
Generating train examples...:  74%|#######4  | 23382/31500 [01:08<00:59, 135.36 examples/s][A
Generating train examples...:  74%|#######4  | 23404/31500 [01:08<00:52, 155.67 examples/s][A
Generating train examples...:  74%|#######4  | 23426/31500 [01:08<00:50, 158.59 examples/s][A
Generating train examples...:  74%|#######4  | 23443/31500 [01:08<00:58, 138.40 examples/s][A
Generating train examples...:  74%|#######4  | 23459/31500 [01:09<00:57, 138.76 examples/s][A
Generating train examples...:  75%|#######4  | 23484/31500 [01:09<00:48, 165.82 examples/s][A
Generating train examples...:  75%|#######4  | 23507/31500 [01:09<00:43, 182.32 examples/s][A
Generating train examples...:  75%|#######4  | 23536/31500 [01:09<00:38, 208.94 examples/s][A
Generating train examples...:  75%|#######4  | 23562/31500 [01:09<00:36, 218.92 examples/s][A
Generating train examples...:  75%|#######4  | 23591/31500 [01:09<00:33, 235.71 examples/s][A
Generating train examples...:  75%|#######4  | 23619/31500 [01:09<00:32, 245.69 examples/s][A
Generating train examples...:  75%|#######5  | 23655/31500 [01:09<00:28, 277.61 examples/s][A
Generating train examples...:  75%|#######5  | 23690/31500 [01:09<00:26, 298.01 examples/s][A
Generating train examples...:  75%|#######5  | 23721/31500 [01:10<00:26, 288.68 examples/s][A
Generating train examples...:  75%|#######5  | 23753/31500 [01:10<00:26, 295.81 examples/s][A
Generating train examples...:  76%|#######5  | 23783/31500 [01:10<00:30, 257.15 examples/s][A
Generating train examples...:  76%|#######5  | 23810/31500 [01:10<00:39, 194.53 examples/s][A
Generating train examples...:  76%|#######5  | 23901/31500 [01:10<00:21, 351.21 examples/s][A
Generating train examples...:  76%|#######6  | 23973/31500 [01:10<00:17, 418.97 examples/s][A
Generating train examples...:  76%|#######6  | 24063/31500 [01:10<00:13, 536.42 examples/s][A
Generating train examples...:  77%|#######6  | 24185/31500 [01:10<00:10, 712.27 examples/s][A
Generating train examples...:  77%|#######7  | 24303/31500 [01:11<00:08, 837.06 examples/s][A
Generating train examples...:  77%|#######7  | 24394/31500 [01:11<00:11, 616.78 examples/s][A
Generating train examples...:  78%|#######7  | 24501/31500 [01:11<00:11, 615.71 examples/s][A
Generating train examples...:  78%|#######8  | 24572/31500 [01:11<00:13, 525.53 examples/s][A
Generating train examples...:  78%|#######8  | 24633/31500 [01:11<00:13, 504.85 examples/s][A
Generating train examples...:  78%|#######8  | 24689/31500 [01:11<00:14, 458.09 examples/s][A
Generating train examples...:  79%|#######8  | 24739/31500 [01:12<00:19, 350.08 examples/s][A
Generating train examples...:  79%|#######8  | 24780/31500 [01:12<00:22, 298.30 examples/s][A
Generating train examples...:  79%|#######8  | 24839/31500 [01:12<00:19, 337.59 examples/s][A
Generating train examples...:  79%|#######9  | 24889/31500 [01:12<00:18, 360.71 examples/s][A
Generating train examples...:  79%|#######9  | 24953/31500 [01:12<00:15, 417.78 examples/s][A
Generating train examples...:  79%|#######9  | 25000/31500 [01:12<00:17, 369.92 examples/s][A
Generating train examples...:  80%|#######9  | 25053/31500 [01:13<00:15, 403.93 examples/s][A
Generating train examples...:  80%|#######9  | 25098/31500 [01:13<00:15, 401.02 examples/s][A
Generating train examples...:  80%|#######9  | 25141/31500 [01:13<00:15, 399.01 examples/s][A
Generating train examples...:  80%|########  | 25201/31500 [01:13<00:18, 338.17 examples/s][A
Generating train examples...:  80%|########  | 25239/31500 [01:13<00:18, 336.52 examples/s][A
Generating train examples...:  80%|########  | 25275/31500 [01:13<00:18, 340.92 examples/s][A
Generating train examples...:  80%|########  | 25349/31500 [01:13<00:14, 438.52 examples/s][A
Generating train examples...:  81%|########  | 25406/31500 [01:13<00:12, 471.59 examples/s][A
Generating train examples...:  81%|########  | 25456/31500 [01:14<00:14, 425.10 examples/s][A
Generating train examples...:  81%|########  | 25502/31500 [01:14<00:16, 370.06 examples/s][A
Generating train examples...:  81%|########1 | 25542/31500 [01:14<00:20, 295.08 examples/s][A
Generating train examples...:  81%|########1 | 25586/31500 [01:14<00:18, 325.04 examples/s][A
Generating train examples...:  81%|########1 | 25634/31500 [01:14<00:16, 359.76 examples/s][A
Generating train examples...:  82%|########1 | 25689/31500 [01:14<00:14, 405.82 examples/s][A
Generating train examples...:  82%|########1 | 25787/31500 [01:14<00:10, 555.25 examples/s][A
Generating train examples...:  82%|########2 | 25852/31500 [01:14<00:09, 571.37 examples/s][A
Generating train examples...:  82%|########2 | 25913/31500 [01:15<00:17, 310.45 examples/s][A
Generating train examples...:  82%|########2 | 25960/31500 [01:15<00:23, 238.20 examples/s][A
Generating train examples...:  83%|########2 | 25997/31500 [01:15<00:25, 212.03 examples/s][A
Generating train examples...:  83%|########2 | 26028/31500 [01:16<00:29, 184.58 examples/s][A
Generating train examples...:  83%|########2 | 26053/31500 [01:16<00:30, 178.46 examples/s][A
Generating train examples...:  83%|########2 | 26076/31500 [01:16<00:38, 141.76 examples/s][A
Generating train examples...:  83%|########2 | 26094/31500 [01:16<00:38, 138.77 examples/s][A
Generating train examples...:  83%|########2 | 26111/31500 [01:16<00:42, 125.46 examples/s][A
Generating train examples...:  83%|########2 | 26126/31500 [01:17<00:44, 120.21 examples/s][A
Generating train examples...:  83%|########2 | 26139/31500 [01:17<00:51, 103.40 examples/s][A
Generating train examples...:  83%|########3 | 26151/31500 [01:17<00:51, 103.64 examples/s][A
Generating train examples...:  83%|########3 | 26162/31500 [01:17<00:58, 90.91 examples/s] [A
Generating train examples...:  83%|########3 | 26172/31500 [01:17<00:59, 90.12 examples/s][A
Generating train examples...:  83%|########3 | 26185/31500 [01:17<00:53, 98.63 examples/s][A
Generating train examples...:  83%|########3 | 26200/31500 [01:17<00:48, 110.08 examples/s][A
Generating train examples...:  83%|########3 | 26212/31500 [01:18<00:51, 101.85 examples/s][A
Generating train examples...:  83%|########3 | 26226/31500 [01:18<00:47, 110.73 examples/s][A
Generating train examples...:  83%|########3 | 26238/31500 [01:18<00:48, 108.02 examples/s][A
Generating train examples...:  83%|########3 | 26254/31500 [01:18<00:43, 120.71 examples/s][A
Generating train examples...:  83%|########3 | 26270/31500 [01:18<00:40, 129.97 examples/s][A
Generating train examples...:  83%|########3 | 26284/31500 [01:18<00:41, 124.67 examples/s][A
Generating train examples...:  83%|########3 | 26297/31500 [01:18<00:49, 105.36 examples/s][A
Generating train examples...:  84%|########3 | 26321/31500 [01:18<00:37, 137.17 examples/s][A
Generating train examples...:  84%|########3 | 26358/31500 [01:19<00:27, 188.20 examples/s][A
Generating train examples...:  84%|########3 | 26379/31500 [01:19<00:26, 193.84 examples/s][A
Generating train examples...:  84%|########3 | 26411/31500 [01:19<00:23, 220.53 examples/s][A
Generating train examples...:  84%|########3 | 26434/31500 [01:19<00:24, 207.16 examples/s][A
Generating train examples...:  84%|########3 | 26456/31500 [01:19<00:24, 208.59 examples/s][A
Generating train examples...:  84%|########4 | 26478/31500 [01:19<00:24, 205.81 examples/s][A
Generating train examples...:  84%|########4 | 26519/31500 [01:19<00:19, 254.37 examples/s][A
Generating train examples...:  84%|########4 | 26545/31500 [01:19<00:22, 223.76 examples/s][A
Generating train examples...:  84%|########4 | 26579/31500 [01:19<00:20, 245.35 examples/s][A
Generating train examples...:  84%|########4 | 26605/31500 [01:20<00:26, 182.74 examples/s][A
Generating train examples...:  85%|########4 | 26706/31500 [01:20<00:13, 360.12 examples/s][A
Generating train examples...:  85%|########5 | 26781/31500 [01:20<00:10, 449.32 examples/s][A
Generating train examples...:  85%|########5 | 26886/31500 [01:20<00:07, 583.31 examples/s][A
Generating train examples...:  86%|########5 | 26956/31500 [01:20<00:07, 589.83 examples/s][A
Generating train examples...:  86%|########5 | 27030/31500 [01:20<00:07, 590.75 examples/s][A
Generating train examples...:  86%|########6 | 27093/31500 [01:20<00:07, 575.01 examples/s][A
Generating train examples...:  86%|########6 | 27153/31500 [01:21<00:08, 499.54 examples/s][A
Generating train examples...:  86%|########6 | 27207/31500 [01:21<00:08, 498.14 examples/s][A
Generating train examples...:  87%|########6 | 27259/31500 [01:21<00:08, 487.20 examples/s][A
Generating train examples...:  87%|########6 | 27310/31500 [01:21<00:14, 299.25 examples/s][A
Generating train examples...:  87%|########6 | 27350/31500 [01:21<00:14, 278.53 examples/s][A
Generating train examples...:  87%|########6 | 27385/31500 [01:21<00:15, 269.49 examples/s][A
Generating train examples...:  87%|########7 | 27418/31500 [01:22<00:15, 270.72 examples/s][A
Generating train examples...:  87%|########7 | 27479/31500 [01:22<00:11, 340.84 examples/s][A
Generating train examples...:  87%|########7 | 27528/31500 [01:22<00:10, 370.84 examples/s][A
Generating train examples...:  88%|########7 | 27570/31500 [01:22<00:14, 277.45 examples/s][A
Generating train examples...:  88%|########7 | 27604/31500 [01:22<00:14, 260.73 examples/s][A
Generating train examples...:  88%|########7 | 27636/31500 [01:22<00:14, 271.07 examples/s][A
Generating train examples...:  88%|########7 | 27667/31500 [01:22<00:15, 249.56 examples/s][A
Generating train examples...:  88%|########7 | 27695/31500 [01:23<00:14, 254.00 examples/s][A
Generating train examples...:  88%|########8 | 27723/31500 [01:23<00:15, 246.43 examples/s][A
Generating train examples...:  88%|########8 | 27755/31500 [01:23<00:14, 261.95 examples/s][A
Generating train examples...:  88%|########8 | 27784/31500 [01:23<00:13, 268.98 examples/s][A
Generating train examples...:  88%|########8 | 27812/31500 [01:23<00:14, 254.18 examples/s][A
Generating train examples...:  88%|########8 | 27844/31500 [01:23<00:13, 269.08 examples/s][A
Generating train examples...:  89%|########8 | 27883/31500 [01:23<00:11, 301.96 examples/s][A
Generating train examples...:  89%|########8 | 27914/31500 [01:23<00:11, 301.32 examples/s][A
Generating train examples...:  89%|########8 | 27946/31500 [01:23<00:11, 301.48 examples/s][A
Generating train examples...:  89%|########8 | 27984/31500 [01:24<00:11, 313.60 examples/s][A
Generating train examples...:  89%|########8 | 28016/31500 [01:24<00:15, 222.19 examples/s][A
Generating train examples...:  89%|########9 | 28042/31500 [01:24<00:18, 188.70 examples/s][A
Generating train examples...:  89%|########9 | 28065/31500 [01:24<00:19, 180.53 examples/s][A
Generating train examples...:  89%|########9 | 28086/31500 [01:24<00:19, 176.46 examples/s][A
Generating train examples...:  89%|########9 | 28107/31500 [01:24<00:18, 181.62 examples/s][A
Generating train examples...:  89%|########9 | 28164/31500 [01:24<00:12, 273.84 examples/s][A
Generating train examples...:  90%|########9 | 28267/31500 [01:25<00:06, 465.84 examples/s][A
Generating train examples...:  90%|######### | 28383/31500 [01:25<00:04, 626.79 examples/s][A
Generating train examples...:  90%|######### | 28473/31500 [01:25<00:04, 699.09 examples/s][A
Generating train examples...:  91%|######### | 28602/31500 [01:25<00:03, 861.68 examples/s][A
Generating train examples...:  91%|#########1| 28701/31500 [01:25<00:03, 723.24 examples/s][A
Generating train examples...:  91%|#########1| 28781/31500 [01:25<00:03, 707.48 examples/s][A
Generating train examples...:  92%|#########1| 28909/31500 [01:25<00:03, 850.19 examples/s][A
Generating train examples...:  92%|#########2| 29035/31500 [01:25<00:02, 957.49 examples/s][A
Generating train examples...:  93%|#########2| 29159/31500 [01:25<00:02, 1033.56 examples/s][A
Generating train examples...:  93%|#########2| 29272/31500 [01:26<00:02, 1060.01 examples/s][A
Generating train examples...:  93%|#########3| 29382/31500 [01:26<00:02, 1031.87 examples/s][A
Generating train examples...:  94%|#########3| 29488/31500 [01:26<00:03, 573.85 examples/s] [A
Generating train examples...:  94%|#########3| 29590/31500 [01:26<00:02, 648.98 examples/s][A
Generating train examples...:  94%|#########4| 29677/31500 [01:26<00:02, 670.62 examples/s][A
Generating train examples...:  94%|#########4| 29760/31500 [01:26<00:02, 686.21 examples/s][A
Generating train examples...:  95%|#########4| 29870/31500 [01:26<00:02, 782.90 examples/s][A
Generating train examples...:  95%|#########5| 29960/31500 [01:27<00:01, 777.66 examples/s][A
Generating train examples...:  95%|#########5| 30056/31500 [01:27<00:01, 780.82 examples/s][A
Generating train examples...:  96%|#########5| 30140/31500 [01:27<00:03, 407.95 examples/s][A
Generating train examples...:  96%|#########5| 30204/31500 [01:27<00:03, 365.33 examples/s][A
Generating train examples...:  96%|#########6| 30257/31500 [01:28<00:03, 368.19 examples/s][A
Generating train examples...:  96%|#########6| 30309/31500 [01:28<00:03, 394.41 examples/s][A
Generating train examples...:  96%|#########6| 30359/31500 [01:28<00:02, 401.45 examples/s][A
Generating train examples...:  97%|#########6| 30407/31500 [01:28<00:02, 376.98 examples/s][A
Generating train examples...:  97%|#########6| 30458/31500 [01:28<00:02, 405.68 examples/s][A
Generating train examples...:  97%|#########6| 30520/31500 [01:28<00:02, 448.01 examples/s][A
Generating train examples...:  97%|#########7| 30589/31500 [01:28<00:01, 503.99 examples/s][A
Generating train examples...:  97%|#########7| 30657/31500 [01:28<00:01, 549.44 examples/s][A
Generating train examples...:  98%|#########7| 30716/31500 [01:28<00:01, 505.40 examples/s][A
Generating train examples...:  98%|#########7| 30770/31500 [01:29<00:01, 475.76 examples/s][A
Generating train examples...:  98%|#########7| 30820/31500 [01:29<00:01, 377.69 examples/s][A
Generating train examples...:  98%|#########8| 30882/31500 [01:29<00:01, 431.09 examples/s][A
Generating train examples...:  98%|#########8| 30951/31500 [01:29<00:01, 487.76 examples/s][A
Generating train examples...:  98%|#########8| 31005/31500 [01:29<00:01, 429.31 examples/s][A
Generating train examples...:  99%|#########8| 31109/31500 [01:29<00:00, 564.33 examples/s][A
Generating train examples...:  99%|#########9| 31190/31500 [01:29<00:00, 625.40 examples/s][A
Generating train examples...:  99%|#########9| 31296/31500 [01:30<00:00, 738.59 examples/s][A
Generating train examples...: 100%|#########9| 31401/31500 [01:30<00:00, 822.55 examples/s][A
Generating train examples...: 100%|#########9| 31488/31500 [01:30<00:00, 782.71 examples/s][A
                                                                                           [A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:   0%|          | 0/31500 [00:00<?, ? examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  14%|#3        | 4350/31500 [00:00<00:00, 43495.37 examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  28%|##7       | 8700/31500 [00:00<00:00, 31477.92 examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  45%|####5     | 14209/31500 [00:00<00:00, 40406.00 examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  59%|#####8    | 18541/31500 [00:00<00:00, 35007.51 examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  75%|#######5  | 23625/31500 [00:00<00:00, 33310.26 examples/s][A
Shuffling visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*...:  93%|#########2| 29203/31500 [00:00<00:00, 39213.07 examples/s][A
                                                                                                                                                                     [A[INFO: writer.py:  305]: Done writing visual_prompt_tuning/data_path/resisc45/3.0.0.incompleteA0SLY4/resisc45-train.tfrecord*. Number of examples: 31500 (shards: [7875, 7875, 7875, 7875])
Generating splits...: 100%|##########| 1/1 [01:31<00:00, 91.18s/ splits]                                                                        2023-09-15 17:07:36.636627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Dataset resisc45 downloaded and prepared to visual_prompt_tuning/data_path/resisc45/3.0.0. Subsequent calls will reuse this data.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[:800]+train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:07:38 visual_prompt]: Number of images: 1000
[09/15 17:07:38 visual_prompt]: Number of classes: 45 / 45
[09/15 17:07:38 visual_prompt]: Loading validation data...
[09/15 17:07:38 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:07:39 visual_prompt]: Number of images: 200
[09/15 17:07:39 visual_prompt]: Number of classes: 45 / 45
[09/15 17:07:39 visual_prompt]: Loading test data...
[09/15 17:07:39 visual_prompt]: Constructing vtab-resisc45 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[25200:], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:07:49 visual_prompt]: Number of images: 6300
[09/15 17:07:49 visual_prompt]: Number of classes: 45 / 45
[09/15 17:07:49 visual_prompt]: Constructing models...
[09/15 17:07:53 visual_prompt]: Total Parameters: 86754861	 Gradient Parameters: 956205
[09/15 17:07:53 visual_prompt]: tuned percent:1.102
[09/15 17:07:55 visual_prompt]: Device used for model: 0
[09/15 17:07:55 visual_prompt]: Setting up Evalutator...
[09/15 17:07:55 visual_prompt]: Setting up Trainer...
[09/15 17:07:55 visual_prompt]: 	Setting up the optimizer...
[09/15 17:07:55 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 124, in main
    train(cfg, args)
  File "visual_prompt_tuning/train.py", line 109, in train
    trainer.train_classifier(train_loader, val_loader, test_loader)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 185, in train_classifier
    train_loss, _ = self.forward_one_batch(X, targets, True)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 86, in forward_one_batch
    outputs = self.model(inputs)  # (batchsize, num_cls)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_models.py", line 175, in forward
    x = self.enc(x)  # batch_size x self.feat_dim
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 161, in forward
    x, attn_weights = self.transformer(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 138, in forward
    embedding_output)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 124, in forward_deep_prompt
    hidden_states, weights = self.encoder.layer[i](hidden_states)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 199, in forward
    x, weights = self.attn(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 106, in forward
    context_layer = torch.matmul(attention_probs, value_layer) # B, num_head, num_patches, head_size
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 11.91 GiB total capacity; 11.00 GiB already allocated; 14.94 MiB free; 11.11 GiB reserved in total by PyTorch)
[09/15 17:08:30 visual_prompt]: Rank of current process: 0. World size: 1
[09/15 17:08:30 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2,3
GPU 0,1              NVIDIA TITAN X (Pascal)
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/15 17:08:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed44'], train_type='')
[09/15 17:08:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/15 17:08:30 visual_prompt]: Training with config:
[09/15 17:08:30 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-resisc45',
          'NO_TEST': False,
          'NUMBER_CLASSES': 45,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed44/vtab-resisc45/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/15 17:08:30 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-15 17:08:30.564885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-15 17:08:31.846986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:08:31.847108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:08:31.847124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-15 17:08:34.340638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:08:34.340798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:08:34.340827: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/15 17:08:34 visual_prompt]: Constructing vtab-resisc45 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
2023-09-15 17:08:34.361018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[:800]+train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:08:36 visual_prompt]: Number of images: 1000
[09/15 17:08:36 visual_prompt]: Number of classes: 45 / 45
[09/15 17:08:36 visual_prompt]: Loading validation data...
[09/15 17:08:36 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:08:37 visual_prompt]: Number of images: 200
[09/15 17:08:37 visual_prompt]: Number of classes: 45 / 45
[09/15 17:08:37 visual_prompt]: Loading test data...
[09/15 17:08:37 visual_prompt]: Constructing vtab-resisc45 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[25200:], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:08:47 visual_prompt]: Number of images: 6300
[09/15 17:08:47 visual_prompt]: Number of classes: 45 / 45
[09/15 17:08:47 visual_prompt]: Constructing models...
[09/15 17:08:51 visual_prompt]: Total Parameters: 86754861	 Gradient Parameters: 956205
[09/15 17:08:51 visual_prompt]: tuned percent:1.102
[09/15 17:08:53 visual_prompt]: Device used for model: 0
[09/15 17:08:53 visual_prompt]: Setting up Evalutator...
[09/15 17:08:53 visual_prompt]: Setting up Trainer...
[09/15 17:08:53 visual_prompt]: 	Setting up the optimizer...
[09/15 17:08:53 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 124, in main
    train(cfg, args)
  File "visual_prompt_tuning/train.py", line 109, in train
    trainer.train_classifier(train_loader, val_loader, test_loader)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 185, in train_classifier
    train_loss, _ = self.forward_one_batch(X, targets, True)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 86, in forward_one_batch
    outputs = self.model(inputs)  # (batchsize, num_cls)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_models.py", line 175, in forward
    x = self.enc(x)  # batch_size x self.feat_dim
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 161, in forward
    x, attn_weights = self.transformer(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 138, in forward
    embedding_output)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 124, in forward_deep_prompt
    hidden_states, weights = self.encoder.layer[i](hidden_states)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 199, in forward
    x, weights = self.attn(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 106, in forward
    context_layer = torch.matmul(attention_probs, value_layer) # B, num_head, num_patches, head_size
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 11.91 GiB total capacity; 11.00 GiB already allocated; 14.94 MiB free; 11.11 GiB reserved in total by PyTorch)
[09/15 17:09:28 visual_prompt]: Rank of current process: 0. World size: 1
[09/15 17:09:28 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2,3
GPU 0,1              NVIDIA TITAN X (Pascal)
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/15 17:09:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed82'], train_type='')
[09/15 17:09:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/15 17:09:28 visual_prompt]: Training with config:
[09/15 17:09:28 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-resisc45',
          'NO_TEST': False,
          'NUMBER_CLASSES': 45,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed82/vtab-resisc45/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/15 17:09:28 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-15 17:09:28.743176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-15 17:09:29.958635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:09:29.958755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:09:29.958769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-15 17:09:32.225253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:09:32.225414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:09:32.225445: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/15 17:09:32 visual_prompt]: Constructing vtab-resisc45 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
2023-09-15 17:09:32.246228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[:800]+train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:09:34 visual_prompt]: Number of images: 1000
[09/15 17:09:34 visual_prompt]: Number of classes: 45 / 45
[09/15 17:09:34 visual_prompt]: Loading validation data...
[09/15 17:09:34 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:09:35 visual_prompt]: Number of images: 200
[09/15 17:09:35 visual_prompt]: Number of classes: 45 / 45
[09/15 17:09:35 visual_prompt]: Loading test data...
[09/15 17:09:35 visual_prompt]: Constructing vtab-resisc45 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[25200:], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:09:45 visual_prompt]: Number of images: 6300
[09/15 17:09:45 visual_prompt]: Number of classes: 45 / 45
[09/15 17:09:45 visual_prompt]: Constructing models...
[09/15 17:09:48 visual_prompt]: Total Parameters: 86754861	 Gradient Parameters: 956205
[09/15 17:09:48 visual_prompt]: tuned percent:1.102
[09/15 17:09:51 visual_prompt]: Device used for model: 0
[09/15 17:09:51 visual_prompt]: Setting up Evalutator...
[09/15 17:09:51 visual_prompt]: Setting up Trainer...
[09/15 17:09:51 visual_prompt]: 	Setting up the optimizer...
[09/15 17:09:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 124, in main
    train(cfg, args)
  File "visual_prompt_tuning/train.py", line 109, in train
    trainer.train_classifier(train_loader, val_loader, test_loader)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 185, in train_classifier
    train_loss, _ = self.forward_one_batch(X, targets, True)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 86, in forward_one_batch
    outputs = self.model(inputs)  # (batchsize, num_cls)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_models.py", line 175, in forward
    x = self.enc(x)  # batch_size x self.feat_dim
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 161, in forward
    x, attn_weights = self.transformer(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 138, in forward
    embedding_output)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 124, in forward_deep_prompt
    hidden_states, weights = self.encoder.layer[i](hidden_states)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 199, in forward
    x, weights = self.attn(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 106, in forward
    context_layer = torch.matmul(attention_probs, value_layer) # B, num_head, num_patches, head_size
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 11.91 GiB total capacity; 11.00 GiB already allocated; 14.94 MiB free; 11.11 GiB reserved in total by PyTorch)
[09/15 17:10:16 visual_prompt]: Rank of current process: 0. World size: 1
[09/15 17:10:16 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2,3
GPU 0,1              NVIDIA TITAN X (Pascal)
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/15 17:10:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed100'], train_type='')
[09/15 17:10:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/15 17:10:16 visual_prompt]: Training with config:
[09/15 17:10:16 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-resisc45',
          'NO_TEST': False,
          'NUMBER_CLASSES': 45,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed100/vtab-resisc45/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/15 17:10:16 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-15 17:10:16.252021: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-15 17:10:17.517403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:10:17.517523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:10:17.517540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-15 17:10:19.990767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:10:19.990930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:10:19.990961: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/15 17:10:19 visual_prompt]: Constructing vtab-resisc45 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
2023-09-15 17:10:20.011950: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[:800]+train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:10:22 visual_prompt]: Number of images: 1000
[09/15 17:10:22 visual_prompt]: Number of classes: 45 / 45
[09/15 17:10:22 visual_prompt]: Loading validation data...
[09/15 17:10:22 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:10:22 visual_prompt]: Number of images: 200
[09/15 17:10:22 visual_prompt]: Number of classes: 45 / 45
[09/15 17:10:22 visual_prompt]: Loading test data...
[09/15 17:10:22 visual_prompt]: Constructing vtab-resisc45 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[25200:], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:10:33 visual_prompt]: Number of images: 6300
[09/15 17:10:33 visual_prompt]: Number of classes: 45 / 45
[09/15 17:10:33 visual_prompt]: Constructing models...
[09/15 17:10:36 visual_prompt]: Total Parameters: 86754861	 Gradient Parameters: 956205
[09/15 17:10:36 visual_prompt]: tuned percent:1.102
[09/15 17:10:39 visual_prompt]: Device used for model: 0
[09/15 17:10:39 visual_prompt]: Setting up Evalutator...
[09/15 17:10:39 visual_prompt]: Setting up Trainer...
[09/15 17:10:39 visual_prompt]: 	Setting up the optimizer...
[09/15 17:10:39 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 124, in main
    train(cfg, args)
  File "visual_prompt_tuning/train.py", line 109, in train
    trainer.train_classifier(train_loader, val_loader, test_loader)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 185, in train_classifier
    train_loss, _ = self.forward_one_batch(X, targets, True)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 86, in forward_one_batch
    outputs = self.model(inputs)  # (batchsize, num_cls)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_models.py", line 175, in forward
    x = self.enc(x)  # batch_size x self.feat_dim
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 161, in forward
    x, attn_weights = self.transformer(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 138, in forward
    embedding_output)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 124, in forward_deep_prompt
    hidden_states, weights = self.encoder.layer[i](hidden_states)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 199, in forward
    x, weights = self.attn(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 106, in forward
    context_layer = torch.matmul(attention_probs, value_layer) # B, num_head, num_patches, head_size
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 11.91 GiB total capacity; 11.00 GiB already allocated; 14.94 MiB free; 11.11 GiB reserved in total by PyTorch)
[09/15 17:11:02 visual_prompt]: Rank of current process: 0. World size: 1
[09/15 17:11:02 visual_prompt]: Environment info:
-------------------  ----------------------------------------------------
Python               3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              1.7.1
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2,3
GPU 0,1              NVIDIA TITAN X (Pascal)
Pillow               9.3.0
cv2                  4.8.0
-------------------  ----------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.0
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[09/15 17:11:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '100', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-resisc45', 'DATA.NUMBER_CLASSES', '45', 'SOLVER.BASE_LR', '5.0', 'SOLVER.WEIGHT_DECAY', '0.0001', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir/seed800'], train_type='')
[09/15 17:11:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/15 17:11:02 visual_prompt]: Training with config:
[09/15 17:11:02 visual_prompt]: {'CUDNN_BENCHMARK': False,
 'DATA': {'BATCH_SIZE': 64,
          'CLASS_WEIGHTS_TYPE': 'none',
          'CROPSIZE': 224,
          'DATAPATH': 'visual_prompt_tuning/data_path',
          'FEATURE': 'sup_vitb16_imagenet21k',
          'MULTILABEL': False,
          'NAME': 'vtab-resisc45',
          'NO_TEST': False,
          'NUMBER_CLASSES': 45,
          'NUM_WORKERS': 4,
          'PERCENTAGE': 1.0,
          'PIN_MEMORY': True},
 'DBG': False,
 'MODEL': {'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'}),
           'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}),
           'MLP_NUM': 0,
           'MODEL_ROOT': 'visual_prompt_tuning/model_root',
           'PROMPT': {'CLSEMB_FOLDER': '',
                      'CLSEMB_PATH': '',
                      'DEEP': True,
                      'DEEP_SHARED': False,
                      'DROPOUT': 0.1,
                      'FORWARD_DEEP_NOEXPAND': False,
                      'INITIATION': 'random',
                      'LOCATION': 'prepend',
                      'NUM_DEEP_LAYERS': None,
                      'NUM_TOKENS': 100,
                      'PROJECT': -1,
                      'REVERSE_DEEP': False,
                      'SAVE_FOR_EACH_EPOCH': False,
                      'VIT_POOL_TYPE': 'original'},
           'SAVE_CKPT': False,
           'TRANSFER_TYPE': 'prompt',
           'TYPE': 'vit',
           'WEIGHT_PATH': ''},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/seed800/vtab-resisc45/sup_vitb16_imagenet21k/lr5.0_wd0.0001/run1',
 'RUN_N_TIMES': 1,
 'SEED': None,
 'SOLVER': {'BASE_LR': 5.0,
            'BIAS_MULTIPLIER': 1.0,
            'DBG_TRAINABLE': False,
            'LOG_EVERY_N': 100,
            'LOSS': 'softmax',
            'LOSS_ALPHA': 0.01,
            'MOMENTUM': 0.9,
            'OPTIMIZER': 'sgd',
            'PATIENCE': 300,
            'SCHEDULER': 'cosine',
            'TOTAL_EPOCH': 100,
            'WARMUP_EPOCH': 10,
            'WEIGHT_DECAY': 0.0001,
            'WEIGHT_DECAY_BIAS': 0}}
[09/15 17:11:02 visual_prompt]: Loading training data (final training data for vtab)...
2023-09-15 17:11:02.217846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-15 17:11:03.447420: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:11:03.447542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:11:03.447558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2023-09-15 17:11:05.737461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:11:05.737620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/cv2/../../lib64:
2023-09-15 17:11:05.737649: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[09/15 17:11:05 visual_prompt]: Constructing vtab-resisc45 dataset trainval...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
2023-09-15 17:11:05.758273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[:800]+train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:11:08 visual_prompt]: Number of images: 1000
[09/15 17:11:08 visual_prompt]: Number of classes: 45 / 45
[09/15 17:11:08 visual_prompt]: Loading validation data...
[09/15 17:11:08 visual_prompt]: Constructing vtab-resisc45 dataset val...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[18900:19100], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:11:08 visual_prompt]: Number of images: 200
[09/15 17:11:08 visual_prompt]: Number of classes: 45 / 45
[09/15 17:11:08 visual_prompt]: Loading test data...
[09/15 17:11:08 visual_prompt]: Constructing vtab-resisc45 dataset test...
[INFO: dataset_info.py:  566]: Load dataset info from visual_prompt_tuning/data_path/resisc45/3.0.0
[INFO: dataset_builder.py:  510]: Reusing dataset resisc45 (visual_prompt_tuning/data_path/resisc45/3.0.0)
[INFO: logging_logger.py:   53]: Constructing tf.data.Dataset resisc45 for split train[25200:], from visual_prompt_tuning/data_path/resisc45/3.0.0
[09/15 17:11:19 visual_prompt]: Number of images: 6300
[09/15 17:11:19 visual_prompt]: Number of classes: 45 / 45
[09/15 17:11:19 visual_prompt]: Constructing models...
[09/15 17:11:22 visual_prompt]: Total Parameters: 86754861	 Gradient Parameters: 956205
[09/15 17:11:22 visual_prompt]: tuned percent:1.102
[09/15 17:11:24 visual_prompt]: Device used for model: 0
[09/15 17:11:24 visual_prompt]: Setting up Evalutator...
[09/15 17:11:24 visual_prompt]: Setting up Trainer...
[09/15 17:11:24 visual_prompt]: 	Setting up the optimizer...
[09/15 17:11:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
Traceback (most recent call last):
  File "visual_prompt_tuning/train.py", line 129, in <module>
    main(args)
  File "visual_prompt_tuning/train.py", line 124, in main
    train(cfg, args)
  File "visual_prompt_tuning/train.py", line 109, in train
    trainer.train_classifier(train_loader, val_loader, test_loader)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 185, in train_classifier
    train_loss, _ = self.forward_one_batch(X, targets, True)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 86, in forward_one_batch
    outputs = self.model(inputs)  # (batchsize, num_cls)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_models.py", line 175, in forward
    x = self.enc(x)  # batch_size x self.feat_dim
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 161, in forward
    x, attn_weights = self.transformer(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 138, in forward
    embedding_output)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_prompt/vit.py", line 124, in forward_deep_prompt
    hidden_states, weights = self.encoder.layer[i](hidden_states)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 199, in forward
    x, weights = self.attn(x)
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/models/vit_backbones/vit.py", line 106, in forward
    context_layer = torch.matmul(attention_probs, value_layer) # B, num_head, num_patches, head_size
RuntimeError: CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 11.91 GiB total capacity; 11.00 GiB already allocated; 14.94 MiB free; 11.11 GiB reserved in total by PyTorch)
