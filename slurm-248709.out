/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 02:19:27 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 02:19:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 02:19:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 02:19:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 02:19:28 visual_prompt]: Training with config:
[11/22 02:19:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 02:19:28 visual_prompt]: Loading training data...
[11/22 02:19:28 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 02:19:28 visual_prompt]: Loading validation data...
[11/22 02:19:28 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 02:19:28 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 02:19:32 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 02:19:32 visual_prompt]: tuned percent:0.532
[11/22 02:19:32 visual_prompt]: Device used for model: 0
[11/22 02:19:32 visual_prompt]: Setting up Evaluator...
[11/22 02:19:32 visual_prompt]: Setting up Trainer...
[11/22 02:19:32 visual_prompt]: 	Setting up the optimizer...
[11/22 02:19:32 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 02:27:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.13e+00, avg batch time: 6.5822, average train loss: 1.4863
[11/22 02:28:04 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5800, average loss: 1.4553
[11/22 02:28:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 02:28:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 02:35:30 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.3813, average train loss: 23.4194
[11/22 02:36:21 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5799, average loss: 5.9050
[11/22 02:36:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[11/22 02:36:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 02:43:43 visual_prompt]: Epoch 3 / 100: avg data time: 4.88e+00, avg batch time: 6.3138, average train loss: 22.7559
[11/22 02:44:34 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5806, average loss: 78.4539
[11/22 02:44:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 47.22	
[11/22 02:44:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 02:51:57 visual_prompt]: Epoch 4 / 100: avg data time: 4.89e+00, avg batch time: 6.3241, average train loss: 31.9098
[11/22 02:52:48 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5818, average loss: 36.0121
[11/22 02:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.13	
[11/22 02:52:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 03:00:11 visual_prompt]: Epoch 5 / 100: avg data time: 4.91e+00, avg batch time: 6.3364, average train loss: 37.4111
[11/22 03:01:02 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5772, average loss: 33.6763
[11/22 03:01:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.87	
[11/22 03:01:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 03:08:27 visual_prompt]: Epoch 6 / 100: avg data time: 4.92e+00, avg batch time: 6.3519, average train loss: 80.9835
[11/22 03:09:18 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5830, average loss: 70.5767
[11/22 03:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[11/22 03:09:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 03:16:42 visual_prompt]: Epoch 7 / 100: avg data time: 4.91e+00, avg batch time: 6.3447, average train loss: 62.2236
[11/22 03:17:31 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5797, average loss: 54.4756
[11/22 03:17:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/22 03:17:31 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 03:24:56 visual_prompt]: Epoch 8 / 100: avg data time: 4.92e+00, avg batch time: 6.3438, average train loss: 130.3972
[11/22 03:25:46 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5752, average loss: 173.7895
[11/22 03:25:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.03	
[11/22 03:25:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 03:33:12 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3707, average train loss: 111.8224
[11/22 03:34:03 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5772, average loss: 51.1531
[11/22 03:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.05	
[11/22 03:34:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 03:41:23 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.2863, average train loss: 105.2176
[11/22 03:42:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5802, average loss: 31.9708
[11/22 03:42:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.58	
[11/22 03:42:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 03:49:41 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.3823, average train loss: 129.0567
[11/22 03:50:31 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5796, average loss: 13.2878
[11/22 03:50:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.27	
[11/22 03:50:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 03:57:55 visual_prompt]: Epoch 12 / 100: avg data time: 4.90e+00, avg batch time: 6.3278, average train loss: 208.1526
[11/22 03:58:45 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5791, average loss: 183.8571
[11/22 03:58:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/22 03:58:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 04:06:11 visual_prompt]: Epoch 13 / 100: avg data time: 4.93e+00, avg batch time: 6.3591, average train loss: 148.6304
[11/22 04:07:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5802, average loss: 167.0876
[11/22 04:07:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[11/22 04:07:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 04:14:25 visual_prompt]: Epoch 14 / 100: avg data time: 4.91e+00, avg batch time: 6.3381, average train loss: 112.9457
[11/22 04:15:16 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5833, average loss: 180.0684
[11/22 04:15:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.04	
[11/22 04:15:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 04:22:39 visual_prompt]: Epoch 15 / 100: avg data time: 4.91e+00, avg batch time: 6.3322, average train loss: 107.0701
[11/22 04:23:30 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5799, average loss: 218.0983
[11/22 04:23:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 50.02	
[11/22 04:23:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 04:30:56 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3627, average train loss: 157.8699
[11/22 04:31:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5800, average loss: 6.8180
[11/22 04:31:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.42	
[11/22 04:31:47 visual_prompt]: Best epoch 16: best metric: -6.818
[11/22 04:31:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 04:39:08 visual_prompt]: Epoch 17 / 100: avg data time: 4.88e+00, avg batch time: 6.3042, average train loss: 172.9522
[11/22 04:39:58 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5792, average loss: 46.7653
[11/22 04:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.43	
[11/22 04:39:58 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 04:47:23 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3557, average train loss: 134.8895
[11/22 04:48:14 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5816, average loss: 44.4161
[11/22 04:48:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.95	
[11/22 04:48:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 04:55:38 visual_prompt]: Epoch 19 / 100: avg data time: 4.92e+00, avg batch time: 6.3462, average train loss: 108.6106
[11/22 04:56:29 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5825, average loss: 330.5166
[11/22 04:56:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.82	
[11/22 04:56:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 05:03:55 visual_prompt]: Epoch 20 / 100: avg data time: 4.94e+00, avg batch time: 6.3661, average train loss: 141.1177
[11/22 05:04:45 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5779, average loss: 192.2731
[11/22 05:04:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.96	
[11/22 05:04:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 05:12:12 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3765, average train loss: 133.8192
[11/22 05:13:03 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5815, average loss: 236.0819
[11/22 05:13:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.05	
[11/22 05:13:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 05:20:27 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e+00, avg batch time: 6.3453, average train loss: 166.6178
[11/22 05:21:18 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5807, average loss: 36.2407
[11/22 05:21:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.01	
[11/22 05:21:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 05:28:43 visual_prompt]: Epoch 23 / 100: avg data time: 4.94e+00, avg batch time: 6.3671, average train loss: 107.7752
[11/22 05:29:34 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5801, average loss: 94.2358
[11/22 05:29:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.56	
[11/22 05:29:34 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 05:36:59 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3543, average train loss: 116.4842
[11/22 05:37:49 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5832, average loss: 106.7851
[11/22 05:37:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.64	
[11/22 05:37:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 05:45:16 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3724, average train loss: 113.7748
[11/22 05:46:06 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5867, average loss: 109.0722
[11/22 05:46:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.17	
[11/22 05:46:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 05:53:28 visual_prompt]: Epoch 26 / 100: avg data time: 4.88e+00, avg batch time: 6.3012, average train loss: 146.5544
[11/22 05:54:18 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5823, average loss: 21.7410
[11/22 05:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.72	
[11/22 05:54:18 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 06:01:43 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3575, average train loss: 103.7777
[11/22 06:02:34 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5811, average loss: 98.3964
[11/22 06:02:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.96	
[11/22 06:02:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 06:10:01 visual_prompt]: Epoch 28 / 100: avg data time: 4.96e+00, avg batch time: 6.3802, average train loss: 91.9104
[11/22 06:10:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5815, average loss: 96.4467
[11/22 06:10:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.64	
[11/22 06:10:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 06:18:12 visual_prompt]: Epoch 29 / 100: avg data time: 4.86e+00, avg batch time: 6.2894, average train loss: 128.0840
[11/22 06:19:03 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5806, average loss: 263.1504
[11/22 06:19:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[11/22 06:19:03 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 06:26:30 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.3845, average train loss: 124.3856
[11/22 06:27:21 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5807, average loss: 35.3219
[11/22 06:27:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 45.57	
[11/22 06:27:21 visual_prompt]: Stopping early.
[11/22 06:27:21 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 06:27:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 06:27:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 06:27:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 06:27:21 visual_prompt]: Training with config:
[11/22 06:27:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 06:27:21 visual_prompt]: Loading training data...
[11/22 06:27:21 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 06:27:21 visual_prompt]: Loading validation data...
[11/22 06:27:21 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 06:27:21 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 06:27:24 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 06:27:24 visual_prompt]: tuned percent:0.532
[11/22 06:27:24 visual_prompt]: Device used for model: 0
[11/22 06:27:24 visual_prompt]: Setting up Evaluator...
[11/22 06:27:24 visual_prompt]: Setting up Trainer...
[11/22 06:27:24 visual_prompt]: 	Setting up the optimizer...
[11/22 06:27:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 06:34:50 visual_prompt]: Epoch 1 / 100: avg data time: 4.94e+00, avg batch time: 6.3769, average train loss: 1.4863
[11/22 06:35:41 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5820, average loss: 1.4553
[11/22 06:35:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 06:35:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 06:43:09 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e+00, avg batch time: 6.3942, average train loss: 29.6890
[11/22 06:43:59 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5777, average loss: 4.8085
[11/22 06:43:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/22 06:43:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 06:51:24 visual_prompt]: Epoch 3 / 100: avg data time: 4.92e+00, avg batch time: 6.3565, average train loss: 28.3773
[11/22 06:52:15 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5810, average loss: 36.1099
[11/22 06:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.14	
[11/22 06:52:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 06:59:41 visual_prompt]: Epoch 4 / 100: avg data time: 4.95e+00, avg batch time: 6.3799, average train loss: 28.7815
[11/22 07:00:32 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5772, average loss: 28.0690
[11/22 07:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.59	
[11/22 07:00:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 07:07:58 visual_prompt]: Epoch 5 / 100: avg data time: 4.93e+00, avg batch time: 6.3642, average train loss: 37.3561
[11/22 07:08:50 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5860, average loss: 105.6275
[11/22 07:08:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.50	
[11/22 07:08:50 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 07:16:25 visual_prompt]: Epoch 6 / 100: avg data time: 5.07e+00, avg batch time: 6.4983, average train loss: 49.8338
[11/22 07:17:16 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5812, average loss: 79.5973
[11/22 07:17:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.72	
[11/22 07:17:16 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 07:24:47 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4412, average train loss: 76.3471
[11/22 07:25:39 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5795, average loss: 59.3471
[11/22 07:25:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.57	
[11/22 07:25:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 07:33:11 visual_prompt]: Epoch 8 / 100: avg data time: 5.03e+00, avg batch time: 6.4630, average train loss: 121.1505
[11/22 07:34:03 visual_prompt]: Inference (val):avg data time: 2.26e-04, avg batch time: 0.5990, average loss: 242.3564
[11/22 07:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.41	
[11/22 07:34:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 07:41:33 visual_prompt]: Epoch 9 / 100: avg data time: 5.01e+00, avg batch time: 6.4308, average train loss: 98.8507
[11/22 07:42:24 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5808, average loss: 265.9323
[11/22 07:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.62	
[11/22 07:42:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 07:49:55 visual_prompt]: Epoch 10 / 100: avg data time: 5.01e+00, avg batch time: 6.4332, average train loss: 108.4417
[11/22 07:50:46 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5813, average loss: 25.7128
[11/22 07:50:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.06	
[11/22 07:50:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 07:58:18 visual_prompt]: Epoch 11 / 100: avg data time: 5.03e+00, avg batch time: 6.4607, average train loss: 86.0772
[11/22 07:59:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5798, average loss: 233.3680
[11/22 07:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.84	
[11/22 07:59:10 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 08:06:40 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e+00, avg batch time: 6.4257, average train loss: 125.8367
[11/22 08:07:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5794, average loss: 3.7898
[11/22 08:07:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.28	
[11/22 08:07:32 visual_prompt]: Best epoch 12: best metric: -3.790
[11/22 08:07:32 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 08:15:03 visual_prompt]: Epoch 13 / 100: avg data time: 5.02e+00, avg batch time: 6.4499, average train loss: 145.2245
[11/22 08:15:55 visual_prompt]: Inference (val):avg data time: 4.28e-04, avg batch time: 0.5767, average loss: 16.6351
[11/22 08:15:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/22 08:15:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 08:23:26 visual_prompt]: Epoch 14 / 100: avg data time: 5.02e+00, avg batch time: 6.4499, average train loss: 130.2937
[11/22 08:24:18 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5811, average loss: 52.4746
[11/22 08:24:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.90	
[11/22 08:24:18 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 08:31:49 visual_prompt]: Epoch 15 / 100: avg data time: 5.01e+00, avg batch time: 6.4415, average train loss: 80.5654
[11/22 08:32:40 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5769, average loss: 43.1324
[11/22 08:32:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.08	
[11/22 08:32:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 08:40:11 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e+00, avg batch time: 6.4347, average train loss: 106.6968
[11/22 08:41:02 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5819, average loss: 337.7281
[11/22 08:41:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.76	
[11/22 08:41:02 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 08:48:35 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4619, average train loss: 128.5729
[11/22 08:49:26 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5775, average loss: 380.2673
[11/22 08:49:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.12	
[11/22 08:49:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 08:56:58 visual_prompt]: Epoch 18 / 100: avg data time: 5.01e+00, avg batch time: 6.4453, average train loss: 109.7811
[11/22 08:57:49 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5785, average loss: 17.9192
[11/22 08:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.66	
[11/22 08:57:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 09:05:21 visual_prompt]: Epoch 19 / 100: avg data time: 5.02e+00, avg batch time: 6.4507, average train loss: 130.5409
[11/22 09:06:13 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5799, average loss: 84.5841
[11/22 09:06:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.71	
[11/22 09:06:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 09:13:45 visual_prompt]: Epoch 20 / 100: avg data time: 5.03e+00, avg batch time: 6.4658, average train loss: 92.9746
[11/22 09:14:37 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5818, average loss: 141.7912
[11/22 09:14:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.49	
[11/22 09:14:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 09:22:09 visual_prompt]: Epoch 21 / 100: avg data time: 5.04e+00, avg batch time: 6.4625, average train loss: 93.9640
[11/22 09:23:01 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5814, average loss: 143.8580
[11/22 09:23:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.35	
[11/22 09:23:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 09:30:32 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e+00, avg batch time: 6.4522, average train loss: 108.6632
[11/22 09:31:24 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5779, average loss: 164.8212
[11/22 09:31:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/22 09:31:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 09:38:57 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e+00, avg batch time: 6.4689, average train loss: 147.8838
[11/22 09:39:48 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5801, average loss: 4.1596
[11/22 09:39:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 35.92	
[11/22 09:39:48 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 09:47:19 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4378, average train loss: 131.2509
[11/22 09:48:11 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5789, average loss: 268.7511
[11/22 09:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.99	
[11/22 09:48:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 09:55:43 visual_prompt]: Epoch 25 / 100: avg data time: 5.04e+00, avg batch time: 6.4604, average train loss: 89.2651
[11/22 09:56:35 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5785, average loss: 16.8490
[11/22 09:56:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.50	
[11/22 09:56:35 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 10:04:06 visual_prompt]: Epoch 26 / 100: avg data time: 5.01e+00, avg batch time: 6.4392, average train loss: 109.7163
[11/22 10:04:57 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5807, average loss: 135.4173
[11/22 10:04:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/22 10:04:57 visual_prompt]: Stopping early.
[11/22 10:04:57 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 10:04:57 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 10:04:57 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 10:04:57 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 10:04:57 visual_prompt]: Training with config:
[11/22 10:04:57 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 10:04:57 visual_prompt]: Loading training data...
[11/22 10:04:57 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 10:04:57 visual_prompt]: Loading validation data...
[11/22 10:04:57 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 10:04:57 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 10:05:00 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 10:05:00 visual_prompt]: tuned percent:0.532
[11/22 10:05:00 visual_prompt]: Device used for model: 0
[11/22 10:05:00 visual_prompt]: Setting up Evaluator...
[11/22 10:05:00 visual_prompt]: Setting up Trainer...
[11/22 10:05:00 visual_prompt]: 	Setting up the optimizer...
[11/22 10:05:00 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 10:12:35 visual_prompt]: Epoch 1 / 100: avg data time: 5.05e+00, avg batch time: 6.4894, average train loss: 1.4863
[11/22 10:13:26 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5828, average loss: 1.4553
[11/22 10:13:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 10:13:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 10:21:01 visual_prompt]: Epoch 2 / 100: avg data time: 5.05e+00, avg batch time: 6.4892, average train loss: 20.3780
[11/22 10:21:52 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5815, average loss: 5.1255
[11/22 10:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[11/22 10:21:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 10:29:24 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4534, average train loss: 22.9462
[11/22 10:30:16 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5838, average loss: 23.8554
[11/22 10:30:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.59	
[11/22 10:30:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 10:37:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e+00, avg batch time: 6.4723, average train loss: 30.8549
[11/22 10:38:40 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5843, average loss: 40.9484
[11/22 10:38:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.05	
[11/22 10:38:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 10:46:12 visual_prompt]: Epoch 5 / 100: avg data time: 5.01e+00, avg batch time: 6.4452, average train loss: 39.4185
[11/22 10:47:03 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5758, average loss: 25.5446
[11/22 10:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/22 10:47:03 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 10:54:36 visual_prompt]: Epoch 6 / 100: avg data time: 5.04e+00, avg batch time: 6.4655, average train loss: 55.9571
[11/22 10:55:27 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5805, average loss: 104.3030
[11/22 10:55:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/22 10:55:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 11:02:59 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4426, average train loss: 45.2455
[11/22 11:03:50 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5808, average loss: 79.2160
[11/22 11:03:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.91	
[11/22 11:03:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 11:11:43 visual_prompt]: Epoch 8 / 100: avg data time: 5.33e+00, avg batch time: 6.7567, average train loss: 65.1711
[11/22 11:12:36 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5784, average loss: 14.0736
[11/22 11:12:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/22 11:12:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 11:20:04 visual_prompt]: Epoch 9 / 100: avg data time: 4.98e+00, avg batch time: 6.4060, average train loss: 54.6180
[11/22 11:20:56 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5774, average loss: 82.0216
[11/22 11:20:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/22 11:20:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 11:28:24 visual_prompt]: Epoch 10 / 100: avg data time: 4.97e+00, avg batch time: 6.4006, average train loss: 86.8197
[11/22 11:29:15 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5804, average loss: 59.5717
[11/22 11:29:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.88	
[11/22 11:29:15 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 11:36:44 visual_prompt]: Epoch 11 / 100: avg data time: 4.98e+00, avg batch time: 6.4132, average train loss: 96.6974
[11/22 11:37:36 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5820, average loss: 84.8839
[11/22 11:37:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.14	
[11/22 11:37:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 11:45:04 visual_prompt]: Epoch 12 / 100: avg data time: 4.98e+00, avg batch time: 6.4018, average train loss: 110.2374
[11/22 11:45:55 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5797, average loss: 40.7016
[11/22 11:45:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.03	
[11/22 11:45:55 visual_prompt]: Best epoch 12: best metric: -40.702
[11/22 11:45:55 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 11:53:24 visual_prompt]: Epoch 13 / 100: avg data time: 4.99e+00, avg batch time: 6.4065, average train loss: 82.8512
[11/22 11:54:15 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5792, average loss: 42.2964
[11/22 11:54:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/22 11:54:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 12:01:45 visual_prompt]: Epoch 14 / 100: avg data time: 5.00e+00, avg batch time: 6.4216, average train loss: 186.6293
[11/22 12:02:36 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5807, average loss: 151.4444
[11/22 12:02:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/22 12:02:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 12:10:05 visual_prompt]: Epoch 15 / 100: avg data time: 4.99e+00, avg batch time: 6.4158, average train loss: 126.1228
[11/22 12:10:57 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5810, average loss: 54.1846
[11/22 12:10:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.20	
[11/22 12:10:57 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 12:18:27 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4274, average train loss: 77.2475
[11/22 12:19:18 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5821, average loss: 147.1842
[11/22 12:19:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.70	
[11/22 12:19:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 12:26:49 visual_prompt]: Epoch 17 / 100: avg data time: 5.00e+00, avg batch time: 6.4312, average train loss: 69.4608
[11/22 12:27:40 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5807, average loss: 224.6104
[11/22 12:27:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.21	
[11/22 12:27:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 12:35:09 visual_prompt]: Epoch 18 / 100: avg data time: 5.00e+00, avg batch time: 6.4201, average train loss: 107.6016
[11/22 12:36:01 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5761, average loss: 28.3802
[11/22 12:36:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.00	
[11/22 12:36:01 visual_prompt]: Best epoch 18: best metric: -28.380
[11/22 12:36:01 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 12:43:30 visual_prompt]: Epoch 19 / 100: avg data time: 4.99e+00, avg batch time: 6.4153, average train loss: 73.0924
[11/22 12:44:21 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5791, average loss: 5.8467
[11/22 12:44:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/22 12:44:21 visual_prompt]: Best epoch 19: best metric: -5.847
[11/22 12:44:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 12:51:52 visual_prompt]: Epoch 20 / 100: avg data time: 5.01e+00, avg batch time: 6.4408, average train loss: 92.2818
[11/22 12:52:44 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5809, average loss: 147.1998
[11/22 12:52:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.43	
[11/22 12:52:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 13:00:16 visual_prompt]: Epoch 21 / 100: avg data time: 5.03e+00, avg batch time: 6.4539, average train loss: 113.5255
[11/22 13:01:07 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5840, average loss: 59.1547
[11/22 13:01:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.86	
[11/22 13:01:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 13:08:38 visual_prompt]: Epoch 22 / 100: avg data time: 5.01e+00, avg batch time: 6.4362, average train loss: 91.3612
[11/22 13:09:30 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5839, average loss: 10.5461
[11/22 13:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.10	
[11/22 13:09:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 13:17:02 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e+00, avg batch time: 6.4649, average train loss: 133.1470
[11/22 13:17:54 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5800, average loss: 85.4615
[11/22 13:17:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.47	
[11/22 13:17:54 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 13:25:24 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4300, average train loss: 80.1999
[11/22 13:26:15 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5810, average loss: 3.8078
[11/22 13:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.12	
[11/22 13:26:15 visual_prompt]: Best epoch 24: best metric: -3.808
[11/22 13:26:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 13:33:47 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4491, average train loss: 122.6318
[11/22 13:34:38 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5826, average loss: 156.8054
[11/22 13:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.67	
[11/22 13:34:38 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 13:42:09 visual_prompt]: Epoch 26 / 100: avg data time: 5.01e+00, avg batch time: 6.4325, average train loss: 93.7701
[11/22 13:43:00 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5818, average loss: 10.4415
[11/22 13:43:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.47	
[11/22 13:43:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 13:50:30 visual_prompt]: Epoch 27 / 100: avg data time: 5.00e+00, avg batch time: 6.4225, average train loss: 93.0354
[11/22 13:51:22 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5847, average loss: 173.7292
[11/22 13:51:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.06	
[11/22 13:51:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 13:58:54 visual_prompt]: Epoch 28 / 100: avg data time: 5.03e+00, avg batch time: 6.4656, average train loss: 98.3128
[11/22 13:59:46 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5796, average loss: 115.2049
[11/22 13:59:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.74	
[11/22 13:59:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 14:07:15 visual_prompt]: Epoch 29 / 100: avg data time: 5.00e+00, avg batch time: 6.4216, average train loss: 92.3197
[11/22 14:08:07 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5801, average loss: 208.0735
[11/22 14:08:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.10	
[11/22 14:08:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 14:15:38 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e+00, avg batch time: 6.4364, average train loss: 117.8638
[11/22 14:16:29 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5774, average loss: 151.8972
[11/22 14:16:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/22 14:16:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 14:23:58 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4118, average train loss: 136.5047
[11/22 14:24:50 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5857, average loss: 18.3430
[11/22 14:24:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/22 14:24:50 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 14:32:21 visual_prompt]: Epoch 32 / 100: avg data time: 5.02e+00, avg batch time: 6.4433, average train loss: 64.2359
[11/22 14:33:12 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5799, average loss: 106.8584
[11/22 14:33:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.53	
[11/22 14:33:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 14:40:43 visual_prompt]: Epoch 33 / 100: avg data time: 5.01e+00, avg batch time: 6.4375, average train loss: 94.7470
[11/22 14:41:34 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5824, average loss: 178.2198
[11/22 14:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.42	
[11/22 14:41:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/22 14:49:04 visual_prompt]: Epoch 34 / 100: avg data time: 4.99e+00, avg batch time: 6.4184, average train loss: 105.6765
[11/22 14:49:55 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5765, average loss: 11.9395
[11/22 14:49:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/22 14:49:55 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/22 14:57:25 visual_prompt]: Epoch 35 / 100: avg data time: 5.00e+00, avg batch time: 6.4233, average train loss: 119.8641
[11/22 14:58:17 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5812, average loss: 197.5336
[11/22 14:58:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/22 14:58:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/22 15:05:48 visual_prompt]: Epoch 36 / 100: avg data time: 5.03e+00, avg batch time: 6.4500, average train loss: 78.3067
[11/22 15:06:40 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5836, average loss: 3.5021
[11/22 15:06:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 46.27	
[11/22 15:06:40 visual_prompt]: Best epoch 36: best metric: -3.502
[11/22 15:06:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/22 15:14:10 visual_prompt]: Epoch 37 / 100: avg data time: 5.01e+00, avg batch time: 6.4340, average train loss: 75.9535
[11/22 15:15:02 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5829, average loss: 67.3251
[11/22 15:15:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/22 15:15:02 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/22 15:22:32 visual_prompt]: Epoch 38 / 100: avg data time: 5.01e+00, avg batch time: 6.4379, average train loss: 48.9238
[11/22 15:23:24 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5792, average loss: 80.9727
[11/22 15:23:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.82	
[11/22 15:23:24 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/22 15:30:55 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4383, average train loss: 88.0498
[11/22 15:31:46 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5789, average loss: 72.4487
[11/22 15:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.85	
[11/22 15:31:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/22 15:39:16 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e+00, avg batch time: 6.4276, average train loss: 58.7556
[11/22 15:40:07 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5788, average loss: 11.0629
[11/22 15:40:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/22 15:40:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[11/22 15:47:38 visual_prompt]: Epoch 41 / 100: avg data time: 5.00e+00, avg batch time: 6.4313, average train loss: 50.7774
[11/22 15:48:29 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5785, average loss: 67.7956
[11/22 15:48:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/22 15:48:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/22 15:55:59 visual_prompt]: Epoch 42 / 100: avg data time: 5.00e+00, avg batch time: 6.4207, average train loss: 83.1322
[11/22 15:56:50 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5795, average loss: 175.8947
[11/22 15:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.14	
[11/22 15:56:50 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/22 16:04:22 visual_prompt]: Epoch 43 / 100: avg data time: 5.03e+00, avg batch time: 6.4618, average train loss: 83.4012
[11/22 16:05:14 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5827, average loss: 187.2698
[11/22 16:05:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.43	
[11/22 16:05:14 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/22 16:12:46 visual_prompt]: Epoch 44 / 100: avg data time: 5.02e+00, avg batch time: 6.4511, average train loss: 70.3138
[11/22 16:13:37 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5775, average loss: 100.1013
[11/22 16:13:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.89	
[11/22 16:13:37 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/22 16:21:08 visual_prompt]: Epoch 45 / 100: avg data time: 5.02e+00, avg batch time: 6.4409, average train loss: 63.3193
[11/22 16:22:00 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5829, average loss: 5.9979
[11/22 16:22:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.27	
[11/22 16:22:00 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/22 16:29:30 visual_prompt]: Epoch 46 / 100: avg data time: 5.00e+00, avg batch time: 6.4316, average train loss: 57.3201
[11/22 16:30:21 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5808, average loss: 44.7624
[11/22 16:30:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.64	
[11/22 16:30:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/22 16:37:52 visual_prompt]: Epoch 47 / 100: avg data time: 5.01e+00, avg batch time: 6.4399, average train loss: 57.2510
[11/22 16:38:44 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5837, average loss: 8.4430
[11/22 16:38:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/22 16:38:44 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[11/22 16:46:15 visual_prompt]: Epoch 48 / 100: avg data time: 5.02e+00, avg batch time: 6.4484, average train loss: 52.1243
[11/22 16:47:07 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5810, average loss: 52.3113
[11/22 16:47:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.63	
[11/22 16:47:07 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[11/22 16:54:38 visual_prompt]: Epoch 49 / 100: avg data time: 5.01e+00, avg batch time: 6.4430, average train loss: 42.0767
[11/22 16:55:29 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5819, average loss: 38.1934
[11/22 16:55:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/22 16:55:29 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[11/22 17:03:19 visual_prompt]: Epoch 50 / 100: avg data time: 5.29e+00, avg batch time: 6.7135, average train loss: 97.6234
[11/22 17:04:13 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5776, average loss: 148.9838
[11/22 17:04:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.77	
[11/22 17:04:13 visual_prompt]: Stopping early.
[11/22 17:04:15 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 17:04:15 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 17:04:15 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 17:04:15 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 17:04:15 visual_prompt]: Training with config:
[11/22 17:04:15 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr50.0_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 17:04:15 visual_prompt]: Loading training data...
[11/22 17:04:15 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 17:04:15 visual_prompt]: Loading validation data...
[11/22 17:04:15 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 17:04:15 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 17:04:18 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 17:04:18 visual_prompt]: tuned percent:0.532
[11/22 17:04:18 visual_prompt]: Device used for model: 0
[11/22 17:04:18 visual_prompt]: Setting up Evaluator...
[11/22 17:04:18 visual_prompt]: Setting up Trainer...
[11/22 17:04:18 visual_prompt]: 	Setting up the optimizer...
[11/22 17:04:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 17:11:57 visual_prompt]: Epoch 1 / 100: avg data time: 5.12e+00, avg batch time: 6.5537, average train loss: 1.4863
[11/22 17:12:49 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5780, average loss: 1.4553
[11/22 17:12:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 17:12:49 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/22 17:20:19 visual_prompt]: Epoch 2 / 100: avg data time: 5.00e+00, avg batch time: 6.4324, average train loss: 18.7267
[11/22 17:21:11 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5799, average loss: 23.8607
[11/22 17:21:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.63	
[11/22 17:21:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/22 17:28:42 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4496, average train loss: 27.0763
[11/22 17:29:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5792, average loss: 39.5016
[11/22 17:29:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.12	
[11/22 17:29:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/22 17:37:03 visual_prompt]: Epoch 4 / 100: avg data time: 4.98e+00, avg batch time: 6.4146, average train loss: 57.2564
[11/22 17:37:55 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5772, average loss: 68.3047
[11/22 17:37:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.11	
[11/22 17:37:55 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/22 17:45:24 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4138, average train loss: 41.7823
[11/22 17:46:15 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5784, average loss: 11.4361
[11/22 17:46:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/22 17:46:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/22 17:53:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.03e+00, avg batch time: 6.4537, average train loss: 46.3878
[11/22 17:54:39 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.5782, average loss: 47.0229
[11/22 17:54:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/22 17:54:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/22 18:02:09 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4366, average train loss: 49.5998
[11/22 18:03:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5778, average loss: 149.5717
[11/22 18:03:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.98	
[11/22 18:03:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/22 18:10:32 visual_prompt]: Epoch 8 / 100: avg data time: 5.01e+00, avg batch time: 6.4419, average train loss: 78.7175
[11/22 18:11:24 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5827, average loss: 57.6138
[11/22 18:11:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/22 18:11:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/22 18:18:53 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4245, average train loss: 46.2650
[11/22 18:19:45 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5768, average loss: 84.5307
[11/22 18:19:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/22 18:19:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/22 18:27:14 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4179, average train loss: 92.3278
[11/22 18:28:06 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5786, average loss: 27.6195
[11/22 18:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.81	
[11/22 18:28:06 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/22 18:35:37 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4438, average train loss: 122.7208
[11/22 18:36:29 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5825, average loss: 6.6309
[11/22 18:36:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[11/22 18:36:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/22 18:43:59 visual_prompt]: Epoch 12 / 100: avg data time: 5.02e+00, avg batch time: 6.4364, average train loss: 94.4580
[11/22 18:44:51 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5823, average loss: 44.9683
[11/22 18:44:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.02	
[11/22 18:44:51 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/22 18:52:22 visual_prompt]: Epoch 13 / 100: avg data time: 5.01e+00, avg batch time: 6.4375, average train loss: 119.3497
[11/22 18:53:13 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5760, average loss: 8.7367
[11/22 18:53:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.11	
[11/22 18:53:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/22 19:00:43 visual_prompt]: Epoch 14 / 100: avg data time: 5.00e+00, avg batch time: 6.4282, average train loss: 87.4063
[11/22 19:01:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5826, average loss: 76.1077
[11/22 19:01:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.35	
[11/22 19:01:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/22 19:09:05 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4289, average train loss: 51.3531
[11/22 19:09:56 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5808, average loss: 67.2423
[11/22 19:09:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/22 19:09:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/22 19:17:26 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4309, average train loss: 78.9950
[11/22 19:18:18 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5775, average loss: 27.0773
[11/22 19:18:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.69	
[11/22 19:18:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/22 19:25:49 visual_prompt]: Epoch 17 / 100: avg data time: 5.01e+00, avg batch time: 6.4423, average train loss: 26.5004
[11/22 19:26:41 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5797, average loss: 108.9821
[11/22 19:26:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/22 19:26:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/22 19:34:10 visual_prompt]: Epoch 18 / 100: avg data time: 4.98e+00, avg batch time: 6.4135, average train loss: 62.2150
[11/22 19:35:02 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5826, average loss: 8.0574
[11/22 19:35:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/22 19:35:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/22 19:42:33 visual_prompt]: Epoch 19 / 100: avg data time: 5.01e+00, avg batch time: 6.4394, average train loss: 66.2149
[11/22 19:43:24 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5833, average loss: 3.2948
[11/22 19:43:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.62	
[11/22 19:43:24 visual_prompt]: Best epoch 19: best metric: -3.295
[11/22 19:43:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/22 19:50:55 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4447, average train loss: 44.9275
[11/22 19:51:46 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5810, average loss: 16.6158
[11/22 19:51:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/22 19:51:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/22 19:59:18 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4449, average train loss: 64.0591
[11/22 20:00:09 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5811, average loss: 24.9053
[11/22 20:00:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.12	
[11/22 20:00:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/22 20:07:40 visual_prompt]: Epoch 22 / 100: avg data time: 5.01e+00, avg batch time: 6.4401, average train loss: 47.1782
[11/22 20:08:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5808, average loss: 70.3440
[11/22 20:08:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.75	
[11/22 20:08:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/22 20:16:03 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e+00, avg batch time: 6.4490, average train loss: 37.2159
[11/22 20:16:55 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5828, average loss: 12.5568
[11/22 20:16:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.42	
[11/22 20:16:55 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/22 20:24:26 visual_prompt]: Epoch 24 / 100: avg data time: 5.02e+00, avg batch time: 6.4426, average train loss: 41.6032
[11/22 20:25:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5773, average loss: 8.8968
[11/22 20:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.66	
[11/22 20:25:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/22 20:32:50 visual_prompt]: Epoch 25 / 100: avg data time: 5.04e+00, avg batch time: 6.4661, average train loss: 51.7500
[11/22 20:33:42 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5801, average loss: 13.4114
[11/22 20:33:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.85	
[11/22 20:33:42 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/22 20:41:11 visual_prompt]: Epoch 26 / 100: avg data time: 4.99e+00, avg batch time: 6.4234, average train loss: 25.6396
[11/22 20:42:03 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5783, average loss: 36.6733
[11/22 20:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[11/22 20:42:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/22 20:49:33 visual_prompt]: Epoch 27 / 100: avg data time: 4.99e+00, avg batch time: 6.4230, average train loss: 38.7008
[11/22 20:50:24 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5779, average loss: 56.9118
[11/22 20:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.70	
[11/22 20:50:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/22 20:57:55 visual_prompt]: Epoch 28 / 100: avg data time: 5.01e+00, avg batch time: 6.4404, average train loss: 57.5679
[11/22 20:58:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5814, average loss: 22.7835
[11/22 20:58:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.64	
[11/22 20:58:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/22 21:06:18 visual_prompt]: Epoch 29 / 100: avg data time: 5.02e+00, avg batch time: 6.4509, average train loss: 59.0418
[11/22 21:07:10 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5786, average loss: 72.1700
[11/22 21:07:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.84	
[11/22 21:07:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/22 21:14:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e+00, avg batch time: 6.4453, average train loss: 39.6449
[11/22 21:15:33 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5799, average loss: 62.3798
[11/22 21:15:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.16	
[11/22 21:15:33 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/22 21:23:02 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4236, average train loss: 42.6935
[11/22 21:23:54 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5828, average loss: 4.9063
[11/22 21:23:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.99	
[11/22 21:23:54 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/22 21:31:24 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4336, average train loss: 45.2211
[11/22 21:32:16 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5796, average loss: 5.5182
[11/22 21:32:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.52	
[11/22 21:32:16 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/22 21:39:46 visual_prompt]: Epoch 33 / 100: avg data time: 5.00e+00, avg batch time: 6.4331, average train loss: 38.1421
[11/22 21:40:38 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5809, average loss: 12.0966
[11/22 21:40:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.22	
[11/22 21:40:38 visual_prompt]: Stopping early.
[11/22 21:40:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/22 21:40:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/22 21:40:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/22 21:40:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/22 21:40:38 visual_prompt]: Training with config:
[11/22 21:40:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/22 21:40:38 visual_prompt]: Loading training data...
[11/22 21:40:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/22 21:40:38 visual_prompt]: Loading validation data...
[11/22 21:40:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/22 21:40:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/22 21:40:41 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/22 21:40:41 visual_prompt]: tuned percent:0.532
[11/22 21:40:41 visual_prompt]: Device used for model: 0
[11/22 21:40:41 visual_prompt]: Setting up Evaluator...
[11/22 21:40:41 visual_prompt]: Setting up Trainer...
[11/22 21:40:41 visual_prompt]: 	Setting up the optimizer...
[11/22 21:40:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/22 21:48:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4535, average train loss: 1.4863
[11/22 21:49:04 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5799, average loss: 1.4553
[11/22 21:49:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/22 21:49:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/22 21:56:37 visual_prompt]: Epoch 2 / 100: avg data time: 5.04e+00, avg batch time: 6.4708, average train loss: 9.2644
[11/22 21:57:28 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5778, average loss: 7.2979
[11/22 21:57:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.57	
[11/22 21:57:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/22 22:04:59 visual_prompt]: Epoch 3 / 100: avg data time: 4.99e+00, avg batch time: 6.4294, average train loss: 11.8082
[11/22 22:05:50 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5785, average loss: 17.2598
[11/22 22:05:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.68	
[11/22 22:05:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/22 22:13:19 visual_prompt]: Epoch 4 / 100: avg data time: 4.98e+00, avg batch time: 6.4188, average train loss: 15.7340
[11/22 22:14:11 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5783, average loss: 6.6949
[11/22 22:14:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.09	
[11/22 22:14:11 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/22 22:21:40 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4169, average train loss: 21.7801
[11/22 22:22:32 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5803, average loss: 60.4453
[11/22 22:22:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.72	
[11/22 22:22:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/22 22:30:04 visual_prompt]: Epoch 6 / 100: avg data time: 5.03e+00, avg batch time: 6.4552, average train loss: 39.3944
[11/22 22:30:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5782, average loss: 56.8249
[11/22 22:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.45	
[11/22 22:30:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/22 22:38:25 visual_prompt]: Epoch 7 / 100: avg data time: 4.99e+00, avg batch time: 6.4215, average train loss: 41.5170
[11/22 22:39:16 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5830, average loss: 13.9227
[11/22 22:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.53	
[11/22 22:39:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/22 22:46:48 visual_prompt]: Epoch 8 / 100: avg data time: 5.02e+00, avg batch time: 6.4497, average train loss: 50.4916
[11/22 22:47:39 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5788, average loss: 110.5232
[11/22 22:47:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/22 22:47:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/22 22:55:09 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4313, average train loss: 91.9525
[11/22 22:56:01 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5795, average loss: 244.2756
[11/22 22:56:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.05	
[11/22 22:56:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/22 23:03:31 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4281, average train loss: 66.3340
[11/22 23:04:22 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5829, average loss: 11.5450
[11/22 23:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.45	
[11/22 23:04:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/22 23:11:54 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4595, average train loss: 61.0317
[11/22 23:12:46 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5797, average loss: 7.7466
[11/22 23:12:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.03	
[11/22 23:12:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/22 23:20:16 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e+00, avg batch time: 6.4257, average train loss: 77.4658
[11/22 23:21:07 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5791, average loss: 20.5838
[11/22 23:21:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.51	
[11/22 23:21:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/22 23:28:39 visual_prompt]: Epoch 13 / 100: avg data time: 5.03e+00, avg batch time: 6.4554, average train loss: 50.8149
[11/22 23:29:31 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5811, average loss: 98.8989
[11/22 23:29:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.48	
[11/22 23:29:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/22 23:37:00 visual_prompt]: Epoch 14 / 100: avg data time: 4.98e+00, avg batch time: 6.4121, average train loss: 51.6674
[11/22 23:37:51 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5783, average loss: 40.5529
[11/22 23:37:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.67	
[11/22 23:37:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/22 23:45:19 visual_prompt]: Epoch 15 / 100: avg data time: 4.97e+00, avg batch time: 6.4012, average train loss: 61.2310
[11/22 23:46:10 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5789, average loss: 74.9735
[11/22 23:46:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.50	
[11/22 23:46:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/22 23:53:38 visual_prompt]: Epoch 16 / 100: avg data time: 4.97e+00, avg batch time: 6.3969, average train loss: 60.7043
[11/22 23:54:29 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5769, average loss: 313.0779
[11/22 23:54:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.15	
[11/22 23:54:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 00:01:58 visual_prompt]: Epoch 17 / 100: avg data time: 4.98e+00, avg batch time: 6.4081, average train loss: 84.5412
[11/23 00:02:49 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5794, average loss: 128.9083
[11/23 00:02:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.84	
[11/23 00:02:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 00:10:16 visual_prompt]: Epoch 18 / 100: avg data time: 4.96e+00, avg batch time: 6.3902, average train loss: 93.7010
[11/23 00:11:08 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5800, average loss: 6.8398
[11/23 00:11:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.52	
[11/23 00:11:08 visual_prompt]: Best epoch 18: best metric: -6.840
[11/23 00:11:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 00:18:35 visual_prompt]: Epoch 19 / 100: avg data time: 4.96e+00, avg batch time: 6.3859, average train loss: 89.5964
[11/23 00:19:26 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5802, average loss: 131.6036
[11/23 00:19:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/23 00:19:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 00:26:55 visual_prompt]: Epoch 20 / 100: avg data time: 5.00e+00, avg batch time: 6.4189, average train loss: 82.3185
[11/23 00:27:46 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5831, average loss: 84.5250
[11/23 00:27:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.58	
[11/23 00:27:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 00:35:15 visual_prompt]: Epoch 21 / 100: avg data time: 4.98e+00, avg batch time: 6.4122, average train loss: 56.3152
[11/23 00:36:07 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5771, average loss: 123.3887
[11/23 00:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.70	
[11/23 00:36:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 00:43:37 visual_prompt]: Epoch 22 / 100: avg data time: 5.00e+00, avg batch time: 6.4256, average train loss: 68.6338
[11/23 00:44:28 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5779, average loss: 12.9044
[11/23 00:44:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.65	
[11/23 00:44:28 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 00:51:57 visual_prompt]: Epoch 23 / 100: avg data time: 4.99e+00, avg batch time: 6.4171, average train loss: 76.1778
[11/23 00:52:49 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5812, average loss: 38.9189
[11/23 00:52:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.68	
[11/23 00:52:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 01:00:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.99e+00, avg batch time: 6.4159, average train loss: 59.8707
[11/23 01:01:09 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5822, average loss: 110.5927
[11/23 01:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.18	
[11/23 01:01:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 01:08:39 visual_prompt]: Epoch 25 / 100: avg data time: 4.99e+00, avg batch time: 6.4215, average train loss: 60.0324
[11/23 01:09:30 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5807, average loss: 97.2395
[11/23 01:09:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.80	
[11/23 01:09:30 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 01:17:00 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4292, average train loss: 68.9984
[11/23 01:17:52 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5808, average loss: 58.5007
[11/23 01:17:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.79	
[11/23 01:17:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 01:25:21 visual_prompt]: Epoch 27 / 100: avg data time: 4.99e+00, avg batch time: 6.4197, average train loss: 50.0887
[11/23 01:26:13 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5799, average loss: 45.2765
[11/23 01:26:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.22	
[11/23 01:26:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 01:33:45 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4555, average train loss: 58.0203
[11/23 01:34:36 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5841, average loss: 31.2717
[11/23 01:34:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/23 01:34:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 01:42:07 visual_prompt]: Epoch 29 / 100: avg data time: 5.00e+00, avg batch time: 6.4298, average train loss: 54.2602
[11/23 01:42:58 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5811, average loss: 80.8989
[11/23 01:42:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.75	
[11/23 01:42:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 01:50:31 visual_prompt]: Epoch 30 / 100: avg data time: 5.04e+00, avg batch time: 6.4755, average train loss: 69.7901
[11/23 01:51:23 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5803, average loss: 20.1720
[11/23 01:51:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.60	
[11/23 01:51:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 01:58:53 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4224, average train loss: 74.0750
[11/23 01:59:44 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5801, average loss: 49.9190
[11/23 01:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.88	
[11/23 01:59:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 02:07:15 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4341, average train loss: 58.6641
[11/23 02:08:06 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.5781, average loss: 106.6819
[11/23 02:08:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.30	
[11/23 02:08:06 visual_prompt]: Stopping early.
[11/23 02:08:06 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 02:08:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 02:08:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/23 02:08:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 02:08:06 visual_prompt]: Training with config:
[11/23 02:08:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 02:08:06 visual_prompt]: Loading training data...
[11/23 02:08:06 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 02:08:06 visual_prompt]: Loading validation data...
[11/23 02:08:06 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 02:08:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 02:08:09 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 02:08:09 visual_prompt]: tuned percent:0.532
[11/23 02:08:09 visual_prompt]: Device used for model: 0
[11/23 02:08:09 visual_prompt]: Setting up Evaluator...
[11/23 02:08:09 visual_prompt]: Setting up Trainer...
[11/23 02:08:09 visual_prompt]: 	Setting up the optimizer...
[11/23 02:08:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 02:15:42 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4589, average train loss: 1.4863
[11/23 02:16:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5844, average loss: 1.4553
[11/23 02:16:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 02:16:33 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 02:24:04 visual_prompt]: Epoch 2 / 100: avg data time: 5.00e+00, avg batch time: 6.4344, average train loss: 8.2590
[11/23 02:24:55 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5785, average loss: 6.5246
[11/23 02:24:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.04	
[11/23 02:24:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 02:32:27 visual_prompt]: Epoch 3 / 100: avg data time: 5.01e+00, avg batch time: 6.4492, average train loss: 12.8542
[11/23 02:33:18 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5822, average loss: 43.0126
[11/23 02:33:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.14	
[11/23 02:33:18 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 02:40:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.00e+00, avg batch time: 6.4387, average train loss: 24.3482
[11/23 02:41:40 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5797, average loss: 38.9421
[11/23 02:41:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/23 02:41:40 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 02:49:11 visual_prompt]: Epoch 5 / 100: avg data time: 5.00e+00, avg batch time: 6.4335, average train loss: 16.7612
[11/23 02:50:02 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5784, average loss: 34.1162
[11/23 02:50:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.36	
[11/23 02:50:02 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 02:57:34 visual_prompt]: Epoch 6 / 100: avg data time: 5.02e+00, avg batch time: 6.4541, average train loss: 32.9153
[11/23 02:58:26 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5786, average loss: 33.9918
[11/23 02:58:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[11/23 02:58:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 03:05:55 visual_prompt]: Epoch 7 / 100: avg data time: 4.99e+00, avg batch time: 6.4231, average train loss: 42.2689
[11/23 03:06:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5836, average loss: 10.0477
[11/23 03:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.37	
[11/23 03:06:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 03:14:18 visual_prompt]: Epoch 8 / 100: avg data time: 5.01e+00, avg batch time: 6.4396, average train loss: 44.8138
[11/23 03:15:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5842, average loss: 11.9901
[11/23 03:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.26	
[11/23 03:15:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 03:22:40 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4331, average train loss: 47.6991
[11/23 03:23:31 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5782, average loss: 26.2309
[11/23 03:23:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.40	
[11/23 03:23:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 03:31:02 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4384, average train loss: 45.2072
[11/23 03:31:54 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5776, average loss: 32.8155
[11/23 03:31:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.87	
[11/23 03:31:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 03:39:25 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4460, average train loss: 55.8975
[11/23 03:40:16 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5817, average loss: 97.0035
[11/23 03:40:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/23 03:40:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 03:47:47 visual_prompt]: Epoch 12 / 100: avg data time: 5.01e+00, avg batch time: 6.4349, average train loss: 73.6140
[11/23 03:48:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5804, average loss: 46.6619
[11/23 03:48:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/23 03:48:39 visual_prompt]: Best epoch 12: best metric: -46.662
[11/23 03:48:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 03:56:09 visual_prompt]: Epoch 13 / 100: avg data time: 5.00e+00, avg batch time: 6.4302, average train loss: 73.8447
[11/23 03:57:00 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5786, average loss: 36.8033
[11/23 03:57:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.25	
[11/23 03:57:00 visual_prompt]: Best epoch 13: best metric: -36.803
[11/23 03:57:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 04:04:31 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4364, average train loss: 66.3276
[11/23 04:05:23 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5851, average loss: 40.3746
[11/23 04:05:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.99	
[11/23 04:05:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 04:12:53 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4273, average train loss: 44.0138
[11/23 04:13:44 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5849, average loss: 62.5143
[11/23 04:13:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.06	
[11/23 04:13:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 04:21:14 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4242, average train loss: 60.8178
[11/23 04:22:05 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5810, average loss: 78.9373
[11/23 04:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.80	
[11/23 04:22:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 04:29:36 visual_prompt]: Epoch 17 / 100: avg data time: 5.00e+00, avg batch time: 6.4363, average train loss: 70.1742
[11/23 04:30:27 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5805, average loss: 47.0000
[11/23 04:30:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.10	
[11/23 04:30:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 04:37:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.98e+00, avg batch time: 6.4068, average train loss: 72.0207
[11/23 04:38:47 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5768, average loss: 180.6186
[11/23 04:38:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.03	
[11/23 04:38:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 04:46:17 visual_prompt]: Epoch 19 / 100: avg data time: 4.99e+00, avg batch time: 6.4254, average train loss: 52.7497
[11/23 04:47:09 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5814, average loss: 10.9395
[11/23 04:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/23 04:47:09 visual_prompt]: Best epoch 19: best metric: -10.940
[11/23 04:47:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 04:54:40 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4502, average train loss: 66.2339
[11/23 04:55:32 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5794, average loss: 68.7037
[11/23 04:55:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/23 04:55:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 05:03:03 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4469, average train loss: 41.2648
[11/23 05:03:55 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5809, average loss: 22.5610
[11/23 05:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.42	
[11/23 05:03:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 05:11:26 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e+00, avg batch time: 6.4429, average train loss: 62.9471
[11/23 05:12:17 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5809, average loss: 22.4820
[11/23 05:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/23 05:12:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 05:19:49 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e+00, avg batch time: 6.4532, average train loss: 43.8226
[11/23 05:20:41 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5839, average loss: 2.9938
[11/23 05:20:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 50.62	
[11/23 05:20:41 visual_prompt]: Best epoch 23: best metric: -2.994
[11/23 05:20:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 05:28:11 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4336, average train loss: 53.3922
[11/23 05:29:03 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5824, average loss: 58.7837
[11/23 05:29:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.56	
[11/23 05:29:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 05:36:35 visual_prompt]: Epoch 25 / 100: avg data time: 5.03e+00, avg batch time: 6.4561, average train loss: 55.7526
[11/23 05:37:26 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5809, average loss: 81.7253
[11/23 05:37:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.51	
[11/23 05:37:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 05:44:56 visual_prompt]: Epoch 26 / 100: avg data time: 4.99e+00, avg batch time: 6.4214, average train loss: 55.7976
[11/23 05:45:47 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5831, average loss: 21.4056
[11/23 05:45:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.68	
[11/23 05:45:47 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 05:53:17 visual_prompt]: Epoch 27 / 100: avg data time: 4.99e+00, avg batch time: 6.4217, average train loss: 34.8045
[11/23 05:54:09 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5852, average loss: 27.6092
[11/23 05:54:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/23 05:54:09 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 06:01:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.03e+00, avg batch time: 6.4640, average train loss: 44.9755
[11/23 06:02:33 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5831, average loss: 1.4754
[11/23 06:02:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.14	
[11/23 06:02:33 visual_prompt]: Best epoch 28: best metric: -1.475
[11/23 06:02:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 06:10:02 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4224, average train loss: 44.0545
[11/23 06:10:54 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5780, average loss: 260.0705
[11/23 06:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.09	
[11/23 06:10:54 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 06:18:25 visual_prompt]: Epoch 30 / 100: avg data time: 5.02e+00, avg batch time: 6.4473, average train loss: 63.1470
[11/23 06:19:17 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5806, average loss: 24.1087
[11/23 06:19:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.04	
[11/23 06:19:17 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 06:26:46 visual_prompt]: Epoch 31 / 100: avg data time: 4.99e+00, avg batch time: 6.4181, average train loss: 37.0340
[11/23 06:27:38 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5787, average loss: 11.5403
[11/23 06:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.37	
[11/23 06:27:38 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 06:35:08 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4373, average train loss: 44.4204
[11/23 06:36:00 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5777, average loss: 109.9710
[11/23 06:36:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.73	
[11/23 06:36:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 06:43:32 visual_prompt]: Epoch 33 / 100: avg data time: 5.01e+00, avg batch time: 6.4519, average train loss: 53.9043
[11/23 06:44:23 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5823, average loss: 58.6641
[11/23 06:44:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.13	
[11/23 06:44:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 06:51:54 visual_prompt]: Epoch 34 / 100: avg data time: 5.01e+00, avg batch time: 6.4409, average train loss: 46.9848
[11/23 06:52:46 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5783, average loss: 76.9097
[11/23 06:52:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.49	
[11/23 06:52:46 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 07:00:17 visual_prompt]: Epoch 35 / 100: avg data time: 5.02e+00, avg batch time: 6.4465, average train loss: 44.3540
[11/23 07:01:09 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5823, average loss: 27.6591
[11/23 07:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.30	
[11/23 07:01:09 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 07:08:40 visual_prompt]: Epoch 36 / 100: avg data time: 5.01e+00, avg batch time: 6.4479, average train loss: 48.0853
[11/23 07:09:32 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5806, average loss: 40.0645
[11/23 07:09:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.56	
[11/23 07:09:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 07:17:04 visual_prompt]: Epoch 37 / 100: avg data time: 5.02e+00, avg batch time: 6.4547, average train loss: 41.3010
[11/23 07:17:55 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5834, average loss: 6.3328
[11/23 07:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.50	
[11/23 07:17:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 07:25:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.01e+00, avg batch time: 6.4375, average train loss: 41.6885
[11/23 07:26:17 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5785, average loss: 65.0417
[11/23 07:26:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.63	
[11/23 07:26:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 07:33:49 visual_prompt]: Epoch 39 / 100: avg data time: 5.03e+00, avg batch time: 6.4549, average train loss: 44.3886
[11/23 07:34:41 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5822, average loss: 6.3829
[11/23 07:34:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 47.31	
[11/23 07:34:41 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/23 07:42:13 visual_prompt]: Epoch 40 / 100: avg data time: 5.02e+00, avg batch time: 6.4539, average train loss: 35.7436
[11/23 07:43:04 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5824, average loss: 45.0229
[11/23 07:43:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/23 07:43:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/23 07:50:35 visual_prompt]: Epoch 41 / 100: avg data time: 5.01e+00, avg batch time: 6.4410, average train loss: 63.7943
[11/23 07:51:27 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5796, average loss: 27.7560
[11/23 07:51:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 51.02	
[11/23 07:51:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/23 07:58:57 visual_prompt]: Epoch 42 / 100: avg data time: 5.01e+00, avg batch time: 6.4386, average train loss: 37.8346
[11/23 07:59:49 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5818, average loss: 28.7439
[11/23 07:59:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.39	
[11/23 07:59:49 visual_prompt]: Stopping early.
[11/23 07:59:49 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 07:59:49 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 07:59:49 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/23 07:59:49 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 07:59:49 visual_prompt]: Training with config:
[11/23 07:59:49 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 07:59:49 visual_prompt]: Loading training data...
[11/23 07:59:49 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 07:59:49 visual_prompt]: Loading validation data...
[11/23 07:59:49 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 07:59:49 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 07:59:52 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 07:59:52 visual_prompt]: tuned percent:0.532
[11/23 07:59:52 visual_prompt]: Device used for model: 0
[11/23 07:59:52 visual_prompt]: Setting up Evaluator...
[11/23 07:59:52 visual_prompt]: Setting up Trainer...
[11/23 07:59:52 visual_prompt]: 	Setting up the optimizer...
[11/23 07:59:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 08:07:24 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4654, average train loss: 1.4863
[11/23 08:08:16 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5809, average loss: 1.4553
[11/23 08:08:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 08:08:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 08:15:47 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4428, average train loss: 14.1045
[11/23 08:16:39 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5778, average loss: 9.4368
[11/23 08:16:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.83	
[11/23 08:16:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 08:24:10 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4480, average train loss: 12.1708
[11/23 08:25:02 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5774, average loss: 17.5772
[11/23 08:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.57	
[11/23 08:25:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 08:32:31 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e+00, avg batch time: 6.4203, average train loss: 28.3325
[11/23 08:33:22 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5810, average loss: 30.1488
[11/23 08:33:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.28	
[11/23 08:33:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 08:40:52 visual_prompt]: Epoch 5 / 100: avg data time: 4.99e+00, avg batch time: 6.4252, average train loss: 20.1486
[11/23 08:41:44 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5825, average loss: 34.7076
[11/23 08:41:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.32	
[11/23 08:41:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 08:49:16 visual_prompt]: Epoch 6 / 100: avg data time: 5.02e+00, avg batch time: 6.4586, average train loss: 13.5248
[11/23 08:50:08 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5845, average loss: 7.0067
[11/23 08:50:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.84	
[11/23 08:50:08 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 08:57:37 visual_prompt]: Epoch 7 / 100: avg data time: 4.98e+00, avg batch time: 6.4166, average train loss: 13.7616
[11/23 08:58:29 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5805, average loss: 48.1128
[11/23 08:58:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.41	
[11/23 08:58:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 09:05:59 visual_prompt]: Epoch 8 / 100: avg data time: 5.00e+00, avg batch time: 6.4335, average train loss: 52.1651
[11/23 09:06:51 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5819, average loss: 11.1195
[11/23 09:06:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.54	
[11/23 09:06:51 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 09:14:20 visual_prompt]: Epoch 9 / 100: avg data time: 4.99e+00, avg batch time: 6.4229, average train loss: 41.3893
[11/23 09:15:12 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5811, average loss: 26.3347
[11/23 09:15:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.17	
[11/23 09:15:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 09:22:42 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4275, average train loss: 44.9572
[11/23 09:23:33 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5863, average loss: 42.2427
[11/23 09:23:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.87	
[11/23 09:23:33 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 09:31:05 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4527, average train loss: 42.2056
[11/23 09:31:57 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5801, average loss: 51.3139
[11/23 09:31:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.48	
[11/23 09:31:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 09:39:27 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e+00, avg batch time: 6.4362, average train loss: 43.9473
[11/23 09:40:19 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5811, average loss: 31.6831
[11/23 09:40:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.15	
[11/23 09:40:19 visual_prompt]: Best epoch 12: best metric: -31.683
[11/23 09:40:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 09:47:51 visual_prompt]: Epoch 13 / 100: avg data time: 5.02e+00, avg batch time: 6.4489, average train loss: 32.5941
[11/23 09:48:42 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5807, average loss: 33.9490
[11/23 09:48:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/23 09:48:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 09:56:13 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4338, average train loss: 48.6793
[11/23 09:57:04 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5829, average loss: 57.6376
[11/23 09:57:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.49	
[11/23 09:57:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 10:04:34 visual_prompt]: Epoch 15 / 100: avg data time: 4.99e+00, avg batch time: 6.4169, average train loss: 43.8270
[11/23 10:05:25 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5795, average loss: 61.6118
[11/23 10:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.04	
[11/23 10:05:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 10:12:55 visual_prompt]: Epoch 16 / 100: avg data time: 4.99e+00, avg batch time: 6.4233, average train loss: 22.3551
[11/23 10:13:47 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5784, average loss: 47.9962
[11/23 10:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.83	
[11/23 10:13:47 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 10:21:17 visual_prompt]: Epoch 17 / 100: avg data time: 5.01e+00, avg batch time: 6.4384, average train loss: 49.6621
[11/23 10:22:09 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5807, average loss: 10.1766
[11/23 10:22:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.02	
[11/23 10:22:09 visual_prompt]: Best epoch 17: best metric: -10.177
[11/23 10:22:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 10:29:38 visual_prompt]: Epoch 18 / 100: avg data time: 4.99e+00, avg batch time: 6.4228, average train loss: 40.4469
[11/23 10:30:30 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5799, average loss: 40.1932
[11/23 10:30:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.31	
[11/23 10:30:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 10:38:00 visual_prompt]: Epoch 19 / 100: avg data time: 5.01e+00, avg batch time: 6.4334, average train loss: 35.7924
[11/23 10:38:52 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5793, average loss: 12.3812
[11/23 10:38:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.54	
[11/23 10:38:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 10:46:24 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4515, average train loss: 40.1632
[11/23 10:47:15 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5827, average loss: 36.6647
[11/23 10:47:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.07	
[11/23 10:47:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 10:54:46 visual_prompt]: Epoch 21 / 100: avg data time: 5.01e+00, avg batch time: 6.4420, average train loss: 36.4532
[11/23 10:55:38 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5840, average loss: 25.0213
[11/23 10:55:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.33	
[11/23 10:55:38 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 11:03:08 visual_prompt]: Epoch 22 / 100: avg data time: 5.01e+00, avg batch time: 6.4349, average train loss: 46.5363
[11/23 11:04:00 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5784, average loss: 54.7477
[11/23 11:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.19	
[11/23 11:04:00 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 11:11:32 visual_prompt]: Epoch 23 / 100: avg data time: 5.03e+00, avg batch time: 6.4538, average train loss: 41.4210
[11/23 11:12:23 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5849, average loss: 70.8233
[11/23 11:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.70	
[11/23 11:12:23 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 11:19:53 visual_prompt]: Epoch 24 / 100: avg data time: 4.99e+00, avg batch time: 6.4227, average train loss: 25.7247
[11/23 11:20:44 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5773, average loss: 20.1975
[11/23 11:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.90	
[11/23 11:20:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 11:28:20 visual_prompt]: Epoch 25 / 100: avg data time: 5.09e+00, avg batch time: 6.5112, average train loss: 49.7056
[11/23 11:29:12 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5819, average loss: 292.2785
[11/23 11:29:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.15	
[11/23 11:29:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 11:36:42 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4250, average train loss: 80.1109
[11/23 11:37:33 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5829, average loss: 61.1482
[11/23 11:37:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.78	
[11/23 11:37:33 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 11:45:03 visual_prompt]: Epoch 27 / 100: avg data time: 4.99e+00, avg batch time: 6.4270, average train loss: 32.7905
[11/23 11:45:55 visual_prompt]: Inference (val):avg data time: 4.04e-03, avg batch time: 0.5834, average loss: 54.5140
[11/23 11:45:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[11/23 11:45:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 11:53:26 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4489, average train loss: 38.8043
[11/23 11:54:18 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5841, average loss: 39.8181
[11/23 11:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.88	
[11/23 11:54:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 12:01:48 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4256, average train loss: 28.7661
[11/23 12:02:39 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.5791, average loss: 11.3278
[11/23 12:02:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/23 12:02:39 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 12:10:16 visual_prompt]: Epoch 30 / 100: avg data time: 5.09e+00, avg batch time: 6.5201, average train loss: 42.6049
[11/23 12:11:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5796, average loss: 2.1007
[11/23 12:11:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.02	
[11/23 12:11:08 visual_prompt]: Best epoch 30: best metric: -2.101
[11/23 12:11:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 12:18:38 visual_prompt]: Epoch 31 / 100: avg data time: 5.00e+00, avg batch time: 6.4313, average train loss: 22.0164
[11/23 12:19:29 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5803, average loss: 68.9451
[11/23 12:19:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/23 12:19:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 12:27:05 visual_prompt]: Epoch 32 / 100: avg data time: 5.08e+00, avg batch time: 6.5098, average train loss: 40.7430
[11/23 12:27:57 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5822, average loss: 15.0380
[11/23 12:27:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.16	
[11/23 12:27:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 12:35:25 visual_prompt]: Epoch 33 / 100: avg data time: 4.97e+00, avg batch time: 6.4018, average train loss: 22.2787
[11/23 12:36:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5797, average loss: 13.6798
[11/23 12:36:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.80	
[11/23 12:36:16 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 12:43:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.95e+00, avg batch time: 6.3777, average train loss: 36.2158
[11/23 12:44:34 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5825, average loss: 22.6130
[11/23 12:44:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.23	
[11/23 12:44:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 12:51:59 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3659, average train loss: 56.1053
[11/23 12:52:50 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5776, average loss: 5.3855
[11/23 12:52:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/23 12:52:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 13:00:18 visual_prompt]: Epoch 36 / 100: avg data time: 4.96e+00, avg batch time: 6.3861, average train loss: 59.4651
[11/23 13:01:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5789, average loss: 48.3050
[11/23 13:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.81	
[11/23 13:01:09 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 13:08:35 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3713, average train loss: 32.2662
[11/23 13:09:26 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5843, average loss: 72.6989
[11/23 13:09:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/23 13:09:26 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 13:16:52 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.3807, average train loss: 42.5562
[11/23 13:17:44 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5820, average loss: 4.2675
[11/23 13:17:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.39	
[11/23 13:17:44 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 13:25:10 visual_prompt]: Epoch 39 / 100: avg data time: 4.94e+00, avg batch time: 6.3729, average train loss: 36.5143
[11/23 13:26:01 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5785, average loss: 4.1555
[11/23 13:26:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.22	
[11/23 13:26:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/23 13:33:27 visual_prompt]: Epoch 40 / 100: avg data time: 4.94e+00, avg batch time: 6.3718, average train loss: 39.6153
[11/23 13:34:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5815, average loss: 7.0833
[11/23 13:34:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/23 13:34:18 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/23 13:41:45 visual_prompt]: Epoch 41 / 100: avg data time: 4.95e+00, avg batch time: 6.3824, average train loss: 19.3398
[11/23 13:42:36 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5797, average loss: 206.9054
[11/23 13:42:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.06	
[11/23 13:42:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/23 13:50:02 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3744, average train loss: 50.4669
[11/23 13:50:53 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5799, average loss: 4.0986
[11/23 13:50:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.62	
[11/23 13:50:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/23 13:58:21 visual_prompt]: Epoch 43 / 100: avg data time: 4.97e+00, avg batch time: 6.3964, average train loss: 43.5799
[11/23 13:59:12 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5817, average loss: 134.5260
[11/23 13:59:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.64	
[11/23 13:59:12 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/23 14:06:41 visual_prompt]: Epoch 44 / 100: avg data time: 4.97e+00, avg batch time: 6.4040, average train loss: 45.4177
[11/23 14:07:32 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5782, average loss: 15.0290
[11/23 14:07:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.72	
[11/23 14:07:32 visual_prompt]: Stopping early.
[11/23 14:07:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 14:07:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 14:07:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/23 14:07:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 14:07:32 visual_prompt]: Training with config:
[11/23 14:07:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr25.0_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 14:07:32 visual_prompt]: Loading training data...
[11/23 14:07:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 14:07:32 visual_prompt]: Loading validation data...
[11/23 14:07:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 14:07:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 14:07:35 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 14:07:35 visual_prompt]: tuned percent:0.532
[11/23 14:07:35 visual_prompt]: Device used for model: 0
[11/23 14:07:35 visual_prompt]: Setting up Evaluator...
[11/23 14:07:35 visual_prompt]: Setting up Trainer...
[11/23 14:07:35 visual_prompt]: 	Setting up the optimizer...
[11/23 14:07:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 14:15:02 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.3966, average train loss: 1.4863
[11/23 14:15:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5774, average loss: 1.4553
[11/23 14:15:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 14:15:54 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/23 14:23:21 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.3844, average train loss: 12.0091
[11/23 14:24:12 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5780, average loss: 5.3519
[11/23 14:24:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.88	
[11/23 14:24:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/23 14:31:38 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e+00, avg batch time: 6.3774, average train loss: 12.7435
[11/23 14:32:29 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5775, average loss: 21.8348
[11/23 14:32:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.51	
[11/23 14:32:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/23 14:39:54 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3594, average train loss: 28.3749
[11/23 14:40:45 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5822, average loss: 21.9880
[11/23 14:40:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/23 14:40:45 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/23 14:48:15 visual_prompt]: Epoch 5 / 100: avg data time: 4.99e+00, avg batch time: 6.4159, average train loss: 30.4389
[11/23 14:49:06 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5807, average loss: 17.9642
[11/23 14:49:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/23 14:49:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/23 14:56:35 visual_prompt]: Epoch 6 / 100: avg data time: 4.99e+00, avg batch time: 6.4156, average train loss: 38.2745
[11/23 14:57:26 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5760, average loss: 24.7019
[11/23 14:57:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.51	
[11/23 14:57:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/23 15:04:52 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3650, average train loss: 17.9071
[11/23 15:05:43 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5797, average loss: 54.3213
[11/23 15:05:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[11/23 15:05:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/23 15:13:09 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3755, average train loss: 37.1880
[11/23 15:14:00 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5783, average loss: 25.2939
[11/23 15:14:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.58	
[11/23 15:14:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/23 15:21:25 visual_prompt]: Epoch 9 / 100: avg data time: 4.93e+00, avg batch time: 6.3625, average train loss: 32.9157
[11/23 15:22:16 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5816, average loss: 7.0755
[11/23 15:22:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.00	
[11/23 15:22:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/23 15:29:42 visual_prompt]: Epoch 10 / 100: avg data time: 4.94e+00, avg batch time: 6.3681, average train loss: 29.5431
[11/23 15:30:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5790, average loss: 16.9934
[11/23 15:30:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.65	
[11/23 15:30:33 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/23 15:38:00 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3781, average train loss: 24.2630
[11/23 15:38:51 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5784, average loss: 22.6335
[11/23 15:38:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/23 15:38:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/23 15:46:17 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3704, average train loss: 35.4042
[11/23 15:47:08 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5789, average loss: 49.3523
[11/23 15:47:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.53	
[11/23 15:47:08 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/23 15:54:35 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3790, average train loss: 24.6365
[11/23 15:55:26 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5820, average loss: 52.9193
[11/23 15:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/23 15:55:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/23 16:02:52 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3676, average train loss: 31.0816
[11/23 16:03:43 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5765, average loss: 8.3084
[11/23 16:03:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.55	
[11/23 16:03:43 visual_prompt]: Best epoch 14: best metric: -8.308
[11/23 16:03:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/23 16:11:07 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3515, average train loss: 34.8043
[11/23 16:11:58 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5831, average loss: 9.7471
[11/23 16:11:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.99	
[11/23 16:11:58 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/23 16:19:24 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3678, average train loss: 66.6468
[11/23 16:20:15 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5795, average loss: 36.3207
[11/23 16:20:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.19	
[11/23 16:20:15 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/23 16:27:43 visual_prompt]: Epoch 17 / 100: avg data time: 4.96e+00, avg batch time: 6.3915, average train loss: 17.2166
[11/23 16:28:34 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5814, average loss: 35.5849
[11/23 16:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.25	
[11/23 16:28:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/23 16:36:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3677, average train loss: 21.8187
[11/23 16:36:51 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5817, average loss: 6.5733
[11/23 16:36:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/23 16:36:51 visual_prompt]: Best epoch 18: best metric: -6.573
[11/23 16:36:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/23 16:44:17 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3651, average train loss: 21.6233
[11/23 16:45:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5820, average loss: 58.2876
[11/23 16:45:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/23 16:45:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/23 16:52:36 visual_prompt]: Epoch 20 / 100: avg data time: 4.97e+00, avg batch time: 6.3978, average train loss: 26.4669
[11/23 16:53:27 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5826, average loss: 35.9255
[11/23 16:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.98	
[11/23 16:53:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/23 17:00:57 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4331, average train loss: 22.5894
[11/23 17:01:49 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5836, average loss: 4.4938
[11/23 17:01:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/23 17:01:49 visual_prompt]: Best epoch 21: best metric: -4.494
[11/23 17:01:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/23 17:09:19 visual_prompt]: Epoch 22 / 100: avg data time: 5.00e+00, avg batch time: 6.4254, average train loss: 36.8448
[11/23 17:10:10 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5786, average loss: 31.1177
[11/23 17:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.58	
[11/23 17:10:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/23 17:17:41 visual_prompt]: Epoch 23 / 100: avg data time: 5.00e+00, avg batch time: 6.4350, average train loss: 25.7429
[11/23 17:18:32 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5820, average loss: 27.3958
[11/23 17:18:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.39	
[11/23 17:18:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/23 17:26:02 visual_prompt]: Epoch 24 / 100: avg data time: 4.99e+00, avg batch time: 6.4217, average train loss: 22.0812
[11/23 17:26:53 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5840, average loss: 16.3876
[11/23 17:26:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[11/23 17:26:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/23 17:34:24 visual_prompt]: Epoch 25 / 100: avg data time: 5.01e+00, avg batch time: 6.4380, average train loss: 27.0851
[11/23 17:35:15 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5804, average loss: 19.4446
[11/23 17:35:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.63	
[11/23 17:35:15 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/23 17:42:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.98e+00, avg batch time: 6.4147, average train loss: 16.4704
[11/23 17:43:38 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5756, average loss: 2.5804
[11/23 17:43:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 58.80	
[11/23 17:43:38 visual_prompt]: Best epoch 26: best metric: -2.580
[11/23 17:43:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/23 17:51:06 visual_prompt]: Epoch 27 / 100: avg data time: 4.97e+00, avg batch time: 6.3982, average train loss: 36.2296
[11/23 17:51:58 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5783, average loss: 63.0418
[11/23 17:51:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[11/23 17:51:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/23 17:59:28 visual_prompt]: Epoch 28 / 100: avg data time: 5.00e+00, avg batch time: 6.4301, average train loss: 45.4160
[11/23 18:00:19 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5783, average loss: 5.5664
[11/23 18:00:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.39	
[11/23 18:00:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/23 18:07:48 visual_prompt]: Epoch 29 / 100: avg data time: 4.98e+00, avg batch time: 6.4117, average train loss: 19.8106
[11/23 18:08:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5812, average loss: 4.8114
[11/23 18:08:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.27	
[11/23 18:08:40 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/23 18:16:10 visual_prompt]: Epoch 30 / 100: avg data time: 5.00e+00, avg batch time: 6.4340, average train loss: 12.8429
[11/23 18:17:01 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5836, average loss: 24.3753
[11/23 18:17:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.03	
[11/23 18:17:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/23 18:24:30 visual_prompt]: Epoch 31 / 100: avg data time: 4.97e+00, avg batch time: 6.4057, average train loss: 31.7836
[11/23 18:25:22 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5792, average loss: 2.1278
[11/23 18:25:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 60.76	
[11/23 18:25:22 visual_prompt]: Best epoch 31: best metric: -2.128
[11/23 18:25:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/23 18:32:51 visual_prompt]: Epoch 32 / 100: avg data time: 4.98e+00, avg batch time: 6.4152, average train loss: 10.5953
[11/23 18:33:42 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5793, average loss: 12.6125
[11/23 18:33:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.98	
[11/23 18:33:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/23 18:41:13 visual_prompt]: Epoch 33 / 100: avg data time: 5.00e+00, avg batch time: 6.4313, average train loss: 24.0571
[11/23 18:42:04 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5782, average loss: 3.9808
[11/23 18:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.03	
[11/23 18:42:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/23 18:49:33 visual_prompt]: Epoch 34 / 100: avg data time: 4.97e+00, avg batch time: 6.4083, average train loss: 14.0902
[11/23 18:50:24 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5810, average loss: 5.2535
[11/23 18:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/23 18:50:24 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/23 18:57:53 visual_prompt]: Epoch 35 / 100: avg data time: 4.98e+00, avg batch time: 6.4093, average train loss: 18.7800
[11/23 18:58:45 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5804, average loss: 19.7491
[11/23 18:58:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/23 18:58:45 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/23 19:06:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.00e+00, avg batch time: 6.4315, average train loss: 16.4630
[11/23 19:07:06 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5866, average loss: 28.7687
[11/23 19:07:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.87	
[11/23 19:07:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/23 19:14:35 visual_prompt]: Epoch 37 / 100: avg data time: 4.97e+00, avg batch time: 6.4069, average train loss: 20.7447
[11/23 19:15:26 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5801, average loss: 34.2183
[11/23 19:15:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.61	
[11/23 19:15:26 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/23 19:22:56 visual_prompt]: Epoch 38 / 100: avg data time: 4.98e+00, avg batch time: 6.4199, average train loss: 15.3798
[11/23 19:23:47 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5803, average loss: 50.9128
[11/23 19:23:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/23 19:23:47 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/23 19:31:16 visual_prompt]: Epoch 39 / 100: avg data time: 4.98e+00, avg batch time: 6.4114, average train loss: 27.5735
[11/23 19:32:08 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5804, average loss: 19.0553
[11/23 19:32:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.25	
[11/23 19:32:08 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/23 19:39:36 visual_prompt]: Epoch 40 / 100: avg data time: 4.98e+00, avg batch time: 6.4050, average train loss: 11.9866
[11/23 19:40:27 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5789, average loss: 4.5235
[11/23 19:40:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 63.94	
[11/23 19:40:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/23 19:47:56 visual_prompt]: Epoch 41 / 100: avg data time: 4.98e+00, avg batch time: 6.4120, average train loss: 9.0450
[11/23 19:48:48 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5774, average loss: 20.2232
[11/23 19:48:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.34	
[11/23 19:48:48 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/23 19:56:16 visual_prompt]: Epoch 42 / 100: avg data time: 4.97e+00, avg batch time: 6.3995, average train loss: 7.0879
[11/23 19:57:07 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5854, average loss: 1.3983
[11/23 19:57:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.39	
[11/23 19:57:07 visual_prompt]: Best epoch 42: best metric: -1.398
[11/23 19:57:07 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/23 20:04:37 visual_prompt]: Epoch 43 / 100: avg data time: 4.99e+00, avg batch time: 6.4285, average train loss: 14.8000
[11/23 20:05:29 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5795, average loss: 18.5769
[11/23 20:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.19	
[11/23 20:05:29 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/23 20:12:59 visual_prompt]: Epoch 44 / 100: avg data time: 4.99e+00, avg batch time: 6.4294, average train loss: 14.2442
[11/23 20:13:50 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5829, average loss: 16.6304
[11/23 20:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.74	
[11/23 20:13:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/23 20:21:20 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e+00, avg batch time: 6.4181, average train loss: 9.1219
[11/23 20:22:11 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5802, average loss: 9.5314
[11/23 20:22:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.70	
[11/23 20:22:11 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/23 20:29:39 visual_prompt]: Epoch 46 / 100: avg data time: 4.97e+00, avg batch time: 6.4058, average train loss: 6.9335
[11/23 20:30:31 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5766, average loss: 6.1607
[11/23 20:30:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.45	
[11/23 20:30:31 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/23 20:37:59 visual_prompt]: Epoch 47 / 100: avg data time: 4.98e+00, avg batch time: 6.4102, average train loss: 6.3023
[11/23 20:38:51 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5774, average loss: 5.9604
[11/23 20:38:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.55	
[11/23 20:38:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/23 20:46:19 visual_prompt]: Epoch 48 / 100: avg data time: 4.97e+00, avg batch time: 6.3996, average train loss: 10.8818
[11/23 20:47:10 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5764, average loss: 4.0505
[11/23 20:47:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.84	
[11/23 20:47:10 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/23 20:54:39 visual_prompt]: Epoch 49 / 100: avg data time: 4.97e+00, avg batch time: 6.4070, average train loss: 5.2683
[11/23 20:55:30 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5758, average loss: 12.3859
[11/23 20:55:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[11/23 20:55:30 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/23 21:02:59 visual_prompt]: Epoch 50 / 100: avg data time: 4.97e+00, avg batch time: 6.4096, average train loss: 10.7237
[11/23 21:03:50 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5777, average loss: 22.7845
[11/23 21:03:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.22	
[11/23 21:03:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/23 21:11:19 visual_prompt]: Epoch 51 / 100: avg data time: 4.97e+00, avg batch time: 6.4094, average train loss: 6.8120
[11/23 21:12:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5781, average loss: 14.6110
[11/23 21:12:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.73	
[11/23 21:12:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/23 21:19:40 visual_prompt]: Epoch 52 / 100: avg data time: 4.99e+00, avg batch time: 6.4262, average train loss: 8.3853
[11/23 21:20:32 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5759, average loss: 10.9722
[11/23 21:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[11/23 21:20:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[11/23 21:28:04 visual_prompt]: Epoch 53 / 100: avg data time: 5.02e+00, avg batch time: 6.4531, average train loss: 6.7071
[11/23 21:28:55 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5807, average loss: 13.6650
[11/23 21:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.58	
[11/23 21:28:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[11/23 21:36:27 visual_prompt]: Epoch 54 / 100: avg data time: 5.01e+00, avg batch time: 6.4458, average train loss: 5.6029
[11/23 21:37:18 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5788, average loss: 26.8152
[11/23 21:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.03	
[11/23 21:37:18 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[11/23 21:44:47 visual_prompt]: Epoch 55 / 100: avg data time: 4.97e+00, avg batch time: 6.4073, average train loss: 11.5853
[11/23 21:45:38 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5827, average loss: 1.6903
[11/23 21:45:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 64.94	
[11/23 21:45:38 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[11/23 21:53:07 visual_prompt]: Epoch 56 / 100: avg data time: 4.98e+00, avg batch time: 6.4146, average train loss: 3.3948
[11/23 21:53:59 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5826, average loss: 3.6458
[11/23 21:53:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.44	
[11/23 21:53:59 visual_prompt]: Stopping early.
[11/23 21:53:59 visual_prompt]: Rank of current process: 0. World size: 1
[11/23 21:53:59 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/23 21:53:59 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/23 21:53:59 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/23 21:53:59 visual_prompt]: Training with config:
[11/23 21:53:59 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/23 21:53:59 visual_prompt]: Loading training data...
[11/23 21:53:59 visual_prompt]: Constructing mammo-cbis dataset train...
[11/23 21:53:59 visual_prompt]: Loading validation data...
[11/23 21:53:59 visual_prompt]: Constructing mammo-cbis dataset val...
[11/23 21:53:59 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/23 21:54:02 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/23 21:54:02 visual_prompt]: tuned percent:0.532
[11/23 21:54:02 visual_prompt]: Device used for model: 0
[11/23 21:54:02 visual_prompt]: Setting up Evaluator...
[11/23 21:54:02 visual_prompt]: Setting up Trainer...
[11/23 21:54:02 visual_prompt]: 	Setting up the optimizer...
[11/23 21:54:02 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/23 22:01:33 visual_prompt]: Epoch 1 / 100: avg data time: 5.00e+00, avg batch time: 6.4410, average train loss: 1.4863
[11/23 22:02:24 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5794, average loss: 1.4553
[11/23 22:02:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/23 22:02:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/23 22:09:54 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4298, average train loss: 4.2628
[11/23 22:10:46 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5834, average loss: 3.0798
[11/23 22:10:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.96	
[11/23 22:10:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/23 22:18:16 visual_prompt]: Epoch 3 / 100: avg data time: 5.00e+00, avg batch time: 6.4273, average train loss: 2.8057
[11/23 22:19:07 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5790, average loss: 5.1767
[11/23 22:19:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/23 22:19:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/23 22:26:35 visual_prompt]: Epoch 4 / 100: avg data time: 4.97e+00, avg batch time: 6.4035, average train loss: 6.0841
[11/23 22:27:27 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5838, average loss: 1.0925
[11/23 22:27:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.41	
[11/23 22:27:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/23 22:34:55 visual_prompt]: Epoch 5 / 100: avg data time: 4.97e+00, avg batch time: 6.4072, average train loss: 9.0258
[11/23 22:35:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5818, average loss: 4.7054
[11/23 22:35:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.99	
[11/23 22:35:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/23 22:43:18 visual_prompt]: Epoch 6 / 100: avg data time: 5.01e+00, avg batch time: 6.4508, average train loss: 7.8715
[11/23 22:44:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5822, average loss: 7.6205
[11/23 22:44:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.77	
[11/23 22:44:10 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/23 22:51:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.97e+00, avg batch time: 6.4017, average train loss: 11.8376
[11/23 22:52:29 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5794, average loss: 8.5169
[11/23 22:52:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.50	
[11/23 22:52:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/23 23:00:01 visual_prompt]: Epoch 8 / 100: avg data time: 5.02e+00, avg batch time: 6.4511, average train loss: 16.9194
[11/23 23:00:52 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5855, average loss: 24.7710
[11/23 23:00:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.84	
[11/23 23:00:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/23 23:08:23 visual_prompt]: Epoch 9 / 100: avg data time: 5.01e+00, avg batch time: 6.4395, average train loss: 19.4422
[11/23 23:09:15 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5815, average loss: 30.7351
[11/23 23:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/23 23:09:15 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/23 23:16:45 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e+00, avg batch time: 6.4348, average train loss: 20.7824
[11/23 23:17:37 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5800, average loss: 33.1404
[11/23 23:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/23 23:17:37 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/23 23:25:08 visual_prompt]: Epoch 11 / 100: avg data time: 5.01e+00, avg batch time: 6.4423, average train loss: 21.0017
[11/23 23:26:00 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5832, average loss: 24.1618
[11/23 23:26:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.44	
[11/23 23:26:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/23 23:33:30 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e+00, avg batch time: 6.4272, average train loss: 25.9167
[11/23 23:34:21 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5804, average loss: 19.8308
[11/23 23:34:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.68	
[11/23 23:34:21 visual_prompt]: Best epoch 12: best metric: -19.831
[11/23 23:34:21 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/23 23:41:53 visual_prompt]: Epoch 13 / 100: avg data time: 5.01e+00, avg batch time: 6.4459, average train loss: 28.3131
[11/23 23:42:44 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5832, average loss: 11.1644
[11/23 23:42:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 55.78	
[11/23 23:42:44 visual_prompt]: Best epoch 13: best metric: -11.164
[11/23 23:42:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/23 23:50:16 visual_prompt]: Epoch 14 / 100: avg data time: 5.02e+00, avg batch time: 6.4556, average train loss: 19.9398
[11/23 23:51:08 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5806, average loss: 3.8987
[11/23 23:51:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/23 23:51:08 visual_prompt]: Best epoch 14: best metric: -3.899
[11/23 23:51:08 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/23 23:58:37 visual_prompt]: Epoch 15 / 100: avg data time: 4.98e+00, avg batch time: 6.4157, average train loss: 17.1764
[11/23 23:59:28 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5821, average loss: 26.4822
[11/23 23:59:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 41.06	rocauc: 40.92	
[11/23 23:59:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 00:06:57 visual_prompt]: Epoch 16 / 100: avg data time: 4.98e+00, avg batch time: 6.4115, average train loss: 22.4121
[11/24 00:07:49 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5774, average loss: 9.6794
[11/24 00:07:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.11	
[11/24 00:07:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 00:15:17 visual_prompt]: Epoch 17 / 100: avg data time: 4.97e+00, avg batch time: 6.4059, average train loss: 17.7470
[11/24 00:16:09 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5789, average loss: 25.9551
[11/24 00:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.43	
[11/24 00:16:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 00:23:36 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.3906, average train loss: 20.3399
[11/24 00:24:27 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5797, average loss: 71.2985
[11/24 00:24:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/24 00:24:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 00:31:55 visual_prompt]: Epoch 19 / 100: avg data time: 4.95e+00, avg batch time: 6.3899, average train loss: 18.2647
[11/24 00:32:46 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5792, average loss: 9.5806
[11/24 00:32:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.06	
[11/24 00:32:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 00:40:16 visual_prompt]: Epoch 20 / 100: avg data time: 4.98e+00, avg batch time: 6.4176, average train loss: 25.2810
[11/24 00:41:07 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5797, average loss: 22.5832
[11/24 00:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.03	
[11/24 00:41:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 00:48:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.98e+00, avg batch time: 6.4131, average train loss: 21.7394
[11/24 00:49:27 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5797, average loss: 24.3224
[11/24 00:49:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.05	
[11/24 00:49:27 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 00:56:56 visual_prompt]: Epoch 22 / 100: avg data time: 4.98e+00, avg batch time: 6.4135, average train loss: 35.5453
[11/24 00:57:48 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5777, average loss: 6.4928
[11/24 00:57:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.24	
[11/24 00:57:48 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 01:05:18 visual_prompt]: Epoch 23 / 100: avg data time: 5.00e+00, avg batch time: 6.4347, average train loss: 21.4196
[11/24 01:06:10 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5809, average loss: 17.7449
[11/24 01:06:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.61	
[11/24 01:06:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 01:13:38 visual_prompt]: Epoch 24 / 100: avg data time: 4.97e+00, avg batch time: 6.4078, average train loss: 23.0666
[11/24 01:14:29 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5824, average loss: 69.2306
[11/24 01:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.45	
[11/24 01:14:29 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 01:22:00 visual_prompt]: Epoch 25 / 100: avg data time: 4.99e+00, avg batch time: 6.4316, average train loss: 27.6949
[11/24 01:22:51 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5792, average loss: 70.0105
[11/24 01:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.41	
[11/24 01:22:51 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 01:30:20 visual_prompt]: Epoch 26 / 100: avg data time: 4.98e+00, avg batch time: 6.4076, average train loss: 21.9503
[11/24 01:31:11 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5800, average loss: 28.9259
[11/24 01:31:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.27	
[11/24 01:31:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 01:38:41 visual_prompt]: Epoch 27 / 100: avg data time: 4.99e+00, avg batch time: 6.4265, average train loss: 23.8609
[11/24 01:39:33 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5799, average loss: 15.4007
[11/24 01:39:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.99	
[11/24 01:39:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 01:47:04 visual_prompt]: Epoch 28 / 100: avg data time: 5.01e+00, avg batch time: 6.4456, average train loss: 23.3968
[11/24 01:47:56 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5798, average loss: 18.5482
[11/24 01:47:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.14	
[11/24 01:47:56 visual_prompt]: Stopping early.
[11/24 01:47:56 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 01:47:56 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 01:47:56 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/24 01:47:56 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 01:47:56 visual_prompt]: Training with config:
[11/24 01:47:56 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 01:47:56 visual_prompt]: Loading training data...
[11/24 01:47:56 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 01:47:56 visual_prompt]: Loading validation data...
[11/24 01:47:56 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 01:47:56 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 01:47:59 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 01:47:59 visual_prompt]: tuned percent:0.532
[11/24 01:47:59 visual_prompt]: Device used for model: 0
[11/24 01:47:59 visual_prompt]: Setting up Evaluator...
[11/24 01:47:59 visual_prompt]: Setting up Trainer...
[11/24 01:47:59 visual_prompt]: 	Setting up the optimizer...
[11/24 01:47:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 01:55:31 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4593, average train loss: 1.4863
[11/24 01:56:23 visual_prompt]: Inference (val):avg data time: 3.98e-05, avg batch time: 0.5801, average loss: 1.4553
[11/24 01:56:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 01:56:23 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/24 02:03:54 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4486, average train loss: 3.6290
[11/24 02:04:46 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5784, average loss: 0.7015
[11/24 02:04:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.64	
[11/24 02:04:46 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/24 02:12:17 visual_prompt]: Epoch 3 / 100: avg data time: 5.00e+00, avg batch time: 6.4407, average train loss: 3.3315
[11/24 02:13:09 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5744, average loss: 6.6219
[11/24 02:13:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[11/24 02:13:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/24 02:20:39 visual_prompt]: Epoch 4 / 100: avg data time: 5.00e+00, avg batch time: 6.4330, average train loss: 4.5911
[11/24 02:21:31 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5790, average loss: 18.1257
[11/24 02:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.95	
[11/24 02:21:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/24 02:29:01 visual_prompt]: Epoch 5 / 100: avg data time: 4.99e+00, avg batch time: 6.4312, average train loss: 9.1223
[11/24 02:29:53 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5769, average loss: 9.0045
[11/24 02:29:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.47	
[11/24 02:29:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/24 02:37:27 visual_prompt]: Epoch 6 / 100: avg data time: 5.05e+00, avg batch time: 6.4887, average train loss: 4.2861
[11/24 02:38:19 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5845, average loss: 12.1229
[11/24 02:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/24 02:38:19 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/24 02:45:50 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4497, average train loss: 8.5586
[11/24 02:46:42 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5786, average loss: 1.7698
[11/24 02:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.86	
[11/24 02:46:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/24 02:54:13 visual_prompt]: Epoch 8 / 100: avg data time: 5.01e+00, avg batch time: 6.4474, average train loss: 11.6387
[11/24 02:55:05 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5803, average loss: 23.7068
[11/24 02:55:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/24 02:55:05 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/24 03:02:36 visual_prompt]: Epoch 9 / 100: avg data time: 5.01e+00, avg batch time: 6.4479, average train loss: 19.9712
[11/24 03:03:28 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5823, average loss: 10.6126
[11/24 03:03:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/24 03:03:28 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/24 03:11:00 visual_prompt]: Epoch 10 / 100: avg data time: 5.01e+00, avg batch time: 6.4490, average train loss: 11.6369
[11/24 03:11:51 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5806, average loss: 25.8073
[11/24 03:11:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/24 03:11:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/24 03:19:24 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4595, average train loss: 17.4059
[11/24 03:20:15 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5798, average loss: 9.1535
[11/24 03:20:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.11	
[11/24 03:20:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/24 03:27:46 visual_prompt]: Epoch 12 / 100: avg data time: 5.01e+00, avg batch time: 6.4433, average train loss: 20.5649
[11/24 03:28:38 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5803, average loss: 16.1951
[11/24 03:28:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.04	
[11/24 03:28:38 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/24 03:36:10 visual_prompt]: Epoch 13 / 100: avg data time: 5.02e+00, avg batch time: 6.4501, average train loss: 20.7172
[11/24 03:37:01 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5779, average loss: 20.2129
[11/24 03:37:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/24 03:37:01 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/24 03:44:32 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4443, average train loss: 29.2269
[11/24 03:45:24 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5878, average loss: 12.0221
[11/24 03:45:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/24 03:45:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/24 03:52:55 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4364, average train loss: 16.4286
[11/24 03:53:46 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5810, average loss: 41.7761
[11/24 03:53:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/24 03:53:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 04:01:17 visual_prompt]: Epoch 16 / 100: avg data time: 5.00e+00, avg batch time: 6.4369, average train loss: 26.0824
[11/24 04:02:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5808, average loss: 10.6975
[11/24 04:02:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/24 04:02:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 04:09:40 visual_prompt]: Epoch 17 / 100: avg data time: 5.01e+00, avg batch time: 6.4470, average train loss: 30.1166
[11/24 04:10:31 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5824, average loss: 2.9526
[11/24 04:10:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.60	
[11/24 04:10:31 visual_prompt]: Best epoch 17: best metric: -2.953
[11/24 04:10:31 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 04:18:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.98e+00, avg batch time: 6.4133, average train loss: 19.3340
[11/24 04:18:52 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5819, average loss: 6.7008
[11/24 04:18:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.61	
[11/24 04:18:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 04:26:19 visual_prompt]: Epoch 19 / 100: avg data time: 4.96e+00, avg batch time: 6.3934, average train loss: 15.5036
[11/24 04:27:11 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5802, average loss: 5.0658
[11/24 04:27:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.26	
[11/24 04:27:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 04:34:40 visual_prompt]: Epoch 20 / 100: avg data time: 4.99e+00, avg batch time: 6.4246, average train loss: 20.9254
[11/24 04:35:32 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5777, average loss: 8.0544
[11/24 04:35:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/24 04:35:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 04:43:03 visual_prompt]: Epoch 21 / 100: avg data time: 5.01e+00, avg batch time: 6.4419, average train loss: 11.6590
[11/24 04:43:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5784, average loss: 31.2982
[11/24 04:43:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.47	
[11/24 04:43:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 04:51:26 visual_prompt]: Epoch 22 / 100: avg data time: 5.02e+00, avg batch time: 6.4532, average train loss: 20.6247
[11/24 04:52:18 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5778, average loss: 25.8599
[11/24 04:52:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/24 04:52:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 04:59:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.03e+00, avg batch time: 6.4558, average train loss: 26.0219
[11/24 05:00:42 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5804, average loss: 23.6759
[11/24 05:00:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[11/24 05:00:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 05:08:12 visual_prompt]: Epoch 24 / 100: avg data time: 5.00e+00, avg batch time: 6.4326, average train loss: 13.6635
[11/24 05:09:04 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5774, average loss: 10.0365
[11/24 05:09:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.47	
[11/24 05:09:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 05:16:36 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4584, average train loss: 17.6200
[11/24 05:17:28 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5779, average loss: 0.6902
[11/24 05:17:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 57.28	
[11/24 05:17:28 visual_prompt]: Best epoch 25: best metric: -0.690
[11/24 05:17:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 05:24:59 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4376, average train loss: 22.7075
[11/24 05:25:50 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5799, average loss: 6.7935
[11/24 05:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.86	
[11/24 05:25:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 05:33:21 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4429, average train loss: 26.4200
[11/24 05:34:13 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5803, average loss: 19.3973
[11/24 05:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.33	
[11/24 05:34:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 05:41:45 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4532, average train loss: 19.0276
[11/24 05:42:36 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5793, average loss: 18.1109
[11/24 05:42:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.91	
[11/24 05:42:36 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/24 05:50:07 visual_prompt]: Epoch 29 / 100: avg data time: 5.01e+00, avg batch time: 6.4420, average train loss: 16.6779
[11/24 05:50:58 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5764, average loss: 59.9815
[11/24 05:50:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.77	
[11/24 05:50:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/24 05:58:31 visual_prompt]: Epoch 30 / 100: avg data time: 5.03e+00, avg batch time: 6.4568, average train loss: 21.1487
[11/24 05:59:22 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5795, average loss: 5.0961
[11/24 05:59:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.28	
[11/24 05:59:22 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/24 06:06:52 visual_prompt]: Epoch 31 / 100: avg data time: 5.00e+00, avg batch time: 6.4308, average train loss: 17.6643
[11/24 06:07:44 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5799, average loss: 22.5894
[11/24 06:07:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/24 06:07:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/24 06:15:16 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4558, average train loss: 17.2669
[11/24 06:16:08 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5762, average loss: 79.8224
[11/24 06:16:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/24 06:16:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/24 06:23:40 visual_prompt]: Epoch 33 / 100: avg data time: 5.01e+00, avg batch time: 6.4500, average train loss: 17.8570
[11/24 06:24:31 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5789, average loss: 5.8537
[11/24 06:24:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.80	
[11/24 06:24:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/24 06:32:02 visual_prompt]: Epoch 34 / 100: avg data time: 5.00e+00, avg batch time: 6.4358, average train loss: 12.7621
[11/24 06:32:53 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5790, average loss: 35.0363
[11/24 06:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.25	
[11/24 06:32:53 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/24 06:40:25 visual_prompt]: Epoch 35 / 100: avg data time: 5.00e+00, avg batch time: 6.4550, average train loss: 11.9029
[11/24 06:41:17 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5825, average loss: 26.8221
[11/24 06:41:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/24 06:41:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/24 06:48:48 visual_prompt]: Epoch 36 / 100: avg data time: 5.01e+00, avg batch time: 6.4457, average train loss: 17.2054
[11/24 06:49:40 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5780, average loss: 41.0775
[11/24 06:49:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.96	
[11/24 06:49:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/24 06:57:09 visual_prompt]: Epoch 37 / 100: avg data time: 4.99e+00, avg batch time: 6.4234, average train loss: 15.1260
[11/24 06:58:01 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5771, average loss: 4.0567
[11/24 06:58:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/24 06:58:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/24 07:05:31 visual_prompt]: Epoch 38 / 100: avg data time: 4.99e+00, avg batch time: 6.4315, average train loss: 12.4601
[11/24 07:06:23 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5853, average loss: 16.4591
[11/24 07:06:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.95	
[11/24 07:06:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/24 07:13:52 visual_prompt]: Epoch 39 / 100: avg data time: 4.98e+00, avg batch time: 6.4145, average train loss: 14.7313
[11/24 07:14:43 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5776, average loss: 2.9662
[11/24 07:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/24 07:14:43 visual_prompt]: Stopping early.
[11/24 07:14:43 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 07:14:43 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 07:14:43 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/24 07:14:43 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 07:14:43 visual_prompt]: Training with config:
[11/24 07:14:43 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 07:14:43 visual_prompt]: Loading training data...
[11/24 07:14:43 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 07:14:43 visual_prompt]: Loading validation data...
[11/24 07:14:43 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 07:14:43 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 07:14:46 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 07:14:46 visual_prompt]: tuned percent:0.532
[11/24 07:14:46 visual_prompt]: Device used for model: 0
[11/24 07:14:46 visual_prompt]: Setting up Evaluator...
[11/24 07:14:46 visual_prompt]: Setting up Trainer...
[11/24 07:14:46 visual_prompt]: 	Setting up the optimizer...
[11/24 07:14:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 07:22:17 visual_prompt]: Epoch 1 / 100: avg data time: 5.01e+00, avg batch time: 6.4458, average train loss: 1.4863
[11/24 07:23:09 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5801, average loss: 1.4553
[11/24 07:23:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 07:23:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/24 07:30:40 visual_prompt]: Epoch 2 / 100: avg data time: 5.00e+00, avg batch time: 6.4354, average train loss: 3.8484
[11/24 07:31:31 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5774, average loss: 4.6136
[11/24 07:31:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.53	
[11/24 07:31:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/24 07:39:01 visual_prompt]: Epoch 3 / 100: avg data time: 4.99e+00, avg batch time: 6.4248, average train loss: 4.0152
[11/24 07:39:53 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5768, average loss: 3.4962
[11/24 07:39:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/24 07:39:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/24 07:47:21 visual_prompt]: Epoch 4 / 100: avg data time: 4.97e+00, avg batch time: 6.4096, average train loss: 9.5956
[11/24 07:48:13 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5809, average loss: 17.7444
[11/24 07:48:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.27	
[11/24 07:48:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/24 07:55:42 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4191, average train loss: 11.9517
[11/24 07:56:33 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5827, average loss: 6.3556
[11/24 07:56:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.19	
[11/24 07:56:33 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/24 08:04:04 visual_prompt]: Epoch 6 / 100: avg data time: 4.99e+00, avg batch time: 6.4300, average train loss: 5.5102
[11/24 08:04:55 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5799, average loss: 12.4938
[11/24 08:04:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.18	
[11/24 08:04:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/24 08:12:23 visual_prompt]: Epoch 7 / 100: avg data time: 4.96e+00, avg batch time: 6.3967, average train loss: 10.8707
[11/24 08:13:14 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5814, average loss: 15.6162
[11/24 08:13:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/24 08:13:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/24 08:20:44 visual_prompt]: Epoch 8 / 100: avg data time: 4.99e+00, avg batch time: 6.4232, average train loss: 16.1962
[11/24 08:21:36 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5802, average loss: 20.9911
[11/24 08:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/24 08:21:36 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/24 08:29:05 visual_prompt]: Epoch 9 / 100: avg data time: 4.98e+00, avg batch time: 6.4130, average train loss: 10.8896
[11/24 08:29:56 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.6211, average loss: 9.4035
[11/24 08:29:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.40	
[11/24 08:29:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/24 08:37:24 visual_prompt]: Epoch 10 / 100: avg data time: 4.96e+00, avg batch time: 6.3906, average train loss: 8.6100
[11/24 08:38:15 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5801, average loss: 13.1743
[11/24 08:38:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.28	
[11/24 08:38:15 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/24 08:45:46 visual_prompt]: Epoch 11 / 100: avg data time: 5.00e+00, avg batch time: 6.4323, average train loss: 18.8795
[11/24 08:46:37 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5785, average loss: 8.2741
[11/24 08:46:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[11/24 08:46:37 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/24 08:54:06 visual_prompt]: Epoch 12 / 100: avg data time: 4.98e+00, avg batch time: 6.4126, average train loss: 6.8283
[11/24 08:54:57 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5780, average loss: 5.3706
[11/24 08:54:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.73	
[11/24 08:54:57 visual_prompt]: Best epoch 12: best metric: -5.371
[11/24 08:54:57 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/24 09:02:27 visual_prompt]: Epoch 13 / 100: avg data time: 5.00e+00, avg batch time: 6.4275, average train loss: 23.1503
[11/24 09:03:19 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5807, average loss: 18.8135
[11/24 09:03:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/24 09:03:19 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/24 09:10:48 visual_prompt]: Epoch 14 / 100: avg data time: 4.97e+00, avg batch time: 6.4109, average train loss: 17.3023
[11/24 09:11:39 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5768, average loss: 9.3853
[11/24 09:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.40	
[11/24 09:11:39 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/24 09:19:08 visual_prompt]: Epoch 15 / 100: avg data time: 4.98e+00, avg batch time: 6.4188, average train loss: 15.3914
[11/24 09:20:00 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5803, average loss: 16.7519
[11/24 09:20:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.92	
[11/24 09:20:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 09:27:29 visual_prompt]: Epoch 16 / 100: avg data time: 4.98e+00, avg batch time: 6.4183, average train loss: 8.8022
[11/24 09:28:21 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5773, average loss: 17.3945
[11/24 09:28:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.41	
[11/24 09:28:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 09:35:51 visual_prompt]: Epoch 17 / 100: avg data time: 4.99e+00, avg batch time: 6.4292, average train loss: 11.0128
[11/24 09:36:43 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5840, average loss: 4.9359
[11/24 09:36:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.66	
[11/24 09:36:43 visual_prompt]: Best epoch 17: best metric: -4.936
[11/24 09:36:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 09:44:13 visual_prompt]: Epoch 18 / 100: avg data time: 5.00e+00, avg batch time: 6.4286, average train loss: 20.5911
[11/24 09:45:04 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5772, average loss: 2.0057
[11/24 09:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.90	
[11/24 09:45:04 visual_prompt]: Best epoch 18: best metric: -2.006
[11/24 09:45:04 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 09:52:35 visual_prompt]: Epoch 19 / 100: avg data time: 4.99e+00, avg batch time: 6.4376, average train loss: 11.3233
[11/24 09:53:27 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5871, average loss: 34.0491
[11/24 09:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/24 09:53:27 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 10:00:59 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4570, average train loss: 11.8072
[11/24 10:01:50 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5852, average loss: 7.3134
[11/24 10:01:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/24 10:01:50 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 10:09:22 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4508, average train loss: 6.6352
[11/24 10:10:14 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5810, average loss: 2.0948
[11/24 10:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.44	
[11/24 10:10:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 10:17:44 visual_prompt]: Epoch 22 / 100: avg data time: 4.99e+00, avg batch time: 6.4291, average train loss: 11.7063
[11/24 10:18:36 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5800, average loss: 22.8586
[11/24 10:18:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.40	
[11/24 10:18:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 10:26:08 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e+00, avg batch time: 6.4545, average train loss: 17.6822
[11/24 10:26:59 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5798, average loss: 12.0150
[11/24 10:26:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/24 10:26:59 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 10:34:31 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4522, average train loss: 16.8503
[11/24 10:35:22 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5811, average loss: 5.5806
[11/24 10:35:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.11	
[11/24 10:35:22 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 10:42:57 visual_prompt]: Epoch 25 / 100: avg data time: 5.05e+00, avg batch time: 6.4927, average train loss: 13.8365
[11/24 10:43:49 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5835, average loss: 1.9885
[11/24 10:43:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.12	
[11/24 10:43:49 visual_prompt]: Best epoch 25: best metric: -1.989
[11/24 10:43:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 10:51:20 visual_prompt]: Epoch 26 / 100: avg data time: 5.01e+00, avg batch time: 6.4444, average train loss: 14.8586
[11/24 10:52:12 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5783, average loss: 12.7063
[11/24 10:52:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.66	
[11/24 10:52:12 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 10:59:43 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4402, average train loss: 21.0689
[11/24 11:00:34 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5803, average loss: 23.5132
[11/24 11:00:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.67	
[11/24 11:00:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 11:08:06 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4479, average train loss: 28.3326
[11/24 11:08:57 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5796, average loss: 12.2928
[11/24 11:08:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.39	
[11/24 11:08:57 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/24 11:16:27 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4221, average train loss: 10.9070
[11/24 11:17:18 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5808, average loss: 17.8515
[11/24 11:17:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.68	
[11/24 11:17:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/24 11:24:49 visual_prompt]: Epoch 30 / 100: avg data time: 5.00e+00, avg batch time: 6.4418, average train loss: 11.5604
[11/24 11:25:41 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5829, average loss: 21.8766
[11/24 11:25:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.59	
[11/24 11:25:41 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/24 11:33:10 visual_prompt]: Epoch 31 / 100: avg data time: 4.98e+00, avg batch time: 6.4122, average train loss: 8.7012
[11/24 11:34:01 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5784, average loss: 0.6995
[11/24 11:34:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/24 11:34:01 visual_prompt]: Best epoch 31: best metric: -0.700
[11/24 11:34:01 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/24 11:41:31 visual_prompt]: Epoch 32 / 100: avg data time: 4.99e+00, avg batch time: 6.4252, average train loss: 5.9034
[11/24 11:42:23 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5768, average loss: 0.8802
[11/24 11:42:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.57	
[11/24 11:42:23 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/24 11:49:54 visual_prompt]: Epoch 33 / 100: avg data time: 5.00e+00, avg batch time: 6.4401, average train loss: 6.1837
[11/24 11:50:45 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5789, average loss: 9.3105
[11/24 11:50:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.39	
[11/24 11:50:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/24 11:58:15 visual_prompt]: Epoch 34 / 100: avg data time: 4.99e+00, avg batch time: 6.4179, average train loss: 7.6691
[11/24 11:59:06 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5799, average loss: 1.2568
[11/24 11:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.96	
[11/24 11:59:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/24 12:06:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.97e+00, avg batch time: 6.4045, average train loss: 16.6743
[11/24 12:07:26 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5762, average loss: 24.7372
[11/24 12:07:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.41	
[11/24 12:07:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/24 12:14:57 visual_prompt]: Epoch 36 / 100: avg data time: 5.01e+00, avg batch time: 6.4404, average train loss: 15.7066
[11/24 12:15:48 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5779, average loss: 8.1762
[11/24 12:15:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.91	
[11/24 12:15:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/24 12:23:20 visual_prompt]: Epoch 37 / 100: avg data time: 5.01e+00, avg batch time: 6.4470, average train loss: 20.3900
[11/24 12:24:11 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5835, average loss: 28.9904
[11/24 12:24:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.22	
[11/24 12:24:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/24 12:31:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.00e+00, avg batch time: 6.4285, average train loss: 18.5016
[11/24 12:32:33 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5797, average loss: 9.8416
[11/24 12:32:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.39	
[11/24 12:32:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/24 12:40:05 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4518, average train loss: 15.5384
[11/24 12:40:56 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5787, average loss: 28.7403
[11/24 12:40:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.33	
[11/24 12:40:56 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/24 12:48:27 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e+00, avg batch time: 6.4349, average train loss: 21.1376
[11/24 12:49:18 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5813, average loss: 19.2719
[11/24 12:49:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.65	
[11/24 12:49:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/24 12:56:49 visual_prompt]: Epoch 41 / 100: avg data time: 5.00e+00, avg batch time: 6.4391, average train loss: 16.0181
[11/24 12:57:41 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5796, average loss: 15.8603
[11/24 12:57:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.94	
[11/24 12:57:41 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/24 13:05:11 visual_prompt]: Epoch 42 / 100: avg data time: 5.00e+00, avg batch time: 6.4334, average train loss: 11.2651
[11/24 13:06:03 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5780, average loss: 2.4032
[11/24 13:06:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.85	
[11/24 13:06:03 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/24 13:13:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e+00, avg batch time: 6.4545, average train loss: 8.5799
[11/24 13:14:27 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5840, average loss: 14.3877
[11/24 13:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.71	
[11/24 13:14:27 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/24 13:21:59 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e+00, avg batch time: 6.4598, average train loss: 11.4445
[11/24 13:22:51 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5797, average loss: 21.7082
[11/24 13:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.43	
[11/24 13:22:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/24 13:30:23 visual_prompt]: Epoch 45 / 100: avg data time: 5.02e+00, avg batch time: 6.4502, average train loss: 24.4704
[11/24 13:31:14 visual_prompt]: Inference (val):avg data time: 4.19e-05, avg batch time: 0.5799, average loss: 5.0379
[11/24 13:31:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/24 13:31:14 visual_prompt]: Stopping early.
[11/24 13:31:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 13:31:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 13:31:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/24 13:31:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 13:31:14 visual_prompt]: Training with config:
[11/24 13:31:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr10.0_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 13:31:14 visual_prompt]: Loading training data...
[11/24 13:31:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 13:31:14 visual_prompt]: Loading validation data...
[11/24 13:31:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 13:31:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 13:31:17 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 13:31:17 visual_prompt]: tuned percent:0.532
[11/24 13:31:17 visual_prompt]: Device used for model: 0
[11/24 13:31:17 visual_prompt]: Setting up Evaluator...
[11/24 13:31:17 visual_prompt]: Setting up Trainer...
[11/24 13:31:17 visual_prompt]: 	Setting up the optimizer...
[11/24 13:31:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 13:38:50 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4681, average train loss: 1.4863
[11/24 13:39:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5807, average loss: 1.4553
[11/24 13:39:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 13:39:42 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/24 13:47:13 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4534, average train loss: 4.2951
[11/24 13:48:05 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5787, average loss: 1.8348
[11/24 13:48:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.72	
[11/24 13:48:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/24 13:55:36 visual_prompt]: Epoch 3 / 100: avg data time: 5.01e+00, avg batch time: 6.4372, average train loss: 5.0061
[11/24 13:56:27 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5816, average loss: 5.8642
[11/24 13:56:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/24 13:56:27 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/24 14:03:58 visual_prompt]: Epoch 4 / 100: avg data time: 5.00e+00, avg batch time: 6.4328, average train loss: 11.8872
[11/24 14:04:49 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5826, average loss: 6.2582
[11/24 14:04:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/24 14:04:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/24 14:12:19 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4221, average train loss: 8.2661
[11/24 14:13:11 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5806, average loss: 11.0977
[11/24 14:13:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[11/24 14:13:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/24 14:20:43 visual_prompt]: Epoch 6 / 100: avg data time: 5.02e+00, avg batch time: 6.4586, average train loss: 5.4826
[11/24 14:21:34 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5763, average loss: 14.5264
[11/24 14:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.61	
[11/24 14:21:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/24 14:29:05 visual_prompt]: Epoch 7 / 100: avg data time: 5.00e+00, avg batch time: 6.4372, average train loss: 14.0829
[11/24 14:29:57 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5780, average loss: 17.7971
[11/24 14:29:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[11/24 14:29:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/24 14:37:27 visual_prompt]: Epoch 8 / 100: avg data time: 5.00e+00, avg batch time: 6.4370, average train loss: 13.7356
[11/24 14:38:19 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5809, average loss: 27.1819
[11/24 14:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/24 14:38:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/24 14:45:50 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4376, average train loss: 15.8670
[11/24 14:46:41 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5823, average loss: 40.9099
[11/24 14:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.88	
[11/24 14:46:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/24 14:54:12 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4347, average train loss: 11.0402
[11/24 14:55:03 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5802, average loss: 5.8996
[11/24 14:55:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.87	
[11/24 14:55:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/24 15:02:33 visual_prompt]: Epoch 11 / 100: avg data time: 4.99e+00, avg batch time: 6.4228, average train loss: 14.0393
[11/24 15:03:24 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5793, average loss: 20.6367
[11/24 15:03:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.55	
[11/24 15:03:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/24 15:10:53 visual_prompt]: Epoch 12 / 100: avg data time: 4.97e+00, avg batch time: 6.4103, average train loss: 13.4744
[11/24 15:11:44 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5791, average loss: 6.5964
[11/24 15:11:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.92	
[11/24 15:11:44 visual_prompt]: Best epoch 12: best metric: -6.596
[11/24 15:11:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/24 15:19:15 visual_prompt]: Epoch 13 / 100: avg data time: 4.99e+00, avg batch time: 6.4329, average train loss: 8.6314
[11/24 15:20:06 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5827, average loss: 21.5790
[11/24 15:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.97	
[11/24 15:20:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/24 15:27:36 visual_prompt]: Epoch 14 / 100: avg data time: 5.00e+00, avg batch time: 6.4295, average train loss: 13.9254
[11/24 15:28:28 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5803, average loss: 4.2329
[11/24 15:28:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.71	
[11/24 15:28:28 visual_prompt]: Best epoch 14: best metric: -4.233
[11/24 15:28:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/24 15:35:57 visual_prompt]: Epoch 15 / 100: avg data time: 4.98e+00, avg batch time: 6.4120, average train loss: 11.5434
[11/24 15:36:48 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5793, average loss: 22.3574
[11/24 15:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.71	
[11/24 15:36:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/24 15:44:17 visual_prompt]: Epoch 16 / 100: avg data time: 4.97e+00, avg batch time: 6.4081, average train loss: 9.9482
[11/24 15:45:09 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5796, average loss: 2.2060
[11/24 15:45:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.05	
[11/24 15:45:09 visual_prompt]: Best epoch 16: best metric: -2.206
[11/24 15:45:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/24 15:52:43 visual_prompt]: Epoch 17 / 100: avg data time: 5.04e+00, avg batch time: 6.4811, average train loss: 11.8424
[11/24 15:53:34 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5771, average loss: 7.5604
[11/24 15:53:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.27	
[11/24 15:53:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/24 16:01:02 visual_prompt]: Epoch 18 / 100: avg data time: 4.97e+00, avg batch time: 6.4029, average train loss: 10.1184
[11/24 16:01:54 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.5756, average loss: 7.6597
[11/24 16:01:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.09	
[11/24 16:01:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/24 16:09:22 visual_prompt]: Epoch 19 / 100: avg data time: 4.97e+00, avg batch time: 6.4012, average train loss: 12.8917
[11/24 16:10:13 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5811, average loss: 34.6207
[11/24 16:10:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.08	
[11/24 16:10:13 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/24 16:17:43 visual_prompt]: Epoch 20 / 100: avg data time: 4.99e+00, avg batch time: 6.4196, average train loss: 12.5878
[11/24 16:18:34 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5791, average loss: 9.1452
[11/24 16:18:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.52	
[11/24 16:18:34 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/24 16:26:04 visual_prompt]: Epoch 21 / 100: avg data time: 4.99e+00, avg batch time: 6.4261, average train loss: 13.7105
[11/24 16:26:55 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5796, average loss: 3.6799
[11/24 16:26:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.74	
[11/24 16:26:55 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/24 16:34:24 visual_prompt]: Epoch 22 / 100: avg data time: 4.97e+00, avg batch time: 6.4092, average train loss: 13.6711
[11/24 16:35:15 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5816, average loss: 10.6699
[11/24 16:35:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.64	
[11/24 16:35:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/24 16:42:45 visual_prompt]: Epoch 23 / 100: avg data time: 4.99e+00, avg batch time: 6.4278, average train loss: 8.5223
[11/24 16:43:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5790, average loss: 4.3967
[11/24 16:43:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.44	
[11/24 16:43:36 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/24 16:51:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.98e+00, avg batch time: 6.4211, average train loss: 5.2597
[11/24 16:51:57 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5806, average loss: 3.5950
[11/24 16:51:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.57	
[11/24 16:51:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/24 16:59:27 visual_prompt]: Epoch 25 / 100: avg data time: 4.99e+00, avg batch time: 6.4251, average train loss: 5.8605
[11/24 17:00:18 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5830, average loss: 0.6970
[11/24 17:00:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.75	
[11/24 17:00:18 visual_prompt]: Best epoch 25: best metric: -0.697
[11/24 17:00:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/24 17:07:48 visual_prompt]: Epoch 26 / 100: avg data time: 4.99e+00, avg batch time: 6.4300, average train loss: 8.1918
[11/24 17:08:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5798, average loss: 5.4254
[11/24 17:08:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.80	
[11/24 17:08:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/24 17:16:08 visual_prompt]: Epoch 27 / 100: avg data time: 4.97e+00, avg batch time: 6.4003, average train loss: 10.7751
[11/24 17:16:59 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5796, average loss: 1.5116
[11/24 17:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.32	
[11/24 17:16:59 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/24 17:24:29 visual_prompt]: Epoch 28 / 100: avg data time: 5.00e+00, avg batch time: 6.4322, average train loss: 4.8519
[11/24 17:25:21 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5796, average loss: 1.0155
[11/24 17:25:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.01	
[11/24 17:25:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/24 17:32:50 visual_prompt]: Epoch 29 / 100: avg data time: 4.99e+00, avg batch time: 6.4219, average train loss: 9.7333
[11/24 17:33:42 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5771, average loss: 2.0517
[11/24 17:33:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.65	
[11/24 17:33:42 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/24 17:41:12 visual_prompt]: Epoch 30 / 100: avg data time: 4.99e+00, avg batch time: 6.4287, average train loss: 3.5240
[11/24 17:42:03 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5860, average loss: 8.9571
[11/24 17:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.93	
[11/24 17:42:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/24 17:49:32 visual_prompt]: Epoch 31 / 100: avg data time: 4.98e+00, avg batch time: 6.4187, average train loss: 6.7305
[11/24 17:50:24 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5799, average loss: 1.6209
[11/24 17:50:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.13	
[11/24 17:50:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/24 17:57:54 visual_prompt]: Epoch 32 / 100: avg data time: 5.00e+00, avg batch time: 6.4307, average train loss: 3.9989
[11/24 17:58:45 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5794, average loss: 5.8083
[11/24 17:58:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.15	
[11/24 17:58:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/24 18:06:17 visual_prompt]: Epoch 33 / 100: avg data time: 5.00e+00, avg batch time: 6.4430, average train loss: 6.7435
[11/24 18:07:08 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5805, average loss: 0.7349
[11/24 18:07:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.80	
[11/24 18:07:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/24 18:14:38 visual_prompt]: Epoch 34 / 100: avg data time: 5.00e+00, avg batch time: 6.4333, average train loss: 4.5611
[11/24 18:15:30 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5816, average loss: 8.3701
[11/24 18:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.71	
[11/24 18:15:30 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/24 18:23:00 visual_prompt]: Epoch 35 / 100: avg data time: 5.00e+00, avg batch time: 6.4315, average train loss: 6.1257
[11/24 18:23:52 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5811, average loss: 1.4494
[11/24 18:23:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.74	
[11/24 18:23:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/24 18:31:24 visual_prompt]: Epoch 36 / 100: avg data time: 5.03e+00, avg batch time: 6.4595, average train loss: 5.1354
[11/24 18:32:16 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5864, average loss: 1.3743
[11/24 18:32:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.72	
[11/24 18:32:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/24 18:39:46 visual_prompt]: Epoch 37 / 100: avg data time: 4.99e+00, avg batch time: 6.4287, average train loss: 4.5551
[11/24 18:40:37 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5839, average loss: 1.0983
[11/24 18:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.33	
[11/24 18:40:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/24 18:48:08 visual_prompt]: Epoch 38 / 100: avg data time: 5.01e+00, avg batch time: 6.4427, average train loss: 3.0907
[11/24 18:49:00 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5787, average loss: 1.0862
[11/24 18:49:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.41	
[11/24 18:49:00 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/24 18:56:31 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4438, average train loss: 5.6515
[11/24 18:57:22 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5805, average loss: 2.5797
[11/24 18:57:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.86	
[11/24 18:57:22 visual_prompt]: Stopping early.
[11/24 18:57:23 visual_prompt]: Rank of current process: 0. World size: 1
[11/24 18:57:23 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/24 18:57:23 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/24 18:57:23 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/24 18:57:23 visual_prompt]: Training with config:
[11/24 18:57:23 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/24 18:57:23 visual_prompt]: Loading training data...
[11/24 18:57:23 visual_prompt]: Constructing mammo-cbis dataset train...
[11/24 18:57:23 visual_prompt]: Loading validation data...
[11/24 18:57:23 visual_prompt]: Constructing mammo-cbis dataset val...
[11/24 18:57:23 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/24 18:57:25 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/24 18:57:25 visual_prompt]: tuned percent:0.532
[11/24 18:57:25 visual_prompt]: Device used for model: 0
[11/24 18:57:25 visual_prompt]: Setting up Evaluator...
[11/24 18:57:25 visual_prompt]: Setting up Trainer...
[11/24 18:57:25 visual_prompt]: 	Setting up the optimizer...
[11/24 18:57:25 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/24 19:04:58 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4603, average train loss: 1.4863
[11/24 19:05:49 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5775, average loss: 1.4553
[11/24 19:05:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/24 19:05:49 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/24 19:13:20 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4436, average train loss: 2.7848
[11/24 19:14:12 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5787, average loss: 0.9262
[11/24 19:14:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.59	
[11/24 19:14:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/24 19:21:44 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4555, average train loss: 1.2319
[11/24 19:22:36 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5792, average loss: 3.8233
[11/24 19:22:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.98	
[11/24 19:22:36 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/24 19:30:06 visual_prompt]: Epoch 4 / 100: avg data time: 5.00e+00, avg batch time: 6.4382, average train loss: 1.6728
[11/24 19:30:58 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5789, average loss: 2.7204
[11/24 19:30:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.22	
[11/24 19:30:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/24 19:38:29 visual_prompt]: Epoch 5 / 100: avg data time: 5.00e+00, avg batch time: 6.4353, average train loss: 2.3166
[11/24 19:39:20 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5765, average loss: 4.3611
[11/24 19:39:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.06	
[11/24 19:39:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/24 19:46:53 visual_prompt]: Epoch 6 / 100: avg data time: 5.03e+00, avg batch time: 6.4630, average train loss: 3.7838
[11/24 19:47:44 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5801, average loss: 10.6632
[11/24 19:47:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.33	
[11/24 19:47:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/24 19:55:14 visual_prompt]: Epoch 7 / 100: avg data time: 4.99e+00, avg batch time: 6.4297, average train loss: 4.9261
[11/24 19:56:06 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5775, average loss: 4.4988
[11/24 19:56:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.71	
[11/24 19:56:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/24 20:03:38 visual_prompt]: Epoch 8 / 100: avg data time: 5.01e+00, avg batch time: 6.4502, average train loss: 8.2477
[11/24 20:04:29 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5847, average loss: 8.5580
[11/24 20:04:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.83	
[11/24 20:04:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/24 20:12:00 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4381, average train loss: 9.1507
[11/24 20:12:52 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5782, average loss: 12.4504
[11/24 20:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.75	
[11/24 20:12:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/24 20:20:21 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e+00, avg batch time: 6.4261, average train loss: 7.3559
[11/24 20:21:13 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5794, average loss: 7.3023
[11/24 20:21:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.39	
[11/24 20:21:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/24 20:28:44 visual_prompt]: Epoch 11 / 100: avg data time: 5.01e+00, avg batch time: 6.4440, average train loss: 7.3332
[11/24 20:29:36 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5824, average loss: 6.1562
[11/24 20:29:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.15	
[11/24 20:29:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/24 20:37:07 visual_prompt]: Epoch 12 / 100: avg data time: 5.00e+00, avg batch time: 6.4352, average train loss: 10.6316
[11/24 20:37:58 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5808, average loss: 35.5423
[11/24 20:37:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.48	
[11/24 20:37:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/24 20:45:29 visual_prompt]: Epoch 13 / 100: avg data time: 5.01e+00, avg batch time: 6.4441, average train loss: 15.0183
[11/24 20:46:21 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5775, average loss: 11.8189
[11/24 20:46:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.09	
[11/24 20:46:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/24 20:53:52 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4398, average train loss: 13.3394
[11/24 20:54:43 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5772, average loss: 16.1210
[11/24 20:54:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.29	
[11/24 20:54:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/24 21:02:15 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4440, average train loss: 8.0343
[11/24 21:03:06 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5786, average loss: 19.8728
[11/24 21:03:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.65	
[11/24 21:03:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/24 21:10:38 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e+00, avg batch time: 6.4510, average train loss: 15.3063
[11/24 21:11:29 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5770, average loss: 8.9128
[11/24 21:11:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.36	
[11/24 21:11:29 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/24 21:19:01 visual_prompt]: Epoch 17 / 100: avg data time: 5.01e+00, avg batch time: 6.4435, average train loss: 11.2095
[11/24 21:19:52 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5809, average loss: 6.7191
[11/24 21:19:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.71	
[11/24 21:19:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/24 21:27:23 visual_prompt]: Epoch 18 / 100: avg data time: 5.00e+00, avg batch time: 6.4352, average train loss: 12.4548
[11/24 21:28:14 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5795, average loss: 7.6133
[11/24 21:28:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.66	
[11/24 21:28:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/24 21:35:45 visual_prompt]: Epoch 19 / 100: avg data time: 5.00e+00, avg batch time: 6.4299, average train loss: 9.2137
[11/24 21:36:36 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5785, average loss: 5.8031
[11/24 21:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.36	
[11/24 21:36:36 visual_prompt]: Best epoch 19: best metric: -5.803
[11/24 21:36:36 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/24 21:44:09 visual_prompt]: Epoch 20 / 100: avg data time: 5.03e+00, avg batch time: 6.4703, average train loss: 10.6842
[11/24 21:45:01 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5815, average loss: 20.7116
[11/24 21:45:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.68	
[11/24 21:45:01 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/24 21:52:33 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4554, average train loss: 9.4496
[11/24 21:53:24 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5815, average loss: 11.1390
[11/24 21:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/24 21:53:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/24 22:00:55 visual_prompt]: Epoch 22 / 100: avg data time: 5.00e+00, avg batch time: 6.4348, average train loss: 9.6387
[11/24 22:01:46 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5771, average loss: 16.5941
[11/24 22:01:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.69	
[11/24 22:01:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/24 22:09:18 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e+00, avg batch time: 6.4571, average train loss: 12.5725
[11/24 22:10:10 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5815, average loss: 7.6509
[11/24 22:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[11/24 22:10:10 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/24 22:17:41 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4479, average train loss: 13.1446
[11/24 22:18:33 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5801, average loss: 13.6834
[11/24 22:18:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.08	
[11/24 22:18:33 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/24 22:26:05 visual_prompt]: Epoch 25 / 100: avg data time: 5.03e+00, avg batch time: 6.4661, average train loss: 7.5349
[11/24 22:26:57 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5812, average loss: 12.0203
[11/24 22:26:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[11/24 22:26:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/24 22:34:28 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4377, average train loss: 11.5619
[11/24 22:35:19 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5791, average loss: 9.9770
[11/24 22:35:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.05	
[11/24 22:35:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/24 22:42:50 visual_prompt]: Epoch 27 / 100: avg data time: 5.00e+00, avg batch time: 6.4339, average train loss: 13.0516
[11/24 22:43:41 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5800, average loss: 4.0530
[11/24 22:43:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.58	
[11/24 22:43:41 visual_prompt]: Best epoch 27: best metric: -4.053
[11/24 22:43:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/24 22:51:12 visual_prompt]: Epoch 28 / 100: avg data time: 5.00e+00, avg batch time: 6.4362, average train loss: 8.3452
[11/24 22:52:04 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.5796, average loss: 13.7381
[11/24 22:52:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.46	
[11/24 22:52:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/24 22:59:34 visual_prompt]: Epoch 29 / 100: avg data time: 5.00e+00, avg batch time: 6.4316, average train loss: 11.3038
[11/24 23:00:26 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5804, average loss: 3.0765
[11/24 23:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.86	
[11/24 23:00:26 visual_prompt]: Best epoch 29: best metric: -3.076
[11/24 23:00:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/24 23:07:57 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e+00, avg batch time: 6.4503, average train loss: 12.1638
[11/24 23:08:49 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5760, average loss: 8.7520
[11/24 23:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.82	
[11/24 23:08:49 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/24 23:16:18 visual_prompt]: Epoch 31 / 100: avg data time: 4.98e+00, avg batch time: 6.4165, average train loss: 7.9387
[11/24 23:17:09 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5807, average loss: 31.3213
[11/24 23:17:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/24 23:17:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/24 23:24:40 visual_prompt]: Epoch 32 / 100: avg data time: 4.99e+00, avg batch time: 6.4297, average train loss: 8.3573
[11/24 23:25:31 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5782, average loss: 15.2481
[11/24 23:25:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.90	
[11/24 23:25:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/24 23:33:04 visual_prompt]: Epoch 33 / 100: avg data time: 5.03e+00, avg batch time: 6.4640, average train loss: 11.0858
[11/24 23:33:55 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5808, average loss: 7.8440
[11/24 23:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.80	
[11/24 23:33:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/24 23:41:25 visual_prompt]: Epoch 34 / 100: avg data time: 4.99e+00, avg batch time: 6.4245, average train loss: 8.0202
[11/24 23:42:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5815, average loss: 11.2091
[11/24 23:42:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.95	
[11/24 23:42:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/24 23:49:47 visual_prompt]: Epoch 35 / 100: avg data time: 4.99e+00, avg batch time: 6.4292, average train loss: 7.0952
[11/24 23:50:38 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5839, average loss: 18.0191
[11/24 23:50:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.48	
[11/24 23:50:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/24 23:58:10 visual_prompt]: Epoch 36 / 100: avg data time: 5.02e+00, avg batch time: 6.4537, average train loss: 13.6207
[11/24 23:59:02 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5810, average loss: 1.8677
[11/24 23:59:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.25	
[11/24 23:59:02 visual_prompt]: Best epoch 36: best metric: -1.868
[11/24 23:59:02 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/25 00:06:32 visual_prompt]: Epoch 37 / 100: avg data time: 4.99e+00, avg batch time: 6.4271, average train loss: 7.1356
[11/25 00:07:23 visual_prompt]: Inference (val):avg data time: 1.85e-04, avg batch time: 0.5885, average loss: 2.8733
[11/25 00:07:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.03	
[11/25 00:07:23 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/25 00:14:55 visual_prompt]: Epoch 38 / 100: avg data time: 5.01e+00, avg batch time: 6.4491, average train loss: 7.6268
[11/25 00:15:46 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5830, average loss: 3.0940
[11/25 00:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.72	
[11/25 00:15:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/25 00:23:17 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4368, average train loss: 11.2297
[11/25 00:24:09 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5807, average loss: 1.2887
[11/25 00:24:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.76	
[11/25 00:24:09 visual_prompt]: Best epoch 39: best metric: -1.289
[11/25 00:24:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/25 00:31:40 visual_prompt]: Epoch 40 / 100: avg data time: 5.00e+00, avg batch time: 6.4409, average train loss: 10.2636
[11/25 00:32:31 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5822, average loss: 11.4468
[11/25 00:32:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.05	
[11/25 00:32:31 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/25 00:40:02 visual_prompt]: Epoch 41 / 100: avg data time: 5.01e+00, avg batch time: 6.4426, average train loss: 8.0118
[11/25 00:40:54 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5780, average loss: 2.2145
[11/25 00:40:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.31	
[11/25 00:40:54 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/25 00:48:25 visual_prompt]: Epoch 42 / 100: avg data time: 5.01e+00, avg batch time: 6.4491, average train loss: 10.1627
[11/25 00:49:17 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5835, average loss: 8.4205
[11/25 00:49:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.99	
[11/25 00:49:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/25 00:56:48 visual_prompt]: Epoch 43 / 100: avg data time: 5.02e+00, avg batch time: 6.4522, average train loss: 7.2841
[11/25 00:57:40 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5785, average loss: 19.0636
[11/25 00:57:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.07	
[11/25 00:57:40 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/25 01:05:13 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e+00, avg batch time: 6.4693, average train loss: 6.0035
[11/25 01:06:05 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5810, average loss: 12.1730
[11/25 01:06:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/25 01:06:05 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/25 01:13:36 visual_prompt]: Epoch 45 / 100: avg data time: 5.01e+00, avg batch time: 6.4451, average train loss: 5.0494
[11/25 01:14:27 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5787, average loss: 2.5811
[11/25 01:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.07	
[11/25 01:14:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/25 01:21:58 visual_prompt]: Epoch 46 / 100: avg data time: 5.00e+00, avg batch time: 6.4319, average train loss: 6.4797
[11/25 01:22:49 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5789, average loss: 1.0688
[11/25 01:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.60	
[11/25 01:22:49 visual_prompt]: Best epoch 46: best metric: -1.069
[11/25 01:22:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/25 01:30:21 visual_prompt]: Epoch 47 / 100: avg data time: 5.02e+00, avg batch time: 6.4520, average train loss: 8.5035
[11/25 01:31:13 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5805, average loss: 1.4006
[11/25 01:31:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/25 01:31:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/25 01:38:44 visual_prompt]: Epoch 48 / 100: avg data time: 5.01e+00, avg batch time: 6.4455, average train loss: 5.4785
[11/25 01:39:35 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5846, average loss: 9.2214
[11/25 01:39:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.14	
[11/25 01:39:35 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/25 01:47:06 visual_prompt]: Epoch 49 / 100: avg data time: 5.00e+00, avg batch time: 6.4389, average train loss: 6.0560
[11/25 01:47:58 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5808, average loss: 22.8427
[11/25 01:47:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.96	
[11/25 01:47:58 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/25 01:55:30 visual_prompt]: Epoch 50 / 100: avg data time: 5.01e+00, avg batch time: 6.4484, average train loss: 6.4326
[11/25 01:56:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5788, average loss: 6.2267
[11/25 01:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.12	
[11/25 01:56:22 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/25 02:03:54 visual_prompt]: Epoch 51 / 100: avg data time: 5.02e+00, avg batch time: 6.4550, average train loss: 7.8440
[11/25 02:04:45 visual_prompt]: Inference (val):avg data time: 5.09e-05, avg batch time: 0.5801, average loss: 0.7176
[11/25 02:04:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 52.60	
[11/25 02:04:45 visual_prompt]: Best epoch 51: best metric: -0.718
[11/25 02:04:45 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/25 02:12:18 visual_prompt]: Epoch 52 / 100: avg data time: 5.03e+00, avg batch time: 6.4663, average train loss: 5.8174
[11/25 02:13:10 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5845, average loss: 0.7059
[11/25 02:13:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.63	
[11/25 02:13:10 visual_prompt]: Best epoch 52: best metric: -0.706
[11/25 02:13:10 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/25 02:20:43 visual_prompt]: Epoch 53 / 100: avg data time: 5.04e+00, avg batch time: 6.4722, average train loss: 5.2114
[11/25 02:21:34 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5779, average loss: 6.7011
[11/25 02:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.00	
[11/25 02:21:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/25 02:29:06 visual_prompt]: Epoch 54 / 100: avg data time: 5.01e+00, avg batch time: 6.4469, average train loss: 7.7452
[11/25 02:29:57 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5793, average loss: 25.7155
[11/25 02:29:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.73	
[11/25 02:29:57 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/25 02:37:27 visual_prompt]: Epoch 55 / 100: avg data time: 4.99e+00, avg batch time: 6.4288, average train loss: 4.6377
[11/25 02:38:19 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5818, average loss: 5.6612
[11/25 02:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.38	
[11/25 02:38:19 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/25 02:45:49 visual_prompt]: Epoch 56 / 100: avg data time: 4.99e+00, avg batch time: 6.4244, average train loss: 3.1049
[11/25 02:46:40 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5783, average loss: 1.9974
[11/25 02:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.42	
[11/25 02:46:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/25 02:54:12 visual_prompt]: Epoch 57 / 100: avg data time: 5.01e+00, avg batch time: 6.4506, average train loss: 7.2028
[11/25 02:55:04 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5836, average loss: 12.0926
[11/25 02:55:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.37	
[11/25 02:55:04 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/25 03:02:34 visual_prompt]: Epoch 58 / 100: avg data time: 4.99e+00, avg batch time: 6.4281, average train loss: 6.2803
[11/25 03:03:25 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5809, average loss: 4.2504
[11/25 03:03:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.98	
[11/25 03:03:25 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/25 03:10:57 visual_prompt]: Epoch 59 / 100: avg data time: 5.01e+00, avg batch time: 6.4473, average train loss: 5.1015
[11/25 03:11:48 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5801, average loss: 2.8702
[11/25 03:11:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.66	
[11/25 03:11:48 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/25 03:19:20 visual_prompt]: Epoch 60 / 100: avg data time: 5.01e+00, avg batch time: 6.4468, average train loss: 5.0333
[11/25 03:20:11 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.5797, average loss: 0.8204
[11/25 03:20:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.76	
[11/25 03:20:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[11/25 03:27:42 visual_prompt]: Epoch 61 / 100: avg data time: 5.01e+00, avg batch time: 6.4440, average train loss: 2.9351
[11/25 03:28:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5793, average loss: 2.7852
[11/25 03:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.39	
[11/25 03:28:34 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[11/25 03:36:04 visual_prompt]: Epoch 62 / 100: avg data time: 4.99e+00, avg batch time: 6.4293, average train loss: 4.6942
[11/25 03:36:56 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5802, average loss: 4.1326
[11/25 03:36:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.83	
[11/25 03:36:56 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[11/25 03:44:26 visual_prompt]: Epoch 63 / 100: avg data time: 4.99e+00, avg batch time: 6.4296, average train loss: 2.7773
[11/25 03:45:18 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5806, average loss: 7.2329
[11/25 03:45:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.46	
[11/25 03:45:18 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[11/25 03:52:49 visual_prompt]: Epoch 64 / 100: avg data time: 5.01e+00, avg batch time: 6.4405, average train loss: 2.9002
[11/25 03:53:40 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5781, average loss: 1.0962
[11/25 03:53:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.44	
[11/25 03:53:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[11/25 04:01:10 visual_prompt]: Epoch 65 / 100: avg data time: 4.99e+00, avg batch time: 6.4205, average train loss: 2.2727
[11/25 04:02:02 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5786, average loss: 0.6925
[11/25 04:02:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/25 04:02:02 visual_prompt]: Best epoch 65: best metric: -0.693
[11/25 04:02:02 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[11/25 04:09:31 visual_prompt]: Epoch 66 / 100: avg data time: 4.99e+00, avg batch time: 6.4252, average train loss: 1.4498
[11/25 04:10:23 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5831, average loss: 0.9905
[11/25 04:10:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.02	
[11/25 04:10:23 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[11/25 04:17:53 visual_prompt]: Epoch 67 / 100: avg data time: 4.99e+00, avg batch time: 6.4277, average train loss: 1.9112
[11/25 04:18:45 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5786, average loss: 1.9140
[11/25 04:18:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.73	
[11/25 04:18:45 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[11/25 04:26:15 visual_prompt]: Epoch 68 / 100: avg data time: 5.00e+00, avg batch time: 6.4333, average train loss: 1.7048
[11/25 04:27:07 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5842, average loss: 0.9801
[11/25 04:27:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.73	
[11/25 04:27:07 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[11/25 04:34:38 visual_prompt]: Epoch 69 / 100: avg data time: 5.01e+00, avg batch time: 6.4521, average train loss: 1.7174
[11/25 04:35:30 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5817, average loss: 1.5635
[11/25 04:35:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/25 04:35:30 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[11/25 04:43:01 visual_prompt]: Epoch 70 / 100: avg data time: 5.01e+00, avg batch time: 6.4477, average train loss: 1.1911
[11/25 04:43:53 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5803, average loss: 0.7427
[11/25 04:43:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.53	
[11/25 04:43:53 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[11/25 04:51:25 visual_prompt]: Epoch 71 / 100: avg data time: 5.01e+00, avg batch time: 6.4464, average train loss: 2.0104
[11/25 04:52:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5785, average loss: 2.5056
[11/25 04:52:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.35	
[11/25 04:52:16 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[11/25 04:59:47 visual_prompt]: Epoch 72 / 100: avg data time: 5.00e+00, avg batch time: 6.4407, average train loss: 3.0487
[11/25 05:00:39 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5788, average loss: 4.9806
[11/25 05:00:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/25 05:00:39 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[11/25 05:08:10 visual_prompt]: Epoch 73 / 100: avg data time: 5.00e+00, avg batch time: 6.4360, average train loss: 1.3755
[11/25 05:09:01 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5811, average loss: 0.8977
[11/25 05:09:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.26	
[11/25 05:09:01 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[11/25 05:16:31 visual_prompt]: Epoch 74 / 100: avg data time: 4.99e+00, avg batch time: 6.4292, average train loss: 1.2382
[11/25 05:17:22 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5790, average loss: 2.1079
[11/25 05:17:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.18	
[11/25 05:17:22 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[11/25 05:24:51 visual_prompt]: Epoch 75 / 100: avg data time: 4.97e+00, avg batch time: 6.4045, average train loss: 0.9729
[11/25 05:25:42 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5790, average loss: 2.1979
[11/25 05:25:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.84	
[11/25 05:25:42 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[11/25 05:33:12 visual_prompt]: Epoch 76 / 100: avg data time: 4.98e+00, avg batch time: 6.4205, average train loss: 0.9251
[11/25 05:34:03 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5786, average loss: 0.7825
[11/25 05:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.85	
[11/25 05:34:03 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[11/25 05:41:32 visual_prompt]: Epoch 77 / 100: avg data time: 4.98e+00, avg batch time: 6.4128, average train loss: 1.0279
[11/25 05:42:24 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5846, average loss: 0.7550
[11/25 05:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.77	
[11/25 05:42:24 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[11/25 05:49:52 visual_prompt]: Epoch 78 / 100: avg data time: 4.97e+00, avg batch time: 6.4110, average train loss: 0.7910
[11/25 05:50:44 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5791, average loss: 1.0162
[11/25 05:50:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.34	
[11/25 05:50:44 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[11/25 05:58:14 visual_prompt]: Epoch 79 / 100: avg data time: 5.00e+00, avg batch time: 6.4323, average train loss: 0.7969
[11/25 05:59:06 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5834, average loss: 0.7253
[11/25 05:59:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.19	
[11/25 05:59:06 visual_prompt]: Stopping early.
[11/25 05:59:06 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 05:59:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 05:59:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/25 05:59:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 05:59:06 visual_prompt]: Training with config:
[11/25 05:59:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 05:59:06 visual_prompt]: Loading training data...
[11/25 05:59:06 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 05:59:06 visual_prompt]: Loading validation data...
[11/25 05:59:06 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 05:59:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 05:59:08 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 05:59:08 visual_prompt]: tuned percent:0.532
[11/25 05:59:09 visual_prompt]: Device used for model: 0
[11/25 05:59:09 visual_prompt]: Setting up Evaluator...
[11/25 05:59:09 visual_prompt]: Setting up Trainer...
[11/25 05:59:09 visual_prompt]: 	Setting up the optimizer...
[11/25 05:59:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 06:06:40 visual_prompt]: Epoch 1 / 100: avg data time: 5.00e+00, avg batch time: 6.4412, average train loss: 1.4863
[11/25 06:07:31 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5824, average loss: 1.4553
[11/25 06:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 06:07:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/25 06:15:01 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4255, average train loss: 2.8978
[11/25 06:15:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5815, average loss: 1.1899
[11/25 06:15:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/25 06:15:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/25 06:23:22 visual_prompt]: Epoch 3 / 100: avg data time: 4.98e+00, avg batch time: 6.4199, average train loss: 0.9268
[11/25 06:24:13 visual_prompt]: Inference (val):avg data time: 4.26e-05, avg batch time: 0.5808, average loss: 2.7142
[11/25 06:24:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.76	
[11/25 06:24:13 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/25 06:31:43 visual_prompt]: Epoch 4 / 100: avg data time: 4.98e+00, avg batch time: 6.4159, average train loss: 1.0662
[11/25 06:32:34 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5834, average loss: 1.0212
[11/25 06:32:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.06	
[11/25 06:32:34 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/25 06:40:02 visual_prompt]: Epoch 5 / 100: avg data time: 4.97e+00, avg batch time: 6.4011, average train loss: 2.5803
[11/25 06:40:53 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5762, average loss: 1.5971
[11/25 06:40:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/25 06:40:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/25 06:48:23 visual_prompt]: Epoch 6 / 100: avg data time: 5.00e+00, avg batch time: 6.4284, average train loss: 4.0769
[11/25 06:49:15 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5806, average loss: 2.8670
[11/25 06:49:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.65	
[11/25 06:49:15 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/25 06:56:43 visual_prompt]: Epoch 7 / 100: avg data time: 4.97e+00, avg batch time: 6.3973, average train loss: 5.1670
[11/25 06:57:34 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5779, average loss: 2.9397
[11/25 06:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.88	
[11/25 06:57:34 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/25 07:05:03 visual_prompt]: Epoch 8 / 100: avg data time: 4.98e+00, avg batch time: 6.4149, average train loss: 4.9820
[11/25 07:05:54 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5786, average loss: 1.7092
[11/25 07:05:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.12	
[11/25 07:05:54 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/25 07:13:23 visual_prompt]: Epoch 9 / 100: avg data time: 4.98e+00, avg batch time: 6.4130, average train loss: 8.7479
[11/25 07:14:15 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5783, average loss: 14.9935
[11/25 07:14:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.28	
[11/25 07:14:15 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/25 07:21:43 visual_prompt]: Epoch 10 / 100: avg data time: 4.97e+00, avg batch time: 6.4056, average train loss: 7.4337
[11/25 07:22:34 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5806, average loss: 2.8783
[11/25 07:22:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 36.28	
[11/25 07:22:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/25 07:30:04 visual_prompt]: Epoch 11 / 100: avg data time: 4.98e+00, avg batch time: 6.4177, average train loss: 10.4079
[11/25 07:30:55 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5824, average loss: 14.2705
[11/25 07:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.36	
[11/25 07:30:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/25 07:38:24 visual_prompt]: Epoch 12 / 100: avg data time: 4.97e+00, avg batch time: 6.4077, average train loss: 8.1934
[11/25 07:39:15 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5824, average loss: 1.4378
[11/25 07:39:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.42	
[11/25 07:39:15 visual_prompt]: Best epoch 12: best metric: -1.438
[11/25 07:39:15 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/25 07:46:44 visual_prompt]: Epoch 13 / 100: avg data time: 4.97e+00, avg batch time: 6.4148, average train loss: 6.6119
[11/25 07:47:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5773, average loss: 5.7244
[11/25 07:47:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.10	
[11/25 07:47:36 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/25 07:55:04 visual_prompt]: Epoch 14 / 100: avg data time: 4.96e+00, avg batch time: 6.3999, average train loss: 7.0518
[11/25 07:55:55 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5783, average loss: 1.4982
[11/25 07:55:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.48	
[11/25 07:55:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/25 08:03:23 visual_prompt]: Epoch 15 / 100: avg data time: 4.95e+00, avg batch time: 6.3861, average train loss: 8.7011
[11/25 08:04:14 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5787, average loss: 19.3746
[11/25 08:04:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[11/25 08:04:14 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/25 08:11:43 visual_prompt]: Epoch 16 / 100: avg data time: 4.98e+00, avg batch time: 6.4145, average train loss: 11.8345
[11/25 08:12:34 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5798, average loss: 12.6651
[11/25 08:12:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.78	
[11/25 08:12:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/25 08:20:04 visual_prompt]: Epoch 17 / 100: avg data time: 4.99e+00, avg batch time: 6.4243, average train loss: 10.2071
[11/25 08:20:55 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5789, average loss: 19.4111
[11/25 08:20:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/25 08:20:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/25 08:28:25 visual_prompt]: Epoch 18 / 100: avg data time: 4.98e+00, avg batch time: 6.4187, average train loss: 11.8288
[11/25 08:29:16 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5810, average loss: 8.3764
[11/25 08:29:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.77	
[11/25 08:29:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/25 08:36:55 visual_prompt]: Epoch 19 / 100: avg data time: 5.11e+00, avg batch time: 6.5445, average train loss: 9.3241
[11/25 08:37:46 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5787, average loss: 10.6516
[11/25 08:37:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.59	
[11/25 08:37:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/25 08:45:16 visual_prompt]: Epoch 20 / 100: avg data time: 4.99e+00, avg batch time: 6.4261, average train loss: 10.6186
[11/25 08:46:07 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5800, average loss: 43.1789
[11/25 08:46:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.98	
[11/25 08:46:07 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/25 08:53:38 visual_prompt]: Epoch 21 / 100: avg data time: 5.00e+00, avg batch time: 6.4328, average train loss: 11.0316
[11/25 08:54:29 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5840, average loss: 5.5902
[11/25 08:54:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.13	
[11/25 08:54:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/25 09:02:00 visual_prompt]: Epoch 22 / 100: avg data time: 5.00e+00, avg batch time: 6.4365, average train loss: 7.3485
[11/25 09:02:51 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5798, average loss: 5.8560
[11/25 09:02:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.23	
[11/25 09:02:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/25 09:10:25 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e+00, avg batch time: 6.4775, average train loss: 4.9776
[11/25 09:11:16 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5819, average loss: 8.4203
[11/25 09:11:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/25 09:11:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/25 09:18:47 visual_prompt]: Epoch 24 / 100: avg data time: 5.00e+00, avg batch time: 6.4353, average train loss: 6.1281
[11/25 09:19:39 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5828, average loss: 9.4248
[11/25 09:19:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 51.89	
[11/25 09:19:39 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/25 09:27:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4585, average train loss: 7.9870
[11/25 09:28:02 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5777, average loss: 6.5772
[11/25 09:28:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/25 09:28:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/25 09:35:35 visual_prompt]: Epoch 26 / 100: avg data time: 5.02e+00, avg batch time: 6.4596, average train loss: 6.0641
[11/25 09:36:26 visual_prompt]: Inference (val):avg data time: 2.57e-04, avg batch time: 0.6044, average loss: 10.5304
[11/25 09:36:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.37	
[11/25 09:36:26 visual_prompt]: Stopping early.
[11/25 09:36:27 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 09:36:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 09:36:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/25 09:36:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 09:36:27 visual_prompt]: Training with config:
[11/25 09:36:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 09:36:27 visual_prompt]: Loading training data...
[11/25 09:36:27 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 09:36:27 visual_prompt]: Loading validation data...
[11/25 09:36:27 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 09:36:27 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 09:36:29 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 09:36:29 visual_prompt]: tuned percent:0.532
[11/25 09:36:29 visual_prompt]: Device used for model: 0
[11/25 09:36:29 visual_prompt]: Setting up Evaluator...
[11/25 09:36:29 visual_prompt]: Setting up Trainer...
[11/25 09:36:29 visual_prompt]: 	Setting up the optimizer...
[11/25 09:36:30 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 09:44:02 visual_prompt]: Epoch 1 / 100: avg data time: 5.01e+00, avg batch time: 6.4558, average train loss: 1.4863
[11/25 09:44:53 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5837, average loss: 1.4553
[11/25 09:44:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 09:44:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/25 09:52:26 visual_prompt]: Epoch 2 / 100: avg data time: 5.02e+00, avg batch time: 6.4615, average train loss: 3.1415
[11/25 09:53:17 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5786, average loss: 1.3160
[11/25 09:53:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/25 09:53:17 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/25 10:00:49 visual_prompt]: Epoch 3 / 100: avg data time: 5.01e+00, avg batch time: 6.4452, average train loss: 0.8800
[11/25 10:01:40 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5834, average loss: 3.0546
[11/25 10:01:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.60	
[11/25 10:01:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/25 10:09:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.01e+00, avg batch time: 6.4443, average train loss: 2.1609
[11/25 10:10:03 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5777, average loss: 6.2397
[11/25 10:10:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 42.68	rocauc: 45.98	
[11/25 10:10:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/25 10:17:34 visual_prompt]: Epoch 5 / 100: avg data time: 5.00e+00, avg batch time: 6.4392, average train loss: 6.3105
[11/25 10:18:25 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5831, average loss: 2.2250
[11/25 10:18:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.37	
[11/25 10:18:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/25 10:25:58 visual_prompt]: Epoch 6 / 100: avg data time: 5.03e+00, avg batch time: 6.4631, average train loss: 5.2307
[11/25 10:26:49 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5836, average loss: 5.6028
[11/25 10:26:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.85	
[11/25 10:26:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/25 10:34:19 visual_prompt]: Epoch 7 / 100: avg data time: 4.99e+00, avg batch time: 6.4288, average train loss: 2.6285
[11/25 10:35:11 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5801, average loss: 1.8194
[11/25 10:35:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.04	
[11/25 10:35:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/25 10:42:42 visual_prompt]: Epoch 8 / 100: avg data time: 5.00e+00, avg batch time: 6.4395, average train loss: 2.9380
[11/25 10:43:34 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5785, average loss: 1.8029
[11/25 10:43:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.73	
[11/25 10:43:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/25 10:51:05 visual_prompt]: Epoch 9 / 100: avg data time: 5.01e+00, avg batch time: 6.4539, average train loss: 1.6077
[11/25 10:51:57 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5831, average loss: 10.4896
[11/25 10:51:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.60	
[11/25 10:51:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/25 10:59:28 visual_prompt]: Epoch 10 / 100: avg data time: 5.00e+00, avg batch time: 6.4371, average train loss: 6.3316
[11/25 11:00:19 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5836, average loss: 1.6291
[11/25 11:00:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.74	
[11/25 11:00:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/25 11:07:51 visual_prompt]: Epoch 11 / 100: avg data time: 5.01e+00, avg batch time: 6.4476, average train loss: 2.7613
[11/25 11:08:42 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5815, average loss: 0.8698
[11/25 11:08:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.13	
[11/25 11:08:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/25 11:16:14 visual_prompt]: Epoch 12 / 100: avg data time: 5.01e+00, avg batch time: 6.4432, average train loss: 2.3419
[11/25 11:17:05 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5796, average loss: 1.0342
[11/25 11:17:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.02	
[11/25 11:17:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/25 11:24:35 visual_prompt]: Epoch 13 / 100: avg data time: 5.00e+00, avg batch time: 6.4327, average train loss: 1.7913
[11/25 11:25:27 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5791, average loss: 0.8108
[11/25 11:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.19	
[11/25 11:25:27 visual_prompt]: Best epoch 13: best metric: -0.811
[11/25 11:25:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/25 11:32:57 visual_prompt]: Epoch 14 / 100: avg data time: 4.99e+00, avg batch time: 6.4325, average train loss: 3.0682
[11/25 11:33:49 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5820, average loss: 13.1656
[11/25 11:33:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.51	
[11/25 11:33:49 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/25 11:41:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.98e+00, avg batch time: 6.4099, average train loss: 9.6092
[11/25 11:42:09 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5781, average loss: 6.3453
[11/25 11:42:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.41	
[11/25 11:42:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/25 11:49:39 visual_prompt]: Epoch 16 / 100: avg data time: 4.99e+00, avg batch time: 6.4250, average train loss: 3.2655
[11/25 11:50:31 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5789, average loss: 2.4876
[11/25 11:50:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.36	
[11/25 11:50:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/25 11:58:00 visual_prompt]: Epoch 17 / 100: avg data time: 4.99e+00, avg batch time: 6.4245, average train loss: 4.4160
[11/25 11:58:52 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5780, average loss: 6.9346
[11/25 11:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/25 11:58:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/25 12:06:22 visual_prompt]: Epoch 18 / 100: avg data time: 4.99e+00, avg batch time: 6.4282, average train loss: 10.7765
[11/25 12:07:14 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5826, average loss: 11.4695
[11/25 12:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.02	
[11/25 12:07:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/25 12:14:43 visual_prompt]: Epoch 19 / 100: avg data time: 4.99e+00, avg batch time: 6.4216, average train loss: 6.7249
[11/25 12:15:35 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5799, average loss: 16.3497
[11/25 12:15:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/25 12:15:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/25 12:23:07 visual_prompt]: Epoch 20 / 100: avg data time: 5.02e+00, avg batch time: 6.4507, average train loss: 6.2630
[11/25 12:23:58 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5790, average loss: 1.1243
[11/25 12:23:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.98	
[11/25 12:23:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/25 12:31:30 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4512, average train loss: 2.0511
[11/25 12:32:21 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5860, average loss: 1.7977
[11/25 12:32:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.32	
[11/25 12:32:21 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/25 12:39:53 visual_prompt]: Epoch 22 / 100: avg data time: 5.01e+00, avg batch time: 6.4461, average train loss: 6.9889
[11/25 12:40:44 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5821, average loss: 1.5059
[11/25 12:40:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.36	
[11/25 12:40:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/25 12:48:24 visual_prompt]: Epoch 23 / 100: avg data time: 5.13e+00, avg batch time: 6.5714, average train loss: 9.8862
[11/25 12:49:16 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5820, average loss: 28.9307
[11/25 12:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.67	
[11/25 12:49:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/25 12:56:46 visual_prompt]: Epoch 24 / 100: avg data time: 5.00e+00, avg batch time: 6.4316, average train loss: 12.5138
[11/25 12:57:38 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5858, average loss: 5.0367
[11/25 12:57:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.15	
[11/25 12:57:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/25 13:05:12 visual_prompt]: Epoch 25 / 100: avg data time: 5.04e+00, avg batch time: 6.4795, average train loss: 5.8144
[11/25 13:06:03 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5799, average loss: 6.2093
[11/25 13:06:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.54	
[11/25 13:06:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/25 13:13:34 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4385, average train loss: 3.7135
[11/25 13:14:26 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5796, average loss: 1.9935
[11/25 13:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.35	
[11/25 13:14:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/25 13:21:57 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4442, average train loss: 2.4783
[11/25 13:22:48 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5821, average loss: 2.7283
[11/25 13:22:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.93	
[11/25 13:22:48 visual_prompt]: Stopping early.
[11/25 13:22:49 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 13:22:49 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 13:22:49 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/25 13:22:49 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 13:22:49 visual_prompt]: Training with config:
[11/25 13:22:49 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr5.0_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 13:22:49 visual_prompt]: Loading training data...
[11/25 13:22:49 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 13:22:49 visual_prompt]: Loading validation data...
[11/25 13:22:49 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 13:22:49 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 13:22:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 13:22:51 visual_prompt]: tuned percent:0.532
[11/25 13:22:51 visual_prompt]: Device used for model: 0
[11/25 13:22:51 visual_prompt]: Setting up Evaluator...
[11/25 13:22:51 visual_prompt]: Setting up Trainer...
[11/25 13:22:51 visual_prompt]: 	Setting up the optimizer...
[11/25 13:22:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 13:30:26 visual_prompt]: Epoch 1 / 100: avg data time: 5.06e+00, avg batch time: 6.4954, average train loss: 1.4863
[11/25 13:31:18 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5810, average loss: 1.4553
[11/25 13:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 13:31:18 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/25 13:38:48 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4309, average train loss: 2.6144
[11/25 13:39:40 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5829, average loss: 1.6850
[11/25 13:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/25 13:39:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/25 13:47:13 visual_prompt]: Epoch 3 / 100: avg data time: 5.04e+00, avg batch time: 6.4773, average train loss: 1.1001
[11/25 13:48:05 visual_prompt]: Inference (val):avg data time: 2.56e-04, avg batch time: 0.6030, average loss: 3.0125
[11/25 13:48:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.64	
[11/25 13:48:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/25 13:55:35 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e+00, avg batch time: 6.4244, average train loss: 1.9004
[11/25 13:56:27 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5786, average loss: 0.7538
[11/25 13:56:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.54	
[11/25 13:56:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/25 14:03:57 visual_prompt]: Epoch 5 / 100: avg data time: 4.99e+00, avg batch time: 6.4274, average train loss: 3.6940
[11/25 14:04:48 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5791, average loss: 1.7423
[11/25 14:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.03	
[11/25 14:04:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/25 14:12:22 visual_prompt]: Epoch 6 / 100: avg data time: 5.04e+00, avg batch time: 6.4824, average train loss: 4.4831
[11/25 14:13:14 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5805, average loss: 0.8799
[11/25 14:13:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.39	
[11/25 14:13:14 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/25 14:20:45 visual_prompt]: Epoch 7 / 100: avg data time: 4.99e+00, avg batch time: 6.4367, average train loss: 3.9795
[11/25 14:21:36 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5801, average loss: 0.8672
[11/25 14:21:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/25 14:21:36 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/25 14:29:07 visual_prompt]: Epoch 8 / 100: avg data time: 5.00e+00, avg batch time: 6.4364, average train loss: 1.3259
[11/25 14:29:58 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5824, average loss: 3.8142
[11/25 14:29:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.20	
[11/25 14:29:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/25 14:37:29 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4363, average train loss: 3.2749
[11/25 14:38:20 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5817, average loss: 0.7072
[11/25 14:38:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.42	
[11/25 14:38:20 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/25 14:45:51 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e+00, avg batch time: 6.4275, average train loss: 5.9248
[11/25 14:46:42 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5793, average loss: 10.7246
[11/25 14:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.68	
[11/25 14:46:42 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/25 14:54:17 visual_prompt]: Epoch 11 / 100: avg data time: 5.06e+00, avg batch time: 6.4903, average train loss: 11.3017
[11/25 14:55:08 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5803, average loss: 7.9929
[11/25 14:55:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.29	
[11/25 14:55:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/25 15:02:40 visual_prompt]: Epoch 12 / 100: avg data time: 5.01e+00, avg batch time: 6.4513, average train loss: 8.8127
[11/25 15:03:31 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5794, average loss: 16.7781
[11/25 15:03:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.64	
[11/25 15:03:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/25 15:11:02 visual_prompt]: Epoch 13 / 100: avg data time: 4.99e+00, avg batch time: 6.4329, average train loss: 5.9571
[11/25 15:11:53 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5812, average loss: 5.6421
[11/25 15:11:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[11/25 15:11:53 visual_prompt]: Best epoch 13: best metric: -5.642
[11/25 15:11:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/25 15:19:23 visual_prompt]: Epoch 14 / 100: avg data time: 4.99e+00, avg batch time: 6.4234, average train loss: 2.4866
[11/25 15:20:14 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5783, average loss: 3.7670
[11/25 15:20:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/25 15:20:14 visual_prompt]: Best epoch 14: best metric: -3.767
[11/25 15:20:14 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/25 15:27:45 visual_prompt]: Epoch 15 / 100: avg data time: 4.99e+00, avg batch time: 6.4287, average train loss: 3.6729
[11/25 15:28:36 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5860, average loss: 3.9165
[11/25 15:28:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/25 15:28:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/25 15:36:06 visual_prompt]: Epoch 16 / 100: avg data time: 4.98e+00, avg batch time: 6.4180, average train loss: 2.0203
[11/25 15:36:57 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5831, average loss: 1.5735
[11/25 15:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.89	
[11/25 15:36:57 visual_prompt]: Best epoch 16: best metric: -1.574
[11/25 15:36:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/25 15:44:28 visual_prompt]: Epoch 17 / 100: avg data time: 5.00e+00, avg batch time: 6.4423, average train loss: 3.5485
[11/25 15:45:20 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5800, average loss: 4.3087
[11/25 15:45:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.93	
[11/25 15:45:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/25 15:52:51 visual_prompt]: Epoch 18 / 100: avg data time: 5.00e+00, avg batch time: 6.4467, average train loss: 1.9943
[11/25 15:53:42 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5784, average loss: 9.7803
[11/25 15:53:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.02	
[11/25 15:53:42 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/25 16:01:12 visual_prompt]: Epoch 19 / 100: avg data time: 4.99e+00, avg batch time: 6.4267, average train loss: 3.1845
[11/25 16:02:04 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5813, average loss: 3.5012
[11/25 16:02:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.63	
[11/25 16:02:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/25 16:09:36 visual_prompt]: Epoch 20 / 100: avg data time: 5.01e+00, avg batch time: 6.4517, average train loss: 3.6631
[11/25 16:10:27 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5864, average loss: 8.6215
[11/25 16:10:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.25	
[11/25 16:10:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/25 16:18:00 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4583, average train loss: 2.3673
[11/25 16:18:51 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5809, average loss: 3.9653
[11/25 16:18:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/25 16:18:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/25 16:26:22 visual_prompt]: Epoch 22 / 100: avg data time: 5.01e+00, avg batch time: 6.4425, average train loss: 6.5071
[11/25 16:27:14 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5784, average loss: 9.1794
[11/25 16:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.55	
[11/25 16:27:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/25 16:34:46 visual_prompt]: Epoch 23 / 100: avg data time: 5.01e+00, avg batch time: 6.4538, average train loss: 3.0043
[11/25 16:35:37 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5822, average loss: 5.2822
[11/25 16:35:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.23	
[11/25 16:35:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/25 16:43:09 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4556, average train loss: 2.2262
[11/25 16:44:00 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5767, average loss: 0.9039
[11/25 16:44:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.32	
[11/25 16:44:00 visual_prompt]: Best epoch 24: best metric: -0.904
[11/25 16:44:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/25 16:51:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.02e+00, avg batch time: 6.4584, average train loss: 1.2421
[11/25 16:52:24 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5835, average loss: 2.8685
[11/25 16:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/25 16:52:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/25 17:00:02 visual_prompt]: Epoch 26 / 100: avg data time: 5.09e+00, avg batch time: 6.5304, average train loss: 4.3956
[11/25 17:00:53 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5806, average loss: 6.3707
[11/25 17:00:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.38	
[11/25 17:00:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/25 17:08:25 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4545, average train loss: 2.5497
[11/25 17:09:17 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5800, average loss: 2.3572
[11/25 17:09:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.18	
[11/25 17:09:17 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/25 17:16:49 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4566, average train loss: 1.1325
[11/25 17:17:40 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5805, average loss: 3.2577
[11/25 17:17:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.46	
[11/25 17:17:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/25 17:25:11 visual_prompt]: Epoch 29 / 100: avg data time: 5.00e+00, avg batch time: 6.4344, average train loss: 1.8593
[11/25 17:26:02 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.5811, average loss: 0.8613
[11/25 17:26:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.33	
[11/25 17:26:02 visual_prompt]: Best epoch 29: best metric: -0.861
[11/25 17:26:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/25 17:33:34 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e+00, avg batch time: 6.4488, average train loss: 1.0190
[11/25 17:34:26 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5815, average loss: 2.1965
[11/25 17:34:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.53	
[11/25 17:34:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/25 17:41:57 visual_prompt]: Epoch 31 / 100: avg data time: 5.01e+00, avg batch time: 6.4463, average train loss: 2.8724
[11/25 17:42:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5790, average loss: 2.0827
[11/25 17:42:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.06	
[11/25 17:42:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/25 17:50:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4520, average train loss: 2.2419
[11/25 17:51:12 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5783, average loss: 6.7590
[11/25 17:51:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.26	
[11/25 17:51:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/25 17:58:43 visual_prompt]: Epoch 33 / 100: avg data time: 5.01e+00, avg batch time: 6.4437, average train loss: 2.2798
[11/25 17:59:34 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5815, average loss: 0.8635
[11/25 17:59:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.96	
[11/25 17:59:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/25 18:07:05 visual_prompt]: Epoch 34 / 100: avg data time: 5.00e+00, avg batch time: 6.4372, average train loss: 1.6345
[11/25 18:07:57 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5788, average loss: 5.9542
[11/25 18:07:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.08	
[11/25 18:07:57 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/25 18:15:27 visual_prompt]: Epoch 35 / 100: avg data time: 5.00e+00, avg batch time: 6.4358, average train loss: 1.6118
[11/25 18:16:19 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5813, average loss: 0.7026
[11/25 18:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.72	
[11/25 18:16:19 visual_prompt]: Best epoch 35: best metric: -0.703
[11/25 18:16:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/25 18:23:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.04e+00, avg batch time: 6.4803, average train loss: 1.4294
[11/25 18:24:44 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5778, average loss: 2.4456
[11/25 18:24:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.76	
[11/25 18:24:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/25 18:32:15 visual_prompt]: Epoch 37 / 100: avg data time: 5.00e+00, avg batch time: 6.4422, average train loss: 1.2235
[11/25 18:33:07 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5784, average loss: 0.6777
[11/25 18:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.67	
[11/25 18:33:07 visual_prompt]: Best epoch 37: best metric: -0.678
[11/25 18:33:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/25 18:40:37 visual_prompt]: Epoch 38 / 100: avg data time: 5.00e+00, avg batch time: 6.4365, average train loss: 1.2389
[11/25 18:41:29 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5799, average loss: 1.4924
[11/25 18:41:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.98	
[11/25 18:41:29 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/25 18:49:01 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4505, average train loss: 0.9588
[11/25 18:49:52 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5828, average loss: 0.6362
[11/25 18:49:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.88	
[11/25 18:49:52 visual_prompt]: Best epoch 39: best metric: -0.636
[11/25 18:49:52 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/25 18:57:23 visual_prompt]: Epoch 40 / 100: avg data time: 4.99e+00, avg batch time: 6.4339, average train loss: 0.8859
[11/25 18:58:14 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5809, average loss: 1.1745
[11/25 18:58:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.89	
[11/25 18:58:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/25 19:05:45 visual_prompt]: Epoch 41 / 100: avg data time: 5.00e+00, avg batch time: 6.4340, average train loss: 1.2287
[11/25 19:06:36 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5817, average loss: 0.6970
[11/25 19:06:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.98	
[11/25 19:06:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/25 19:14:07 visual_prompt]: Epoch 42 / 100: avg data time: 5.00e+00, avg batch time: 6.4382, average train loss: 1.0386
[11/25 19:14:59 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5800, average loss: 1.3201
[11/25 19:14:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.47	
[11/25 19:14:59 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/25 19:22:30 visual_prompt]: Epoch 43 / 100: avg data time: 5.01e+00, avg batch time: 6.4465, average train loss: 0.9658
[11/25 19:23:22 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5792, average loss: 2.7622
[11/25 19:23:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.70	
[11/25 19:23:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/25 19:30:55 visual_prompt]: Epoch 44 / 100: avg data time: 5.03e+00, avg batch time: 6.4676, average train loss: 1.4320
[11/25 19:31:46 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5804, average loss: 0.7566
[11/25 19:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 72.10	
[11/25 19:31:46 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/25 19:39:18 visual_prompt]: Epoch 45 / 100: avg data time: 5.00e+00, avg batch time: 6.4501, average train loss: 1.3490
[11/25 19:40:09 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5805, average loss: 1.6259
[11/25 19:40:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 70.33	
[11/25 19:40:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/25 19:47:40 visual_prompt]: Epoch 46 / 100: avg data time: 5.00e+00, avg batch time: 6.4340, average train loss: 1.0446
[11/25 19:48:31 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5776, average loss: 0.6560
[11/25 19:48:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.81	
[11/25 19:48:31 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/25 19:56:02 visual_prompt]: Epoch 47 / 100: avg data time: 5.00e+00, avg batch time: 6.4358, average train loss: 0.8554
[11/25 19:56:54 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5884, average loss: 1.0124
[11/25 19:56:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.78	
[11/25 19:56:54 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/25 20:04:23 visual_prompt]: Epoch 48 / 100: avg data time: 4.98e+00, avg batch time: 6.4199, average train loss: 0.8019
[11/25 20:05:15 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5818, average loss: 2.2158
[11/25 20:05:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.12	
[11/25 20:05:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/25 20:12:46 visual_prompt]: Epoch 49 / 100: avg data time: 5.00e+00, avg batch time: 6.4447, average train loss: 1.0876
[11/25 20:13:38 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5863, average loss: 3.0571
[11/25 20:13:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.02	
[11/25 20:13:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/25 20:21:09 visual_prompt]: Epoch 50 / 100: avg data time: 5.00e+00, avg batch time: 6.4468, average train loss: 1.2478
[11/25 20:22:01 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5825, average loss: 0.7618
[11/25 20:22:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.31	
[11/25 20:22:01 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/25 20:29:31 visual_prompt]: Epoch 51 / 100: avg data time: 5.00e+00, avg batch time: 6.4382, average train loss: 0.8562
[11/25 20:30:23 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5799, average loss: 0.8258
[11/25 20:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.06	
[11/25 20:30:23 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/25 20:37:55 visual_prompt]: Epoch 52 / 100: avg data time: 5.01e+00, avg batch time: 6.4496, average train loss: 0.8619
[11/25 20:38:46 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5809, average loss: 0.7581
[11/25 20:38:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.09	
[11/25 20:38:46 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/25 20:46:20 visual_prompt]: Epoch 53 / 100: avg data time: 5.05e+00, avg batch time: 6.4899, average train loss: 1.0585
[11/25 20:47:12 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5831, average loss: 0.6482
[11/25 20:47:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.67	
[11/25 20:47:12 visual_prompt]: Stopping early.
[11/25 20:47:12 visual_prompt]: Rank of current process: 0. World size: 1
[11/25 20:47:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/25 20:47:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/25 20:47:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/25 20:47:12 visual_prompt]: Training with config:
[11/25 20:47:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/25 20:47:12 visual_prompt]: Loading training data...
[11/25 20:47:12 visual_prompt]: Constructing mammo-cbis dataset train...
[11/25 20:47:12 visual_prompt]: Loading validation data...
[11/25 20:47:12 visual_prompt]: Constructing mammo-cbis dataset val...
[11/25 20:47:12 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/25 20:47:15 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/25 20:47:15 visual_prompt]: tuned percent:0.532
[11/25 20:47:15 visual_prompt]: Device used for model: 0
[11/25 20:47:15 visual_prompt]: Setting up Evaluator...
[11/25 20:47:15 visual_prompt]: Setting up Trainer...
[11/25 20:47:15 visual_prompt]: 	Setting up the optimizer...
[11/25 20:47:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/25 20:54:47 visual_prompt]: Epoch 1 / 100: avg data time: 5.02e+00, avg batch time: 6.4580, average train loss: 1.4863
[11/25 20:55:39 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5804, average loss: 1.4553
[11/25 20:55:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/25 20:55:39 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/25 21:03:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.01e+00, avg batch time: 6.4408, average train loss: 1.5538
[11/25 21:04:01 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5783, average loss: 0.9104
[11/25 21:04:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[11/25 21:04:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/25 21:11:33 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4530, average train loss: 0.7967
[11/25 21:12:25 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5781, average loss: 1.1474
[11/25 21:12:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.12	
[11/25 21:12:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/25 21:19:55 visual_prompt]: Epoch 4 / 100: avg data time: 4.99e+00, avg batch time: 6.4222, average train loss: 1.1288
[11/25 21:20:46 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5802, average loss: 0.7620
[11/25 21:20:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.86	
[11/25 21:20:46 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/25 21:28:17 visual_prompt]: Epoch 5 / 100: avg data time: 5.00e+00, avg batch time: 6.4388, average train loss: 1.4050
[11/25 21:29:09 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5790, average loss: 1.5900
[11/25 21:29:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.49	
[11/25 21:29:09 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/25 21:36:40 visual_prompt]: Epoch 6 / 100: avg data time: 5.01e+00, avg batch time: 6.4495, average train loss: 1.9946
[11/25 21:37:32 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5837, average loss: 0.7178
[11/25 21:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.44	
[11/25 21:37:32 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/25 21:45:02 visual_prompt]: Epoch 7 / 100: avg data time: 5.00e+00, avg batch time: 6.4290, average train loss: 3.5436
[11/25 21:45:54 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5838, average loss: 0.7324
[11/25 21:45:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 48.82	
[11/25 21:45:54 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/25 21:53:26 visual_prompt]: Epoch 8 / 100: avg data time: 5.02e+00, avg batch time: 6.4526, average train loss: 2.5787
[11/25 21:54:17 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5787, average loss: 5.1541
[11/25 21:54:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.62	
[11/25 21:54:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/25 22:01:48 visual_prompt]: Epoch 9 / 100: avg data time: 5.00e+00, avg batch time: 6.4327, average train loss: 2.9303
[11/25 22:02:39 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5839, average loss: 0.7207
[11/25 22:02:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.26	
[11/25 22:02:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/25 22:10:09 visual_prompt]: Epoch 10 / 100: avg data time: 4.99e+00, avg batch time: 6.4276, average train loss: 4.3887
[11/25 22:11:01 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5793, average loss: 2.5096
[11/25 22:11:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.03	
[11/25 22:11:01 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/25 22:18:33 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e+00, avg batch time: 6.4556, average train loss: 4.1012
[11/25 22:19:25 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5838, average loss: 2.6728
[11/25 22:19:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.02	
[11/25 22:19:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/25 22:26:55 visual_prompt]: Epoch 12 / 100: avg data time: 4.99e+00, avg batch time: 6.4291, average train loss: 5.3184
[11/25 22:27:46 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5780, average loss: 1.1836
[11/25 22:27:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.24	
[11/25 22:27:46 visual_prompt]: Best epoch 12: best metric: -1.184
[11/25 22:27:46 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/25 22:35:18 visual_prompt]: Epoch 13 / 100: avg data time: 5.01e+00, avg batch time: 6.4535, average train loss: 3.7504
[11/25 22:36:10 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5795, average loss: 1.4799
[11/25 22:36:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.98	
[11/25 22:36:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/25 22:43:41 visual_prompt]: Epoch 14 / 100: avg data time: 5.01e+00, avg batch time: 6.4407, average train loss: 4.2360
[11/25 22:44:32 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5848, average loss: 13.8317
[11/25 22:44:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.00	
[11/25 22:44:32 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/25 22:52:03 visual_prompt]: Epoch 15 / 100: avg data time: 4.99e+00, avg batch time: 6.4326, average train loss: 5.3924
[11/25 22:52:54 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5794, average loss: 2.5251
[11/25 22:52:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.43	
[11/25 22:52:54 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/25 23:00:22 visual_prompt]: Epoch 16 / 100: avg data time: 4.96e+00, avg batch time: 6.3929, average train loss: 3.5871
[11/25 23:01:13 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5801, average loss: 2.3650
[11/25 23:01:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.85	
[11/25 23:01:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/25 23:08:40 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3868, average train loss: 4.7276
[11/25 23:09:31 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5832, average loss: 2.5114
[11/25 23:09:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.18	
[11/25 23:09:31 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/25 23:16:57 visual_prompt]: Epoch 18 / 100: avg data time: 4.92e+00, avg batch time: 6.3581, average train loss: 4.7482
[11/25 23:17:48 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5822, average loss: 4.3037
[11/25 23:17:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.01	
[11/25 23:17:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/25 23:25:14 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3724, average train loss: 4.8727
[11/25 23:26:05 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5790, average loss: 15.6805
[11/25 23:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[11/25 23:26:05 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/25 23:33:33 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e+00, avg batch time: 6.3953, average train loss: 3.9398
[11/25 23:34:24 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5841, average loss: 4.8538
[11/25 23:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.06	
[11/25 23:34:24 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/25 23:41:51 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3925, average train loss: 2.6785
[11/25 23:42:43 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5826, average loss: 2.7862
[11/25 23:42:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.30	
[11/25 23:42:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/25 23:50:10 visual_prompt]: Epoch 22 / 100: avg data time: 4.95e+00, avg batch time: 6.3832, average train loss: 3.1041
[11/25 23:51:01 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5769, average loss: 4.1943
[11/25 23:51:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.44	
[11/25 23:51:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/25 23:58:29 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4068, average train loss: 4.4100
[11/25 23:59:21 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5782, average loss: 4.5350
[11/25 23:59:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.91	
[11/25 23:59:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/26 00:06:47 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3747, average train loss: 2.9875
[11/26 00:07:38 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5794, average loss: 1.0411
[11/26 00:07:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.31	
[11/26 00:07:38 visual_prompt]: Best epoch 24: best metric: -1.041
[11/26 00:07:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/26 00:15:07 visual_prompt]: Epoch 25 / 100: avg data time: 4.97e+00, avg batch time: 6.4066, average train loss: 3.2723
[11/26 00:15:58 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5809, average loss: 6.0491
[11/26 00:15:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.69	
[11/26 00:15:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/26 00:23:24 visual_prompt]: Epoch 26 / 100: avg data time: 4.95e+00, avg batch time: 6.3781, average train loss: 5.1346
[11/26 00:24:15 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5808, average loss: 4.9967
[11/26 00:24:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.25	
[11/26 00:24:15 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/26 00:31:42 visual_prompt]: Epoch 27 / 100: avg data time: 4.94e+00, avg batch time: 6.3739, average train loss: 3.7347
[11/26 00:32:33 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5816, average loss: 7.5016
[11/26 00:32:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/26 00:32:33 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/26 00:40:00 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e+00, avg batch time: 6.3838, average train loss: 6.7449
[11/26 00:40:51 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5820, average loss: 6.1131
[11/26 00:40:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.57	
[11/26 00:40:51 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/26 00:48:17 visual_prompt]: Epoch 29 / 100: avg data time: 4.93e+00, avg batch time: 6.3699, average train loss: 4.1330
[11/26 00:49:08 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5788, average loss: 4.1240
[11/26 00:49:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.20	
[11/26 00:49:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/26 00:56:36 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.4016, average train loss: 6.1640
[11/26 00:57:27 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5815, average loss: 4.6863
[11/26 00:57:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.86	
[11/26 00:57:27 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/26 01:04:53 visual_prompt]: Epoch 31 / 100: avg data time: 4.93e+00, avg batch time: 6.3635, average train loss: 2.3970
[11/26 01:05:44 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5798, average loss: 0.9740
[11/26 01:05:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.18	
[11/26 01:05:44 visual_prompt]: Best epoch 31: best metric: -0.974
[11/26 01:05:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/26 01:13:16 visual_prompt]: Epoch 32 / 100: avg data time: 5.02e+00, avg batch time: 6.4593, average train loss: 4.0516
[11/26 01:14:07 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5772, average loss: 5.0493
[11/26 01:14:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.82	
[11/26 01:14:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/26 01:21:34 visual_prompt]: Epoch 33 / 100: avg data time: 4.94e+00, avg batch time: 6.3802, average train loss: 3.0158
[11/26 01:22:25 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5819, average loss: 0.7154
[11/26 01:22:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/26 01:22:25 visual_prompt]: Best epoch 33: best metric: -0.715
[11/26 01:22:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/26 01:29:51 visual_prompt]: Epoch 34 / 100: avg data time: 4.94e+00, avg batch time: 6.3746, average train loss: 3.0531
[11/26 01:30:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5816, average loss: 6.5177
[11/26 01:30:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.99	
[11/26 01:30:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/26 01:38:09 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3751, average train loss: 3.8015
[11/26 01:39:00 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5800, average loss: 4.3024
[11/26 01:39:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.26	
[11/26 01:39:00 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/26 01:46:29 visual_prompt]: Epoch 36 / 100: avg data time: 4.97e+00, avg batch time: 6.4113, average train loss: 3.6850
[11/26 01:47:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5814, average loss: 1.6586
[11/26 01:47:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.49	
[11/26 01:47:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/26 01:54:47 visual_prompt]: Epoch 37 / 100: avg data time: 4.94e+00, avg batch time: 6.3793, average train loss: 2.3560
[11/26 01:55:38 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5810, average loss: 3.3506
[11/26 01:55:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.18	
[11/26 01:55:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/26 02:03:07 visual_prompt]: Epoch 38 / 100: avg data time: 4.98e+00, avg batch time: 6.4162, average train loss: 2.1797
[11/26 02:04:01 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5832, average loss: 1.3502
[11/26 02:04:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.47	
[11/26 02:04:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/26 02:11:29 visual_prompt]: Epoch 39 / 100: avg data time: 4.96e+00, avg batch time: 6.3975, average train loss: 3.0097
[11/26 02:12:20 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5824, average loss: 1.6081
[11/26 02:12:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 47.02	
[11/26 02:12:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/26 02:19:46 visual_prompt]: Epoch 40 / 100: avg data time: 4.94e+00, avg batch time: 6.3747, average train loss: 2.1590
[11/26 02:20:37 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5814, average loss: 2.5659
[11/26 02:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.97	
[11/26 02:20:37 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/26 02:28:04 visual_prompt]: Epoch 41 / 100: avg data time: 4.94e+00, avg batch time: 6.3799, average train loss: 3.9374
[11/26 02:28:55 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5800, average loss: 0.7776
[11/26 02:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.58	
[11/26 02:28:55 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/26 02:36:21 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3725, average train loss: 3.3744
[11/26 02:37:12 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5805, average loss: 3.0424
[11/26 02:37:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.54	
[11/26 02:37:12 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/26 02:44:40 visual_prompt]: Epoch 43 / 100: avg data time: 4.96e+00, avg batch time: 6.3919, average train loss: 2.2511
[11/26 02:45:31 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5832, average loss: 5.2004
[11/26 02:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.20	
[11/26 02:45:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/26 02:52:59 visual_prompt]: Epoch 44 / 100: avg data time: 4.96e+00, avg batch time: 6.3975, average train loss: 2.9197
[11/26 02:53:50 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5840, average loss: 6.6694
[11/26 02:53:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.34	
[11/26 02:53:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/26 03:01:19 visual_prompt]: Epoch 45 / 100: avg data time: 4.96e+00, avg batch time: 6.4053, average train loss: 5.4124
[11/26 03:02:10 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5803, average loss: 2.3087
[11/26 03:02:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.23	
[11/26 03:02:10 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/26 03:09:37 visual_prompt]: Epoch 46 / 100: avg data time: 4.95e+00, avg batch time: 6.3920, average train loss: 3.1880
[11/26 03:10:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5869, average loss: 3.7959
[11/26 03:10:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.39	
[11/26 03:10:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/26 03:17:56 visual_prompt]: Epoch 47 / 100: avg data time: 4.96e+00, avg batch time: 6.3925, average train loss: 3.3901
[11/26 03:18:47 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5816, average loss: 12.2685
[11/26 03:18:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.24	
[11/26 03:18:47 visual_prompt]: Stopping early.
[11/26 03:18:47 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 03:18:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 03:18:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/26 03:18:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 03:18:47 visual_prompt]: Training with config:
[11/26 03:18:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 03:18:47 visual_prompt]: Loading training data...
[11/26 03:18:47 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 03:18:47 visual_prompt]: Loading validation data...
[11/26 03:18:47 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 03:18:47 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 03:18:50 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 03:18:50 visual_prompt]: tuned percent:0.532
[11/26 03:18:50 visual_prompt]: Device used for model: 0
[11/26 03:18:50 visual_prompt]: Setting up Evaluator...
[11/26 03:18:50 visual_prompt]: Setting up Trainer...
[11/26 03:18:50 visual_prompt]: 	Setting up the optimizer...
[11/26 03:18:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 03:26:18 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.3949, average train loss: 1.4863
[11/26 03:27:10 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5806, average loss: 1.4553
[11/26 03:27:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 03:27:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/26 03:34:37 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e+00, avg batch time: 6.3825, average train loss: 1.6350
[11/26 03:35:28 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5823, average loss: 1.0889
[11/26 03:35:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.61	
[11/26 03:35:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/26 03:42:55 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.3925, average train loss: 0.8564
[11/26 03:43:46 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5793, average loss: 2.0091
[11/26 03:43:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.74	
[11/26 03:43:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/26 03:51:15 visual_prompt]: Epoch 4 / 100: avg data time: 4.96e+00, avg batch time: 6.4024, average train loss: 0.8667
[11/26 03:52:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5777, average loss: 0.7010
[11/26 03:52:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[11/26 03:52:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/26 03:59:32 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3780, average train loss: 0.8591
[11/26 04:00:23 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5824, average loss: 1.4949
[11/26 04:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.80	
[11/26 04:00:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/26 04:07:51 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.3954, average train loss: 1.0410
[11/26 04:08:42 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5844, average loss: 1.0563
[11/26 04:08:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/26 04:08:42 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/26 04:16:08 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3678, average train loss: 1.0587
[11/26 04:16:59 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5807, average loss: 1.5394
[11/26 04:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.79	
[11/26 04:16:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/26 04:24:26 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3841, average train loss: 0.9856
[11/26 04:25:17 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5778, average loss: 1.2600
[11/26 04:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[11/26 04:25:17 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/26 04:32:44 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3731, average train loss: 1.1851
[11/26 04:33:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5811, average loss: 2.2828
[11/26 04:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.81	
[11/26 04:33:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/26 04:41:01 visual_prompt]: Epoch 10 / 100: avg data time: 4.94e+00, avg batch time: 6.3746, average train loss: 6.4870
[11/26 04:41:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5758, average loss: 1.7846
[11/26 04:41:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.25	
[11/26 04:41:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/26 04:49:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.3934, average train loss: 4.1940
[11/26 04:50:11 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5775, average loss: 0.7725
[11/26 04:50:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.22	
[11/26 04:50:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/26 04:57:37 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3727, average train loss: 5.2577
[11/26 04:58:28 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5805, average loss: 1.0665
[11/26 04:58:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.48	
[11/26 04:58:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/26 05:05:55 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3849, average train loss: 5.7331
[11/26 05:06:46 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5842, average loss: 0.8797
[11/26 05:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.99	
[11/26 05:06:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/26 05:14:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3779, average train loss: 2.3982
[11/26 05:15:04 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5824, average loss: 2.9792
[11/26 05:15:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.20	
[11/26 05:15:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/26 05:22:30 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3729, average train loss: 1.2540
[11/26 05:23:21 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5808, average loss: 1.1216
[11/26 05:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.35	
[11/26 05:23:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/26 05:30:48 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3783, average train loss: 3.0308
[11/26 05:31:39 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5775, average loss: 0.6882
[11/26 05:31:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.51	
[11/26 05:31:39 visual_prompt]: Best epoch 16: best metric: -0.688
[11/26 05:31:39 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/26 05:39:06 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3895, average train loss: 1.8124
[11/26 05:39:57 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5782, average loss: 2.5545
[11/26 05:39:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.42	
[11/26 05:39:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/26 05:47:23 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3661, average train loss: 3.3923
[11/26 05:48:14 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5788, average loss: 4.1445
[11/26 05:48:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.33	
[11/26 05:48:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/26 05:55:39 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3594, average train loss: 4.9310
[11/26 05:56:30 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5816, average loss: 2.9908
[11/26 05:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.89	
[11/26 05:56:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/26 06:03:57 visual_prompt]: Epoch 20 / 100: avg data time: 4.95e+00, avg batch time: 6.3862, average train loss: 3.1189
[11/26 06:04:48 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5798, average loss: 1.0089
[11/26 06:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/26 06:04:48 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/26 06:12:15 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3835, average train loss: 2.4156
[11/26 06:13:06 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5799, average loss: 1.3406
[11/26 06:13:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.79	
[11/26 06:13:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/26 06:20:33 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3744, average train loss: 1.5438
[11/26 06:21:24 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5783, average loss: 3.6511
[11/26 06:21:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.96	
[11/26 06:21:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/26 06:28:51 visual_prompt]: Epoch 23 / 100: avg data time: 4.95e+00, avg batch time: 6.3893, average train loss: 3.9009
[11/26 06:29:42 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5804, average loss: 4.4872
[11/26 06:29:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.60	
[11/26 06:29:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/26 06:37:09 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3790, average train loss: 2.8096
[11/26 06:38:00 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5798, average loss: 2.9821
[11/26 06:38:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.71	
[11/26 06:38:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/26 06:45:27 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3888, average train loss: 2.2089
[11/26 06:46:18 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5831, average loss: 5.1471
[11/26 06:46:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.62	
[11/26 06:46:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/26 06:53:44 visual_prompt]: Epoch 26 / 100: avg data time: 4.94e+00, avg batch time: 6.3720, average train loss: 3.4482
[11/26 06:54:35 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5804, average loss: 1.4598
[11/26 06:54:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/26 06:54:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/26 07:02:01 visual_prompt]: Epoch 27 / 100: avg data time: 4.92e+00, avg batch time: 6.3573, average train loss: 1.7899
[11/26 07:02:52 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5791, average loss: 3.3906
[11/26 07:02:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.80	
[11/26 07:02:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/26 07:10:18 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e+00, avg batch time: 6.3763, average train loss: 3.2631
[11/26 07:11:09 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5786, average loss: 0.7212
[11/26 07:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.76	
[11/26 07:11:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/26 07:18:36 visual_prompt]: Epoch 29 / 100: avg data time: 4.95e+00, avg batch time: 6.3801, average train loss: 2.4844
[11/26 07:19:27 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5853, average loss: 4.5180
[11/26 07:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/26 07:19:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/26 07:26:54 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.3917, average train loss: 2.0008
[11/26 07:27:46 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5783, average loss: 2.5384
[11/26 07:27:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.94	
[11/26 07:27:46 visual_prompt]: Stopping early.
[11/26 07:27:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 07:27:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 07:27:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/26 07:27:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 07:27:46 visual_prompt]: Training with config:
[11/26 07:27:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 07:27:46 visual_prompt]: Loading training data...
[11/26 07:27:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 07:27:46 visual_prompt]: Loading validation data...
[11/26 07:27:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 07:27:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 07:27:49 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 07:27:49 visual_prompt]: tuned percent:0.532
[11/26 07:27:49 visual_prompt]: Device used for model: 0
[11/26 07:27:49 visual_prompt]: Setting up Evaluator...
[11/26 07:27:49 visual_prompt]: Setting up Trainer...
[11/26 07:27:49 visual_prompt]: 	Setting up the optimizer...
[11/26 07:27:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 07:35:16 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.3918, average train loss: 1.4863
[11/26 07:36:07 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5860, average loss: 1.4553
[11/26 07:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 07:36:07 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/26 07:43:35 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.3946, average train loss: 1.6214
[11/26 07:44:26 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5801, average loss: 1.1949
[11/26 07:44:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.63	
[11/26 07:44:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/26 07:51:53 visual_prompt]: Epoch 3 / 100: avg data time: 4.95e+00, avg batch time: 6.3848, average train loss: 0.8810
[11/26 07:52:44 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5765, average loss: 1.9229
[11/26 07:52:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.67	
[11/26 07:52:44 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/26 08:00:12 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3892, average train loss: 0.8860
[11/26 08:01:03 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5848, average loss: 0.6878
[11/26 08:01:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.24	
[11/26 08:01:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/26 08:08:30 visual_prompt]: Epoch 5 / 100: avg data time: 4.95e+00, avg batch time: 6.3857, average train loss: 0.9844
[11/26 08:09:21 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5796, average loss: 1.3880
[11/26 08:09:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/26 08:09:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/26 08:16:48 visual_prompt]: Epoch 6 / 100: avg data time: 4.95e+00, avg batch time: 6.3885, average train loss: 1.5478
[11/26 08:17:39 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5804, average loss: 0.8937
[11/26 08:17:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.44	
[11/26 08:17:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/26 08:25:06 visual_prompt]: Epoch 7 / 100: avg data time: 4.95e+00, avg batch time: 6.3863, average train loss: 1.0173
[11/26 08:25:57 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5859, average loss: 0.7426
[11/26 08:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.80	
[11/26 08:25:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/26 08:33:25 visual_prompt]: Epoch 8 / 100: avg data time: 4.96e+00, avg batch time: 6.3951, average train loss: 0.8847
[11/26 08:34:16 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5801, average loss: 1.4942
[11/26 08:34:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/26 08:34:16 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/26 08:41:43 visual_prompt]: Epoch 9 / 100: avg data time: 4.95e+00, avg batch time: 6.3852, average train loss: 2.7653
[11/26 08:42:34 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5865, average loss: 1.0565
[11/26 08:42:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.41	
[11/26 08:42:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/26 08:50:01 visual_prompt]: Epoch 10 / 100: avg data time: 4.95e+00, avg batch time: 6.3829, average train loss: 2.6951
[11/26 08:50:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5780, average loss: 4.2018
[11/26 08:50:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.56	
[11/26 08:50:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/26 08:58:20 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3902, average train loss: 4.0179
[11/26 08:59:11 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5851, average loss: 6.0288
[11/26 08:59:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[11/26 08:59:11 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/26 09:06:37 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3733, average train loss: 2.0882
[11/26 09:07:28 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5838, average loss: 1.0290
[11/26 09:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.19	
[11/26 09:07:28 visual_prompt]: Best epoch 12: best metric: -1.029
[11/26 09:07:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/26 09:14:55 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3863, average train loss: 1.2469
[11/26 09:15:46 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5801, average loss: 1.4594
[11/26 09:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.04	
[11/26 09:15:46 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/26 09:23:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3829, average train loss: 1.1669
[11/26 09:24:04 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5801, average loss: 1.1698
[11/26 09:24:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/26 09:24:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/26 09:31:30 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3634, average train loss: 0.9826
[11/26 09:32:21 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5815, average loss: 0.7357
[11/26 09:32:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/26 09:32:21 visual_prompt]: Best epoch 15: best metric: -0.736
[11/26 09:32:21 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/26 09:39:47 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3779, average train loss: 1.0206
[11/26 09:40:38 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5805, average loss: 0.6875
[11/26 09:40:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.50	
[11/26 09:40:38 visual_prompt]: Best epoch 16: best metric: -0.687
[11/26 09:40:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/26 09:48:04 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3681, average train loss: 0.9372
[11/26 09:48:55 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5784, average loss: 0.7151
[11/26 09:48:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/26 09:48:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/26 09:56:21 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3679, average train loss: 0.8880
[11/26 09:57:12 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5772, average loss: 1.1504
[11/26 09:57:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.23	
[11/26 09:57:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/26 10:04:38 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3670, average train loss: 0.9286
[11/26 10:05:29 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5781, average loss: 1.1004
[11/26 10:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.36	
[11/26 10:05:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/26 10:13:00 visual_prompt]: Epoch 20 / 100: avg data time: 5.01e+00, avg batch time: 6.4437, average train loss: 1.0324
[11/26 10:13:51 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5805, average loss: 0.7345
[11/26 10:13:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.63	
[11/26 10:13:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/26 10:21:18 visual_prompt]: Epoch 21 / 100: avg data time: 4.94e+00, avg batch time: 6.3801, average train loss: 1.0471
[11/26 10:22:09 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5823, average loss: 1.3865
[11/26 10:22:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.72	
[11/26 10:22:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/26 10:29:35 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3775, average train loss: 1.2070
[11/26 10:30:26 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5780, average loss: 0.9246
[11/26 10:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.99	
[11/26 10:30:26 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/26 10:37:55 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4044, average train loss: 0.8842
[11/26 10:38:46 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5819, average loss: 1.4459
[11/26 10:38:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.29	
[11/26 10:38:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/26 10:46:12 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3742, average train loss: 0.9811
[11/26 10:47:03 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5808, average loss: 0.6807
[11/26 10:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.36	
[11/26 10:47:03 visual_prompt]: Best epoch 24: best metric: -0.681
[11/26 10:47:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/26 10:54:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.96e+00, avg batch time: 6.3904, average train loss: 0.9889
[11/26 10:55:21 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5811, average loss: 1.7266
[11/26 10:55:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.85	
[11/26 10:55:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/26 11:02:49 visual_prompt]: Epoch 26 / 100: avg data time: 4.95e+00, avg batch time: 6.3864, average train loss: 1.1506
[11/26 11:03:40 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5798, average loss: 1.0583
[11/26 11:03:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.25	
[11/26 11:03:40 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/26 11:11:05 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3656, average train loss: 0.9342
[11/26 11:11:56 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5802, average loss: 1.0897
[11/26 11:11:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.55	
[11/26 11:11:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/26 11:19:24 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e+00, avg batch time: 6.3875, average train loss: 0.9433
[11/26 11:20:15 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5803, average loss: 1.0355
[11/26 11:20:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.10	
[11/26 11:20:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/26 11:27:41 visual_prompt]: Epoch 29 / 100: avg data time: 4.94e+00, avg batch time: 6.3752, average train loss: 0.8282
[11/26 11:28:32 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5833, average loss: 1.9617
[11/26 11:28:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.40	
[11/26 11:28:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/26 11:35:59 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e+00, avg batch time: 6.3876, average train loss: 0.8803
[11/26 11:36:50 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5812, average loss: 1.3985
[11/26 11:36:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.14	
[11/26 11:36:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/26 11:44:15 visual_prompt]: Epoch 31 / 100: avg data time: 4.92e+00, avg batch time: 6.3567, average train loss: 0.8130
[11/26 11:45:06 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5815, average loss: 0.6648
[11/26 11:45:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 65.11	
[11/26 11:45:06 visual_prompt]: Best epoch 31: best metric: -0.665
[11/26 11:45:06 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/26 11:52:33 visual_prompt]: Epoch 32 / 100: avg data time: 4.94e+00, avg batch time: 6.3793, average train loss: 0.9211
[11/26 11:53:24 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5811, average loss: 0.9366
[11/26 11:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.68	
[11/26 11:53:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/26 12:00:51 visual_prompt]: Epoch 33 / 100: avg data time: 4.94e+00, avg batch time: 6.3792, average train loss: 0.9207
[11/26 12:01:42 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5833, average loss: 0.7185
[11/26 12:01:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.69	
[11/26 12:01:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/26 12:09:08 visual_prompt]: Epoch 34 / 100: avg data time: 4.94e+00, avg batch time: 6.3740, average train loss: 0.9264
[11/26 12:09:59 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5798, average loss: 1.7004
[11/26 12:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.54	
[11/26 12:09:59 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/26 12:17:25 visual_prompt]: Epoch 35 / 100: avg data time: 4.93e+00, avg batch time: 6.3648, average train loss: 0.9421
[11/26 12:18:16 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5798, average loss: 0.7892
[11/26 12:18:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.04	
[11/26 12:18:16 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/26 12:25:44 visual_prompt]: Epoch 36 / 100: avg data time: 4.96e+00, avg batch time: 6.3999, average train loss: 0.7960
[11/26 12:26:35 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5854, average loss: 0.7737
[11/26 12:26:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.26	
[11/26 12:26:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/26 12:34:02 visual_prompt]: Epoch 37 / 100: avg data time: 4.95e+00, avg batch time: 6.3873, average train loss: 0.8507
[11/26 12:34:53 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5834, average loss: 0.8610
[11/26 12:34:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.59	
[11/26 12:34:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/26 12:42:20 visual_prompt]: Epoch 38 / 100: avg data time: 4.95e+00, avg batch time: 6.3868, average train loss: 0.7865
[11/26 12:43:12 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5832, average loss: 1.3960
[11/26 12:43:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.72	
[11/26 12:43:12 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/26 12:50:39 visual_prompt]: Epoch 39 / 100: avg data time: 4.95e+00, avg batch time: 6.3925, average train loss: 0.8903
[11/26 12:51:30 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5789, average loss: 1.3137
[11/26 12:51:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.14	
[11/26 12:51:30 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/26 12:58:57 visual_prompt]: Epoch 40 / 100: avg data time: 4.94e+00, avg batch time: 6.3796, average train loss: 0.7843
[11/26 12:59:48 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5862, average loss: 0.6927
[11/26 12:59:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.93	
[11/26 12:59:48 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/26 13:07:15 visual_prompt]: Epoch 41 / 100: avg data time: 4.95e+00, avg batch time: 6.3811, average train loss: 0.7661
[11/26 13:08:06 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5808, average loss: 0.8193
[11/26 13:08:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[11/26 13:08:06 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/26 13:15:32 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3739, average train loss: 0.7495
[11/26 13:16:23 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5838, average loss: 0.6496
[11/26 13:16:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.28	
[11/26 13:16:23 visual_prompt]: Best epoch 42: best metric: -0.650
[11/26 13:16:23 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/26 13:23:52 visual_prompt]: Epoch 43 / 100: avg data time: 4.97e+00, avg batch time: 6.4050, average train loss: 0.7161
[11/26 13:24:43 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5770, average loss: 1.9414
[11/26 13:24:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.75	
[11/26 13:24:43 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/26 13:32:12 visual_prompt]: Epoch 44 / 100: avg data time: 4.97e+00, avg batch time: 6.4151, average train loss: 0.8816
[11/26 13:33:03 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5797, average loss: 0.6577
[11/26 13:33:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.47	
[11/26 13:33:03 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/26 13:40:30 visual_prompt]: Epoch 45 / 100: avg data time: 4.95e+00, avg batch time: 6.3862, average train loss: 0.7604
[11/26 13:41:21 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5818, average loss: 0.7783
[11/26 13:41:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.51	
[11/26 13:41:21 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/26 13:48:48 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e+00, avg batch time: 6.3784, average train loss: 0.7785
[11/26 13:49:39 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5811, average loss: 0.6453
[11/26 13:49:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.25	
[11/26 13:49:39 visual_prompt]: Best epoch 46: best metric: -0.645
[11/26 13:49:39 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/26 13:57:06 visual_prompt]: Epoch 47 / 100: avg data time: 4.95e+00, avg batch time: 6.3950, average train loss: 0.9601
[11/26 13:57:57 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5866, average loss: 0.7167
[11/26 13:57:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.11	
[11/26 13:57:57 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/26 14:05:24 visual_prompt]: Epoch 48 / 100: avg data time: 4.94e+00, avg batch time: 6.3764, average train loss: 0.6963
[11/26 14:06:15 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5808, average loss: 1.7540
[11/26 14:06:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.67	
[11/26 14:06:15 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/26 14:13:44 visual_prompt]: Epoch 49 / 100: avg data time: 4.97e+00, avg batch time: 6.4157, average train loss: 0.9557
[11/26 14:14:35 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5812, average loss: 1.4158
[11/26 14:14:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.71	
[11/26 14:14:35 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/26 14:22:01 visual_prompt]: Epoch 50 / 100: avg data time: 4.94e+00, avg batch time: 6.3727, average train loss: 0.9288
[11/26 14:22:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5817, average loss: 0.7403
[11/26 14:22:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.05	
[11/26 14:22:52 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/26 14:30:18 visual_prompt]: Epoch 51 / 100: avg data time: 4.93e+00, avg batch time: 6.3721, average train loss: 0.7229
[11/26 14:31:09 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5850, average loss: 0.8697
[11/26 14:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.91	
[11/26 14:31:09 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/26 14:38:36 visual_prompt]: Epoch 52 / 100: avg data time: 4.94e+00, avg batch time: 6.3782, average train loss: 0.7241
[11/26 14:39:27 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5834, average loss: 0.6523
[11/26 14:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.87	
[11/26 14:39:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/26 14:46:55 visual_prompt]: Epoch 53 / 100: avg data time: 4.97e+00, avg batch time: 6.4033, average train loss: 0.7654
[11/26 14:47:46 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5807, average loss: 0.6691
[11/26 14:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.50	
[11/26 14:47:46 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/26 14:55:14 visual_prompt]: Epoch 54 / 100: avg data time: 4.96e+00, avg batch time: 6.3983, average train loss: 0.7238
[11/26 14:56:05 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5801, average loss: 1.7287
[11/26 14:56:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.79	
[11/26 14:56:05 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[11/26 15:03:31 visual_prompt]: Epoch 55 / 100: avg data time: 4.93e+00, avg batch time: 6.3628, average train loss: 1.0356
[11/26 15:04:22 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5834, average loss: 2.2162
[11/26 15:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.28	
[11/26 15:04:22 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[11/26 15:11:47 visual_prompt]: Epoch 56 / 100: avg data time: 4.92e+00, avg batch time: 6.3626, average train loss: 1.2473
[11/26 15:12:38 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5789, average loss: 0.9496
[11/26 15:12:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.13	
[11/26 15:12:38 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[11/26 15:20:06 visual_prompt]: Epoch 57 / 100: avg data time: 4.95e+00, avg batch time: 6.3881, average train loss: 0.8415
[11/26 15:20:57 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5808, average loss: 0.8823
[11/26 15:20:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.23	
[11/26 15:20:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[11/26 15:28:22 visual_prompt]: Epoch 58 / 100: avg data time: 4.92e+00, avg batch time: 6.3618, average train loss: 0.7703
[11/26 15:29:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5825, average loss: 0.9684
[11/26 15:29:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.40	
[11/26 15:29:13 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[11/26 15:36:41 visual_prompt]: Epoch 59 / 100: avg data time: 4.95e+00, avg batch time: 6.3866, average train loss: 0.7828
[11/26 15:37:32 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5879, average loss: 0.6654
[11/26 15:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.61	
[11/26 15:37:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[11/26 15:44:59 visual_prompt]: Epoch 60 / 100: avg data time: 4.95e+00, avg batch time: 6.3843, average train loss: 0.6723
[11/26 15:45:50 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5803, average loss: 0.6401
[11/26 15:45:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.13	
[11/26 15:45:50 visual_prompt]: Best epoch 60: best metric: -0.640
[11/26 15:45:50 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[11/26 15:53:16 visual_prompt]: Epoch 61 / 100: avg data time: 4.93e+00, avg batch time: 6.3667, average train loss: 0.7060
[11/26 15:54:07 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5835, average loss: 0.6808
[11/26 15:54:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.25	
[11/26 15:54:07 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[11/26 16:01:34 visual_prompt]: Epoch 62 / 100: avg data time: 4.94e+00, avg batch time: 6.3792, average train loss: 0.6743
[11/26 16:02:25 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5818, average loss: 0.7265
[11/26 16:02:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.70	
[11/26 16:02:25 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[11/26 16:09:51 visual_prompt]: Epoch 63 / 100: avg data time: 4.94e+00, avg batch time: 6.3800, average train loss: 0.6645
[11/26 16:10:42 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5798, average loss: 0.6328
[11/26 16:10:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.30	
[11/26 16:10:42 visual_prompt]: Best epoch 63: best metric: -0.633
[11/26 16:10:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[11/26 16:18:08 visual_prompt]: Epoch 64 / 100: avg data time: 4.94e+00, avg batch time: 6.3722, average train loss: 0.6621
[11/26 16:18:59 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5823, average loss: 0.7139
[11/26 16:18:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.77	
[11/26 16:18:59 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[11/26 16:26:26 visual_prompt]: Epoch 65 / 100: avg data time: 4.94e+00, avg batch time: 6.3763, average train loss: 0.6703
[11/26 16:27:18 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5777, average loss: 0.6501
[11/26 16:27:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.36	
[11/26 16:27:18 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[11/26 16:34:44 visual_prompt]: Epoch 66 / 100: avg data time: 4.93e+00, avg batch time: 6.3700, average train loss: 0.7395
[11/26 16:35:35 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5815, average loss: 0.6679
[11/26 16:35:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.39	
[11/26 16:35:35 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[11/26 16:43:01 visual_prompt]: Epoch 67 / 100: avg data time: 4.94e+00, avg batch time: 6.3732, average train loss: 0.6559
[11/26 16:43:52 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5776, average loss: 0.7737
[11/26 16:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.17	
[11/26 16:43:52 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[11/26 16:51:18 visual_prompt]: Epoch 68 / 100: avg data time: 4.94e+00, avg batch time: 6.3727, average train loss: 0.7044
[11/26 16:52:09 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5784, average loss: 0.6332
[11/26 16:52:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.44	
[11/26 16:52:09 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[11/26 16:59:36 visual_prompt]: Epoch 69 / 100: avg data time: 4.94e+00, avg batch time: 6.3831, average train loss: 0.6891
[11/26 17:00:27 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5783, average loss: 0.6384
[11/26 17:00:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.15	
[11/26 17:00:27 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[11/26 17:07:54 visual_prompt]: Epoch 70 / 100: avg data time: 4.95e+00, avg batch time: 6.3880, average train loss: 0.6296
[11/26 17:08:45 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5789, average loss: 0.7300
[11/26 17:08:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.00	
[11/26 17:08:46 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[11/26 17:16:12 visual_prompt]: Epoch 71 / 100: avg data time: 4.93e+00, avg batch time: 6.3711, average train loss: 0.6490
[11/26 17:17:03 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5799, average loss: 0.6348
[11/26 17:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.61	
[11/26 17:17:03 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[11/26 17:24:29 visual_prompt]: Epoch 72 / 100: avg data time: 4.93e+00, avg batch time: 6.3695, average train loss: 0.6206
[11/26 17:25:20 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5805, average loss: 0.6337
[11/26 17:25:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.83	
[11/26 17:25:20 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[11/26 17:32:48 visual_prompt]: Epoch 73 / 100: avg data time: 4.96e+00, avg batch time: 6.3991, average train loss: 0.6205
[11/26 17:33:39 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5835, average loss: 0.7726
[11/26 17:33:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.87	
[11/26 17:33:39 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[11/26 17:41:05 visual_prompt]: Epoch 74 / 100: avg data time: 4.93e+00, avg batch time: 6.3729, average train loss: 0.6449
[11/26 17:41:56 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5837, average loss: 0.6412
[11/26 17:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.38	
[11/26 17:41:56 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[11/26 17:49:22 visual_prompt]: Epoch 75 / 100: avg data time: 4.94e+00, avg batch time: 6.3702, average train loss: 0.6157
[11/26 17:50:13 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5813, average loss: 0.6767
[11/26 17:50:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.55	
[11/26 17:50:13 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[11/26 17:57:40 visual_prompt]: Epoch 76 / 100: avg data time: 4.94e+00, avg batch time: 6.3736, average train loss: 0.6182
[11/26 17:58:31 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5793, average loss: 0.6633
[11/26 17:58:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.46	
[11/26 17:58:31 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[11/26 18:05:56 visual_prompt]: Epoch 77 / 100: avg data time: 4.93e+00, avg batch time: 6.3641, average train loss: 0.6020
[11/26 18:06:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5781, average loss: 0.7176
[11/26 18:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.95	
[11/26 18:06:47 visual_prompt]: Stopping early.
[11/26 18:06:47 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 18:06:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 18:06:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/26 18:06:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 18:06:47 visual_prompt]: Training with config:
[11/26 18:06:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 18:06:47 visual_prompt]: Loading training data...
[11/26 18:06:47 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 18:06:47 visual_prompt]: Loading validation data...
[11/26 18:06:47 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 18:06:47 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 18:06:50 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 18:06:50 visual_prompt]: tuned percent:0.532
[11/26 18:06:50 visual_prompt]: Device used for model: 0
[11/26 18:06:50 visual_prompt]: Setting up Evaluator...
[11/26 18:06:50 visual_prompt]: Setting up Trainer...
[11/26 18:06:50 visual_prompt]: 	Setting up the optimizer...
[11/26 18:06:50 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 18:14:18 visual_prompt]: Epoch 1 / 100: avg data time: 4.95e+00, avg batch time: 6.3928, average train loss: 1.4863
[11/26 18:15:09 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5811, average loss: 1.4553
[11/26 18:15:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 18:15:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/26 18:22:36 visual_prompt]: Epoch 2 / 100: avg data time: 4.95e+00, avg batch time: 6.3840, average train loss: 1.6234
[11/26 18:23:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5826, average loss: 1.2002
[11/26 18:23:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.39	
[11/26 18:23:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/26 18:30:55 visual_prompt]: Epoch 3 / 100: avg data time: 4.95e+00, avg batch time: 6.3876, average train loss: 0.8825
[11/26 18:31:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5778, average loss: 1.9262
[11/26 18:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.37	
[11/26 18:31:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/26 18:39:12 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3769, average train loss: 0.8895
[11/26 18:40:03 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5804, average loss: 0.6904
[11/26 18:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.46	
[11/26 18:40:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/26 18:47:29 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3693, average train loss: 1.0184
[11/26 18:48:21 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5778, average loss: 1.2124
[11/26 18:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/26 18:48:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/26 18:55:48 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.3939, average train loss: 1.7453
[11/26 18:56:39 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5788, average loss: 2.4215
[11/26 18:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.67	
[11/26 18:56:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/26 19:04:05 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3629, average train loss: 2.6563
[11/26 19:04:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5792, average loss: 1.1308
[11/26 19:04:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[11/26 19:04:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/26 19:12:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.94e+00, avg batch time: 6.3797, average train loss: 0.9193
[11/26 19:13:14 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5845, average loss: 1.9297
[11/26 19:13:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.54	
[11/26 19:13:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/26 19:20:39 visual_prompt]: Epoch 9 / 100: avg data time: 4.92e+00, avg batch time: 6.3593, average train loss: 1.5521
[11/26 19:21:30 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5829, average loss: 0.7257
[11/26 19:21:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 62.16	
[11/26 19:21:30 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/26 19:28:55 visual_prompt]: Epoch 10 / 100: avg data time: 4.93e+00, avg batch time: 6.3638, average train loss: 1.8357
[11/26 19:29:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5809, average loss: 1.1747
[11/26 19:29:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.59	
[11/26 19:29:47 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/26 19:37:13 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3801, average train loss: 1.4509
[11/26 19:38:04 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5793, average loss: 1.2769
[11/26 19:38:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[11/26 19:38:04 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/26 19:45:31 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3724, average train loss: 1.3602
[11/26 19:46:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5806, average loss: 0.8997
[11/26 19:46:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.84	
[11/26 19:46:22 visual_prompt]: Best epoch 12: best metric: -0.900
[11/26 19:46:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/26 19:53:49 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3832, average train loss: 1.4793
[11/26 19:54:40 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5788, average loss: 0.7527
[11/26 19:54:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.32	
[11/26 19:54:40 visual_prompt]: Best epoch 13: best metric: -0.753
[11/26 19:54:40 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/26 20:02:06 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3729, average train loss: 1.3267
[11/26 20:02:57 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5824, average loss: 0.7889
[11/26 20:02:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.60	
[11/26 20:02:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/26 20:10:22 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3570, average train loss: 0.8805
[11/26 20:11:13 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5782, average loss: 1.0179
[11/26 20:11:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.91	
[11/26 20:11:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/26 20:18:39 visual_prompt]: Epoch 16 / 100: avg data time: 4.93e+00, avg batch time: 6.3678, average train loss: 1.0770
[11/26 20:19:30 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5797, average loss: 0.7695
[11/26 20:19:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 60.53	
[11/26 20:19:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/26 20:26:57 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3854, average train loss: 1.0693
[11/26 20:27:48 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5809, average loss: 1.1426
[11/26 20:27:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.77	
[11/26 20:27:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/26 20:35:15 visual_prompt]: Epoch 18 / 100: avg data time: 4.95e+00, avg batch time: 6.3861, average train loss: 1.7269
[11/26 20:36:06 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5828, average loss: 3.1994
[11/26 20:36:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.98	
[11/26 20:36:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/26 20:43:33 visual_prompt]: Epoch 19 / 100: avg data time: 4.95e+00, avg batch time: 6.3836, average train loss: 0.9595
[11/26 20:44:24 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5796, average loss: 1.2690
[11/26 20:44:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 66.41	
[11/26 20:44:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/26 20:51:52 visual_prompt]: Epoch 20 / 100: avg data time: 4.95e+00, avg batch time: 6.3890, average train loss: 0.9201
[11/26 20:52:43 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5798, average loss: 1.3413
[11/26 20:52:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.75	
[11/26 20:52:43 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/26 21:00:10 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3864, average train loss: 0.9774
[11/26 21:01:01 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5803, average loss: 1.1516
[11/26 21:01:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.61	
[11/26 21:01:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/26 21:08:27 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3734, average train loss: 1.1508
[11/26 21:09:18 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5830, average loss: 0.9339
[11/26 21:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.30	
[11/26 21:09:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/26 21:16:46 visual_prompt]: Epoch 23 / 100: avg data time: 4.95e+00, avg batch time: 6.3887, average train loss: 0.9111
[11/26 21:17:37 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5786, average loss: 1.0304
[11/26 21:17:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.42	
[11/26 21:17:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/26 21:25:03 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3701, average train loss: 0.8268
[11/26 21:25:54 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5809, average loss: 1.1132
[11/26 21:25:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 68.37	
[11/26 21:25:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/26 21:33:21 visual_prompt]: Epoch 25 / 100: avg data time: 4.96e+00, avg batch time: 6.3913, average train loss: 1.0879
[11/26 21:34:12 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5863, average loss: 1.8979
[11/26 21:34:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.44	
[11/26 21:34:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/26 21:41:39 visual_prompt]: Epoch 26 / 100: avg data time: 4.94e+00, avg batch time: 6.3803, average train loss: 1.1431
[11/26 21:42:30 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5782, average loss: 0.7541
[11/26 21:42:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.81	
[11/26 21:42:30 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/26 21:49:57 visual_prompt]: Epoch 27 / 100: avg data time: 4.94e+00, avg batch time: 6.3767, average train loss: 0.9422
[11/26 21:50:48 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5809, average loss: 0.8976
[11/26 21:50:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.41	
[11/26 21:50:48 visual_prompt]: Stopping early.
[11/26 21:50:48 visual_prompt]: Rank of current process: 0. World size: 1
[11/26 21:50:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/26 21:50:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/26 21:50:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/26 21:50:48 visual_prompt]: Training with config:
[11/26 21:50:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/26 21:50:48 visual_prompt]: Loading training data...
[11/26 21:50:48 visual_prompt]: Constructing mammo-cbis dataset train...
[11/26 21:50:48 visual_prompt]: Loading validation data...
[11/26 21:50:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/26 21:50:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/26 21:50:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/26 21:50:51 visual_prompt]: tuned percent:0.532
[11/26 21:50:51 visual_prompt]: Device used for model: 0
[11/26 21:50:51 visual_prompt]: Setting up Evaluator...
[11/26 21:50:51 visual_prompt]: Setting up Trainer...
[11/26 21:50:51 visual_prompt]: 	Setting up the optimizer...
[11/26 21:50:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/26 21:58:19 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.3995, average train loss: 1.4863
[11/26 21:59:10 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5817, average loss: 1.4553
[11/26 21:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/26 21:59:10 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/26 22:06:37 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e+00, avg batch time: 6.3815, average train loss: 1.1795
[11/26 22:07:28 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5830, average loss: 0.6956
[11/26 22:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/26 22:07:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/26 22:14:55 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e+00, avg batch time: 6.3791, average train loss: 0.7272
[11/26 22:15:46 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5808, average loss: 0.7472
[11/26 22:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/26 22:15:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/26 22:23:12 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3759, average train loss: 0.7497
[11/26 22:24:03 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5767, average loss: 0.7911
[11/26 22:24:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/26 22:24:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/26 22:31:29 visual_prompt]: Epoch 5 / 100: avg data time: 4.93e+00, avg batch time: 6.3598, average train loss: 0.7555
[11/26 22:32:20 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5789, average loss: 1.1662
[11/26 22:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.83	
[11/26 22:32:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/26 22:39:48 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.3945, average train loss: 0.7732
[11/26 22:40:39 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5803, average loss: 0.7100
[11/26 22:40:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.75	
[11/26 22:40:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/26 22:48:04 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3645, average train loss: 0.7512
[11/26 22:48:55 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5781, average loss: 0.8093
[11/26 22:48:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/26 22:48:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/26 22:56:22 visual_prompt]: Epoch 8 / 100: avg data time: 4.94e+00, avg batch time: 6.3826, average train loss: 0.9242
[11/26 22:57:13 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5802, average loss: 2.3953
[11/26 22:57:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.52	
[11/26 22:57:13 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/26 23:04:41 visual_prompt]: Epoch 9 / 100: avg data time: 4.95e+00, avg batch time: 6.3887, average train loss: 0.9086
[11/26 23:05:32 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5811, average loss: 0.9776
[11/26 23:05:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[11/26 23:05:32 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/26 23:12:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.94e+00, avg batch time: 6.3753, average train loss: 0.9466
[11/26 23:13:50 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.5818, average loss: 0.9460
[11/26 23:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.76	
[11/26 23:13:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/26 23:21:18 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.3951, average train loss: 1.2816
[11/26 23:22:09 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5808, average loss: 0.8141
[11/26 23:22:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.91	
[11/26 23:22:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/26 23:29:35 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3721, average train loss: 1.0734
[11/26 23:30:26 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5760, average loss: 0.7131
[11/26 23:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.28	
[11/26 23:30:26 visual_prompt]: Best epoch 12: best metric: -0.713
[11/26 23:30:26 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/26 23:37:53 visual_prompt]: Epoch 13 / 100: avg data time: 4.94e+00, avg batch time: 6.3833, average train loss: 0.9674
[11/26 23:38:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5821, average loss: 0.8383
[11/26 23:38:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.55	
[11/26 23:38:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/26 23:46:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3728, average train loss: 1.3544
[11/26 23:47:01 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5774, average loss: 1.4522
[11/26 23:47:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.14	
[11/26 23:47:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/26 23:54:27 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3694, average train loss: 0.9761
[11/26 23:55:18 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5806, average loss: 0.8391
[11/26 23:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[11/26 23:55:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/27 00:02:45 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3746, average train loss: 0.8855
[11/27 00:03:36 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5838, average loss: 1.1889
[11/27 00:03:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.95	
[11/27 00:03:36 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/27 00:11:03 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3871, average train loss: 0.8701
[11/27 00:11:54 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5809, average loss: 0.7937
[11/27 00:11:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.73	
[11/27 00:11:54 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/27 00:19:20 visual_prompt]: Epoch 18 / 100: avg data time: 4.94e+00, avg batch time: 6.3714, average train loss: 1.2564
[11/27 00:20:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5795, average loss: 0.8474
[11/27 00:20:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[11/27 00:20:11 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/27 00:27:37 visual_prompt]: Epoch 19 / 100: avg data time: 4.94e+00, avg batch time: 6.3712, average train loss: 1.0420
[11/27 00:28:28 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5809, average loss: 2.1713
[11/27 00:28:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[11/27 00:28:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/27 00:35:56 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e+00, avg batch time: 6.3932, average train loss: 1.6317
[11/27 00:36:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5814, average loss: 2.0296
[11/27 00:36:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.89	
[11/27 00:36:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/27 00:44:14 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3832, average train loss: 1.4047
[11/27 00:45:05 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5820, average loss: 2.0380
[11/27 00:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.06	
[11/27 00:45:05 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/27 00:52:32 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3756, average train loss: 1.1997
[11/27 00:53:23 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5837, average loss: 1.0199
[11/27 00:53:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.06	
[11/27 00:53:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/27 01:00:50 visual_prompt]: Epoch 23 / 100: avg data time: 4.96e+00, avg batch time: 6.3905, average train loss: 1.6932
[11/27 01:01:41 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5824, average loss: 5.9419
[11/27 01:01:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.57	
[11/27 01:01:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/27 01:09:08 visual_prompt]: Epoch 24 / 100: avg data time: 4.94e+00, avg batch time: 6.3735, average train loss: 1.3954
[11/27 01:09:59 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5783, average loss: 1.0848
[11/27 01:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/27 01:09:59 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/27 01:17:26 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3883, average train loss: 1.4704
[11/27 01:18:17 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5901, average loss: 2.5826
[11/27 01:18:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.97	
[11/27 01:18:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/27 01:25:43 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e+00, avg batch time: 6.3708, average train loss: 1.3950
[11/27 01:26:34 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5798, average loss: 0.7533
[11/27 01:26:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[11/27 01:26:34 visual_prompt]: Stopping early.
[11/27 01:26:34 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 01:26:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 01:26:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 01:26:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 01:26:34 visual_prompt]: Training with config:
[11/27 01:26:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 01:26:34 visual_prompt]: Loading training data...
[11/27 01:26:34 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 01:26:34 visual_prompt]: Loading validation data...
[11/27 01:26:34 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 01:26:34 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 01:26:37 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 01:26:37 visual_prompt]: tuned percent:0.532
[11/27 01:26:37 visual_prompt]: Device used for model: 0
[11/27 01:26:37 visual_prompt]: Setting up Evaluator...
[11/27 01:26:37 visual_prompt]: Setting up Trainer...
[11/27 01:26:37 visual_prompt]: 	Setting up the optimizer...
[11/27 01:26:37 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 01:34:06 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.4038, average train loss: 1.4863
[11/27 01:34:57 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5820, average loss: 1.4553
[11/27 01:34:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 01:34:57 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/27 01:42:24 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e+00, avg batch time: 6.3779, average train loss: 1.1983
[11/27 01:43:15 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5824, average loss: 0.6985
[11/27 01:43:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/27 01:43:15 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/27 01:50:41 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e+00, avg batch time: 6.3816, average train loss: 0.7529
[11/27 01:51:32 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5804, average loss: 0.7602
[11/27 01:51:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.00	
[11/27 01:51:32 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/27 01:58:58 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3679, average train loss: 0.8826
[11/27 01:59:49 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5845, average loss: 0.8200
[11/27 01:59:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.32	
[11/27 01:59:49 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/27 02:07:15 visual_prompt]: Epoch 5 / 100: avg data time: 4.92e+00, avg batch time: 6.3610, average train loss: 0.8840
[11/27 02:08:06 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5811, average loss: 1.1470
[11/27 02:08:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/27 02:08:06 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/27 02:15:33 visual_prompt]: Epoch 6 / 100: avg data time: 4.95e+00, avg batch time: 6.3859, average train loss: 0.8625
[11/27 02:16:24 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5809, average loss: 0.6905
[11/27 02:16:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 62.09	
[11/27 02:16:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/27 02:23:50 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3668, average train loss: 0.7278
[11/27 02:24:41 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5806, average loss: 0.7797
[11/27 02:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.62	
[11/27 02:24:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/27 02:32:07 visual_prompt]: Epoch 8 / 100: avg data time: 4.94e+00, avg batch time: 6.3807, average train loss: 0.8387
[11/27 02:32:58 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5833, average loss: 1.8256
[11/27 02:32:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/27 02:32:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/27 02:40:25 visual_prompt]: Epoch 9 / 100: avg data time: 4.95e+00, avg batch time: 6.3823, average train loss: 0.8937
[11/27 02:41:16 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5806, average loss: 1.4170
[11/27 02:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.00	
[11/27 02:41:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/27 02:48:43 visual_prompt]: Epoch 10 / 100: avg data time: 4.94e+00, avg batch time: 6.3821, average train loss: 0.8014
[11/27 02:49:34 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5787, average loss: 0.7553
[11/27 02:49:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.26	
[11/27 02:49:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/27 02:57:01 visual_prompt]: Epoch 11 / 100: avg data time: 4.95e+00, avg batch time: 6.3842, average train loss: 0.7719
[11/27 02:57:52 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5832, average loss: 1.0939
[11/27 02:57:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[11/27 02:57:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/27 03:05:18 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e+00, avg batch time: 6.3613, average train loss: 1.2029
[11/27 03:06:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5783, average loss: 0.6821
[11/27 03:06:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 59.40	
[11/27 03:06:09 visual_prompt]: Best epoch 12: best metric: -0.682
[11/27 03:06:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/27 03:13:36 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3856, average train loss: 0.9304
[11/27 03:14:27 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5795, average loss: 0.6770
[11/27 03:14:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 61.99	
[11/27 03:14:27 visual_prompt]: Best epoch 13: best metric: -0.677
[11/27 03:14:27 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/27 03:21:53 visual_prompt]: Epoch 14 / 100: avg data time: 4.94e+00, avg batch time: 6.3795, average train loss: 1.0278
[11/27 03:22:44 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5805, average loss: 0.7013
[11/27 03:22:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.30	
[11/27 03:22:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/27 03:30:10 visual_prompt]: Epoch 15 / 100: avg data time: 4.93e+00, avg batch time: 6.3695, average train loss: 0.7587
[11/27 03:31:01 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5819, average loss: 1.3136
[11/27 03:31:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.77	
[11/27 03:31:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/27 03:38:27 visual_prompt]: Epoch 16 / 100: avg data time: 4.93e+00, avg batch time: 6.3671, average train loss: 0.9340
[11/27 03:39:18 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5772, average loss: 0.8048
[11/27 03:39:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.97	
[11/27 03:39:18 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/27 03:46:44 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3727, average train loss: 0.8456
[11/27 03:47:35 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5785, average loss: 1.1311
[11/27 03:47:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.70	
[11/27 03:47:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/27 03:55:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.92e+00, avg batch time: 6.3531, average train loss: 1.0051
[11/27 03:55:51 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5841, average loss: 1.1554
[11/27 03:55:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.01	
[11/27 03:55:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/27 04:03:17 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3677, average train loss: 0.8364
[11/27 04:04:08 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5843, average loss: 0.6971
[11/27 04:04:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.09	
[11/27 04:04:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/27 04:11:35 visual_prompt]: Epoch 20 / 100: avg data time: 4.95e+00, avg batch time: 6.3862, average train loss: 0.7105
[11/27 04:12:26 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5795, average loss: 0.6882
[11/27 04:12:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.63	
[11/27 04:12:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/27 04:19:53 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3881, average train loss: 0.7184
[11/27 04:20:44 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5800, average loss: 0.9805
[11/27 04:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/27 04:20:44 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/27 04:28:10 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3705, average train loss: 0.7620
[11/27 04:29:01 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5782, average loss: 0.8825
[11/27 04:29:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[11/27 04:29:01 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/27 04:36:30 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4067, average train loss: 0.7701
[11/27 04:37:21 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5820, average loss: 1.0716
[11/27 04:37:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.25	
[11/27 04:37:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/27 04:44:46 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3628, average train loss: 0.8550
[11/27 04:45:37 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5778, average loss: 0.7206
[11/27 04:45:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/27 04:45:37 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/27 04:53:05 visual_prompt]: Epoch 25 / 100: avg data time: 4.96e+00, avg batch time: 6.3932, average train loss: 1.0153
[11/27 04:53:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5830, average loss: 1.9391
[11/27 04:53:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.55	
[11/27 04:53:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/27 05:01:23 visual_prompt]: Epoch 26 / 100: avg data time: 4.94e+00, avg batch time: 6.3810, average train loss: 1.0461
[11/27 05:02:14 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5770, average loss: 0.7227
[11/27 05:02:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.77	
[11/27 05:02:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/27 05:09:39 visual_prompt]: Epoch 27 / 100: avg data time: 4.93e+00, avg batch time: 6.3650, average train loss: 0.8019
[11/27 05:10:31 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5779, average loss: 0.8428
[11/27 05:10:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/27 05:10:31 visual_prompt]: Stopping early.
[11/27 05:10:31 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 05:10:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 05:10:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 05:10:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 05:10:31 visual_prompt]: Training with config:
[11/27 05:10:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 05:10:31 visual_prompt]: Loading training data...
[11/27 05:10:31 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 05:10:31 visual_prompt]: Loading validation data...
[11/27 05:10:31 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 05:10:31 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 05:10:34 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 05:10:34 visual_prompt]: tuned percent:0.532
[11/27 05:10:34 visual_prompt]: Device used for model: 0
[11/27 05:10:34 visual_prompt]: Setting up Evaluator...
[11/27 05:10:34 visual_prompt]: Setting up Trainer...
[11/27 05:10:34 visual_prompt]: 	Setting up the optimizer...
[11/27 05:10:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 05:18:02 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.4029, average train loss: 1.4863
[11/27 05:18:53 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5842, average loss: 1.4553
[11/27 05:18:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 05:18:53 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/27 05:26:21 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e+00, avg batch time: 6.3929, average train loss: 1.2004
[11/27 05:27:12 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5803, average loss: 0.6988
[11/27 05:27:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/27 05:27:12 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/27 05:34:39 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e+00, avg batch time: 6.3791, average train loss: 0.7590
[11/27 05:35:30 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5765, average loss: 0.7680
[11/27 05:35:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/27 05:35:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/27 05:42:56 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3750, average train loss: 0.8984
[11/27 05:43:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5804, average loss: 0.8087
[11/27 05:43:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[11/27 05:43:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/27 05:51:14 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3763, average train loss: 0.9182
[11/27 05:52:05 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5811, average loss: 1.3584
[11/27 05:52:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/27 05:52:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/27 05:59:33 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.3984, average train loss: 0.8877
[11/27 06:00:24 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5790, average loss: 0.8583
[11/27 06:00:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.88	
[11/27 06:00:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/27 06:07:49 visual_prompt]: Epoch 7 / 100: avg data time: 4.92e+00, avg batch time: 6.3548, average train loss: 0.7590
[11/27 06:08:40 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5814, average loss: 0.9747
[11/27 06:08:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[11/27 06:08:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/27 06:16:06 visual_prompt]: Epoch 8 / 100: avg data time: 4.94e+00, avg batch time: 6.3713, average train loss: 0.7757
[11/27 06:16:57 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5829, average loss: 1.4752
[11/27 06:16:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.70	
[11/27 06:16:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/27 06:24:23 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3702, average train loss: 0.9687
[11/27 06:25:14 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5802, average loss: 1.7041
[11/27 06:25:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.12	
[11/27 06:25:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/27 06:32:41 visual_prompt]: Epoch 10 / 100: avg data time: 4.95e+00, avg batch time: 6.3803, average train loss: 0.9234
[11/27 06:33:32 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5822, average loss: 0.6652
[11/27 06:33:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.91	
[11/27 06:33:32 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/27 06:40:59 visual_prompt]: Epoch 11 / 100: avg data time: 4.94e+00, avg batch time: 6.3798, average train loss: 0.9014
[11/27 06:41:49 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5774, average loss: 1.0716
[11/27 06:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.08	
[11/27 06:41:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/27 06:49:16 visual_prompt]: Epoch 12 / 100: avg data time: 4.94e+00, avg batch time: 6.3733, average train loss: 0.8637
[11/27 06:50:07 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5828, average loss: 1.0738
[11/27 06:50:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/27 06:50:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/27 06:57:34 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3802, average train loss: 0.7342
[11/27 06:58:25 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5767, average loss: 0.7680
[11/27 06:58:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.86	
[11/27 06:58:25 visual_prompt]: Best epoch 13: best metric: -0.768
[11/27 06:58:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/27 07:05:52 visual_prompt]: Epoch 14 / 100: avg data time: 4.95e+00, avg batch time: 6.3888, average train loss: 0.8942
[11/27 07:06:43 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5775, average loss: 0.7401
[11/27 07:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 62.99	
[11/27 07:06:43 visual_prompt]: Best epoch 14: best metric: -0.740
[11/27 07:06:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/27 07:14:08 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3579, average train loss: 0.8148
[11/27 07:14:59 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5814, average loss: 0.8043
[11/27 07:14:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.22	
[11/27 07:14:59 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/27 07:22:26 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3747, average train loss: 0.8598
[11/27 07:23:17 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5811, average loss: 0.6505
[11/27 07:23:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.94	
[11/27 07:23:17 visual_prompt]: Best epoch 16: best metric: -0.650
[11/27 07:23:17 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/27 07:30:44 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3838, average train loss: 0.7246
[11/27 07:31:35 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5810, average loss: 0.7440
[11/27 07:31:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.41	
[11/27 07:31:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/27 07:39:01 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3658, average train loss: 0.9067
[11/27 07:39:52 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5778, average loss: 1.7585
[11/27 07:39:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.82	
[11/27 07:39:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/27 07:47:18 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3665, average train loss: 0.8283
[11/27 07:48:09 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5815, average loss: 1.1293
[11/27 07:48:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/27 07:48:09 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/27 07:55:37 visual_prompt]: Epoch 20 / 100: avg data time: 4.96e+00, avg batch time: 6.3994, average train loss: 0.7449
[11/27 07:56:28 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5788, average loss: 0.6278
[11/27 07:56:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.43	
[11/27 07:56:28 visual_prompt]: Best epoch 20: best metric: -0.628
[11/27 07:56:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/27 08:03:55 visual_prompt]: Epoch 21 / 100: avg data time: 4.95e+00, avg batch time: 6.3879, average train loss: 0.7236
[11/27 08:04:46 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5779, average loss: 1.1887
[11/27 08:04:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.24	
[11/27 08:04:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/27 08:12:13 visual_prompt]: Epoch 22 / 100: avg data time: 4.94e+00, avg batch time: 6.3771, average train loss: 0.7983
[11/27 08:13:04 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5809, average loss: 1.2417
[11/27 08:13:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.28	
[11/27 08:13:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/27 08:20:32 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4057, average train loss: 0.8778
[11/27 08:21:23 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5820, average loss: 0.9785
[11/27 08:21:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.27	
[11/27 08:21:23 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/27 08:28:49 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3669, average train loss: 0.7457
[11/27 08:29:40 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5764, average loss: 1.3981
[11/27 08:29:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.88	
[11/27 08:29:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/27 08:37:08 visual_prompt]: Epoch 25 / 100: avg data time: 4.96e+00, avg batch time: 6.3946, average train loss: 0.7502
[11/27 08:37:59 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5789, average loss: 0.7029
[11/27 08:37:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.09	
[11/27 08:37:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/27 08:45:25 visual_prompt]: Epoch 26 / 100: avg data time: 4.93e+00, avg batch time: 6.3617, average train loss: 0.6993
[11/27 08:46:16 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5807, average loss: 0.6264
[11/27 08:46:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.34	
[11/27 08:46:16 visual_prompt]: Best epoch 26: best metric: -0.626
[11/27 08:46:16 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/27 08:53:41 visual_prompt]: Epoch 27 / 100: avg data time: 4.92e+00, avg batch time: 6.3565, average train loss: 0.7001
[11/27 08:54:32 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5781, average loss: 0.8586
[11/27 08:54:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.79	
[11/27 08:54:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/27 09:01:58 visual_prompt]: Epoch 28 / 100: avg data time: 4.94e+00, avg batch time: 6.3775, average train loss: 0.7071
[11/27 09:02:49 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5790, average loss: 0.7898
[11/27 09:02:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 74.59	
[11/27 09:02:49 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/27 09:10:15 visual_prompt]: Epoch 29 / 100: avg data time: 4.94e+00, avg batch time: 6.3726, average train loss: 0.7472
[11/27 09:11:06 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5797, average loss: 1.2905
[11/27 09:11:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.60	
[11/27 09:11:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/27 09:18:34 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.3943, average train loss: 0.7447
[11/27 09:19:25 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5807, average loss: 0.7021
[11/27 09:19:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.63	
[11/27 09:19:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/27 09:26:50 visual_prompt]: Epoch 31 / 100: avg data time: 4.93e+00, avg batch time: 6.3596, average train loss: 0.7410
[11/27 09:27:41 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5869, average loss: 0.6355
[11/27 09:27:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.55	
[11/27 09:27:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/27 09:35:09 visual_prompt]: Epoch 32 / 100: avg data time: 4.95e+00, avg batch time: 6.3854, average train loss: 0.7250
[11/27 09:36:00 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5857, average loss: 0.6228
[11/27 09:36:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 73.43	
[11/27 09:36:00 visual_prompt]: Best epoch 32: best metric: -0.623
[11/27 09:36:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/27 09:43:27 visual_prompt]: Epoch 33 / 100: avg data time: 4.95e+00, avg batch time: 6.3830, average train loss: 0.6586
[11/27 09:44:18 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5831, average loss: 0.6086
[11/27 09:44:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 74.28	
[11/27 09:44:18 visual_prompt]: Best epoch 33: best metric: -0.609
[11/27 09:44:18 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/27 09:51:54 visual_prompt]: Epoch 34 / 100: avg data time: 5.08e+00, avg batch time: 6.5189, average train loss: 0.7196
[11/27 09:52:45 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5822, average loss: 0.6373
[11/27 09:52:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.15	
[11/27 09:52:45 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/27 10:00:12 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3768, average train loss: 0.6718
[11/27 10:01:03 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5776, average loss: 0.6527
[11/27 10:01:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 73.02	
[11/27 10:01:03 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/27 10:08:36 visual_prompt]: Epoch 36 / 100: avg data time: 5.04e+00, avg batch time: 6.4713, average train loss: 0.7162
[11/27 10:09:27 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5853, average loss: 1.2581
[11/27 10:09:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.58	
[11/27 10:09:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/27 10:17:04 visual_prompt]: Epoch 37 / 100: avg data time: 5.09e+00, avg batch time: 6.5271, average train loss: 0.7757
[11/27 10:17:55 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5810, average loss: 0.8346
[11/27 10:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 72.84	
[11/27 10:17:55 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/27 10:25:26 visual_prompt]: Epoch 38 / 100: avg data time: 5.00e+00, avg batch time: 6.4395, average train loss: 0.6646
[11/27 10:26:17 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5803, average loss: 0.6188
[11/27 10:26:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.29	
[11/27 10:26:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/27 10:33:44 visual_prompt]: Epoch 39 / 100: avg data time: 4.95e+00, avg batch time: 6.3803, average train loss: 0.6615
[11/27 10:34:35 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5808, average loss: 0.6355
[11/27 10:34:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.07	
[11/27 10:34:35 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/27 10:42:02 visual_prompt]: Epoch 40 / 100: avg data time: 4.95e+00, avg batch time: 6.3851, average train loss: 0.7041
[11/27 10:42:53 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5771, average loss: 0.7088
[11/27 10:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.97	
[11/27 10:42:53 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/27 10:50:19 visual_prompt]: Epoch 41 / 100: avg data time: 4.94e+00, avg batch time: 6.3751, average train loss: 0.6663
[11/27 10:51:10 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5791, average loss: 0.6483
[11/27 10:51:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 73.61	
[11/27 10:51:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/27 10:58:36 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e+00, avg batch time: 6.3718, average train loss: 0.6256
[11/27 10:59:28 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5794, average loss: 0.7569
[11/27 10:59:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.87	
[11/27 10:59:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/27 11:06:55 visual_prompt]: Epoch 43 / 100: avg data time: 4.96e+00, avg batch time: 6.3946, average train loss: 0.6088
[11/27 11:07:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5788, average loss: 1.1159
[11/27 11:07:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 75.65	
[11/27 11:07:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/27 11:15:15 visual_prompt]: Epoch 44 / 100: avg data time: 4.96e+00, avg batch time: 6.4023, average train loss: 0.7478
[11/27 11:16:06 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5782, average loss: 0.5945
[11/27 11:16:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 75.54	
[11/27 11:16:06 visual_prompt]: Best epoch 44: best metric: -0.595
[11/27 11:16:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/27 11:23:33 visual_prompt]: Epoch 45 / 100: avg data time: 4.95e+00, avg batch time: 6.3856, average train loss: 0.6332
[11/27 11:24:24 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5779, average loss: 0.5908
[11/27 11:24:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.64	
[11/27 11:24:24 visual_prompt]: Best epoch 45: best metric: -0.591
[11/27 11:24:24 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/27 11:31:50 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e+00, avg batch time: 6.3753, average train loss: 0.5853
[11/27 11:32:42 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5803, average loss: 0.6293
[11/27 11:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.87	
[11/27 11:32:42 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/27 11:40:09 visual_prompt]: Epoch 47 / 100: avg data time: 4.96e+00, avg batch time: 6.3902, average train loss: 0.6431
[11/27 11:41:00 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5782, average loss: 0.6813
[11/27 11:41:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.84	
[11/27 11:41:00 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/27 11:48:26 visual_prompt]: Epoch 48 / 100: avg data time: 4.93e+00, avg batch time: 6.3720, average train loss: 0.6118
[11/27 11:49:17 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5813, average loss: 0.7943
[11/27 11:49:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 74.49	
[11/27 11:49:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/27 11:56:45 visual_prompt]: Epoch 49 / 100: avg data time: 4.96e+00, avg batch time: 6.3953, average train loss: 0.6062
[11/27 11:57:36 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5858, average loss: 0.6202
[11/27 11:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.99	
[11/27 11:57:36 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/27 12:05:04 visual_prompt]: Epoch 50 / 100: avg data time: 4.96e+00, avg batch time: 6.3963, average train loss: 0.6151
[11/27 12:05:55 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5844, average loss: 0.8952
[11/27 12:05:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 74.80	
[11/27 12:05:55 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/27 12:13:22 visual_prompt]: Epoch 51 / 100: avg data time: 4.94e+00, avg batch time: 6.3767, average train loss: 0.5953
[11/27 12:14:13 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5848, average loss: 0.8696
[11/27 12:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 74.88	
[11/27 12:14:13 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/27 12:21:40 visual_prompt]: Epoch 52 / 100: avg data time: 4.96e+00, avg batch time: 6.3942, average train loss: 0.5918
[11/27 12:22:32 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5799, average loss: 0.6252
[11/27 12:22:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.38	
[11/27 12:22:32 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/27 12:30:00 visual_prompt]: Epoch 53 / 100: avg data time: 4.96e+00, avg batch time: 6.3987, average train loss: 0.6374
[11/27 12:30:51 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5840, average loss: 0.6561
[11/27 12:30:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 75.69	
[11/27 12:30:51 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/27 12:38:18 visual_prompt]: Epoch 54 / 100: avg data time: 4.94e+00, avg batch time: 6.3878, average train loss: 0.6122
[11/27 12:39:09 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5776, average loss: 0.6972
[11/27 12:39:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.11	
[11/27 12:39:09 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[11/27 12:46:35 visual_prompt]: Epoch 55 / 100: avg data time: 4.93e+00, avg batch time: 6.3675, average train loss: 0.6575
[11/27 12:47:26 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5824, average loss: 0.9848
[11/27 12:47:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.64	
[11/27 12:47:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[11/27 12:54:53 visual_prompt]: Epoch 56 / 100: avg data time: 4.95e+00, avg batch time: 6.3896, average train loss: 0.6801
[11/27 12:55:44 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5809, average loss: 0.6264
[11/27 12:55:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.30	
[11/27 12:55:44 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[11/27 13:03:12 visual_prompt]: Epoch 57 / 100: avg data time: 4.96e+00, avg batch time: 6.3945, average train loss: 0.5297
[11/27 13:04:04 visual_prompt]: Inference (val):avg data time: 2.67e-04, avg batch time: 0.6072, average loss: 1.1900
[11/27 13:04:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.85	
[11/27 13:04:04 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[11/27 13:11:30 visual_prompt]: Epoch 58 / 100: avg data time: 4.94e+00, avg batch time: 6.3778, average train loss: 0.5367
[11/27 13:12:22 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5802, average loss: 0.7478
[11/27 13:12:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.04	
[11/27 13:12:22 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[11/27 13:19:49 visual_prompt]: Epoch 59 / 100: avg data time: 4.96e+00, avg batch time: 6.3961, average train loss: 0.5299
[11/27 13:20:41 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5808, average loss: 1.0627
[11/27 13:20:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 65.80	
[11/27 13:20:41 visual_prompt]: Stopping early.
[11/27 13:20:41 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 13:20:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 13:20:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 13:20:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 13:20:41 visual_prompt]: Training with config:
[11/27 13:20:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 13:20:41 visual_prompt]: Loading training data...
[11/27 13:20:41 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 13:20:41 visual_prompt]: Loading validation data...
[11/27 13:20:41 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 13:20:41 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 13:20:44 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 13:20:44 visual_prompt]: tuned percent:0.532
[11/27 13:20:44 visual_prompt]: Device used for model: 0
[11/27 13:20:44 visual_prompt]: Setting up Evaluator...
[11/27 13:20:44 visual_prompt]: Setting up Trainer...
[11/27 13:20:44 visual_prompt]: 	Setting up the optimizer...
[11/27 13:20:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 13:28:12 visual_prompt]: Epoch 1 / 100: avg data time: 4.96e+00, avg batch time: 6.4008, average train loss: 1.4863
[11/27 13:29:03 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5831, average loss: 1.4553
[11/27 13:29:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 13:29:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/27 13:36:30 visual_prompt]: Epoch 2 / 100: avg data time: 4.94e+00, avg batch time: 6.3822, average train loss: 1.2006
[11/27 13:37:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5757, average loss: 0.6988
[11/27 13:37:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[11/27 13:37:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/27 13:44:49 visual_prompt]: Epoch 3 / 100: avg data time: 4.95e+00, avg batch time: 6.3913, average train loss: 0.7595
[11/27 13:45:40 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5818, average loss: 0.7682
[11/27 13:45:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.81	
[11/27 13:45:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/27 13:53:12 visual_prompt]: Epoch 4 / 100: avg data time: 5.02e+00, avg batch time: 6.4531, average train loss: 0.8947
[11/27 13:54:03 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5802, average loss: 0.8124
[11/27 13:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.61	
[11/27 13:54:03 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/27 14:01:29 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3722, average train loss: 0.9223
[11/27 14:02:20 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5836, average loss: 1.3861
[11/27 14:02:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.24	
[11/27 14:02:20 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/27 14:09:47 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.3919, average train loss: 0.8900
[11/27 14:10:38 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5859, average loss: 0.8766
[11/27 14:10:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[11/27 14:10:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/27 14:18:04 visual_prompt]: Epoch 7 / 100: avg data time: 4.93e+00, avg batch time: 6.3671, average train loss: 0.7588
[11/27 14:18:55 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5793, average loss: 1.0101
[11/27 14:18:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/27 14:18:55 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/27 14:26:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3873, average train loss: 0.7895
[11/27 14:27:14 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5784, average loss: 1.4801
[11/27 14:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.99	
[11/27 14:27:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/27 14:34:40 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e+00, avg batch time: 6.3773, average train loss: 1.0567
[11/27 14:35:31 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5769, average loss: 1.9678
[11/27 14:35:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.97	
[11/27 14:35:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/27 14:42:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.94e+00, avg batch time: 6.3751, average train loss: 0.8385
[11/27 14:43:49 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5840, average loss: 0.8806
[11/27 14:43:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.53	
[11/27 14:43:49 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/27 14:51:17 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.3998, average train loss: 0.9429
[11/27 14:52:08 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5787, average loss: 1.2620
[11/27 14:52:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/27 14:52:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/27 14:59:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e+00, avg batch time: 6.3659, average train loss: 0.8875
[11/27 15:00:24 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5804, average loss: 1.1847
[11/27 15:00:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.54	
[11/27 15:00:24 visual_prompt]: Best epoch 12: best metric: -1.185
[11/27 15:00:24 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/27 15:07:51 visual_prompt]: Epoch 13 / 100: avg data time: 4.94e+00, avg batch time: 6.3762, average train loss: 0.7386
[11/27 15:08:42 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5799, average loss: 0.9022
[11/27 15:08:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.41	
[11/27 15:08:42 visual_prompt]: Best epoch 13: best metric: -0.902
[11/27 15:08:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/27 15:16:08 visual_prompt]: Epoch 14 / 100: avg data time: 4.93e+00, avg batch time: 6.3714, average train loss: 0.9029
[11/27 15:16:59 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5804, average loss: 0.6527
[11/27 15:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.88	
[11/27 15:16:59 visual_prompt]: Best epoch 14: best metric: -0.653
[11/27 15:16:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/27 15:24:24 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3597, average train loss: 0.7763
[11/27 15:25:15 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5823, average loss: 1.0136
[11/27 15:25:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.59	
[11/27 15:25:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/27 15:32:42 visual_prompt]: Epoch 16 / 100: avg data time: 4.94e+00, avg batch time: 6.3816, average train loss: 0.7729
[11/27 15:33:33 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5814, average loss: 0.7274
[11/27 15:33:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.14	
[11/27 15:33:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/27 15:40:59 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e+00, avg batch time: 6.3682, average train loss: 0.7495
[11/27 15:41:50 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5798, average loss: 0.6481
[11/27 15:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.01	
[11/27 15:41:50 visual_prompt]: Best epoch 17: best metric: -0.648
[11/27 15:41:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/27 15:49:16 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3677, average train loss: 1.0452
[11/27 15:50:07 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5847, average loss: 1.8409
[11/27 15:50:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.54	
[11/27 15:50:07 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/27 15:57:33 visual_prompt]: Epoch 19 / 100: avg data time: 4.93e+00, avg batch time: 6.3674, average train loss: 1.4687
[11/27 15:58:24 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5790, average loss: 0.8980
[11/27 15:58:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.40	
[11/27 15:58:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/27 16:05:53 visual_prompt]: Epoch 20 / 100: avg data time: 4.97e+00, avg batch time: 6.4051, average train loss: 0.7341
[11/27 16:06:44 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5851, average loss: 0.6098
[11/27 16:06:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.99	
[11/27 16:06:44 visual_prompt]: Best epoch 20: best metric: -0.610
[11/27 16:06:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/27 16:14:11 visual_prompt]: Epoch 21 / 100: avg data time: 4.94e+00, avg batch time: 6.3814, average train loss: 0.7037
[11/27 16:15:02 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5801, average loss: 1.2582
[11/27 16:15:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 72.44	
[11/27 16:15:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/27 16:22:32 visual_prompt]: Epoch 22 / 100: avg data time: 4.99e+00, avg batch time: 6.4294, average train loss: 0.9042
[11/27 16:23:23 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5791, average loss: 1.1301
[11/27 16:23:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.60	
[11/27 16:23:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/27 16:30:55 visual_prompt]: Epoch 23 / 100: avg data time: 5.02e+00, avg batch time: 6.4569, average train loss: 0.8556
[11/27 16:31:46 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5804, average loss: 0.7865
[11/27 16:31:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 73.93	
[11/27 16:31:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/27 16:39:12 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.3693, average train loss: 0.7096
[11/27 16:40:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5847, average loss: 1.2536
[11/27 16:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.79	
[11/27 16:40:03 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/27 16:47:30 visual_prompt]: Epoch 25 / 100: avg data time: 4.95e+00, avg batch time: 6.3886, average train loss: 0.6866
[11/27 16:48:21 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5776, average loss: 0.8741
[11/27 16:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.86	
[11/27 16:48:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/27 16:55:47 visual_prompt]: Epoch 26 / 100: avg data time: 4.94e+00, avg batch time: 6.3726, average train loss: 0.6706
[11/27 16:56:38 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5786, average loss: 0.8436
[11/27 16:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 73.76	
[11/27 16:56:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/27 17:04:04 visual_prompt]: Epoch 27 / 100: avg data time: 4.92e+00, avg batch time: 6.3617, average train loss: 0.7306
[11/27 17:04:55 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5813, average loss: 0.9208
[11/27 17:04:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 75.87	
[11/27 17:04:55 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/27 17:12:33 visual_prompt]: Epoch 28 / 100: avg data time: 5.11e+00, avg batch time: 6.5473, average train loss: 0.6340
[11/27 17:13:24 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5861, average loss: 0.6632
[11/27 17:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.90	
[11/27 17:13:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/27 17:20:52 visual_prompt]: Epoch 29 / 100: avg data time: 4.96e+00, avg batch time: 6.3955, average train loss: 0.6710
[11/27 17:21:43 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5822, average loss: 1.4244
[11/27 17:21:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 74.79	
[11/27 17:21:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/27 17:29:11 visual_prompt]: Epoch 30 / 100: avg data time: 4.95e+00, avg batch time: 6.3962, average train loss: 0.6302
[11/27 17:30:02 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5813, average loss: 1.2564
[11/27 17:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 73.18	
[11/27 17:30:02 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/27 17:37:27 visual_prompt]: Epoch 31 / 100: avg data time: 4.92e+00, avg batch time: 6.3544, average train loss: 0.7490
[11/27 17:38:18 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5805, average loss: 0.6630
[11/27 17:38:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.20	
[11/27 17:38:18 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/27 17:45:45 visual_prompt]: Epoch 32 / 100: avg data time: 4.94e+00, avg batch time: 6.3796, average train loss: 0.6544
[11/27 17:46:36 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5798, average loss: 0.6319
[11/27 17:46:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.40	
[11/27 17:46:36 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/27 17:54:03 visual_prompt]: Epoch 33 / 100: avg data time: 4.94e+00, avg batch time: 6.3921, average train loss: 0.5834
[11/27 17:54:54 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5827, average loss: 0.6300
[11/27 17:54:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.76	
[11/27 17:54:54 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/27 18:02:21 visual_prompt]: Epoch 34 / 100: avg data time: 4.94e+00, avg batch time: 6.3756, average train loss: 0.6105
[11/27 18:03:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5830, average loss: 0.9244
[11/27 18:03:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 72.72	
[11/27 18:03:11 visual_prompt]: Stopping early.
[11/27 18:03:12 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 18:03:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 18:03:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 18:03:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 18:03:12 visual_prompt]: Training with config:
[11/27 18:03:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 18:03:12 visual_prompt]: Loading training data...
[11/27 18:03:12 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 18:03:12 visual_prompt]: Loading validation data...
[11/27 18:03:12 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 18:03:12 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 18:03:14 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 18:03:14 visual_prompt]: tuned percent:0.532
[11/27 18:03:14 visual_prompt]: Device used for model: 0
[11/27 18:03:14 visual_prompt]: Setting up Evaluator...
[11/27 18:03:14 visual_prompt]: Setting up Trainer...
[11/27 18:03:14 visual_prompt]: 	Setting up the optimizer...
[11/27 18:03:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 18:10:43 visual_prompt]: Epoch 1 / 100: avg data time: 4.97e+00, avg batch time: 6.4085, average train loss: 1.4863
[11/27 18:11:34 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5809, average loss: 1.4553
[11/27 18:11:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 18:11:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/27 18:19:03 visual_prompt]: Epoch 2 / 100: avg data time: 4.97e+00, avg batch time: 6.4054, average train loss: 1.0767
[11/27 18:19:54 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5803, average loss: 0.7165
[11/27 18:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.89	
[11/27 18:19:54 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/27 18:27:21 visual_prompt]: Epoch 3 / 100: avg data time: 4.95e+00, avg batch time: 6.3871, average train loss: 0.7123
[11/27 18:28:12 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5798, average loss: 0.8119
[11/27 18:28:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/27 18:28:12 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/27 18:35:39 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3788, average train loss: 0.7353
[11/27 18:36:30 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5805, average loss: 0.7853
[11/27 18:36:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/27 18:36:30 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/27 18:43:57 visual_prompt]: Epoch 5 / 100: avg data time: 4.94e+00, avg batch time: 6.3783, average train loss: 0.7493
[11/27 18:44:48 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5787, average loss: 0.7440
[11/27 18:44:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/27 18:44:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/27 18:52:16 visual_prompt]: Epoch 6 / 100: avg data time: 4.97e+00, avg batch time: 6.4053, average train loss: 0.7282
[11/27 18:53:07 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5815, average loss: 0.6939
[11/27 18:53:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.75	
[11/27 18:53:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/27 19:00:34 visual_prompt]: Epoch 7 / 100: avg data time: 4.94e+00, avg batch time: 6.3734, average train loss: 0.7207
[11/27 19:01:25 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5814, average loss: 1.1219
[11/27 19:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/27 19:01:25 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/27 19:08:52 visual_prompt]: Epoch 8 / 100: avg data time: 4.95e+00, avg batch time: 6.3908, average train loss: 0.7393
[11/27 19:09:44 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5808, average loss: 0.8992
[11/27 19:09:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/27 19:09:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/27 19:17:12 visual_prompt]: Epoch 9 / 100: avg data time: 4.96e+00, avg batch time: 6.4003, average train loss: 0.7502
[11/27 19:18:03 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5786, average loss: 0.7116
[11/27 19:18:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.54	
[11/27 19:18:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/27 19:25:30 visual_prompt]: Epoch 10 / 100: avg data time: 4.95e+00, avg batch time: 6.3895, average train loss: 0.7194
[11/27 19:26:21 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5809, average loss: 0.6989
[11/27 19:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[11/27 19:26:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/27 19:33:49 visual_prompt]: Epoch 11 / 100: avg data time: 4.96e+00, avg batch time: 6.3939, average train loss: 0.7433
[11/27 19:34:40 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5794, average loss: 0.8597
[11/27 19:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/27 19:34:40 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/27 19:42:07 visual_prompt]: Epoch 12 / 100: avg data time: 4.95e+00, avg batch time: 6.3847, average train loss: 0.7901
[11/27 19:42:58 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5782, average loss: 0.7401
[11/27 19:42:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.09	
[11/27 19:42:58 visual_prompt]: Best epoch 12: best metric: -0.740
[11/27 19:42:58 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/27 19:50:26 visual_prompt]: Epoch 13 / 100: avg data time: 4.95e+00, avg batch time: 6.3847, average train loss: 0.7767
[11/27 19:51:17 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5781, average loss: 0.7056
[11/27 19:51:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.08	
[11/27 19:51:17 visual_prompt]: Best epoch 13: best metric: -0.706
[11/27 19:51:17 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/27 19:58:36 visual_prompt]: Epoch 14 / 100: avg data time: 4.83e+00, avg batch time: 6.2685, average train loss: 0.8127
[11/27 19:59:24 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5817, average loss: 1.2457
[11/27 19:59:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.24	
[11/27 19:59:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/27 20:06:27 visual_prompt]: Epoch 15 / 100: avg data time: 4.60e+00, avg batch time: 6.0386, average train loss: 0.8469
[11/27 20:07:16 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5824, average loss: 1.0016
[11/27 20:07:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/27 20:07:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/27 20:14:19 visual_prompt]: Epoch 16 / 100: avg data time: 4.61e+00, avg batch time: 6.0443, average train loss: 0.7687
[11/27 20:15:07 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5793, average loss: 0.7205
[11/27 20:15:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.86	
[11/27 20:15:07 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/27 20:22:15 visual_prompt]: Epoch 17 / 100: avg data time: 4.67e+00, avg batch time: 6.1035, average train loss: 0.7556
[11/27 20:23:04 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5819, average loss: 0.8274
[11/27 20:23:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.77	
[11/27 20:23:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/27 20:30:11 visual_prompt]: Epoch 18 / 100: avg data time: 4.66e+00, avg batch time: 6.0961, average train loss: 0.8427
[11/27 20:31:00 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5822, average loss: 0.9535
[11/27 20:31:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.84	
[11/27 20:31:00 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/27 20:38:06 visual_prompt]: Epoch 19 / 100: avg data time: 4.65e+00, avg batch time: 6.0900, average train loss: 0.8264
[11/27 20:38:55 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5777, average loss: 0.6885
[11/27 20:38:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.56	
[11/27 20:38:55 visual_prompt]: Best epoch 19: best metric: -0.689
[11/27 20:38:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/27 20:46:03 visual_prompt]: Epoch 20 / 100: avg data time: 4.68e+00, avg batch time: 6.1145, average train loss: 0.8535
[11/27 20:46:52 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5798, average loss: 0.6880
[11/27 20:46:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.41	
[11/27 20:46:52 visual_prompt]: Best epoch 20: best metric: -0.688
[11/27 20:46:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/27 20:54:00 visual_prompt]: Epoch 21 / 100: avg data time: 4.67e+00, avg batch time: 6.1122, average train loss: 0.7238
[11/27 20:54:49 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5829, average loss: 1.0100
[11/27 20:54:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.40	
[11/27 20:54:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/27 21:01:57 visual_prompt]: Epoch 22 / 100: avg data time: 4.67e+00, avg batch time: 6.1047, average train loss: 0.7808
[11/27 21:02:45 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5797, average loss: 0.8744
[11/27 21:02:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/27 21:02:45 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/27 21:09:53 visual_prompt]: Epoch 23 / 100: avg data time: 4.68e+00, avg batch time: 6.1126, average train loss: 0.7535
[11/27 21:10:42 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5824, average loss: 1.0724
[11/27 21:10:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/27 21:10:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/27 21:17:49 visual_prompt]: Epoch 24 / 100: avg data time: 4.67e+00, avg batch time: 6.0994, average train loss: 0.7305
[11/27 21:18:38 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5823, average loss: 0.6910
[11/27 21:18:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.36	
[11/27 21:18:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/27 21:25:47 visual_prompt]: Epoch 25 / 100: avg data time: 4.68e+00, avg batch time: 6.1155, average train loss: 0.7646
[11/27 21:26:36 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5816, average loss: 0.7354
[11/27 21:26:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.28	
[11/27 21:26:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/27 21:33:43 visual_prompt]: Epoch 26 / 100: avg data time: 4.66e+00, avg batch time: 6.0998, average train loss: 0.8526
[11/27 21:34:32 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5802, average loss: 1.0537
[11/27 21:34:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.66	
[11/27 21:34:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/27 21:41:38 visual_prompt]: Epoch 27 / 100: avg data time: 4.65e+00, avg batch time: 6.0860, average train loss: 0.8048
[11/27 21:42:27 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5779, average loss: 0.9531
[11/27 21:42:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.50	
[11/27 21:42:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/27 21:49:34 visual_prompt]: Epoch 28 / 100: avg data time: 4.67e+00, avg batch time: 6.1045, average train loss: 0.8162
[11/27 21:50:23 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5790, average loss: 0.9955
[11/27 21:50:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.38	
[11/27 21:50:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/27 21:57:30 visual_prompt]: Epoch 29 / 100: avg data time: 4.66e+00, avg batch time: 6.0965, average train loss: 0.7588
[11/27 21:58:18 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5875, average loss: 1.0721
[11/27 21:58:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.06	
[11/27 21:58:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/27 22:05:23 visual_prompt]: Epoch 30 / 100: avg data time: 4.63e+00, avg batch time: 6.0620, average train loss: 0.7299
[11/27 22:06:11 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5786, average loss: 0.8199
[11/27 22:06:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.34	
[11/27 22:06:11 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/27 22:13:14 visual_prompt]: Epoch 31 / 100: avg data time: 4.60e+00, avg batch time: 6.0401, average train loss: 0.7621
[11/27 22:14:03 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5757, average loss: 0.7268
[11/27 22:14:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[11/27 22:14:03 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/27 22:21:09 visual_prompt]: Epoch 32 / 100: avg data time: 4.65e+00, avg batch time: 6.0903, average train loss: 0.7685
[11/27 22:21:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5841, average loss: 0.8899
[11/27 22:21:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.62	
[11/27 22:21:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/27 22:29:02 visual_prompt]: Epoch 33 / 100: avg data time: 4.62e+00, avg batch time: 6.0539, average train loss: 0.7532
[11/27 22:29:50 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5809, average loss: 0.6912
[11/27 22:29:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.70	
[11/27 22:29:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/27 22:36:53 visual_prompt]: Epoch 34 / 100: avg data time: 4.62e+00, avg batch time: 6.0470, average train loss: 0.8270
[11/27 22:37:42 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5769, average loss: 1.1602
[11/27 22:37:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.30	
[11/27 22:37:42 visual_prompt]: Stopping early.
[11/27 22:37:42 visual_prompt]: Rank of current process: 0. World size: 1
[11/27 22:37:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/27 22:37:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/27 22:37:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/27 22:37:42 visual_prompt]: Training with config:
[11/27 22:37:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/27 22:37:42 visual_prompt]: Loading training data...
[11/27 22:37:42 visual_prompt]: Constructing mammo-cbis dataset train...
[11/27 22:37:42 visual_prompt]: Loading validation data...
[11/27 22:37:42 visual_prompt]: Constructing mammo-cbis dataset val...
[11/27 22:37:42 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/27 22:37:44 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/27 22:37:44 visual_prompt]: tuned percent:0.532
[11/27 22:37:44 visual_prompt]: Device used for model: 0
[11/27 22:37:44 visual_prompt]: Setting up Evaluator...
[11/27 22:37:44 visual_prompt]: Setting up Trainer...
[11/27 22:37:44 visual_prompt]: 	Setting up the optimizer...
[11/27 22:37:44 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/27 22:44:49 visual_prompt]: Epoch 1 / 100: avg data time: 4.62e+00, avg batch time: 6.0614, average train loss: 1.4863
[11/27 22:45:37 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5805, average loss: 1.4553
[11/27 22:45:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/27 22:45:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/27 22:52:42 visual_prompt]: Epoch 2 / 100: avg data time: 4.63e+00, avg batch time: 6.0641, average train loss: 1.0889
[11/27 22:53:30 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5808, average loss: 0.7247
[11/27 22:53:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/27 22:53:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/27 23:00:36 visual_prompt]: Epoch 3 / 100: avg data time: 4.64e+00, avg batch time: 6.0779, average train loss: 0.7219
[11/27 23:01:25 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5784, average loss: 0.8414
[11/27 23:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.48	
[11/27 23:01:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/27 23:08:31 visual_prompt]: Epoch 4 / 100: avg data time: 4.66e+00, avg batch time: 6.0914, average train loss: 0.7836
[11/27 23:09:20 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5829, average loss: 0.8061
[11/27 23:09:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/27 23:09:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/27 23:16:27 visual_prompt]: Epoch 5 / 100: avg data time: 4.65e+00, avg batch time: 6.0888, average train loss: 0.8177
[11/27 23:17:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5810, average loss: 0.6885
[11/27 23:17:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/27 23:17:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/27 23:24:23 visual_prompt]: Epoch 6 / 100: avg data time: 4.67e+00, avg batch time: 6.1079, average train loss: 0.7580
[11/27 23:25:12 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5814, average loss: 0.6742
[11/27 23:25:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.82	
[11/27 23:25:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/27 23:32:18 visual_prompt]: Epoch 7 / 100: avg data time: 4.65e+00, avg batch time: 6.0861, average train loss: 0.7373
[11/27 23:33:07 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5815, average loss: 1.7252
[11/27 23:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.26	
[11/27 23:33:07 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/27 23:40:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.67e+00, avg batch time: 6.1077, average train loss: 0.7694
[11/27 23:41:04 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5777, average loss: 1.1083
[11/27 23:41:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.02	
[11/27 23:41:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/27 23:48:10 visual_prompt]: Epoch 9 / 100: avg data time: 4.66e+00, avg batch time: 6.0960, average train loss: 0.8029
[11/27 23:48:59 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5797, average loss: 0.6786
[11/27 23:48:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.02	
[11/27 23:48:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/27 23:56:06 visual_prompt]: Epoch 10 / 100: avg data time: 4.66e+00, avg batch time: 6.0926, average train loss: 0.7228
[11/27 23:56:55 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5775, average loss: 0.7685
[11/27 23:56:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[11/27 23:56:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/28 00:04:03 visual_prompt]: Epoch 11 / 100: avg data time: 4.68e+00, avg batch time: 6.1176, average train loss: 0.7622
[11/28 00:04:52 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5842, average loss: 0.7761
[11/28 00:04:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.23	
[11/28 00:04:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/28 00:12:18 visual_prompt]: Epoch 12 / 100: avg data time: 4.93e+00, avg batch time: 6.3686, average train loss: 0.7614
[11/28 00:13:09 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5803, average loss: 0.7236
[11/28 00:13:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.74	
[11/28 00:13:09 visual_prompt]: Best epoch 12: best metric: -0.724
[11/28 00:13:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/28 00:20:44 visual_prompt]: Epoch 13 / 100: avg data time: 5.06e+00, avg batch time: 6.4970, average train loss: 0.7759
[11/28 00:21:33 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5788, average loss: 0.7158
[11/28 00:21:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/28 00:21:33 visual_prompt]: Best epoch 13: best metric: -0.716
[11/28 00:21:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/28 00:28:52 visual_prompt]: Epoch 14 / 100: avg data time: 4.83e+00, avg batch time: 6.2658, average train loss: 0.7538
[11/28 00:29:44 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5791, average loss: 0.7155
[11/28 00:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/28 00:29:44 visual_prompt]: Best epoch 14: best metric: -0.716
[11/28 00:29:44 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/28 00:37:08 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3518, average train loss: 0.7450
[11/28 00:37:57 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5803, average loss: 0.7131
[11/28 00:37:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/28 00:37:57 visual_prompt]: Best epoch 15: best metric: -0.713
[11/28 00:37:57 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/28 00:45:05 visual_prompt]: Epoch 16 / 100: avg data time: 4.68e+00, avg batch time: 6.1117, average train loss: 0.7322
[11/28 00:45:54 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5801, average loss: 0.9053
[11/28 00:45:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/28 00:45:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/28 00:53:02 visual_prompt]: Epoch 17 / 100: avg data time: 4.68e+00, avg batch time: 6.1211, average train loss: 0.7835
[11/28 00:53:51 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5794, average loss: 0.8792
[11/28 00:53:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.69	
[11/28 00:53:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/28 01:01:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.68e+00, avg batch time: 6.1219, average train loss: 0.7829
[11/28 01:01:49 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5792, average loss: 0.8792
[11/28 01:01:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.64	
[11/28 01:01:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/28 01:08:57 visual_prompt]: Epoch 19 / 100: avg data time: 4.67e+00, avg batch time: 6.1118, average train loss: 0.7793
[11/28 01:09:46 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5814, average loss: 0.7425
[11/28 01:09:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/28 01:09:46 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/28 01:16:57 visual_prompt]: Epoch 20 / 100: avg data time: 4.71e+00, avg batch time: 6.1637, average train loss: 0.7126
[11/28 01:17:46 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5794, average loss: 0.6826
[11/28 01:17:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/28 01:17:46 visual_prompt]: Best epoch 20: best metric: -0.683
[11/28 01:17:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/28 01:24:57 visual_prompt]: Epoch 21 / 100: avg data time: 4.70e+00, avg batch time: 6.1576, average train loss: 0.7119
[11/28 01:25:46 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5815, average loss: 0.6854
[11/28 01:25:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.80	
[11/28 01:25:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/28 01:32:55 visual_prompt]: Epoch 22 / 100: avg data time: 4.68e+00, avg batch time: 6.1199, average train loss: 0.7526
[11/28 01:33:43 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5811, average loss: 0.9010
[11/28 01:33:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/28 01:33:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/28 01:40:57 visual_prompt]: Epoch 23 / 100: avg data time: 4.74e+00, avg batch time: 6.1904, average train loss: 0.8169
[11/28 01:41:46 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5820, average loss: 0.8924
[11/28 01:41:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/28 01:41:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/28 01:48:51 visual_prompt]: Epoch 24 / 100: avg data time: 4.62e+00, avg batch time: 6.0618, average train loss: 0.7557
[11/28 01:49:40 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5775, average loss: 0.6873
[11/28 01:49:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 62.08	
[11/28 01:49:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/28 01:56:45 visual_prompt]: Epoch 25 / 100: avg data time: 4.64e+00, avg batch time: 6.0743, average train loss: 0.7295
[11/28 01:57:34 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5779, average loss: 0.6772
[11/28 01:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.99	
[11/28 01:57:34 visual_prompt]: Best epoch 25: best metric: -0.677
[11/28 01:57:34 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/28 02:04:38 visual_prompt]: Epoch 26 / 100: avg data time: 4.62e+00, avg batch time: 6.0595, average train loss: 0.7363
[11/28 02:05:27 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5810, average loss: 0.7935
[11/28 02:05:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/28 02:05:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/28 02:12:31 visual_prompt]: Epoch 27 / 100: avg data time: 4.62e+00, avg batch time: 6.0615, average train loss: 0.7015
[11/28 02:13:20 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5797, average loss: 0.6977
[11/28 02:13:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 62.49	
[11/28 02:13:20 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/28 02:20:25 visual_prompt]: Epoch 28 / 100: avg data time: 4.63e+00, avg batch time: 6.0765, average train loss: 0.7252
[11/28 02:21:14 visual_prompt]: Inference (val):avg data time: 1.89e-04, avg batch time: 0.6015, average loss: 0.6889
[11/28 02:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/28 02:21:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/28 02:28:20 visual_prompt]: Epoch 29 / 100: avg data time: 4.64e+00, avg batch time: 6.0820, average train loss: 0.7129
[11/28 02:29:08 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5763, average loss: 0.7465
[11/28 02:29:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/28 02:29:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/28 02:36:14 visual_prompt]: Epoch 30 / 100: avg data time: 4.64e+00, avg batch time: 6.0849, average train loss: 0.7191
[11/28 02:37:03 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5821, average loss: 0.8272
[11/28 02:37:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.31	
[11/28 02:37:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/28 02:44:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.61e+00, avg batch time: 6.0439, average train loss: 0.7088
[11/28 02:44:54 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5801, average loss: 0.6902
[11/28 02:44:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.13	
[11/28 02:44:54 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/28 02:52:01 visual_prompt]: Epoch 32 / 100: avg data time: 4.66e+00, avg batch time: 6.1009, average train loss: 0.7403
[11/28 02:52:50 visual_prompt]: Inference (val):avg data time: 1.49e-04, avg batch time: 0.6145, average loss: 0.8600
[11/28 02:52:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/28 02:52:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/28 02:59:56 visual_prompt]: Epoch 33 / 100: avg data time: 4.64e+00, avg batch time: 6.0813, average train loss: 0.7203
[11/28 03:00:45 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5836, average loss: 0.6888
[11/28 03:00:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.78	
[11/28 03:00:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/28 03:07:51 visual_prompt]: Epoch 34 / 100: avg data time: 4.64e+00, avg batch time: 6.0816, average train loss: 0.7136
[11/28 03:08:39 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5776, average loss: 0.6986
[11/28 03:08:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.36	
[11/28 03:08:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/28 03:15:44 visual_prompt]: Epoch 35 / 100: avg data time: 4.63e+00, avg batch time: 6.0692, average train loss: 0.7147
[11/28 03:16:32 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5824, average loss: 0.7499
[11/28 03:16:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/28 03:16:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/28 03:23:38 visual_prompt]: Epoch 36 / 100: avg data time: 4.64e+00, avg batch time: 6.0750, average train loss: 0.7125
[11/28 03:24:26 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5801, average loss: 0.6890
[11/28 03:24:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.34	
[11/28 03:24:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/28 03:31:31 visual_prompt]: Epoch 37 / 100: avg data time: 4.63e+00, avg batch time: 6.0683, average train loss: 0.7257
[11/28 03:32:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5889, average loss: 0.7514
[11/28 03:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/28 03:32:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/28 03:39:25 visual_prompt]: Epoch 38 / 100: avg data time: 4.63e+00, avg batch time: 6.0667, average train loss: 0.7024
[11/28 03:40:13 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5838, average loss: 0.6758
[11/28 03:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.01	
[11/28 03:40:13 visual_prompt]: Best epoch 38: best metric: -0.676
[11/28 03:40:13 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/28 03:47:18 visual_prompt]: Epoch 39 / 100: avg data time: 4.63e+00, avg batch time: 6.0670, average train loss: 0.7164
[11/28 03:48:07 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5797, average loss: 0.7275
[11/28 03:48:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[11/28 03:48:07 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/28 03:55:12 visual_prompt]: Epoch 40 / 100: avg data time: 4.63e+00, avg batch time: 6.0803, average train loss: 0.7100
[11/28 03:56:01 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5790, average loss: 0.7220
[11/28 03:56:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/28 03:56:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/28 04:03:10 visual_prompt]: Epoch 41 / 100: avg data time: 4.67e+00, avg batch time: 6.1198, average train loss: 0.7213
[11/28 04:03:58 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5843, average loss: 0.8634
[11/28 04:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/28 04:03:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/28 04:11:04 visual_prompt]: Epoch 42 / 100: avg data time: 4.64e+00, avg batch time: 6.0745, average train loss: 0.7201
[11/28 04:11:52 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5777, average loss: 0.6875
[11/28 04:11:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/28 04:11:52 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/28 04:19:02 visual_prompt]: Epoch 43 / 100: avg data time: 4.70e+00, avg batch time: 6.1420, average train loss: 0.7456
[11/28 04:19:51 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5790, average loss: 0.7035
[11/28 04:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.30	
[11/28 04:19:51 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/28 04:26:58 visual_prompt]: Epoch 44 / 100: avg data time: 4.66e+00, avg batch time: 6.1004, average train loss: 0.7153
[11/28 04:27:47 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5788, average loss: 0.6854
[11/28 04:27:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.85	
[11/28 04:27:47 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/28 04:34:54 visual_prompt]: Epoch 45 / 100: avg data time: 4.66e+00, avg batch time: 6.1007, average train loss: 0.7200
[11/28 04:35:43 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5787, average loss: 0.6873
[11/28 04:35:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[11/28 04:35:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/28 04:42:47 visual_prompt]: Epoch 46 / 100: avg data time: 4.62e+00, avg batch time: 6.0562, average train loss: 0.7171
[11/28 04:43:35 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5788, average loss: 0.7302
[11/28 04:43:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.67	
[11/28 04:43:35 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/28 04:50:42 visual_prompt]: Epoch 47 / 100: avg data time: 4.65e+00, avg batch time: 6.0972, average train loss: 0.7280
[11/28 04:51:30 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5776, average loss: 0.7229
[11/28 04:51:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.61	
[11/28 04:51:30 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/28 04:58:36 visual_prompt]: Epoch 48 / 100: avg data time: 4.64e+00, avg batch time: 6.0849, average train loss: 0.7174
[11/28 04:59:25 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5785, average loss: 0.6994
[11/28 04:59:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/28 04:59:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/28 05:06:31 visual_prompt]: Epoch 49 / 100: avg data time: 4.64e+00, avg batch time: 6.0770, average train loss: 0.7036
[11/28 05:07:19 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5809, average loss: 0.6869
[11/28 05:07:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.10	
[11/28 05:07:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/28 05:14:26 visual_prompt]: Epoch 50 / 100: avg data time: 4.63e+00, avg batch time: 6.0946, average train loss: 0.7272
[11/28 05:15:15 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5791, average loss: 0.9267
[11/28 05:15:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/28 05:15:15 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/28 05:22:21 visual_prompt]: Epoch 51 / 100: avg data time: 4.64e+00, avg batch time: 6.0899, average train loss: 0.7200
[11/28 05:23:10 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5773, average loss: 0.7696
[11/28 05:23:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.26	
[11/28 05:23:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/28 05:30:15 visual_prompt]: Epoch 52 / 100: avg data time: 4.63e+00, avg batch time: 6.0742, average train loss: 0.7037
[11/28 05:31:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5810, average loss: 0.7411
[11/28 05:31:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.82	
[11/28 05:31:03 visual_prompt]: Stopping early.
[11/28 05:31:04 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 05:31:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 05:31:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/28 05:31:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 05:31:04 visual_prompt]: Training with config:
[11/28 05:31:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 05:31:04 visual_prompt]: Loading training data...
[11/28 05:31:04 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 05:31:04 visual_prompt]: Loading validation data...
[11/28 05:31:04 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 05:31:04 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/28 05:31:06 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/28 05:31:06 visual_prompt]: tuned percent:0.532
[11/28 05:31:06 visual_prompt]: Device used for model: 0
[11/28 05:31:06 visual_prompt]: Setting up Evaluator...
[11/28 05:31:06 visual_prompt]: Setting up Trainer...
[11/28 05:31:06 visual_prompt]: 	Setting up the optimizer...
[11/28 05:31:06 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 05:38:14 visual_prompt]: Epoch 1 / 100: avg data time: 4.66e+00, avg batch time: 6.1011, average train loss: 1.4863
[11/28 05:39:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5783, average loss: 1.4553
[11/28 05:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/28 05:39:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/28 05:46:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.63e+00, avg batch time: 6.0665, average train loss: 1.0902
[11/28 05:46:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5804, average loss: 0.7249
[11/28 05:46:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/28 05:46:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/28 05:54:01 visual_prompt]: Epoch 3 / 100: avg data time: 4.64e+00, avg batch time: 6.0740, average train loss: 0.7235
[11/28 05:54:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5787, average loss: 0.8395
[11/28 05:54:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.53	
[11/28 05:54:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/28 06:01:57 visual_prompt]: Epoch 4 / 100: avg data time: 4.67e+00, avg batch time: 6.1084, average train loss: 0.7893
[11/28 06:02:47 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5818, average loss: 0.8533
[11/28 06:02:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.83	
[11/28 06:02:47 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/28 06:09:55 visual_prompt]: Epoch 5 / 100: avg data time: 4.68e+00, avg batch time: 6.1211, average train loss: 0.8105
[11/28 06:10:44 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5826, average loss: 0.7082
[11/28 06:10:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/28 06:10:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/28 06:17:55 visual_prompt]: Epoch 6 / 100: avg data time: 4.71e+00, avg batch time: 6.1519, average train loss: 0.7664
[11/28 06:18:44 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5865, average loss: 0.6719
[11/28 06:18:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/28 06:18:44 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/28 06:25:51 visual_prompt]: Epoch 7 / 100: avg data time: 4.67e+00, avg batch time: 6.1059, average train loss: 0.7331
[11/28 06:26:41 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5797, average loss: 1.1880
[11/28 06:26:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.68	
[11/28 06:26:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/28 06:33:49 visual_prompt]: Epoch 8 / 100: avg data time: 4.69e+00, avg batch time: 6.1245, average train loss: 0.7783
[11/28 06:34:38 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5789, average loss: 1.4210
[11/28 06:34:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.70	
[11/28 06:34:38 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/28 06:41:46 visual_prompt]: Epoch 9 / 100: avg data time: 4.66e+00, avg batch time: 6.1064, average train loss: 0.8966
[11/28 06:42:35 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5817, average loss: 0.6636
[11/28 06:42:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.04	
[11/28 06:42:35 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/28 06:49:39 visual_prompt]: Epoch 10 / 100: avg data time: 4.62e+00, avg batch time: 6.0616, average train loss: 0.7290
[11/28 06:50:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5832, average loss: 0.8045
[11/28 06:50:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.91	
[11/28 06:50:27 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/28 06:57:36 visual_prompt]: Epoch 11 / 100: avg data time: 4.66e+00, avg batch time: 6.1215, average train loss: 0.7937
[11/28 06:58:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5843, average loss: 1.1487
[11/28 06:58:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.00	
[11/28 06:58:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/28 07:05:31 visual_prompt]: Epoch 12 / 100: avg data time: 4.64e+00, avg batch time: 6.0860, average train loss: 0.7618
[11/28 07:06:20 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5812, average loss: 0.6465
[11/28 07:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.15	
[11/28 07:06:20 visual_prompt]: Best epoch 12: best metric: -0.647
[11/28 07:06:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/28 07:13:27 visual_prompt]: Epoch 13 / 100: avg data time: 4.66e+00, avg batch time: 6.0990, average train loss: 0.7177
[11/28 07:14:15 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5767, average loss: 0.7420
[11/28 07:14:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.91	
[11/28 07:14:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/28 07:21:21 visual_prompt]: Epoch 14 / 100: avg data time: 4.63e+00, avg batch time: 6.0751, average train loss: 0.6855
[11/28 07:22:09 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5802, average loss: 0.7182
[11/28 07:22:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.02	
[11/28 07:22:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/28 07:29:13 visual_prompt]: Epoch 15 / 100: avg data time: 4.62e+00, avg batch time: 6.0581, average train loss: 0.7269
[11/28 07:30:02 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5843, average loss: 0.6450
[11/28 07:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/28 07:30:02 visual_prompt]: Best epoch 15: best metric: -0.645
[11/28 07:30:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/28 07:37:06 visual_prompt]: Epoch 16 / 100: avg data time: 4.62e+00, avg batch time: 6.0585, average train loss: 0.7688
[11/28 07:37:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5844, average loss: 0.7389
[11/28 07:37:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 65.84	
[11/28 07:37:55 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/28 07:45:02 visual_prompt]: Epoch 17 / 100: avg data time: 4.65e+00, avg batch time: 6.0978, average train loss: 0.7174
[11/28 07:45:51 visual_prompt]: Inference (val):avg data time: 3.87e-05, avg batch time: 0.5797, average loss: 0.8170
[11/28 07:45:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.48	
[11/28 07:45:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/28 07:53:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.69e+00, avg batch time: 6.1275, average train loss: 0.7280
[11/28 07:53:49 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5810, average loss: 1.0515
[11/28 07:53:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.65	
[11/28 07:53:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/28 08:00:55 visual_prompt]: Epoch 19 / 100: avg data time: 4.64e+00, avg batch time: 6.0802, average train loss: 0.7665
[11/28 08:01:44 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5769, average loss: 0.7208
[11/28 08:01:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.37	
[11/28 08:01:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/28 08:08:49 visual_prompt]: Epoch 20 / 100: avg data time: 4.64e+00, avg batch time: 6.0738, average train loss: 0.6482
[11/28 08:09:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5841, average loss: 0.6210
[11/28 08:09:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.19	
[11/28 08:09:37 visual_prompt]: Best epoch 20: best metric: -0.621
[11/28 08:09:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/28 08:16:43 visual_prompt]: Epoch 21 / 100: avg data time: 4.63e+00, avg batch time: 6.0713, average train loss: 0.6475
[11/28 08:17:31 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5811, average loss: 0.9763
[11/28 08:17:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 73.13	
[11/28 08:17:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/28 08:24:39 visual_prompt]: Epoch 22 / 100: avg data time: 4.66e+00, avg batch time: 6.1070, average train loss: 0.6757
[11/28 08:25:27 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5774, average loss: 0.8792
[11/28 08:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 73.96	
[11/28 08:25:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/28 08:32:34 visual_prompt]: Epoch 23 / 100: avg data time: 4.65e+00, avg batch time: 6.0912, average train loss: 0.6603
[11/28 08:33:22 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5789, average loss: 1.1808
[11/28 08:33:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.05	
[11/28 08:33:22 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/28 08:40:27 visual_prompt]: Epoch 24 / 100: avg data time: 4.63e+00, avg batch time: 6.0684, average train loss: 0.6834
[11/28 08:41:16 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5779, average loss: 0.6618
[11/28 08:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.24	
[11/28 08:41:16 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/28 08:48:22 visual_prompt]: Epoch 25 / 100: avg data time: 4.65e+00, avg batch time: 6.0894, average train loss: 0.6908
[11/28 08:49:11 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5810, average loss: 0.7300
[11/28 08:49:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 74.09	
[11/28 08:49:11 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/28 08:56:19 visual_prompt]: Epoch 26 / 100: avg data time: 4.67e+00, avg batch time: 6.1131, average train loss: 0.6515
[11/28 08:57:08 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5815, average loss: 0.6007
[11/28 08:57:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 73.94	
[11/28 08:57:08 visual_prompt]: Best epoch 26: best metric: -0.601
[11/28 08:57:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/28 09:04:15 visual_prompt]: Epoch 27 / 100: avg data time: 4.66e+00, avg batch time: 6.0997, average train loss: 0.6220
[11/28 09:05:04 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5785, average loss: 0.6727
[11/28 09:05:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 76.09	
[11/28 09:05:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/28 09:12:11 visual_prompt]: Epoch 28 / 100: avg data time: 4.65e+00, avg batch time: 6.0956, average train loss: 0.6932
[11/28 09:12:59 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5819, average loss: 0.7420
[11/28 09:12:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 75.80	
[11/28 09:12:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/28 09:20:04 visual_prompt]: Epoch 29 / 100: avg data time: 4.63e+00, avg batch time: 6.0703, average train loss: 0.6056
[11/28 09:20:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5799, average loss: 0.6275
[11/28 09:20:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 75.67	
[11/28 09:20:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/28 09:27:59 visual_prompt]: Epoch 30 / 100: avg data time: 4.65e+00, avg batch time: 6.0834, average train loss: 0.5842
[11/28 09:28:48 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5822, average loss: 1.5055
[11/28 09:28:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 72.48	
[11/28 09:28:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/28 09:35:55 visual_prompt]: Epoch 31 / 100: avg data time: 4.65e+00, avg batch time: 6.0945, average train loss: 0.6911
[11/28 09:36:44 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5809, average loss: 0.6117
[11/28 09:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.46	
[11/28 09:36:44 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/28 09:43:54 visual_prompt]: Epoch 32 / 100: avg data time: 4.71e+00, avg batch time: 6.1467, average train loss: 0.6841
[11/28 09:44:43 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5794, average loss: 1.1420
[11/28 09:44:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.26	
[11/28 09:44:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/28 09:51:54 visual_prompt]: Epoch 33 / 100: avg data time: 4.71e+00, avg batch time: 6.1587, average train loss: 0.6362
[11/28 09:52:43 visual_prompt]: Inference (val):avg data time: 2.34e-04, avg batch time: 0.5975, average loss: 0.6317
[11/28 09:52:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.48	
[11/28 09:52:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/28 09:59:52 visual_prompt]: Epoch 34 / 100: avg data time: 4.68e+00, avg batch time: 6.1161, average train loss: 0.6442
[11/28 10:00:41 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5812, average loss: 0.6702
[11/28 10:00:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.03	
[11/28 10:00:41 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/28 10:07:50 visual_prompt]: Epoch 35 / 100: avg data time: 4.69e+00, avg batch time: 6.1254, average train loss: 0.5889
[11/28 10:08:38 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5773, average loss: 0.6170
[11/28 10:08:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 74.47	
[11/28 10:08:38 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/28 10:15:48 visual_prompt]: Epoch 36 / 100: avg data time: 4.70e+00, avg batch time: 6.1386, average train loss: 0.5843
[11/28 10:16:37 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5794, average loss: 1.2020
[11/28 10:16:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 74.43	
[11/28 10:16:37 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/28 10:23:43 visual_prompt]: Epoch 37 / 100: avg data time: 4.65e+00, avg batch time: 6.0822, average train loss: 0.6478
[11/28 10:24:31 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5769, average loss: 0.7317
[11/28 10:24:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.28	
[11/28 10:24:31 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/28 10:31:37 visual_prompt]: Epoch 38 / 100: avg data time: 4.63e+00, avg batch time: 6.0712, average train loss: 0.5724
[11/28 10:32:26 visual_prompt]: Inference (val):avg data time: 3.66e-04, avg batch time: 0.6073, average loss: 0.6365
[11/28 10:32:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.94	
[11/28 10:32:26 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/28 10:39:32 visual_prompt]: Epoch 39 / 100: avg data time: 4.64e+00, avg batch time: 6.0835, average train loss: 0.5634
[11/28 10:40:20 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5807, average loss: 0.7090
[11/28 10:40:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.80	
[11/28 10:40:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/28 10:47:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.64e+00, avg batch time: 6.0695, average train loss: 0.6224
[11/28 10:48:14 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5807, average loss: 0.9828
[11/28 10:48:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 73.65	
[11/28 10:48:14 visual_prompt]: Stopping early.
[11/28 10:48:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/28 10:48:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/28 10:48:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/28 10:48:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/28 10:48:14 visual_prompt]: Training with config:
[11/28 10:48:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/28 10:48:14 visual_prompt]: Loading training data...
[11/28 10:48:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/28 10:48:14 visual_prompt]: Loading validation data...
[11/28 10:48:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/28 10:48:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/28 10:48:17 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/28 10:48:17 visual_prompt]: tuned percent:0.532
[11/28 10:48:17 visual_prompt]: Device used for model: 0
[11/28 10:48:17 visual_prompt]: Setting up Evaluator...
[11/28 10:48:17 visual_prompt]: Setting up Trainer...
[11/28 10:48:17 visual_prompt]: 	Setting up the optimizer...
[11/28 10:48:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/28 10:55:25 visual_prompt]: Epoch 1 / 100: avg data time: 4.67e+00, avg batch time: 6.1189, average train loss: 1.4863
[11/28 10:56:14 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5781, average loss: 1.4553
[11/28 10:56:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/28 10:56:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/28 11:03:20 visual_prompt]: Epoch 2 / 100: avg data time: 4.65e+00, avg batch time: 6.0843, average train loss: 1.0903
[11/28 11:04:09 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5771, average loss: 0.7250
[11/28 11:04:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[11/28 11:04:09 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/28 11:11:20 visual_prompt]: Epoch 3 / 100: avg data time: 4.71e+00, avg batch time: 6.1521, average train loss: 0.7237
[11/28 11:12:09 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5782, average loss: 0.8399
[11/28 11:12:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/28 11:12:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/28 11:19:20 visual_prompt]: Epoch 4 / 100: avg data time: 4.71e+00, avg batch time: 6.1551, average train loss: 0.7933
[11/28 11:20:09 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5812, average loss: 0.8096
[11/28 11:20:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/28 11:20:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/28 11:27:18 visual_prompt]: Epoch 5 / 100: avg data time: 4.68e+00, avg batch time: 6.1310, average train loss: 0.8336
[11/28 11:28:08 visual_prompt]: Inference (val):avg data time: 2.47e-04, avg batch time: 0.6720, average loss: 0.6890
[11/28 11:28:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.67	
[11/28 11:28:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/28 11:35:20 visual_prompt]: Epoch 6 / 100: avg data time: 4.71e+00, avg batch time: 6.1590, average train loss: 0.7535
[11/28 11:36:11 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5769, average loss: 0.6721
[11/28 11:36:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.13	
[11/28 11:36:11 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/28 11:43:17 visual_prompt]: Epoch 7 / 100: avg data time: 4.64e+00, avg batch time: 6.0824, average train loss: 0.7298
[11/28 11:44:05 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5811, average loss: 1.6587
[11/28 11:44:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[11/28 11:44:05 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/28 11:51:09 visual_prompt]: Epoch 8 / 100: avg data time: 4.62e+00, avg batch time: 6.0565, average train loss: 0.7889
[11/28 11:51:58 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5772, average loss: 1.3869
[11/28 11:51:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.23	
[11/28 11:51:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/28 11:59:08 visual_prompt]: Epoch 9 / 100: avg data time: 4.70e+00, avg batch time: 6.1449, average train loss: 0.9032
[11/28 11:59:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5794, average loss: 0.6673
[11/28 11:59:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.27	
[11/28 11:59:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/28 12:07:25 visual_prompt]: Epoch 10 / 100: avg data time: 4.93e+00, avg batch time: 6.3707, average train loss: 0.7352
[11/28 12:08:18 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5818, average loss: 0.8182
[11/28 12:08:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/28 12:08:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/28 12:16:04 visual_prompt]: Epoch 11 / 100: avg data time: 5.22e+00, avg batch time: 6.6600, average train loss: 0.7594
[11/28 12:16:57 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5832, average loss: 1.1425
[11/28 12:16:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.76	
[11/28 12:16:57 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/28 12:24:41 visual_prompt]: Epoch 12 / 100: avg data time: 5.19e+00, avg batch time: 6.6286, average train loss: 0.7588
[11/28 12:25:34 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5828, average loss: 0.6451
[11/28 12:25:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.14	
[11/28 12:25:34 visual_prompt]: Best epoch 12: best metric: -0.645
[11/28 12:25:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/28 12:33:19 visual_prompt]: Epoch 13 / 100: avg data time: 5.21e+00, avg batch time: 6.6480, average train loss: 0.7121
[11/28 12:34:12 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5808, average loss: 0.7472
[11/28 12:34:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/28 12:34:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/28 12:41:58 visual_prompt]: Epoch 14 / 100: avg data time: 5.21e+00, avg batch time: 6.6453, average train loss: 0.6895
[11/28 12:42:51 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5848, average loss: 0.7282
[11/28 12:42:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.06	
[11/28 12:42:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/28 12:50:34 visual_prompt]: Epoch 15 / 100: avg data time: 5.17e+00, avg batch time: 6.6084, average train loss: 0.7205
[11/28 12:51:27 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5794, average loss: 0.8441
[11/28 12:51:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[11/28 12:51:27 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
