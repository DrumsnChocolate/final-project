/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 22:38:25 visual_prompt]: Rank of current process: 0. World size: 1
[09/27 22:38:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/27 22:38:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 22:38:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/27 22:38:27 visual_prompt]: Training with config:
[09/27 22:38:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dtd/sup_vitb16_imagenet21k/prompt50/crop224/test/seed2845/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 2845, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dtd', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 47, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/27 22:38:27 visual_prompt]: Loading training data...
2023-09-27 22:38:29.178918: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-27 22:38:30.968643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-27 22:38:46.510475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/27 22:39:13 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 22:39:18 visual_prompt]: Number of images: 1000
[09/27 22:39:18 visual_prompt]: Number of classes: 47 / 47
[09/27 22:39:18 visual_prompt]: Loading validation data...
[09/27 22:39:18 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 22:39:18 visual_prompt]: Number of images: 200
[09/27 22:39:18 visual_prompt]: Number of classes: 47 / 47
[09/27 22:39:18 visual_prompt]: Loading test data...
[09/27 22:39:18 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 22:39:23 visual_prompt]: Number of images: 1880
[09/27 22:39:23 visual_prompt]: Number of classes: 47 / 47
[09/27 22:39:23 visual_prompt]: Constructing models...
[09/27 22:39:26 visual_prompt]: Total Parameters: 86295599	 Gradient Parameters: 496943
[09/27 22:39:26 visual_prompt]: tuned percent:0.576
[09/27 22:39:28 visual_prompt]: Device used for model: 0
[09/27 22:39:28 visual_prompt]: Setting up Evaluator...
[09/27 22:39:28 visual_prompt]: Setting up Trainer...
[09/27 22:39:28 visual_prompt]: 	Setting up the optimizer...
[09/27 22:39:28 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/27 22:39:58 visual_prompt]: Epoch 1 / 100: avg data time: 1.95e-01, avg batch time: 1.8473, average train loss: 3.9456
[09/27 22:39:59 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1827, average loss: 3.9491
[09/27 22:39:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 13.50	
[09/27 22:40:06 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2098, average loss: 3.9465
[09/27 22:40:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.53	
[09/27 22:40:06 visual_prompt]: Best epoch 1: best metric: 0.015
[09/27 22:40:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/27 22:40:14 visual_prompt]: Epoch 2 / 100: avg data time: 3.51e-02, avg batch time: 0.4815, average train loss: 3.9562
[09/27 22:40:16 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1657, average loss: 3.8322
[09/27 22:40:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 15.50	
[09/27 22:40:23 visual_prompt]: Inference (test):avg data time: 2.90e-05, avg batch time: 0.2096, average loss: 3.8990
[09/27 22:40:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.39	
[09/27 22:40:23 visual_prompt]: Best epoch 2: best metric: 0.040
[09/27 22:40:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/27 22:40:31 visual_prompt]: Epoch 3 / 100: avg data time: 4.07e-02, avg batch time: 0.4894, average train loss: 3.9298
[09/27 22:40:32 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1667, average loss: 3.8534
[09/27 22:40:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 17.00	
[09/27 22:40:39 visual_prompt]: Inference (test):avg data time: 1.01e-04, avg batch time: 0.2099, average loss: 3.9090
[09/27 22:40:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.34	top5: 13.19	
[09/27 22:40:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/27 22:40:48 visual_prompt]: Epoch 4 / 100: avg data time: 4.48e-02, avg batch time: 0.4937, average train loss: 3.8988
[09/27 22:40:49 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1672, average loss: 4.3015
[09/27 22:40:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.00	
[09/27 22:40:56 visual_prompt]: Inference (test):avg data time: 1.73e-04, avg batch time: 0.2102, average loss: 4.3113
[09/27 22:40:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:40:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/27 22:41:04 visual_prompt]: Epoch 5 / 100: avg data time: 3.48e-02, avg batch time: 0.4862, average train loss: 4.0858
[09/27 22:41:06 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1684, average loss: 3.9468
[09/27 22:41:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 13.00	
[09/27 22:41:13 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2129, average loss: 3.9918
[09/27 22:41:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.26	top5: 12.50	
[09/27 22:41:13 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/27 22:41:21 visual_prompt]: Epoch 6 / 100: avg data time: 4.11e-02, avg batch time: 0.4938, average train loss: 4.0003
[09/27 22:41:23 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1684, average loss: 4.1477
[09/27 22:41:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 18.00	
[09/27 22:41:30 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.2128, average loss: 4.3714
[09/27 22:41:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.29	
[09/27 22:41:30 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/27 22:41:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.40e-02, avg batch time: 0.4982, average train loss: 4.3134
[09/27 22:41:40 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1687, average loss: 4.3897
[09/27 22:41:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 14.50	
[09/27 22:41:47 visual_prompt]: Inference (test):avg data time: 2.61e-05, avg batch time: 0.2127, average loss: 4.4745
[09/27 22:41:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.34	top5: 12.82	
[09/27 22:41:47 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/27 22:41:55 visual_prompt]: Epoch 8 / 100: avg data time: 4.42e-02, avg batch time: 0.4976, average train loss: 4.0996
[09/27 22:41:57 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1688, average loss: 4.1112
[09/27 22:41:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 17.50	
[09/27 22:42:04 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2127, average loss: 4.2145
[09/27 22:42:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.35	top5: 14.68	
[09/27 22:42:04 visual_prompt]: Best epoch 8: best metric: 0.045
[09/27 22:42:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/27 22:42:12 visual_prompt]: Epoch 9 / 100: avg data time: 3.42e-02, avg batch time: 0.4897, average train loss: 4.0594
[09/27 22:42:13 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1696, average loss: 3.9775
[09/27 22:42:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 29.00	
[09/27 22:42:21 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2136, average loss: 4.0605
[09/27 22:42:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.30	top5: 22.55	
[09/27 22:42:21 visual_prompt]: Best epoch 9: best metric: 0.060
[09/27 22:42:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/27 22:42:29 visual_prompt]: Epoch 10 / 100: avg data time: 4.82e-02, avg batch time: 0.5033, average train loss: 4.2522
[09/27 22:42:30 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1689, average loss: 4.9623
[09/27 22:42:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/27 22:42:38 visual_prompt]: Inference (test):avg data time: 4.05e-05, avg batch time: 0.2135, average loss: 5.0122
[09/27 22:42:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:42:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/27 22:42:46 visual_prompt]: Epoch 11 / 100: avg data time: 4.08e-02, avg batch time: 0.4962, average train loss: 5.0992
[09/27 22:42:47 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1694, average loss: 4.6681
[09/27 22:42:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 15.50	
[09/27 22:42:55 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2140, average loss: 4.7419
[09/27 22:42:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.96	
[09/27 22:42:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/27 22:43:03 visual_prompt]: Epoch 12 / 100: avg data time: 4.04e-02, avg batch time: 0.4965, average train loss: 4.7032
[09/27 22:43:04 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1695, average loss: 4.3362
[09/27 22:43:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.50	
[09/27 22:43:11 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2135, average loss: 4.4934
[09/27 22:43:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.77	top5: 10.64	
[09/27 22:43:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/27 22:43:20 visual_prompt]: Epoch 13 / 100: avg data time: 4.24e-02, avg batch time: 0.4981, average train loss: 4.2497
[09/27 22:43:21 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1690, average loss: 4.1468
[09/27 22:43:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/27 22:43:29 visual_prompt]: Inference (test):avg data time: 1.61e-04, avg batch time: 0.2136, average loss: 4.1492
[09/27 22:43:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.03	top5: 11.12	
[09/27 22:43:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/27 22:43:37 visual_prompt]: Epoch 14 / 100: avg data time: 3.26e-02, avg batch time: 0.4917, average train loss: 4.1916
[09/27 22:43:38 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1696, average loss: 4.4057
[09/27 22:43:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 11.50	
[09/27 22:43:46 visual_prompt]: Inference (test):avg data time: 2.82e-05, avg batch time: 0.2137, average loss: 4.4503
[09/27 22:43:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:43:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/27 22:43:54 visual_prompt]: Epoch 15 / 100: avg data time: 4.11e-02, avg batch time: 0.4977, average train loss: 4.4013
[09/27 22:43:55 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1692, average loss: 4.3193
[09/27 22:43:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 15.50	
[09/27 22:44:03 visual_prompt]: Inference (test):avg data time: 3.24e-04, avg batch time: 0.2133, average loss: 4.4993
[09/27 22:44:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 10.64	
[09/27 22:44:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/27 22:44:11 visual_prompt]: Epoch 16 / 100: avg data time: 4.58e-02, avg batch time: 0.5020, average train loss: 4.5294
[09/27 22:44:12 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1701, average loss: 4.2846
[09/27 22:44:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.00	
[09/27 22:44:20 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2131, average loss: 4.3731
[09/27 22:44:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.28	
[09/27 22:44:20 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/27 22:44:28 visual_prompt]: Epoch 17 / 100: avg data time: 4.63e-02, avg batch time: 0.5027, average train loss: 4.1445
[09/27 22:44:29 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1698, average loss: 4.0936
[09/27 22:44:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 11.00	
[09/27 22:44:37 visual_prompt]: Inference (test):avg data time: 2.84e-05, avg batch time: 0.2139, average loss: 4.1325
[09/27 22:44:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/27 22:44:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/27 22:44:45 visual_prompt]: Epoch 18 / 100: avg data time: 4.09e-02, avg batch time: 0.4973, average train loss: 4.2167
[09/27 22:44:46 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1693, average loss: 4.2589
[09/27 22:44:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 9.00	
[09/27 22:44:54 visual_prompt]: Inference (test):avg data time: 5.16e-04, avg batch time: 0.2138, average loss: 4.2204
[09/27 22:44:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.37	
[09/27 22:44:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/27 22:45:02 visual_prompt]: Epoch 19 / 100: avg data time: 4.21e-02, avg batch time: 0.4982, average train loss: 4.3398
[09/27 22:45:04 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1698, average loss: 4.9379
[09/27 22:45:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.00	
[09/27 22:45:11 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2142, average loss: 4.5760
[09/27 22:45:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/27 22:45:11 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/27 22:45:19 visual_prompt]: Epoch 20 / 100: avg data time: 4.68e-02, avg batch time: 0.5033, average train loss: 4.5929
[09/27 22:45:21 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1696, average loss: 4.4953
[09/27 22:45:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.00	
[09/27 22:45:28 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2144, average loss: 4.5372
[09/27 22:45:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:45:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/27 22:45:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.42e-02, avg batch time: 0.5003, average train loss: 4.3774
[09/27 22:45:38 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1697, average loss: 4.0141
[09/27 22:45:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 8.50	
[09/27 22:45:45 visual_prompt]: Inference (test):avg data time: 2.76e-05, avg batch time: 0.2141, average loss: 4.0776
[09/27 22:45:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.29	top5: 10.32	
[09/27 22:45:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/27 22:45:53 visual_prompt]: Epoch 22 / 100: avg data time: 3.63e-02, avg batch time: 0.4921, average train loss: 4.2342
[09/27 22:45:55 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1697, average loss: 4.3195
[09/27 22:45:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/27 22:46:02 visual_prompt]: Inference (test):avg data time: 2.65e-04, avg batch time: 0.2150, average loss: 4.3378
[09/27 22:46:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.45	top5: 11.06	
[09/27 22:46:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/27 22:46:10 visual_prompt]: Epoch 23 / 100: avg data time: 4.26e-02, avg batch time: 0.4996, average train loss: 4.2952
[09/27 22:46:12 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1693, average loss: 4.1011
[09/27 22:46:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 11.00	
[09/27 22:46:19 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2148, average loss: 4.1240
[09/27 22:46:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:46:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/27 22:46:27 visual_prompt]: Epoch 24 / 100: avg data time: 4.34e-02, avg batch time: 0.4995, average train loss: 4.1561
[09/27 22:46:29 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1699, average loss: 4.0315
[09/27 22:46:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.00	
[09/27 22:46:36 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2138, average loss: 4.1420
[09/27 22:46:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.74	
[09/27 22:46:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/27 22:46:44 visual_prompt]: Epoch 25 / 100: avg data time: 3.26e-02, avg batch time: 0.4928, average train loss: 4.0669
[09/27 22:46:46 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1696, average loss: 4.2243
[09/27 22:46:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 10.50	
[09/27 22:46:53 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2145, average loss: 4.1491
[09/27 22:46:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.93	
[09/27 22:46:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/27 22:47:01 visual_prompt]: Epoch 26 / 100: avg data time: 3.98e-02, avg batch time: 0.4966, average train loss: 4.1291
[09/27 22:47:03 visual_prompt]: Inference (val):avg data time: 1.86e-05, avg batch time: 0.1693, average loss: 4.0080
[09/27 22:47:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 13.00	
[09/27 22:47:10 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2141, average loss: 4.0819
[09/27 22:47:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.12	
[09/27 22:47:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/27 22:47:18 visual_prompt]: Epoch 27 / 100: avg data time: 4.76e-02, avg batch time: 0.5038, average train loss: 4.1319
[09/27 22:47:20 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1700, average loss: 4.0821
[09/27 22:47:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 10.00	
[09/27 22:47:27 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2136, average loss: 4.1625
[09/27 22:47:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:47:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/27 22:47:35 visual_prompt]: Epoch 28 / 100: avg data time: 4.01e-02, avg batch time: 0.4974, average train loss: 4.0485
[09/27 22:47:37 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1700, average loss: 4.1791
[09/27 22:47:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.50	
[09/27 22:47:44 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2135, average loss: 4.1595
[09/27 22:47:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:47:44 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/27 22:47:52 visual_prompt]: Epoch 29 / 100: avg data time: 3.58e-02, avg batch time: 0.4931, average train loss: 4.0348
[09/27 22:47:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1700, average loss: 4.0231
[09/27 22:47:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 15.00	
[09/27 22:48:01 visual_prompt]: Inference (test):avg data time: 2.82e-05, avg batch time: 0.2160, average loss: 4.0419
[09/27 22:48:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.39	top5: 11.44	
[09/27 22:48:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/27 22:48:09 visual_prompt]: Epoch 30 / 100: avg data time: 4.11e-02, avg batch time: 0.4975, average train loss: 4.0794
[09/27 22:48:11 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.1702, average loss: 4.1595
[09/27 22:48:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.00	
[09/27 22:48:18 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2145, average loss: 4.1527
[09/27 22:48:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 13.14	
[09/27 22:48:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/27 22:48:26 visual_prompt]: Epoch 31 / 100: avg data time: 3.91e-02, avg batch time: 0.4956, average train loss: 4.0060
[09/27 22:48:27 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1703, average loss: 4.2022
[09/27 22:48:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 15.50	
[09/27 22:48:35 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2151, average loss: 4.2093
[09/27 22:48:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.29	top5: 11.76	
[09/27 22:48:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/27 22:48:43 visual_prompt]: Epoch 32 / 100: avg data time: 3.79e-02, avg batch time: 0.4958, average train loss: 4.2200
[09/27 22:48:45 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1700, average loss: 4.2469
[09/27 22:48:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/27 22:48:52 visual_prompt]: Inference (test):avg data time: 2.85e-05, avg batch time: 0.2142, average loss: 4.2281
[09/27 22:48:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.53	
[09/27 22:48:52 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/27 22:49:00 visual_prompt]: Epoch 33 / 100: avg data time: 3.57e-02, avg batch time: 0.4943, average train loss: 4.1427
[09/27 22:49:02 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1704, average loss: 4.0182
[09/27 22:49:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 12.50	
[09/27 22:49:09 visual_prompt]: Inference (test):avg data time: 1.13e-04, avg batch time: 0.2139, average loss: 4.0875
[09/27 22:49:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:49:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/27 22:49:17 visual_prompt]: Epoch 34 / 100: avg data time: 4.28e-02, avg batch time: 0.4997, average train loss: 4.0912
[09/27 22:49:19 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1702, average loss: 4.0852
[09/27 22:49:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.50	
[09/27 22:49:26 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2147, average loss: 4.1088
[09/27 22:49:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.59	
[09/27 22:49:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/27 22:49:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.46e-02, avg batch time: 0.5011, average train loss: 4.0250
[09/27 22:49:36 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1695, average loss: 4.1871
[09/27 22:49:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.00	
[09/27 22:49:43 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2135, average loss: 4.2751
[09/27 22:49:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 22:49:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/27 22:49:51 visual_prompt]: Epoch 36 / 100: avg data time: 3.65e-02, avg batch time: 0.4943, average train loss: 4.0783
[09/27 22:49:53 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1702, average loss: 3.9653
[09/27 22:49:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/27 22:50:00 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2134, average loss: 4.0400
[09/27 22:50:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.45	top5: 10.64	
[09/27 22:50:00 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/27 22:50:08 visual_prompt]: Epoch 37 / 100: avg data time: 4.59e-02, avg batch time: 0.5019, average train loss: 4.0338
[09/27 22:50:10 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1697, average loss: 4.0553
[09/27 22:50:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.00	
[09/27 22:50:17 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2135, average loss: 4.0691
[09/27 22:50:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.91	top5: 10.64	
[09/27 22:50:17 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/27 22:50:26 visual_prompt]: Epoch 38 / 100: avg data time: 4.05e-02, avg batch time: 0.4970, average train loss: 4.0943
[09/27 22:50:27 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1702, average loss: 4.3181
[09/27 22:50:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.00	
[09/27 22:50:34 visual_prompt]: Inference (test):avg data time: 1.64e-04, avg batch time: 0.2142, average loss: 4.2617
[09/27 22:50:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.49	top5: 12.18	
[09/27 22:50:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/27 22:50:43 visual_prompt]: Epoch 39 / 100: avg data time: 4.18e-02, avg batch time: 0.5006, average train loss: 4.0854
[09/27 22:50:44 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1699, average loss: 4.1659
[09/27 22:50:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.50	
[09/27 22:50:51 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2144, average loss: 4.0945
[09/27 22:50:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.35	top5: 11.01	
[09/27 22:50:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/27 22:51:00 visual_prompt]: Epoch 40 / 100: avg data time: 3.98e-02, avg batch time: 0.4978, average train loss: 4.1104
[09/27 22:51:01 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1702, average loss: 4.0769
[09/27 22:51:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 14.00	
[09/27 22:51:09 visual_prompt]: Inference (test):avg data time: 2.83e-05, avg batch time: 0.2152, average loss: 4.1502
[09/27 22:51:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.66	top5: 12.13	
[09/27 22:51:09 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/27 22:51:17 visual_prompt]: Epoch 41 / 100: avg data time: 4.15e-02, avg batch time: 0.4978, average train loss: 4.0069
[09/27 22:51:18 visual_prompt]: Inference (val):avg data time: 1.67e-05, avg batch time: 0.1699, average loss: 4.7599
[09/27 22:51:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/27 22:51:25 visual_prompt]: Inference (test):avg data time: 2.81e-05, avg batch time: 0.2147, average loss: 4.8767
[09/27 22:51:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 11.22	
[09/27 22:51:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/27 22:51:34 visual_prompt]: Epoch 42 / 100: avg data time: 3.69e-02, avg batch time: 0.4937, average train loss: 4.1420
[09/27 22:51:35 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1699, average loss: 4.0901
[09/27 22:51:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 14.50	
[09/27 22:51:42 visual_prompt]: Inference (test):avg data time: 4.67e-05, avg batch time: 0.2144, average loss: 4.1027
[09/27 22:51:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.61	top5: 12.61	
[09/27 22:51:42 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/27 22:51:51 visual_prompt]: Epoch 43 / 100: avg data time: 4.02e-02, avg batch time: 0.4969, average train loss: 4.0623
[09/27 22:51:52 visual_prompt]: Inference (val):avg data time: 1.69e-05, avg batch time: 0.1702, average loss: 4.1183
[09/27 22:51:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.00	
[09/27 22:51:59 visual_prompt]: Inference (test):avg data time: 1.08e-04, avg batch time: 0.2148, average loss: 4.1131
[09/27 22:51:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.38	
[09/27 22:51:59 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/27 22:52:08 visual_prompt]: Epoch 44 / 100: avg data time: 4.09e-02, avg batch time: 0.4990, average train loss: 4.1255
[09/27 22:52:09 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1700, average loss: 4.0804
[09/27 22:52:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.50	
[09/27 22:52:16 visual_prompt]: Inference (test):avg data time: 3.95e-05, avg batch time: 0.2135, average loss: 4.0683
[09/27 22:52:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 22:52:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/27 22:52:25 visual_prompt]: Epoch 45 / 100: avg data time: 4.46e-02, avg batch time: 0.5025, average train loss: 4.1173
[09/27 22:52:26 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1694, average loss: 4.0487
[09/27 22:52:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 9.00	
[09/27 22:52:33 visual_prompt]: Inference (test):avg data time: 2.83e-05, avg batch time: 0.2142, average loss: 4.0507
[09/27 22:52:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:52:33 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/27 22:52:42 visual_prompt]: Epoch 46 / 100: avg data time: 3.81e-02, avg batch time: 0.4946, average train loss: 4.1002
[09/27 22:52:43 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1703, average loss: 4.0002
[09/27 22:52:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/27 22:52:50 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2141, average loss: 4.0375
[09/27 22:52:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.64	
[09/27 22:52:50 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/27 22:52:59 visual_prompt]: Epoch 47 / 100: avg data time: 4.25e-02, avg batch time: 0.4993, average train loss: 4.0413
[09/27 22:53:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1704, average loss: 3.9642
[09/27 22:53:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 9.00	
[09/27 22:53:07 visual_prompt]: Inference (test):avg data time: 4.28e-05, avg batch time: 0.2146, average loss: 3.9893
[09/27 22:53:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 22:53:08 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/27 22:53:16 visual_prompt]: Epoch 48 / 100: avg data time: 4.32e-02, avg batch time: 0.4997, average train loss: 4.0470
[09/27 22:53:17 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1701, average loss: 3.9319
[09/27 22:53:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 15.00	
[09/27 22:53:24 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2144, average loss: 3.9841
[09/27 22:53:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/27 22:53:24 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/27 22:53:33 visual_prompt]: Epoch 49 / 100: avg data time: 3.46e-02, avg batch time: 0.4926, average train loss: 3.9710
[09/27 22:53:34 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1693, average loss: 4.1059
[09/27 22:53:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.00	
[09/27 22:53:41 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2139, average loss: 4.0180
[09/27 22:53:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.96	
[09/27 22:53:41 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/27 22:53:50 visual_prompt]: Epoch 50 / 100: avg data time: 4.06e-02, avg batch time: 0.4976, average train loss: 3.9886
[09/27 22:53:51 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1700, average loss: 4.0423
[09/27 22:53:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.00	
[09/27 22:53:58 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2155, average loss: 4.0183
[09/27 22:53:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.33	
[09/27 22:53:58 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/27 22:54:07 visual_prompt]: Epoch 51 / 100: avg data time: 4.55e-02, avg batch time: 0.5032, average train loss: 3.9673
[09/27 22:54:08 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1701, average loss: 3.8815
[09/27 22:54:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 19.50	
[09/27 22:54:16 visual_prompt]: Inference (test):avg data time: 2.58e-05, avg batch time: 0.2139, average loss: 3.9339
[09/27 22:54:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.35	top5: 15.00	
[09/27 22:54:16 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/27 22:54:24 visual_prompt]: Epoch 52 / 100: avg data time: 4.14e-02, avg batch time: 0.4988, average train loss: 3.8935
[09/27 22:54:25 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1701, average loss: 3.8533
[09/27 22:54:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 16.00	
[09/27 22:54:33 visual_prompt]: Inference (test):avg data time: 2.76e-05, avg batch time: 0.2141, average loss: 3.9141
[09/27 22:54:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 16.28	
[09/27 22:54:33 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/27 22:54:41 visual_prompt]: Epoch 53 / 100: avg data time: 4.64e-02, avg batch time: 0.5031, average train loss: 3.9216
[09/27 22:54:42 visual_prompt]: Inference (val):avg data time: 1.99e-05, avg batch time: 0.1700, average loss: 3.8464
[09/27 22:54:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 18.50	
[09/27 22:54:50 visual_prompt]: Inference (test):avg data time: 8.90e-05, avg batch time: 0.2154, average loss: 3.9506
[09/27 22:54:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.34	top5: 13.56	
[09/27 22:54:50 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/27 22:54:58 visual_prompt]: Epoch 54 / 100: avg data time: 4.42e-02, avg batch time: 0.5012, average train loss: 3.9188
[09/27 22:54:59 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.1698, average loss: 3.8006
[09/27 22:54:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 24.50	
[09/27 22:55:07 visual_prompt]: Inference (test):avg data time: 2.84e-05, avg batch time: 0.2151, average loss: 3.9266
[09/27 22:55:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.11	top5: 18.56	
[09/27 22:55:07 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/27 22:55:15 visual_prompt]: Epoch 55 / 100: avg data time: 3.36e-02, avg batch time: 0.4905, average train loss: 3.6581
[09/27 22:55:16 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1697, average loss: 3.6920
[09/27 22:55:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 25.00	
[09/27 22:55:24 visual_prompt]: Inference (test):avg data time: 3.81e-05, avg batch time: 0.2145, average loss: 3.8307
[09/27 22:55:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 7.23	top5: 25.00	
[09/27 22:55:24 visual_prompt]: Best epoch 55: best metric: 0.070
[09/27 22:55:24 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/27 22:55:32 visual_prompt]: Epoch 56 / 100: avg data time: 3.59e-02, avg batch time: 0.4928, average train loss: 3.1663
[09/27 22:55:33 visual_prompt]: Inference (val):avg data time: 2.04e-05, avg batch time: 0.1701, average loss: 3.0237
[09/27 22:55:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 25.50	top5: 57.50	
[09/27 22:55:41 visual_prompt]: Inference (test):avg data time: 2.80e-05, avg batch time: 0.2143, average loss: 3.2175
[09/27 22:55:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 22.02	top5: 47.71	
[09/27 22:55:41 visual_prompt]: Best epoch 56: best metric: 0.255
[09/27 22:55:41 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/27 22:55:49 visual_prompt]: Epoch 57 / 100: avg data time: 4.34e-02, avg batch time: 0.5001, average train loss: 2.1371
[09/27 22:55:50 visual_prompt]: Inference (val):avg data time: 1.75e-05, avg batch time: 0.1700, average loss: 2.4694
[09/27 22:55:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 36.00	top5: 68.50	
[09/27 22:55:57 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2149, average loss: 2.9150
[09/27 22:55:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 27.29	top5: 55.48	
[09/27 22:55:57 visual_prompt]: Best epoch 57: best metric: 0.360
[09/27 22:55:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/27 22:56:06 visual_prompt]: Epoch 58 / 100: avg data time: 4.19e-02, avg batch time: 0.4991, average train loss: 1.5563
[09/27 22:56:07 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1706, average loss: 0.8379
[09/27 22:56:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 77.50	top5: 95.00	
[09/27 22:56:15 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2145, average loss: 1.9601
[09/27 22:56:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 49.63	top5: 81.97	
[09/27 22:56:15 visual_prompt]: Best epoch 58: best metric: 0.775
[09/27 22:56:15 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/27 22:56:23 visual_prompt]: Epoch 59 / 100: avg data time: 4.64e-02, avg batch time: 0.5034, average train loss: 0.8626
[09/27 22:56:24 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1705, average loss: 0.5488
[09/27 22:56:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 85.00	top5: 97.50	
[09/27 22:56:32 visual_prompt]: Inference (test):avg data time: 1.43e-04, avg batch time: 0.2150, average loss: 1.7398
[09/27 22:56:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.57	top5: 83.09	
[09/27 22:56:32 visual_prompt]: Best epoch 59: best metric: 0.850
[09/27 22:56:32 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/27 22:56:40 visual_prompt]: Epoch 60 / 100: avg data time: 3.62e-02, avg batch time: 0.4948, average train loss: 0.5497
[09/27 22:56:41 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1704, average loss: 0.4662
[09/27 22:56:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 88.00	top5: 99.50	
[09/27 22:56:49 visual_prompt]: Inference (test):avg data time: 2.71e-05, avg batch time: 0.2161, average loss: 1.7396
[09/27 22:56:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.62	top5: 83.35	
[09/27 22:56:49 visual_prompt]: Best epoch 60: best metric: 0.880
[09/27 22:56:49 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/27 22:56:57 visual_prompt]: Epoch 61 / 100: avg data time: 4.12e-02, avg batch time: 0.4985, average train loss: 0.3470
[09/27 22:56:58 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1703, average loss: 0.3722
[09/27 22:56:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.50	top5: 99.00	
[09/27 22:57:06 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2142, average loss: 1.6096
[09/27 22:57:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 58.72	top5: 85.27	
[09/27 22:57:06 visual_prompt]: Best epoch 61: best metric: 0.935
[09/27 22:57:06 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/27 22:57:14 visual_prompt]: Epoch 62 / 100: avg data time: 4.16e-02, avg batch time: 0.4993, average train loss: 0.2778
[09/27 22:57:15 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1704, average loss: 0.2239
[09/27 22:57:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 100.00	
[09/27 22:57:23 visual_prompt]: Inference (test):avg data time: 2.74e-05, avg batch time: 0.2146, average loss: 1.5164
[09/27 22:57:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.53	top5: 87.07	
[09/27 22:57:23 visual_prompt]: Best epoch 62: best metric: 0.960
[09/27 22:57:23 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/27 22:57:31 visual_prompt]: Epoch 63 / 100: avg data time: 4.66e-02, avg batch time: 0.5031, average train loss: 0.2180
[09/27 22:57:33 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1698, average loss: 0.1364
[09/27 22:57:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 22:57:40 visual_prompt]: Inference (test):avg data time: 2.77e-05, avg batch time: 0.2146, average loss: 1.4086
[09/27 22:57:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.44	top5: 87.82	
[09/27 22:57:40 visual_prompt]: Best epoch 63: best metric: 0.995
[09/27 22:57:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/27 22:57:48 visual_prompt]: Epoch 64 / 100: avg data time: 3.37e-02, avg batch time: 0.4918, average train loss: 0.1836
[09/27 22:57:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1702, average loss: 0.3105
[09/27 22:57:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.00	top5: 100.00	
[09/27 22:57:57 visual_prompt]: Inference (test):avg data time: 2.68e-05, avg batch time: 0.2142, average loss: 1.5864
[09/27 22:57:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.60	top5: 86.17	
[09/27 22:57:57 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/27 22:58:05 visual_prompt]: Epoch 65 / 100: avg data time: 4.85e-02, avg batch time: 0.5052, average train loss: 0.4442
[09/27 22:58:07 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1705, average loss: 0.2518
[09/27 22:58:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 96.50	top5: 100.00	
[09/27 22:58:14 visual_prompt]: Inference (test):avg data time: 1.32e-04, avg batch time: 0.2147, average loss: 1.4255
[09/27 22:58:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.86	top5: 87.39	
[09/27 22:58:14 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/27 22:58:23 visual_prompt]: Epoch 66 / 100: avg data time: 4.60e-02, avg batch time: 0.5034, average train loss: 0.3010
[09/27 22:58:24 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1703, average loss: 0.1956
[09/27 22:58:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/27 22:58:31 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2152, average loss: 1.4409
[09/27 22:58:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.16	top5: 87.50	
[09/27 22:58:32 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/27 22:58:40 visual_prompt]: Epoch 67 / 100: avg data time: 3.56e-02, avg batch time: 0.4929, average train loss: 0.1794
[09/27 22:58:41 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1703, average loss: 0.1031
[09/27 22:58:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/27 22:58:49 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2148, average loss: 1.3375
[09/27 22:58:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.94	top5: 89.20	
[09/27 22:58:49 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/27 22:58:57 visual_prompt]: Epoch 68 / 100: avg data time: 3.72e-02, avg batch time: 0.4943, average train loss: 0.1199
[09/27 22:58:58 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1701, average loss: 0.1136
[09/27 22:58:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 22:59:06 visual_prompt]: Inference (test):avg data time: 7.45e-04, avg batch time: 0.2150, average loss: 1.3195
[09/27 22:59:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.41	top5: 88.83	
[09/27 22:59:06 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/27 22:59:14 visual_prompt]: Epoch 69 / 100: avg data time: 4.95e-02, avg batch time: 0.5069, average train loss: 0.0982
[09/27 22:59:15 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1702, average loss: 0.0789
[09/27 22:59:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 22:59:23 visual_prompt]: Inference (test):avg data time: 2.02e-04, avg batch time: 0.2149, average loss: 1.2819
[09/27 22:59:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.32	top5: 90.64	
[09/27 22:59:23 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/27 22:59:31 visual_prompt]: Epoch 70 / 100: avg data time: 3.29e-02, avg batch time: 0.4909, average train loss: 0.0922
[09/27 22:59:32 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1702, average loss: 0.0827
[09/27 22:59:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 22:59:40 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2155, average loss: 1.2283
[09/27 22:59:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.45	top5: 90.37	
[09/27 22:59:40 visual_prompt]: Best epoch 70: best metric: 1.000
[09/27 22:59:40 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/27 22:59:48 visual_prompt]: Epoch 71 / 100: avg data time: 3.38e-02, avg batch time: 0.4932, average train loss: 0.0851
[09/27 22:59:49 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1701, average loss: 0.0568
[09/27 22:59:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 22:59:57 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2153, average loss: 1.2034
[09/27 22:59:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.07	top5: 90.96	
[09/27 22:59:57 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/27 23:00:05 visual_prompt]: Epoch 72 / 100: avg data time: 4.07e-02, avg batch time: 0.4986, average train loss: 0.0822
[09/27 23:00:06 visual_prompt]: Inference (val):avg data time: 1.63e-05, avg batch time: 0.1701, average loss: 0.0671
[09/27 23:00:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 23:00:14 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2149, average loss: 1.2137
[09/27 23:00:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 90.64	
[09/27 23:00:14 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/27 23:00:22 visual_prompt]: Epoch 73 / 100: avg data time: 3.75e-02, avg batch time: 0.4953, average train loss: 0.0899
[09/27 23:00:23 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1702, average loss: 0.1000
[09/27 23:00:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/27 23:00:31 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2150, average loss: 1.2788
[09/27 23:00:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 90.64	
[09/27 23:00:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/27 23:00:39 visual_prompt]: Epoch 74 / 100: avg data time: 4.10e-02, avg batch time: 0.4976, average train loss: 0.1100
[09/27 23:00:40 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1703, average loss: 0.1014
[09/27 23:00:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:00:48 visual_prompt]: Inference (test):avg data time: 1.57e-04, avg batch time: 0.2143, average loss: 1.2878
[09/27 23:00:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 90.53	
[09/27 23:00:48 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/27 23:00:56 visual_prompt]: Epoch 75 / 100: avg data time: 3.59e-02, avg batch time: 0.4947, average train loss: 0.1600
[09/27 23:00:57 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1699, average loss: 0.1135
[09/27 23:00:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/27 23:01:05 visual_prompt]: Inference (test):avg data time: 2.54e-05, avg batch time: 0.2154, average loss: 1.2477
[09/27 23:01:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 90.16	
[09/27 23:01:05 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/27 23:01:13 visual_prompt]: Epoch 76 / 100: avg data time: 4.32e-02, avg batch time: 0.5009, average train loss: 0.1230
[09/27 23:01:15 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1705, average loss: 0.0892
[09/27 23:01:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:01:22 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2149, average loss: 1.2063
[09/27 23:01:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 91.22	
[09/27 23:01:22 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/27 23:01:30 visual_prompt]: Epoch 77 / 100: avg data time: 4.16e-02, avg batch time: 0.4990, average train loss: 0.0747
[09/27 23:01:32 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1702, average loss: 0.0485
[09/27 23:01:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:01:39 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2145, average loss: 1.2045
[09/27 23:01:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 91.44	
[09/27 23:01:39 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/27 23:01:47 visual_prompt]: Epoch 78 / 100: avg data time: 4.37e-02, avg batch time: 0.5008, average train loss: 0.0533
[09/27 23:01:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1713, average loss: 0.0367
[09/27 23:01:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:01:56 visual_prompt]: Inference (test):avg data time: 2.83e-05, avg batch time: 0.2142, average loss: 1.1573
[09/27 23:01:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.31	top5: 92.34	
[09/27 23:01:56 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/27 23:02:04 visual_prompt]: Epoch 79 / 100: avg data time: 4.32e-02, avg batch time: 0.5009, average train loss: 0.0429
[09/27 23:02:06 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1704, average loss: 0.0316
[09/27 23:02:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:02:13 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2142, average loss: 1.1629
[09/27 23:02:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.67	top5: 92.07	
[09/27 23:02:13 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/27 23:02:22 visual_prompt]: Epoch 80 / 100: avg data time: 4.26e-02, avg batch time: 0.5000, average train loss: 0.0363
[09/27 23:02:23 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1703, average loss: 0.0348
[09/27 23:02:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 23:02:30 visual_prompt]: Inference (test):avg data time: 1.06e-04, avg batch time: 0.2145, average loss: 1.1490
[09/27 23:02:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.78	top5: 92.45	
[09/27 23:02:30 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/27 23:02:39 visual_prompt]: Epoch 81 / 100: avg data time: 4.40e-02, avg batch time: 0.5015, average train loss: 0.0371
[09/27 23:02:40 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1705, average loss: 0.0347
[09/27 23:02:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:02:47 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2155, average loss: 1.1828
[09/27 23:02:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.72	top5: 91.44	
[09/27 23:02:47 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/27 23:02:55 visual_prompt]: Epoch 82 / 100: avg data time: 3.43e-02, avg batch time: 0.4934, average train loss: 0.0395
[09/27 23:02:57 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1702, average loss: 0.0329
[09/27 23:02:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:03:04 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2149, average loss: 1.1819
[09/27 23:03:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.62	top5: 91.81	
[09/27 23:03:04 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/27 23:03:12 visual_prompt]: Epoch 83 / 100: avg data time: 4.24e-02, avg batch time: 0.5001, average train loss: 0.0342
[09/27 23:03:14 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1700, average loss: 0.0238
[09/27 23:03:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:03:21 visual_prompt]: Inference (test):avg data time: 4.31e-05, avg batch time: 0.2142, average loss: 1.1655
[09/27 23:03:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.68	top5: 92.13	
[09/27 23:03:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/27 23:03:30 visual_prompt]: Epoch 84 / 100: avg data time: 4.42e-02, avg batch time: 0.5013, average train loss: 0.0284
[09/27 23:03:31 visual_prompt]: Inference (val):avg data time: 1.71e-05, avg batch time: 0.1704, average loss: 0.0198
[09/27 23:03:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:03:39 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2146, average loss: 1.1607
[09/27 23:03:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.63	top5: 92.07	
[09/27 23:03:39 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/27 23:03:47 visual_prompt]: Epoch 85 / 100: avg data time: 4.63e-02, avg batch time: 0.5031, average train loss: 0.0275
[09/27 23:03:48 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1698, average loss: 0.0215
[09/27 23:03:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:03:56 visual_prompt]: Inference (test):avg data time: 2.70e-05, avg batch time: 0.2148, average loss: 1.1803
[09/27 23:03:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.52	top5: 91.38	
[09/27 23:03:56 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/27 23:04:04 visual_prompt]: Epoch 86 / 100: avg data time: 4.77e-02, avg batch time: 0.5046, average train loss: 0.0248
[09/27 23:04:05 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1701, average loss: 0.0193
[09/27 23:04:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:04:13 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2142, average loss: 1.2036
[09/27 23:04:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.51	top5: 91.54	
[09/27 23:04:13 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/27 23:04:21 visual_prompt]: Epoch 87 / 100: avg data time: 4.65e-02, avg batch time: 0.5056, average train loss: 0.0223
[09/27 23:04:23 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1702, average loss: 0.0173
[09/27 23:04:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:04:30 visual_prompt]: Inference (test):avg data time: 2.66e-05, avg batch time: 0.2144, average loss: 1.2094
[09/27 23:04:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.99	top5: 91.81	
[09/27 23:04:30 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/27 23:04:38 visual_prompt]: Epoch 88 / 100: avg data time: 4.14e-02, avg batch time: 0.4989, average train loss: 0.0204
[09/27 23:04:40 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1699, average loss: 0.0162
[09/27 23:04:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:04:47 visual_prompt]: Inference (test):avg data time: 1.10e-03, avg batch time: 0.2169, average loss: 1.2071
[09/27 23:04:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.26	top5: 91.65	
[09/27 23:04:47 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/27 23:04:55 visual_prompt]: Epoch 89 / 100: avg data time: 3.03e-02, avg batch time: 0.4889, average train loss: 0.0182
[09/27 23:04:57 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1705, average loss: 0.0139
[09/27 23:04:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:05:04 visual_prompt]: Inference (test):avg data time: 6.69e-04, avg batch time: 0.2148, average loss: 1.2146
[09/27 23:05:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.10	top5: 91.60	
[09/27 23:05:04 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/27 23:05:12 visual_prompt]: Epoch 90 / 100: avg data time: 4.09e-02, avg batch time: 0.4979, average train loss: 0.0171
[09/27 23:05:14 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.1700, average loss: 0.0138
[09/27 23:05:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:05:21 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2145, average loss: 1.2207
[09/27 23:05:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.63	top5: 91.44	
[09/27 23:05:21 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/27 23:05:30 visual_prompt]: Epoch 91 / 100: avg data time: 4.66e-02, avg batch time: 0.5036, average train loss: 0.0161
[09/27 23:05:31 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1702, average loss: 0.0132
[09/27 23:05:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:05:38 visual_prompt]: Inference (test):avg data time: 2.80e-05, avg batch time: 0.2145, average loss: 1.2304
[09/27 23:05:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.83	top5: 91.28	
[09/27 23:05:38 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/27 23:05:47 visual_prompt]: Epoch 92 / 100: avg data time: 4.68e-02, avg batch time: 0.5034, average train loss: 0.0156
[09/27 23:05:48 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1703, average loss: 0.0127
[09/27 23:05:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:05:55 visual_prompt]: Inference (test):avg data time: 1.23e-04, avg batch time: 0.2151, average loss: 1.2274
[09/27 23:05:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.52	top5: 91.22	
[09/27 23:05:55 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/27 23:06:04 visual_prompt]: Epoch 93 / 100: avg data time: 3.66e-02, avg batch time: 0.4942, average train loss: 0.0153
[09/27 23:06:05 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1702, average loss: 0.0125
[09/27 23:06:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:06:13 visual_prompt]: Inference (test):avg data time: 2.75e-05, avg batch time: 0.2141, average loss: 1.2381
[09/27 23:06:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.52	top5: 91.28	
[09/27 23:06:13 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/27 23:06:21 visual_prompt]: Epoch 94 / 100: avg data time: 4.75e-02, avg batch time: 0.5045, average train loss: 0.0151
[09/27 23:06:22 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1704, average loss: 0.0126
[09/27 23:06:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:06:30 visual_prompt]: Inference (test):avg data time: 2.63e-05, avg batch time: 0.2144, average loss: 1.2439
[09/27 23:06:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.10	top5: 91.38	
[09/27 23:06:30 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/27 23:06:38 visual_prompt]: Epoch 95 / 100: avg data time: 3.69e-02, avg batch time: 0.4950, average train loss: 0.0149
[09/27 23:06:39 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1700, average loss: 0.0122
[09/27 23:06:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:06:47 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2142, average loss: 1.2452
[09/27 23:06:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.41	top5: 91.33	
[09/27 23:06:47 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/27 23:06:55 visual_prompt]: Epoch 96 / 100: avg data time: 4.42e-02, avg batch time: 0.5017, average train loss: 0.0146
[09/27 23:06:57 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1702, average loss: 0.0121
[09/27 23:06:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:07:04 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2143, average loss: 1.2450
[09/27 23:07:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.20	top5: 91.38	
[09/27 23:07:04 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/27 23:07:12 visual_prompt]: Epoch 97 / 100: avg data time: 4.36e-02, avg batch time: 0.5019, average train loss: 0.0143
[09/27 23:07:14 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1704, average loss: 0.0121
[09/27 23:07:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:07:21 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2150, average loss: 1.2486
[09/27 23:07:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 69.15	top5: 91.33	
[09/27 23:07:21 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/27 23:07:29 visual_prompt]: Epoch 98 / 100: avg data time: 3.61e-02, avg batch time: 0.4932, average train loss: 0.0143
[09/27 23:07:31 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1703, average loss: 0.0120
[09/27 23:07:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:07:38 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2150, average loss: 1.2498
[09/27 23:07:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.88	top5: 91.28	
[09/27 23:07:38 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/27 23:07:46 visual_prompt]: Epoch 99 / 100: avg data time: 5.08e-02, avg batch time: 0.5077, average train loss: 0.0141
[09/27 23:07:48 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1702, average loss: 0.0120
[09/27 23:07:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:07:55 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2146, average loss: 1.2499
[09/27 23:07:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.88	top5: 91.38	
[09/27 23:07:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/27 23:08:04 visual_prompt]: Epoch 100 / 100: avg data time: 4.27e-02, avg batch time: 0.4999, average train loss: 0.0141
[09/27 23:08:05 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1703, average loss: 0.0120
[09/27 23:08:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:08:12 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2156, average loss: 1.2502
[09/27 23:08:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.88	top5: 91.44	
[09/27 23:08:12 visual_prompt]: Rank of current process: 0. World size: 1
[09/27 23:08:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/27 23:08:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 23:08:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/27 23:08:12 visual_prompt]: Training with config:
[09/27 23:08:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dtd/sup_vitb16_imagenet21k/prompt50/crop224/test/seed8786/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8786, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dtd', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 47, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/27 23:08:12 visual_prompt]: Loading training data...
[09/27 23:08:12 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:08:15 visual_prompt]: Number of images: 1000
[09/27 23:08:15 visual_prompt]: Number of classes: 47 / 47
[09/27 23:08:15 visual_prompt]: Loading validation data...
[09/27 23:08:15 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:08:16 visual_prompt]: Number of images: 200
[09/27 23:08:16 visual_prompt]: Number of classes: 47 / 47
[09/27 23:08:16 visual_prompt]: Loading test data...
[09/27 23:08:16 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:08:20 visual_prompt]: Number of images: 1880
[09/27 23:08:20 visual_prompt]: Number of classes: 47 / 47
[09/27 23:08:20 visual_prompt]: Constructing models...
[09/27 23:08:22 visual_prompt]: Total Parameters: 86295599	 Gradient Parameters: 496943
[09/27 23:08:22 visual_prompt]: tuned percent:0.576
[09/27 23:08:22 visual_prompt]: Device used for model: 0
[09/27 23:08:22 visual_prompt]: Setting up Evaluator...
[09/27 23:08:22 visual_prompt]: Setting up Trainer...
[09/27 23:08:22 visual_prompt]: 	Setting up the optimizer...
[09/27 23:08:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/27 23:08:31 visual_prompt]: Epoch 1 / 100: avg data time: 4.74e-02, avg batch time: 0.5027, average train loss: 3.9259
[09/27 23:08:32 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1689, average loss: 3.8778
[09/27 23:08:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.00	
[09/27 23:08:40 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2134, average loss: 3.9411
[09/27 23:08:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.59	
[09/27 23:08:40 visual_prompt]: Best epoch 1: best metric: 0.025
[09/27 23:08:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/27 23:08:48 visual_prompt]: Epoch 2 / 100: avg data time: 3.69e-02, avg batch time: 0.4943, average train loss: 3.9045
[09/27 23:08:49 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1690, average loss: 3.7403
[09/27 23:08:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.50	top5: 22.00	
[09/27 23:08:57 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2128, average loss: 3.8241
[09/27 23:08:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.79	top5: 17.13	
[09/27 23:08:57 visual_prompt]: Best epoch 2: best metric: 0.055
[09/27 23:08:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/27 23:09:05 visual_prompt]: Epoch 3 / 100: avg data time: 5.24e-02, avg batch time: 0.5082, average train loss: 3.9000
[09/27 23:09:07 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1695, average loss: 4.2934
[09/27 23:09:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.50	
[09/27 23:09:14 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2140, average loss: 4.2930
[09/27 23:09:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.45	top5: 15.80	
[09/27 23:09:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/27 23:09:22 visual_prompt]: Epoch 4 / 100: avg data time: 4.86e-02, avg batch time: 0.5040, average train loss: 3.9225
[09/27 23:09:24 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1695, average loss: 3.9837
[09/27 23:09:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 7.50	
[09/27 23:09:31 visual_prompt]: Inference (test):avg data time: 1.23e-04, avg batch time: 0.2136, average loss: 4.0240
[09/27 23:09:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.83	top5: 12.93	
[09/27 23:09:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/27 23:09:40 visual_prompt]: Epoch 5 / 100: avg data time: 4.70e-02, avg batch time: 0.5026, average train loss: 3.7995
[09/27 23:09:41 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1698, average loss: 4.0625
[09/27 23:09:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/27 23:09:48 visual_prompt]: Inference (test):avg data time: 4.35e-05, avg batch time: 0.2131, average loss: 4.0876
[09/27 23:09:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.88	top5: 14.79	
[09/27 23:09:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/27 23:09:57 visual_prompt]: Epoch 6 / 100: avg data time: 4.71e-02, avg batch time: 0.5024, average train loss: 4.1550
[09/27 23:09:58 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1698, average loss: 4.4565
[09/27 23:09:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 10.50	
[09/27 23:10:06 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2134, average loss: 4.4651
[09/27 23:10:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.29	
[09/27 23:10:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/27 23:10:14 visual_prompt]: Epoch 7 / 100: avg data time: 4.21e-02, avg batch time: 0.4986, average train loss: 4.3642
[09/27 23:10:16 visual_prompt]: Inference (val):avg data time: 4.17e-05, avg batch time: 0.1697, average loss: 4.1607
[09/27 23:10:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 12.50	
[09/27 23:10:23 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2133, average loss: 4.2622
[09/27 23:10:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 13.40	
[09/27 23:10:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/27 23:10:31 visual_prompt]: Epoch 8 / 100: avg data time: 4.78e-02, avg batch time: 0.5037, average train loss: 4.2723
[09/27 23:10:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1698, average loss: 4.0965
[09/27 23:10:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 22.50	
[09/27 23:10:40 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2139, average loss: 4.2138
[09/27 23:10:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.87	top5: 18.35	
[09/27 23:10:40 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/27 23:10:48 visual_prompt]: Epoch 9 / 100: avg data time: 3.69e-02, avg batch time: 0.4934, average train loss: 4.8595
[09/27 23:10:50 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1698, average loss: 4.7699
[09/27 23:10:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 12.00	
[09/27 23:10:57 visual_prompt]: Inference (test):avg data time: 2.85e-05, avg batch time: 0.2139, average loss: 4.8401
[09/27 23:10:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 0.96	top5: 11.17	
[09/27 23:10:57 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/27 23:11:06 visual_prompt]: Epoch 10 / 100: avg data time: 3.59e-02, avg batch time: 0.4924, average train loss: 12.7203
[09/27 23:11:07 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1694, average loss: 12.0552
[09/27 23:11:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 14.00	
[09/27 23:11:14 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2134, average loss: 14.2149
[09/27 23:11:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.39	
[09/27 23:11:14 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/27 23:11:23 visual_prompt]: Epoch 11 / 100: avg data time: 5.02e-02, avg batch time: 0.5073, average train loss: 12.4322
[09/27 23:11:24 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1701, average loss: 9.4844
[09/27 23:11:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/27 23:11:32 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2143, average loss: 10.1239
[09/27 23:11:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.76	
[09/27 23:11:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/27 23:11:40 visual_prompt]: Epoch 12 / 100: avg data time: 3.42e-02, avg batch time: 0.4916, average train loss: 13.3347
[09/27 23:11:41 visual_prompt]: Inference (val):avg data time: 5.38e-05, avg batch time: 0.1696, average loss: 15.4068
[09/27 23:11:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 12.00	
[09/27 23:11:49 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2142, average loss: 14.8740
[09/27 23:11:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.55	top5: 11.22	
[09/27 23:11:49 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/27 23:11:57 visual_prompt]: Epoch 13 / 100: avg data time: 3.55e-02, avg batch time: 0.4936, average train loss: 12.0349
[09/27 23:11:58 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1696, average loss: 8.5383
[09/27 23:11:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 8.50	
[09/27 23:12:06 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2140, average loss: 8.4100
[09/27 23:12:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.53	
[09/27 23:12:06 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/27 23:12:14 visual_prompt]: Epoch 14 / 100: avg data time: 3.42e-02, avg batch time: 0.4925, average train loss: 11.3634
[09/27 23:12:16 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1693, average loss: 12.0945
[09/27 23:12:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/27 23:12:23 visual_prompt]: Inference (test):avg data time: 2.92e-05, avg batch time: 0.2148, average loss: 11.0762
[09/27 23:12:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.01	
[09/27 23:12:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/27 23:12:31 visual_prompt]: Epoch 15 / 100: avg data time: 4.15e-02, avg batch time: 0.4988, average train loss: 10.1784
[09/27 23:12:33 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1699, average loss: 9.2820
[09/27 23:12:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 11.00	
[09/27 23:12:40 visual_prompt]: Inference (test):avg data time: 3.99e-05, avg batch time: 0.2135, average loss: 8.5984
[09/27 23:12:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.28	
[09/27 23:12:40 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/27 23:12:48 visual_prompt]: Epoch 16 / 100: avg data time: 4.56e-02, avg batch time: 0.5023, average train loss: 8.9839
[09/27 23:12:50 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1698, average loss: 7.6330
[09/27 23:12:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.00	
[09/27 23:12:57 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2136, average loss: 6.9363
[09/27 23:12:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.96	
[09/27 23:12:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/27 23:13:06 visual_prompt]: Epoch 17 / 100: avg data time: 4.54e-02, avg batch time: 0.5020, average train loss: 10.0633
[09/27 23:13:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1695, average loss: 15.2076
[09/27 23:13:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.00	
[09/27 23:13:15 visual_prompt]: Inference (test):avg data time: 4.66e-04, avg batch time: 0.2150, average loss: 15.5126
[09/27 23:13:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:13:15 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/27 23:13:23 visual_prompt]: Epoch 18 / 100: avg data time: 3.25e-02, avg batch time: 0.4915, average train loss: 9.6553
[09/27 23:13:24 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1700, average loss: 8.6026
[09/27 23:13:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/27 23:13:32 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2146, average loss: 8.0918
[09/27 23:13:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/27 23:13:32 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/27 23:13:40 visual_prompt]: Epoch 19 / 100: avg data time: 4.46e-02, avg batch time: 0.5015, average train loss: 6.9411
[09/27 23:13:41 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1698, average loss: 5.5986
[09/27 23:13:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 12.00	
[09/27 23:13:49 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2138, average loss: 6.0266
[09/27 23:13:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 9.89	
[09/27 23:13:49 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/27 23:13:57 visual_prompt]: Epoch 20 / 100: avg data time: 4.36e-02, avg batch time: 0.5001, average train loss: 5.6282
[09/27 23:13:59 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1695, average loss: 5.0003
[09/27 23:13:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 11.50	
[09/27 23:14:06 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2135, average loss: 5.1104
[09/27 23:14:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 10.64	
[09/27 23:14:06 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/27 23:14:15 visual_prompt]: Epoch 21 / 100: avg data time: 4.84e-02, avg batch time: 0.5046, average train loss: 4.6626
[09/27 23:14:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1699, average loss: 4.5098
[09/27 23:14:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.50	
[09/27 23:14:23 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2145, average loss: 4.5942
[09/27 23:14:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:14:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/27 23:14:32 visual_prompt]: Epoch 22 / 100: avg data time: 4.71e-02, avg batch time: 0.5041, average train loss: 4.8177
[09/27 23:14:33 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1693, average loss: 4.3130
[09/27 23:14:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 17.00	
[09/27 23:14:41 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2147, average loss: 4.4206
[09/27 23:14:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.74	
[09/27 23:14:41 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/27 23:14:49 visual_prompt]: Epoch 23 / 100: avg data time: 4.80e-02, avg batch time: 0.5040, average train loss: 4.6775
[09/27 23:14:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1699, average loss: 4.4366
[09/27 23:14:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/27 23:14:58 visual_prompt]: Inference (test):avg data time: 2.85e-05, avg batch time: 0.2131, average loss: 4.7315
[09/27 23:14:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.27	
[09/27 23:14:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/27 23:15:06 visual_prompt]: Epoch 24 / 100: avg data time: 4.33e-02, avg batch time: 0.4987, average train loss: 4.5500
[09/27 23:15:08 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1695, average loss: 4.6608
[09/27 23:15:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.50	
[09/27 23:15:15 visual_prompt]: Inference (test):avg data time: 4.35e-04, avg batch time: 0.2134, average loss: 4.5562
[09/27 23:15:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:15:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/27 23:15:23 visual_prompt]: Epoch 25 / 100: avg data time: 4.59e-02, avg batch time: 0.5015, average train loss: 4.2516
[09/27 23:15:25 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1698, average loss: 4.1003
[09/27 23:15:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.00	
[09/27 23:15:32 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2136, average loss: 4.1733
[09/27 23:15:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 23:15:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/27 23:15:41 visual_prompt]: Epoch 26 / 100: avg data time: 3.39e-02, avg batch time: 0.4901, average train loss: 4.2042
[09/27 23:15:42 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1700, average loss: 3.9770
[09/27 23:15:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 16.00	
[09/27 23:15:50 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2143, average loss: 4.0577
[09/27 23:15:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 11.01	
[09/27 23:15:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/27 23:15:58 visual_prompt]: Epoch 27 / 100: avg data time: 4.67e-02, avg batch time: 0.5036, average train loss: 4.1046
[09/27 23:15:59 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1700, average loss: 4.6493
[09/27 23:15:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.00	
[09/27 23:16:07 visual_prompt]: Inference (test):avg data time: 2.89e-05, avg batch time: 0.2138, average loss: 4.6355
[09/27 23:16:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 23:16:07 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/27 23:16:15 visual_prompt]: Epoch 28 / 100: avg data time: 4.46e-02, avg batch time: 0.5008, average train loss: 4.1551
[09/27 23:16:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1697, average loss: 4.9052
[09/27 23:16:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 9.50	
[09/27 23:16:24 visual_prompt]: Inference (test):avg data time: 1.57e-04, avg batch time: 0.2138, average loss: 4.8802
[09/27 23:16:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:16:24 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/27 23:16:32 visual_prompt]: Epoch 29 / 100: avg data time: 4.75e-02, avg batch time: 0.5035, average train loss: 4.2459
[09/27 23:16:34 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1693, average loss: 4.2202
[09/27 23:16:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.00	
[09/27 23:16:41 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2132, average loss: 4.1975
[09/27 23:16:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.60	
[09/27 23:16:41 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/27 23:16:50 visual_prompt]: Epoch 30 / 100: avg data time: 3.35e-02, avg batch time: 0.4910, average train loss: 4.1297
[09/27 23:16:51 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1703, average loss: 4.0241
[09/27 23:16:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/27 23:16:58 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2139, average loss: 4.0003
[09/27 23:16:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 23:16:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/27 23:17:07 visual_prompt]: Epoch 31 / 100: avg data time: 4.27e-02, avg batch time: 0.4993, average train loss: 4.0625
[09/27 23:17:08 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1695, average loss: 4.0703
[09/27 23:17:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/27 23:17:16 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2132, average loss: 4.1156
[09/27 23:17:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/27 23:17:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/27 23:17:24 visual_prompt]: Epoch 32 / 100: avg data time: 3.61e-02, avg batch time: 0.4932, average train loss: 4.0612
[09/27 23:17:25 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1698, average loss: 4.1342
[09/27 23:17:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 18.00	
[09/27 23:17:33 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2133, average loss: 4.2589
[09/27 23:17:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 13.78	
[09/27 23:17:33 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/27 23:17:41 visual_prompt]: Epoch 33 / 100: avg data time: 4.66e-02, avg batch time: 0.5026, average train loss: 4.0920
[09/27 23:17:43 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1695, average loss: 4.0789
[09/27 23:17:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.00	
[09/27 23:17:50 visual_prompt]: Inference (test):avg data time: 2.94e-04, avg batch time: 0.2139, average loss: 3.9988
[09/27 23:17:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.72	top5: 10.69	
[09/27 23:17:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/27 23:17:58 visual_prompt]: Epoch 34 / 100: avg data time: 4.14e-02, avg batch time: 0.4982, average train loss: 4.0402
[09/27 23:18:00 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1699, average loss: 4.0303
[09/27 23:18:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.00	
[09/27 23:18:07 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2136, average loss: 4.0175
[09/27 23:18:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.53	
[09/27 23:18:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/27 23:18:15 visual_prompt]: Epoch 35 / 100: avg data time: 4.85e-02, avg batch time: 0.5049, average train loss: 4.0827
[09/27 23:18:17 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1700, average loss: 4.0313
[09/27 23:18:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 14.50	
[09/27 23:18:24 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2134, average loss: 4.0860
[09/27 23:18:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 12.07	
[09/27 23:18:24 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/27 23:18:33 visual_prompt]: Epoch 36 / 100: avg data time: 3.89e-02, avg batch time: 0.4961, average train loss: 4.0617
[09/27 23:18:34 visual_prompt]: Inference (val):avg data time: 1.04e-04, avg batch time: 0.1761, average loss: 4.1524
[09/27 23:18:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 8.50	
[09/27 23:18:42 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2139, average loss: 4.1097
[09/27 23:18:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 11.28	
[09/27 23:18:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/27 23:18:50 visual_prompt]: Epoch 37 / 100: avg data time: 4.57e-02, avg batch time: 0.5022, average train loss: 4.1302
[09/27 23:18:52 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1695, average loss: 4.2468
[09/27 23:18:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 17.50	
[09/27 23:18:59 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2145, average loss: 4.3547
[09/27 23:18:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 13.72	
[09/27 23:18:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/27 23:19:07 visual_prompt]: Epoch 38 / 100: avg data time: 4.18e-02, avg batch time: 0.4989, average train loss: 4.2818
[09/27 23:19:09 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1697, average loss: 4.1639
[09/27 23:19:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 9.00	
[09/27 23:19:16 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2137, average loss: 4.1384
[09/27 23:19:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.77	top5: 11.81	
[09/27 23:19:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/27 23:19:24 visual_prompt]: Epoch 39 / 100: avg data time: 4.51e-02, avg batch time: 0.5013, average train loss: 4.2944
[09/27 23:19:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1695, average loss: 4.2040
[09/27 23:19:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 13.00	
[09/27 23:19:33 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2133, average loss: 4.1671
[09/27 23:19:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 12.71	
[09/27 23:19:33 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/27 23:19:42 visual_prompt]: Epoch 40 / 100: avg data time: 4.50e-02, avg batch time: 0.5015, average train loss: 4.0574
[09/27 23:19:43 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1693, average loss: 3.8944
[09/27 23:19:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 18.00	
[09/27 23:19:51 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2136, average loss: 3.9458
[09/27 23:19:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 13.99	
[09/27 23:19:51 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/27 23:19:59 visual_prompt]: Epoch 41 / 100: avg data time: 4.64e-02, avg batch time: 0.5026, average train loss: 4.0910
[09/27 23:20:00 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1694, average loss: 4.4400
[09/27 23:20:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.00	
[09/27 23:20:08 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2134, average loss: 4.3760
[09/27 23:20:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:20:08 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/27 23:20:16 visual_prompt]: Epoch 42 / 100: avg data time: 3.53e-02, avg batch time: 0.4930, average train loss: 4.0832
[09/27 23:20:18 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1696, average loss: 4.0909
[09/27 23:20:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 9.00	
[09/27 23:20:25 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2132, average loss: 4.0858
[09/27 23:20:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.70	
[09/27 23:20:25 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/27 23:20:33 visual_prompt]: Epoch 43 / 100: avg data time: 4.23e-02, avg batch time: 0.5003, average train loss: 4.3021
[09/27 23:20:35 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1698, average loss: 4.5655
[09/27 23:20:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.00	
[09/27 23:20:42 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2137, average loss: 4.7624
[09/27 23:20:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:20:42 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/27 23:20:50 visual_prompt]: Epoch 44 / 100: avg data time: 3.83e-02, avg batch time: 0.4953, average train loss: 4.6117
[09/27 23:20:52 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1699, average loss: 4.3368
[09/27 23:20:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.50	
[09/27 23:20:59 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2144, average loss: 4.2892
[09/27 23:20:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.74	
[09/27 23:20:59 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/27 23:21:08 visual_prompt]: Epoch 45 / 100: avg data time: 4.15e-02, avg batch time: 0.4987, average train loss: 4.3343
[09/27 23:21:09 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1695, average loss: 4.1528
[09/27 23:21:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 15.00	
[09/27 23:21:16 visual_prompt]: Inference (test):avg data time: 3.03e-04, avg batch time: 0.2142, average loss: 4.1700
[09/27 23:21:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:21:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/27 23:21:25 visual_prompt]: Epoch 46 / 100: avg data time: 4.62e-02, avg batch time: 0.5023, average train loss: 4.3006
[09/27 23:21:26 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1699, average loss: 4.5713
[09/27 23:21:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/27 23:21:33 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2151, average loss: 4.4947
[09/27 23:21:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.59	
[09/27 23:21:33 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/27 23:21:42 visual_prompt]: Epoch 47 / 100: avg data time: 4.24e-02, avg batch time: 0.4989, average train loss: 4.2784
[09/27 23:21:43 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1700, average loss: 4.0182
[09/27 23:21:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.00	
[09/27 23:21:51 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2141, average loss: 4.0678
[09/27 23:21:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:21:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/27 23:21:59 visual_prompt]: Epoch 48 / 100: avg data time: 4.51e-02, avg batch time: 0.5017, average train loss: 4.1444
[09/27 23:22:00 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1698, average loss: 4.1067
[09/27 23:22:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 12.50	
[09/27 23:22:08 visual_prompt]: Inference (test):avg data time: 3.08e-05, avg batch time: 0.2145, average loss: 4.1111
[09/27 23:22:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:22:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/27 23:22:16 visual_prompt]: Epoch 49 / 100: avg data time: 4.62e-02, avg batch time: 0.5029, average train loss: 4.0532
[09/27 23:22:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1698, average loss: 3.9881
[09/27 23:22:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.00	
[09/27 23:22:25 visual_prompt]: Inference (test):avg data time: 4.03e-05, avg batch time: 0.2146, average loss: 3.9767
[09/27 23:22:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.82	top5: 12.02	
[09/27 23:22:25 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/27 23:22:33 visual_prompt]: Epoch 50 / 100: avg data time: 4.16e-02, avg batch time: 0.4989, average train loss: 3.9731
[09/27 23:22:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1694, average loss: 4.0676
[09/27 23:22:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 13.50	
[09/27 23:22:42 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2132, average loss: 4.1110
[09/27 23:22:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 11.01	
[09/27 23:22:42 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/27 23:22:51 visual_prompt]: Epoch 51 / 100: avg data time: 4.76e-02, avg batch time: 0.5041, average train loss: 4.2330
[09/27 23:22:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1692, average loss: 4.1162
[09/27 23:22:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/27 23:23:00 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2137, average loss: 4.0919
[09/27 23:23:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.90	
[09/27 23:23:00 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/27 23:23:08 visual_prompt]: Epoch 52 / 100: avg data time: 4.86e-02, avg batch time: 0.5047, average train loss: 4.1051
[09/27 23:23:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1695, average loss: 3.9617
[09/27 23:23:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 14.00	
[09/27 23:23:17 visual_prompt]: Inference (test):avg data time: 3.72e-05, avg batch time: 0.2131, average loss: 4.0648
[09/27 23:23:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:23:17 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/27 23:23:25 visual_prompt]: Epoch 53 / 100: avg data time: 4.24e-02, avg batch time: 0.4983, average train loss: 4.0486
[09/27 23:23:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1694, average loss: 3.9621
[09/27 23:23:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.50	top5: 13.00	
[09/27 23:23:34 visual_prompt]: Inference (test):avg data time: 2.82e-05, avg batch time: 0.2140, average loss: 4.0405
[09/27 23:23:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.55	top5: 11.49	
[09/27 23:23:34 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/27 23:23:43 visual_prompt]: Epoch 54 / 100: avg data time: 4.90e-02, avg batch time: 0.5050, average train loss: 3.9877
[09/27 23:23:44 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1696, average loss: 3.9390
[09/27 23:23:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.50	
[09/27 23:23:52 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2133, average loss: 4.0181
[09/27 23:23:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.03	top5: 11.86	
[09/27 23:23:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/27 23:24:00 visual_prompt]: Epoch 55 / 100: avg data time: 4.89e-02, avg batch time: 0.5064, average train loss: 3.9794
[09/27 23:24:02 visual_prompt]: Inference (val):avg data time: 2.52e-04, avg batch time: 0.2323, average loss: 3.8863
[09/27 23:24:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.50	
[09/27 23:24:09 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2135, average loss: 3.9315
[09/27 23:24:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 12.39	
[09/27 23:24:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/27 23:24:17 visual_prompt]: Epoch 56 / 100: avg data time: 3.95e-02, avg batch time: 0.4965, average train loss: 3.9866
[09/27 23:24:19 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1699, average loss: 4.0977
[09/27 23:24:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 9.50	
[09/27 23:24:26 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2142, average loss: 4.0361
[09/27 23:24:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.87	top5: 10.85	
[09/27 23:24:26 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/27 23:24:35 visual_prompt]: Epoch 57 / 100: avg data time: 4.68e-02, avg batch time: 0.5028, average train loss: 4.0328
[09/27 23:24:36 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1696, average loss: 4.0442
[09/27 23:24:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/27 23:24:43 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.2136, average loss: 4.0347
[09/27 23:24:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.17	
[09/27 23:24:43 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/27 23:24:52 visual_prompt]: Epoch 58 / 100: avg data time: 4.99e-02, avg batch time: 0.5061, average train loss: 3.9905
[09/27 23:24:53 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1698, average loss: 3.9047
[09/27 23:24:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 15.00	
[09/27 23:25:01 visual_prompt]: Inference (test):avg data time: 2.90e-05, avg batch time: 0.2135, average loss: 3.9711
[09/27 23:25:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.14	top5: 10.64	
[09/27 23:25:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/27 23:25:09 visual_prompt]: Epoch 59 / 100: avg data time: 4.84e-02, avg batch time: 0.5047, average train loss: 3.9635
[09/27 23:25:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1697, average loss: 3.8768
[09/27 23:25:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 15.00	
[09/27 23:25:18 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2146, average loss: 3.9057
[09/27 23:25:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 11.49	
[09/27 23:25:18 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/27 23:25:26 visual_prompt]: Epoch 60 / 100: avg data time: 4.80e-02, avg batch time: 0.5037, average train loss: 3.9588
[09/27 23:25:28 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1698, average loss: 3.8829
[09/27 23:25:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 13.00	
[09/27 23:25:35 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2137, average loss: 3.9102
[09/27 23:25:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.55	top5: 12.34	
[09/27 23:25:35 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/27 23:25:44 visual_prompt]: Epoch 61 / 100: avg data time: 4.38e-02, avg batch time: 0.5000, average train loss: 3.9211
[09/27 23:25:45 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1697, average loss: 4.0460
[09/27 23:25:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.50	
[09/27 23:25:53 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2153, average loss: 4.0513
[09/27 23:25:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.37	
[09/27 23:25:53 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/27 23:26:01 visual_prompt]: Epoch 62 / 100: avg data time: 3.55e-02, avg batch time: 0.4918, average train loss: 3.9449
[09/27 23:26:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1695, average loss: 3.9153
[09/27 23:26:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/27 23:26:10 visual_prompt]: Inference (test):avg data time: 3.00e-05, avg batch time: 0.2149, average loss: 3.9404
[09/27 23:26:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.65	
[09/27 23:26:10 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/27 23:26:18 visual_prompt]: Epoch 63 / 100: avg data time: 4.66e-02, avg batch time: 0.5032, average train loss: 3.9163
[09/27 23:26:19 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1701, average loss: 3.8943
[09/27 23:26:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 14.00	
[09/27 23:26:27 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2142, average loss: 3.8978
[09/27 23:26:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.09	top5: 13.40	
[09/27 23:26:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/27 23:26:35 visual_prompt]: Epoch 64 / 100: avg data time: 4.42e-02, avg batch time: 0.5027, average train loss: 3.9251
[09/27 23:26:37 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1694, average loss: 3.8571
[09/27 23:26:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 16.00	
[09/27 23:26:44 visual_prompt]: Inference (test):avg data time: 2.80e-05, avg batch time: 0.2136, average loss: 3.9266
[09/27 23:26:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.70	
[09/27 23:26:44 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/27 23:26:52 visual_prompt]: Epoch 65 / 100: avg data time: 4.40e-02, avg batch time: 0.5005, average train loss: 3.9187
[09/27 23:26:54 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1693, average loss: 3.8738
[09/27 23:26:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.00	
[09/27 23:27:01 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2139, average loss: 3.9130
[09/27 23:27:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.14	top5: 12.61	
[09/27 23:27:01 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/27 23:27:10 visual_prompt]: Epoch 66 / 100: avg data time: 4.53e-02, avg batch time: 0.5019, average train loss: 3.8971
[09/27 23:27:11 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1700, average loss: 3.8400
[09/27 23:27:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 14.00	
[09/27 23:27:19 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2149, average loss: 3.8912
[09/27 23:27:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.40	top5: 14.20	
[09/27 23:27:19 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/27 23:27:27 visual_prompt]: Epoch 67 / 100: avg data time: 5.26e-02, avg batch time: 0.5088, average train loss: 3.8647
[09/27 23:27:29 visual_prompt]: Inference (val):avg data time: 4.55e-05, avg batch time: 0.1697, average loss: 3.9510
[09/27 23:27:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 13.00	
[09/27 23:27:36 visual_prompt]: Inference (test):avg data time: 2.82e-05, avg batch time: 0.2147, average loss: 4.0492
[09/27 23:27:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 11.12	
[09/27 23:27:36 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/27 23:27:44 visual_prompt]: Epoch 68 / 100: avg data time: 5.20e-02, avg batch time: 0.5087, average train loss: 3.8788
[09/27 23:27:46 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1698, average loss: 3.8443
[09/27 23:27:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.00	
[09/27 23:27:53 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2137, average loss: 3.8804
[09/27 23:27:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.14	top5: 13.35	
[09/27 23:27:53 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/27 23:28:02 visual_prompt]: Epoch 69 / 100: avg data time: 3.72e-02, avg batch time: 0.4955, average train loss: 3.8643
[09/27 23:28:03 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1700, average loss: 3.9049
[09/27 23:28:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 14.00	
[09/27 23:28:10 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2149, average loss: 4.0255
[09/27 23:28:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 11.01	
[09/27 23:28:10 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/27 23:28:19 visual_prompt]: Epoch 70 / 100: avg data time: 4.37e-02, avg batch time: 0.5011, average train loss: 3.8816
[09/27 23:28:20 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1698, average loss: 3.8552
[09/27 23:28:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 14.50	
[09/27 23:28:28 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2139, average loss: 3.9232
[09/27 23:28:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.03	top5: 12.82	
[09/27 23:28:28 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/27 23:28:36 visual_prompt]: Epoch 71 / 100: avg data time: 4.40e-02, avg batch time: 0.5007, average train loss: 3.8300
[09/27 23:28:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1696, average loss: 3.8362
[09/27 23:28:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.50	top5: 17.00	
[09/27 23:28:45 visual_prompt]: Inference (test):avg data time: 2.87e-05, avg batch time: 0.2140, average loss: 3.8860
[09/27 23:28:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.72	top5: 13.46	
[09/27 23:28:45 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/27 23:28:53 visual_prompt]: Epoch 72 / 100: avg data time: 4.15e-02, avg batch time: 0.4989, average train loss: 3.8003
[09/27 23:28:55 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1698, average loss: 3.7957
[09/27 23:28:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 14.50	
[09/27 23:29:02 visual_prompt]: Inference (test):avg data time: 1.49e-04, avg batch time: 0.2141, average loss: 3.8549
[09/27 23:29:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 14.04	
[09/27 23:29:02 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/27 23:29:10 visual_prompt]: Epoch 73 / 100: avg data time: 4.81e-02, avg batch time: 0.5057, average train loss: 3.8524
[09/27 23:29:12 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1700, average loss: 3.9248
[09/27 23:29:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.50	
[09/27 23:29:19 visual_prompt]: Inference (test):avg data time: 2.84e-05, avg batch time: 0.2143, average loss: 3.9709
[09/27 23:29:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/27 23:29:19 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/27 23:29:28 visual_prompt]: Epoch 74 / 100: avg data time: 3.52e-02, avg batch time: 0.4939, average train loss: 3.9181
[09/27 23:29:29 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1698, average loss: 3.8245
[09/27 23:29:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 14.50	
[09/27 23:29:36 visual_prompt]: Inference (test):avg data time: 3.03e-04, avg batch time: 0.2141, average loss: 3.8543
[09/27 23:29:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 11.81	
[09/27 23:29:37 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/27 23:29:45 visual_prompt]: Epoch 75 / 100: avg data time: 4.99e-02, avg batch time: 0.5066, average train loss: 3.8636
[09/27 23:29:46 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1698, average loss: 3.8012
[09/27 23:29:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 17.00	
[09/27 23:29:54 visual_prompt]: Inference (test):avg data time: 4.00e-05, avg batch time: 0.2143, average loss: 3.8455
[09/27 23:29:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.88	top5: 15.74	
[09/27 23:29:54 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/27 23:30:02 visual_prompt]: Epoch 76 / 100: avg data time: 4.09e-02, avg batch time: 0.4981, average train loss: 3.8378
[09/27 23:30:04 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1696, average loss: 3.7546
[09/27 23:30:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 18.50	
[09/27 23:30:11 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2143, average loss: 3.8333
[09/27 23:30:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.82	top5: 13.14	
[09/27 23:30:11 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/27 23:30:19 visual_prompt]: Epoch 77 / 100: avg data time: 4.53e-02, avg batch time: 0.5016, average train loss: 3.8049
[09/27 23:30:21 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1697, average loss: 3.7790
[09/27 23:30:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.00	top5: 16.50	
[09/27 23:30:28 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2136, average loss: 3.8557
[09/27 23:30:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.36	top5: 15.37	
[09/27 23:30:28 visual_prompt]: Best epoch 77: best metric: 0.080
[09/27 23:30:28 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/27 23:30:37 visual_prompt]: Epoch 78 / 100: avg data time: 5.15e-02, avg batch time: 0.5080, average train loss: 3.7987
[09/27 23:30:38 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1697, average loss: 3.7227
[09/27 23:30:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 19.50	
[09/27 23:30:46 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2144, average loss: 3.8184
[09/27 23:30:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.83	top5: 15.69	
[09/27 23:30:46 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/27 23:30:54 visual_prompt]: Epoch 79 / 100: avg data time: 4.72e-02, avg batch time: 0.5037, average train loss: 3.7667
[09/27 23:30:55 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1700, average loss: 3.6636
[09/27 23:30:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 20.50	
[09/27 23:31:03 visual_prompt]: Inference (test):avg data time: 1.96e-04, avg batch time: 0.2140, average loss: 3.8049
[09/27 23:31:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.67	top5: 17.13	
[09/27 23:31:03 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/27 23:31:11 visual_prompt]: Epoch 80 / 100: avg data time: 4.64e-02, avg batch time: 0.5038, average train loss: 3.7596
[09/27 23:31:13 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1698, average loss: 3.6897
[09/27 23:31:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 20.50	
[09/27 23:31:20 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2148, average loss: 3.7826
[09/27 23:31:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.41	top5: 18.35	
[09/27 23:31:20 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/27 23:31:28 visual_prompt]: Epoch 81 / 100: avg data time: 4.92e-02, avg batch time: 0.5055, average train loss: 3.7304
[09/27 23:31:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1698, average loss: 3.6530
[09/27 23:31:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 23.50	
[09/27 23:31:37 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2160, average loss: 3.8020
[09/27 23:31:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.00	top5: 18.14	
[09/27 23:31:37 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/27 23:31:46 visual_prompt]: Epoch 82 / 100: avg data time: 4.44e-02, avg batch time: 0.5047, average train loss: 3.7592
[09/27 23:31:47 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1695, average loss: 3.6899
[09/27 23:31:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 23.50	
[09/27 23:31:55 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2141, average loss: 3.7932
[09/27 23:31:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.94	top5: 16.97	
[09/27 23:31:55 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/27 23:32:03 visual_prompt]: Epoch 83 / 100: avg data time: 3.87e-02, avg batch time: 0.4967, average train loss: 3.7188
[09/27 23:32:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1702, average loss: 3.6368
[09/27 23:32:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 25.00	
[09/27 23:32:12 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2148, average loss: 3.7995
[09/27 23:32:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.68	top5: 18.83	
[09/27 23:32:12 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/27 23:32:20 visual_prompt]: Epoch 84 / 100: avg data time: 3.74e-02, avg batch time: 0.4951, average train loss: 3.8044
[09/27 23:32:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1701, average loss: 3.7032
[09/27 23:32:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 16.50	
[09/27 23:32:29 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2142, average loss: 3.7818
[09/27 23:32:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.59	top5: 16.86	
[09/27 23:32:29 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/27 23:32:37 visual_prompt]: Epoch 85 / 100: avg data time: 4.34e-02, avg batch time: 0.5012, average train loss: 3.7192
[09/27 23:32:39 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1701, average loss: 3.6181
[09/27 23:32:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.00	top5: 25.50	
[09/27 23:32:46 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2139, average loss: 3.7865
[09/27 23:32:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.41	top5: 19.79	
[09/27 23:32:46 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/27 23:32:54 visual_prompt]: Epoch 86 / 100: avg data time: 4.35e-02, avg batch time: 0.5001, average train loss: 3.7090
[09/27 23:32:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1700, average loss: 3.6903
[09/27 23:32:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 21.00	
[09/27 23:33:03 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2139, average loss: 3.8032
[09/27 23:33:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.79	top5: 17.50	
[09/27 23:33:03 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/27 23:33:12 visual_prompt]: Epoch 87 / 100: avg data time: 3.36e-02, avg batch time: 0.4913, average train loss: 3.6745
[09/27 23:33:13 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1696, average loss: 3.6178
[09/27 23:33:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 30.00	
[09/27 23:33:20 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2149, average loss: 3.7748
[09/27 23:33:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.16	top5: 20.37	
[09/27 23:33:20 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/27 23:33:29 visual_prompt]: Epoch 88 / 100: avg data time: 3.84e-02, avg batch time: 0.4955, average train loss: 3.6471
[09/27 23:33:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1696, average loss: 3.5555
[09/27 23:33:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 9.50	top5: 35.00	
[09/27 23:33:37 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2149, average loss: 3.7163
[09/27 23:33:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.37	top5: 22.66	
[09/27 23:33:37 visual_prompt]: Best epoch 88: best metric: 0.095
[09/27 23:33:37 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/27 23:33:46 visual_prompt]: Epoch 89 / 100: avg data time: 3.60e-02, avg batch time: 0.4948, average train loss: 3.5168
[09/27 23:33:47 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1697, average loss: 3.3180
[09/27 23:33:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 13.50	top5: 40.00	
[09/27 23:33:55 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2139, average loss: 3.5094
[09/27 23:33:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 12.18	top5: 33.09	
[09/27 23:33:55 visual_prompt]: Best epoch 89: best metric: 0.135
[09/27 23:33:55 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/27 23:34:03 visual_prompt]: Epoch 90 / 100: avg data time: 4.39e-02, avg batch time: 0.5006, average train loss: 3.2202
[09/27 23:34:04 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1700, average loss: 2.9801
[09/27 23:34:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 28.00	top5: 54.00	
[09/27 23:34:12 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2143, average loss: 3.2236
[09/27 23:34:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 17.93	top5: 43.83	
[09/27 23:34:12 visual_prompt]: Best epoch 90: best metric: 0.280
[09/27 23:34:12 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/27 23:34:20 visual_prompt]: Epoch 91 / 100: avg data time: 3.91e-02, avg batch time: 0.4958, average train loss: 2.7425
[09/27 23:34:21 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1699, average loss: 2.3714
[09/27 23:34:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 37.00	top5: 76.50	
[09/27 23:34:29 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2139, average loss: 2.7290
[09/27 23:34:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 29.84	top5: 60.96	
[09/27 23:34:29 visual_prompt]: Best epoch 91: best metric: 0.370
[09/27 23:34:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/27 23:34:37 visual_prompt]: Epoch 92 / 100: avg data time: 3.96e-02, avg batch time: 0.4984, average train loss: 2.0216
[09/27 23:34:39 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1702, average loss: 1.7143
[09/27 23:34:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 55.50	top5: 90.00	
[09/27 23:34:46 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2141, average loss: 2.2187
[09/27 23:34:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 41.44	top5: 72.55	
[09/27 23:34:46 visual_prompt]: Best epoch 92: best metric: 0.555
[09/27 23:34:46 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/27 23:34:54 visual_prompt]: Epoch 93 / 100: avg data time: 4.64e-02, avg batch time: 0.5035, average train loss: 1.5288
[09/27 23:34:56 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1700, average loss: 1.3655
[09/27 23:34:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 66.50	top5: 92.50	
[09/27 23:35:03 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2142, average loss: 2.0041
[09/27 23:35:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 46.33	top5: 77.50	
[09/27 23:35:03 visual_prompt]: Best epoch 93: best metric: 0.665
[09/27 23:35:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/27 23:35:12 visual_prompt]: Epoch 94 / 100: avg data time: 4.71e-02, avg batch time: 0.5041, average train loss: 1.1931
[09/27 23:35:13 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1698, average loss: 1.0508
[09/27 23:35:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 78.00	top5: 97.50	
[09/27 23:35:20 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2140, average loss: 1.8232
[09/27 23:35:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 50.05	top5: 80.85	
[09/27 23:35:21 visual_prompt]: Best epoch 94: best metric: 0.780
[09/27 23:35:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/27 23:35:29 visual_prompt]: Epoch 95 / 100: avg data time: 4.54e-02, avg batch time: 0.5027, average train loss: 0.9442
[09/27 23:35:30 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1703, average loss: 0.8115
[09/27 23:35:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 84.50	top5: 98.00	
[09/27 23:35:38 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2143, average loss: 1.7159
[09/27 23:35:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.34	top5: 83.03	
[09/27 23:35:38 visual_prompt]: Best epoch 95: best metric: 0.845
[09/27 23:35:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/27 23:35:46 visual_prompt]: Epoch 96 / 100: avg data time: 4.87e-02, avg batch time: 0.5055, average train loss: 0.7797
[09/27 23:35:48 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1700, average loss: 0.7154
[09/27 23:35:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 86.00	top5: 99.00	
[09/27 23:35:55 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2143, average loss: 1.6689
[09/27 23:35:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.56	top5: 83.14	
[09/27 23:35:55 visual_prompt]: Best epoch 96: best metric: 0.860
[09/27 23:35:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/27 23:36:03 visual_prompt]: Epoch 97 / 100: avg data time: 3.97e-02, avg batch time: 0.4966, average train loss: 0.6773
[09/27 23:36:05 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1704, average loss: 0.6370
[09/27 23:36:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.00	top5: 99.00	
[09/27 23:36:12 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2139, average loss: 1.6493
[09/27 23:36:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 54.63	top5: 83.99	
[09/27 23:36:12 visual_prompt]: Best epoch 97: best metric: 0.900
[09/27 23:36:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/27 23:36:21 visual_prompt]: Epoch 98 / 100: avg data time: 4.75e-02, avg batch time: 0.5042, average train loss: 0.6131
[09/27 23:36:22 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1698, average loss: 0.5864
[09/27 23:36:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 90.50	top5: 99.00	
[09/27 23:36:30 visual_prompt]: Inference (test):avg data time: 4.46e-05, avg batch time: 0.2145, average loss: 1.6308
[09/27 23:36:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.05	top5: 83.78	
[09/27 23:36:30 visual_prompt]: Best epoch 98: best metric: 0.905
[09/27 23:36:30 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/27 23:36:38 visual_prompt]: Epoch 99 / 100: avg data time: 3.81e-02, avg batch time: 0.4957, average train loss: 0.5721
[09/27 23:36:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1695, average loss: 0.5670
[09/27 23:36:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 99.00	
[09/27 23:36:47 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2138, average loss: 1.6197
[09/27 23:36:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.37	top5: 84.20	
[09/27 23:36:47 visual_prompt]: Best epoch 99: best metric: 0.925
[09/27 23:36:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/27 23:36:55 visual_prompt]: Epoch 100 / 100: avg data time: 4.01e-02, avg batch time: 0.4986, average train loss: 0.5531
[09/27 23:36:57 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1700, average loss: 0.5597
[09/27 23:36:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 99.00	
[09/27 23:37:04 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2143, average loss: 1.6167
[09/27 23:37:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 55.74	top5: 84.10	
[09/27 23:37:04 visual_prompt]: Rank of current process: 0. World size: 1
[09/27 23:37:04 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/27 23:37:04 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/27 23:37:04 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/27 23:37:04 visual_prompt]: Training with config:
[09/27 23:37:04 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dtd/sup_vitb16_imagenet21k/prompt50/crop224/test/seed5168/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 5168, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dtd', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 47, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/27 23:37:04 visual_prompt]: Loading training data...
[09/27 23:37:04 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:37:07 visual_prompt]: Number of images: 1000
[09/27 23:37:07 visual_prompt]: Number of classes: 47 / 47
[09/27 23:37:07 visual_prompt]: Loading validation data...
[09/27 23:37:07 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:37:07 visual_prompt]: Number of images: 200
[09/27 23:37:07 visual_prompt]: Number of classes: 47 / 47
[09/27 23:37:07 visual_prompt]: Loading test data...
[09/27 23:37:07 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/27 23:37:12 visual_prompt]: Number of images: 1880
[09/27 23:37:12 visual_prompt]: Number of classes: 47 / 47
[09/27 23:37:12 visual_prompt]: Constructing models...
[09/27 23:37:14 visual_prompt]: Total Parameters: 86295599	 Gradient Parameters: 496943
[09/27 23:37:14 visual_prompt]: tuned percent:0.576
[09/27 23:37:14 visual_prompt]: Device used for model: 0
[09/27 23:37:14 visual_prompt]: Setting up Evaluator...
[09/27 23:37:14 visual_prompt]: Setting up Trainer...
[09/27 23:37:14 visual_prompt]: 	Setting up the optimizer...
[09/27 23:37:14 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/27 23:37:23 visual_prompt]: Epoch 1 / 100: avg data time: 4.56e-02, avg batch time: 0.4985, average train loss: 3.9392
[09/27 23:37:24 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1688, average loss: 3.9420
[09/27 23:37:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/27 23:37:31 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2131, average loss: 3.9543
[09/27 23:37:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.81	top5: 11.44	
[09/27 23:37:31 visual_prompt]: Best epoch 1: best metric: 0.025
[09/27 23:37:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/27 23:37:40 visual_prompt]: Epoch 2 / 100: avg data time: 4.53e-02, avg batch time: 0.5001, average train loss: 3.9480
[09/27 23:37:41 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1694, average loss: 3.8682
[09/27 23:37:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.50	
[09/27 23:37:49 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2130, average loss: 3.8914
[09/27 23:37:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.77	top5: 11.28	
[09/27 23:37:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/27 23:37:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.51e-02, avg batch time: 0.5010, average train loss: 3.9661
[09/27 23:37:58 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1694, average loss: 3.9313
[09/27 23:37:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 18.00	
[09/27 23:38:06 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2130, average loss: 3.9197
[09/27 23:38:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.62	top5: 15.53	
[09/27 23:38:06 visual_prompt]: Best epoch 3: best metric: 0.045
[09/27 23:38:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/27 23:38:14 visual_prompt]: Epoch 4 / 100: avg data time: 4.57e-02, avg batch time: 0.5020, average train loss: 3.9223
[09/27 23:38:16 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1696, average loss: 3.8110
[09/27 23:38:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 17.50	
[09/27 23:38:23 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2138, average loss: 3.8528
[09/27 23:38:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.83	top5: 15.96	
[09/27 23:38:23 visual_prompt]: Best epoch 4: best metric: 0.050
[09/27 23:38:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/27 23:38:31 visual_prompt]: Epoch 5 / 100: avg data time: 4.61e-02, avg batch time: 0.5017, average train loss: 3.9517
[09/27 23:38:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1696, average loss: 3.8217
[09/27 23:38:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 18.00	
[09/27 23:38:40 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2141, average loss: 3.8625
[09/27 23:38:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.20	top5: 16.65	
[09/27 23:38:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/27 23:38:49 visual_prompt]: Epoch 6 / 100: avg data time: 4.65e-02, avg batch time: 0.5016, average train loss: 4.0690
[09/27 23:38:50 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1693, average loss: 4.0282
[09/27 23:38:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 14.50	
[09/27 23:38:58 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2131, average loss: 4.0861
[09/27 23:38:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.06	
[09/27 23:38:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/27 23:39:06 visual_prompt]: Epoch 7 / 100: avg data time: 3.52e-02, avg batch time: 0.4915, average train loss: 4.2695
[09/27 23:39:07 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1692, average loss: 4.1380
[09/27 23:39:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.00	
[09/27 23:39:15 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2133, average loss: 4.2356
[09/27 23:39:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 10.64	
[09/27 23:39:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/27 23:39:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.71e-02, avg batch time: 0.5025, average train loss: 4.1776
[09/27 23:39:25 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1697, average loss: 3.9750
[09/27 23:39:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 17.00	
[09/27 23:39:32 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2140, average loss: 4.0285
[09/27 23:39:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.66	top5: 13.78	
[09/27 23:39:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/27 23:39:40 visual_prompt]: Epoch 9 / 100: avg data time: 4.64e-02, avg batch time: 0.5024, average train loss: 4.0714
[09/27 23:39:42 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1695, average loss: 4.2167
[09/27 23:39:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 14.50	
[09/27 23:39:49 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2145, average loss: 4.3444
[09/27 23:39:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.18	
[09/27 23:39:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/27 23:39:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.56e-02, avg batch time: 0.5026, average train loss: 4.1899
[09/27 23:39:59 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1698, average loss: 4.1025
[09/27 23:39:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 14.50	
[09/27 23:40:07 visual_prompt]: Inference (test):avg data time: 3.07e-05, avg batch time: 0.2142, average loss: 4.1350
[09/27 23:40:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.39	top5: 11.49	
[09/27 23:40:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/27 23:40:15 visual_prompt]: Epoch 11 / 100: avg data time: 4.25e-02, avg batch time: 0.4993, average train loss: 4.1234
[09/27 23:40:16 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1698, average loss: 3.9392
[09/27 23:40:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 14.50	
[09/27 23:40:24 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2133, average loss: 4.0408
[09/27 23:40:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:40:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/27 23:40:32 visual_prompt]: Epoch 12 / 100: avg data time: 4.58e-02, avg batch time: 0.5023, average train loss: 4.0845
[09/27 23:40:34 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 4.0274
[09/27 23:40:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 12.50	
[09/27 23:40:41 visual_prompt]: Inference (test):avg data time: 2.69e-04, avg batch time: 0.2140, average loss: 3.9921
[09/27 23:40:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.87	top5: 10.85	
[09/27 23:40:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/27 23:40:49 visual_prompt]: Epoch 13 / 100: avg data time: 4.14e-02, avg batch time: 0.4970, average train loss: 4.1302
[09/27 23:40:51 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1696, average loss: 4.4296
[09/27 23:40:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.00	
[09/27 23:40:58 visual_prompt]: Inference (test):avg data time: 3.84e-04, avg batch time: 0.2144, average loss: 4.4671
[09/27 23:40:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.59	
[09/27 23:40:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/27 23:41:07 visual_prompt]: Epoch 14 / 100: avg data time: 3.86e-02, avg batch time: 0.4962, average train loss: 4.2047
[09/27 23:41:08 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1696, average loss: 4.0583
[09/27 23:41:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 13.00	
[09/27 23:41:15 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2135, average loss: 4.1900
[09/27 23:41:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.53	
[09/27 23:41:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/27 23:41:24 visual_prompt]: Epoch 15 / 100: avg data time: 4.61e-02, avg batch time: 0.5022, average train loss: 4.1498
[09/27 23:41:25 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1698, average loss: 4.0584
[09/27 23:41:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.00	
[09/27 23:41:33 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2141, average loss: 4.0848
[09/27 23:41:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.17	
[09/27 23:41:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/27 23:41:41 visual_prompt]: Epoch 16 / 100: avg data time: 4.53e-02, avg batch time: 0.5012, average train loss: 4.1178
[09/27 23:41:43 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1694, average loss: 4.3398
[09/27 23:41:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 8.00	
[09/27 23:41:50 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2137, average loss: 4.2686
[09/27 23:41:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:41:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/27 23:41:58 visual_prompt]: Epoch 17 / 100: avg data time: 4.57e-02, avg batch time: 0.5019, average train loss: 4.1251
[09/27 23:42:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1695, average loss: 4.0583
[09/27 23:42:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/27 23:42:07 visual_prompt]: Inference (test):avg data time: 5.87e-04, avg batch time: 0.2149, average loss: 4.0675
[09/27 23:42:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.34	
[09/27 23:42:07 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/27 23:42:16 visual_prompt]: Epoch 18 / 100: avg data time: 4.60e-02, avg batch time: 0.5020, average train loss: 4.1215
[09/27 23:42:17 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1694, average loss: 4.1748
[09/27 23:42:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/27 23:42:25 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2137, average loss: 4.1952
[09/27 23:42:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.86	
[09/27 23:42:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/27 23:42:33 visual_prompt]: Epoch 19 / 100: avg data time: 3.40e-02, avg batch time: 0.4929, average train loss: 4.1169
[09/27 23:42:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1700, average loss: 4.1208
[09/27 23:42:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/27 23:42:42 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2141, average loss: 4.1970
[09/27 23:42:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 10.64	
[09/27 23:42:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/27 23:42:50 visual_prompt]: Epoch 20 / 100: avg data time: 4.81e-02, avg batch time: 0.5044, average train loss: 5.1891
[09/27 23:42:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1699, average loss: 7.7313
[09/27 23:42:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 12.00	
[09/27 23:42:59 visual_prompt]: Inference (test):avg data time: 5.13e-04, avg batch time: 0.2143, average loss: 7.4862
[09/27 23:42:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:42:59 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/27 23:43:08 visual_prompt]: Epoch 21 / 100: avg data time: 4.25e-02, avg batch time: 0.4999, average train loss: 7.5068
[09/27 23:43:09 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1694, average loss: 6.6362
[09/27 23:43:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 12.50	
[09/27 23:43:16 visual_prompt]: Inference (test):avg data time: 5.40e-04, avg batch time: 0.2148, average loss: 6.4111
[09/27 23:43:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.81	top5: 10.80	
[09/27 23:43:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/27 23:43:25 visual_prompt]: Epoch 22 / 100: avg data time: 5.16e-02, avg batch time: 0.5073, average train loss: 6.1235
[09/27 23:43:26 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1696, average loss: 5.1782
[09/27 23:43:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 8.00	
[09/27 23:43:34 visual_prompt]: Inference (test):avg data time: 2.91e-05, avg batch time: 0.2137, average loss: 5.1121
[09/27 23:43:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.28	
[09/27 23:43:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/27 23:43:42 visual_prompt]: Epoch 23 / 100: avg data time: 4.80e-02, avg batch time: 0.5056, average train loss: 4.6129
[09/27 23:43:44 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1699, average loss: 4.2562
[09/27 23:43:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/27 23:43:51 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.2145, average loss: 4.3958
[09/27 23:43:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.74	
[09/27 23:43:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/27 23:43:59 visual_prompt]: Epoch 24 / 100: avg data time: 4.06e-02, avg batch time: 0.4969, average train loss: 4.4992
[09/27 23:44:01 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1697, average loss: 4.3802
[09/27 23:44:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 15.00	
[09/27 23:44:08 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2133, average loss: 4.5618
[09/27 23:44:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.01	
[09/27 23:44:08 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/27 23:44:17 visual_prompt]: Epoch 25 / 100: avg data time: 4.45e-02, avg batch time: 0.5020, average train loss: 4.4028
[09/27 23:44:18 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1699, average loss: 4.7600
[09/27 23:44:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 7.50	
[09/27 23:44:26 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2148, average loss: 4.5585
[09/27 23:44:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/27 23:44:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/27 23:44:34 visual_prompt]: Epoch 26 / 100: avg data time: 3.97e-02, avg batch time: 0.4959, average train loss: 4.4332
[09/27 23:44:35 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1699, average loss: 4.0985
[09/27 23:44:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.50	
[09/27 23:44:43 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2140, average loss: 4.1525
[09/27 23:44:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.45	top5: 11.65	
[09/27 23:44:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/27 23:44:51 visual_prompt]: Epoch 27 / 100: avg data time: 5.12e-02, avg batch time: 0.5079, average train loss: 4.2474
[09/27 23:44:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1700, average loss: 5.4486
[09/27 23:44:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/27 23:45:00 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2141, average loss: 5.5553
[09/27 23:45:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/27 23:45:00 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/27 23:45:08 visual_prompt]: Epoch 28 / 100: avg data time: 4.13e-02, avg batch time: 0.4995, average train loss: 4.7718
[09/27 23:45:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1696, average loss: 4.5823
[09/27 23:45:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.00	
[09/27 23:45:17 visual_prompt]: Inference (test):avg data time: 4.77e-05, avg batch time: 0.2133, average loss: 4.5510
[09/27 23:45:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.81	
[09/27 23:45:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/27 23:45:26 visual_prompt]: Epoch 29 / 100: avg data time: 4.47e-02, avg batch time: 0.5016, average train loss: 4.8401
[09/27 23:45:27 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1696, average loss: 4.9981
[09/27 23:45:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.00	
[09/27 23:45:35 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2138, average loss: 4.7735
[09/27 23:45:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/27 23:45:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/27 23:45:43 visual_prompt]: Epoch 30 / 100: avg data time: 4.50e-02, avg batch time: 0.5023, average train loss: 4.6975
[09/27 23:45:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 5.1021
[09/27 23:45:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.50	
[09/27 23:45:52 visual_prompt]: Inference (test):avg data time: 4.02e-05, avg batch time: 0.2138, average loss: 4.7397
[09/27 23:45:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.29	top5: 11.97	
[09/27 23:45:52 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/27 23:46:00 visual_prompt]: Epoch 31 / 100: avg data time: 3.89e-02, avg batch time: 0.4971, average train loss: 4.4277
[09/27 23:46:02 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1699, average loss: 4.5004
[09/27 23:46:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 7.50	
[09/27 23:46:09 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2142, average loss: 4.3111
[09/27 23:46:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.19	top5: 10.64	
[09/27 23:46:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/27 23:46:18 visual_prompt]: Epoch 32 / 100: avg data time: 4.67e-02, avg batch time: 0.5029, average train loss: 4.1606
[09/27 23:46:19 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1698, average loss: 4.2353
[09/27 23:46:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.00	
[09/27 23:46:27 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2142, average loss: 4.2145
[09/27 23:46:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 11.70	
[09/27 23:46:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/27 23:46:35 visual_prompt]: Epoch 33 / 100: avg data time: 4.89e-02, avg batch time: 0.5051, average train loss: 4.0756
[09/27 23:46:36 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1700, average loss: 4.1622
[09/27 23:46:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 13.00	
[09/27 23:46:44 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2144, average loss: 4.1100
[09/27 23:46:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.55	top5: 13.62	
[09/27 23:46:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/27 23:46:52 visual_prompt]: Epoch 34 / 100: avg data time: 4.80e-02, avg batch time: 0.5047, average train loss: 3.9711
[09/27 23:46:54 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1698, average loss: 4.1719
[09/27 23:46:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.00	
[09/27 23:47:01 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2141, average loss: 4.0630
[09/27 23:47:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.16	top5: 12.93	
[09/27 23:47:01 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/27 23:47:10 visual_prompt]: Epoch 35 / 100: avg data time: 5.10e-02, avg batch time: 0.5073, average train loss: 3.9940
[09/27 23:47:11 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1698, average loss: 4.2130
[09/27 23:47:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.50	
[09/27 23:47:18 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2151, average loss: 4.3355
[09/27 23:47:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.93	top5: 11.86	
[09/27 23:47:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/27 23:47:27 visual_prompt]: Epoch 36 / 100: avg data time: 5.10e-02, avg batch time: 0.5073, average train loss: 4.0522
[09/27 23:47:28 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1695, average loss: 3.9931
[09/27 23:47:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 17.00	
[09/27 23:47:36 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2148, average loss: 4.0505
[09/27 23:47:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 16.38	
[09/27 23:47:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/27 23:47:44 visual_prompt]: Epoch 37 / 100: avg data time: 4.75e-02, avg batch time: 0.5041, average train loss: 3.7390
[09/27 23:47:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1699, average loss: 3.7403
[09/27 23:47:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 24.00	
[09/27 23:47:53 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2143, average loss: 3.8306
[09/27 23:47:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.53	top5: 20.80	
[09/27 23:47:53 visual_prompt]: Best epoch 37: best metric: 0.065
[09/27 23:47:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/27 23:48:01 visual_prompt]: Epoch 38 / 100: avg data time: 3.62e-02, avg batch time: 0.4938, average train loss: 4.0859
[09/27 23:48:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1695, average loss: 5.0176
[09/27 23:48:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.50	
[09/27 23:48:10 visual_prompt]: Inference (test):avg data time: 5.72e-04, avg batch time: 0.2150, average loss: 4.9964
[09/27 23:48:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.72	top5: 11.49	
[09/27 23:48:10 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/27 23:48:19 visual_prompt]: Epoch 39 / 100: avg data time: 5.11e-02, avg batch time: 0.5074, average train loss: 4.3653
[09/27 23:48:20 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1700, average loss: 4.0496
[09/27 23:48:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 20.00	
[09/27 23:48:28 visual_prompt]: Inference (test):avg data time: 1.15e-04, avg batch time: 0.2134, average loss: 4.1552
[09/27 23:48:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.68	top5: 17.34	
[09/27 23:48:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/27 23:48:36 visual_prompt]: Epoch 40 / 100: avg data time: 3.57e-02, avg batch time: 0.4930, average train loss: 4.0487
[09/27 23:48:37 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 3.8323
[09/27 23:48:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.50	top5: 20.50	
[09/27 23:48:45 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2141, average loss: 3.8332
[09/27 23:48:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 7.34	top5: 21.76	
[09/27 23:48:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/27 23:48:53 visual_prompt]: Epoch 41 / 100: avg data time: 4.79e-02, avg batch time: 0.5045, average train loss: 3.4527
[09/27 23:48:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1703, average loss: 3.6051
[09/27 23:48:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 11.50	top5: 36.00	
[09/27 23:49:02 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2136, average loss: 3.7883
[09/27 23:49:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 11.49	top5: 31.97	
[09/27 23:49:02 visual_prompt]: Best epoch 41: best metric: 0.115
[09/27 23:49:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/27 23:49:10 visual_prompt]: Epoch 42 / 100: avg data time: 3.45e-02, avg batch time: 0.4915, average train loss: 3.2948
[09/27 23:49:12 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1701, average loss: 5.3231
[09/27 23:49:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 20.00	
[09/27 23:49:19 visual_prompt]: Inference (test):avg data time: 3.98e-05, avg batch time: 0.2143, average loss: 5.3036
[09/27 23:49:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.55	top5: 18.46	
[09/27 23:49:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/27 23:49:28 visual_prompt]: Epoch 43 / 100: avg data time: 4.76e-02, avg batch time: 0.5051, average train loss: 3.6754
[09/27 23:49:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1700, average loss: 2.8696
[09/27 23:49:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 24.50	top5: 55.50	
[09/27 23:49:36 visual_prompt]: Inference (test):avg data time: 1.39e-04, avg batch time: 0.2152, average loss: 3.2167
[09/27 23:49:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 21.28	top5: 48.72	
[09/27 23:49:36 visual_prompt]: Best epoch 43: best metric: 0.245
[09/27 23:49:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/27 23:49:44 visual_prompt]: Epoch 44 / 100: avg data time: 3.41e-02, avg batch time: 0.4925, average train loss: 4.0109
[09/27 23:49:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1698, average loss: 3.6223
[09/27 23:49:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 17.50	top5: 38.50	
[09/27 23:49:54 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2140, average loss: 3.8134
[09/27 23:49:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 14.52	top5: 38.67	
[09/27 23:49:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/27 23:50:02 visual_prompt]: Epoch 45 / 100: avg data time: 4.91e-02, avg batch time: 0.5055, average train loss: 5.5363
[09/27 23:50:03 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.1695, average loss: 5.9856
[09/27 23:50:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 12.50	
[09/27 23:50:11 visual_prompt]: Inference (test):avg data time: 1.65e-04, avg batch time: 0.2146, average loss: 6.0902
[09/27 23:50:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.72	top5: 11.60	
[09/27 23:50:11 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/27 23:50:19 visual_prompt]: Epoch 46 / 100: avg data time: 4.62e-02, avg batch time: 0.5033, average train loss: 5.8380
[09/27 23:50:21 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1700, average loss: 5.1001
[09/27 23:50:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 16.00	
[09/27 23:50:28 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2140, average loss: 5.1202
[09/27 23:50:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.40	top5: 13.56	
[09/27 23:50:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/27 23:50:36 visual_prompt]: Epoch 47 / 100: avg data time: 4.68e-02, avg batch time: 0.5031, average train loss: 4.9348
[09/27 23:50:38 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1699, average loss: 5.0253
[09/27 23:50:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 19.50	
[09/27 23:50:45 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2133, average loss: 5.1704
[09/27 23:50:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.35	top5: 15.90	
[09/27 23:50:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/27 23:50:54 visual_prompt]: Epoch 48 / 100: avg data time: 5.10e-02, avg batch time: 0.5076, average train loss: 5.0748
[09/27 23:50:55 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1701, average loss: 4.6511
[09/27 23:50:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 13.50	
[09/27 23:51:03 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2142, average loss: 4.7433
[09/27 23:51:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.88	top5: 15.32	
[09/27 23:51:03 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/27 23:51:11 visual_prompt]: Epoch 49 / 100: avg data time: 4.77e-02, avg batch time: 0.5037, average train loss: 4.5532
[09/27 23:51:13 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1697, average loss: 4.0737
[09/27 23:51:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 16.50	
[09/27 23:51:20 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2138, average loss: 4.1896
[09/27 23:51:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.72	top5: 15.59	
[09/27 23:51:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/27 23:51:28 visual_prompt]: Epoch 50 / 100: avg data time: 4.73e-02, avg batch time: 0.5052, average train loss: 4.0443
[09/27 23:51:30 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1697, average loss: 4.1642
[09/27 23:51:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 16.00	
[09/27 23:51:37 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2135, average loss: 4.1494
[09/27 23:51:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.99	top5: 14.68	
[09/27 23:51:37 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/27 23:51:45 visual_prompt]: Epoch 51 / 100: avg data time: 4.73e-02, avg batch time: 0.5037, average train loss: 3.8599
[09/27 23:51:47 visual_prompt]: Inference (val):avg data time: 4.91e-05, avg batch time: 0.1697, average loss: 4.2375
[09/27 23:51:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 15.00	
[09/27 23:51:54 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2144, average loss: 4.2614
[09/27 23:51:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 6.33	top5: 15.53	
[09/27 23:51:54 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/27 23:52:03 visual_prompt]: Epoch 52 / 100: avg data time: 4.20e-02, avg batch time: 0.4991, average train loss: 3.8929
[09/27 23:52:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1696, average loss: 4.0808
[09/27 23:52:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 20.50	
[09/27 23:52:11 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2141, average loss: 4.1519
[09/27 23:52:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.73	top5: 18.83	
[09/27 23:52:11 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/27 23:52:20 visual_prompt]: Epoch 53 / 100: avg data time: 3.83e-02, avg batch time: 0.4956, average train loss: 4.0140
[09/27 23:52:21 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1699, average loss: 4.4092
[09/27 23:52:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 12.50	
[09/27 23:52:29 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2143, average loss: 4.4457
[09/27 23:52:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.23	top5: 14.52	
[09/27 23:52:29 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/27 23:52:37 visual_prompt]: Epoch 54 / 100: avg data time: 4.04e-02, avg batch time: 0.4982, average train loss: 4.2017
[09/27 23:52:38 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1697, average loss: 4.4001
[09/27 23:52:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 16.50	
[09/27 23:52:46 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2143, average loss: 4.3175
[09/27 23:52:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 17.55	
[09/27 23:52:46 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/27 23:52:54 visual_prompt]: Epoch 55 / 100: avg data time: 4.64e-02, avg batch time: 0.5032, average train loss: 4.1330
[09/27 23:52:56 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1698, average loss: 4.0763
[09/27 23:52:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 20.50	
[09/27 23:53:03 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2160, average loss: 4.1232
[09/27 23:53:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.93	top5: 19.73	
[09/27 23:53:03 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/27 23:53:11 visual_prompt]: Epoch 56 / 100: avg data time: 4.48e-02, avg batch time: 0.5017, average train loss: 3.9699
[09/27 23:53:13 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1695, average loss: 3.9829
[09/27 23:53:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 22.50	
[09/27 23:53:20 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2140, average loss: 4.0361
[09/27 23:53:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.27	top5: 19.68	
[09/27 23:53:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/27 23:53:29 visual_prompt]: Epoch 57 / 100: avg data time: 4.71e-02, avg batch time: 0.5047, average train loss: 3.6028
[09/27 23:53:30 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1699, average loss: 3.5947
[09/27 23:53:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 11.00	top5: 31.00	
[09/27 23:53:38 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2147, average loss: 3.5888
[09/27 23:53:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 14.26	top5: 33.19	
[09/27 23:53:38 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/27 23:53:46 visual_prompt]: Epoch 58 / 100: avg data time: 3.66e-02, avg batch time: 0.4947, average train loss: 3.2909
[09/27 23:53:47 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1699, average loss: 3.2531
[09/27 23:53:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 10.00	top5: 50.50	
[09/27 23:53:55 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2145, average loss: 3.3752
[09/27 23:53:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 11.38	top5: 42.55	
[09/27 23:53:55 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/27 23:54:03 visual_prompt]: Epoch 59 / 100: avg data time: 4.82e-02, avg batch time: 0.5049, average train loss: 3.5402
[09/27 23:54:05 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1702, average loss: 3.5875
[09/27 23:54:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 22.50	top5: 46.50	
[09/27 23:54:12 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2139, average loss: 3.6038
[09/27 23:54:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 14.79	top5: 45.21	
[09/27 23:54:12 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/27 23:54:21 visual_prompt]: Epoch 60 / 100: avg data time: 4.57e-02, avg batch time: 0.5023, average train loss: 2.5870
[09/27 23:54:22 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1703, average loss: 1.9123
[09/27 23:54:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 47.50	top5: 84.50	
[09/27 23:54:29 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2136, average loss: 2.4947
[09/27 23:54:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 33.78	top5: 71.17	
[09/27 23:54:29 visual_prompt]: Best epoch 60: best metric: 0.475
[09/27 23:54:29 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/27 23:54:38 visual_prompt]: Epoch 61 / 100: avg data time: 4.71e-02, avg batch time: 0.5036, average train loss: 2.0006
[09/27 23:54:39 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1701, average loss: 1.6057
[09/27 23:54:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 52.00	top5: 85.50	
[09/27 23:54:47 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2145, average loss: 2.2167
[09/27 23:54:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 37.98	top5: 73.56	
[09/27 23:54:47 visual_prompt]: Best epoch 61: best metric: 0.520
[09/27 23:54:47 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/27 23:54:55 visual_prompt]: Epoch 62 / 100: avg data time: 4.32e-02, avg batch time: 0.5004, average train loss: 1.6838
[09/27 23:54:57 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1699, average loss: 1.3266
[09/27 23:54:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 58.50	top5: 93.00	
[09/27 23:55:04 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2145, average loss: 2.2705
[09/27 23:55:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 41.91	top5: 75.80	
[09/27 23:55:04 visual_prompt]: Best epoch 62: best metric: 0.585
[09/27 23:55:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/27 23:55:12 visual_prompt]: Epoch 63 / 100: avg data time: 4.91e-02, avg batch time: 0.5054, average train loss: 1.1368
[09/27 23:55:14 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1702, average loss: 0.7719
[09/27 23:55:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 76.50	top5: 97.00	
[09/27 23:55:21 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2136, average loss: 1.7800
[09/27 23:55:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.99	top5: 82.29	
[09/27 23:55:21 visual_prompt]: Best epoch 63: best metric: 0.765
[09/27 23:55:21 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/27 23:55:30 visual_prompt]: Epoch 64 / 100: avg data time: 4.63e-02, avg batch time: 0.5040, average train loss: 0.6952
[09/27 23:55:31 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1699, average loss: 0.6342
[09/27 23:55:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 83.00	top5: 99.00	
[09/27 23:55:39 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2144, average loss: 1.8621
[09/27 23:55:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 51.86	top5: 81.54	
[09/27 23:55:39 visual_prompt]: Best epoch 64: best metric: 0.830
[09/27 23:55:39 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/27 23:55:47 visual_prompt]: Epoch 65 / 100: avg data time: 4.55e-02, avg batch time: 0.5035, average train loss: 0.4812
[09/27 23:55:49 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1702, average loss: 0.3889
[09/27 23:55:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 89.00	top5: 99.50	
[09/27 23:55:56 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2140, average loss: 1.6686
[09/27 23:55:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 56.54	top5: 84.36	
[09/27 23:55:56 visual_prompt]: Best epoch 65: best metric: 0.890
[09/27 23:55:56 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/27 23:56:05 visual_prompt]: Epoch 66 / 100: avg data time: 4.34e-02, avg batch time: 0.4998, average train loss: 0.3431
[09/27 23:56:06 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1699, average loss: 0.5335
[09/27 23:56:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 87.00	top5: 98.00	
[09/27 23:56:14 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2143, average loss: 1.8241
[09/27 23:56:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.87	top5: 81.97	
[09/27 23:56:14 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/27 23:56:22 visual_prompt]: Epoch 67 / 100: avg data time: 4.49e-02, avg batch time: 0.5015, average train loss: 0.3405
[09/27 23:56:23 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1701, average loss: 0.3340
[09/27 23:56:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 93.00	top5: 100.00	
[09/27 23:56:31 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2141, average loss: 1.6013
[09/27 23:56:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.34	top5: 85.27	
[09/27 23:56:31 visual_prompt]: Best epoch 67: best metric: 0.930
[09/27 23:56:31 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/27 23:56:39 visual_prompt]: Epoch 68 / 100: avg data time: 4.75e-02, avg batch time: 0.5047, average train loss: 0.2616
[09/27 23:56:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1700, average loss: 0.3158
[09/27 23:56:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 92.50	top5: 100.00	
[09/27 23:56:48 visual_prompt]: Inference (test):avg data time: 1.37e-04, avg batch time: 0.2143, average loss: 1.5928
[09/27 23:56:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.77	top5: 85.59	
[09/27 23:56:48 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/27 23:56:57 visual_prompt]: Epoch 69 / 100: avg data time: 4.63e-02, avg batch time: 0.5029, average train loss: 0.2682
[09/27 23:56:58 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1702, average loss: 0.1657
[09/27 23:56:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/27 23:57:05 visual_prompt]: Inference (test):avg data time: 3.77e-05, avg batch time: 0.2153, average loss: 1.4442
[09/27 23:57:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.02	top5: 87.61	
[09/27 23:57:05 visual_prompt]: Best epoch 69: best metric: 0.980
[09/27 23:57:05 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/27 23:57:14 visual_prompt]: Epoch 70 / 100: avg data time: 4.75e-02, avg batch time: 0.5053, average train loss: 0.2001
[09/27 23:57:15 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1699, average loss: 0.1398
[09/27 23:57:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.00	top5: 100.00	
[09/27 23:57:23 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2144, average loss: 1.3807
[09/27 23:57:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.71	top5: 88.35	
[09/27 23:57:23 visual_prompt]: Best epoch 70: best metric: 0.990
[09/27 23:57:23 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/27 23:57:31 visual_prompt]: Epoch 71 / 100: avg data time: 3.88e-02, avg batch time: 0.4970, average train loss: 0.1524
[09/27 23:57:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1702, average loss: 0.1038
[09/27 23:57:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 23:57:40 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2152, average loss: 1.3246
[09/27 23:57:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.63	top5: 89.84	
[09/27 23:57:40 visual_prompt]: Best epoch 71: best metric: 0.995
[09/27 23:57:40 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/27 23:57:48 visual_prompt]: Epoch 72 / 100: avg data time: 4.59e-02, avg batch time: 0.5043, average train loss: 0.1194
[09/27 23:57:50 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1700, average loss: 0.1163
[09/27 23:57:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 23:57:57 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2140, average loss: 1.3222
[09/27 23:57:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.63	top5: 88.83	
[09/27 23:57:57 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/27 23:58:06 visual_prompt]: Epoch 73 / 100: avg data time: 4.90e-02, avg batch time: 0.5060, average train loss: 0.1008
[09/27 23:58:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1701, average loss: 0.0690
[09/27 23:58:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:58:15 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.2145, average loss: 1.2688
[09/27 23:58:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.01	top5: 90.96	
[09/27 23:58:15 visual_prompt]: Best epoch 73: best metric: 1.000
[09/27 23:58:15 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/27 23:58:23 visual_prompt]: Epoch 74 / 100: avg data time: 4.66e-02, avg batch time: 0.5045, average train loss: 0.0977
[09/27 23:58:25 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1703, average loss: 0.0694
[09/27 23:58:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:58:32 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2152, average loss: 1.2608
[09/27 23:58:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.80	top5: 90.64	
[09/27 23:58:32 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/27 23:58:40 visual_prompt]: Epoch 75 / 100: avg data time: 3.66e-02, avg batch time: 0.4958, average train loss: 0.0913
[09/27 23:58:42 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1702, average loss: 0.0593
[09/27 23:58:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:58:49 visual_prompt]: Inference (test):avg data time: 2.93e-05, avg batch time: 0.2144, average loss: 1.2638
[09/27 23:58:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.43	top5: 90.90	
[09/27 23:58:49 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/27 23:58:58 visual_prompt]: Epoch 76 / 100: avg data time: 4.11e-02, avg batch time: 0.4987, average train loss: 0.0855
[09/27 23:58:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1699, average loss: 0.0657
[09/27 23:58:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:59:06 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2135, average loss: 1.2746
[09/27 23:59:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 90.64	
[09/27 23:59:06 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/27 23:59:15 visual_prompt]: Epoch 77 / 100: avg data time: 4.38e-02, avg batch time: 0.5004, average train loss: 0.0799
[09/27 23:59:16 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1703, average loss: 0.0633
[09/27 23:59:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:59:24 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2145, average loss: 1.2464
[09/27 23:59:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.86	top5: 91.12	
[09/27 23:59:24 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/27 23:59:32 visual_prompt]: Epoch 78 / 100: avg data time: 5.04e-02, avg batch time: 0.5072, average train loss: 0.0818
[09/27 23:59:34 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1699, average loss: 0.0592
[09/27 23:59:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/27 23:59:41 visual_prompt]: Inference (test):avg data time: 3.72e-05, avg batch time: 0.2145, average loss: 1.2733
[09/27 23:59:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.69	top5: 90.59	
[09/27 23:59:41 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/27 23:59:50 visual_prompt]: Epoch 79 / 100: avg data time: 5.10e-02, avg batch time: 0.5077, average train loss: 0.0865
[09/27 23:59:51 visual_prompt]: Inference (val):avg data time: 3.94e-05, avg batch time: 0.1699, average loss: 0.0672
[09/27 23:59:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/27 23:59:59 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2145, average loss: 1.2504
[09/27 23:59:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.80	top5: 90.96	
[09/27 23:59:59 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/28 00:00:07 visual_prompt]: Epoch 80 / 100: avg data time: 3.83e-02, avg batch time: 0.4951, average train loss: 0.0757
[09/28 00:00:08 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1702, average loss: 0.0561
[09/28 00:00:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/28 00:00:16 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2152, average loss: 1.2365
[09/28 00:00:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.97	top5: 91.60	
[09/28 00:00:16 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/28 00:00:24 visual_prompt]: Epoch 81 / 100: avg data time: 3.87e-02, avg batch time: 0.4969, average train loss: 0.0671
[09/28 00:00:26 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1701, average loss: 0.0700
[09/28 00:00:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/28 00:00:33 visual_prompt]: Inference (test):avg data time: 3.72e-05, avg batch time: 0.2143, average loss: 1.2652
[09/28 00:00:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.17	top5: 90.69	
[09/28 00:00:33 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/28 00:00:41 visual_prompt]: Epoch 82 / 100: avg data time: 3.77e-02, avg batch time: 0.4961, average train loss: 0.0676
[09/28 00:00:43 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1700, average loss: 0.0475
[09/28 00:00:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:00:50 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2147, average loss: 1.2510
[09/28 00:00:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.22	top5: 91.01	
[09/28 00:00:50 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/28 00:00:58 visual_prompt]: Epoch 83 / 100: avg data time: 3.61e-02, avg batch time: 0.4948, average train loss: 0.0636
[09/28 00:01:00 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1703, average loss: 0.0395
[09/28 00:01:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:01:07 visual_prompt]: Inference (test):avg data time: 6.13e-04, avg batch time: 0.2146, average loss: 1.2044
[09/28 00:01:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.93	top5: 91.38	
[09/28 00:01:07 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/28 00:01:16 visual_prompt]: Epoch 84 / 100: avg data time: 4.74e-02, avg batch time: 0.5039, average train loss: 0.0545
[09/28 00:01:17 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.1700, average loss: 0.0368
[09/28 00:01:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:01:25 visual_prompt]: Inference (test):avg data time: 3.88e-05, avg batch time: 0.2141, average loss: 1.2274
[09/28 00:01:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.29	top5: 91.12	
[09/28 00:01:25 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/28 00:01:33 visual_prompt]: Epoch 85 / 100: avg data time: 4.49e-02, avg batch time: 0.5017, average train loss: 0.0470
[09/28 00:01:34 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1698, average loss: 0.0405
[09/28 00:01:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/28 00:01:42 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2135, average loss: 1.2237
[09/28 00:01:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 90.90	
[09/28 00:01:42 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/28 00:01:50 visual_prompt]: Epoch 86 / 100: avg data time: 4.08e-02, avg batch time: 0.4989, average train loss: 0.0389
[09/28 00:01:52 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1701, average loss: 0.0249
[09/28 00:01:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:01:59 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2146, average loss: 1.1966
[09/28 00:01:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.24	top5: 91.70	
[09/28 00:01:59 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/28 00:02:07 visual_prompt]: Epoch 87 / 100: avg data time: 4.70e-02, avg batch time: 0.5042, average train loss: 0.0303
[09/28 00:02:09 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1702, average loss: 0.0233
[09/28 00:02:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:02:16 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2145, average loss: 1.2102
[09/28 00:02:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 68.51	top5: 91.49	
[09/28 00:02:16 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/28 00:02:25 visual_prompt]: Epoch 88 / 100: avg data time: 4.38e-02, avg batch time: 0.5010, average train loss: 0.0259
[09/28 00:02:26 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1697, average loss: 0.0190
[09/28 00:02:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:02:34 visual_prompt]: Inference (test):avg data time: 2.71e-04, avg batch time: 0.2160, average loss: 1.2183
[09/28 00:02:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 92.07	
[09/28 00:02:34 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/28 00:02:42 visual_prompt]: Epoch 89 / 100: avg data time: 3.91e-02, avg batch time: 0.4979, average train loss: 0.0219
[09/28 00:02:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1701, average loss: 0.0159
[09/28 00:02:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:02:51 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2139, average loss: 1.2267
[09/28 00:02:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 91.38	
[09/28 00:02:51 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/28 00:02:59 visual_prompt]: Epoch 90 / 100: avg data time: 3.70e-02, avg batch time: 0.4945, average train loss: 0.0196
[09/28 00:03:01 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1697, average loss: 0.0149
[09/28 00:03:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:03:08 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2147, average loss: 1.2182
[09/28 00:03:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.66	top5: 91.33	
[09/28 00:03:08 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/28 00:03:16 visual_prompt]: Epoch 91 / 100: avg data time: 3.40e-02, avg batch time: 0.4914, average train loss: 0.0182
[09/28 00:03:18 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1700, average loss: 0.0140
[09/28 00:03:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:03:25 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2145, average loss: 1.2248
[09/28 00:03:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.61	top5: 91.17	
[09/28 00:03:25 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/28 00:03:34 visual_prompt]: Epoch 92 / 100: avg data time: 3.58e-02, avg batch time: 0.4952, average train loss: 0.0173
[09/28 00:03:35 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1699, average loss: 0.0137
[09/28 00:03:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:03:43 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2138, average loss: 1.2313
[09/28 00:03:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.23	top5: 91.06	
[09/28 00:03:43 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/28 00:03:51 visual_prompt]: Epoch 93 / 100: avg data time: 4.73e-02, avg batch time: 0.5041, average train loss: 0.0168
[09/28 00:03:53 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1696, average loss: 0.0133
[09/28 00:03:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:04:00 visual_prompt]: Inference (test):avg data time: 3.90e-05, avg batch time: 0.2139, average loss: 1.2271
[09/28 00:04:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.98	top5: 91.06	
[09/28 00:04:00 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/28 00:04:08 visual_prompt]: Epoch 94 / 100: avg data time: 3.42e-02, avg batch time: 0.4915, average train loss: 0.0167
[09/28 00:04:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1702, average loss: 0.0133
[09/28 00:04:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:04:17 visual_prompt]: Inference (test):avg data time: 4.03e-05, avg batch time: 0.2141, average loss: 1.2316
[09/28 00:04:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.55	top5: 91.22	
[09/28 00:04:17 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/28 00:04:26 visual_prompt]: Epoch 95 / 100: avg data time: 4.42e-02, avg batch time: 0.5024, average train loss: 0.0164
[09/28 00:04:27 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1698, average loss: 0.0131
[09/28 00:04:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:04:34 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2149, average loss: 1.2362
[09/28 00:04:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.34	top5: 91.06	
[09/28 00:04:34 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/28 00:04:43 visual_prompt]: Epoch 96 / 100: avg data time: 4.84e-02, avg batch time: 0.5057, average train loss: 0.0165
[09/28 00:04:44 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1700, average loss: 0.0131
[09/28 00:04:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:04:52 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2141, average loss: 1.2384
[09/28 00:04:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 91.01	
[09/28 00:04:52 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/28 00:05:00 visual_prompt]: Epoch 97 / 100: avg data time: 5.21e-02, avg batch time: 0.5089, average train loss: 0.0161
[09/28 00:05:02 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1698, average loss: 0.0130
[09/28 00:05:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:05:09 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2138, average loss: 1.2392
[09/28 00:05:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.50	top5: 91.01	
[09/28 00:05:09 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/28 00:05:17 visual_prompt]: Epoch 98 / 100: avg data time: 4.37e-02, avg batch time: 0.5011, average train loss: 0.0162
[09/28 00:05:19 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1700, average loss: 0.0130
[09/28 00:05:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:05:26 visual_prompt]: Inference (test):avg data time: 2.45e-04, avg batch time: 0.2146, average loss: 1.2404
[09/28 00:05:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.39	top5: 91.17	
[09/28 00:05:26 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/28 00:05:35 visual_prompt]: Epoch 99 / 100: avg data time: 3.46e-02, avg batch time: 0.4932, average train loss: 0.0160
[09/28 00:05:36 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1702, average loss: 0.0130
[09/28 00:05:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:05:43 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2146, average loss: 1.2402
[09/28 00:05:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.45	top5: 91.17	
[09/28 00:05:43 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/28 00:05:52 visual_prompt]: Epoch 100 / 100: avg data time: 4.14e-02, avg batch time: 0.4991, average train loss: 0.0159
[09/28 00:05:53 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1702, average loss: 0.0130
[09/28 00:05:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:06:01 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2142, average loss: 1.2402
[09/28 00:06:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.50	top5: 91.17	
[09/28 00:06:01 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 00:06:01 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 00:06:01 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 00:06:01 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 00:06:01 visual_prompt]: Training with config:
[09/28 00:06:01 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dtd/sup_vitb16_imagenet21k/prompt50/crop224/test/seed737/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 737, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dtd', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 47, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 00:06:01 visual_prompt]: Loading training data...
[09/28 00:06:01 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:06:03 visual_prompt]: Number of images: 1000
[09/28 00:06:03 visual_prompt]: Number of classes: 47 / 47
[09/28 00:06:03 visual_prompt]: Loading validation data...
[09/28 00:06:03 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:06:04 visual_prompt]: Number of images: 200
[09/28 00:06:04 visual_prompt]: Number of classes: 47 / 47
[09/28 00:06:04 visual_prompt]: Loading test data...
[09/28 00:06:04 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:06:08 visual_prompt]: Number of images: 1880
[09/28 00:06:08 visual_prompt]: Number of classes: 47 / 47
[09/28 00:06:08 visual_prompt]: Constructing models...
[09/28 00:06:11 visual_prompt]: Total Parameters: 86295599	 Gradient Parameters: 496943
[09/28 00:06:11 visual_prompt]: tuned percent:0.576
[09/28 00:06:11 visual_prompt]: Device used for model: 0
[09/28 00:06:11 visual_prompt]: Setting up Evaluator...
[09/28 00:06:11 visual_prompt]: Setting up Trainer...
[09/28 00:06:11 visual_prompt]: 	Setting up the optimizer...
[09/28 00:06:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 00:06:19 visual_prompt]: Epoch 1 / 100: avg data time: 3.30e-02, avg batch time: 0.4866, average train loss: 3.9555
[09/28 00:06:20 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1691, average loss: 3.9234
[09/28 00:06:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 10.00	
[09/28 00:06:28 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2140, average loss: 3.9754
[09/28 00:06:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.44	top5: 10.80	
[09/28 00:06:28 visual_prompt]: Best epoch 1: best metric: 0.010
[09/28 00:06:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/28 00:06:36 visual_prompt]: Epoch 2 / 100: avg data time: 4.55e-02, avg batch time: 0.5012, average train loss: 3.9689
[09/28 00:06:38 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1690, average loss: 3.8561
[09/28 00:06:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 15.50	
[09/28 00:06:45 visual_prompt]: Inference (test):avg data time: 3.91e-05, avg batch time: 0.2132, average loss: 3.8738
[09/28 00:06:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.51	top5: 14.04	
[09/28 00:06:45 visual_prompt]: Best epoch 2: best metric: 0.030
[09/28 00:06:45 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/28 00:06:53 visual_prompt]: Epoch 3 / 100: avg data time: 3.85e-02, avg batch time: 0.4942, average train loss: 3.9047
[09/28 00:06:55 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1696, average loss: 3.7921
[09/28 00:06:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 18.50	
[09/28 00:07:02 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2135, average loss: 3.8494
[09/28 00:07:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.64	top5: 15.16	
[09/28 00:07:02 visual_prompt]: Best epoch 3: best metric: 0.050
[09/28 00:07:02 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/28 00:07:11 visual_prompt]: Epoch 4 / 100: avg data time: 5.10e-02, avg batch time: 0.5067, average train loss: 3.8614
[09/28 00:07:12 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1696, average loss: 3.9289
[09/28 00:07:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 20.00	
[09/28 00:07:20 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2132, average loss: 3.9478
[09/28 00:07:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.89	top5: 17.50	
[09/28 00:07:20 visual_prompt]: Best epoch 4: best metric: 0.060
[09/28 00:07:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/28 00:07:28 visual_prompt]: Epoch 5 / 100: avg data time: 5.25e-02, avg batch time: 0.5081, average train loss: 3.8907
[09/28 00:07:30 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1697, average loss: 3.7935
[09/28 00:07:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 18.00	
[09/28 00:07:37 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2137, average loss: 3.8314
[09/28 00:07:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.41	top5: 21.38	
[09/28 00:07:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/28 00:07:46 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e-02, avg batch time: 0.5035, average train loss: 4.0113
[09/28 00:07:47 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1696, average loss: 4.0873
[09/28 00:07:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.00	top5: 20.50	
[09/28 00:07:55 visual_prompt]: Inference (test):avg data time: 7.73e-04, avg batch time: 0.2148, average loss: 4.1074
[09/28 00:07:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.53	top5: 18.40	
[09/28 00:07:55 visual_prompt]: Best epoch 6: best metric: 0.080
[09/28 00:07:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/28 00:08:03 visual_prompt]: Epoch 7 / 100: avg data time: 4.12e-02, avg batch time: 0.4981, average train loss: 3.9335
[09/28 00:08:04 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1699, average loss: 4.0666
[09/28 00:08:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 21.00	
[09/28 00:08:12 visual_prompt]: Inference (test):avg data time: 4.07e-04, avg batch time: 0.2151, average loss: 4.1206
[09/28 00:08:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.47	top5: 16.91	
[09/28 00:08:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/28 00:08:20 visual_prompt]: Epoch 8 / 100: avg data time: 4.39e-02, avg batch time: 0.5004, average train loss: 4.0479
[09/28 00:08:22 visual_prompt]: Inference (val):avg data time: 7.31e-04, avg batch time: 0.2776, average loss: 4.1468
[09/28 00:08:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.50	top5: 17.50	
[09/28 00:08:30 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2136, average loss: 4.0719
[09/28 00:08:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.36	top5: 15.74	
[09/28 00:08:30 visual_prompt]: Best epoch 8: best metric: 0.085
[09/28 00:08:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/28 00:08:38 visual_prompt]: Epoch 9 / 100: avg data time: 3.71e-02, avg batch time: 0.4949, average train loss: 3.9546
[09/28 00:08:39 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1696, average loss: 4.3629
[09/28 00:08:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/28 00:08:47 visual_prompt]: Inference (test):avg data time: 1.36e-04, avg batch time: 0.2144, average loss: 4.3181
[09/28 00:08:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.26	top5: 13.72	
[09/28 00:08:47 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/28 00:08:55 visual_prompt]: Epoch 10 / 100: avg data time: 4.53e-02, avg batch time: 0.5013, average train loss: 4.2619
[09/28 00:08:57 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1696, average loss: 3.9692
[09/28 00:08:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 18.00	
[09/28 00:09:04 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2137, average loss: 4.0481
[09/28 00:09:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 17.13	
[09/28 00:09:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/28 00:09:13 visual_prompt]: Epoch 11 / 100: avg data time: 4.18e-02, avg batch time: 0.4985, average train loss: 4.2152
[09/28 00:09:14 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1698, average loss: 4.3961
[09/28 00:09:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/28 00:09:22 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2134, average loss: 4.3556
[09/28 00:09:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 14.10	
[09/28 00:09:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/28 00:09:30 visual_prompt]: Epoch 12 / 100: avg data time: 4.65e-02, avg batch time: 0.5027, average train loss: 5.1836
[09/28 00:09:32 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1693, average loss: 7.9055
[09/28 00:09:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/28 00:09:39 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2137, average loss: 6.8452
[09/28 00:09:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:09:39 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/28 00:09:47 visual_prompt]: Epoch 13 / 100: avg data time: 3.83e-02, avg batch time: 0.4967, average train loss: 8.0857
[09/28 00:09:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1695, average loss: 8.8095
[09/28 00:09:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.00	
[09/28 00:09:56 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2133, average loss: 8.2401
[09/28 00:09:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.64	
[09/28 00:09:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/28 00:10:05 visual_prompt]: Epoch 14 / 100: avg data time: 4.46e-02, avg batch time: 0.5007, average train loss: 7.9547
[09/28 00:10:06 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1696, average loss: 6.5656
[09/28 00:10:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 13.00	
[09/28 00:10:13 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2140, average loss: 7.2043
[09/28 00:10:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:10:13 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/28 00:10:22 visual_prompt]: Epoch 15 / 100: avg data time: 4.34e-02, avg batch time: 0.4994, average train loss: 8.7583
[09/28 00:10:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1696, average loss: 8.4024
[09/28 00:10:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 9.00	
[09/28 00:10:31 visual_prompt]: Inference (test):avg data time: 5.21e-05, avg batch time: 0.2134, average loss: 7.4665
[09/28 00:10:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.12	
[09/28 00:10:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/28 00:10:39 visual_prompt]: Epoch 16 / 100: avg data time: 4.53e-02, avg batch time: 0.5020, average train loss: 7.8692
[09/28 00:10:40 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1693, average loss: 11.1073
[09/28 00:10:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 13.50	
[09/28 00:10:48 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2147, average loss: 12.3306
[09/28 00:10:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.45	top5: 10.48	
[09/28 00:10:48 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/28 00:10:56 visual_prompt]: Epoch 17 / 100: avg data time: 4.66e-02, avg batch time: 0.5029, average train loss: 9.4181
[09/28 00:10:58 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1697, average loss: 8.2978
[09/28 00:10:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.00	
[09/28 00:11:05 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2139, average loss: 7.3235
[09/28 00:11:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:11:05 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/28 00:11:13 visual_prompt]: Epoch 18 / 100: avg data time: 3.63e-02, avg batch time: 0.4939, average train loss: 6.7091
[09/28 00:11:15 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1698, average loss: 4.6728
[09/28 00:11:15 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/28 00:11:22 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2134, average loss: 4.6782
[09/28 00:11:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:11:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/28 00:11:31 visual_prompt]: Epoch 19 / 100: avg data time: 4.44e-02, avg batch time: 0.5012, average train loss: 5.4715
[09/28 00:11:32 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1696, average loss: 5.6772
[09/28 00:11:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/28 00:11:40 visual_prompt]: Inference (test):avg data time: 2.39e-04, avg batch time: 0.2136, average loss: 5.2122
[09/28 00:11:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:11:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/28 00:11:48 visual_prompt]: Epoch 20 / 100: avg data time: 4.57e-02, avg batch time: 0.5019, average train loss: 5.1648
[09/28 00:11:49 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 5.1220
[09/28 00:11:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.50	
[09/28 00:11:57 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2143, average loss: 4.9332
[09/28 00:11:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:11:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/28 00:12:05 visual_prompt]: Epoch 21 / 100: avg data time: 4.51e-02, avg batch time: 0.5029, average train loss: 4.7719
[09/28 00:12:07 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1696, average loss: 4.6686
[09/28 00:12:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.00	
[09/28 00:12:14 visual_prompt]: Inference (test):avg data time: 3.09e-05, avg batch time: 0.2146, average loss: 4.5219
[09/28 00:12:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:12:14 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/28 00:12:23 visual_prompt]: Epoch 22 / 100: avg data time: 4.92e-02, avg batch time: 0.5056, average train loss: 4.4872
[09/28 00:12:24 visual_prompt]: Inference (val):avg data time: 5.22e-05, avg batch time: 0.1699, average loss: 4.4528
[09/28 00:12:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 8.00	
[09/28 00:12:31 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2150, average loss: 4.2874
[09/28 00:12:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.12	
[09/28 00:12:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/28 00:12:40 visual_prompt]: Epoch 23 / 100: avg data time: 4.57e-02, avg batch time: 0.5021, average train loss: 4.2465
[09/28 00:12:41 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1698, average loss: 4.8695
[09/28 00:12:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 8.50	
[09/28 00:12:49 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2133, average loss: 4.7156
[09/28 00:12:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 10.64	
[09/28 00:12:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/28 00:12:57 visual_prompt]: Epoch 24 / 100: avg data time: 4.55e-02, avg batch time: 0.5021, average train loss: 4.6468
[09/28 00:12:59 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1695, average loss: 5.2756
[09/28 00:12:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.00	
[09/28 00:13:06 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2140, average loss: 5.1460
[09/28 00:13:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:13:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/28 00:13:14 visual_prompt]: Epoch 25 / 100: avg data time: 4.71e-02, avg batch time: 0.5038, average train loss: 4.9628
[09/28 00:13:16 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1700, average loss: 6.7527
[09/28 00:13:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.50	
[09/28 00:13:23 visual_prompt]: Inference (test):avg data time: 4.99e-04, avg batch time: 0.2142, average loss: 6.7857
[09/28 00:13:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:13:23 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/28 00:13:32 visual_prompt]: Epoch 26 / 100: avg data time: 5.25e-02, avg batch time: 0.5081, average train loss: 5.4783
[09/28 00:13:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1699, average loss: 5.1965
[09/28 00:13:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 9.00	
[09/28 00:13:41 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2144, average loss: 5.3220
[09/28 00:13:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.85	
[09/28 00:13:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/28 00:13:49 visual_prompt]: Epoch 27 / 100: avg data time: 4.25e-02, avg batch time: 0.4996, average train loss: 4.9931
[09/28 00:13:51 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1700, average loss: 5.4686
[09/28 00:13:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 12.00	
[09/28 00:13:58 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2130, average loss: 5.4033
[09/28 00:13:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.85	
[09/28 00:13:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/28 00:14:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.72e-02, avg batch time: 0.5036, average train loss: 5.8621
[09/28 00:14:08 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1701, average loss: 5.2275
[09/28 00:14:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/28 00:14:16 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2136, average loss: 5.2692
[09/28 00:14:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:14:16 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/28 00:14:24 visual_prompt]: Epoch 29 / 100: avg data time: 5.25e-02, avg batch time: 0.5080, average train loss: 5.5652
[09/28 00:14:26 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1697, average loss: 5.7139
[09/28 00:14:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.50	
[09/28 00:14:33 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2137, average loss: 5.9037
[09/28 00:14:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:14:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/28 00:14:42 visual_prompt]: Epoch 30 / 100: avg data time: 5.09e-02, avg batch time: 0.5068, average train loss: 7.1019
[09/28 00:14:43 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1693, average loss: 7.2713
[09/28 00:14:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.50	
[09/28 00:14:50 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2138, average loss: 7.3833
[09/28 00:14:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/28 00:14:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/28 00:14:59 visual_prompt]: Epoch 31 / 100: avg data time: 4.97e-02, avg batch time: 0.5059, average train loss: 7.4300
[09/28 00:15:00 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1693, average loss: 6.9430
[09/28 00:15:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 12.50	
[09/28 00:15:08 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2135, average loss: 6.8662
[09/28 00:15:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.48	
[09/28 00:15:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/28 00:15:16 visual_prompt]: Epoch 32 / 100: avg data time: 4.57e-02, avg batch time: 0.5027, average train loss: 6.0933
[09/28 00:15:18 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1697, average loss: 5.5924
[09/28 00:15:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 7.50	
[09/28 00:15:25 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2138, average loss: 5.2869
[09/28 00:15:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.74	
[09/28 00:15:25 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/28 00:15:34 visual_prompt]: Epoch 33 / 100: avg data time: 4.25e-02, avg batch time: 0.4998, average train loss: 4.8208
[09/28 00:15:35 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1698, average loss: 4.4976
[09/28 00:15:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 15.00	
[09/28 00:15:43 visual_prompt]: Inference (test):avg data time: 2.94e-05, avg batch time: 0.2143, average loss: 4.5427
[09/28 00:15:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:15:43 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/28 00:15:51 visual_prompt]: Epoch 34 / 100: avg data time: 4.71e-02, avg batch time: 0.5026, average train loss: 4.3457
[09/28 00:15:53 visual_prompt]: Inference (val):avg data time: 4.09e-05, avg batch time: 0.1696, average loss: 4.4478
[09/28 00:15:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 9.00	
[09/28 00:16:00 visual_prompt]: Inference (test):avg data time: 5.75e-04, avg batch time: 0.2143, average loss: 4.4613
[09/28 00:16:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:16:00 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/28 00:16:08 visual_prompt]: Epoch 35 / 100: avg data time: 4.63e-02, avg batch time: 0.5025, average train loss: 4.4034
[09/28 00:16:10 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1695, average loss: 5.3564
[09/28 00:16:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 11.00	
[09/28 00:16:17 visual_prompt]: Inference (test):avg data time: 3.01e-04, avg batch time: 0.2136, average loss: 5.2364
[09/28 00:16:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.48	
[09/28 00:16:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/28 00:16:25 visual_prompt]: Epoch 36 / 100: avg data time: 4.01e-02, avg batch time: 0.4962, average train loss: 4.8862
[09/28 00:16:27 visual_prompt]: Inference (val):avg data time: 4.25e-05, avg batch time: 0.1697, average loss: 4.6742
[09/28 00:16:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 9.50	
[09/28 00:16:34 visual_prompt]: Inference (test):avg data time: 3.96e-05, avg batch time: 0.2143, average loss: 4.7673
[09/28 00:16:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:16:34 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/28 00:16:43 visual_prompt]: Epoch 37 / 100: avg data time: 4.66e-02, avg batch time: 0.5040, average train loss: 4.4016
[09/28 00:16:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1697, average loss: 4.4414
[09/28 00:16:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 7.00	
[09/28 00:16:52 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2133, average loss: 4.4245
[09/28 00:16:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:16:52 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/28 00:17:00 visual_prompt]: Epoch 38 / 100: avg data time: 5.31e-02, avg batch time: 0.5091, average train loss: 4.3711
[09/28 00:17:02 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1714, average loss: 4.1140
[09/28 00:17:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 16.50	
[09/28 00:17:09 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2131, average loss: 4.1971
[09/28 00:17:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.65	
[09/28 00:17:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/28 00:17:18 visual_prompt]: Epoch 39 / 100: avg data time: 3.94e-02, avg batch time: 0.4959, average train loss: 4.1583
[09/28 00:17:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1695, average loss: 4.2283
[09/28 00:17:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 10.00	
[09/28 00:17:27 visual_prompt]: Inference (test):avg data time: 6.34e-05, avg batch time: 0.2139, average loss: 4.2726
[09/28 00:17:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/28 00:17:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/28 00:17:35 visual_prompt]: Epoch 40 / 100: avg data time: 4.73e-02, avg batch time: 0.5033, average train loss: 4.1171
[09/28 00:17:37 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1698, average loss: 4.2210
[09/28 00:17:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/28 00:17:44 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2138, average loss: 4.2382
[09/28 00:17:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.48	
[09/28 00:17:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/28 00:17:52 visual_prompt]: Epoch 41 / 100: avg data time: 4.00e-02, avg batch time: 0.4980, average train loss: 4.1829
[09/28 00:17:54 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1697, average loss: 4.1222
[09/28 00:17:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.00	
[09/28 00:18:01 visual_prompt]: Inference (test):avg data time: 3.65e-05, avg batch time: 0.2141, average loss: 4.1701
[09/28 00:18:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.98	top5: 11.65	
[09/28 00:18:01 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/28 00:18:10 visual_prompt]: Epoch 42 / 100: avg data time: 5.20e-02, avg batch time: 0.5093, average train loss: 4.1174
[09/28 00:18:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1698, average loss: 4.0030
[09/28 00:18:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.50	
[09/28 00:18:19 visual_prompt]: Inference (test):avg data time: 3.02e-04, avg batch time: 0.2150, average loss: 4.0832
[09/28 00:18:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.78	top5: 13.03	
[09/28 00:18:19 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/28 00:18:27 visual_prompt]: Epoch 43 / 100: avg data time: 4.33e-02, avg batch time: 0.5001, average train loss: 4.0471
[09/28 00:18:28 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.1699, average loss: 4.1592
[09/28 00:18:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 12.00	
[09/28 00:18:36 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2136, average loss: 4.1991
[09/28 00:18:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.33	
[09/28 00:18:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/28 00:18:44 visual_prompt]: Epoch 44 / 100: avg data time: 4.99e-02, avg batch time: 0.5061, average train loss: 4.0494
[09/28 00:18:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1696, average loss: 4.1508
[09/28 00:18:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 12.50	
[09/28 00:18:53 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2136, average loss: 4.1027
[09/28 00:18:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 14.20	
[09/28 00:18:53 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/28 00:19:02 visual_prompt]: Epoch 45 / 100: avg data time: 4.83e-02, avg batch time: 0.5052, average train loss: 4.1866
[09/28 00:19:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1699, average loss: 4.2985
[09/28 00:19:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 15.00	
[09/28 00:19:11 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2136, average loss: 4.2976
[09/28 00:19:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 12.82	
[09/28 00:19:11 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/28 00:19:19 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e-02, avg batch time: 0.5061, average train loss: 4.5420
[09/28 00:19:21 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1695, average loss: 4.7728
[09/28 00:19:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.50	
[09/28 00:19:28 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2142, average loss: 4.8253
[09/28 00:19:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 13.19	
[09/28 00:19:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/28 00:19:37 visual_prompt]: Epoch 47 / 100: avg data time: 5.14e-02, avg batch time: 0.5085, average train loss: 5.0540
[09/28 00:19:38 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1693, average loss: 6.1582
[09/28 00:19:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 8.50	
[09/28 00:19:46 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2133, average loss: 5.5168
[09/28 00:19:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.71	top5: 11.81	
[09/28 00:19:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/28 00:19:54 visual_prompt]: Epoch 48 / 100: avg data time: 4.63e-02, avg batch time: 0.5022, average train loss: 5.3721
[09/28 00:19:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1693, average loss: 4.4883
[09/28 00:19:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 11.50	
[09/28 00:20:03 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2141, average loss: 4.4370
[09/28 00:20:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.54	
[09/28 00:20:03 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/28 00:20:11 visual_prompt]: Epoch 49 / 100: avg data time: 4.00e-02, avg batch time: 0.4958, average train loss: 4.3720
[09/28 00:20:13 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1699, average loss: 4.4444
[09/28 00:20:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 14.50	
[09/28 00:20:20 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2135, average loss: 4.4449
[09/28 00:20:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.91	
[09/28 00:20:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/28 00:20:29 visual_prompt]: Epoch 50 / 100: avg data time: 5.36e-02, avg batch time: 0.5093, average train loss: 4.2393
[09/28 00:20:30 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1697, average loss: 4.2389
[09/28 00:20:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.00	
[09/28 00:20:38 visual_prompt]: Inference (test):avg data time: 3.88e-05, avg batch time: 0.2136, average loss: 4.2599
[09/28 00:20:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.90	
[09/28 00:20:38 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/28 00:20:46 visual_prompt]: Epoch 51 / 100: avg data time: 4.45e-02, avg batch time: 0.5027, average train loss: 4.4064
[09/28 00:20:47 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1697, average loss: 4.7110
[09/28 00:20:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 12.00	
[09/28 00:20:55 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2141, average loss: 4.4970
[09/28 00:20:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.62	top5: 11.70	
[09/28 00:20:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/28 00:21:03 visual_prompt]: Epoch 52 / 100: avg data time: 3.74e-02, avg batch time: 0.4951, average train loss: 6.8308
[09/28 00:21:05 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1705, average loss: 4.9504
[09/28 00:21:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/28 00:21:12 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2142, average loss: 4.7645
[09/28 00:21:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.61	top5: 10.64	
[09/28 00:21:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/28 00:21:21 visual_prompt]: Epoch 53 / 100: avg data time: 4.00e-02, avg batch time: 0.4971, average train loss: 5.9556
[09/28 00:21:22 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1698, average loss: 4.9995
[09/28 00:21:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.50	
[09/28 00:21:29 visual_prompt]: Inference (test):avg data time: 5.66e-05, avg batch time: 0.2141, average loss: 4.7924
[09/28 00:21:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 11.01	
[09/28 00:21:29 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/28 00:21:38 visual_prompt]: Epoch 54 / 100: avg data time: 3.77e-02, avg batch time: 0.4945, average train loss: 6.2808
[09/28 00:21:39 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1694, average loss: 7.4412
[09/28 00:21:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.00	
[09/28 00:21:47 visual_prompt]: Inference (test):avg data time: 2.81e-05, avg batch time: 0.2131, average loss: 6.5603
[09/28 00:21:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:21:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/28 00:21:55 visual_prompt]: Epoch 55 / 100: avg data time: 4.20e-02, avg batch time: 0.4978, average train loss: 7.0896
[09/28 00:21:56 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1697, average loss: 6.6746
[09/28 00:21:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 7.50	
[09/28 00:22:04 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2135, average loss: 5.9425
[09/28 00:22:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/28 00:22:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/28 00:22:12 visual_prompt]: Epoch 56 / 100: avg data time: 4.85e-02, avg batch time: 0.5037, average train loss: 5.7091
[09/28 00:22:14 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1695, average loss: 4.9097
[09/28 00:22:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/28 00:22:21 visual_prompt]: Inference (test):avg data time: 3.86e-04, avg batch time: 0.2135, average loss: 4.7229
[09/28 00:22:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.65	
[09/28 00:22:21 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/28 00:22:30 visual_prompt]: Epoch 57 / 100: avg data time: 4.86e-02, avg batch time: 0.5044, average train loss: 4.9572
[09/28 00:22:31 visual_prompt]: Inference (val):avg data time: 3.96e-05, avg batch time: 0.1693, average loss: 5.1519
[09/28 00:22:31 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 9.00	
[09/28 00:22:39 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2150, average loss: 4.8655
[09/28 00:22:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:22:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/28 00:22:47 visual_prompt]: Epoch 58 / 100: avg data time: 5.01e-02, avg batch time: 0.5059, average train loss: 4.6948
[09/28 00:22:49 visual_prompt]: Inference (val):avg data time: 4.37e-05, avg batch time: 0.1696, average loss: 4.4290
[09/28 00:22:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/28 00:22:56 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2144, average loss: 4.4777
[09/28 00:22:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:22:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/28 00:23:05 visual_prompt]: Epoch 59 / 100: avg data time: 5.31e-02, avg batch time: 0.5088, average train loss: 4.3862
[09/28 00:23:06 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1695, average loss: 4.3457
[09/28 00:23:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.00	
[09/28 00:23:14 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2147, average loss: 4.3265
[09/28 00:23:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.97	
[09/28 00:23:14 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/28 00:23:22 visual_prompt]: Epoch 60 / 100: avg data time: 4.77e-02, avg batch time: 0.5039, average train loss: 4.2112
[09/28 00:23:23 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1694, average loss: 4.2597
[09/28 00:23:23 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/28 00:23:31 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2138, average loss: 4.2752
[09/28 00:23:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:23:31 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/28 00:23:39 visual_prompt]: Epoch 61 / 100: avg data time: 4.71e-02, avg batch time: 0.5028, average train loss: 4.2104
[09/28 00:23:41 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1695, average loss: 5.3758
[09/28 00:23:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 14.00	
[09/28 00:23:48 visual_prompt]: Inference (test):avg data time: 2.95e-05, avg batch time: 0.2136, average loss: 4.9713
[09/28 00:23:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 10.80	
[09/28 00:23:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/28 00:23:57 visual_prompt]: Epoch 62 / 100: avg data time: 4.37e-02, avg batch time: 0.5005, average train loss: 4.4041
[09/28 00:23:58 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1695, average loss: 4.1394
[09/28 00:23:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 14.50	
[09/28 00:24:06 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2139, average loss: 4.1710
[09/28 00:24:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.04	top5: 13.51	
[09/28 00:24:06 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/28 00:24:14 visual_prompt]: Epoch 63 / 100: avg data time: 3.74e-02, avg batch time: 0.4949, average train loss: 4.2201
[09/28 00:24:16 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1698, average loss: 4.2007
[09/28 00:24:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 9.50	
[09/28 00:24:23 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2137, average loss: 4.1598
[09/28 00:24:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.71	top5: 10.69	
[09/28 00:24:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/28 00:24:31 visual_prompt]: Epoch 64 / 100: avg data time: 4.27e-02, avg batch time: 0.4984, average train loss: 4.1783
[09/28 00:24:33 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1697, average loss: 4.0390
[09/28 00:24:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/28 00:24:40 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2142, average loss: 4.0257
[09/28 00:24:40 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 11.91	
[09/28 00:24:40 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/28 00:24:48 visual_prompt]: Epoch 65 / 100: avg data time: 3.85e-02, avg batch time: 0.4967, average train loss: 4.0422
[09/28 00:24:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1699, average loss: 3.9962
[09/28 00:24:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 14.50	
[09/28 00:24:57 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2138, average loss: 4.0001
[09/28 00:24:57 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.66	top5: 12.55	
[09/28 00:24:57 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/28 00:25:06 visual_prompt]: Epoch 66 / 100: avg data time: 3.76e-02, avg batch time: 0.4950, average train loss: 4.0787
[09/28 00:25:07 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1696, average loss: 4.0276
[09/28 00:25:07 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/28 00:25:15 visual_prompt]: Inference (test):avg data time: 9.49e-05, avg batch time: 0.2137, average loss: 4.0393
[09/28 00:25:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.61	top5: 12.23	
[09/28 00:25:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/28 00:25:23 visual_prompt]: Epoch 67 / 100: avg data time: 5.05e-02, avg batch time: 0.5071, average train loss: 4.0375
[09/28 00:25:24 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1699, average loss: 3.9004
[09/28 00:25:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/28 00:25:32 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2137, average loss: 3.9581
[09/28 00:25:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.14	top5: 12.34	
[09/28 00:25:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/28 00:25:40 visual_prompt]: Epoch 68 / 100: avg data time: 4.64e-02, avg batch time: 0.5035, average train loss: 4.0123
[09/28 00:25:42 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1697, average loss: 3.9418
[09/28 00:25:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.50	top5: 15.50	
[09/28 00:25:49 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2146, average loss: 4.0238
[09/28 00:25:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.15	top5: 13.83	
[09/28 00:25:49 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/28 00:25:58 visual_prompt]: Epoch 69 / 100: avg data time: 3.92e-02, avg batch time: 0.4997, average train loss: 3.8547
[09/28 00:25:59 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1698, average loss: 3.6462
[09/28 00:25:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.00	top5: 28.50	
[09/28 00:26:07 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2137, average loss: 3.7752
[09/28 00:26:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.37	top5: 23.83	
[09/28 00:26:07 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/28 00:26:15 visual_prompt]: Epoch 70 / 100: avg data time: 4.29e-02, avg batch time: 0.5003, average train loss: 3.5548
[09/28 00:26:17 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1703, average loss: 3.8038
[09/28 00:26:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.00	top5: 20.50	
[09/28 00:26:24 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2135, average loss: 3.8545
[09/28 00:26:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.53	top5: 19.10	
[09/28 00:26:24 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/28 00:26:32 visual_prompt]: Epoch 71 / 100: avg data time: 4.21e-02, avg batch time: 0.5007, average train loss: 3.1234
[09/28 00:26:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1700, average loss: 2.1901
[09/28 00:26:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 42.50	top5: 71.00	
[09/28 00:26:41 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2143, average loss: 2.6549
[09/28 00:26:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 31.44	top5: 60.27	
[09/28 00:26:41 visual_prompt]: Best epoch 71: best metric: 0.425
[09/28 00:26:41 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/28 00:26:50 visual_prompt]: Epoch 72 / 100: avg data time: 3.74e-02, avg batch time: 0.4955, average train loss: 1.8427
[09/28 00:26:51 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1700, average loss: 1.3827
[09/28 00:26:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 62.50	top5: 89.50	
[09/28 00:26:59 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2154, average loss: 2.0891
[09/28 00:26:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 43.99	top5: 76.28	
[09/28 00:26:59 visual_prompt]: Best epoch 72: best metric: 0.625
[09/28 00:26:59 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/28 00:27:07 visual_prompt]: Epoch 73 / 100: avg data time: 4.86e-02, avg batch time: 0.5054, average train loss: 1.0043
[09/28 00:27:09 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1700, average loss: 0.5454
[09/28 00:27:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 85.50	top5: 99.50	
[09/28 00:27:16 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2151, average loss: 1.6986
[09/28 00:27:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 52.98	top5: 82.39	
[09/28 00:27:16 visual_prompt]: Best epoch 73: best metric: 0.855
[09/28 00:27:16 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/28 00:27:24 visual_prompt]: Epoch 74 / 100: avg data time: 4.73e-02, avg batch time: 0.5043, average train loss: 0.5009
[09/28 00:27:26 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1700, average loss: 0.3157
[09/28 00:27:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 95.50	top5: 100.00	
[09/28 00:27:34 visual_prompt]: Inference (test):avg data time: 4.86e-05, avg batch time: 0.2148, average loss: 1.5680
[09/28 00:27:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 57.66	top5: 85.85	
[09/28 00:27:34 visual_prompt]: Best epoch 74: best metric: 0.955
[09/28 00:27:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/28 00:27:42 visual_prompt]: Epoch 75 / 100: avg data time: 4.71e-02, avg batch time: 0.5040, average train loss: 0.2291
[09/28 00:27:43 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1699, average loss: 0.1452
[09/28 00:27:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/28 00:27:51 visual_prompt]: Inference (test):avg data time: 2.58e-04, avg batch time: 0.2150, average loss: 1.4946
[09/28 00:27:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.49	top5: 85.90	
[09/28 00:27:51 visual_prompt]: Best epoch 75: best metric: 0.980
[09/28 00:27:51 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/28 00:27:59 visual_prompt]: Epoch 76 / 100: avg data time: 4.59e-02, avg batch time: 0.5026, average train loss: 0.1332
[09/28 00:28:01 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1701, average loss: 0.0856
[09/28 00:28:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/28 00:28:08 visual_prompt]: Inference (test):avg data time: 5.22e-04, avg batch time: 0.2145, average loss: 1.4327
[09/28 00:28:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.11	top5: 88.14	
[09/28 00:28:08 visual_prompt]: Best epoch 76: best metric: 0.995
[09/28 00:28:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/28 00:28:16 visual_prompt]: Epoch 77 / 100: avg data time: 3.72e-02, avg batch time: 0.4942, average train loss: 0.0944
[09/28 00:28:18 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1698, average loss: 0.0845
[09/28 00:28:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:28:25 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2144, average loss: 1.4215
[09/28 00:28:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.28	top5: 87.87	
[09/28 00:28:25 visual_prompt]: Best epoch 77: best metric: 1.000
[09/28 00:28:25 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/28 00:28:34 visual_prompt]: Epoch 78 / 100: avg data time: 5.01e-02, avg batch time: 0.5066, average train loss: 0.0795
[09/28 00:28:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1703, average loss: 0.0666
[09/28 00:28:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:28:43 visual_prompt]: Inference (test):avg data time: 3.89e-05, avg batch time: 0.2138, average loss: 1.3724
[09/28 00:28:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.87	top5: 88.24	
[09/28 00:28:43 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/28 00:28:51 visual_prompt]: Epoch 79 / 100: avg data time: 4.73e-02, avg batch time: 0.5043, average train loss: 0.0715
[09/28 00:28:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1700, average loss: 0.0630
[09/28 00:28:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:29:00 visual_prompt]: Inference (test):avg data time: 1.92e-04, avg batch time: 0.2151, average loss: 1.3773
[09/28 00:29:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.66	top5: 88.30	
[09/28 00:29:00 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/28 00:29:08 visual_prompt]: Epoch 80 / 100: avg data time: 4.38e-02, avg batch time: 0.5013, average train loss: 0.0661
[09/28 00:29:10 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1702, average loss: 0.0595
[09/28 00:29:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:29:17 visual_prompt]: Inference (test):avg data time: 1.42e-04, avg batch time: 0.2144, average loss: 1.3529
[09/28 00:29:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.14	top5: 88.72	
[09/28 00:29:17 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/28 00:29:26 visual_prompt]: Epoch 81 / 100: avg data time: 4.91e-02, avg batch time: 0.5062, average train loss: 0.0673
[09/28 00:29:27 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1701, average loss: 0.0515
[09/28 00:29:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:29:35 visual_prompt]: Inference (test):avg data time: 5.11e-04, avg batch time: 0.2144, average loss: 1.3285
[09/28 00:29:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.88	top5: 89.36	
[09/28 00:29:35 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/28 00:29:43 visual_prompt]: Epoch 82 / 100: avg data time: 5.04e-02, avg batch time: 0.5069, average train loss: 0.0602
[09/28 00:29:45 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1697, average loss: 0.0439
[09/28 00:29:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:29:52 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2140, average loss: 1.3176
[09/28 00:29:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.94	top5: 89.41	
[09/28 00:29:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/28 00:30:00 visual_prompt]: Epoch 83 / 100: avg data time: 3.45e-02, avg batch time: 0.4919, average train loss: 0.0566
[09/28 00:30:02 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.1698, average loss: 0.0473
[09/28 00:30:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:30:09 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2144, average loss: 1.3061
[09/28 00:30:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 64.89	top5: 89.41	
[09/28 00:30:09 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/28 00:30:18 visual_prompt]: Epoch 84 / 100: avg data time: 4.35e-02, avg batch time: 0.5010, average train loss: 0.0511
[09/28 00:30:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1699, average loss: 0.0445
[09/28 00:30:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:30:27 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2140, average loss: 1.3344
[09/28 00:30:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.67	top5: 89.47	
[09/28 00:30:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/28 00:30:35 visual_prompt]: Epoch 85 / 100: avg data time: 4.69e-02, avg batch time: 0.5037, average train loss: 0.0497
[09/28 00:30:37 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1696, average loss: 0.0415
[09/28 00:30:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:30:44 visual_prompt]: Inference (test):avg data time: 3.74e-05, avg batch time: 0.2148, average loss: 1.3129
[09/28 00:30:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.43	top5: 90.00	
[09/28 00:30:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/28 00:30:53 visual_prompt]: Epoch 86 / 100: avg data time: 4.91e-02, avg batch time: 0.5065, average train loss: 0.0520
[09/28 00:30:54 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1699, average loss: 0.0786
[09/28 00:30:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/28 00:31:02 visual_prompt]: Inference (test):avg data time: 3.87e-05, avg batch time: 0.2145, average loss: 1.3947
[09/28 00:31:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 62.13	top5: 89.10	
[09/28 00:31:02 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/28 00:31:10 visual_prompt]: Epoch 87 / 100: avg data time: 3.87e-02, avg batch time: 0.4956, average train loss: 0.0680
[09/28 00:31:12 visual_prompt]: Inference (val):avg data time: 4.03e-05, avg batch time: 0.1702, average loss: 0.0570
[09/28 00:31:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:31:19 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2152, average loss: 1.3423
[09/28 00:31:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.05	top5: 89.20	
[09/28 00:31:19 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/28 00:31:27 visual_prompt]: Epoch 88 / 100: avg data time: 5.04e-02, avg batch time: 0.5069, average train loss: 0.0550
[09/28 00:31:29 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1699, average loss: 0.0406
[09/28 00:31:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:31:36 visual_prompt]: Inference (test):avg data time: 2.98e-04, avg batch time: 0.2153, average loss: 1.3043
[09/28 00:31:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.21	top5: 89.57	
[09/28 00:31:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/28 00:31:45 visual_prompt]: Epoch 89 / 100: avg data time: 4.49e-02, avg batch time: 0.5017, average train loss: 0.0444
[09/28 00:31:46 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1698, average loss: 0.0322
[09/28 00:31:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:31:54 visual_prompt]: Inference (test):avg data time: 1.26e-03, avg batch time: 0.2151, average loss: 1.2881
[09/28 00:31:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.28	top5: 90.21	
[09/28 00:31:54 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/28 00:32:02 visual_prompt]: Epoch 90 / 100: avg data time: 4.74e-02, avg batch time: 0.5040, average train loss: 0.0351
[09/28 00:32:04 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1697, average loss: 0.0273
[09/28 00:32:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:32:11 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2151, average loss: 1.2848
[09/28 00:32:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.85	top5: 90.21	
[09/28 00:32:11 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/28 00:32:19 visual_prompt]: Epoch 91 / 100: avg data time: 4.50e-02, avg batch time: 0.5024, average train loss: 0.0311
[09/28 00:32:21 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1700, average loss: 0.0241
[09/28 00:32:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:32:29 visual_prompt]: Inference (test):avg data time: 3.82e-05, avg batch time: 0.2142, average loss: 1.2906
[09/28 00:32:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.48	top5: 89.52	
[09/28 00:32:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/28 00:32:37 visual_prompt]: Epoch 92 / 100: avg data time: 4.46e-02, avg batch time: 0.5013, average train loss: 0.0282
[09/28 00:32:38 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1699, average loss: 0.0227
[09/28 00:32:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:32:46 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2138, average loss: 1.2762
[09/28 00:32:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.90	top5: 90.53	
[09/28 00:32:46 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/28 00:32:54 visual_prompt]: Epoch 93 / 100: avg data time: 3.72e-02, avg batch time: 0.4956, average train loss: 0.0271
[09/28 00:32:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1694, average loss: 0.0224
[09/28 00:32:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:33:03 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2138, average loss: 1.2872
[09/28 00:33:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.53	top5: 90.48	
[09/28 00:33:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/28 00:33:11 visual_prompt]: Epoch 94 / 100: avg data time: 4.16e-02, avg batch time: 0.4985, average train loss: 0.0261
[09/28 00:33:13 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.1705, average loss: 0.0216
[09/28 00:33:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:33:20 visual_prompt]: Inference (test):avg data time: 4.06e-05, avg batch time: 0.2144, average loss: 1.2800
[09/28 00:33:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 90.53	
[09/28 00:33:20 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/28 00:33:29 visual_prompt]: Epoch 95 / 100: avg data time: 4.85e-02, avg batch time: 0.5069, average train loss: 0.0255
[09/28 00:33:30 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1700, average loss: 0.0217
[09/28 00:33:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:33:38 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2139, average loss: 1.2812
[09/28 00:33:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.85	top5: 90.69	
[09/28 00:33:38 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/28 00:33:46 visual_prompt]: Epoch 96 / 100: avg data time: 5.10e-02, avg batch time: 0.5077, average train loss: 0.0252
[09/28 00:33:48 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1697, average loss: 0.0215
[09/28 00:33:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:33:55 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2143, average loss: 1.2800
[09/28 00:33:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.64	top5: 90.74	
[09/28 00:33:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/28 00:34:04 visual_prompt]: Epoch 97 / 100: avg data time: 4.25e-02, avg batch time: 0.4995, average train loss: 0.0251
[09/28 00:34:05 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1701, average loss: 0.0213
[09/28 00:34:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:34:13 visual_prompt]: Inference (test):avg data time: 5.49e-04, avg batch time: 0.2146, average loss: 1.2797
[09/28 00:34:13 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.59	top5: 90.48	
[09/28 00:34:13 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/28 00:34:21 visual_prompt]: Epoch 98 / 100: avg data time: 4.56e-02, avg batch time: 0.5022, average train loss: 0.0247
[09/28 00:34:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1704, average loss: 0.0210
[09/28 00:34:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:34:30 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2139, average loss: 1.2802
[09/28 00:34:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.53	top5: 90.43	
[09/28 00:34:30 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/28 00:34:38 visual_prompt]: Epoch 99 / 100: avg data time: 5.09e-02, avg batch time: 0.5080, average train loss: 0.0247
[09/28 00:34:40 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1701, average loss: 0.0211
[09/28 00:34:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:34:47 visual_prompt]: Inference (test):avg data time: 1.16e-04, avg batch time: 0.2148, average loss: 1.2809
[09/28 00:34:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.48	top5: 90.43	
[09/28 00:34:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/28 00:34:56 visual_prompt]: Epoch 100 / 100: avg data time: 4.72e-02, avg batch time: 0.5043, average train loss: 0.0245
[09/28 00:34:57 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1700, average loss: 0.0211
[09/28 00:34:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:35:05 visual_prompt]: Inference (test):avg data time: 4.33e-04, avg batch time: 0.2147, average loss: 1.2810
[09/28 00:35:05 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.48	top5: 90.43	
[09/28 00:35:05 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 00:35:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 00:35:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-dtd', 'DATA.NUMBER_CLASSES', '47', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 00:35:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 00:35:05 visual_prompt]: Training with config:
[09/28 00:35:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-dtd/sup_vitb16_imagenet21k/prompt50/crop224/test/seed8490/lr5.0_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 8490, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-dtd', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 47, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 00:35:05 visual_prompt]: Loading training data...
[09/28 00:35:05 visual_prompt]: Constructing vtab-dtd dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:35:07 visual_prompt]: Number of images: 1000
[09/28 00:35:07 visual_prompt]: Number of classes: 47 / 47
[09/28 00:35:07 visual_prompt]: Loading validation data...
[09/28 00:35:07 visual_prompt]: Constructing vtab-dtd dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split validation[:200], from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:35:08 visual_prompt]: Number of images: 200
[09/28 00:35:08 visual_prompt]: Number of classes: 47 / 47
[09/28 00:35:08 visual_prompt]: Loading test data...
[09/28 00:35:08 visual_prompt]: Constructing vtab-dtd dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/dtd/3.0.1
[INFO: dataset_builder.py:  573]: Reusing dataset dtd (visual_prompt_tuning/data_path/dtd/3.0.1)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset dtd for split test, from visual_prompt_tuning/data_path/dtd/3.0.1
[09/28 00:35:12 visual_prompt]: Number of images: 1880
[09/28 00:35:12 visual_prompt]: Number of classes: 47 / 47
[09/28 00:35:12 visual_prompt]: Constructing models...
[09/28 00:35:15 visual_prompt]: Total Parameters: 86295599	 Gradient Parameters: 496943
[09/28 00:35:15 visual_prompt]: tuned percent:0.576
[09/28 00:35:15 visual_prompt]: Device used for model: 0
[09/28 00:35:15 visual_prompt]: Setting up Evaluator...
[09/28 00:35:15 visual_prompt]: Setting up Trainer...
[09/28 00:35:15 visual_prompt]: 	Setting up the optimizer...
[09/28 00:35:15 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 00:35:23 visual_prompt]: Epoch 1 / 100: avg data time: 4.48e-02, avg batch time: 0.4979, average train loss: 3.9143
[09/28 00:35:24 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1689, average loss: 3.9041
[09/28 00:35:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 16.50	
[09/28 00:35:32 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2125, average loss: 3.9249
[09/28 00:35:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 1.97	top5: 10.43	
[09/28 00:35:32 visual_prompt]: Best epoch 1: best metric: 0.030
[09/28 00:35:32 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[09/28 00:35:40 visual_prompt]: Epoch 2 / 100: avg data time: 4.58e-02, avg batch time: 0.4999, average train loss: 3.8925
[09/28 00:35:42 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1692, average loss: 3.8063
[09/28 00:35:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 16.00	
[09/28 00:35:49 visual_prompt]: Inference (test):avg data time: 4.01e-05, avg batch time: 0.2128, average loss: 3.8766
[09/28 00:35:49 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 11.86	
[09/28 00:35:49 visual_prompt]: Best epoch 2: best metric: 0.045
[09/28 00:35:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[09/28 00:35:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.55e-02, avg batch time: 0.5004, average train loss: 3.9193
[09/28 00:35:59 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1697, average loss: 3.8720
[09/28 00:35:59 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 12.00	
[09/28 00:36:06 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2139, average loss: 3.9029
[09/28 00:36:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 12.02	
[09/28 00:36:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[09/28 00:36:14 visual_prompt]: Epoch 4 / 100: avg data time: 4.16e-02, avg batch time: 0.4980, average train loss: 3.8801
[09/28 00:36:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1694, average loss: 3.7111
[09/28 00:36:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 24.00	
[09/28 00:36:23 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2133, average loss: 3.7263
[09/28 00:36:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 5.69	top5: 23.51	
[09/28 00:36:23 visual_prompt]: Best epoch 4: best metric: 0.065
[09/28 00:36:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[09/28 00:36:32 visual_prompt]: Epoch 5 / 100: avg data time: 3.66e-02, avg batch time: 0.4935, average train loss: 3.7047
[09/28 00:36:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1696, average loss: 4.3502
[09/28 00:36:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 14.50	
[09/28 00:36:41 visual_prompt]: Inference (test):avg data time: 4.59e-04, avg batch time: 0.2138, average loss: 4.4322
[09/28 00:36:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.82	top5: 13.56	
[09/28 00:36:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[09/28 00:36:49 visual_prompt]: Epoch 6 / 100: avg data time: 3.72e-02, avg batch time: 0.4933, average train loss: 3.8174
[09/28 00:36:50 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1697, average loss: 3.2094
[09/28 00:36:50 visual_prompt]: Classification results with val_vtab-dtd: top1: 17.00	top5: 42.00	
[09/28 00:36:58 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2136, average loss: 3.3510
[09/28 00:36:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 17.13	top5: 40.37	
[09/28 00:36:58 visual_prompt]: Best epoch 6: best metric: 0.170
[09/28 00:36:58 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[09/28 00:37:06 visual_prompt]: Epoch 7 / 100: avg data time: 4.50e-02, avg batch time: 0.5011, average train loss: 3.6633
[09/28 00:37:08 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1696, average loss: 3.5645
[09/28 00:37:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 8.00	top5: 32.50	
[09/28 00:37:15 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2145, average loss: 3.7252
[09/28 00:37:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 8.72	top5: 27.13	
[09/28 00:37:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[09/28 00:37:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.87e-02, avg batch time: 0.5058, average train loss: 4.0526
[09/28 00:37:25 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1699, average loss: 3.6609
[09/28 00:37:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 10.50	top5: 30.00	
[09/28 00:37:32 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2141, average loss: 3.9564
[09/28 00:37:32 visual_prompt]: Classification results with test_vtab-dtd: top1: 7.82	top5: 23.78	
[09/28 00:37:32 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[09/28 00:37:41 visual_prompt]: Epoch 9 / 100: avg data time: 4.94e-02, avg batch time: 0.5056, average train loss: 4.0151
[09/28 00:37:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1696, average loss: 3.9864
[09/28 00:37:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 10.50	top5: 26.50	
[09/28 00:37:50 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2143, average loss: 4.0917
[09/28 00:37:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 6.97	top5: 24.26	
[09/28 00:37:50 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[09/28 00:37:58 visual_prompt]: Epoch 10 / 100: avg data time: 4.82e-02, avg batch time: 0.5047, average train loss: 3.7854
[09/28 00:38:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1698, average loss: 3.9271
[09/28 00:38:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 11.00	top5: 27.50	
[09/28 00:38:07 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2134, average loss: 3.9867
[09/28 00:38:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 9.68	top5: 28.03	
[09/28 00:38:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[09/28 00:38:15 visual_prompt]: Epoch 11 / 100: avg data time: 4.64e-02, avg batch time: 0.5033, average train loss: 4.4885
[09/28 00:38:17 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1698, average loss: 5.3283
[09/28 00:38:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/28 00:38:24 visual_prompt]: Inference (test):avg data time: 3.04e-05, avg batch time: 0.2143, average loss: 4.8757
[09/28 00:38:24 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.39	top5: 12.66	
[09/28 00:38:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[09/28 00:38:33 visual_prompt]: Epoch 12 / 100: avg data time: 4.71e-02, avg batch time: 0.5041, average train loss: 4.7552
[09/28 00:38:34 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1700, average loss: 4.9949
[09/28 00:38:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 13.00	
[09/28 00:38:41 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2140, average loss: 4.7176
[09/28 00:38:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 13.09	
[09/28 00:38:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[09/28 00:38:50 visual_prompt]: Epoch 13 / 100: avg data time: 3.75e-02, avg batch time: 0.4955, average train loss: 4.6362
[09/28 00:38:51 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1702, average loss: 4.6146
[09/28 00:38:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 14.00	
[09/28 00:38:59 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2138, average loss: 4.3579
[09/28 00:38:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.03	top5: 12.66	
[09/28 00:38:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[09/28 00:39:07 visual_prompt]: Epoch 14 / 100: avg data time: 4.07e-02, avg batch time: 0.4980, average train loss: 4.7390
[09/28 00:39:08 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1702, average loss: 5.1147
[09/28 00:39:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 14.00	
[09/28 00:39:16 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2139, average loss: 5.0420
[09/28 00:39:16 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.86	
[09/28 00:39:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[09/28 00:39:24 visual_prompt]: Epoch 15 / 100: avg data time: 4.63e-02, avg batch time: 0.5032, average train loss: 4.9256
[09/28 00:39:26 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1699, average loss: 4.7045
[09/28 00:39:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 16.00	
[09/28 00:39:33 visual_prompt]: Inference (test):avg data time: 4.46e-04, avg batch time: 0.2144, average loss: 4.5575
[09/28 00:39:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 13.30	
[09/28 00:39:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[09/28 00:39:42 visual_prompt]: Epoch 16 / 100: avg data time: 4.88e-02, avg batch time: 0.5055, average train loss: 4.3653
[09/28 00:39:43 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1698, average loss: 4.7790
[09/28 00:39:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 10.50	
[09/28 00:39:51 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2140, average loss: 4.6562
[09/28 00:39:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 10.85	
[09/28 00:39:51 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[09/28 00:39:59 visual_prompt]: Epoch 17 / 100: avg data time: 4.93e-02, avg batch time: 0.5056, average train loss: 4.3380
[09/28 00:40:01 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1696, average loss: 4.3297
[09/28 00:40:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 14.00	
[09/28 00:40:08 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2134, average loss: 4.2927
[09/28 00:40:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.60	
[09/28 00:40:08 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[09/28 00:40:16 visual_prompt]: Epoch 18 / 100: avg data time: 3.98e-02, avg batch time: 0.4970, average train loss: 4.3209
[09/28 00:40:18 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1695, average loss: 4.3627
[09/28 00:40:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.50	
[09/28 00:40:25 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2137, average loss: 4.3398
[09/28 00:40:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:40:25 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[09/28 00:40:33 visual_prompt]: Epoch 19 / 100: avg data time: 4.49e-02, avg batch time: 0.5018, average train loss: 4.5412
[09/28 00:40:35 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1701, average loss: 4.6191
[09/28 00:40:35 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 6.50	
[09/28 00:40:42 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2137, average loss: 4.6051
[09/28 00:40:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.01	
[09/28 00:40:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[09/28 00:40:51 visual_prompt]: Epoch 20 / 100: avg data time: 5.23e-02, avg batch time: 0.5092, average train loss: 4.4110
[09/28 00:40:52 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1694, average loss: 4.0704
[09/28 00:40:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 9.50	
[09/28 00:41:00 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2133, average loss: 4.1581
[09/28 00:41:00 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:41:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[09/28 00:41:08 visual_prompt]: Epoch 21 / 100: avg data time: 4.53e-02, avg batch time: 0.5011, average train loss: 4.1328
[09/28 00:41:10 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1692, average loss: 4.1611
[09/28 00:41:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 10.50	
[09/28 00:41:17 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2134, average loss: 4.1524
[09/28 00:41:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:41:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[09/28 00:41:26 visual_prompt]: Epoch 22 / 100: avg data time: 5.15e-02, avg batch time: 0.5072, average train loss: 4.1467
[09/28 00:41:27 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1698, average loss: 4.4042
[09/28 00:41:27 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.00	
[09/28 00:41:34 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2139, average loss: 4.3771
[09/28 00:41:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:41:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[09/28 00:41:43 visual_prompt]: Epoch 23 / 100: avg data time: 3.53e-02, avg batch time: 0.4933, average train loss: 4.2939
[09/28 00:41:44 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1694, average loss: 4.4150
[09/28 00:41:44 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 8.50	
[09/28 00:41:52 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2134, average loss: 4.3932
[09/28 00:41:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:41:52 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[09/28 00:42:00 visual_prompt]: Epoch 24 / 100: avg data time: 4.81e-02, avg batch time: 0.5048, average train loss: 4.2872
[09/28 00:42:02 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1691, average loss: 4.2795
[09/28 00:42:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 9.50	
[09/28 00:42:09 visual_prompt]: Inference (test):avg data time: 4.00e-05, avg batch time: 0.2139, average loss: 4.3330
[09/28 00:42:09 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:42:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[09/28 00:42:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.29e-02, avg batch time: 0.5089, average train loss: 4.1861
[09/28 00:42:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1697, average loss: 4.0099
[09/28 00:42:19 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 8.50	
[09/28 00:42:26 visual_prompt]: Inference (test):avg data time: 1.66e-04, avg batch time: 0.2136, average loss: 4.0443
[09/28 00:42:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.64	
[09/28 00:42:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[09/28 00:42:35 visual_prompt]: Epoch 26 / 100: avg data time: 4.64e-02, avg batch time: 0.5019, average train loss: 4.1578
[09/28 00:42:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1696, average loss: 4.3307
[09/28 00:42:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 11.50	
[09/28 00:42:43 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2142, average loss: 4.3335
[09/28 00:42:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 10.64	
[09/28 00:42:43 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[09/28 00:42:52 visual_prompt]: Epoch 27 / 100: avg data time: 4.71e-02, avg batch time: 0.5029, average train loss: 4.0847
[09/28 00:42:53 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1696, average loss: 4.0950
[09/28 00:42:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.00	
[09/28 00:43:01 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2146, average loss: 4.1441
[09/28 00:43:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:43:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[09/28 00:43:09 visual_prompt]: Epoch 28 / 100: avg data time: 5.08e-02, avg batch time: 0.5069, average train loss: 4.1302
[09/28 00:43:11 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1701, average loss: 4.1234
[09/28 00:43:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 9.50	
[09/28 00:43:18 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2139, average loss: 4.0559
[09/28 00:43:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:43:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[09/28 00:43:26 visual_prompt]: Epoch 29 / 100: avg data time: 4.55e-02, avg batch time: 0.5024, average train loss: 4.0850
[09/28 00:43:28 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1696, average loss: 4.0810
[09/28 00:43:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 10.50	
[09/28 00:43:35 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2136, average loss: 4.0384
[09/28 00:43:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.64	
[09/28 00:43:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[09/28 00:43:44 visual_prompt]: Epoch 30 / 100: avg data time: 4.70e-02, avg batch time: 0.5032, average train loss: 4.0531
[09/28 00:43:45 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1698, average loss: 4.0086
[09/28 00:43:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 10.50	
[09/28 00:43:53 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2144, average loss: 4.0302
[09/28 00:43:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:43:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[09/28 00:44:01 visual_prompt]: Epoch 31 / 100: avg data time: 4.73e-02, avg batch time: 0.5050, average train loss: 4.0850
[09/28 00:44:03 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1699, average loss: 3.9928
[09/28 00:44:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 10.00	
[09/28 00:44:10 visual_prompt]: Inference (test):avg data time: 3.50e-05, avg batch time: 0.2140, average loss: 4.0509
[09/28 00:44:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.69	
[09/28 00:44:10 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[09/28 00:44:18 visual_prompt]: Epoch 32 / 100: avg data time: 5.09e-02, avg batch time: 0.5064, average train loss: 4.1216
[09/28 00:44:20 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1697, average loss: 4.2183
[09/28 00:44:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 0.50	top5: 11.00	
[09/28 00:44:27 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2138, average loss: 4.1678
[09/28 00:44:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:44:27 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[09/28 00:44:35 visual_prompt]: Epoch 33 / 100: avg data time: 3.50e-02, avg batch time: 0.4935, average train loss: 4.0274
[09/28 00:44:37 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1695, average loss: 4.1412
[09/28 00:44:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 16.50	
[09/28 00:44:44 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2134, average loss: 4.1731
[09/28 00:44:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.50	top5: 10.64	
[09/28 00:44:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[09/28 00:44:53 visual_prompt]: Epoch 34 / 100: avg data time: 4.53e-02, avg batch time: 0.5026, average train loss: 4.1203
[09/28 00:44:54 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1697, average loss: 4.1766
[09/28 00:44:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/28 00:45:02 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2141, average loss: 4.2473
[09/28 00:45:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:45:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[09/28 00:45:10 visual_prompt]: Epoch 35 / 100: avg data time: 4.57e-02, avg batch time: 0.5017, average train loss: 4.1540
[09/28 00:45:11 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1697, average loss: 4.0511
[09/28 00:45:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 12.50	
[09/28 00:45:19 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2148, average loss: 4.0490
[09/28 00:45:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:45:19 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[09/28 00:45:27 visual_prompt]: Epoch 36 / 100: avg data time: 4.59e-02, avg batch time: 0.5034, average train loss: 4.0460
[09/28 00:45:29 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1699, average loss: 4.0597
[09/28 00:45:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 11.00	
[09/28 00:45:36 visual_prompt]: Inference (test):avg data time: 2.96e-05, avg batch time: 0.2138, average loss: 4.1512
[09/28 00:45:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:45:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[09/28 00:45:44 visual_prompt]: Epoch 37 / 100: avg data time: 3.98e-02, avg batch time: 0.4974, average train loss: 4.0649
[09/28 00:45:46 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1697, average loss: 3.9843
[09/28 00:45:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 11.50	
[09/28 00:45:53 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2139, average loss: 4.0314
[09/28 00:45:53 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.02	top5: 10.80	
[09/28 00:45:53 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[09/28 00:46:02 visual_prompt]: Epoch 38 / 100: avg data time: 3.97e-02, avg batch time: 0.4978, average train loss: 4.0460
[09/28 00:46:03 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1699, average loss: 4.0703
[09/28 00:46:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 13.00	
[09/28 00:46:11 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2143, average loss: 4.1229
[09/28 00:46:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.94	top5: 11.70	
[09/28 00:46:11 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[09/28 00:46:19 visual_prompt]: Epoch 39 / 100: avg data time: 4.18e-02, avg batch time: 0.4982, average train loss: 4.0921
[09/28 00:46:20 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1700, average loss: 3.9723
[09/28 00:46:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.50	
[09/28 00:46:28 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2150, average loss: 4.0410
[09/28 00:46:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.07	top5: 10.90	
[09/28 00:46:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[09/28 00:46:36 visual_prompt]: Epoch 40 / 100: avg data time: 4.98e-02, avg batch time: 0.5057, average train loss: 4.0830
[09/28 00:46:38 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1701, average loss: 4.0264
[09/28 00:46:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 11.50	
[09/28 00:46:45 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2136, average loss: 4.1004
[09/28 00:46:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.91	
[09/28 00:46:45 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[09/28 00:46:53 visual_prompt]: Epoch 41 / 100: avg data time: 4.67e-02, avg batch time: 0.5025, average train loss: 4.0476
[09/28 00:46:55 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1697, average loss: 4.0030
[09/28 00:46:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 10.50	
[09/28 00:47:02 visual_prompt]: Inference (test):avg data time: 2.97e-05, avg batch time: 0.2141, average loss: 4.0546
[09/28 00:47:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:47:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[09/28 00:47:11 visual_prompt]: Epoch 42 / 100: avg data time: 4.94e-02, avg batch time: 0.5069, average train loss: 4.0251
[09/28 00:47:12 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1695, average loss: 4.0472
[09/28 00:47:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 10.00	
[09/28 00:47:20 visual_prompt]: Inference (test):avg data time: 2.98e-05, avg batch time: 0.2141, average loss: 4.0419
[09/28 00:47:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/28 00:47:20 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[09/28 00:47:28 visual_prompt]: Epoch 43 / 100: avg data time: 4.83e-02, avg batch time: 0.5049, average train loss: 4.0306
[09/28 00:47:30 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1699, average loss: 3.9725
[09/28 00:47:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.50	top5: 14.00	
[09/28 00:47:37 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2138, average loss: 4.0103
[09/28 00:47:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.98	top5: 11.28	
[09/28 00:47:37 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[09/28 00:47:45 visual_prompt]: Epoch 44 / 100: avg data time: 4.93e-02, avg batch time: 0.5057, average train loss: 4.0443
[09/28 00:47:47 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1698, average loss: 4.1608
[09/28 00:47:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 12.00	
[09/28 00:47:54 visual_prompt]: Inference (test):avg data time: 4.29e-04, avg batch time: 0.2142, average loss: 4.1251
[09/28 00:47:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.49	
[09/28 00:47:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[09/28 00:48:03 visual_prompt]: Epoch 45 / 100: avg data time: 3.93e-02, avg batch time: 0.4981, average train loss: 4.0103
[09/28 00:48:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 4.0117
[09/28 00:48:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 9.00	
[09/28 00:48:12 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2148, average loss: 4.0152
[09/28 00:48:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:48:12 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[09/28 00:48:20 visual_prompt]: Epoch 46 / 100: avg data time: 5.05e-02, avg batch time: 0.5072, average train loss: 4.0359
[09/28 00:48:22 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1696, average loss: 3.9443
[09/28 00:48:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 16.50	
[09/28 00:48:29 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2138, average loss: 4.0479
[09/28 00:48:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:48:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[09/28 00:48:37 visual_prompt]: Epoch 47 / 100: avg data time: 3.74e-02, avg batch time: 0.4952, average train loss: 4.0061
[09/28 00:48:39 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1696, average loss: 3.9688
[09/28 00:48:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.50	top5: 13.00	
[09/28 00:48:46 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2134, average loss: 4.0228
[09/28 00:48:46 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.06	
[09/28 00:48:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[09/28 00:48:54 visual_prompt]: Epoch 48 / 100: avg data time: 4.56e-02, avg batch time: 0.5014, average train loss: 3.9974
[09/28 00:48:56 visual_prompt]: Inference (val):avg data time: 4.18e-05, avg batch time: 0.1696, average loss: 4.0032
[09/28 00:48:56 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 11.00	
[09/28 00:49:03 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2144, average loss: 4.0420
[09/28 00:49:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.18	top5: 10.43	
[09/28 00:49:03 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[09/28 00:49:12 visual_prompt]: Epoch 49 / 100: avg data time: 4.46e-02, avg batch time: 0.5012, average train loss: 4.0064
[09/28 00:49:13 visual_prompt]: Inference (val):avg data time: 4.02e-05, avg batch time: 0.1696, average loss: 4.0280
[09/28 00:49:13 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 9.50	
[09/28 00:49:21 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2139, average loss: 4.0100
[09/28 00:49:21 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.22	
[09/28 00:49:21 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[09/28 00:49:29 visual_prompt]: Epoch 50 / 100: avg data time: 4.91e-02, avg batch time: 0.5050, average train loss: 4.0338
[09/28 00:49:30 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1696, average loss: 3.9963
[09/28 00:49:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 9.50	
[09/28 00:49:38 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2138, average loss: 3.9826
[09/28 00:49:38 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.80	
[09/28 00:49:38 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[09/28 00:49:46 visual_prompt]: Epoch 51 / 100: avg data time: 4.86e-02, avg batch time: 0.5050, average train loss: 3.9997
[09/28 00:49:48 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1699, average loss: 3.9611
[09/28 00:49:48 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 13.50	
[09/28 00:49:55 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2139, average loss: 3.9853
[09/28 00:49:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.09	top5: 13.14	
[09/28 00:49:55 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[09/28 00:50:03 visual_prompt]: Epoch 52 / 100: avg data time: 3.74e-02, avg batch time: 0.4950, average train loss: 4.0104
[09/28 00:50:05 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 3.9400
[09/28 00:50:05 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 13.50	
[09/28 00:50:12 visual_prompt]: Inference (test):avg data time: 3.03e-05, avg batch time: 0.2141, average loss: 3.9745
[09/28 00:50:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 11.17	
[09/28 00:50:12 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[09/28 00:50:21 visual_prompt]: Epoch 53 / 100: avg data time: 5.27e-02, avg batch time: 0.5094, average train loss: 3.9724
[09/28 00:50:22 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1701, average loss: 3.9895
[09/28 00:50:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 14.00	
[09/28 00:50:30 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2147, average loss: 4.0083
[09/28 00:50:30 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.34	top5: 12.71	
[09/28 00:50:30 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[09/28 00:50:38 visual_prompt]: Epoch 54 / 100: avg data time: 4.73e-02, avg batch time: 0.5032, average train loss: 3.9556
[09/28 00:50:40 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1699, average loss: 3.9587
[09/28 00:50:40 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.50	top5: 15.00	
[09/28 00:50:47 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2144, average loss: 4.0928
[09/28 00:50:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 10.64	
[09/28 00:50:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[09/28 00:50:55 visual_prompt]: Epoch 55 / 100: avg data time: 4.03e-02, avg batch time: 0.4988, average train loss: 4.0477
[09/28 00:50:57 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1696, average loss: 3.9878
[09/28 00:50:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 1.00	top5: 13.50	
[09/28 00:51:04 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2147, average loss: 3.9860
[09/28 00:51:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.13	top5: 12.50	
[09/28 00:51:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[09/28 00:51:13 visual_prompt]: Epoch 56 / 100: avg data time: 4.80e-02, avg batch time: 0.5061, average train loss: 3.9646
[09/28 00:51:14 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1699, average loss: 3.8262
[09/28 00:51:14 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.00	top5: 22.00	
[09/28 00:51:22 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2147, average loss: 3.9172
[09/28 00:51:22 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.46	top5: 16.60	
[09/28 00:51:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[09/28 00:51:30 visual_prompt]: Epoch 57 / 100: avg data time: 4.79e-02, avg batch time: 0.5042, average train loss: 3.9584
[09/28 00:51:32 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1701, average loss: 3.9509
[09/28 00:51:32 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 14.00	
[09/28 00:51:39 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2139, average loss: 3.9842
[09/28 00:51:39 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.46	top5: 11.91	
[09/28 00:51:39 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[09/28 00:51:47 visual_prompt]: Epoch 58 / 100: avg data time: 4.89e-02, avg batch time: 0.5068, average train loss: 3.9293
[09/28 00:51:49 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1702, average loss: 3.9518
[09/28 00:51:49 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 14.50	
[09/28 00:51:56 visual_prompt]: Inference (test):avg data time: 4.15e-05, avg batch time: 0.2143, average loss: 3.9542
[09/28 00:51:56 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.88	top5: 15.05	
[09/28 00:51:56 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[09/28 00:52:05 visual_prompt]: Epoch 59 / 100: avg data time: 4.32e-02, avg batch time: 0.4994, average train loss: 3.8667
[09/28 00:52:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1697, average loss: 3.7887
[09/28 00:52:06 visual_prompt]: Classification results with val_vtab-dtd: top1: 6.50	top5: 20.50	
[09/28 00:52:14 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2142, average loss: 3.8575
[09/28 00:52:14 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.78	top5: 18.40	
[09/28 00:52:14 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[09/28 00:52:22 visual_prompt]: Epoch 60 / 100: avg data time: 4.74e-02, avg batch time: 0.5041, average train loss: 3.8708
[09/28 00:52:24 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1699, average loss: 3.8743
[09/28 00:52:24 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 19.50	
[09/28 00:52:31 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2148, average loss: 3.9557
[09/28 00:52:31 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.24	top5: 15.37	
[09/28 00:52:31 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[09/28 00:52:39 visual_prompt]: Epoch 61 / 100: avg data time: 4.01e-02, avg batch time: 0.4989, average train loss: 3.8632
[09/28 00:52:41 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1702, average loss: 4.0234
[09/28 00:52:41 visual_prompt]: Classification results with val_vtab-dtd: top1: 2.00	top5: 12.50	
[09/28 00:52:48 visual_prompt]: Inference (test):avg data time: 3.10e-05, avg batch time: 0.2144, average loss: 4.0260
[09/28 00:52:48 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.71	top5: 11.60	
[09/28 00:52:48 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[09/28 00:52:57 visual_prompt]: Epoch 62 / 100: avg data time: 4.96e-02, avg batch time: 0.5061, average train loss: 3.8395
[09/28 00:52:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1699, average loss: 3.7736
[09/28 00:52:58 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 20.50	
[09/28 00:53:06 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2145, average loss: 3.8790
[09/28 00:53:06 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.03	top5: 15.53	
[09/28 00:53:06 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[09/28 00:53:14 visual_prompt]: Epoch 63 / 100: avg data time: 4.99e-02, avg batch time: 0.5065, average train loss: 3.8499
[09/28 00:53:16 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1696, average loss: 3.8191
[09/28 00:53:16 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.00	top5: 17.00	
[09/28 00:53:23 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2160, average loss: 3.8492
[09/28 00:53:23 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.35	top5: 15.74	
[09/28 00:53:23 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[09/28 00:53:31 visual_prompt]: Epoch 64 / 100: avg data time: 4.61e-02, avg batch time: 0.5028, average train loss: 3.9508
[09/28 00:53:33 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 3.8741
[09/28 00:53:33 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.50	top5: 17.50	
[09/28 00:53:41 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2141, average loss: 3.8871
[09/28 00:53:41 visual_prompt]: Classification results with test_vtab-dtd: top1: 2.87	top5: 18.67	
[09/28 00:53:41 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[09/28 00:53:49 visual_prompt]: Epoch 65 / 100: avg data time: 4.75e-02, avg batch time: 0.5053, average train loss: 3.8769
[09/28 00:53:51 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1700, average loss: 3.8057
[09/28 00:53:51 visual_prompt]: Classification results with val_vtab-dtd: top1: 4.00	top5: 18.50	
[09/28 00:53:58 visual_prompt]: Inference (test):avg data time: 1.60e-04, avg batch time: 0.2145, average loss: 3.8369
[09/28 00:53:58 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.04	top5: 16.17	
[09/28 00:53:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[09/28 00:54:06 visual_prompt]: Epoch 66 / 100: avg data time: 4.77e-02, avg batch time: 0.5042, average train loss: 3.8338
[09/28 00:54:08 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1698, average loss: 3.7519
[09/28 00:54:08 visual_prompt]: Classification results with val_vtab-dtd: top1: 3.50	top5: 21.00	
[09/28 00:54:15 visual_prompt]: Inference (test):avg data time: 3.66e-05, avg batch time: 0.2145, average loss: 3.8009
[09/28 00:54:15 visual_prompt]: Classification results with test_vtab-dtd: top1: 3.40	top5: 16.81	
[09/28 00:54:15 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[09/28 00:54:24 visual_prompt]: Epoch 67 / 100: avg data time: 4.92e-02, avg batch time: 0.5061, average train loss: 3.7166
[09/28 00:54:25 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1696, average loss: 3.7448
[09/28 00:54:25 visual_prompt]: Classification results with val_vtab-dtd: top1: 5.00	top5: 20.00	
[09/28 00:54:33 visual_prompt]: Inference (test):avg data time: 2.92e-05, avg batch time: 0.2151, average loss: 3.7926
[09/28 00:54:33 visual_prompt]: Classification results with test_vtab-dtd: top1: 4.41	top5: 18.62	
[09/28 00:54:33 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[09/28 00:54:41 visual_prompt]: Epoch 68 / 100: avg data time: 4.26e-02, avg batch time: 0.4999, average train loss: 3.6616
[09/28 00:54:42 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1700, average loss: 3.4588
[09/28 00:54:42 visual_prompt]: Classification results with val_vtab-dtd: top1: 12.50	top5: 32.50	
[09/28 00:54:50 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2141, average loss: 3.5755
[09/28 00:54:50 visual_prompt]: Classification results with test_vtab-dtd: top1: 8.35	top5: 27.77	
[09/28 00:54:50 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[09/28 00:54:58 visual_prompt]: Epoch 69 / 100: avg data time: 4.82e-02, avg batch time: 0.5057, average train loss: 3.5562
[09/28 00:55:00 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1704, average loss: 3.6722
[09/28 00:55:00 visual_prompt]: Classification results with val_vtab-dtd: top1: 7.50	top5: 25.00	
[09/28 00:55:07 visual_prompt]: Inference (test):avg data time: 1.01e-03, avg batch time: 0.2149, average loss: 3.6747
[09/28 00:55:07 visual_prompt]: Classification results with test_vtab-dtd: top1: 6.86	top5: 24.89	
[09/28 00:55:07 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[09/28 00:55:16 visual_prompt]: Epoch 70 / 100: avg data time: 4.76e-02, avg batch time: 0.5039, average train loss: 3.4618
[09/28 00:55:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1700, average loss: 3.2361
[09/28 00:55:17 visual_prompt]: Classification results with val_vtab-dtd: top1: 17.00	top5: 41.50	
[09/28 00:55:25 visual_prompt]: Inference (test):avg data time: 1.66e-04, avg batch time: 0.2153, average loss: 3.3807
[09/28 00:55:25 visual_prompt]: Classification results with test_vtab-dtd: top1: 12.82	top5: 35.64	
[09/28 00:55:25 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[09/28 00:55:33 visual_prompt]: Epoch 71 / 100: avg data time: 5.12e-02, avg batch time: 0.5078, average train loss: 2.7761
[09/28 00:55:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1702, average loss: 2.3158
[09/28 00:55:34 visual_prompt]: Classification results with val_vtab-dtd: top1: 36.50	top5: 70.00	
[09/28 00:55:42 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2140, average loss: 2.6473
[09/28 00:55:42 visual_prompt]: Classification results with test_vtab-dtd: top1: 29.79	top5: 62.18	
[09/28 00:55:42 visual_prompt]: Best epoch 71: best metric: 0.365
[09/28 00:55:42 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[09/28 00:55:50 visual_prompt]: Epoch 72 / 100: avg data time: 4.32e-02, avg batch time: 0.5009, average train loss: 1.6710
[09/28 00:55:52 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1698, average loss: 0.9254
[09/28 00:55:52 visual_prompt]: Classification results with val_vtab-dtd: top1: 75.00	top5: 97.00	
[09/28 00:55:59 visual_prompt]: Inference (test):avg data time: 3.84e-05, avg batch time: 0.2144, average loss: 1.7091
[09/28 00:55:59 visual_prompt]: Classification results with test_vtab-dtd: top1: 53.51	top5: 83.30	
[09/28 00:55:59 visual_prompt]: Best epoch 72: best metric: 0.750
[09/28 00:55:59 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[09/28 00:56:08 visual_prompt]: Epoch 73 / 100: avg data time: 4.40e-02, avg batch time: 0.5016, average train loss: 0.8234
[09/28 00:56:09 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1704, average loss: 0.3954
[09/28 00:56:09 visual_prompt]: Classification results with val_vtab-dtd: top1: 91.00	top5: 100.00	
[09/28 00:56:17 visual_prompt]: Inference (test):avg data time: 5.24e-04, avg batch time: 0.2144, average loss: 1.4367
[09/28 00:56:17 visual_prompt]: Classification results with test_vtab-dtd: top1: 60.59	top5: 88.14	
[09/28 00:56:17 visual_prompt]: Best epoch 73: best metric: 0.910
[09/28 00:56:17 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[09/28 00:56:25 visual_prompt]: Epoch 74 / 100: avg data time: 4.00e-02, avg batch time: 0.4991, average train loss: 0.3545
[09/28 00:56:26 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1702, average loss: 0.1869
[09/28 00:56:26 visual_prompt]: Classification results with val_vtab-dtd: top1: 97.50	top5: 100.00	
[09/28 00:56:34 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2150, average loss: 1.4119
[09/28 00:56:34 visual_prompt]: Classification results with test_vtab-dtd: top1: 61.06	top5: 87.29	
[09/28 00:56:34 visual_prompt]: Best epoch 74: best metric: 0.975
[09/28 00:56:34 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[09/28 00:56:42 visual_prompt]: Epoch 75 / 100: avg data time: 4.73e-02, avg batch time: 0.5044, average train loss: 0.1747
[09/28 00:56:43 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1702, average loss: 0.1361
[09/28 00:56:43 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.00	top5: 100.00	
[09/28 00:56:51 visual_prompt]: Inference (test):avg data time: 4.13e-05, avg batch time: 0.2142, average loss: 1.3302
[09/28 00:56:51 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.67	top5: 89.47	
[09/28 00:56:51 visual_prompt]: Best epoch 75: best metric: 0.980
[09/28 00:56:51 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[09/28 00:56:59 visual_prompt]: Epoch 76 / 100: avg data time: 4.66e-02, avg batch time: 0.5045, average train loss: 0.1153
[09/28 00:57:01 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1698, average loss: 0.1020
[09/28 00:57:01 visual_prompt]: Classification results with val_vtab-dtd: top1: 98.50	top5: 100.00	
[09/28 00:57:08 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2145, average loss: 1.3095
[09/28 00:57:08 visual_prompt]: Classification results with test_vtab-dtd: top1: 63.09	top5: 89.52	
[09/28 00:57:08 visual_prompt]: Best epoch 76: best metric: 0.985
[09/28 00:57:08 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[09/28 00:57:17 visual_prompt]: Epoch 77 / 100: avg data time: 4.50e-02, avg batch time: 0.5029, average train loss: 0.0851
[09/28 00:57:18 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1698, average loss: 0.0665
[09/28 00:57:18 visual_prompt]: Classification results with val_vtab-dtd: top1: 99.50	top5: 100.00	
[09/28 00:57:26 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2139, average loss: 1.2481
[09/28 00:57:26 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.74	top5: 90.59	
[09/28 00:57:26 visual_prompt]: Best epoch 77: best metric: 0.995
[09/28 00:57:26 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[09/28 00:57:34 visual_prompt]: Epoch 78 / 100: avg data time: 4.79e-02, avg batch time: 0.5044, average train loss: 0.0705
[09/28 00:57:36 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1701, average loss: 0.0538
[09/28 00:57:36 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:57:43 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2144, average loss: 1.2376
[09/28 00:57:43 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.96	top5: 90.43	
[09/28 00:57:43 visual_prompt]: Best epoch 78: best metric: 1.000
[09/28 00:57:43 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[09/28 00:57:52 visual_prompt]: Epoch 79 / 100: avg data time: 4.53e-02, avg batch time: 0.5018, average train loss: 0.0642
[09/28 00:57:53 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1699, average loss: 0.0520
[09/28 00:57:53 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:58:01 visual_prompt]: Inference (test):avg data time: 4.19e-05, avg batch time: 0.2147, average loss: 1.2300
[09/28 00:58:01 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.12	top5: 90.64	
[09/28 00:58:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[09/28 00:58:09 visual_prompt]: Epoch 80 / 100: avg data time: 4.60e-02, avg batch time: 0.5030, average train loss: 0.0594
[09/28 00:58:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1699, average loss: 0.0474
[09/28 00:58:10 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:58:18 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2142, average loss: 1.2154
[09/28 00:58:18 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 90.74	
[09/28 00:58:18 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[09/28 00:58:26 visual_prompt]: Epoch 81 / 100: avg data time: 4.31e-02, avg batch time: 0.5010, average train loss: 0.0538
[09/28 00:58:28 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1697, average loss: 0.0425
[09/28 00:58:28 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:58:35 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2144, average loss: 1.2349
[09/28 00:58:35 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 90.69	
[09/28 00:58:35 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[09/28 00:58:44 visual_prompt]: Epoch 82 / 100: avg data time: 3.63e-02, avg batch time: 0.4934, average train loss: 0.0486
[09/28 00:58:45 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1703, average loss: 0.0369
[09/28 00:58:45 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:58:52 visual_prompt]: Inference (test):avg data time: 4.83e-04, avg batch time: 0.2149, average loss: 1.2232
[09/28 00:58:52 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 90.90	
[09/28 00:58:52 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[09/28 00:59:01 visual_prompt]: Epoch 83 / 100: avg data time: 3.70e-02, avg batch time: 0.4949, average train loss: 0.0469
[09/28 00:59:02 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1704, average loss: 0.0357
[09/28 00:59:02 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:59:10 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2140, average loss: 1.2158
[09/28 00:59:10 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.54	top5: 90.59	
[09/28 00:59:10 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[09/28 00:59:18 visual_prompt]: Epoch 84 / 100: avg data time: 4.43e-02, avg batch time: 0.5009, average train loss: 0.0444
[09/28 00:59:20 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1698, average loss: 0.0314
[09/28 00:59:20 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:59:27 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2148, average loss: 1.2335
[09/28 00:59:27 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 90.59	
[09/28 00:59:27 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[09/28 00:59:35 visual_prompt]: Epoch 85 / 100: avg data time: 3.37e-02, avg batch time: 0.4922, average train loss: 0.0409
[09/28 00:59:37 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1700, average loss: 0.0304
[09/28 00:59:37 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 00:59:44 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2138, average loss: 1.2299
[09/28 00:59:44 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.44	top5: 90.48	
[09/28 00:59:44 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[09/28 00:59:53 visual_prompt]: Epoch 86 / 100: avg data time: 3.93e-02, avg batch time: 0.4964, average train loss: 0.0423
[09/28 00:59:54 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1697, average loss: 0.0312
[09/28 00:59:54 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:00:01 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2145, average loss: 1.2506
[09/28 01:00:02 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.33	top5: 90.32	
[09/28 01:00:02 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[09/28 01:00:10 visual_prompt]: Epoch 87 / 100: avg data time: 4.46e-02, avg batch time: 0.5014, average train loss: 0.0396
[09/28 01:00:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1697, average loss: 0.0288
[09/28 01:00:11 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:00:19 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2144, average loss: 1.2355
[09/28 01:00:19 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.29	top5: 90.43	
[09/28 01:00:19 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[09/28 01:00:27 visual_prompt]: Epoch 88 / 100: avg data time: 4.57e-02, avg batch time: 0.5030, average train loss: 0.0337
[09/28 01:00:29 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1702, average loss: 0.0273
[09/28 01:00:29 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:00:36 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2146, average loss: 1.2411
[09/28 01:00:36 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 90.21	
[09/28 01:00:36 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[09/28 01:00:45 visual_prompt]: Epoch 89 / 100: avg data time: 4.04e-02, avg batch time: 0.4983, average train loss: 0.0289
[09/28 01:00:46 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1698, average loss: 0.0217
[09/28 01:00:46 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:00:54 visual_prompt]: Inference (test):avg data time: 2.99e-05, avg batch time: 0.2137, average loss: 1.2478
[09/28 01:00:54 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.48	
[09/28 01:00:54 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[09/28 01:01:02 visual_prompt]: Epoch 90 / 100: avg data time: 3.95e-02, avg batch time: 0.4970, average train loss: 0.0255
[09/28 01:01:03 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1703, average loss: 0.0213
[09/28 01:01:03 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:01:11 visual_prompt]: Inference (test):avg data time: 3.67e-05, avg batch time: 0.2139, average loss: 1.2746
[09/28 01:01:11 visual_prompt]: Classification results with test_vtab-dtd: top1: 65.64	top5: 90.80	
[09/28 01:01:11 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[09/28 01:01:19 visual_prompt]: Epoch 91 / 100: avg data time: 4.10e-02, avg batch time: 0.4984, average train loss: 0.0234
[09/28 01:01:21 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1699, average loss: 0.0180
[09/28 01:01:21 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:01:28 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2142, average loss: 1.2508
[09/28 01:01:28 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 90.64	
[09/28 01:01:28 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[09/28 01:01:36 visual_prompt]: Epoch 92 / 100: avg data time: 3.43e-02, avg batch time: 0.4928, average train loss: 0.0212
[09/28 01:01:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1699, average loss: 0.0175
[09/28 01:01:38 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:01:45 visual_prompt]: Inference (test):avg data time: 1.85e-04, avg batch time: 0.2141, average loss: 1.2533
[09/28 01:01:45 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.91	top5: 90.53	
[09/28 01:01:45 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[09/28 01:01:54 visual_prompt]: Epoch 93 / 100: avg data time: 4.31e-02, avg batch time: 0.5001, average train loss: 0.0205
[09/28 01:01:55 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1702, average loss: 0.0157
[09/28 01:01:55 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:02:03 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2143, average loss: 1.2641
[09/28 01:02:03 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.97	top5: 89.95	
[09/28 01:02:03 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[09/28 01:02:11 visual_prompt]: Epoch 94 / 100: avg data time: 4.44e-02, avg batch time: 0.5025, average train loss: 0.0200
[09/28 01:02:12 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1700, average loss: 0.0165
[09/28 01:02:12 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:02:20 visual_prompt]: Inference (test):avg data time: 3.83e-05, avg batch time: 0.2145, average loss: 1.2655
[09/28 01:02:20 visual_prompt]: Classification results with test_vtab-dtd: top1: 67.02	top5: 90.43	
[09/28 01:02:20 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[09/28 01:02:28 visual_prompt]: Epoch 95 / 100: avg data time: 4.35e-02, avg batch time: 0.5005, average train loss: 0.0192
[09/28 01:02:30 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1697, average loss: 0.0163
[09/28 01:02:30 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:02:37 visual_prompt]: Inference (test):avg data time: 5.66e-04, avg batch time: 0.2145, average loss: 1.2678
[09/28 01:02:37 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.65	top5: 90.37	
[09/28 01:02:37 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[09/28 01:02:46 visual_prompt]: Epoch 96 / 100: avg data time: 4.78e-02, avg batch time: 0.5043, average train loss: 0.0190
[09/28 01:02:47 visual_prompt]: Inference (val):avg data time: 4.56e-05, avg batch time: 0.1709, average loss: 0.0155
[09/28 01:02:47 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:02:55 visual_prompt]: Inference (test):avg data time: 3.62e-05, avg batch time: 0.2140, average loss: 1.2711
[09/28 01:02:55 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.76	top5: 90.27	
[09/28 01:02:55 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[09/28 01:03:03 visual_prompt]: Epoch 97 / 100: avg data time: 4.66e-02, avg batch time: 0.5037, average train loss: 0.0188
[09/28 01:03:04 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1701, average loss: 0.0157
[09/28 01:03:04 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:03:12 visual_prompt]: Inference (test):avg data time: 5.27e-04, avg batch time: 0.2145, average loss: 1.2706
[09/28 01:03:12 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 90.21	
[09/28 01:03:12 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[09/28 01:03:20 visual_prompt]: Epoch 98 / 100: avg data time: 4.93e-02, avg batch time: 0.5063, average train loss: 0.0186
[09/28 01:03:22 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1703, average loss: 0.0156
[09/28 01:03:22 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:03:29 visual_prompt]: Inference (test):avg data time: 3.05e-05, avg batch time: 0.2138, average loss: 1.2717
[09/28 01:03:29 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.38	top5: 90.27	
[09/28 01:03:29 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[09/28 01:03:38 visual_prompt]: Epoch 99 / 100: avg data time: 4.43e-02, avg batch time: 0.5012, average train loss: 0.0185
[09/28 01:03:39 visual_prompt]: Inference (val):avg data time: 4.54e-05, avg batch time: 0.1702, average loss: 0.0155
[09/28 01:03:39 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:03:47 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2138, average loss: 1.2717
[09/28 01:03:47 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 90.27	
[09/28 01:03:47 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[09/28 01:03:55 visual_prompt]: Epoch 100 / 100: avg data time: 4.77e-02, avg batch time: 0.5040, average train loss: 0.0184
[09/28 01:03:57 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1699, average loss: 0.0155
[09/28 01:03:57 visual_prompt]: Classification results with val_vtab-dtd: top1: 100.00	top5: 100.00	
[09/28 01:04:04 visual_prompt]: Inference (test):avg data time: 4.42e-04, avg batch time: 0.2140, average loss: 1.2717
[09/28 01:04:04 visual_prompt]: Classification results with test_vtab-dtd: top1: 66.49	top5: 90.21	
