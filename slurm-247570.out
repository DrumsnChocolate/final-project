/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 16:54:08 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 16:54:09 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 16:54:09 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 16:54:09 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 16:54:09 visual_prompt]: Training with config:
[11/13 16:54:09 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.25_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 16:54:09 visual_prompt]: Loading training data...
[11/13 16:54:09 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 16:54:09 visual_prompt]: Loading validation data...
[11/13 16:54:09 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 16:54:09 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 16:54:12 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 16:54:12 visual_prompt]: tuned percent:0.536
[11/13 16:54:13 visual_prompt]: Device used for model: 0
[11/13 16:54:13 visual_prompt]: Setting up Evaluator...
[11/13 16:54:13 visual_prompt]: Setting up Trainer...
[11/13 16:54:13 visual_prompt]: 	Setting up the optimizer...
[11/13 16:54:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 17:01:21 visual_prompt]: Epoch 1 / 100: avg data time: 1.18e+01, avg batch time: 12.2296, average train loss: 1.4017
[11/13 17:02:12 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1584, average loss: 1.2969
[11/13 17:02:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 17:02:12 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/13 17:08:42 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1190, average train loss: 1.4240
[11/13 17:09:26 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1551, average loss: 0.6896
[11/13 17:09:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.10	
[11/13 17:09:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/13 17:16:02 visual_prompt]: Epoch 3 / 100: avg data time: 1.10e+01, avg batch time: 11.3221, average train loss: 0.7053
[11/13 17:16:48 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1549, average loss: 0.6910
[11/13 17:16:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.86	
[11/13 17:16:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/13 17:23:30 visual_prompt]: Epoch 4 / 100: avg data time: 1.11e+01, avg batch time: 11.4890, average train loss: 0.6941
[11/13 17:24:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1551, average loss: 0.6943
[11/13 17:24:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.92	
[11/13 17:24:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/13 17:30:56 visual_prompt]: Epoch 5 / 100: avg data time: 1.11e+01, avg batch time: 11.4258, average train loss: 0.7331
[11/13 17:31:41 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1546, average loss: 0.6873
[11/13 17:31:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.26	
[11/13 17:31:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/13 17:38:23 visual_prompt]: Epoch 6 / 100: avg data time: 1.11e+01, avg batch time: 11.4819, average train loss: 0.7440
[11/13 17:39:09 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1549, average loss: 0.6740
[11/13 17:39:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.84	
[11/13 17:39:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/13 17:45:28 visual_prompt]: Epoch 7 / 100: avg data time: 1.05e+01, avg batch time: 10.8283, average train loss: 0.7171
[11/13 17:46:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1547, average loss: 0.6689
[11/13 17:46:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 61.83	
[11/13 17:46:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/13 17:53:02 visual_prompt]: Epoch 8 / 100: avg data time: 1.14e+01, avg batch time: 11.7340, average train loss: 0.7066
[11/13 17:53:49 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1547, average loss: 0.6648
[11/13 17:53:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.47	
[11/13 17:53:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/13 18:00:40 visual_prompt]: Epoch 9 / 100: avg data time: 1.14e+01, avg batch time: 11.7380, average train loss: 0.6864
[11/13 18:01:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1549, average loss: 0.6958
[11/13 18:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.03	
[11/13 18:01:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/13 18:07:53 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1305, average train loss: 0.6628
[11/13 18:08:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1563, average loss: 0.6445
[11/13 18:08:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.86	
[11/13 18:08:40 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/13 18:15:17 visual_prompt]: Epoch 11 / 100: avg data time: 1.10e+01, avg batch time: 11.3355, average train loss: 0.6792
[11/13 18:16:01 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1550, average loss: 0.6552
[11/13 18:16:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.42	
[11/13 18:16:01 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/13 18:22:34 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2318, average train loss: 0.6736
[11/13 18:23:20 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1550, average loss: 0.7371
[11/13 18:23:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 69.09	
[11/13 18:23:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/13 18:29:54 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2360, average train loss: 0.7443
[11/13 18:30:37 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1584, average loss: 0.7039
[11/13 18:30:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.02	
[11/13 18:30:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/13 18:36:59 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8980, average train loss: 0.6801
[11/13 18:37:45 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1550, average loss: 0.7292
[11/13 18:37:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.78	
[11/13 18:37:45 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/13 18:44:30 visual_prompt]: Epoch 15 / 100: avg data time: 1.12e+01, avg batch time: 11.5841, average train loss: 0.6873
[11/13 18:45:13 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1593, average loss: 0.8067
[11/13 18:45:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.88	
[11/13 18:45:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/13 18:51:26 visual_prompt]: Epoch 16 / 100: avg data time: 1.03e+01, avg batch time: 10.6604, average train loss: 0.6775
[11/13 18:52:09 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1552, average loss: 0.8387
[11/13 18:52:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 70.67	
[11/13 18:52:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/13 18:58:46 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e+01, avg batch time: 11.3458, average train loss: 0.7107
[11/13 18:59:29 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1548, average loss: 0.6252
[11/13 18:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.39	
[11/13 18:59:29 visual_prompt]: Best epoch 17: best metric: -0.625
[11/13 18:59:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/13 19:05:45 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e+01, avg batch time: 10.7450, average train loss: 0.6610
[11/13 19:06:27 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1556, average loss: 0.6284
[11/13 19:06:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.66	
[11/13 19:06:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/13 19:12:55 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0572, average train loss: 0.6644
[11/13 19:13:40 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1550, average loss: 0.6291
[11/13 19:13:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.97	
[11/13 19:13:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/13 19:20:10 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1487, average train loss: 0.6069
[11/13 19:20:54 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1551, average loss: 0.6020
[11/13 19:20:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.82	
[11/13 19:20:54 visual_prompt]: Best epoch 20: best metric: -0.602
[11/13 19:20:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/13 19:27:23 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.1007, average train loss: 0.6149
[11/13 19:28:07 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1554, average loss: 0.6033
[11/13 19:28:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.15	
[11/13 19:28:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/13 19:34:35 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.0854, average train loss: 0.6226
[11/13 19:35:19 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1552, average loss: 0.6335
[11/13 19:35:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.48	
[11/13 19:35:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/13 19:41:49 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.1274, average train loss: 0.6043
[11/13 19:42:33 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1565, average loss: 0.6338
[11/13 19:42:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.27	
[11/13 19:42:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/13 19:49:02 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e+01, avg batch time: 11.1142, average train loss: 0.6458
[11/13 19:49:47 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1575, average loss: 0.6417
[11/13 19:49:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.02	
[11/13 19:49:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/13 19:56:16 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1233, average train loss: 0.5915
[11/13 19:57:01 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1571, average loss: 0.6203
[11/13 19:57:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.26	
[11/13 19:57:01 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/13 20:03:30 visual_prompt]: Epoch 26 / 100: avg data time: 1.08e+01, avg batch time: 11.1177, average train loss: 0.6273
[11/13 20:04:14 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1547, average loss: 0.5987
[11/13 20:04:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 74.00	
[11/13 20:04:14 visual_prompt]: Best epoch 26: best metric: -0.599
[11/13 20:04:14 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/13 20:10:44 visual_prompt]: Epoch 27 / 100: avg data time: 1.08e+01, avg batch time: 11.1413, average train loss: 0.5716
[11/13 20:11:28 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1557, average loss: 0.6553
[11/13 20:11:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.53	
[11/13 20:11:28 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/13 20:17:59 visual_prompt]: Epoch 28 / 100: avg data time: 1.08e+01, avg batch time: 11.1412, average train loss: 0.6112
[11/13 20:18:43 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1589, average loss: 0.6402
[11/13 20:18:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.70	
[11/13 20:18:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/13 20:25:12 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1190, average train loss: 0.5532
[11/13 20:25:56 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1550, average loss: 0.6537
[11/13 20:25:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.34	
[11/13 20:25:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/13 20:32:25 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1157, average train loss: 0.5478
[11/13 20:33:09 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1575, average loss: 0.6180
[11/13 20:33:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 72.00	
[11/13 20:33:09 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/13 20:39:38 visual_prompt]: Epoch 31 / 100: avg data time: 1.08e+01, avg batch time: 11.1074, average train loss: 0.5215
[11/13 20:40:23 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1551, average loss: 0.6603
[11/13 20:40:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.18	
[11/13 20:40:23 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/13 20:46:57 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2463, average train loss: 0.5315
[11/13 20:47:42 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1555, average loss: 0.6632
[11/13 20:47:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.74	
[11/13 20:47:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/13 20:54:15 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2278, average train loss: 0.5278
[11/13 20:54:59 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1548, average loss: 0.6460
[11/13 20:54:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.37	
[11/13 20:54:59 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/13 21:01:29 visual_prompt]: Epoch 34 / 100: avg data time: 1.08e+01, avg batch time: 11.1482, average train loss: 0.4912
[11/13 21:02:14 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1551, average loss: 0.6754
[11/13 21:02:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.71	
[11/13 21:02:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/13 21:08:43 visual_prompt]: Epoch 35 / 100: avg data time: 1.08e+01, avg batch time: 11.1177, average train loss: 0.5140
[11/13 21:09:27 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1601, average loss: 0.7196
[11/13 21:09:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.69	
[11/13 21:09:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/13 21:15:56 visual_prompt]: Epoch 36 / 100: avg data time: 1.07e+01, avg batch time: 11.1018, average train loss: 0.5279
[11/13 21:16:40 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1550, average loss: 0.6947
[11/13 21:16:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.56	
[11/13 21:16:40 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/13 21:23:09 visual_prompt]: Epoch 37 / 100: avg data time: 1.08e+01, avg batch time: 11.1178, average train loss: 0.5511
[11/13 21:23:54 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1550, average loss: 0.9179
[11/13 21:23:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.52	
[11/13 21:23:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/13 21:30:23 visual_prompt]: Epoch 38 / 100: avg data time: 1.08e+01, avg batch time: 11.1125, average train loss: 0.5312
[11/13 21:31:07 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1551, average loss: 0.7600
[11/13 21:31:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.42	
[11/13 21:31:07 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/13 21:37:36 visual_prompt]: Epoch 39 / 100: avg data time: 1.08e+01, avg batch time: 11.1206, average train loss: 0.5952
[11/13 21:38:21 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1555, average loss: 0.6483
[11/13 21:38:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.46	
[11/13 21:38:21 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/13 21:44:48 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0453, average train loss: 0.5115
[11/13 21:45:31 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1575, average loss: 0.6356
[11/13 21:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.14	
[11/13 21:45:32 visual_prompt]: Stopping early.
[11/13 21:45:32 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 21:45:32 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 21:45:32 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 21:45:32 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 21:45:32 visual_prompt]: Training with config:
[11/13 21:45:32 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 21:45:32 visual_prompt]: Loading training data...
[11/13 21:45:32 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 21:45:32 visual_prompt]: Loading validation data...
[11/13 21:45:32 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 21:45:32 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 21:45:35 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 21:45:35 visual_prompt]: tuned percent:0.536
[11/13 21:45:36 visual_prompt]: Device used for model: 0
[11/13 21:45:36 visual_prompt]: Setting up Evaluator...
[11/13 21:45:36 visual_prompt]: Setting up Trainer...
[11/13 21:45:36 visual_prompt]: 	Setting up the optimizer...
[11/13 21:45:36 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 21:52:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0779, average train loss: 1.4017
[11/13 21:52:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1550, average loss: 1.2969
[11/13 21:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 21:52:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/13 21:59:16 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.0789, average train loss: 1.0705
[11/13 22:00:00 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1569, average loss: 0.6907
[11/13 22:00:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 47.90	
[11/13 22:00:00 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/13 22:06:29 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1205, average train loss: 0.7019
[11/13 22:07:14 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1550, average loss: 0.6936
[11/13 22:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[11/13 22:07:14 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/13 22:13:43 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1185, average train loss: 0.6916
[11/13 22:14:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1553, average loss: 0.6810
[11/13 22:14:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.06	
[11/13 22:14:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/13 22:20:56 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.1005, average train loss: 0.7094
[11/13 22:21:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1584, average loss: 0.6902
[11/13 22:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.81	
[11/13 22:21:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/13 22:28:11 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1414, average train loss: 0.7276
[11/13 22:28:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1548, average loss: 0.6840
[11/13 22:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 57.69	
[11/13 22:28:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/13 22:35:22 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0391, average train loss: 0.6935
[11/13 22:36:06 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1551, average loss: 0.7299
[11/13 22:36:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.42	
[11/13 22:36:06 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/13 22:42:40 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.2554, average train loss: 0.7299
[11/13 22:43:25 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1551, average loss: 0.6855
[11/13 22:43:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.34	
[11/13 22:43:25 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/13 22:49:59 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2533, average train loss: 0.6886
[11/13 22:50:44 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1549, average loss: 0.7100
[11/13 22:50:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.02	
[11/13 22:50:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/13 22:57:15 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1776, average train loss: 0.6977
[11/13 22:58:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1550, average loss: 0.6916
[11/13 22:58:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[11/13 22:58:00 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/13 23:04:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1417, average train loss: 0.6889
[11/13 23:05:14 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1579, average loss: 0.6854
[11/13 23:05:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.79	
[11/13 23:05:14 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/13 23:11:44 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.1235, average train loss: 0.7003
[11/13 23:12:28 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1547, average loss: 0.6877
[11/13 23:12:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.50	
[11/13 23:12:28 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/13 23:18:57 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1112, average train loss: 0.7056
[11/13 23:19:42 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1547, average loss: 0.7145
[11/13 23:19:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.20	
[11/13 23:19:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/13 23:26:10 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0870, average train loss: 0.7051
[11/13 23:26:55 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 0.6982
[11/13 23:26:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.38	
[11/13 23:26:55 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/13 23:33:26 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1693, average train loss: 0.7057
[11/13 23:34:10 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1551, average loss: 0.6937
[11/13 23:34:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.71	
[11/13 23:34:10 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/13 23:40:40 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e+01, avg batch time: 11.1164, average train loss: 0.6993
[11/13 23:41:24 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1549, average loss: 0.6912
[11/13 23:41:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/13 23:41:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/13 23:47:53 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.1020, average train loss: 0.6922
[11/13 23:48:37 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1547, average loss: 0.6905
[11/13 23:48:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.27	
[11/13 23:48:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/13 23:55:07 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e+01, avg batch time: 11.1226, average train loss: 0.6950
[11/13 23:55:51 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1550, average loss: 0.6953
[11/13 23:55:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.82	
[11/13 23:55:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/14 00:02:20 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.1076, average train loss: 0.6928
[11/14 00:03:04 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1550, average loss: 0.6963
[11/14 00:03:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/14 00:03:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/14 00:09:34 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1300, average train loss: 0.6907
[11/14 00:10:18 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1552, average loss: 0.7014
[11/14 00:10:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.82	
[11/14 00:10:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/14 00:16:45 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0493, average train loss: 0.6969
[11/14 00:17:29 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1567, average loss: 0.6928
[11/14 00:17:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.90	
[11/14 00:17:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/14 00:23:58 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.1042, average train loss: 0.6965
[11/14 00:24:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1566, average loss: 0.6878
[11/14 00:24:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/14 00:24:43 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/14 00:31:12 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.1197, average train loss: 0.6860
[11/14 00:31:56 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1550, average loss: 0.6994
[11/14 00:31:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.66	
[11/14 00:31:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/14 00:38:24 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0668, average train loss: 0.6959
[11/14 00:39:09 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1549, average loss: 0.6884
[11/14 00:39:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.95	
[11/14 00:39:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/14 00:45:42 visual_prompt]: Epoch 25 / 100: avg data time: 1.09e+01, avg batch time: 11.2321, average train loss: 0.6903
[11/14 00:46:27 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1546, average loss: 0.6907
[11/14 00:46:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.15	
[11/14 00:46:27 visual_prompt]: Stopping early.
[11/14 00:46:27 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 00:46:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 00:46:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 00:46:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 00:46:27 visual_prompt]: Training with config:
[11/14 00:46:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 00:46:27 visual_prompt]: Loading training data...
[11/14 00:46:27 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 00:46:27 visual_prompt]: Loading validation data...
[11/14 00:46:27 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 00:46:27 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 00:46:34 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 00:46:34 visual_prompt]: tuned percent:0.536
[11/14 00:46:34 visual_prompt]: Device used for model: 0
[11/14 00:46:34 visual_prompt]: Setting up Evaluator...
[11/14 00:46:34 visual_prompt]: Setting up Trainer...
[11/14 00:46:34 visual_prompt]: 	Setting up the optimizer...
[11/14 00:46:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 00:53:05 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.1870, average train loss: 1.4017
[11/14 00:53:50 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1565, average loss: 1.2969
[11/14 00:53:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 00:53:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/14 01:00:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1511, average train loss: 1.0723
[11/14 01:01:05 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1551, average loss: 0.6909
[11/14 01:01:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.75	
[11/14 01:01:05 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/14 01:07:35 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1456, average train loss: 0.7033
[11/14 01:08:20 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1578, average loss: 0.6938
[11/14 01:08:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.75	
[11/14 01:08:20 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/14 01:14:50 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1531, average train loss: 0.6929
[11/14 01:15:35 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1549, average loss: 0.6804
[11/14 01:15:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.78	
[11/14 01:15:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/14 01:22:05 visual_prompt]: Epoch 5 / 100: avg data time: 1.08e+01, avg batch time: 11.1273, average train loss: 0.7148
[11/14 01:22:49 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1551, average loss: 0.6962
[11/14 01:22:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/14 01:22:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/14 01:29:19 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1222, average train loss: 0.7385
[11/14 01:30:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1548, average loss: 0.6915
[11/14 01:30:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 55.36	
[11/14 01:30:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/14 01:36:31 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0693, average train loss: 0.6963
[11/14 01:37:15 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1549, average loss: 0.6782
[11/14 01:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 59.73	
[11/14 01:37:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/14 01:43:44 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.1024, average train loss: 0.6892
[11/14 01:44:28 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1584, average loss: 0.6818
[11/14 01:44:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.62	
[11/14 01:44:28 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/14 01:50:58 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.1354, average train loss: 0.6901
[11/14 01:51:43 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1554, average loss: 0.7419
[11/14 01:51:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.10	
[11/14 01:51:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/14 01:58:11 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0967, average train loss: 0.6824
[11/14 01:58:56 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1547, average loss: 0.6651
[11/14 01:58:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 64.44	
[11/14 01:58:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/14 02:05:25 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1144, average train loss: 0.6695
[11/14 02:06:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1551, average loss: 0.6550
[11/14 02:06:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.46	
[11/14 02:06:09 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/14 02:12:38 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.1171, average train loss: 0.6575
[11/14 02:13:23 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1551, average loss: 0.6604
[11/14 02:13:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.08	
[11/14 02:13:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/14 02:19:53 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1340, average train loss: 0.6852
[11/14 02:20:37 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1576, average loss: 0.6496
[11/14 02:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.13	
[11/14 02:20:37 visual_prompt]: Best epoch 13: best metric: -0.650
[11/14 02:20:37 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/14 02:27:07 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1242, average train loss: 0.6885
[11/14 02:27:51 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1551, average loss: 0.7683
[11/14 02:27:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.52	
[11/14 02:27:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/14 02:34:21 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1356, average train loss: 0.6791
[11/14 02:35:06 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1572, average loss: 0.6587
[11/14 02:35:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.92	
[11/14 02:35:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/14 02:41:32 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0334, average train loss: 0.6772
[11/14 02:42:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1551, average loss: 0.7687
[11/14 02:42:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.35	
[11/14 02:42:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/14 02:48:44 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0881, average train loss: 0.6523
[11/14 02:49:28 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1553, average loss: 0.6259
[11/14 02:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.15	
[11/14 02:49:28 visual_prompt]: Best epoch 17: best metric: -0.626
[11/14 02:49:28 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/14 02:56:00 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e+01, avg batch time: 11.1742, average train loss: 0.6554
[11/14 02:56:44 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1551, average loss: 0.7966
[11/14 02:56:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.19	
[11/14 02:56:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/14 03:03:15 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.1573, average train loss: 0.6649
[11/14 03:04:00 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1565, average loss: 0.8159
[11/14 03:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.88	
[11/14 03:04:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/14 03:10:30 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1600, average train loss: 0.6487
[11/14 03:11:15 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1552, average loss: 0.7228
[11/14 03:11:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.19	
[11/14 03:11:15 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/14 03:17:45 visual_prompt]: Epoch 21 / 100: avg data time: 1.08e+01, avg batch time: 11.1292, average train loss: 0.6133
[11/14 03:18:29 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1550, average loss: 0.6511
[11/14 03:18:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.17	
[11/14 03:18:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/14 03:24:59 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.1242, average train loss: 0.6008
[11/14 03:25:44 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 0.6419
[11/14 03:25:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.47	
[11/14 03:25:44 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/14 03:32:12 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.1061, average train loss: 0.6125
[11/14 03:32:57 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1564, average loss: 0.7167
[11/14 03:32:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.31	
[11/14 03:32:57 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/14 03:39:27 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e+01, avg batch time: 11.1286, average train loss: 0.6196
[11/14 03:40:11 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1553, average loss: 0.6156
[11/14 03:40:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.17	
[11/14 03:40:11 visual_prompt]: Best epoch 24: best metric: -0.616
[11/14 03:40:11 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/14 03:46:40 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1072, average train loss: 0.5970
[11/14 03:47:24 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1550, average loss: 0.6255
[11/14 03:47:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 70.11	
[11/14 03:47:24 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/14 03:53:52 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0686, average train loss: 0.6580
[11/14 03:54:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1551, average loss: 0.6410
[11/14 03:54:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.98	
[11/14 03:54:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/14 04:01:04 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.0816, average train loss: 0.6072
[11/14 04:01:49 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1554, average loss: 0.6497
[11/14 04:01:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.42	
[11/14 04:01:49 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/14 04:08:15 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.0329, average train loss: 0.6254
[11/14 04:08:59 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1552, average loss: 0.6641
[11/14 04:08:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.57	
[11/14 04:08:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/14 04:15:29 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1193, average train loss: 0.5999
[11/14 04:16:13 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1552, average loss: 0.6243
[11/14 04:16:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.07	
[11/14 04:16:13 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/14 04:22:41 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0825, average train loss: 0.5994
[11/14 04:23:26 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1551, average loss: 0.7013
[11/14 04:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 71.31	
[11/14 04:23:26 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/14 04:29:53 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0608, average train loss: 0.5889
[11/14 04:30:37 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1553, average loss: 0.6347
[11/14 04:30:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.46	
[11/14 04:30:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/14 04:37:06 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0936, average train loss: 0.5848
[11/14 04:37:50 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1554, average loss: 0.6698
[11/14 04:37:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.09	
[11/14 04:37:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/14 04:44:18 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0860, average train loss: 0.5733
[11/14 04:45:03 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1551, average loss: 0.6526
[11/14 04:45:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.39	
[11/14 04:45:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/14 04:51:31 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0829, average train loss: 0.5752
[11/14 04:52:15 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1549, average loss: 0.6379
[11/14 04:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.42	
[11/14 04:52:15 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/14 04:58:41 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0154, average train loss: 0.5710
[11/14 04:59:26 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1553, average loss: 0.6738
[11/14 04:59:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.95	
[11/14 04:59:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/14 05:05:58 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e+01, avg batch time: 11.2150, average train loss: 0.5626
[11/14 05:06:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1554, average loss: 0.6303
[11/14 05:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.31	
[11/14 05:06:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/14 05:13:14 visual_prompt]: Epoch 37 / 100: avg data time: 1.08e+01, avg batch time: 11.1687, average train loss: 0.5539
[11/14 05:13:59 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1552, average loss: 0.7025
[11/14 05:13:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.42	
[11/14 05:13:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/14 05:20:30 visual_prompt]: Epoch 38 / 100: avg data time: 1.08e+01, avg batch time: 11.1789, average train loss: 0.5348
[11/14 05:21:15 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1553, average loss: 0.6442
[11/14 05:21:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.19	
[11/14 05:21:15 visual_prompt]: Stopping early.
[11/14 05:21:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 05:21:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 05:21:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 05:21:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 05:21:16 visual_prompt]: Training with config:
[11/14 05:21:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 05:21:16 visual_prompt]: Loading training data...
[11/14 05:21:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 05:21:17 visual_prompt]: Loading validation data...
[11/14 05:21:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 05:21:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 05:21:24 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 05:21:24 visual_prompt]: tuned percent:0.536
[11/14 05:21:24 visual_prompt]: Device used for model: 0
[11/14 05:21:24 visual_prompt]: Setting up Evaluator...
[11/14 05:21:24 visual_prompt]: Setting up Trainer...
[11/14 05:21:24 visual_prompt]: 	Setting up the optimizer...
[11/14 05:21:24 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 05:27:53 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.1310, average train loss: 1.4017
[11/14 05:28:38 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1550, average loss: 1.2969
[11/14 05:28:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 05:28:38 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/14 05:35:07 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1285, average train loss: 1.0725
[11/14 05:35:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1590, average loss: 0.6909
[11/14 05:35:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.75	
[11/14 05:35:52 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/14 05:42:21 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1194, average train loss: 0.7035
[11/14 05:43:06 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1580, average loss: 0.6938
[11/14 05:43:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.70	
[11/14 05:43:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/14 05:49:35 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1317, average train loss: 0.6930
[11/14 05:50:20 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1575, average loss: 0.6801
[11/14 05:50:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.87	
[11/14 05:50:20 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/14 05:56:50 visual_prompt]: Epoch 5 / 100: avg data time: 1.08e+01, avg batch time: 11.1303, average train loss: 0.7154
[11/14 05:57:34 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1551, average loss: 0.6998
[11/14 05:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[11/14 05:57:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/14 06:04:04 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1229, average train loss: 0.7346
[11/14 06:04:48 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1565, average loss: 0.7218
[11/14 06:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.89	
[11/14 06:04:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/14 06:11:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.1217, average train loss: 0.7038
[11/14 06:12:02 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1552, average loss: 0.6830
[11/14 06:12:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 59.02	
[11/14 06:12:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/14 06:18:31 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.1035, average train loss: 0.6961
[11/14 06:19:15 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1559, average loss: 0.6761
[11/14 06:19:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.57	
[11/14 06:19:15 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/14 06:25:44 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.1102, average train loss: 0.6812
[11/14 06:26:29 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1548, average loss: 0.7409
[11/14 06:26:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.29	
[11/14 06:26:29 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/14 06:32:57 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0873, average train loss: 0.6646
[11/14 06:33:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1549, average loss: 0.6509
[11/14 06:33:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 67.11	
[11/14 06:33:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/14 06:40:08 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.0523, average train loss: 0.6738
[11/14 06:40:52 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1587, average loss: 0.6655
[11/14 06:40:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 68.55	
[11/14 06:40:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/14 06:47:21 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.0849, average train loss: 0.6587
[11/14 06:48:05 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1546, average loss: 0.6666
[11/14 06:48:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.93	
[11/14 06:48:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/14 06:54:33 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.0913, average train loss: 0.6894
[11/14 06:55:18 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1551, average loss: 0.6548
[11/14 06:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.85	
[11/14 06:55:18 visual_prompt]: Best epoch 13: best metric: -0.655
[11/14 06:55:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/14 07:01:44 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0138, average train loss: 0.6878
[11/14 07:02:28 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1550, average loss: 0.6694
[11/14 07:02:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 66.10	
[11/14 07:02:28 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/14 07:09:02 visual_prompt]: Epoch 15 / 100: avg data time: 1.09e+01, avg batch time: 11.2334, average train loss: 0.6835
[11/14 07:09:46 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1551, average loss: 0.6506
[11/14 07:09:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.01	
[11/14 07:09:46 visual_prompt]: Best epoch 15: best metric: -0.651
[11/14 07:09:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/14 07:16:19 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.2233, average train loss: 0.6733
[11/14 07:17:04 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1548, average loss: 0.6882
[11/14 07:17:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 65.52	
[11/14 07:17:04 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/14 07:23:36 visual_prompt]: Epoch 17 / 100: avg data time: 1.08e+01, avg batch time: 11.1804, average train loss: 0.6547
[11/14 07:24:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1550, average loss: 0.6373
[11/14 07:24:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.19	
[11/14 07:24:21 visual_prompt]: Best epoch 17: best metric: -0.637
[11/14 07:24:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/14 07:30:51 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e+01, avg batch time: 11.1557, average train loss: 0.6536
[11/14 07:31:36 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1550, average loss: 0.8856
[11/14 07:31:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 68.59	
[11/14 07:31:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/14 07:38:05 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.1185, average train loss: 0.6741
[11/14 07:38:50 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1553, average loss: 0.8656
[11/14 07:38:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 68.64	
[11/14 07:38:50 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/14 07:45:19 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1159, average train loss: 0.6525
[11/14 07:46:03 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1551, average loss: 0.7656
[11/14 07:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.25	rocauc: 68.59	
[11/14 07:46:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/14 07:52:33 visual_prompt]: Epoch 21 / 100: avg data time: 1.08e+01, avg batch time: 11.1199, average train loss: 0.6191
[11/14 07:53:17 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1587, average loss: 0.6496
[11/14 07:53:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.86	
[11/14 07:53:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/14 07:59:45 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.0869, average train loss: 0.6023
[11/14 08:00:30 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 0.6382
[11/14 08:00:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.94	
[11/14 08:00:30 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/14 08:06:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.1113, average train loss: 0.5954
[11/14 08:07:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1568, average loss: 0.6280
[11/14 08:07:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.39	
[11/14 08:07:44 visual_prompt]: Best epoch 23: best metric: -0.628
[11/14 08:07:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/14 08:14:13 visual_prompt]: Epoch 24 / 100: avg data time: 1.08e+01, avg batch time: 11.1270, average train loss: 0.5988
[11/14 08:14:58 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1549, average loss: 0.6278
[11/14 08:14:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.48	
[11/14 08:14:58 visual_prompt]: Best epoch 24: best metric: -0.628
[11/14 08:14:58 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/14 08:21:27 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1163, average train loss: 0.5862
[11/14 08:22:12 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1552, average loss: 0.6796
[11/14 08:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.38	
[11/14 08:22:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/14 08:28:40 visual_prompt]: Epoch 26 / 100: avg data time: 1.08e+01, avg batch time: 11.1056, average train loss: 0.6070
[11/14 08:29:25 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1584, average loss: 0.6501
[11/14 08:29:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.96	
[11/14 08:29:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/14 08:35:54 visual_prompt]: Epoch 27 / 100: avg data time: 1.08e+01, avg batch time: 11.1134, average train loss: 0.5635
[11/14 08:36:38 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1552, average loss: 0.6744
[11/14 08:36:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.58	
[11/14 08:36:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/14 08:43:07 visual_prompt]: Epoch 28 / 100: avg data time: 1.08e+01, avg batch time: 11.1110, average train loss: 0.6041
[11/14 08:43:52 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1550, average loss: 0.6869
[11/14 08:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.53	
[11/14 08:43:52 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/14 08:50:21 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1326, average train loss: 0.5578
[11/14 08:51:06 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1552, average loss: 0.6818
[11/14 08:51:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.82	
[11/14 08:51:06 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/14 08:57:35 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1239, average train loss: 0.5610
[11/14 08:58:20 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1551, average loss: 0.7042
[11/14 08:58:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.69	
[11/14 08:58:20 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/14 09:04:45 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9958, average train loss: 0.5311
[11/14 09:05:29 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1571, average loss: 0.7157
[11/14 09:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.79	
[11/14 09:05:29 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/14 09:12:02 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2301, average train loss: 0.5580
[11/14 09:12:47 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1551, average loss: 0.6906
[11/14 09:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.94	
[11/14 09:12:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/14 09:19:18 visual_prompt]: Epoch 33 / 100: avg data time: 1.08e+01, avg batch time: 11.1888, average train loss: 0.5323
[11/14 09:20:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1582, average loss: 0.6420
[11/14 09:20:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.53	
[11/14 09:20:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/14 09:26:34 visual_prompt]: Epoch 34 / 100: avg data time: 1.08e+01, avg batch time: 11.1612, average train loss: 0.5270
[11/14 09:27:19 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1563, average loss: 0.6587
[11/14 09:27:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 65.91	
[11/14 09:27:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/14 09:33:49 visual_prompt]: Epoch 35 / 100: avg data time: 1.08e+01, avg batch time: 11.1408, average train loss: 0.5063
[11/14 09:34:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1550, average loss: 0.7180
[11/14 09:34:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 64.48	
[11/14 09:34:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/14 09:41:02 visual_prompt]: Epoch 36 / 100: avg data time: 1.08e+01, avg batch time: 11.1156, average train loss: 0.5004
[11/14 09:41:47 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1550, average loss: 0.7563
[11/14 09:41:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.99	
[11/14 09:41:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/14 09:48:17 visual_prompt]: Epoch 37 / 100: avg data time: 1.08e+01, avg batch time: 11.1392, average train loss: 0.4916
[11/14 09:49:01 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1552, average loss: 0.7571
[11/14 09:49:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.49	
[11/14 09:49:01 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/14 09:55:31 visual_prompt]: Epoch 38 / 100: avg data time: 1.08e+01, avg batch time: 11.1300, average train loss: 0.4944
[11/14 09:56:16 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1550, average loss: 0.8297
[11/14 09:56:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 66.92	
[11/14 09:56:16 visual_prompt]: Stopping early.
[11/14 09:56:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 09:56:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 09:56:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 09:56:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 09:56:16 visual_prompt]: Training with config:
[11/14 09:56:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.1_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 09:56:16 visual_prompt]: Loading training data...
[11/14 09:56:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 09:56:17 visual_prompt]: Loading validation data...
[11/14 09:56:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 09:56:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 09:56:20 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 09:56:20 visual_prompt]: tuned percent:0.536
[11/14 09:56:20 visual_prompt]: Device used for model: 0
[11/14 09:56:20 visual_prompt]: Setting up Evaluator...
[11/14 09:56:20 visual_prompt]: Setting up Trainer...
[11/14 09:56:20 visual_prompt]: 	Setting up the optimizer...
[11/14 09:56:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 10:02:50 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.1484, average train loss: 1.4017
[11/14 10:03:35 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1584, average loss: 1.2969
[11/14 10:03:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 10:03:35 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/14 10:10:05 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1437, average train loss: 1.0725
[11/14 10:10:50 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1551, average loss: 0.6909
[11/14 10:10:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 47.76	
[11/14 10:10:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/14 10:17:19 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1259, average train loss: 0.7035
[11/14 10:18:04 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1550, average loss: 0.6938
[11/14 10:18:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.66	
[11/14 10:18:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/14 10:24:34 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1462, average train loss: 0.6931
[11/14 10:25:19 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1554, average loss: 0.6804
[11/14 10:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.76	
[11/14 10:25:19 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/14 10:31:47 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.0853, average train loss: 0.7155
[11/14 10:32:32 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1551, average loss: 0.6984
[11/14 10:32:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.54	
[11/14 10:32:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/14 10:39:03 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1739, average train loss: 0.7364
[11/14 10:39:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1550, average loss: 0.7177
[11/14 10:39:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.55	
[11/14 10:39:47 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/14 10:46:18 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.1649, average train loss: 0.7035
[11/14 10:47:03 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1565, average loss: 0.6818
[11/14 10:47:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 58.90	
[11/14 10:47:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/14 10:53:33 visual_prompt]: Epoch 8 / 100: avg data time: 1.08e+01, avg batch time: 11.1401, average train loss: 0.6942
[11/14 10:54:18 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1551, average loss: 0.6765
[11/14 10:54:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.25	
[11/14 10:54:18 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/14 11:00:48 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.1575, average train loss: 0.6780
[11/14 11:01:33 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1550, average loss: 0.7291
[11/14 11:01:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.97	
[11/14 11:01:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/14 11:08:22 visual_prompt]: Epoch 10 / 100: avg data time: 1.13e+01, avg batch time: 11.6681, average train loss: 0.6636
[11/14 11:09:28 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1550, average loss: 0.6480
[11/14 11:09:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.50	
[11/14 11:09:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/14 11:16:14 visual_prompt]: Epoch 11 / 100: avg data time: 1.12e+01, avg batch time: 11.5972, average train loss: 0.6750
[11/14 11:16:58 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1554, average loss: 0.6768
[11/14 11:16:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.24	
[11/14 11:16:58 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/14 11:23:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.1388, average train loss: 0.6563
[11/14 11:24:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1553, average loss: 0.6717
[11/14 11:24:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.11	
[11/14 11:24:13 visual_prompt]: Best epoch 12: best metric: -0.672
[11/14 11:24:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/14 11:30:45 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2082, average train loss: 0.6982
[11/14 11:31:30 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1551, average loss: 0.6465
[11/14 11:31:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.19	
[11/14 11:31:30 visual_prompt]: Best epoch 13: best metric: -0.646
[11/14 11:31:30 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/14 11:37:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0736, average train loss: 0.6822
[11/14 11:38:42 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1553, average loss: 0.6681
[11/14 11:38:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.74	
[11/14 11:38:42 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/14 11:45:11 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1122, average train loss: 0.6672
[11/14 11:45:55 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1559, average loss: 0.6460
[11/14 11:45:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.44	
[11/14 11:45:55 visual_prompt]: Best epoch 15: best metric: -0.646
[11/14 11:45:55 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/14 11:52:27 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e+01, avg batch time: 11.1892, average train loss: 0.6628
[11/14 11:53:12 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1551, average loss: 0.6860
[11/14 11:53:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.65	
[11/14 11:53:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/14 11:59:42 visual_prompt]: Epoch 17 / 100: avg data time: 1.08e+01, avg batch time: 11.1501, average train loss: 0.6485
[11/14 12:00:26 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1592, average loss: 0.6349
[11/14 12:00:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.37	
[11/14 12:00:26 visual_prompt]: Best epoch 17: best metric: -0.635
[11/14 12:00:26 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/14 12:06:57 visual_prompt]: Epoch 18 / 100: avg data time: 1.08e+01, avg batch time: 11.1451, average train loss: 0.6506
[11/14 12:07:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1578, average loss: 0.8987
[11/14 12:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.55	
[11/14 12:07:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/14 12:14:12 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.1596, average train loss: 0.6536
[11/14 12:14:57 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1553, average loss: 0.8199
[11/14 12:14:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 69.12	
[11/14 12:14:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/14 12:21:27 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1396, average train loss: 0.6521
[11/14 12:22:12 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1570, average loss: 0.8552
[11/14 12:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 65.82	
[11/14 12:22:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/14 12:28:40 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0994, average train loss: 0.6300
[11/14 12:29:25 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1580, average loss: 0.6533
[11/14 12:29:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.25	
[11/14 12:29:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/14 12:35:53 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.0985, average train loss: 0.5831
[11/14 12:36:38 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1553, average loss: 0.6557
[11/14 12:36:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.71	
[11/14 12:36:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/14 12:43:06 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.1032, average train loss: 0.5873
[11/14 12:43:51 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1551, average loss: 0.6637
[11/14 12:43:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.43	
[11/14 12:43:51 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/14 12:50:20 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.1024, average train loss: 0.5907
[11/14 12:51:04 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1582, average loss: 0.6852
[11/14 12:51:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 64.31	
[11/14 12:51:04 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/14 12:57:32 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.1012, average train loss: 0.5772
[11/14 12:58:17 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1602, average loss: 0.6986
[11/14 12:58:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 66.80	
[11/14 12:58:17 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/14 13:04:44 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0536, average train loss: 0.6101
[11/14 13:05:28 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1552, average loss: 0.6556
[11/14 13:05:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 66.61	
[11/14 13:05:28 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/14 13:11:57 visual_prompt]: Epoch 27 / 100: avg data time: 1.08e+01, avg batch time: 11.1153, average train loss: 0.5715
[11/14 13:12:42 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1552, average loss: 0.6731
[11/14 13:12:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.78	
[11/14 13:12:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/14 13:19:11 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.1060, average train loss: 0.5767
[11/14 13:19:56 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1564, average loss: 0.7598
[11/14 13:19:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 67.54	
[11/14 13:19:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/14 13:26:25 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1310, average train loss: 0.5634
[11/14 13:27:10 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1568, average loss: 0.6520
[11/14 13:27:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.40	
[11/14 13:27:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/14 13:33:38 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0882, average train loss: 0.5466
[11/14 13:34:23 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1552, average loss: 0.7726
[11/14 13:34:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.25	
[11/14 13:34:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/14 13:41:00 visual_prompt]: Epoch 31 / 100: avg data time: 1.10e+01, avg batch time: 11.3440, average train loss: 0.5028
[11/14 13:41:45 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1551, average loss: 0.7586
[11/14 13:41:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.13	
[11/14 13:41:45 visual_prompt]: Stopping early.
[11/14 13:41:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 13:41:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 13:41:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 13:41:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 13:41:46 visual_prompt]: Training with config:
[11/14 13:41:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 13:41:46 visual_prompt]: Loading training data...
[11/14 13:41:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 13:41:46 visual_prompt]: Loading validation data...
[11/14 13:41:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 13:41:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 13:41:49 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 13:41:49 visual_prompt]: tuned percent:0.536
[11/14 13:41:49 visual_prompt]: Device used for model: 0
[11/14 13:41:49 visual_prompt]: Setting up Evaluator...
[11/14 13:41:49 visual_prompt]: Setting up Trainer...
[11/14 13:41:49 visual_prompt]: 	Setting up the optimizer...
[11/14 13:41:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 13:48:21 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.1898, average train loss: 1.4017
[11/14 13:49:05 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1549, average loss: 1.2969
[11/14 13:49:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 13:49:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/14 13:55:36 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1493, average train loss: 0.9963
[11/14 13:56:20 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1550, average loss: 0.6960
[11/14 13:56:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.43	
[11/14 13:56:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/14 14:02:51 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1491, average train loss: 0.7067
[11/14 14:03:35 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1548, average loss: 0.6914
[11/14 14:03:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.16	
[11/14 14:03:35 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/14 14:10:00 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9726, average train loss: 0.6950
[11/14 14:10:43 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1557, average loss: 0.6846
[11/14 14:10:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/14 14:10:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/14 14:17:05 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9126, average train loss: 0.7228
[11/14 14:17:48 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1586, average loss: 0.7047
[11/14 14:17:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.50	
[11/14 14:17:48 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/14 14:24:30 visual_prompt]: Epoch 6 / 100: avg data time: 1.11e+01, avg batch time: 11.4733, average train loss: 0.7257
[11/14 14:25:17 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1549, average loss: 0.7285
[11/14 14:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.29	
[11/14 14:25:17 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/14 14:32:04 visual_prompt]: Epoch 7 / 100: avg data time: 1.13e+01, avg batch time: 11.6393, average train loss: 0.7121
[11/14 14:32:51 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1550, average loss: 0.6850
[11/14 14:32:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.29	
[11/14 14:32:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/14 14:39:35 visual_prompt]: Epoch 8 / 100: avg data time: 1.12e+01, avg batch time: 11.5414, average train loss: 0.7077
[11/14 14:40:21 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1551, average loss: 0.6910
[11/14 14:40:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.30	
[11/14 14:40:21 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/14 14:47:05 visual_prompt]: Epoch 9 / 100: avg data time: 1.12e+01, avg batch time: 11.5584, average train loss: 0.6956
[11/14 14:47:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1548, average loss: 0.7079
[11/14 14:47:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.13	
[11/14 14:47:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/14 14:54:35 visual_prompt]: Epoch 10 / 100: avg data time: 1.12e+01, avg batch time: 11.5159, average train loss: 0.7094
[11/14 14:55:21 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 0.7066
[11/14 14:55:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.42	
[11/14 14:55:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/14 15:02:04 visual_prompt]: Epoch 11 / 100: avg data time: 1.12e+01, avg batch time: 11.5213, average train loss: 0.6881
[11/14 15:02:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1569, average loss: 0.6668
[11/14 15:02:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 63.45	
[11/14 15:02:50 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/14 15:09:34 visual_prompt]: Epoch 12 / 100: avg data time: 1.12e+01, avg batch time: 11.5369, average train loss: 0.6773
[11/14 15:10:22 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1546, average loss: 0.6955
[11/14 15:10:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 64.64	
[11/14 15:10:22 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/14 15:17:06 visual_prompt]: Epoch 13 / 100: avg data time: 1.12e+01, avg batch time: 11.5624, average train loss: 0.6948
[11/14 15:17:53 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1545, average loss: 0.6748
[11/14 15:17:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 63.77	
[11/14 15:17:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/14 15:24:37 visual_prompt]: Epoch 14 / 100: avg data time: 1.12e+01, avg batch time: 11.5339, average train loss: 0.6903
[11/14 15:25:23 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1546, average loss: 0.8157
[11/14 15:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.37	
[11/14 15:25:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/14 15:32:06 visual_prompt]: Epoch 15 / 100: avg data time: 1.12e+01, avg batch time: 11.5227, average train loss: 0.7070
[11/14 15:32:52 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 0.6795
[11/14 15:32:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.03	
[11/14 15:32:52 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/14 15:39:36 visual_prompt]: Epoch 16 / 100: avg data time: 1.12e+01, avg batch time: 11.5286, average train loss: 0.6916
[11/14 15:40:22 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1551, average loss: 0.6782
[11/14 15:40:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 63.08	
[11/14 15:40:22 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/14 15:47:07 visual_prompt]: Epoch 17 / 100: avg data time: 1.12e+01, avg batch time: 11.5533, average train loss: 0.6827
[11/14 15:47:53 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1549, average loss: 0.6761
[11/14 15:47:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.74	
[11/14 15:47:53 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/14 15:54:37 visual_prompt]: Epoch 18 / 100: avg data time: 1.12e+01, avg batch time: 11.5388, average train loss: 0.6973
[11/14 15:55:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 0.7200
[11/14 15:55:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[11/14 15:55:23 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/14 16:02:07 visual_prompt]: Epoch 19 / 100: avg data time: 1.12e+01, avg batch time: 11.5434, average train loss: 0.6949
[11/14 16:02:53 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1547, average loss: 0.6973
[11/14 16:02:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.11	
[11/14 16:02:53 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/14 16:09:36 visual_prompt]: Epoch 20 / 100: avg data time: 1.12e+01, avg batch time: 11.5055, average train loss: 0.6862
[11/14 16:10:22 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1548, average loss: 0.6916
[11/14 16:10:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 61.37	
[11/14 16:10:22 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/14 16:17:05 visual_prompt]: Epoch 21 / 100: avg data time: 1.12e+01, avg batch time: 11.5177, average train loss: 0.6943
[11/14 16:17:51 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1561, average loss: 0.6889
[11/14 16:17:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.74	
[11/14 16:17:51 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/14 16:24:35 visual_prompt]: Epoch 22 / 100: avg data time: 1.12e+01, avg batch time: 11.5338, average train loss: 0.6876
[11/14 16:25:21 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1547, average loss: 0.6961
[11/14 16:25:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 62.75	
[11/14 16:25:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/14 16:32:06 visual_prompt]: Epoch 23 / 100: avg data time: 1.12e+01, avg batch time: 11.5642, average train loss: 0.6779
[11/14 16:32:53 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1547, average loss: 0.7122
[11/14 16:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.84	
[11/14 16:32:53 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/14 16:39:49 visual_prompt]: Epoch 24 / 100: avg data time: 1.15e+01, avg batch time: 11.8855, average train loss: 0.6882
[11/14 16:40:35 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1572, average loss: 0.6783
[11/14 16:40:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.48	
[11/14 16:40:35 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/14 16:47:19 visual_prompt]: Epoch 25 / 100: avg data time: 1.12e+01, avg batch time: 11.5384, average train loss: 0.6854
[11/14 16:48:05 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1557, average loss: 0.6894
[11/14 16:48:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.16	
[11/14 16:48:05 visual_prompt]: Stopping early.
[11/14 16:48:05 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 16:48:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 16:48:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 16:48:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 16:48:05 visual_prompt]: Training with config:
[11/14 16:48:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 16:48:05 visual_prompt]: Loading training data...
[11/14 16:48:05 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 16:48:05 visual_prompt]: Loading validation data...
[11/14 16:48:05 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 16:48:05 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 16:48:10 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 16:48:10 visual_prompt]: tuned percent:0.536
[11/14 16:48:10 visual_prompt]: Device used for model: 0
[11/14 16:48:10 visual_prompt]: Setting up Evaluator...
[11/14 16:48:10 visual_prompt]: Setting up Trainer...
[11/14 16:48:10 visual_prompt]: 	Setting up the optimizer...
[11/14 16:48:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 16:54:54 visual_prompt]: Epoch 1 / 100: avg data time: 1.12e+01, avg batch time: 11.5268, average train loss: 1.4017
[11/14 16:55:40 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1551, average loss: 1.2969
[11/14 16:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 16:55:40 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/14 17:02:23 visual_prompt]: Epoch 2 / 100: avg data time: 1.12e+01, avg batch time: 11.5121, average train loss: 0.9972
[11/14 17:03:06 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1548, average loss: 0.6963
[11/14 17:03:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.34	
[11/14 17:03:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/14 17:09:39 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.2153, average train loss: 0.7074
[11/14 17:10:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1584, average loss: 0.6913
[11/14 17:10:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/14 17:10:24 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/14 17:16:49 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0065, average train loss: 0.6961
[11/14 17:17:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1547, average loss: 0.6843
[11/14 17:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.82	
[11/14 17:17:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/14 17:23:57 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9738, average train loss: 0.7246
[11/14 17:24:41 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1551, average loss: 0.6985
[11/14 17:24:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.95	
[11/14 17:24:41 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/14 17:31:07 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.0217, average train loss: 0.7290
[11/14 17:31:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1549, average loss: 0.6959
[11/14 17:31:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 59.49	
[11/14 17:31:51 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/14 17:38:18 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0406, average train loss: 0.6991
[11/14 17:39:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1563, average loss: 0.6808
[11/14 17:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.92	
[11/14 17:39:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/14 17:45:27 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 11.0036, average train loss: 0.6972
[11/14 17:46:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1557, average loss: 0.6726
[11/14 17:46:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 62.88	
[11/14 17:46:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/14 17:52:41 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.1212, average train loss: 0.6853
[11/14 17:53:26 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1552, average loss: 0.7307
[11/14 17:53:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.64	
[11/14 17:53:26 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/14 17:59:58 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1949, average train loss: 0.6805
[11/14 18:00:43 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1551, average loss: 0.6662
[11/14 18:00:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.90	
[11/14 18:00:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/14 18:07:15 visual_prompt]: Epoch 11 / 100: avg data time: 1.09e+01, avg batch time: 11.2082, average train loss: 0.6860
[11/14 18:08:00 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1551, average loss: 0.6591
[11/14 18:08:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 66.56	
[11/14 18:08:00 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/14 18:14:32 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.2018, average train loss: 0.6924
[11/14 18:15:17 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1551, average loss: 0.6662
[11/14 18:15:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.06	
[11/14 18:15:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/14 18:21:48 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1524, average train loss: 0.6988
[11/14 18:22:33 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1552, average loss: 0.6767
[11/14 18:22:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.99	
[11/14 18:22:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/14 18:29:02 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1210, average train loss: 0.6837
[11/14 18:29:46 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1584, average loss: 0.7999
[11/14 18:29:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.93	
[11/14 18:29:46 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/14 18:36:16 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1222, average train loss: 0.7022
[11/14 18:37:00 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1549, average loss: 0.6705
[11/14 18:37:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.80	
[11/14 18:37:00 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/14 18:43:29 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0850, average train loss: 0.6883
[11/14 18:44:13 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1549, average loss: 0.7709
[11/14 18:44:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.31	
[11/14 18:44:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/14 18:50:53 visual_prompt]: Epoch 17 / 100: avg data time: 1.11e+01, avg batch time: 11.4359, average train loss: 0.6848
[11/14 18:51:46 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1551, average loss: 0.6528
[11/14 18:51:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.95	
[11/14 18:51:46 visual_prompt]: Best epoch 17: best metric: -0.653
[11/14 18:51:46 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/14 18:59:06 visual_prompt]: Epoch 18 / 100: avg data time: 1.22e+01, avg batch time: 12.5671, average train loss: 0.6804
[11/14 18:59:57 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1543, average loss: 0.6983
[11/14 18:59:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.38	
[11/14 18:59:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/14 19:07:33 visual_prompt]: Epoch 19 / 100: avg data time: 1.27e+01, avg batch time: 13.0093, average train loss: 0.6901
[11/14 19:08:19 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1550, average loss: 0.7053
[11/14 19:08:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 68.86	
[11/14 19:08:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/14 19:15:42 visual_prompt]: Epoch 20 / 100: avg data time: 1.23e+01, avg batch time: 12.6551, average train loss: 0.6648
[11/14 19:16:35 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1548, average loss: 0.6887
[11/14 19:16:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.31	
[11/14 19:16:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/14 19:24:00 visual_prompt]: Epoch 21 / 100: avg data time: 1.23e+01, avg batch time: 12.6965, average train loss: 0.6618
[11/14 19:24:47 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1546, average loss: 0.6413
[11/14 19:24:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.41	
[11/14 19:24:47 visual_prompt]: Best epoch 21: best metric: -0.641
[11/14 19:24:47 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/14 19:31:57 visual_prompt]: Epoch 22 / 100: avg data time: 1.19e+01, avg batch time: 12.2762, average train loss: 0.6560
[11/14 19:32:53 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1555, average loss: 0.7079
[11/14 19:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 70.18	
[11/14 19:32:53 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/14 19:40:04 visual_prompt]: Epoch 23 / 100: avg data time: 1.20e+01, avg batch time: 12.3321, average train loss: 0.6578
[11/14 19:40:58 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1551, average loss: 0.6596
[11/14 19:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 68.46	
[11/14 19:40:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/14 19:48:07 visual_prompt]: Epoch 24 / 100: avg data time: 1.19e+01, avg batch time: 12.2565, average train loss: 0.6430
[11/14 19:48:57 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1551, average loss: 0.6839
[11/14 19:48:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.78	
[11/14 19:48:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/14 19:56:01 visual_prompt]: Epoch 25 / 100: avg data time: 1.18e+01, avg batch time: 12.1234, average train loss: 0.6532
[11/14 19:56:50 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1549, average loss: 0.6401
[11/14 19:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.57	
[11/14 19:56:50 visual_prompt]: Best epoch 25: best metric: -0.640
[11/14 19:56:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/14 20:04:01 visual_prompt]: Epoch 26 / 100: avg data time: 1.19e+01, avg batch time: 12.2992, average train loss: 0.6305
[11/14 20:04:50 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1553, average loss: 0.6215
[11/14 20:04:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.17	
[11/14 20:04:50 visual_prompt]: Best epoch 26: best metric: -0.621
[11/14 20:04:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/14 20:12:18 visual_prompt]: Epoch 27 / 100: avg data time: 1.25e+01, avg batch time: 12.8118, average train loss: 0.6230
[11/14 20:13:13 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1583, average loss: 0.6323
[11/14 20:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.73	
[11/14 20:13:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/14 20:20:03 visual_prompt]: Epoch 28 / 100: avg data time: 1.14e+01, avg batch time: 11.7198, average train loss: 0.6312
[11/14 20:20:48 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1549, average loss: 0.6664
[11/14 20:20:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.91	
[11/14 20:20:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/14 20:27:20 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1909, average train loss: 0.6129
[11/14 20:28:05 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1572, average loss: 0.6346
[11/14 20:28:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.26	
[11/14 20:28:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/14 20:34:34 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1103, average train loss: 0.6134
[11/14 20:35:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1556, average loss: 0.6274
[11/14 20:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.66	
[11/14 20:35:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/14 20:41:47 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0886, average train loss: 0.5958
[11/14 20:42:31 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1553, average loss: 0.6279
[11/14 20:42:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.14	
[11/14 20:42:31 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/14 20:49:01 visual_prompt]: Epoch 32 / 100: avg data time: 1.08e+01, avg batch time: 11.1298, average train loss: 0.6147
[11/14 20:49:45 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1552, average loss: 0.6330
[11/14 20:49:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.91	
[11/14 20:49:45 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/14 20:56:14 visual_prompt]: Epoch 33 / 100: avg data time: 1.08e+01, avg batch time: 11.1110, average train loss: 0.5860
[11/14 20:56:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1552, average loss: 0.6258
[11/14 20:56:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.20	
[11/14 20:56:58 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/14 21:03:25 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0486, average train loss: 0.6002
[11/14 21:04:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1550, average loss: 0.7330
[11/14 21:04:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.87	
[11/14 21:04:10 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/14 21:10:37 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0586, average train loss: 0.5978
[11/14 21:11:21 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1558, average loss: 0.6412
[11/14 21:11:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.63	
[11/14 21:11:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/14 21:17:49 visual_prompt]: Epoch 36 / 100: avg data time: 1.07e+01, avg batch time: 11.0793, average train loss: 0.5801
[11/14 21:18:33 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1572, average loss: 0.6651
[11/14 21:18:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.75	
[11/14 21:18:33 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/14 21:25:01 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.0751, average train loss: 0.5674
[11/14 21:25:45 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1549, average loss: 0.7261
[11/14 21:25:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.98	
[11/14 21:25:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/14 21:32:12 visual_prompt]: Epoch 38 / 100: avg data time: 1.07e+01, avg batch time: 11.0519, average train loss: 0.5632
[11/14 21:32:57 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1589, average loss: 0.6685
[11/14 21:32:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.61	
[11/14 21:32:57 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/14 21:39:25 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0832, average train loss: 0.6019
[11/14 21:40:09 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1549, average loss: 0.6897
[11/14 21:40:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 68.00	
[11/14 21:40:09 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/14 21:46:34 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0076, average train loss: 0.5495
[11/14 21:47:19 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1562, average loss: 0.6529
[11/14 21:47:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.53	
[11/14 21:47:19 visual_prompt]: Stopping early.
[11/14 21:47:19 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 21:47:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 21:47:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 21:47:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 21:47:20 visual_prompt]: Training with config:
[11/14 21:47:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 21:47:20 visual_prompt]: Loading training data...
[11/14 21:47:20 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 21:47:20 visual_prompt]: Loading validation data...
[11/14 21:47:20 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 21:47:20 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/14 21:47:23 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/14 21:47:23 visual_prompt]: tuned percent:0.536
[11/14 21:47:23 visual_prompt]: Device used for model: 0
[11/14 21:47:23 visual_prompt]: Setting up Evaluator...
[11/14 21:47:23 visual_prompt]: Setting up Trainer...
[11/14 21:47:23 visual_prompt]: 	Setting up the optimizer...
[11/14 21:47:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 21:53:49 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0183, average train loss: 1.4017
[11/14 21:54:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1549, average loss: 1.2969
[11/14 21:54:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/14 21:54:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/14 22:00:59 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 11.0023, average train loss: 0.9973
[11/14 22:01:44 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1560, average loss: 0.6963
[11/14 22:01:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.32	
[11/14 22:01:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/14 22:08:31 visual_prompt]: Epoch 3 / 100: avg data time: 1.13e+01, avg batch time: 11.6220, average train loss: 0.7075
[11/14 22:09:19 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1562, average loss: 0.6913
[11/14 22:09:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/14 22:09:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/14 22:16:21 visual_prompt]: Epoch 4 / 100: avg data time: 1.17e+01, avg batch time: 12.0488, average train loss: 0.6962
[11/14 22:17:12 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1550, average loss: 0.6843
[11/14 22:17:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.76	
[11/14 22:17:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/14 22:24:21 visual_prompt]: Epoch 5 / 100: avg data time: 1.19e+01, avg batch time: 12.2615, average train loss: 0.7240
[11/14 22:25:08 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1548, average loss: 0.6927
[11/14 22:25:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.74	
[11/14 22:25:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/14 22:32:12 visual_prompt]: Epoch 6 / 100: avg data time: 1.17e+01, avg batch time: 12.0894, average train loss: 0.7304
[11/14 22:32:59 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1567, average loss: 0.6991
[11/14 22:32:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.27	
[11/14 22:32:59 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/14 22:40:01 visual_prompt]: Epoch 7 / 100: avg data time: 1.17e+01, avg batch time: 12.0375, average train loss: 0.7007
[11/14 22:40:46 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1572, average loss: 0.6809
[11/14 22:40:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.41	
[11/14 22:40:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/14 22:48:09 visual_prompt]: Epoch 8 / 100: avg data time: 1.23e+01, avg batch time: 12.6589, average train loss: 0.6972
[11/14 22:48:59 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1549, average loss: 0.6738
[11/14 22:48:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.36	
[11/14 22:48:59 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/14 22:56:07 visual_prompt]: Epoch 9 / 100: avg data time: 1.19e+01, avg batch time: 12.2269, average train loss: 0.6855
[11/14 22:57:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1548, average loss: 0.7340
[11/14 22:57:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.24	
[11/14 22:57:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/14 23:04:01 visual_prompt]: Epoch 10 / 100: avg data time: 1.17e+01, avg batch time: 12.0031, average train loss: 0.6823
[11/14 23:04:50 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1563, average loss: 0.6665
[11/14 23:04:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.85	
[11/14 23:04:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/14 23:11:43 visual_prompt]: Epoch 11 / 100: avg data time: 1.14e+01, avg batch time: 11.7907, average train loss: 0.6869
[11/14 23:12:30 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1560, average loss: 0.6609
[11/14 23:12:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 65.98	
[11/14 23:12:30 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/14 23:19:17 visual_prompt]: Epoch 12 / 100: avg data time: 1.13e+01, avg batch time: 11.6169, average train loss: 0.6928
[11/14 23:20:05 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1547, average loss: 0.6676
[11/14 23:20:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.21	
[11/14 23:20:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/14 23:27:15 visual_prompt]: Epoch 13 / 100: avg data time: 1.19e+01, avg batch time: 12.2840, average train loss: 0.7019
[11/14 23:28:08 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1567, average loss: 0.6691
[11/14 23:28:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.45	
[11/14 23:28:08 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/14 23:34:39 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1602, average train loss: 0.6917
[11/14 23:35:23 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1548, average loss: 0.7862
[11/14 23:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.03	
[11/14 23:35:23 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/14 23:41:49 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.0381, average train loss: 0.6980
[11/14 23:42:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1552, average loss: 0.6564
[11/14 23:42:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.82	
[11/14 23:42:34 visual_prompt]: Best epoch 15: best metric: -0.656
[11/14 23:42:34 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/14 23:49:01 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0476, average train loss: 0.6968
[11/14 23:49:45 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1551, average loss: 0.7931
[11/14 23:49:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.61	
[11/14 23:49:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/14 23:56:11 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0215, average train loss: 0.6897
[11/14 23:56:55 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1551, average loss: 0.6517
[11/14 23:56:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.83	
[11/14 23:56:55 visual_prompt]: Best epoch 17: best metric: -0.652
[11/14 23:56:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/15 00:03:21 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0078, average train loss: 0.6841
[11/15 00:04:06 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1551, average loss: 0.6975
[11/15 00:04:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 67.30	
[11/15 00:04:06 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/15 00:10:41 visual_prompt]: Epoch 19 / 100: avg data time: 1.09e+01, avg batch time: 11.2852, average train loss: 0.6897
[11/15 00:11:26 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1551, average loss: 0.7390
[11/15 00:11:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.32	
[11/15 00:11:26 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/15 00:18:00 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.2307, average train loss: 0.6652
[11/15 00:18:44 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1548, average loss: 0.7308
[11/15 00:18:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 66.88	
[11/15 00:18:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/15 00:25:17 visual_prompt]: Epoch 21 / 100: avg data time: 1.09e+01, avg batch time: 11.2217, average train loss: 0.6596
[11/15 00:26:02 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1552, average loss: 0.6446
[11/15 00:26:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.70	
[11/15 00:26:02 visual_prompt]: Best epoch 21: best metric: -0.645
[11/15 00:26:02 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/15 00:32:33 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.1680, average train loss: 0.6508
[11/15 00:33:18 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1551, average loss: 0.6764
[11/15 00:33:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.17	
[11/15 00:33:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/15 00:39:48 visual_prompt]: Epoch 23 / 100: avg data time: 1.08e+01, avg batch time: 11.1311, average train loss: 0.6519
[11/15 00:40:32 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1553, average loss: 0.6581
[11/15 00:40:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.23	
[11/15 00:40:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/15 00:47:01 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0974, average train loss: 0.6448
[11/15 00:47:45 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1549, average loss: 0.6868
[11/15 00:47:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.03	
[11/15 00:47:45 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/15 00:54:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0802, average train loss: 0.6553
[11/15 00:54:58 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1551, average loss: 0.6543
[11/15 00:54:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.61	
[11/15 00:54:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/15 01:01:23 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0124, average train loss: 0.6365
[11/15 01:02:07 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1547, average loss: 0.6373
[11/15 01:02:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.11	
[11/15 01:02:07 visual_prompt]: Best epoch 26: best metric: -0.637
[11/15 01:02:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/15 01:08:35 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.0706, average train loss: 0.6287
[11/15 01:09:19 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1581, average loss: 0.6406
[11/15 01:09:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.88	
[11/15 01:09:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/15 01:15:46 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.0416, average train loss: 0.6356
[11/15 01:16:30 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1577, average loss: 0.6742
[11/15 01:16:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.13	
[11/15 01:16:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/15 01:22:58 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0879, average train loss: 0.6263
[11/15 01:23:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 0.6511
[11/15 01:23:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.09	
[11/15 01:23:43 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/15 01:30:10 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0551, average train loss: 0.6270
[11/15 01:30:54 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1560, average loss: 0.6525
[11/15 01:30:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.57	
[11/15 01:30:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/15 01:37:21 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0378, average train loss: 0.6137
[11/15 01:38:05 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1551, average loss: 0.6712
[11/15 01:38:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.75	
[11/15 01:38:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/15 01:44:31 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0228, average train loss: 0.6407
[11/15 01:45:15 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1551, average loss: 0.6787
[11/15 01:45:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.28	
[11/15 01:45:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/15 01:51:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9908, average train loss: 0.6240
[11/15 01:52:24 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1551, average loss: 0.6309
[11/15 01:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 70.29	
[11/15 01:52:24 visual_prompt]: Best epoch 33: best metric: -0.631
[11/15 01:52:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/15 01:58:49 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9950, average train loss: 0.6196
[11/15 01:59:33 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1580, average loss: 0.7583
[11/15 01:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.68	
[11/15 01:59:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/15 02:05:59 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0435, average train loss: 0.6116
[11/15 02:06:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1568, average loss: 0.6350
[11/15 02:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.03	
[11/15 02:06:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/15 02:13:14 visual_prompt]: Epoch 36 / 100: avg data time: 1.08e+01, avg batch time: 11.1745, average train loss: 0.5937
[11/15 02:13:59 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1549, average loss: 0.6709
[11/15 02:13:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.66	
[11/15 02:13:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/15 02:20:32 visual_prompt]: Epoch 37 / 100: avg data time: 1.09e+01, avg batch time: 11.2095, average train loss: 0.5911
[11/15 02:21:17 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1590, average loss: 0.7702
[11/15 02:21:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.30	
[11/15 02:21:17 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/15 02:27:49 visual_prompt]: Epoch 38 / 100: avg data time: 1.09e+01, avg batch time: 11.2050, average train loss: 0.5773
[11/15 02:28:34 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1548, average loss: 0.7292
[11/15 02:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.35	
[11/15 02:28:34 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/15 02:35:06 visual_prompt]: Epoch 39 / 100: avg data time: 1.08e+01, avg batch time: 11.1933, average train loss: 0.5825
[11/15 02:35:50 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1551, average loss: 0.6312
[11/15 02:35:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.38	
[11/15 02:35:50 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/15 02:42:21 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e+01, avg batch time: 11.1478, average train loss: 0.5812
[11/15 02:43:05 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1559, average loss: 0.6562
[11/15 02:43:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.93	
[11/15 02:43:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/15 02:49:35 visual_prompt]: Epoch 41 / 100: avg data time: 1.08e+01, avg batch time: 11.1246, average train loss: 0.5521
[11/15 02:50:19 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1550, average loss: 0.6975
[11/15 02:50:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.18	
[11/15 02:50:19 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/15 02:56:47 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e+01, avg batch time: 11.0817, average train loss: 0.5843
[11/15 02:57:31 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1591, average loss: 0.6947
[11/15 02:57:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.98	
[11/15 02:57:31 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/15 03:03:59 visual_prompt]: Epoch 43 / 100: avg data time: 1.07e+01, avg batch time: 11.0825, average train loss: 0.5627
[11/15 03:04:44 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1582, average loss: 0.6641
[11/15 03:04:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.74	
[11/15 03:04:44 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/15 03:11:10 visual_prompt]: Epoch 44 / 100: avg data time: 1.07e+01, avg batch time: 11.0260, average train loss: 0.5504
[11/15 03:11:54 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1550, average loss: 0.7929
[11/15 03:11:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.91	
[11/15 03:11:54 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/15 03:18:21 visual_prompt]: Epoch 45 / 100: avg data time: 1.07e+01, avg batch time: 11.0464, average train loss: 0.5629
[11/15 03:19:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1546, average loss: 0.6827
[11/15 03:19:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.36	
[11/15 03:19:05 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/15 03:25:31 visual_prompt]: Epoch 46 / 100: avg data time: 1.07e+01, avg batch time: 11.0345, average train loss: 0.5305
[11/15 03:26:15 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1552, average loss: 0.6558
[11/15 03:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 70.65	
[11/15 03:26:15 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/15 03:32:41 visual_prompt]: Epoch 47 / 100: avg data time: 1.07e+01, avg batch time: 11.0067, average train loss: 0.5297
[11/15 03:33:25 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.1549, average loss: 0.7338
[11/15 03:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.00	
[11/15 03:33:25 visual_prompt]: Stopping early.
[11/15 03:33:25 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 03:33:26 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 03:33:26 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/15 03:33:26 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 03:33:26 visual_prompt]: Training with config:
[11/15 03:33:26 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr0.05_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 03:33:26 visual_prompt]: Loading training data...
[11/15 03:33:26 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 03:33:26 visual_prompt]: Loading validation data...
[11/15 03:33:26 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 03:33:26 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/15 03:33:30 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/15 03:33:30 visual_prompt]: tuned percent:0.536
[11/15 03:33:30 visual_prompt]: Device used for model: 0
[11/15 03:33:30 visual_prompt]: Setting up Evaluator...
[11/15 03:33:30 visual_prompt]: Setting up Trainer...
[11/15 03:33:30 visual_prompt]: 	Setting up the optimizer...
[11/15 03:33:30 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 03:39:56 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0406, average train loss: 1.4017
[11/15 03:40:41 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1550, average loss: 1.2969
[11/15 03:40:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/15 03:40:41 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/15 03:47:06 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.0062, average train loss: 0.9974
[11/15 03:47:50 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1552, average loss: 0.6963
[11/15 03:47:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 46.32	
[11/15 03:47:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/15 03:54:16 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0037, average train loss: 0.7075
[11/15 03:55:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1547, average loss: 0.6913
[11/15 03:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/15 03:55:00 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/15 04:01:24 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9638, average train loss: 0.6962
[11/15 04:02:07 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1549, average loss: 0.6843
[11/15 04:02:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.76	
[11/15 04:02:07 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/15 04:08:28 visual_prompt]: Epoch 5 / 100: avg data time: 1.05e+01, avg batch time: 10.8871, average train loss: 0.7239
[11/15 04:09:12 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1551, average loss: 0.6920
[11/15 04:09:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.86	
[11/15 04:09:12 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/15 04:15:37 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9886, average train loss: 0.7310
[11/15 04:16:21 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1553, average loss: 0.6997
[11/15 04:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 59.25	
[11/15 04:16:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/15 04:22:48 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0328, average train loss: 0.7009
[11/15 04:23:33 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1590, average loss: 0.6808
[11/15 04:23:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 61.51	
[11/15 04:23:33 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/15 04:30:05 visual_prompt]: Epoch 8 / 100: avg data time: 1.08e+01, avg batch time: 11.2028, average train loss: 0.6974
[11/15 04:30:50 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1549, average loss: 0.6738
[11/15 04:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 62.30	
[11/15 04:30:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/15 04:37:23 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2259, average train loss: 0.6856
[11/15 04:38:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1551, average loss: 0.7333
[11/15 04:38:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.32	
[11/15 04:38:08 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/15 04:44:38 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1390, average train loss: 0.6829
[11/15 04:45:22 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1551, average loss: 0.6664
[11/15 04:45:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.91	
[11/15 04:45:22 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/15 04:51:51 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.1079, average train loss: 0.6868
[11/15 04:52:36 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1549, average loss: 0.6614
[11/15 04:52:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.02	
[11/15 04:52:36 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/15 04:59:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.0705, average train loss: 0.6933
[11/15 04:59:47 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1583, average loss: 0.6682
[11/15 04:59:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 64.27	
[11/15 04:59:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/15 05:06:15 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.0810, average train loss: 0.7000
[11/15 05:07:00 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1590, average loss: 0.6803
[11/15 05:07:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 64.63	
[11/15 05:07:00 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/15 05:13:27 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0515, average train loss: 0.6895
[11/15 05:14:11 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1550, average loss: 0.7511
[11/15 05:14:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.04	
[11/15 05:14:11 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/15 05:20:40 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.1073, average train loss: 0.6965
[11/15 05:21:24 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1551, average loss: 0.6573
[11/15 05:21:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.48	
[11/15 05:21:24 visual_prompt]: Best epoch 15: best metric: -0.657
[11/15 05:21:24 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/15 05:27:50 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0247, average train loss: 0.7084
[11/15 05:28:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1550, average loss: 0.8042
[11/15 05:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.67	
[11/15 05:28:34 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/15 05:34:58 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9689, average train loss: 0.6934
[11/15 05:35:42 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1550, average loss: 0.6495
[11/15 05:35:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.05	
[11/15 05:35:42 visual_prompt]: Best epoch 17: best metric: -0.650
[11/15 05:35:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/15 05:42:08 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0208, average train loss: 0.6880
[11/15 05:42:53 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1548, average loss: 0.6940
[11/15 05:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 66.80	
[11/15 05:42:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/15 05:49:18 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0064, average train loss: 0.6829
[11/15 05:50:02 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1581, average loss: 0.7317
[11/15 05:50:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.37	
[11/15 05:50:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/15 05:56:28 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.0161, average train loss: 0.6659
[11/15 05:57:12 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1551, average loss: 0.7027
[11/15 05:57:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.52	
[11/15 05:57:12 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/15 06:03:38 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0174, average train loss: 0.6639
[11/15 06:04:22 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1548, average loss: 0.6485
[11/15 06:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.45	
[11/15 06:04:22 visual_prompt]: Best epoch 21: best metric: -0.648
[11/15 06:04:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/15 06:10:48 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.0044, average train loss: 0.6540
[11/15 06:11:32 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1588, average loss: 0.7051
[11/15 06:11:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 68.93	
[11/15 06:11:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/15 06:17:59 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0489, average train loss: 0.6552
[11/15 06:18:43 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1571, average loss: 0.6613
[11/15 06:18:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.06	
[11/15 06:18:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/15 06:25:09 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0305, average train loss: 0.6498
[11/15 06:25:53 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1549, average loss: 0.7112
[11/15 06:25:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.80	
[11/15 06:25:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/15 06:32:18 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0083, average train loss: 0.6704
[11/15 06:33:02 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1548, average loss: 0.6595
[11/15 06:33:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.14	
[11/15 06:33:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/15 06:39:28 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0355, average train loss: 0.6401
[11/15 06:40:13 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 0.6395
[11/15 06:40:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.20	
[11/15 06:40:13 visual_prompt]: Best epoch 26: best metric: -0.640
[11/15 06:40:13 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/15 06:46:47 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2396, average train loss: 0.6310
[11/15 06:47:32 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1549, average loss: 0.6427
[11/15 06:47:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.20	
[11/15 06:47:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/15 06:54:04 visual_prompt]: Epoch 28 / 100: avg data time: 1.08e+01, avg batch time: 11.1920, average train loss: 0.6367
[11/15 06:54:48 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1551, average loss: 0.7055
[11/15 06:54:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.85	
[11/15 06:54:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/15 07:01:20 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1816, average train loss: 0.6280
[11/15 07:02:05 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1561, average loss: 0.6443
[11/15 07:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.68	
[11/15 07:02:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/15 07:08:34 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1270, average train loss: 0.6308
[11/15 07:09:18 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1546, average loss: 0.6383
[11/15 07:09:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.82	
[11/15 07:09:18 visual_prompt]: Best epoch 30: best metric: -0.638
[11/15 07:09:18 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/15 07:15:47 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0887, average train loss: 0.6132
[11/15 07:16:31 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1547, average loss: 0.6730
[11/15 07:16:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.05	
[11/15 07:16:31 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/15 07:22:58 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0659, average train loss: 0.6313
[11/15 07:23:43 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1548, average loss: 0.6801
[11/15 07:23:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 68.18	
[11/15 07:23:43 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/15 07:30:10 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0710, average train loss: 0.6232
[11/15 07:30:55 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1578, average loss: 0.6271
[11/15 07:30:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 70.20	
[11/15 07:30:55 visual_prompt]: Best epoch 33: best metric: -0.627
[11/15 07:30:55 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/15 07:37:21 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0496, average train loss: 0.6143
[11/15 07:38:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1550, average loss: 0.7344
[11/15 07:38:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.22	
[11/15 07:38:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/15 07:44:31 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9937, average train loss: 0.6080
[11/15 07:45:15 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1568, average loss: 0.6371
[11/15 07:45:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.91	
[11/15 07:45:15 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/15 07:51:42 visual_prompt]: Epoch 36 / 100: avg data time: 1.07e+01, avg batch time: 11.0324, average train loss: 0.6018
[11/15 07:52:26 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1577, average loss: 0.6572
[11/15 07:52:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.40	
[11/15 07:52:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/15 07:58:53 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.0488, average train loss: 0.5982
[11/15 07:59:38 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1550, average loss: 0.6882
[11/15 07:59:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.17	
[11/15 07:59:38 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/15 08:06:06 visual_prompt]: Epoch 38 / 100: avg data time: 1.07e+01, avg batch time: 11.0875, average train loss: 0.5736
[11/15 08:06:50 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1554, average loss: 0.7073
[11/15 08:06:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.56	
[11/15 08:06:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/15 08:13:19 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0946, average train loss: 0.5889
[11/15 08:14:03 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1552, average loss: 0.6344
[11/15 08:14:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.92	
[11/15 08:14:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/15 08:20:30 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0546, average train loss: 0.5774
[11/15 08:21:14 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1549, average loss: 0.6468
[11/15 08:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.80	
[11/15 08:21:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/15 08:27:41 visual_prompt]: Epoch 41 / 100: avg data time: 1.07e+01, avg batch time: 11.0335, average train loss: 0.5587
[11/15 08:28:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1566, average loss: 0.6470
[11/15 08:28:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.87	
[11/15 08:28:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/15 08:34:50 visual_prompt]: Epoch 42 / 100: avg data time: 1.06e+01, avg batch time: 11.0044, average train loss: 0.5749
[11/15 08:35:34 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1559, average loss: 0.7001
[11/15 08:35:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.40	
[11/15 08:35:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/15 08:41:57 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 10.9401, average train loss: 0.5594
[11/15 08:42:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1550, average loss: 0.6554
[11/15 08:42:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 69.89	
[11/15 08:42:41 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/15 08:49:06 visual_prompt]: Epoch 44 / 100: avg data time: 1.06e+01, avg batch time: 10.9896, average train loss: 0.5615
[11/15 08:49:51 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1553, average loss: 0.7721
[11/15 08:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.98	
[11/15 08:49:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/15 08:56:26 visual_prompt]: Epoch 45 / 100: avg data time: 1.09e+01, avg batch time: 11.2784, average train loss: 0.5813
[11/15 08:57:11 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1550, average loss: 0.6535
[11/15 08:57:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.54	
[11/15 08:57:11 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/15 09:03:43 visual_prompt]: Epoch 46 / 100: avg data time: 1.08e+01, avg batch time: 11.1945, average train loss: 0.5278
[11/15 09:04:28 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1570, average loss: 0.6951
[11/15 09:04:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.23	
[11/15 09:04:28 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/15 09:10:59 visual_prompt]: Epoch 47 / 100: avg data time: 1.08e+01, avg batch time: 11.1785, average train loss: 0.5300
[11/15 09:11:44 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1550, average loss: 0.6891
[11/15 09:11:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.75	
[11/15 09:11:44 visual_prompt]: Stopping early.
[11/15 09:11:45 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 09:11:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 09:11:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '200', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/15 09:11:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 09:11:45 visual_prompt]: Training with config:
[11/15 09:11:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/test/seed9805/lrNone_wdNone/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': None, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': None, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 09:11:45 visual_prompt]: Loading training data...
[11/15 09:11:45 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 09:11:45 visual_prompt]: Loading validation data...
[11/15 09:11:45 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 09:11:45 visual_prompt]: Loading test data...
[11/15 09:11:45 visual_prompt]: Constructing mammo-cbis dataset test...
[11/15 09:11:45 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/15 09:11:49 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/15 09:11:49 visual_prompt]: tuned percent:0.536
[11/15 09:11:49 visual_prompt]: Device used for model: 0
[11/15 09:11:49 visual_prompt]: Setting up Evaluator...
[11/15 09:11:49 visual_prompt]: Setting up Trainer...
[11/15 09:11:49 visual_prompt]: 	Setting up the optimizer...
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 99, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 94, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 43, in train
    trainer = Trainer(cfg, model, evaluator, cur_device)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 46, in __init__
    self.optimizer = make_optimizer([self.model], cfg.SOLVER)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/solver/optimizer.py", line 36, in make_optimizer
    if train_params.WEIGHT_DECAY > 0:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: '>' not supported between instances of 'NoneType' and 'int'
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
