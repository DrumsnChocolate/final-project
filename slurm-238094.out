/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 01:04:20 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 01:04:20 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 01:04:20 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 01:04:20 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 01:04:20 visual_prompt]: Training with config:
[09/28 01:04:20 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/test/seed7077/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 7077, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 01:04:20 visual_prompt]: Loading training data...
2023-09-28 01:04:20.980646: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-09-28 01:04:21.029733: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-28 01:04:22.315420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[09/28 01:04:24 visual_prompt]: Constructing vtab-sun397 dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 01:04:26 visual_prompt]: Number of images: 1000
[09/28 01:04:26 visual_prompt]: Number of classes: 325 / 397
[09/28 01:04:26 visual_prompt]: Loading validation data...
[09/28 01:04:26 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 01:04:27 visual_prompt]: Number of images: 200
[09/28 01:04:27 visual_prompt]: Number of classes: 136 / 397
[09/28 01:04:27 visual_prompt]: Loading test data...
[09/28 01:04:27 visual_prompt]: Constructing vtab-sun397 dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split test, from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 01:05:06 visual_prompt]: Number of images: 21750
[09/28 01:05:06 visual_prompt]: Number of classes: 397 / 397
[09/28 01:05:06 visual_prompt]: Constructing models...
[09/28 01:05:08 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/28 01:05:08 visual_prompt]: tuned percent:0.885
[09/28 01:05:11 visual_prompt]: Device used for model: 0
[09/28 01:05:11 visual_prompt]: Setting up Evaluator...
[09/28 01:05:11 visual_prompt]: Setting up Trainer...
[09/28 01:05:11 visual_prompt]: 	Setting up the optimizer...
[09/28 01:05:11 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 01:05:24 visual_prompt]: Epoch 1 / 100: avg data time: 1.90e-01, avg batch time: 0.7967, average train loss: 6.0020
[09/28 01:05:27 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1665, average loss: 6.0087
[09/28 01:05:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 1.00	
[09/28 01:05:53 visual_prompt]: 	Test 100/340. loss: 6.001, 0.2152 s / batch. (data: 3.15e-05)max mem: 7.80931 GB 
[09/28 01:06:15 visual_prompt]: 	Test 200/340. loss: 6.016, 0.2161 s / batch. (data: 3.08e-05)max mem: 7.80931 GB 
[09/28 01:06:37 visual_prompt]: 	Test 300/340. loss: 5.989, 0.2190 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 01:06:47 visual_prompt]: Inference (test):avg data time: 7.87e-05, avg batch time: 0.2173, average loss: 6.0019
[09/28 01:06:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 0.24	top5: 0.95	
[09/28 01:06:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/28 01:06:57 visual_prompt]: Epoch 2 / 100: avg data time: 9.13e-02, avg batch time: 0.5461, average train loss: 5.8043
[09/28 01:07:00 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1914, average loss: 5.5878
[09/28 01:07:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.50	
[09/28 01:07:24 visual_prompt]: 	Test 100/340. loss: 5.726, 0.2195 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 01:07:46 visual_prompt]: 	Test 200/340. loss: 5.795, 0.2192 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 01:08:10 visual_prompt]: 	Test 300/340. loss: 5.779, 0.2188 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 01:08:20 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2189, average loss: 5.7899
[09/28 01:08:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.06	top5: 7.83	
[09/28 01:08:21 visual_prompt]: Best epoch 2: best metric: 0.005
[09/28 01:08:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/28 01:08:31 visual_prompt]: Epoch 3 / 100: avg data time: 9.92e-02, avg batch time: 0.5557, average train loss: 5.6321
[09/28 01:08:34 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1697, average loss: 5.4666
[09/28 01:08:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 2.50	top5: 8.50	
[09/28 01:08:57 visual_prompt]: 	Test 100/340. loss: 5.667, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 01:09:19 visual_prompt]: 	Test 200/340. loss: 5.848, 0.2197 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 01:09:41 visual_prompt]: 	Test 300/340. loss: 5.816, 0.2196 s / batch. (data: 4.15e-05)max mem: 7.80931 GB 
[09/28 01:09:51 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2193, average loss: 5.7837
[09/28 01:09:52 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.46	top5: 9.35	
[09/28 01:09:52 visual_prompt]: Best epoch 3: best metric: 0.025
[09/28 01:09:52 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/28 01:10:02 visual_prompt]: Epoch 4 / 100: avg data time: 9.84e-02, avg batch time: 0.5562, average train loss: 5.4754
[09/28 01:10:05 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1698, average loss: 5.2151
[09/28 01:10:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 11.00	
[09/28 01:10:28 visual_prompt]: 	Test 100/340. loss: 5.470, 0.2197 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 01:10:50 visual_prompt]: 	Test 200/340. loss: 5.485, 0.2194 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 01:11:12 visual_prompt]: 	Test 300/340. loss: 5.547, 0.2202 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 01:11:22 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2196, average loss: 5.5246
[09/28 01:11:23 visual_prompt]: Classification results with test_vtab-sun397: top1: 4.71	top5: 12.03	
[09/28 01:11:23 visual_prompt]: Best epoch 4: best metric: 0.050
[09/28 01:11:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/28 01:11:33 visual_prompt]: Epoch 5 / 100: avg data time: 9.88e-02, avg batch time: 0.5579, average train loss: 5.1222
[09/28 01:11:36 visual_prompt]: Inference (val):avg data time: 1.82e-05, avg batch time: 0.1699, average loss: 4.4836
[09/28 01:11:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 12.50	top5: 31.00	
[09/28 01:11:59 visual_prompt]: 	Test 100/340. loss: 5.104, 0.2199 s / batch. (data: 2.34e-05)max mem: 7.80931 GB 
[09/28 01:12:21 visual_prompt]: 	Test 200/340. loss: 5.220, 0.2206 s / batch. (data: 1.00e-04)max mem: 7.80931 GB 
[09/28 01:12:43 visual_prompt]: 	Test 300/340. loss: 5.080, 0.2195 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 01:12:53 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2195, average loss: 5.1889
[09/28 01:12:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 9.58	top5: 19.86	
[09/28 01:12:54 visual_prompt]: Best epoch 5: best metric: 0.125
[09/28 01:12:54 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/28 01:13:04 visual_prompt]: Epoch 6 / 100: avg data time: 9.96e-02, avg batch time: 0.5579, average train loss: 4.2762
[09/28 01:13:07 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1702, average loss: 3.4838
[09/28 01:13:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 29.00	top5: 58.50	
[09/28 01:13:30 visual_prompt]: 	Test 100/340. loss: 4.600, 0.2201 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:13:52 visual_prompt]: 	Test 200/340. loss: 4.990, 0.2195 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:14:14 visual_prompt]: 	Test 300/340. loss: 5.201, 0.2194 s / batch. (data: 9.06e-05)max mem: 7.80931 GB 
[09/28 01:14:26 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2240, average loss: 4.8360
[09/28 01:14:27 visual_prompt]: Classification results with test_vtab-sun397: top1: 13.29	top5: 30.75	
[09/28 01:14:27 visual_prompt]: Best epoch 6: best metric: 0.290
[09/28 01:14:27 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/28 01:14:37 visual_prompt]: Epoch 7 / 100: avg data time: 9.75e-02, avg batch time: 0.5552, average train loss: 2.3933
[09/28 01:14:40 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1701, average loss: 0.8410
[09/28 01:14:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 86.00	top5: 98.00	
[09/28 01:15:04 visual_prompt]: 	Test 100/340. loss: 3.103, 0.2194 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:15:26 visual_prompt]: 	Test 200/340. loss: 3.691, 0.2210 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 01:15:48 visual_prompt]: 	Test 300/340. loss: 3.389, 0.2190 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 01:15:58 visual_prompt]: Inference (test):avg data time: 6.04e-05, avg batch time: 0.2195, average loss: 3.4100
[09/28 01:15:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 35.40	top5: 59.59	
[09/28 01:15:58 visual_prompt]: Best epoch 7: best metric: 0.860
[09/28 01:15:58 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/28 01:16:08 visual_prompt]: Epoch 8 / 100: avg data time: 1.02e-01, avg batch time: 0.5599, average train loss: 0.8032
[09/28 01:16:11 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1699, average loss: 0.2299
[09/28 01:16:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.00	top5: 100.00	
[09/28 01:16:35 visual_prompt]: 	Test 100/340. loss: 2.761, 0.2191 s / batch. (data: 1.01e-04)max mem: 7.80931 GB 
[09/28 01:16:57 visual_prompt]: 	Test 200/340. loss: 3.216, 0.2199 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 01:17:19 visual_prompt]: 	Test 300/340. loss: 3.010, 0.2194 s / batch. (data: 6.48e-05)max mem: 7.80931 GB 
[09/28 01:17:29 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2195, average loss: 2.9768
[09/28 01:17:29 visual_prompt]: Classification results with test_vtab-sun397: top1: 42.05	top5: 67.83	
[09/28 01:17:29 visual_prompt]: Best epoch 8: best metric: 0.970
[09/28 01:17:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/28 01:17:39 visual_prompt]: Epoch 9 / 100: avg data time: 9.53e-02, avg batch time: 0.5547, average train loss: 0.2816
[09/28 01:17:42 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1700, average loss: 0.1510
[09/28 01:17:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 01:18:06 visual_prompt]: 	Test 100/340. loss: 2.760, 0.2199 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 01:18:28 visual_prompt]: 	Test 200/340. loss: 3.170, 0.2193 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 01:18:50 visual_prompt]: 	Test 300/340. loss: 2.853, 0.2205 s / batch. (data: 1.13e-04)max mem: 7.80931 GB 
[09/28 01:19:00 visual_prompt]: Inference (test):avg data time: 3.92e-05, avg batch time: 0.2196, average loss: 2.9383
[09/28 01:19:00 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.43	top5: 69.90	
[09/28 01:19:00 visual_prompt]: Best epoch 9: best metric: 0.985
[09/28 01:19:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/28 01:19:10 visual_prompt]: Epoch 10 / 100: avg data time: 8.94e-02, avg batch time: 0.5487, average train loss: 0.2704
[09/28 01:19:13 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1698, average loss: 0.1816
[09/28 01:19:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:19:37 visual_prompt]: 	Test 100/340. loss: 2.792, 0.2198 s / batch. (data: 8.54e-05)max mem: 7.80931 GB 
[09/28 01:19:59 visual_prompt]: 	Test 200/340. loss: 3.220, 0.2194 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 01:20:21 visual_prompt]: 	Test 300/340. loss: 3.098, 0.2217 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 01:20:31 visual_prompt]: Inference (test):avg data time: 7.00e-05, avg batch time: 0.2197, average loss: 2.9881
[09/28 01:20:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.49	top5: 69.43	
[09/28 01:20:31 visual_prompt]: Best epoch 10: best metric: 1.000
[09/28 01:20:31 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/28 01:20:41 visual_prompt]: Epoch 11 / 100: avg data time: 9.05e-02, avg batch time: 0.5498, average train loss: 0.3809
[09/28 01:20:44 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1701, average loss: 0.3437
[09/28 01:20:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 100.00	
[09/28 01:21:08 visual_prompt]: 	Test 100/340. loss: 3.143, 0.2200 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 01:21:30 visual_prompt]: 	Test 200/340. loss: 3.578, 0.2190 s / batch. (data: 6.22e-05)max mem: 7.80931 GB 
[09/28 01:21:52 visual_prompt]: 	Test 300/340. loss: 3.191, 0.2196 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 01:22:02 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2198, average loss: 3.1758
[09/28 01:22:02 visual_prompt]: Classification results with test_vtab-sun397: top1: 40.08	top5: 66.65	
[09/28 01:22:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/28 01:22:12 visual_prompt]: Epoch 12 / 100: avg data time: 8.85e-02, avg batch time: 0.5478, average train loss: 0.4664
[09/28 01:22:15 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1700, average loss: 0.1789
[09/28 01:22:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:22:39 visual_prompt]: 	Test 100/340. loss: 2.804, 0.2194 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:23:01 visual_prompt]: 	Test 200/340. loss: 3.191, 0.2210 s / batch. (data: 7.82e-05)max mem: 7.80931 GB 
[09/28 01:23:23 visual_prompt]: 	Test 300/340. loss: 2.963, 0.2201 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 01:23:33 visual_prompt]: Inference (test):avg data time: 4.81e-05, avg batch time: 0.2197, average loss: 2.9728
[09/28 01:23:33 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.21	top5: 69.63	
[09/28 01:23:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/28 01:23:43 visual_prompt]: Epoch 13 / 100: avg data time: 1.01e-01, avg batch time: 0.5615, average train loss: 0.3527
[09/28 01:23:47 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1702, average loss: 0.1524
[09/28 01:23:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:24:10 visual_prompt]: 	Test 100/340. loss: 2.862, 0.2198 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 01:24:32 visual_prompt]: 	Test 200/340. loss: 3.273, 0.2197 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 01:24:54 visual_prompt]: 	Test 300/340. loss: 2.756, 0.2200 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 01:25:04 visual_prompt]: Inference (test):avg data time: 3.49e-05, avg batch time: 0.2196, average loss: 2.9311
[09/28 01:25:05 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.84	top5: 70.42	
[09/28 01:25:05 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/28 01:25:15 visual_prompt]: Epoch 14 / 100: avg data time: 1.01e-01, avg batch time: 0.5608, average train loss: 0.2721
[09/28 01:25:18 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1701, average loss: 0.2687
[09/28 01:25:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 100.00	
[09/28 01:25:41 visual_prompt]: 	Test 100/340. loss: 2.558, 0.2185 s / batch. (data: 6.44e-05)max mem: 7.80931 GB 
[09/28 01:26:03 visual_prompt]: 	Test 200/340. loss: 3.169, 0.2196 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 01:26:25 visual_prompt]: 	Test 300/340. loss: 2.880, 0.2201 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:26:35 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2196, average loss: 2.9447
[09/28 01:26:36 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.83	top5: 70.06	
[09/28 01:26:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/28 01:26:46 visual_prompt]: Epoch 15 / 100: avg data time: 9.65e-02, avg batch time: 0.5554, average train loss: 0.2888
[09/28 01:26:49 visual_prompt]: Inference (val):avg data time: 1.95e-05, avg batch time: 0.1699, average loss: 0.1876
[09/28 01:26:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:27:12 visual_prompt]: 	Test 100/340. loss: 2.713, 0.2193 s / batch. (data: 2.48e-05)max mem: 7.80931 GB 
[09/28 01:27:34 visual_prompt]: 	Test 200/340. loss: 3.078, 0.2194 s / batch. (data: 5.75e-05)max mem: 7.80931 GB 
[09/28 01:27:56 visual_prompt]: 	Test 300/340. loss: 2.883, 0.2201 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 01:28:06 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2196, average loss: 2.8863
[09/28 01:28:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.43	top5: 71.61	
[09/28 01:28:07 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/28 01:28:17 visual_prompt]: Epoch 16 / 100: avg data time: 9.69e-02, avg batch time: 0.5568, average train loss: 0.3140
[09/28 01:28:20 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1701, average loss: 0.2449
[09/28 01:28:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 01:28:43 visual_prompt]: 	Test 100/340. loss: 2.629, 0.2202 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:29:05 visual_prompt]: 	Test 200/340. loss: 3.151, 0.2193 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 01:29:27 visual_prompt]: 	Test 300/340. loss: 2.835, 0.2192 s / batch. (data: 3.24e-05)max mem: 7.80931 GB 
[09/28 01:29:48 visual_prompt]: Inference (test):avg data time: 7.67e-05, avg batch time: 0.2326, average loss: 2.9574
[09/28 01:29:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.68	top5: 71.10	
[09/28 01:29:49 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/28 01:29:59 visual_prompt]: Epoch 17 / 100: avg data time: 9.46e-02, avg batch time: 0.5514, average train loss: 0.3156
[09/28 01:30:02 visual_prompt]: Inference (val):avg data time: 1.85e-05, avg batch time: 0.1696, average loss: 0.1674
[09/28 01:30:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:30:25 visual_prompt]: 	Test 100/340. loss: 2.671, 0.2183 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 01:30:47 visual_prompt]: 	Test 200/340. loss: 3.063, 0.2196 s / batch. (data: 3.19e-05)max mem: 7.80931 GB 
[09/28 01:31:09 visual_prompt]: 	Test 300/340. loss: 2.942, 0.2203 s / batch. (data: 3.00e-05)max mem: 7.80931 GB 
[09/28 01:31:19 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2191, average loss: 2.8590
[09/28 01:31:20 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.70	top5: 72.02	
[09/28 01:31:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/28 01:31:29 visual_prompt]: Epoch 18 / 100: avg data time: 8.60e-02, avg batch time: 0.5447, average train loss: 0.2647
[09/28 01:31:33 visual_prompt]: Inference (val):avg data time: 1.40e-05, avg batch time: 0.1698, average loss: 0.2242
[09/28 01:31:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 01:31:56 visual_prompt]: 	Test 100/340. loss: 2.859, 0.2203 s / batch. (data: 6.15e-05)max mem: 7.80931 GB 
[09/28 01:32:18 visual_prompt]: 	Test 200/340. loss: 3.271, 0.2205 s / batch. (data: 8.39e-05)max mem: 7.80931 GB 
[09/28 01:32:40 visual_prompt]: 	Test 300/340. loss: 2.854, 0.2198 s / batch. (data: 6.27e-05)max mem: 7.80931 GB 
[09/28 01:32:50 visual_prompt]: Inference (test):avg data time: 3.70e-05, avg batch time: 0.2197, average loss: 2.9411
[09/28 01:32:51 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.34	top5: 71.48	
[09/28 01:32:51 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/28 01:33:00 visual_prompt]: Epoch 19 / 100: avg data time: 9.35e-02, avg batch time: 0.5519, average train loss: 0.3347
[09/28 01:33:03 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1703, average loss: 0.2635
[09/28 01:33:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 99.50	
[09/28 01:33:27 visual_prompt]: 	Test 100/340. loss: 2.594, 0.2180 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 01:33:49 visual_prompt]: 	Test 200/340. loss: 3.300, 0.2188 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 01:34:11 visual_prompt]: 	Test 300/340. loss: 2.957, 0.2196 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:34:21 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2196, average loss: 2.9259
[09/28 01:34:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.56	top5: 71.91	
[09/28 01:34:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/28 01:34:31 visual_prompt]: Epoch 20 / 100: avg data time: 9.87e-02, avg batch time: 0.5572, average train loss: 0.4011
[09/28 01:34:34 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1699, average loss: 0.1981
[09/28 01:34:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 01:34:58 visual_prompt]: 	Test 100/340. loss: 2.547, 0.2199 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 01:35:20 visual_prompt]: 	Test 200/340. loss: 2.903, 0.2203 s / batch. (data: 9.94e-05)max mem: 7.80931 GB 
[09/28 01:35:42 visual_prompt]: 	Test 300/340. loss: 2.784, 0.2200 s / batch. (data: 6.39e-05)max mem: 7.80931 GB 
[09/28 01:35:52 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2197, average loss: 2.8682
[09/28 01:35:52 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.51	top5: 71.82	
[09/28 01:35:52 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/28 01:36:02 visual_prompt]: Epoch 21 / 100: avg data time: 9.68e-02, avg batch time: 0.5552, average train loss: 0.2905
[09/28 01:36:05 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1701, average loss: 0.1330
[09/28 01:36:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:36:29 visual_prompt]: 	Test 100/340. loss: 2.560, 0.2197 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 01:36:51 visual_prompt]: 	Test 200/340. loss: 3.187, 0.2201 s / batch. (data: 8.80e-05)max mem: 7.80931 GB 
[09/28 01:37:13 visual_prompt]: 	Test 300/340. loss: 2.601, 0.2198 s / batch. (data: 2.19e-05)max mem: 7.80931 GB 
[09/28 01:37:23 visual_prompt]: Inference (test):avg data time: 3.78e-05, avg batch time: 0.2195, average loss: 2.7910
[09/28 01:37:23 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.04	top5: 72.83	
[09/28 01:37:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/28 01:37:33 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e-01, avg batch time: 0.5634, average train loss: 0.2572
[09/28 01:37:36 visual_prompt]: Inference (val):avg data time: 1.97e-05, avg batch time: 0.1706, average loss: 0.1710
[09/28 01:37:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:38:00 visual_prompt]: 	Test 100/340. loss: 2.584, 0.2199 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:38:22 visual_prompt]: 	Test 200/340. loss: 3.238, 0.2200 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 01:38:44 visual_prompt]: 	Test 300/340. loss: 2.855, 0.2196 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 01:38:54 visual_prompt]: Inference (test):avg data time: 4.60e-05, avg batch time: 0.2196, average loss: 2.8258
[09/28 01:38:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.12	top5: 73.12	
[09/28 01:38:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/28 01:39:04 visual_prompt]: Epoch 23 / 100: avg data time: 9.34e-02, avg batch time: 0.5526, average train loss: 0.2864
[09/28 01:39:07 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.1701, average loss: 0.2086
[09/28 01:39:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 01:39:31 visual_prompt]: 	Test 100/340. loss: 2.645, 0.2201 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 01:39:53 visual_prompt]: 	Test 200/340. loss: 3.112, 0.2190 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 01:40:15 visual_prompt]: 	Test 300/340. loss: 2.882, 0.2205 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 01:40:25 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2196, average loss: 2.8589
[09/28 01:40:26 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.74	top5: 73.35	
[09/28 01:40:26 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/28 01:40:36 visual_prompt]: Epoch 24 / 100: avg data time: 9.97e-02, avg batch time: 0.5582, average train loss: 1.9881
[09/28 01:40:39 visual_prompt]: Inference (val):avg data time: 1.81e-05, avg batch time: 0.1702, average loss: 0.6384
[09/28 01:40:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 90.50	top5: 100.00	
[09/28 01:41:02 visual_prompt]: 	Test 100/340. loss: 2.978, 0.2204 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:41:24 visual_prompt]: 	Test 200/340. loss: 3.281, 0.2199 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:41:46 visual_prompt]: 	Test 300/340. loss: 3.092, 0.2202 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 01:41:56 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2196, average loss: 3.1955
[09/28 01:41:57 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.47	top5: 65.83	
[09/28 01:41:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/28 01:42:07 visual_prompt]: Epoch 25 / 100: avg data time: 1.02e-01, avg batch time: 0.5610, average train loss: 0.5493
[09/28 01:42:10 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1703, average loss: 0.1811
[09/28 01:42:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:42:34 visual_prompt]: 	Test 100/340. loss: 2.589, 0.2200 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:42:56 visual_prompt]: 	Test 200/340. loss: 3.182, 0.2195 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:43:18 visual_prompt]: 	Test 300/340. loss: 2.811, 0.2199 s / batch. (data: 6.77e-05)max mem: 7.80931 GB 
[09/28 01:43:28 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2197, average loss: 2.8536
[09/28 01:43:28 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.38	top5: 70.98	
[09/28 01:43:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/28 01:43:38 visual_prompt]: Epoch 26 / 100: avg data time: 9.25e-02, avg batch time: 0.5516, average train loss: 0.7967
[09/28 01:43:41 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1704, average loss: 0.2407
[09/28 01:43:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.00	top5: 100.00	
[09/28 01:44:04 visual_prompt]: 	Test 100/340. loss: 2.680, 0.2194 s / batch. (data: 8.75e-05)max mem: 7.80931 GB 
[09/28 01:44:26 visual_prompt]: 	Test 200/340. loss: 3.196, 0.2190 s / batch. (data: 3.74e-05)max mem: 7.80931 GB 
[09/28 01:44:48 visual_prompt]: 	Test 300/340. loss: 2.836, 0.2194 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:44:58 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2197, average loss: 2.9704
[09/28 01:44:59 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.15	top5: 69.99	
[09/28 01:44:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/28 01:45:09 visual_prompt]: Epoch 27 / 100: avg data time: 9.34e-02, avg batch time: 0.5543, average train loss: 0.3222
[09/28 01:45:12 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1706, average loss: 0.1419
[09/28 01:45:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:45:36 visual_prompt]: 	Test 100/340. loss: 2.433, 0.2191 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:45:58 visual_prompt]: 	Test 200/340. loss: 2.988, 0.2193 s / batch. (data: 8.49e-05)max mem: 7.80931 GB 
[09/28 01:46:20 visual_prompt]: 	Test 300/340. loss: 2.740, 0.2201 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 01:46:30 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2196, average loss: 2.8073
[09/28 01:46:30 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.13	top5: 73.19	
[09/28 01:46:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/28 01:46:40 visual_prompt]: Epoch 28 / 100: avg data time: 9.64e-02, avg batch time: 0.5560, average train loss: 0.2921
[09/28 01:46:43 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1702, average loss: 0.1651
[09/28 01:46:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:47:07 visual_prompt]: 	Test 100/340. loss: 2.700, 0.2201 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 01:47:29 visual_prompt]: 	Test 200/340. loss: 3.077, 0.2196 s / batch. (data: 3.29e-05)max mem: 7.80931 GB 
[09/28 01:47:51 visual_prompt]: 	Test 300/340. loss: 2.783, 0.2197 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 01:48:01 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2196, average loss: 2.8603
[09/28 01:48:01 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.62	top5: 72.33	
[09/28 01:48:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/28 01:48:11 visual_prompt]: Epoch 29 / 100: avg data time: 1.00e-01, avg batch time: 0.5584, average train loss: 0.2469
[09/28 01:48:14 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1707, average loss: 0.1400
[09/28 01:48:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:48:38 visual_prompt]: 	Test 100/340. loss: 2.550, 0.2205 s / batch. (data: 2.34e-05)max mem: 7.80931 GB 
[09/28 01:49:00 visual_prompt]: 	Test 200/340. loss: 2.999, 0.2203 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 01:49:22 visual_prompt]: 	Test 300/340. loss: 2.857, 0.2201 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:49:32 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2197, average loss: 2.8412
[09/28 01:49:32 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.52	top5: 73.28	
[09/28 01:49:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/28 01:49:42 visual_prompt]: Epoch 30 / 100: avg data time: 9.23e-02, avg batch time: 0.5517, average train loss: 0.2598
[09/28 01:49:45 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1700, average loss: 0.1792
[09/28 01:49:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 01:50:09 visual_prompt]: 	Test 100/340. loss: 2.667, 0.2197 s / batch. (data: 4.67e-05)max mem: 7.80931 GB 
[09/28 01:50:31 visual_prompt]: 	Test 200/340. loss: 2.980, 0.2204 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 01:50:53 visual_prompt]: 	Test 300/340. loss: 2.841, 0.2196 s / batch. (data: 7.51e-05)max mem: 7.80931 GB 
[09/28 01:51:03 visual_prompt]: Inference (test):avg data time: 6.54e-05, avg batch time: 0.2196, average loss: 2.8322
[09/28 01:51:03 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.33	top5: 73.19	
[09/28 01:51:03 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/28 01:51:13 visual_prompt]: Epoch 31 / 100: avg data time: 9.35e-02, avg batch time: 0.5522, average train loss: 0.5949
[09/28 01:51:16 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1703, average loss: 0.6525
[09/28 01:51:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 96.00	top5: 100.00	
[09/28 01:51:40 visual_prompt]: 	Test 100/340. loss: 3.004, 0.2201 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:52:02 visual_prompt]: 	Test 200/340. loss: 3.387, 0.2196 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:52:24 visual_prompt]: 	Test 300/340. loss: 3.163, 0.2199 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 01:52:34 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2195, average loss: 3.2253
[09/28 01:52:34 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.72	top5: 67.88	
[09/28 01:52:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/28 01:52:44 visual_prompt]: Epoch 32 / 100: avg data time: 8.26e-02, avg batch time: 0.5420, average train loss: 0.3980
[09/28 01:52:47 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.1701, average loss: 0.1243
[09/28 01:52:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 01:53:11 visual_prompt]: 	Test 100/340. loss: 2.443, 0.2193 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 01:53:33 visual_prompt]: 	Test 200/340. loss: 2.928, 0.2199 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 01:53:55 visual_prompt]: 	Test 300/340. loss: 2.866, 0.2196 s / batch. (data: 2.24e-05)max mem: 7.80931 GB 
[09/28 01:54:05 visual_prompt]: Inference (test):avg data time: 1.39e-04, avg batch time: 0.2196, average loss: 2.8009
[09/28 01:54:05 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.21	top5: 73.46	
[09/28 01:54:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/28 01:54:15 visual_prompt]: Epoch 33 / 100: avg data time: 9.72e-02, avg batch time: 0.5562, average train loss: 0.2032
[09/28 01:54:18 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1702, average loss: 0.1432
[09/28 01:54:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:54:42 visual_prompt]: 	Test 100/340. loss: 2.415, 0.2191 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 01:55:04 visual_prompt]: 	Test 200/340. loss: 3.105, 0.2191 s / batch. (data: 8.58e-05)max mem: 7.80931 GB 
[09/28 01:55:26 visual_prompt]: 	Test 300/340. loss: 2.767, 0.2192 s / batch. (data: 7.58e-05)max mem: 7.80931 GB 
[09/28 01:55:36 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2197, average loss: 2.8302
[09/28 01:55:36 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.63	top5: 73.05	
[09/28 01:55:36 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/28 01:55:46 visual_prompt]: Epoch 34 / 100: avg data time: 9.80e-02, avg batch time: 0.5572, average train loss: 0.2405
[09/28 01:55:49 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1702, average loss: 0.1431
[09/28 01:55:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:56:13 visual_prompt]: 	Test 100/340. loss: 2.590, 0.2192 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 01:56:35 visual_prompt]: 	Test 200/340. loss: 3.060, 0.2201 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 01:56:57 visual_prompt]: 	Test 300/340. loss: 2.750, 0.2197 s / batch. (data: 2.48e-05)max mem: 7.80931 GB 
[09/28 01:57:07 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2196, average loss: 2.8084
[09/28 01:57:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.50	top5: 74.10	
[09/28 01:57:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/28 01:57:17 visual_prompt]: Epoch 35 / 100: avg data time: 1.01e-01, avg batch time: 0.5591, average train loss: 0.2877
[09/28 01:57:20 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1703, average loss: 0.2297
[09/28 01:57:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 01:57:44 visual_prompt]: 	Test 100/340. loss: 2.590, 0.2195 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 01:58:06 visual_prompt]: 	Test 200/340. loss: 3.082, 0.2193 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 01:58:28 visual_prompt]: 	Test 300/340. loss: 2.762, 0.2191 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 01:58:38 visual_prompt]: Inference (test):avg data time: 3.59e-05, avg batch time: 0.2197, average loss: 2.9205
[09/28 01:58:39 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.10	top5: 73.31	
[09/28 01:58:39 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/28 01:58:48 visual_prompt]: Epoch 36 / 100: avg data time: 9.42e-02, avg batch time: 0.5530, average train loss: 0.3229
[09/28 01:58:51 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1703, average loss: 0.7123
[09/28 01:58:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 01:59:15 visual_prompt]: 	Test 100/340. loss: 3.117, 0.2198 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 01:59:37 visual_prompt]: 	Test 200/340. loss: 3.399, 0.2206 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 01:59:59 visual_prompt]: 	Test 300/340. loss: 3.247, 0.2202 s / batch. (data: 7.18e-05)max mem: 7.80931 GB 
[09/28 02:00:09 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2196, average loss: 3.2953
[09/28 02:00:10 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.29	top5: 67.74	
[09/28 02:00:10 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/28 02:00:20 visual_prompt]: Epoch 37 / 100: avg data time: 9.70e-02, avg batch time: 0.5563, average train loss: 0.4643
[09/28 02:00:23 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1702, average loss: 0.1182
[09/28 02:00:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:00:46 visual_prompt]: 	Test 100/340. loss: 2.452, 0.2201 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 02:01:08 visual_prompt]: 	Test 200/340. loss: 2.998, 0.2211 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 02:01:30 visual_prompt]: 	Test 300/340. loss: 2.705, 0.2196 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:01:40 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2197, average loss: 2.7570
[09/28 02:01:41 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.54	top5: 74.14	
[09/28 02:01:41 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/28 02:01:51 visual_prompt]: Epoch 38 / 100: avg data time: 9.67e-02, avg batch time: 0.5555, average train loss: 0.1836
[09/28 02:01:54 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.1702, average loss: 0.9339
[09/28 02:01:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.00	top5: 100.00	
[09/28 02:02:17 visual_prompt]: 	Test 100/340. loss: 3.144, 0.2200 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 02:02:39 visual_prompt]: 	Test 200/340. loss: 3.492, 0.2192 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 02:03:01 visual_prompt]: 	Test 300/340. loss: 3.195, 0.2196 s / batch. (data: 7.61e-05)max mem: 7.80931 GB 
[09/28 02:03:11 visual_prompt]: Inference (test):avg data time: 3.80e-05, avg batch time: 0.2197, average loss: 3.3736
[09/28 02:03:12 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.94	top5: 69.48	
[09/28 02:03:12 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/28 02:03:22 visual_prompt]: Epoch 39 / 100: avg data time: 1.01e-01, avg batch time: 0.5595, average train loss: 0.6986
[09/28 02:03:25 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1703, average loss: 0.2912
[09/28 02:03:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:03:48 visual_prompt]: 	Test 100/340. loss: 2.762, 0.2208 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:04:10 visual_prompt]: 	Test 200/340. loss: 3.129, 0.2194 s / batch. (data: 2.41e-05)max mem: 7.80931 GB 
[09/28 02:04:32 visual_prompt]: 	Test 300/340. loss: 2.958, 0.2210 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:04:42 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2197, average loss: 2.9049
[09/28 02:04:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.19	top5: 72.74	
[09/28 02:04:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/28 02:04:53 visual_prompt]: Epoch 40 / 100: avg data time: 9.29e-02, avg batch time: 0.5512, average train loss: 0.3482
[09/28 02:04:56 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1702, average loss: 0.1396
[09/28 02:04:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 02:05:19 visual_prompt]: 	Test 100/340. loss: 2.527, 0.2184 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 02:05:41 visual_prompt]: 	Test 200/340. loss: 3.107, 0.2195 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 02:06:03 visual_prompt]: 	Test 300/340. loss: 2.676, 0.2211 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 02:06:13 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2197, average loss: 2.7891
[09/28 02:06:14 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.18	top5: 73.27	
[09/28 02:06:14 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/28 02:06:24 visual_prompt]: Epoch 41 / 100: avg data time: 9.78e-02, avg batch time: 0.5581, average train loss: 0.2449
[09/28 02:06:27 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1702, average loss: 0.1415
[09/28 02:06:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:06:50 visual_prompt]: 	Test 100/340. loss: 2.644, 0.2204 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 02:07:12 visual_prompt]: 	Test 200/340. loss: 3.121, 0.2193 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:07:34 visual_prompt]: 	Test 300/340. loss: 2.663, 0.2202 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 02:07:44 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2197, average loss: 2.8465
[09/28 02:07:45 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.78	top5: 73.07	
[09/28 02:07:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/28 02:07:55 visual_prompt]: Epoch 42 / 100: avg data time: 9.49e-02, avg batch time: 0.5540, average train loss: 2.5412
[09/28 02:07:58 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1704, average loss: 0.6326
[09/28 02:07:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 95.00	top5: 100.00	
[09/28 02:08:21 visual_prompt]: 	Test 100/340. loss: 2.994, 0.2200 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 02:08:43 visual_prompt]: 	Test 200/340. loss: 3.408, 0.2195 s / batch. (data: 2.48e-05)max mem: 7.80931 GB 
[09/28 02:09:05 visual_prompt]: 	Test 300/340. loss: 3.267, 0.2195 s / batch. (data: 6.51e-05)max mem: 7.80931 GB 
[09/28 02:09:15 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2197, average loss: 3.2304
[09/28 02:09:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.28	top5: 65.10	
[09/28 02:09:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/28 02:09:26 visual_prompt]: Epoch 43 / 100: avg data time: 9.50e-02, avg batch time: 0.5541, average train loss: 1.4887
[09/28 02:09:29 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1703, average loss: 0.3295
[09/28 02:09:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 95.50	top5: 100.00	
[09/28 02:09:53 visual_prompt]: 	Test 100/340. loss: 2.652, 0.2198 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:10:15 visual_prompt]: 	Test 200/340. loss: 3.203, 0.2191 s / batch. (data: 2.31e-05)max mem: 7.80931 GB 
[09/28 02:10:37 visual_prompt]: 	Test 300/340. loss: 3.100, 0.2208 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 02:10:47 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2196, average loss: 2.9857
[09/28 02:10:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.80	top5: 69.20	
[09/28 02:10:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/28 02:10:57 visual_prompt]: Epoch 44 / 100: avg data time: 9.62e-02, avg batch time: 0.5551, average train loss: 0.6034
[09/28 02:11:00 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1704, average loss: 0.2812
[09/28 02:11:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 02:11:24 visual_prompt]: 	Test 100/340. loss: 2.586, 0.2195 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:11:46 visual_prompt]: 	Test 200/340. loss: 3.269, 0.2199 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:12:08 visual_prompt]: 	Test 300/340. loss: 3.144, 0.2196 s / batch. (data: 2.41e-05)max mem: 7.80931 GB 
[09/28 02:12:18 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2197, average loss: 3.0356
[09/28 02:12:18 visual_prompt]: Classification results with test_vtab-sun397: top1: 42.95	top5: 68.71	
[09/28 02:12:18 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/28 02:12:28 visual_prompt]: Epoch 45 / 100: avg data time: 8.73e-02, avg batch time: 0.5477, average train loss: 0.2503
[09/28 02:12:31 visual_prompt]: Inference (val):avg data time: 1.66e-05, avg batch time: 0.1700, average loss: 0.1354
[09/28 02:12:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 02:12:54 visual_prompt]: 	Test 100/340. loss: 2.632, 0.2203 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:13:16 visual_prompt]: 	Test 200/340. loss: 3.125, 0.2204 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:13:38 visual_prompt]: 	Test 300/340. loss: 2.937, 0.2198 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:13:49 visual_prompt]: Inference (test):avg data time: 7.98e-05, avg batch time: 0.2197, average loss: 2.8817
[09/28 02:13:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.37	top5: 72.23	
[09/28 02:13:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/28 02:13:59 visual_prompt]: Epoch 46 / 100: avg data time: 8.83e-02, avg batch time: 0.5488, average train loss: 0.3596
[09/28 02:14:02 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.1702, average loss: 0.2612
[09/28 02:14:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 02:14:25 visual_prompt]: 	Test 100/340. loss: 2.803, 0.2187 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:14:47 visual_prompt]: 	Test 200/340. loss: 3.091, 0.2201 s / batch. (data: 6.89e-05)max mem: 7.80931 GB 
[09/28 02:15:10 visual_prompt]: 	Test 300/340. loss: 2.929, 0.2215 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 02:15:20 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2198, average loss: 2.9711
[09/28 02:15:20 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.96	top5: 70.99	
[09/28 02:15:20 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/28 02:15:30 visual_prompt]: Epoch 47 / 100: avg data time: 9.38e-02, avg batch time: 0.5526, average train loss: 0.2972
[09/28 02:15:33 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1698, average loss: 0.1440
[09/28 02:15:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 02:15:57 visual_prompt]: 	Test 100/340. loss: 2.667, 0.2198 s / batch. (data: 2.98e-05)max mem: 7.80931 GB 
[09/28 02:16:19 visual_prompt]: 	Test 200/340. loss: 3.058, 0.2200 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:16:41 visual_prompt]: 	Test 300/340. loss: 2.819, 0.2193 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 02:16:51 visual_prompt]: Inference (test):avg data time: 3.86e-05, avg batch time: 0.2197, average loss: 2.8476
[09/28 02:16:51 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.17	top5: 73.11	
[09/28 02:16:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/28 02:17:01 visual_prompt]: Epoch 48 / 100: avg data time: 9.98e-02, avg batch time: 0.5587, average train loss: 0.1968
[09/28 02:17:04 visual_prompt]: Inference (val):avg data time: 1.70e-05, avg batch time: 0.1702, average loss: 0.1274
[09/28 02:17:04 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:17:28 visual_prompt]: 	Test 100/340. loss: 2.670, 0.2195 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:17:50 visual_prompt]: 	Test 200/340. loss: 2.985, 0.2201 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:18:12 visual_prompt]: 	Test 300/340. loss: 2.872, 0.2211 s / batch. (data: 8.49e-05)max mem: 7.80931 GB 
[09/28 02:18:22 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2197, average loss: 2.8302
[09/28 02:18:22 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.42	top5: 73.16	
[09/28 02:18:22 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/28 02:18:32 visual_prompt]: Epoch 49 / 100: avg data time: 9.36e-02, avg batch time: 0.5535, average train loss: 0.3682
[09/28 02:18:35 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1701, average loss: 0.1991
[09/28 02:18:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:18:59 visual_prompt]: 	Test 100/340. loss: 2.642, 0.2203 s / batch. (data: 7.82e-05)max mem: 7.80931 GB 
[09/28 02:19:21 visual_prompt]: 	Test 200/340. loss: 3.142, 0.2197 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:19:43 visual_prompt]: 	Test 300/340. loss: 3.009, 0.2198 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 02:19:53 visual_prompt]: Inference (test):avg data time: 4.54e-05, avg batch time: 0.2197, average loss: 2.9093
[09/28 02:19:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.29	top5: 72.12	
[09/28 02:19:53 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/28 02:20:03 visual_prompt]: Epoch 50 / 100: avg data time: 1.02e-01, avg batch time: 0.5612, average train loss: 0.2489
[09/28 02:20:06 visual_prompt]: Inference (val):avg data time: 1.72e-05, avg batch time: 0.1702, average loss: 0.1265
[09/28 02:20:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 02:20:30 visual_prompt]: 	Test 100/340. loss: 2.613, 0.2202 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 02:20:52 visual_prompt]: 	Test 200/340. loss: 3.058, 0.2198 s / batch. (data: 1.21e-04)max mem: 7.80931 GB 
[09/28 02:21:14 visual_prompt]: 	Test 300/340. loss: 2.835, 0.2203 s / batch. (data: 2.96e-05)max mem: 7.80931 GB 
[09/28 02:21:24 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2196, average loss: 2.8287
[09/28 02:21:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.35	top5: 73.47	
[09/28 02:21:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/28 02:21:35 visual_prompt]: Epoch 51 / 100: avg data time: 8.83e-02, avg batch time: 0.5473, average train loss: 0.1890
[09/28 02:21:38 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1702, average loss: 0.1286
[09/28 02:21:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:22:01 visual_prompt]: 	Test 100/340. loss: 2.562, 0.2191 s / batch. (data: 4.03e-05)max mem: 7.80931 GB 
[09/28 02:22:23 visual_prompt]: 	Test 200/340. loss: 3.025, 0.2202 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:22:45 visual_prompt]: 	Test 300/340. loss: 2.750, 0.2199 s / batch. (data: 8.92e-05)max mem: 7.80931 GB 
[09/28 02:22:55 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2197, average loss: 2.8022
[09/28 02:22:56 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.97	top5: 73.67	
[09/28 02:22:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/28 02:23:06 visual_prompt]: Epoch 52 / 100: avg data time: 9.66e-02, avg batch time: 0.5552, average train loss: 0.1839
[09/28 02:23:09 visual_prompt]: Inference (val):avg data time: 1.79e-05, avg batch time: 0.1699, average loss: 0.1255
[09/28 02:23:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:23:32 visual_prompt]: 	Test 100/340. loss: 2.542, 0.2194 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:23:54 visual_prompt]: 	Test 200/340. loss: 3.037, 0.2190 s / batch. (data: 2.48e-05)max mem: 7.80931 GB 
[09/28 02:24:16 visual_prompt]: 	Test 300/340. loss: 2.775, 0.2197 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 02:24:26 visual_prompt]: Inference (test):avg data time: 3.51e-05, avg batch time: 0.2197, average loss: 2.8340
[09/28 02:24:27 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.81	top5: 73.71	
[09/28 02:24:27 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/28 02:24:37 visual_prompt]: Epoch 53 / 100: avg data time: 9.87e-02, avg batch time: 0.5573, average train loss: 0.1875
[09/28 02:24:40 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1701, average loss: 0.1306
[09/28 02:24:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:25:03 visual_prompt]: 	Test 100/340. loss: 2.560, 0.2205 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:25:25 visual_prompt]: 	Test 200/340. loss: 3.056, 0.2195 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:25:47 visual_prompt]: 	Test 300/340. loss: 2.750, 0.2197 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:25:57 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2197, average loss: 2.8220
[09/28 02:25:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.00	top5: 74.22	
[09/28 02:25:58 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/28 02:26:07 visual_prompt]: Epoch 54 / 100: avg data time: 8.91e-02, avg batch time: 0.5481, average train loss: 0.1918
[09/28 02:26:10 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1703, average loss: 0.1388
[09/28 02:26:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:26:34 visual_prompt]: 	Test 100/340. loss: 2.584, 0.2200 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:26:56 visual_prompt]: 	Test 200/340. loss: 3.082, 0.2196 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 02:27:18 visual_prompt]: 	Test 300/340. loss: 2.792, 0.2202 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:27:28 visual_prompt]: Inference (test):avg data time: 4.55e-05, avg batch time: 0.2196, average loss: 2.8300
[09/28 02:27:29 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.56	top5: 74.18	
[09/28 02:27:29 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/28 02:27:38 visual_prompt]: Epoch 55 / 100: avg data time: 1.01e-01, avg batch time: 0.5602, average train loss: 0.1968
[09/28 02:27:41 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.1701, average loss: 0.1616
[09/28 02:27:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:28:05 visual_prompt]: 	Test 100/340. loss: 2.469, 0.2197 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 02:28:27 visual_prompt]: 	Test 200/340. loss: 3.052, 0.2207 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 02:28:49 visual_prompt]: 	Test 300/340. loss: 2.723, 0.2204 s / batch. (data: 7.39e-05)max mem: 7.80931 GB 
[09/28 02:28:59 visual_prompt]: Inference (test):avg data time: 8.25e-05, avg batch time: 0.2198, average loss: 2.8484
[09/28 02:28:59 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.40	top5: 74.00	
[09/28 02:28:59 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/28 02:29:09 visual_prompt]: Epoch 56 / 100: avg data time: 9.71e-02, avg batch time: 0.5557, average train loss: 0.2188
[09/28 02:29:12 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.1704, average loss: 0.1339
[09/28 02:29:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:29:36 visual_prompt]: 	Test 100/340. loss: 2.531, 0.2190 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:29:58 visual_prompt]: 	Test 200/340. loss: 3.104, 0.2204 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 02:30:20 visual_prompt]: 	Test 300/340. loss: 2.806, 0.2194 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 02:30:30 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2198, average loss: 2.8261
[09/28 02:30:30 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.10	top5: 74.26	
[09/28 02:30:30 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/28 02:30:40 visual_prompt]: Epoch 57 / 100: avg data time: 8.28e-02, avg batch time: 0.5428, average train loss: 0.1844
[09/28 02:30:43 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1704, average loss: 0.1336
[09/28 02:30:43 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:31:07 visual_prompt]: 	Test 100/340. loss: 2.501, 0.2201 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 02:31:28 visual_prompt]: 	Test 200/340. loss: 3.055, 0.2205 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 02:31:51 visual_prompt]: 	Test 300/340. loss: 2.675, 0.2193 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 02:32:01 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2197, average loss: 2.7774
[09/28 02:32:01 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.71	top5: 74.72	
[09/28 02:32:01 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/28 02:32:11 visual_prompt]: Epoch 58 / 100: avg data time: 9.47e-02, avg batch time: 0.5535, average train loss: 0.1706
[09/28 02:32:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1703, average loss: 0.1224
[09/28 02:32:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:32:38 visual_prompt]: 	Test 100/340. loss: 2.544, 0.2208 s / batch. (data: 7.72e-05)max mem: 7.80931 GB 
[09/28 02:33:00 visual_prompt]: 	Test 200/340. loss: 2.955, 0.2195 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 02:33:22 visual_prompt]: 	Test 300/340. loss: 2.778, 0.2200 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 02:33:32 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2197, average loss: 2.7999
[09/28 02:33:32 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.25	top5: 74.77	
[09/28 02:33:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/28 02:33:42 visual_prompt]: Epoch 59 / 100: avg data time: 9.05e-02, avg batch time: 0.5499, average train loss: 0.1668
[09/28 02:33:45 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1706, average loss: 0.1243
[09/28 02:33:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:34:08 visual_prompt]: 	Test 100/340. loss: 2.541, 0.2184 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 02:34:30 visual_prompt]: 	Test 200/340. loss: 3.052, 0.2200 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 02:34:52 visual_prompt]: 	Test 300/340. loss: 2.800, 0.2205 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 02:35:02 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2197, average loss: 2.8081
[09/28 02:35:03 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.05	top5: 74.83	
[09/28 02:35:03 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/28 02:35:13 visual_prompt]: Epoch 60 / 100: avg data time: 8.81e-02, avg batch time: 0.5476, average train loss: 0.1719
[09/28 02:35:16 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.1704, average loss: 0.1289
[09/28 02:35:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:35:39 visual_prompt]: 	Test 100/340. loss: 2.499, 0.2188 s / batch. (data: 4.86e-05)max mem: 7.80931 GB 
[09/28 02:36:01 visual_prompt]: 	Test 200/340. loss: 3.039, 0.2204 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:36:23 visual_prompt]: 	Test 300/340. loss: 2.789, 0.2204 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:36:33 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2197, average loss: 2.8160
[09/28 02:36:34 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.69	top5: 74.85	
[09/28 02:36:34 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/28 02:36:43 visual_prompt]: Epoch 61 / 100: avg data time: 9.61e-02, avg batch time: 0.5547, average train loss: 0.1612
[09/28 02:36:46 visual_prompt]: Inference (val):avg data time: 1.73e-05, avg batch time: 0.1701, average loss: 0.1277
[09/28 02:36:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:37:10 visual_prompt]: 	Test 100/340. loss: 2.490, 0.2200 s / batch. (data: 2.38e-05)max mem: 7.80931 GB 
[09/28 02:37:32 visual_prompt]: 	Test 200/340. loss: 3.064, 0.2193 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 02:37:54 visual_prompt]: 	Test 300/340. loss: 2.722, 0.2199 s / batch. (data: 6.39e-05)max mem: 7.80931 GB 
[09/28 02:38:04 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2196, average loss: 2.7887
[09/28 02:38:04 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.55	top5: 75.14	
[09/28 02:38:04 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/28 02:38:14 visual_prompt]: Epoch 62 / 100: avg data time: 8.92e-02, avg batch time: 0.5494, average train loss: 0.1561
[09/28 02:38:17 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.1700, average loss: 0.1303
[09/28 02:38:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:38:41 visual_prompt]: 	Test 100/340. loss: 2.504, 0.2189 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 02:39:03 visual_prompt]: 	Test 200/340. loss: 3.140, 0.2188 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 02:39:25 visual_prompt]: 	Test 300/340. loss: 2.780, 0.2201 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:39:35 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2197, average loss: 2.8244
[09/28 02:39:35 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.92	top5: 74.85	
[09/28 02:39:35 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/28 02:39:45 visual_prompt]: Epoch 63 / 100: avg data time: 9.64e-02, avg batch time: 0.5568, average train loss: 0.1677
[09/28 02:39:48 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1702, average loss: 0.1246
[09/28 02:39:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:40:12 visual_prompt]: 	Test 100/340. loss: 2.424, 0.2196 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 02:40:34 visual_prompt]: 	Test 200/340. loss: 3.016, 0.2204 s / batch. (data: 2.96e-05)max mem: 7.80931 GB 
[09/28 02:40:56 visual_prompt]: 	Test 300/340. loss: 2.850, 0.2199 s / batch. (data: 8.20e-05)max mem: 7.80931 GB 
[09/28 02:41:06 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2196, average loss: 2.8080
[09/28 02:41:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.72	top5: 75.10	
[09/28 02:41:07 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/28 02:41:16 visual_prompt]: Epoch 64 / 100: avg data time: 9.57e-02, avg batch time: 0.5542, average train loss: 0.1630
[09/28 02:41:19 visual_prompt]: Inference (val):avg data time: 1.88e-05, avg batch time: 0.1702, average loss: 0.1351
[09/28 02:41:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:41:43 visual_prompt]: 	Test 100/340. loss: 2.559, 0.2193 s / batch. (data: 7.96e-05)max mem: 7.80931 GB 
[09/28 02:42:05 visual_prompt]: 	Test 200/340. loss: 3.065, 0.2198 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:42:27 visual_prompt]: 	Test 300/340. loss: 2.741, 0.2198 s / batch. (data: 2.55e-05)max mem: 7.80931 GB 
[09/28 02:42:37 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2197, average loss: 2.8081
[09/28 02:42:37 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.44	top5: 75.43	
[09/28 02:42:37 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/28 02:42:47 visual_prompt]: Epoch 65 / 100: avg data time: 9.07e-02, avg batch time: 0.5497, average train loss: 0.5215
[09/28 02:42:50 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1703, average loss: 0.2744
[09/28 02:42:50 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:43:14 visual_prompt]: 	Test 100/340. loss: 2.606, 0.2194 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:43:36 visual_prompt]: 	Test 200/340. loss: 3.213, 0.2198 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:43:58 visual_prompt]: 	Test 300/340. loss: 2.804, 0.2201 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 02:44:08 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.2196, average loss: 2.9346
[09/28 02:44:08 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.91	top5: 73.93	
[09/28 02:44:08 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/28 02:44:18 visual_prompt]: Epoch 66 / 100: avg data time: 9.41e-02, avg batch time: 0.5529, average train loss: 0.2364
[09/28 02:44:21 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1701, average loss: 0.1487
[09/28 02:44:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:44:44 visual_prompt]: 	Test 100/340. loss: 2.452, 0.2202 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 02:45:06 visual_prompt]: 	Test 200/340. loss: 3.027, 0.2203 s / batch. (data: 3.10e-05)max mem: 7.80931 GB 
[09/28 02:45:28 visual_prompt]: 	Test 300/340. loss: 2.715, 0.2193 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 02:45:39 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2197, average loss: 2.7802
[09/28 02:45:39 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.31	top5: 74.96	
[09/28 02:45:39 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/28 02:45:49 visual_prompt]: Epoch 67 / 100: avg data time: 9.52e-02, avg batch time: 0.5549, average train loss: 0.1622
[09/28 02:45:52 visual_prompt]: Inference (val):avg data time: 1.64e-05, avg batch time: 0.1701, average loss: 0.1160
[09/28 02:45:52 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:46:15 visual_prompt]: 	Test 100/340. loss: 2.442, 0.2197 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 02:46:37 visual_prompt]: 	Test 200/340. loss: 2.946, 0.2198 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 02:46:59 visual_prompt]: 	Test 300/340. loss: 2.712, 0.2198 s / batch. (data: 7.10e-05)max mem: 7.80931 GB 
[09/28 02:47:10 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2197, average loss: 2.7380
[09/28 02:47:10 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.18	top5: 75.42	
[09/28 02:47:10 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/28 02:47:20 visual_prompt]: Epoch 68 / 100: avg data time: 9.23e-02, avg batch time: 0.5514, average train loss: 0.1361
[09/28 02:47:23 visual_prompt]: Inference (val):avg data time: 1.76e-05, avg batch time: 0.1704, average loss: 0.1027
[09/28 02:47:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:47:46 visual_prompt]: 	Test 100/340. loss: 2.473, 0.2203 s / batch. (data: 3.10e-05)max mem: 7.80931 GB 
[09/28 02:48:08 visual_prompt]: 	Test 200/340. loss: 3.008, 0.2196 s / batch. (data: 2.38e-05)max mem: 7.80931 GB 
[09/28 02:48:30 visual_prompt]: 	Test 300/340. loss: 2.663, 0.2193 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 02:48:40 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2197, average loss: 2.7627
[09/28 02:48:41 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.13	top5: 75.37	
[09/28 02:48:41 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/28 02:48:51 visual_prompt]: Epoch 69 / 100: avg data time: 9.17e-02, avg batch time: 0.5501, average train loss: 0.1269
[09/28 02:48:54 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1701, average loss: 0.1078
[09/28 02:48:54 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:49:17 visual_prompt]: 	Test 100/340. loss: 2.429, 0.2187 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 02:49:39 visual_prompt]: 	Test 200/340. loss: 2.973, 0.2203 s / batch. (data: 7.34e-05)max mem: 7.80931 GB 
[09/28 02:50:01 visual_prompt]: 	Test 300/340. loss: 2.661, 0.2212 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 02:50:12 visual_prompt]: Inference (test):avg data time: 5.39e-05, avg batch time: 0.2196, average loss: 2.7501
[09/28 02:50:12 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.24	top5: 75.78	
[09/28 02:50:12 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/28 02:50:22 visual_prompt]: Epoch 70 / 100: avg data time: 8.45e-02, avg batch time: 0.5452, average train loss: 0.1264
[09/28 02:50:25 visual_prompt]: Inference (val):avg data time: 1.65e-05, avg batch time: 0.1703, average loss: 0.1098
[09/28 02:50:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:50:48 visual_prompt]: 	Test 100/340. loss: 2.437, 0.2205 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 02:51:10 visual_prompt]: 	Test 200/340. loss: 2.980, 0.2200 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 02:51:32 visual_prompt]: 	Test 300/340. loss: 2.674, 0.2207 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 02:51:42 visual_prompt]: Inference (test):avg data time: 6.53e-05, avg batch time: 0.2197, average loss: 2.7629
[09/28 02:51:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.35	top5: 75.80	
[09/28 02:51:43 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/28 02:51:53 visual_prompt]: Epoch 71 / 100: avg data time: 9.52e-02, avg batch time: 0.5537, average train loss: 0.1315
[09/28 02:51:56 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1700, average loss: 0.1056
[09/28 02:51:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:52:19 visual_prompt]: 	Test 100/340. loss: 2.442, 0.2195 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 02:52:41 visual_prompt]: 	Test 200/340. loss: 2.959, 0.2193 s / batch. (data: 3.39e-05)max mem: 7.80931 GB 
[09/28 02:53:03 visual_prompt]: 	Test 300/340. loss: 2.727, 0.2202 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 02:53:13 visual_prompt]: Inference (test):avg data time: 8.34e-05, avg batch time: 0.2198, average loss: 2.7700
[09/28 02:53:14 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.37	top5: 75.73	
[09/28 02:53:14 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/28 02:53:24 visual_prompt]: Epoch 72 / 100: avg data time: 9.41e-02, avg batch time: 0.5528, average train loss: 0.1398
[09/28 02:53:27 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.1707, average loss: 0.1205
[09/28 02:53:27 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:53:50 visual_prompt]: 	Test 100/340. loss: 2.508, 0.2211 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 02:54:12 visual_prompt]: 	Test 200/340. loss: 2.968, 0.2188 s / batch. (data: 2.53e-05)max mem: 7.80931 GB 
[09/28 02:54:34 visual_prompt]: 	Test 300/340. loss: 2.742, 0.2199 s / batch. (data: 3.17e-05)max mem: 7.80931 GB 
[09/28 02:54:44 visual_prompt]: Inference (test):avg data time: 3.47e-05, avg batch time: 0.2197, average loss: 2.8182
[09/28 02:54:45 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.03	top5: 75.44	
[09/28 02:54:45 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/28 02:54:55 visual_prompt]: Epoch 73 / 100: avg data time: 9.89e-02, avg batch time: 0.5574, average train loss: 0.1445
[09/28 02:54:58 visual_prompt]: Inference (val):avg data time: 1.93e-05, avg batch time: 0.1707, average loss: 0.1149
[09/28 02:54:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:55:21 visual_prompt]: 	Test 100/340. loss: 2.494, 0.2185 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:55:43 visual_prompt]: 	Test 200/340. loss: 3.014, 0.2192 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 02:56:05 visual_prompt]: 	Test 300/340. loss: 2.725, 0.2205 s / batch. (data: 3.00e-05)max mem: 7.80931 GB 
[09/28 02:56:15 visual_prompt]: Inference (test):avg data time: 4.19e-05, avg batch time: 0.2197, average loss: 2.7927
[09/28 02:56:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.37	top5: 75.66	
[09/28 02:56:16 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/28 02:56:25 visual_prompt]: Epoch 74 / 100: avg data time: 8.66e-02, avg batch time: 0.5456, average train loss: 0.1389
[09/28 02:56:28 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1702, average loss: 0.1079
[09/28 02:56:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:56:52 visual_prompt]: 	Test 100/340. loss: 2.401, 0.2203 s / batch. (data: 3.03e-05)max mem: 7.80931 GB 
[09/28 02:57:14 visual_prompt]: 	Test 200/340. loss: 2.998, 0.2192 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 02:57:36 visual_prompt]: 	Test 300/340. loss: 2.699, 0.2212 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 02:57:46 visual_prompt]: Inference (test):avg data time: 3.56e-05, avg batch time: 0.2198, average loss: 2.7771
[09/28 02:57:46 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.35	top5: 75.94	
[09/28 02:57:46 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/28 02:57:56 visual_prompt]: Epoch 75 / 100: avg data time: 9.70e-02, avg batch time: 0.5560, average train loss: 0.1297
[09/28 02:57:59 visual_prompt]: Inference (val):avg data time: 1.94e-05, avg batch time: 0.1701, average loss: 0.1053
[09/28 02:57:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:58:23 visual_prompt]: 	Test 100/340. loss: 2.451, 0.2192 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 02:58:45 visual_prompt]: 	Test 200/340. loss: 2.995, 0.2191 s / batch. (data: 8.39e-05)max mem: 7.80931 GB 
[09/28 02:59:07 visual_prompt]: 	Test 300/340. loss: 2.716, 0.2199 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 02:59:17 visual_prompt]: Inference (test):avg data time: 7.30e-05, avg batch time: 0.2197, average loss: 2.7936
[09/28 02:59:17 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.51	top5: 75.60	
[09/28 02:59:17 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/28 02:59:27 visual_prompt]: Epoch 76 / 100: avg data time: 1.03e-01, avg batch time: 0.5630, average train loss: 0.1232
[09/28 02:59:30 visual_prompt]: Inference (val):avg data time: 1.90e-05, avg batch time: 0.1706, average loss: 0.1014
[09/28 02:59:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 02:59:54 visual_prompt]: 	Test 100/340. loss: 2.454, 0.2203 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 03:00:16 visual_prompt]: 	Test 200/340. loss: 3.002, 0.2200 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 03:00:38 visual_prompt]: 	Test 300/340. loss: 2.746, 0.2208 s / batch. (data: 7.46e-05)max mem: 7.80931 GB 
[09/28 03:00:48 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2197, average loss: 2.8047
[09/28 03:00:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.27	top5: 75.47	
[09/28 03:00:49 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/28 03:00:59 visual_prompt]: Epoch 77 / 100: avg data time: 9.67e-02, avg batch time: 0.5556, average train loss: 0.1287
[09/28 03:01:02 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.1701, average loss: 0.1066
[09/28 03:01:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:01:25 visual_prompt]: 	Test 100/340. loss: 2.453, 0.2192 s / batch. (data: 4.27e-05)max mem: 7.80931 GB 
[09/28 03:01:47 visual_prompt]: 	Test 200/340. loss: 2.991, 0.2191 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:02:09 visual_prompt]: 	Test 300/340. loss: 2.781, 0.2197 s / batch. (data: 3.08e-05)max mem: 7.80931 GB 
[09/28 03:02:19 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2196, average loss: 2.7946
[09/28 03:02:20 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.30	top5: 75.82	
[09/28 03:02:20 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/28 03:02:30 visual_prompt]: Epoch 78 / 100: avg data time: 9.48e-02, avg batch time: 0.5535, average train loss: 0.1270
[09/28 03:02:32 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1705, average loss: 0.0994
[09/28 03:02:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:02:56 visual_prompt]: 	Test 100/340. loss: 2.470, 0.2199 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 03:03:18 visual_prompt]: 	Test 200/340. loss: 2.976, 0.2191 s / batch. (data: 4.65e-05)max mem: 7.80931 GB 
[09/28 03:03:40 visual_prompt]: 	Test 300/340. loss: 2.769, 0.2204 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 03:03:50 visual_prompt]: Inference (test):avg data time: 3.54e-05, avg batch time: 0.2196, average loss: 2.8040
[09/28 03:03:51 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.44	top5: 75.76	
[09/28 03:03:51 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/28 03:04:00 visual_prompt]: Epoch 79 / 100: avg data time: 9.02e-02, avg batch time: 0.5495, average train loss: 0.1218
[09/28 03:04:03 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1701, average loss: 0.0992
[09/28 03:04:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:04:27 visual_prompt]: 	Test 100/340. loss: 2.462, 0.2189 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 03:04:49 visual_prompt]: 	Test 200/340. loss: 3.045, 0.2194 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:05:11 visual_prompt]: 	Test 300/340. loss: 2.777, 0.2198 s / batch. (data: 7.82e-05)max mem: 7.80931 GB 
[09/28 03:05:21 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2197, average loss: 2.8015
[09/28 03:05:22 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.05	top5: 75.73	
[09/28 03:05:22 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/28 03:05:32 visual_prompt]: Epoch 80 / 100: avg data time: 1.00e-01, avg batch time: 0.5591, average train loss: 0.1336
[09/28 03:05:35 visual_prompt]: Inference (val):avg data time: 1.91e-05, avg batch time: 0.1702, average loss: 0.1329
[09/28 03:05:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:05:58 visual_prompt]: 	Test 100/340. loss: 2.473, 0.2197 s / batch. (data: 9.51e-05)max mem: 7.80931 GB 
[09/28 03:06:20 visual_prompt]: 	Test 200/340. loss: 3.051, 0.2196 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 03:06:42 visual_prompt]: 	Test 300/340. loss: 2.830, 0.2196 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 03:06:52 visual_prompt]: Inference (test):avg data time: 4.79e-05, avg batch time: 0.2197, average loss: 2.8344
[09/28 03:06:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.78	top5: 75.37	
[09/28 03:06:53 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/28 03:07:02 visual_prompt]: Epoch 81 / 100: avg data time: 9.67e-02, avg batch time: 0.5552, average train loss: 0.1414
[09/28 03:07:05 visual_prompt]: Inference (val):avg data time: 1.78e-05, avg batch time: 0.1703, average loss: 0.1111
[09/28 03:07:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:07:29 visual_prompt]: 	Test 100/340. loss: 2.432, 0.2205 s / batch. (data: 2.22e-05)max mem: 7.80931 GB 
[09/28 03:07:51 visual_prompt]: 	Test 200/340. loss: 2.962, 0.2193 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 03:08:13 visual_prompt]: 	Test 300/340. loss: 2.721, 0.2204 s / batch. (data: 2.96e-05)max mem: 7.80931 GB 
[09/28 03:08:23 visual_prompt]: Inference (test):avg data time: 3.46e-05, avg batch time: 0.2197, average loss: 2.8082
[09/28 03:08:23 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.19	top5: 75.77	
[09/28 03:08:23 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/28 03:08:33 visual_prompt]: Epoch 82 / 100: avg data time: 9.34e-02, avg batch time: 0.5527, average train loss: 0.1286
[09/28 03:08:36 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1704, average loss: 0.0999
[09/28 03:08:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:09:00 visual_prompt]: 	Test 100/340. loss: 2.479, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 03:09:22 visual_prompt]: 	Test 200/340. loss: 2.996, 0.2194 s / batch. (data: 2.57e-05)max mem: 7.80931 GB 
[09/28 03:09:44 visual_prompt]: 	Test 300/340. loss: 2.741, 0.2203 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:09:54 visual_prompt]: Inference (test):avg data time: 4.09e-05, avg batch time: 0.2197, average loss: 2.8073
[09/28 03:09:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.24	top5: 75.84	
[09/28 03:09:54 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/28 03:10:04 visual_prompt]: Epoch 83 / 100: avg data time: 9.92e-02, avg batch time: 0.5584, average train loss: 0.1173
[09/28 03:10:07 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1703, average loss: 0.0960
[09/28 03:10:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:10:31 visual_prompt]: 	Test 100/340. loss: 2.468, 0.2200 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 03:10:53 visual_prompt]: 	Test 200/340. loss: 2.999, 0.2197 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 03:11:15 visual_prompt]: 	Test 300/340. loss: 2.770, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 03:11:25 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2196, average loss: 2.8000
[09/28 03:11:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.63	top5: 75.83	
[09/28 03:11:25 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/28 03:11:35 visual_prompt]: Epoch 84 / 100: avg data time: 1.00e-01, avg batch time: 0.5591, average train loss: 0.1123
[09/28 03:11:38 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1699, average loss: 0.0967
[09/28 03:11:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:12:02 visual_prompt]: 	Test 100/340. loss: 2.485, 0.2207 s / batch. (data: 6.25e-05)max mem: 7.80931 GB 
[09/28 03:12:24 visual_prompt]: 	Test 200/340. loss: 3.011, 0.2200 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 03:12:46 visual_prompt]: 	Test 300/340. loss: 2.749, 0.2196 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 03:12:56 visual_prompt]: Inference (test):avg data time: 3.29e-05, avg batch time: 0.2197, average loss: 2.8095
[09/28 03:12:56 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.29	top5: 75.80	
[09/28 03:12:56 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/28 03:13:06 visual_prompt]: Epoch 85 / 100: avg data time: 9.54e-02, avg batch time: 0.5539, average train loss: 0.1100
[09/28 03:13:09 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1701, average loss: 0.0912
[09/28 03:13:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:13:33 visual_prompt]: 	Test 100/340. loss: 2.455, 0.2200 s / batch. (data: 4.15e-05)max mem: 7.80931 GB 
[09/28 03:13:55 visual_prompt]: 	Test 200/340. loss: 3.019, 0.2198 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 03:14:17 visual_prompt]: 	Test 300/340. loss: 2.775, 0.2196 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 03:14:27 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2196, average loss: 2.8069
[09/28 03:14:27 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.34	top5: 75.89	
[09/28 03:14:27 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/28 03:14:37 visual_prompt]: Epoch 86 / 100: avg data time: 9.79e-02, avg batch time: 0.5566, average train loss: 0.1054
[09/28 03:14:40 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1700, average loss: 0.0899
[09/28 03:14:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:15:04 visual_prompt]: 	Test 100/340. loss: 2.462, 0.2195 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 03:15:26 visual_prompt]: 	Test 200/340. loss: 3.029, 0.2192 s / batch. (data: 3.03e-05)max mem: 7.80931 GB 
[09/28 03:15:48 visual_prompt]: 	Test 300/340. loss: 2.747, 0.2197 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 03:15:58 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2197, average loss: 2.8021
[09/28 03:15:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.32	top5: 75.91	
[09/28 03:15:58 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/28 03:16:08 visual_prompt]: Epoch 87 / 100: avg data time: 9.81e-02, avg batch time: 0.5573, average train loss: 0.1038
[09/28 03:16:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1704, average loss: 0.0879
[09/28 03:16:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:16:35 visual_prompt]: 	Test 100/340. loss: 2.464, 0.2199 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 03:16:57 visual_prompt]: 	Test 200/340. loss: 3.028, 0.2202 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 03:17:19 visual_prompt]: 	Test 300/340. loss: 2.775, 0.2205 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 03:17:29 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2196, average loss: 2.8127
[09/28 03:17:30 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.19	top5: 75.83	
[09/28 03:17:30 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/28 03:17:39 visual_prompt]: Epoch 88 / 100: avg data time: 8.38e-02, avg batch time: 0.5451, average train loss: 0.1027
[09/28 03:17:42 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1702, average loss: 0.0875
[09/28 03:17:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:18:06 visual_prompt]: 	Test 100/340. loss: 2.461, 0.2194 s / batch. (data: 3.03e-05)max mem: 7.80931 GB 
[09/28 03:18:28 visual_prompt]: 	Test 200/340. loss: 3.024, 0.2196 s / batch. (data: 8.63e-05)max mem: 7.80931 GB 
[09/28 03:18:50 visual_prompt]: 	Test 300/340. loss: 2.767, 0.2200 s / batch. (data: 2.67e-05)max mem: 7.80931 GB 
[09/28 03:19:00 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2197, average loss: 2.8151
[09/28 03:19:00 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.29	top5: 75.82	
[09/28 03:19:00 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/28 03:19:10 visual_prompt]: Epoch 89 / 100: avg data time: 9.72e-02, avg batch time: 0.5562, average train loss: 0.1019
[09/28 03:19:13 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1701, average loss: 0.0869
[09/28 03:19:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:19:37 visual_prompt]: 	Test 100/340. loss: 2.454, 0.2195 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 03:19:59 visual_prompt]: 	Test 200/340. loss: 3.021, 0.2200 s / batch. (data: 2.93e-05)max mem: 7.80931 GB 
[09/28 03:20:21 visual_prompt]: 	Test 300/340. loss: 2.779, 0.2203 s / batch. (data: 8.46e-05)max mem: 7.80931 GB 
[09/28 03:20:31 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2197, average loss: 2.8195
[09/28 03:20:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.12	top5: 75.78	
[09/28 03:20:31 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/28 03:20:41 visual_prompt]: Epoch 90 / 100: avg data time: 9.31e-02, avg batch time: 0.5527, average train loss: 0.1010
[09/28 03:20:44 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1701, average loss: 0.0869
[09/28 03:20:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:21:08 visual_prompt]: 	Test 100/340. loss: 2.469, 0.2199 s / batch. (data: 2.50e-05)max mem: 7.80931 GB 
[09/28 03:21:30 visual_prompt]: 	Test 200/340. loss: 3.023, 0.2198 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:21:52 visual_prompt]: 	Test 300/340. loss: 2.778, 0.2200 s / batch. (data: 2.69e-05)max mem: 7.80931 GB 
[09/28 03:22:02 visual_prompt]: Inference (test):avg data time: 3.14e-05, avg batch time: 0.2197, average loss: 2.8271
[09/28 03:22:02 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.11	top5: 75.80	
[09/28 03:22:02 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/28 03:22:12 visual_prompt]: Epoch 91 / 100: avg data time: 9.87e-02, avg batch time: 0.5584, average train loss: 0.1008
[09/28 03:22:15 visual_prompt]: Inference (val):avg data time: 1.62e-05, avg batch time: 0.1698, average loss: 0.0878
[09/28 03:22:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:22:39 visual_prompt]: 	Test 100/340. loss: 2.465, 0.2190 s / batch. (data: 2.46e-05)max mem: 7.80931 GB 
[09/28 03:23:01 visual_prompt]: 	Test 200/340. loss: 3.020, 0.2193 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 03:23:23 visual_prompt]: 	Test 300/340. loss: 2.772, 0.2199 s / batch. (data: 2.77e-05)max mem: 7.80931 GB 
[09/28 03:23:33 visual_prompt]: Inference (test):avg data time: 3.01e-05, avg batch time: 0.2197, average loss: 2.8225
[09/28 03:23:33 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.34	top5: 75.77	
[09/28 03:23:33 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/28 03:23:43 visual_prompt]: Epoch 92 / 100: avg data time: 9.10e-02, avg batch time: 0.5511, average train loss: 0.1002
[09/28 03:23:46 visual_prompt]: Inference (val):avg data time: 1.48e-05, avg batch time: 0.1700, average loss: 0.0877
[09/28 03:23:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:24:10 visual_prompt]: 	Test 100/340. loss: 2.468, 0.2196 s / batch. (data: 2.79e-05)max mem: 7.80931 GB 
[09/28 03:24:32 visual_prompt]: 	Test 200/340. loss: 3.021, 0.2201 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 03:24:54 visual_prompt]: 	Test 300/340. loss: 2.778, 0.2219 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 03:25:09 visual_prompt]: Inference (test):avg data time: 3.97e-05, avg batch time: 0.2201, average loss: 2.8263
[09/28 03:25:09 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.30	top5: 75.84	
[09/28 03:25:09 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/28 03:25:19 visual_prompt]: Epoch 93 / 100: avg data time: 1.10e-01, avg batch time: 0.5691, average train loss: 0.0997
[09/28 03:25:23 visual_prompt]: Inference (val):avg data time: 1.60e-05, avg batch time: 0.1696, average loss: 0.0862
[09/28 03:25:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:25:52 visual_prompt]: 	Test 100/340. loss: 2.476, 0.2179 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 03:26:14 visual_prompt]: 	Test 200/340. loss: 3.030, 0.2199 s / batch. (data: 7.99e-05)max mem: 7.80931 GB 
[09/28 03:26:36 visual_prompt]: 	Test 300/340. loss: 2.769, 0.2196 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 03:26:46 visual_prompt]: Inference (test):avg data time: 1.71e-04, avg batch time: 0.2197, average loss: 2.8284
[09/28 03:26:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.22	top5: 75.84	
[09/28 03:26:47 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/28 03:26:57 visual_prompt]: Epoch 94 / 100: avg data time: 9.10e-02, avg batch time: 0.5487, average train loss: 0.0992
[09/28 03:26:59 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1699, average loss: 0.0860
[09/28 03:26:59 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:27:23 visual_prompt]: 	Test 100/340. loss: 2.472, 0.2198 s / batch. (data: 2.91e-05)max mem: 7.80931 GB 
[09/28 03:27:45 visual_prompt]: 	Test 200/340. loss: 3.030, 0.2192 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 03:28:07 visual_prompt]: 	Test 300/340. loss: 2.777, 0.2200 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:28:17 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2194, average loss: 2.8309
[09/28 03:28:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.17	top5: 75.79	
[09/28 03:28:21 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/28 03:28:30 visual_prompt]: Epoch 95 / 100: avg data time: 8.27e-02, avg batch time: 0.5412, average train loss: 0.0992
[09/28 03:28:33 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.1698, average loss: 0.0867
[09/28 03:28:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:28:56 visual_prompt]: 	Test 100/340. loss: 2.472, 0.2200 s / batch. (data: 2.36e-05)max mem: 7.80931 GB 
[09/28 03:29:18 visual_prompt]: 	Test 200/340. loss: 3.029, 0.2193 s / batch. (data: 9.42e-05)max mem: 7.80931 GB 
[09/28 03:29:40 visual_prompt]: 	Test 300/340. loss: 2.777, 0.2203 s / batch. (data: 2.60e-05)max mem: 7.80931 GB 
[09/28 03:29:50 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2195, average loss: 2.8280
[09/28 03:29:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.24	top5: 75.79	
[09/28 03:29:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/28 03:30:03 visual_prompt]: Epoch 96 / 100: avg data time: 9.53e-02, avg batch time: 0.5526, average train loss: 0.0987
[09/28 03:30:05 visual_prompt]: Inference (val):avg data time: 1.80e-05, avg batch time: 0.1696, average loss: 0.0865
[09/28 03:30:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:30:29 visual_prompt]: 	Test 100/340. loss: 2.478, 0.2185 s / batch. (data: 2.74e-05)max mem: 7.80931 GB 
[09/28 03:30:51 visual_prompt]: 	Test 200/340. loss: 3.032, 0.2196 s / batch. (data: 3.03e-05)max mem: 7.80931 GB 
[09/28 03:31:13 visual_prompt]: 	Test 300/340. loss: 2.784, 0.2193 s / batch. (data: 2.62e-05)max mem: 7.80931 GB 
[09/28 03:31:23 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2195, average loss: 2.8304
[09/28 03:31:24 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.25	top5: 75.74	
[09/28 03:31:24 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/28 03:31:33 visual_prompt]: Epoch 97 / 100: avg data time: 8.17e-02, avg batch time: 0.5417, average train loss: 0.0985
[09/28 03:31:36 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1703, average loss: 0.0863
[09/28 03:31:36 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:31:59 visual_prompt]: 	Test 100/340. loss: 2.476, 0.2188 s / batch. (data: 3.50e-05)max mem: 7.80931 GB 
[09/28 03:32:21 visual_prompt]: 	Test 200/340. loss: 3.035, 0.2196 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 03:32:43 visual_prompt]: 	Test 300/340. loss: 2.787, 0.2197 s / batch. (data: 2.65e-05)max mem: 7.80931 GB 
[09/28 03:32:53 visual_prompt]: Inference (test):avg data time: 3.43e-05, avg batch time: 0.2195, average loss: 2.8320
[09/28 03:32:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.23	top5: 75.78	
[09/28 03:32:54 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/28 03:33:04 visual_prompt]: Epoch 98 / 100: avg data time: 8.92e-02, avg batch time: 0.5479, average train loss: 0.0985
[09/28 03:33:07 visual_prompt]: Inference (val):avg data time: 1.83e-05, avg batch time: 0.1703, average loss: 0.0865
[09/28 03:33:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:33:30 visual_prompt]: 	Test 100/340. loss: 2.475, 0.2205 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 03:33:52 visual_prompt]: 	Test 200/340. loss: 3.034, 0.2205 s / batch. (data: 2.72e-05)max mem: 7.80931 GB 
[09/28 03:34:14 visual_prompt]: 	Test 300/340. loss: 2.786, 0.2200 s / batch. (data: 2.86e-05)max mem: 7.80931 GB 
[09/28 03:34:24 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2197, average loss: 2.8306
[09/28 03:34:24 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.20	top5: 75.79	
[09/28 03:34:24 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/28 03:34:34 visual_prompt]: Epoch 99 / 100: avg data time: 9.60e-02, avg batch time: 0.5541, average train loss: 0.0984
[09/28 03:34:37 visual_prompt]: Inference (val):avg data time: 1.87e-05, avg batch time: 0.1707, average loss: 0.0867
[09/28 03:34:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:35:00 visual_prompt]: 	Test 100/340. loss: 2.474, 0.2194 s / batch. (data: 6.58e-05)max mem: 7.80931 GB 
[09/28 03:35:22 visual_prompt]: 	Test 200/340. loss: 3.032, 0.2193 s / batch. (data: 2.84e-05)max mem: 7.80931 GB 
[09/28 03:35:45 visual_prompt]: 	Test 300/340. loss: 2.784, 0.2208 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 03:35:55 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2196, average loss: 2.8299
[09/28 03:35:55 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.24	top5: 75.80	
[09/28 03:35:55 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/28 03:36:05 visual_prompt]: Epoch 100 / 100: avg data time: 9.34e-02, avg batch time: 0.5527, average train loss: 0.0985
[09/28 03:36:08 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1707, average loss: 0.0866
[09/28 03:36:08 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 03:36:31 visual_prompt]: 	Test 100/340. loss: 2.474, 0.2202 s / batch. (data: 2.81e-05)max mem: 7.80931 GB 
[09/28 03:36:53 visual_prompt]: 	Test 200/340. loss: 3.032, 0.2200 s / batch. (data: 2.88e-05)max mem: 7.80931 GB 
[09/28 03:37:15 visual_prompt]: 	Test 300/340. loss: 2.784, 0.2192 s / batch. (data: 2.43e-05)max mem: 7.80931 GB 
[09/28 03:37:25 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2197, average loss: 2.8302
[09/28 03:37:26 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.23	top5: 75.79	
[09/28 03:37:27 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 03:37:27 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 03:37:27 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 03:37:27 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 03:37:27 visual_prompt]: Training with config:
[09/28 03:37:27 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/test/seed5755/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 5755, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 03:37:27 visual_prompt]: Loading training data...
[09/28 03:37:27 visual_prompt]: Constructing vtab-sun397 dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 03:37:34 visual_prompt]: Number of images: 1000
[09/28 03:37:34 visual_prompt]: Number of classes: 325 / 397
[09/28 03:37:34 visual_prompt]: Loading validation data...
[09/28 03:37:34 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 03:37:34 visual_prompt]: Number of images: 200
[09/28 03:37:34 visual_prompt]: Number of classes: 136 / 397
[09/28 03:37:34 visual_prompt]: Loading test data...
[09/28 03:37:34 visual_prompt]: Constructing vtab-sun397 dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split test, from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 03:38:32 visual_prompt]: Number of images: 21750
[09/28 03:38:32 visual_prompt]: Number of classes: 397 / 397
[09/28 03:38:33 visual_prompt]: Constructing models...
[09/28 03:38:35 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/28 03:38:35 visual_prompt]: tuned percent:0.885
[09/28 03:38:35 visual_prompt]: Device used for model: 0
[09/28 03:38:35 visual_prompt]: Setting up Evaluator...
[09/28 03:38:35 visual_prompt]: Setting up Trainer...
[09/28 03:38:35 visual_prompt]: 	Setting up the optimizer...
[09/28 03:38:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 03:38:45 visual_prompt]: Epoch 1 / 100: avg data time: 9.45e-02, avg batch time: 0.5425, average train loss: 5.9936
[09/28 03:38:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1666, average loss: 5.9919
[09/28 03:38:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 0.50	
[09/28 03:39:11 visual_prompt]: 	Test 100/340. loss: 6.026, 0.2147 s / batch. (data: 3.08e-05)max mem: 7.82315 GB 
[09/28 03:39:33 visual_prompt]: 	Test 200/340. loss: 5.963, 0.2167 s / batch. (data: 2.67e-05)max mem: 7.82315 GB 
[09/28 03:39:55 visual_prompt]: 	Test 300/340. loss: 5.974, 0.2171 s / batch. (data: 2.98e-05)max mem: 7.82315 GB 
[09/28 03:40:05 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2169, average loss: 5.9975
[09/28 03:40:09 visual_prompt]: Classification results with test_vtab-sun397: top1: 0.10	top5: 0.89	
[09/28 03:40:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/28 03:40:19 visual_prompt]: Epoch 2 / 100: avg data time: 9.98e-02, avg batch time: 0.5542, average train loss: 5.8080
[09/28 03:40:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1691, average loss: 5.6029
[09/28 03:40:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 4.50	
[09/28 03:40:45 visual_prompt]: 	Test 100/340. loss: 5.725, 0.2175 s / batch. (data: 7.27e-05)max mem: 7.82369 GB 
[09/28 03:41:07 visual_prompt]: 	Test 200/340. loss: 5.788, 0.2196 s / batch. (data: 2.38e-05)max mem: 7.82369 GB 
[09/28 03:41:29 visual_prompt]: 	Test 300/340. loss: 5.763, 0.2196 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 03:41:39 visual_prompt]: Inference (test):avg data time: 3.37e-05, avg batch time: 0.2187, average loss: 5.7818
[09/28 03:41:40 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.02	top5: 7.67	
[09/28 03:41:40 visual_prompt]: Best epoch 2: best metric: 0.005
[09/28 03:41:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/28 03:41:50 visual_prompt]: Epoch 3 / 100: avg data time: 1.01e-01, avg batch time: 0.5586, average train loss: 5.6079
[09/28 03:41:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1697, average loss: 5.4472
[09/28 03:41:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 9.00	
[09/28 03:42:17 visual_prompt]: 	Test 100/340. loss: 5.615, 0.2187 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 03:42:39 visual_prompt]: 	Test 200/340. loss: 5.734, 0.2197 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 03:43:01 visual_prompt]: 	Test 300/340. loss: 5.765, 0.2194 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 03:43:11 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2193, average loss: 5.7294
[09/28 03:43:11 visual_prompt]: Classification results with test_vtab-sun397: top1: 3.15	top5: 10.68	
[09/28 03:43:11 visual_prompt]: Best epoch 3: best metric: 0.040
[09/28 03:43:11 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/28 03:43:21 visual_prompt]: Epoch 4 / 100: avg data time: 9.94e-02, avg batch time: 0.5571, average train loss: 5.5911
[09/28 03:43:25 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1696, average loss: 5.4324
[09/28 03:43:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.00	
[09/28 03:43:48 visual_prompt]: 	Test 100/340. loss: 5.788, 0.2196 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 03:44:10 visual_prompt]: 	Test 200/340. loss: 6.009, 0.2194 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 03:44:32 visual_prompt]: 	Test 300/340. loss: 5.927, 0.2190 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 03:44:42 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2195, average loss: 5.8867
[09/28 03:44:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 1.05	top5: 5.01	
[09/28 03:44:43 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/28 03:44:53 visual_prompt]: Epoch 5 / 100: avg data time: 9.86e-02, avg batch time: 0.5580, average train loss: 5.5676
[09/28 03:44:56 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1698, average loss: 5.1444
[09/28 03:44:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 4.00	top5: 12.00	
[09/28 03:45:20 visual_prompt]: 	Test 100/340. loss: 5.588, 0.2198 s / batch. (data: 7.15e-05)max mem: 7.82369 GB 
[09/28 03:45:42 visual_prompt]: 	Test 200/340. loss: 5.569, 0.2186 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 03:46:04 visual_prompt]: 	Test 300/340. loss: 5.674, 0.2194 s / batch. (data: 1.07e-04)max mem: 7.82369 GB 
[09/28 03:46:14 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2195, average loss: 5.6175
[09/28 03:46:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.92	top5: 8.44	
[09/28 03:46:16 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/28 03:46:26 visual_prompt]: Epoch 6 / 100: avg data time: 9.48e-02, avg batch time: 0.5551, average train loss: 5.1730
[09/28 03:46:29 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1699, average loss: 4.6967
[09/28 03:46:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 5.00	top5: 18.50	
[09/28 03:46:53 visual_prompt]: 	Test 100/340. loss: 5.234, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 03:47:15 visual_prompt]: 	Test 200/340. loss: 5.576, 0.2193 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 03:47:37 visual_prompt]: 	Test 300/340. loss: 5.479, 0.2195 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 03:47:47 visual_prompt]: Inference (test):avg data time: 3.40e-05, avg batch time: 0.2195, average loss: 5.4254
[09/28 03:47:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 3.29	top5: 12.69	
[09/28 03:47:49 visual_prompt]: Best epoch 6: best metric: 0.050
[09/28 03:47:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/28 03:47:59 visual_prompt]: Epoch 7 / 100: avg data time: 9.74e-02, avg batch time: 0.5553, average train loss: 4.6754
[09/28 03:48:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1707, average loss: 3.6632
[09/28 03:48:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 24.50	top5: 50.50	
[09/28 03:48:26 visual_prompt]: 	Test 100/340. loss: 4.895, 0.2202 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 03:48:48 visual_prompt]: 	Test 200/340. loss: 4.916, 0.2197 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 03:49:10 visual_prompt]: 	Test 300/340. loss: 4.805, 0.2193 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 03:49:20 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2194, average loss: 4.8436
[09/28 03:49:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 12.24	top5: 28.05	
[09/28 03:49:21 visual_prompt]: Best epoch 7: best metric: 0.245
[09/28 03:49:21 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/28 03:49:31 visual_prompt]: Epoch 8 / 100: avg data time: 9.91e-02, avg batch time: 0.5577, average train loss: 3.1184
[09/28 03:49:34 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1700, average loss: 1.7179
[09/28 03:49:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 61.00	top5: 90.50	
[09/28 03:49:58 visual_prompt]: 	Test 100/340. loss: 3.717, 0.2195 s / batch. (data: 3.27e-05)max mem: 7.82369 GB 
[09/28 03:50:20 visual_prompt]: 	Test 200/340. loss: 4.368, 0.2197 s / batch. (data: 4.91e-05)max mem: 7.82369 GB 
[09/28 03:50:42 visual_prompt]: 	Test 300/340. loss: 4.135, 0.2198 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 03:50:52 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2194, average loss: 3.9695
[09/28 03:50:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 25.54	top5: 48.47	
[09/28 03:50:53 visual_prompt]: Best epoch 8: best metric: 0.610
[09/28 03:50:53 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/28 03:51:03 visual_prompt]: Epoch 9 / 100: avg data time: 1.04e-01, avg batch time: 0.5622, average train loss: 1.6560
[09/28 03:51:06 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1699, average loss: 0.6084
[09/28 03:51:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 90.50	top5: 99.50	
[09/28 03:51:30 visual_prompt]: 	Test 100/340. loss: 3.270, 0.2198 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 03:51:52 visual_prompt]: 	Test 200/340. loss: 3.784, 0.2245 s / batch. (data: 4.29e-05)max mem: 7.82369 GB 
[09/28 03:52:14 visual_prompt]: 	Test 300/340. loss: 3.383, 0.2206 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 03:52:24 visual_prompt]: Inference (test):avg data time: 1.17e-04, avg batch time: 0.2195, average loss: 3.2831
[09/28 03:52:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 36.90	top5: 61.52	
[09/28 03:52:25 visual_prompt]: Best epoch 9: best metric: 0.905
[09/28 03:52:25 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/28 03:52:35 visual_prompt]: Epoch 10 / 100: avg data time: 1.05e-01, avg batch time: 0.5628, average train loss: 0.5649
[09/28 03:52:38 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1698, average loss: 0.1742
[09/28 03:52:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 03:53:02 visual_prompt]: 	Test 100/340. loss: 2.840, 0.2202 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 03:53:24 visual_prompt]: 	Test 200/340. loss: 3.516, 0.2199 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 03:53:46 visual_prompt]: 	Test 300/340. loss: 3.134, 0.2197 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 03:53:56 visual_prompt]: Inference (test):avg data time: 6.11e-05, avg batch time: 0.2195, average loss: 3.0306
[09/28 03:53:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.26	top5: 68.38	
[09/28 03:53:58 visual_prompt]: Best epoch 10: best metric: 0.990
[09/28 03:53:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/28 03:54:08 visual_prompt]: Epoch 11 / 100: avg data time: 9.32e-02, avg batch time: 0.5510, average train loss: 0.3600
[09/28 03:54:11 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.1696, average loss: 0.1984
[09/28 03:54:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.00	top5: 100.00	
[09/28 03:54:34 visual_prompt]: 	Test 100/340. loss: 2.965, 0.2199 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 03:54:56 visual_prompt]: 	Test 200/340. loss: 3.328, 0.2192 s / batch. (data: 2.38e-05)max mem: 7.82369 GB 
[09/28 03:55:18 visual_prompt]: 	Test 300/340. loss: 3.139, 0.2196 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 03:55:28 visual_prompt]: Inference (test):avg data time: 5.11e-05, avg batch time: 0.2194, average loss: 2.9991
[09/28 03:55:29 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.31	top5: 68.71	
[09/28 03:55:29 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/28 03:55:39 visual_prompt]: Epoch 12 / 100: avg data time: 9.22e-02, avg batch time: 0.5507, average train loss: 0.3834
[09/28 03:55:42 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1711, average loss: 0.1861
[09/28 03:55:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 03:56:06 visual_prompt]: 	Test 100/340. loss: 2.919, 0.2196 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 03:56:28 visual_prompt]: 	Test 200/340. loss: 3.429, 0.2192 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 03:56:50 visual_prompt]: 	Test 300/340. loss: 2.922, 0.2193 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 03:57:00 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2194, average loss: 2.9992
[09/28 03:57:01 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.27	top5: 69.74	
[09/28 03:57:01 visual_prompt]: Best epoch 12: best metric: 0.995
[09/28 03:57:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/28 03:57:11 visual_prompt]: Epoch 13 / 100: avg data time: 1.01e-01, avg batch time: 0.5600, average train loss: 0.3823
[09/28 03:57:14 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1701, average loss: 1.7164
[09/28 03:57:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 74.00	top5: 92.00	
[09/28 03:57:38 visual_prompt]: 	Test 100/340. loss: 3.708, 0.2199 s / batch. (data: 3.03e-05)max mem: 7.82369 GB 
[09/28 03:58:00 visual_prompt]: 	Test 200/340. loss: 3.977, 0.2193 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 03:58:21 visual_prompt]: 	Test 300/340. loss: 3.728, 0.2200 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 03:58:32 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2195, average loss: 3.8917
[09/28 03:58:32 visual_prompt]: Classification results with test_vtab-sun397: top1: 28.59	top5: 51.24	
[09/28 03:58:32 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/28 03:58:42 visual_prompt]: Epoch 14 / 100: avg data time: 1.03e-01, avg batch time: 0.5610, average train loss: 1.1651
[09/28 03:58:46 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1697, average loss: 0.4128
[09/28 03:58:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 94.50	top5: 100.00	
[09/28 03:59:09 visual_prompt]: 	Test 100/340. loss: 2.970, 0.2195 s / batch. (data: 3.77e-05)max mem: 7.82369 GB 
[09/28 03:59:31 visual_prompt]: 	Test 200/340. loss: 3.532, 0.2190 s / batch. (data: 7.22e-05)max mem: 7.82369 GB 
[09/28 03:59:53 visual_prompt]: 	Test 300/340. loss: 3.164, 0.2199 s / batch. (data: 7.72e-05)max mem: 7.82369 GB 
[09/28 04:00:03 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2196, average loss: 3.1814
[09/28 04:00:06 visual_prompt]: Classification results with test_vtab-sun397: top1: 39.52	top5: 65.04	
[09/28 04:00:06 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/28 04:00:16 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e-01, avg batch time: 0.5626, average train loss: 0.4498
[09/28 04:00:20 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1696, average loss: 0.1422
[09/28 04:00:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.00	top5: 100.00	
[09/28 04:00:43 visual_prompt]: 	Test 100/340. loss: 2.701, 0.2196 s / batch. (data: 3.34e-05)max mem: 7.82369 GB 
[09/28 04:01:05 visual_prompt]: 	Test 200/340. loss: 3.130, 0.2199 s / batch. (data: 3.03e-05)max mem: 7.82369 GB 
[09/28 04:01:27 visual_prompt]: 	Test 300/340. loss: 2.860, 0.2199 s / batch. (data: 3.24e-05)max mem: 7.82369 GB 
[09/28 04:01:37 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2194, average loss: 2.8787
[09/28 04:01:38 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.56	top5: 70.58	
[09/28 04:01:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/28 04:01:48 visual_prompt]: Epoch 16 / 100: avg data time: 9.46e-02, avg batch time: 0.5527, average train loss: 0.3024
[09/28 04:01:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1701, average loss: 0.1966
[09/28 04:01:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 04:02:15 visual_prompt]: 	Test 100/340. loss: 2.714, 0.2199 s / batch. (data: 3.03e-05)max mem: 7.82369 GB 
[09/28 04:02:37 visual_prompt]: 	Test 200/340. loss: 3.118, 0.2197 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 04:02:59 visual_prompt]: 	Test 300/340. loss: 2.858, 0.2198 s / batch. (data: 3.34e-05)max mem: 7.82369 GB 
[09/28 04:03:09 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2196, average loss: 2.8901
[09/28 04:03:10 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.93	top5: 70.85	
[09/28 04:03:10 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/28 04:03:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.02e-01, avg batch time: 0.5604, average train loss: 0.3098
[09/28 04:03:23 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.1698, average loss: 0.2149
[09/28 04:03:23 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 04:03:47 visual_prompt]: 	Test 100/340. loss: 2.474, 0.2195 s / batch. (data: 4.89e-05)max mem: 7.82369 GB 
[09/28 04:04:09 visual_prompt]: 	Test 200/340. loss: 3.258, 0.2209 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 04:04:31 visual_prompt]: 	Test 300/340. loss: 2.962, 0.2194 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 04:04:41 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2194, average loss: 2.8902
[09/28 04:04:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.02	top5: 71.46	
[09/28 04:04:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/28 04:04:54 visual_prompt]: Epoch 18 / 100: avg data time: 1.04e-01, avg batch time: 0.5612, average train loss: 0.3307
[09/28 04:04:57 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1698, average loss: 0.8637
[09/28 04:04:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:05:20 visual_prompt]: 	Test 100/340. loss: 3.113, 0.2189 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 04:05:42 visual_prompt]: 	Test 200/340. loss: 3.588, 0.2198 s / batch. (data: 2.48e-05)max mem: 7.82369 GB 
[09/28 04:06:04 visual_prompt]: 	Test 300/340. loss: 3.135, 0.2193 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 04:06:15 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2194, average loss: 3.3095
[09/28 04:06:15 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.94	top5: 69.42	
[09/28 04:06:15 visual_prompt]: Best epoch 18: best metric: 1.000
[09/28 04:06:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/28 04:06:25 visual_prompt]: Epoch 19 / 100: avg data time: 1.01e-01, avg batch time: 0.5594, average train loss: 3.5335
[09/28 04:06:28 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1699, average loss: 2.5060
[09/28 04:06:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 44.50	top5: 76.00	
[09/28 04:06:52 visual_prompt]: 	Test 100/340. loss: 4.749, 0.2201 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:07:14 visual_prompt]: 	Test 200/340. loss: 4.637, 0.2196 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 04:07:36 visual_prompt]: 	Test 300/340. loss: 4.836, 0.2185 s / batch. (data: 3.10e-05)max mem: 7.82369 GB 
[09/28 04:07:46 visual_prompt]: Inference (test):avg data time: 4.13e-05, avg batch time: 0.2195, average loss: 4.5686
[09/28 04:07:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 17.95	top5: 40.44	
[09/28 04:07:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/28 04:07:57 visual_prompt]: Epoch 20 / 100: avg data time: 9.66e-02, avg batch time: 0.5554, average train loss: 1.1524
[09/28 04:08:00 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1695, average loss: 0.4445
[09/28 04:08:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 93.50	top5: 99.50	
[09/28 04:08:24 visual_prompt]: 	Test 100/340. loss: 2.934, 0.2198 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:08:46 visual_prompt]: 	Test 200/340. loss: 3.455, 0.2197 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 04:09:08 visual_prompt]: 	Test 300/340. loss: 3.274, 0.2201 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 04:09:18 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2195, average loss: 3.3379
[09/28 04:09:19 visual_prompt]: Classification results with test_vtab-sun397: top1: 37.17	top5: 62.08	
[09/28 04:09:19 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/28 04:09:29 visual_prompt]: Epoch 21 / 100: avg data time: 9.84e-02, avg batch time: 0.5564, average train loss: 0.4224
[09/28 04:09:32 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1701, average loss: 0.1644
[09/28 04:09:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.00	top5: 100.00	
[09/28 04:09:55 visual_prompt]: 	Test 100/340. loss: 2.732, 0.2197 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:10:17 visual_prompt]: 	Test 200/340. loss: 3.148, 0.2193 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 04:10:39 visual_prompt]: 	Test 300/340. loss: 3.183, 0.2190 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:10:50 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2195, average loss: 3.0335
[09/28 04:10:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.88	top5: 68.67	
[09/28 04:10:53 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/28 04:11:03 visual_prompt]: Epoch 22 / 100: avg data time: 9.83e-02, avg batch time: 0.5561, average train loss: 0.5347
[09/28 04:11:06 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1692, average loss: 0.1903
[09/28 04:11:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:11:29 visual_prompt]: 	Test 100/340. loss: 2.739, 0.2186 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 04:11:51 visual_prompt]: 	Test 200/340. loss: 3.103, 0.2192 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:12:13 visual_prompt]: 	Test 300/340. loss: 2.890, 0.2200 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:12:24 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2192, average loss: 2.9574
[09/28 04:12:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.51	top5: 70.43	
[09/28 04:12:25 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/28 04:12:35 visual_prompt]: Epoch 23 / 100: avg data time: 1.04e-01, avg batch time: 0.5616, average train loss: 0.2897
[09/28 04:12:38 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1698, average loss: 0.1596
[09/28 04:12:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:13:02 visual_prompt]: 	Test 100/340. loss: 2.642, 0.2195 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:13:24 visual_prompt]: 	Test 200/340. loss: 3.083, 0.2203 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 04:13:46 visual_prompt]: 	Test 300/340. loss: 2.933, 0.2190 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 04:13:56 visual_prompt]: Inference (test):avg data time: 4.62e-05, avg batch time: 0.2195, average loss: 2.9306
[09/28 04:13:56 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.20	top5: 71.89	
[09/28 04:13:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/28 04:14:07 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e-01, avg batch time: 0.5644, average train loss: 0.3137
[09/28 04:14:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1697, average loss: 0.1652
[09/28 04:14:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:14:33 visual_prompt]: 	Test 100/340. loss: 2.544, 0.2202 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 04:14:55 visual_prompt]: 	Test 200/340. loss: 3.232, 0.2190 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:15:17 visual_prompt]: 	Test 300/340. loss: 2.911, 0.2200 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:15:28 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2197, average loss: 2.9284
[09/28 04:15:30 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.30	top5: 71.51	
[09/28 04:15:30 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/28 04:15:40 visual_prompt]: Epoch 25 / 100: avg data time: 1.04e-01, avg batch time: 0.5616, average train loss: 0.3414
[09/28 04:15:44 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1702, average loss: 0.3795
[09/28 04:15:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 04:16:07 visual_prompt]: 	Test 100/340. loss: 2.764, 0.2201 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 04:16:29 visual_prompt]: 	Test 200/340. loss: 3.138, 0.2199 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 04:16:51 visual_prompt]: 	Test 300/340. loss: 3.095, 0.2199 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:17:01 visual_prompt]: Inference (test):avg data time: 5.94e-05, avg batch time: 0.2194, average loss: 3.0262
[09/28 04:17:03 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.71	top5: 70.39	
[09/28 04:17:03 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/28 04:17:13 visual_prompt]: Epoch 26 / 100: avg data time: 1.00e-01, avg batch time: 0.5587, average train loss: 2.0619
[09/28 04:17:16 visual_prompt]: Inference (val):avg data time: 4.73e-05, avg batch time: 0.1712, average loss: 0.7887
[09/28 04:17:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 90.00	top5: 99.50	
[09/28 04:17:40 visual_prompt]: 	Test 100/340. loss: 3.077, 0.2201 s / batch. (data: 7.20e-05)max mem: 7.82369 GB 
[09/28 04:18:02 visual_prompt]: 	Test 200/340. loss: 3.550, 0.2192 s / batch. (data: 4.98e-05)max mem: 7.82369 GB 
[09/28 04:18:24 visual_prompt]: 	Test 300/340. loss: 3.432, 0.2201 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:18:34 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2193, average loss: 3.3068
[09/28 04:18:35 visual_prompt]: Classification results with test_vtab-sun397: top1: 39.44	top5: 63.57	
[09/28 04:18:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/28 04:18:45 visual_prompt]: Epoch 27 / 100: avg data time: 1.00e-01, avg batch time: 0.5584, average train loss: 1.4081
[09/28 04:18:48 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1699, average loss: 0.2901
[09/28 04:18:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 96.00	top5: 100.00	
[09/28 04:19:12 visual_prompt]: 	Test 100/340. loss: 2.756, 0.2197 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 04:19:33 visual_prompt]: 	Test 200/340. loss: 3.493, 0.2194 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 04:19:55 visual_prompt]: 	Test 300/340. loss: 3.132, 0.2203 s / batch. (data: 2.64e-04)max mem: 7.82369 GB 
[09/28 04:20:06 visual_prompt]: Inference (test):avg data time: 7.44e-05, avg batch time: 0.2196, average loss: 3.0807
[09/28 04:20:06 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.46	top5: 66.68	
[09/28 04:20:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/28 04:20:16 visual_prompt]: Epoch 28 / 100: avg data time: 8.92e-02, avg batch time: 0.5489, average train loss: 0.3644
[09/28 04:20:19 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.1699, average loss: 0.1611
[09/28 04:20:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 04:20:43 visual_prompt]: 	Test 100/340. loss: 2.751, 0.2204 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:21:05 visual_prompt]: 	Test 200/340. loss: 3.050, 0.2192 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 04:21:27 visual_prompt]: 	Test 300/340. loss: 2.988, 0.2192 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:21:37 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2195, average loss: 2.9661
[09/28 04:21:40 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.31	top5: 69.88	
[09/28 04:21:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/28 04:21:50 visual_prompt]: Epoch 29 / 100: avg data time: 9.19e-02, avg batch time: 0.5505, average train loss: 0.3259
[09/28 04:21:53 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1698, average loss: 0.2267
[09/28 04:21:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 04:22:16 visual_prompt]: 	Test 100/340. loss: 2.709, 0.2206 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:22:38 visual_prompt]: 	Test 200/340. loss: 3.108, 0.2199 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 04:23:00 visual_prompt]: 	Test 300/340. loss: 3.098, 0.2204 s / batch. (data: 9.04e-05)max mem: 7.82369 GB 
[09/28 04:23:11 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2193, average loss: 2.9909
[09/28 04:23:12 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.24	top5: 70.27	
[09/28 04:23:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/28 04:23:22 visual_prompt]: Epoch 30 / 100: avg data time: 8.99e-02, avg batch time: 0.5489, average train loss: 0.4197
[09/28 04:23:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1697, average loss: 0.4768
[09/28 04:23:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.00	top5: 100.00	
[09/28 04:23:49 visual_prompt]: 	Test 100/340. loss: 2.967, 0.2198 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:24:11 visual_prompt]: 	Test 200/340. loss: 3.521, 0.2202 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:24:33 visual_prompt]: 	Test 300/340. loss: 3.046, 0.2188 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:24:43 visual_prompt]: Inference (test):avg data time: 3.11e-05, avg batch time: 0.2194, average loss: 3.1910
[09/28 04:24:44 visual_prompt]: Classification results with test_vtab-sun397: top1: 42.30	top5: 66.59	
[09/28 04:24:44 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/28 04:24:54 visual_prompt]: Epoch 31 / 100: avg data time: 9.44e-02, avg batch time: 0.5531, average train loss: 0.4866
[09/28 04:24:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1698, average loss: 2.2195
[09/28 04:24:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 75.00	top5: 88.50	
[09/28 04:25:21 visual_prompt]: 	Test 100/340. loss: 4.320, 0.2195 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 04:25:43 visual_prompt]: 	Test 200/340. loss: 4.331, 0.2187 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:26:05 visual_prompt]: 	Test 300/340. loss: 4.075, 0.2192 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:26:15 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2194, average loss: 4.2347
[09/28 04:26:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 26.63	top5: 48.85	
[09/28 04:26:16 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/28 04:26:26 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e-01, avg batch time: 0.5649, average train loss: 0.7188
[09/28 04:26:29 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1699, average loss: 0.1588
[09/28 04:26:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 04:26:53 visual_prompt]: 	Test 100/340. loss: 2.641, 0.2199 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:27:15 visual_prompt]: 	Test 200/340. loss: 2.863, 0.2202 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 04:27:37 visual_prompt]: 	Test 300/340. loss: 2.809, 0.2204 s / batch. (data: 4.86e-05)max mem: 7.82369 GB 
[09/28 04:27:47 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2194, average loss: 2.9072
[09/28 04:27:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.33	top5: 71.32	
[09/28 04:27:47 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/28 04:27:57 visual_prompt]: Epoch 33 / 100: avg data time: 8.95e-02, avg batch time: 0.5480, average train loss: 0.3026
[09/28 04:28:01 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1699, average loss: 0.1794
[09/28 04:28:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 04:28:24 visual_prompt]: 	Test 100/340. loss: 2.692, 0.2202 s / batch. (data: 6.72e-05)max mem: 7.82369 GB 
[09/28 04:28:46 visual_prompt]: 	Test 200/340. loss: 3.230, 0.2200 s / batch. (data: 3.34e-05)max mem: 7.82369 GB 
[09/28 04:29:08 visual_prompt]: 	Test 300/340. loss: 2.841, 0.2203 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:29:18 visual_prompt]: Inference (test):avg data time: 8.32e-05, avg batch time: 0.2195, average loss: 2.8972
[09/28 04:29:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.26	top5: 70.99	
[09/28 04:29:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/28 04:29:31 visual_prompt]: Epoch 34 / 100: avg data time: 8.85e-02, avg batch time: 0.5478, average train loss: 0.2589
[09/28 04:29:34 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1693, average loss: 0.1711
[09/28 04:29:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:29:58 visual_prompt]: 	Test 100/340. loss: 2.701, 0.2203 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:30:20 visual_prompt]: 	Test 200/340. loss: 3.271, 0.2199 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 04:30:42 visual_prompt]: 	Test 300/340. loss: 2.939, 0.2206 s / batch. (data: 3.22e-05)max mem: 7.82369 GB 
[09/28 04:30:52 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2194, average loss: 2.9174
[09/28 04:30:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.74	top5: 71.75	
[09/28 04:30:53 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/28 04:31:03 visual_prompt]: Epoch 35 / 100: avg data time: 9.89e-02, avg batch time: 0.5566, average train loss: 0.2816
[09/28 04:31:06 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1699, average loss: 0.1905
[09/28 04:31:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 04:31:30 visual_prompt]: 	Test 100/340. loss: 2.644, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:31:52 visual_prompt]: 	Test 200/340. loss: 2.947, 0.2194 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:32:14 visual_prompt]: 	Test 300/340. loss: 2.949, 0.2193 s / batch. (data: 3.05e-05)max mem: 7.82369 GB 
[09/28 04:32:24 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2194, average loss: 2.9114
[09/28 04:32:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.83	top5: 72.37	
[09/28 04:32:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/28 04:32:34 visual_prompt]: Epoch 36 / 100: avg data time: 9.81e-02, avg batch time: 0.5564, average train loss: 2.6550
[09/28 04:32:38 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1700, average loss: 1.0049
[09/28 04:32:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 84.50	top5: 100.00	
[09/28 04:33:01 visual_prompt]: 	Test 100/340. loss: 3.207, 0.2199 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 04:33:23 visual_prompt]: 	Test 200/340. loss: 3.831, 0.2197 s / batch. (data: 8.89e-05)max mem: 7.82369 GB 
[09/28 04:33:45 visual_prompt]: 	Test 300/340. loss: 3.527, 0.2199 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 04:33:56 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2194, average loss: 3.4993
[09/28 04:33:56 visual_prompt]: Classification results with test_vtab-sun397: top1: 36.05	top5: 60.07	
[09/28 04:33:56 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/28 04:34:06 visual_prompt]: Epoch 37 / 100: avg data time: 9.39e-02, avg batch time: 0.5537, average train loss: 0.7698
[09/28 04:34:09 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1697, average loss: 0.1810
[09/28 04:34:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:34:33 visual_prompt]: 	Test 100/340. loss: 2.611, 0.2195 s / batch. (data: 2.34e-05)max mem: 7.82369 GB 
[09/28 04:34:55 visual_prompt]: 	Test 200/340. loss: 3.214, 0.2195 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:35:17 visual_prompt]: 	Test 300/340. loss: 3.103, 0.2206 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:35:27 visual_prompt]: Inference (test):avg data time: 3.60e-05, avg batch time: 0.2195, average loss: 2.9387
[09/28 04:35:28 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.29	top5: 70.24	
[09/28 04:35:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/28 04:35:38 visual_prompt]: Epoch 38 / 100: avg data time: 9.32e-02, avg batch time: 0.5520, average train loss: 0.2592
[09/28 04:35:41 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1703, average loss: 0.1590
[09/28 04:35:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:36:04 visual_prompt]: 	Test 100/340. loss: 2.629, 0.2205 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 04:36:26 visual_prompt]: 	Test 200/340. loss: 3.276, 0.2205 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 04:36:48 visual_prompt]: 	Test 300/340. loss: 2.997, 0.2200 s / batch. (data: 8.87e-05)max mem: 7.82369 GB 
[09/28 04:36:59 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2194, average loss: 2.9259
[09/28 04:36:59 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.68	top5: 71.04	
[09/28 04:36:59 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/28 04:37:09 visual_prompt]: Epoch 39 / 100: avg data time: 9.66e-02, avg batch time: 0.5556, average train loss: 0.2400
[09/28 04:37:12 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.1699, average loss: 0.1726
[09/28 04:37:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:37:36 visual_prompt]: 	Test 100/340. loss: 2.740, 0.2198 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:37:58 visual_prompt]: 	Test 200/340. loss: 3.366, 0.2207 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:38:20 visual_prompt]: 	Test 300/340. loss: 2.995, 0.2210 s / batch. (data: 3.05e-05)max mem: 7.82369 GB 
[09/28 04:38:30 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2196, average loss: 2.9627
[09/28 04:38:32 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.25	top5: 71.12	
[09/28 04:38:32 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/28 04:38:42 visual_prompt]: Epoch 40 / 100: avg data time: 1.01e-01, avg batch time: 0.5591, average train loss: 0.2617
[09/28 04:38:45 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1698, average loss: 0.1644
[09/28 04:38:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:39:09 visual_prompt]: 	Test 100/340. loss: 2.564, 0.2195 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 04:39:31 visual_prompt]: 	Test 200/340. loss: 3.103, 0.2196 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:39:53 visual_prompt]: 	Test 300/340. loss: 2.941, 0.2207 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:40:03 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2194, average loss: 2.9100
[09/28 04:40:04 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.70	top5: 72.40	
[09/28 04:40:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/28 04:40:14 visual_prompt]: Epoch 41 / 100: avg data time: 9.52e-02, avg batch time: 0.5551, average train loss: 0.3382
[09/28 04:40:18 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1701, average loss: 0.2207
[09/28 04:40:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:40:41 visual_prompt]: 	Test 100/340. loss: 2.663, 0.2199 s / batch. (data: 8.77e-05)max mem: 7.82369 GB 
[09/28 04:41:03 visual_prompt]: 	Test 200/340. loss: 3.266, 0.2195 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 04:41:25 visual_prompt]: 	Test 300/340. loss: 2.955, 0.2194 s / batch. (data: 7.96e-05)max mem: 7.82369 GB 
[09/28 04:41:35 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2194, average loss: 2.9770
[09/28 04:41:36 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.11	top5: 71.19	
[09/28 04:41:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/28 04:41:46 visual_prompt]: Epoch 42 / 100: avg data time: 9.89e-02, avg batch time: 0.5577, average train loss: 0.5742
[09/28 04:41:49 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1695, average loss: 0.2367
[09/28 04:41:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:42:13 visual_prompt]: 	Test 100/340. loss: 2.639, 0.2191 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:42:35 visual_prompt]: 	Test 200/340. loss: 3.197, 0.2192 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 04:42:57 visual_prompt]: 	Test 300/340. loss: 2.811, 0.2196 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:43:07 visual_prompt]: Inference (test):avg data time: 7.73e-05, avg batch time: 0.2196, average loss: 2.9505
[09/28 04:43:08 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.65	top5: 71.52	
[09/28 04:43:08 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/28 04:43:18 visual_prompt]: Epoch 43 / 100: avg data time: 9.97e-02, avg batch time: 0.5587, average train loss: 0.2640
[09/28 04:43:21 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1696, average loss: 0.1408
[09/28 04:43:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:43:45 visual_prompt]: 	Test 100/340. loss: 2.602, 0.2197 s / batch. (data: 2.36e-05)max mem: 7.82369 GB 
[09/28 04:44:07 visual_prompt]: 	Test 200/340. loss: 3.200, 0.2204 s / batch. (data: 3.10e-05)max mem: 7.82369 GB 
[09/28 04:44:29 visual_prompt]: 	Test 300/340. loss: 2.789, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 04:44:39 visual_prompt]: Inference (test):avg data time: 3.44e-05, avg batch time: 0.2195, average loss: 2.8848
[09/28 04:44:39 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.73	top5: 72.42	
[09/28 04:44:39 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/28 04:44:50 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e-01, avg batch time: 0.5628, average train loss: 0.2316
[09/28 04:44:53 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1697, average loss: 0.1682
[09/28 04:44:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:45:16 visual_prompt]: 	Test 100/340. loss: 2.571, 0.2199 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:45:38 visual_prompt]: 	Test 200/340. loss: 3.152, 0.2196 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:46:00 visual_prompt]: 	Test 300/340. loss: 2.724, 0.2201 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 04:46:10 visual_prompt]: Inference (test):avg data time: 5.61e-05, avg batch time: 0.2196, average loss: 2.8808
[09/28 04:46:11 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.20	top5: 73.21	
[09/28 04:46:11 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/28 04:46:21 visual_prompt]: Epoch 45 / 100: avg data time: 1.08e-01, avg batch time: 0.5663, average train loss: 0.2453
[09/28 04:46:24 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1702, average loss: 0.2135
[09/28 04:46:24 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:46:48 visual_prompt]: 	Test 100/340. loss: 2.682, 0.2201 s / batch. (data: 3.03e-05)max mem: 7.82369 GB 
[09/28 04:47:10 visual_prompt]: 	Test 200/340. loss: 3.258, 0.2195 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 04:47:32 visual_prompt]: 	Test 300/340. loss: 2.982, 0.2196 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 04:47:42 visual_prompt]: Inference (test):avg data time: 3.06e-05, avg batch time: 0.2195, average loss: 2.9814
[09/28 04:47:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.40	top5: 72.46	
[09/28 04:47:43 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/28 04:47:53 visual_prompt]: Epoch 46 / 100: avg data time: 9.35e-02, avg batch time: 0.5521, average train loss: 0.5322
[09/28 04:47:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1701, average loss: 0.2450
[09/28 04:47:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 04:48:19 visual_prompt]: 	Test 100/340. loss: 2.548, 0.2195 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:48:41 visual_prompt]: 	Test 200/340. loss: 3.111, 0.2193 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 04:49:03 visual_prompt]: 	Test 300/340. loss: 2.972, 0.2200 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 04:49:14 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2195, average loss: 2.9456
[09/28 04:49:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.19	top5: 71.98	
[09/28 04:49:16 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/28 04:49:26 visual_prompt]: Epoch 47 / 100: avg data time: 1.07e-01, avg batch time: 0.5646, average train loss: 0.3195
[09/28 04:49:30 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1697, average loss: 0.7983
[09/28 04:49:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:49:53 visual_prompt]: 	Test 100/340. loss: 3.153, 0.2199 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 04:50:15 visual_prompt]: 	Test 200/340. loss: 3.573, 0.2216 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 04:50:37 visual_prompt]: 	Test 300/340. loss: 3.407, 0.2208 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:50:48 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2193, average loss: 3.3848
[09/28 04:50:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.14	top5: 67.76	
[09/28 04:50:49 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[09/28 04:50:58 visual_prompt]: Epoch 48 / 100: avg data time: 9.92e-02, avg batch time: 0.5572, average train loss: 2.0412
[09/28 04:51:02 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1702, average loss: 0.6207
[09/28 04:51:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 94.50	top5: 100.00	
[09/28 04:51:25 visual_prompt]: 	Test 100/340. loss: 2.955, 0.2200 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 04:51:47 visual_prompt]: 	Test 200/340. loss: 3.390, 0.2199 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 04:52:09 visual_prompt]: 	Test 300/340. loss: 3.152, 0.2203 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:52:20 visual_prompt]: Inference (test):avg data time: 4.30e-05, avg batch time: 0.2195, average loss: 3.2115
[09/28 04:52:20 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.39	top5: 65.49	
[09/28 04:52:20 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[09/28 04:52:30 visual_prompt]: Epoch 49 / 100: avg data time: 1.00e-01, avg batch time: 0.5584, average train loss: 0.5047
[09/28 04:52:34 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1700, average loss: 0.7383
[09/28 04:52:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 96.50	top5: 100.00	
[09/28 04:52:57 visual_prompt]: 	Test 100/340. loss: 2.989, 0.2196 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 04:53:19 visual_prompt]: 	Test 200/340. loss: 3.659, 0.2202 s / batch. (data: 2.36e-05)max mem: 7.82369 GB 
[09/28 04:53:41 visual_prompt]: 	Test 300/340. loss: 3.405, 0.2199 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 04:53:51 visual_prompt]: Inference (test):avg data time: 7.88e-05, avg batch time: 0.2195, average loss: 3.3609
[09/28 04:53:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.31	top5: 64.66	
[09/28 04:53:54 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[09/28 04:54:04 visual_prompt]: Epoch 50 / 100: avg data time: 1.04e-01, avg batch time: 0.5614, average train loss: 0.2539
[09/28 04:54:07 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1699, average loss: 3.1540
[09/28 04:54:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 71.50	top5: 89.00	
[09/28 04:54:31 visual_prompt]: 	Test 100/340. loss: 4.524, 0.2185 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 04:54:53 visual_prompt]: 	Test 200/340. loss: 4.559, 0.2198 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 04:55:15 visual_prompt]: 	Test 300/340. loss: 4.747, 0.2193 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 04:55:25 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2194, average loss: 4.5993
[09/28 04:55:26 visual_prompt]: Classification results with test_vtab-sun397: top1: 27.07	top5: 46.88	
[09/28 04:55:26 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[09/28 04:55:36 visual_prompt]: Epoch 51 / 100: avg data time: 9.85e-02, avg batch time: 0.5565, average train loss: 0.5001
[09/28 04:55:39 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1699, average loss: 0.1472
[09/28 04:55:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:56:03 visual_prompt]: 	Test 100/340. loss: 2.612, 0.2196 s / batch. (data: 2.34e-05)max mem: 7.82369 GB 
[09/28 04:56:25 visual_prompt]: 	Test 200/340. loss: 3.040, 0.2194 s / batch. (data: 3.70e-05)max mem: 7.82369 GB 
[09/28 04:56:47 visual_prompt]: 	Test 300/340. loss: 2.865, 0.2328 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 04:56:57 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2196, average loss: 2.9041
[09/28 04:56:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.99	top5: 72.01	
[09/28 04:56:58 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[09/28 04:57:08 visual_prompt]: Epoch 52 / 100: avg data time: 1.01e-01, avg batch time: 0.5598, average train loss: 0.1918
[09/28 04:57:11 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1699, average loss: 0.1407
[09/28 04:57:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 04:57:35 visual_prompt]: 	Test 100/340. loss: 2.607, 0.2199 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 04:57:57 visual_prompt]: 	Test 200/340. loss: 2.987, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:58:19 visual_prompt]: 	Test 300/340. loss: 2.853, 0.2199 s / batch. (data: 3.67e-05)max mem: 7.82369 GB 
[09/28 04:58:29 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2195, average loss: 2.8613
[09/28 04:58:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.77	top5: 72.44	
[09/28 04:58:31 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[09/28 04:58:41 visual_prompt]: Epoch 53 / 100: avg data time: 1.01e-01, avg batch time: 0.5602, average train loss: 0.1793
[09/28 04:58:45 visual_prompt]: Inference (val):avg data time: 4.75e-05, avg batch time: 0.1696, average loss: 0.1315
[09/28 04:58:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 04:59:08 visual_prompt]: 	Test 100/340. loss: 2.571, 0.2198 s / batch. (data: 4.29e-05)max mem: 7.82369 GB 
[09/28 04:59:30 visual_prompt]: 	Test 200/340. loss: 3.077, 0.2191 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 04:59:52 visual_prompt]: 	Test 300/340. loss: 2.897, 0.2192 s / batch. (data: 3.08e-05)max mem: 7.82369 GB 
[09/28 05:00:02 visual_prompt]: Inference (test):avg data time: 6.91e-05, avg batch time: 0.2195, average loss: 2.8919
[09/28 05:00:04 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.34	top5: 73.24	
[09/28 05:00:04 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[09/28 05:00:14 visual_prompt]: Epoch 54 / 100: avg data time: 1.01e-01, avg batch time: 0.5597, average train loss: 0.1923
[09/28 05:00:17 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1700, average loss: 0.1371
[09/28 05:00:17 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:00:41 visual_prompt]: 	Test 100/340. loss: 2.669, 0.2199 s / batch. (data: 2.93e-05)max mem: 7.82369 GB 
[09/28 05:01:02 visual_prompt]: 	Test 200/340. loss: 2.932, 0.2192 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 05:01:25 visual_prompt]: 	Test 300/340. loss: 2.865, 0.2204 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 05:01:35 visual_prompt]: Inference (test):avg data time: 7.69e-05, avg batch time: 0.2195, average loss: 2.8756
[09/28 05:01:35 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.59	top5: 73.30	
[09/28 05:01:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[09/28 05:01:46 visual_prompt]: Epoch 55 / 100: avg data time: 1.09e-01, avg batch time: 0.5673, average train loss: 0.1986
[09/28 05:01:49 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1696, average loss: 0.1357
[09/28 05:01:49 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:02:12 visual_prompt]: 	Test 100/340. loss: 2.649, 0.2212 s / batch. (data: 2.48e-05)max mem: 7.82369 GB 
[09/28 05:02:34 visual_prompt]: 	Test 200/340. loss: 3.089, 0.2194 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:02:56 visual_prompt]: 	Test 300/340. loss: 2.825, 0.2213 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 05:03:07 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2194, average loss: 2.8631
[09/28 05:03:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.84	top5: 74.00	
[09/28 05:03:07 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[09/28 05:03:17 visual_prompt]: Epoch 56 / 100: avg data time: 1.03e-01, avg batch time: 0.5612, average train loss: 0.1954
[09/28 05:03:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1699, average loss: 0.1293
[09/28 05:03:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:03:44 visual_prompt]: 	Test 100/340. loss: 2.624, 0.2198 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 05:04:06 visual_prompt]: 	Test 200/340. loss: 3.040, 0.2194 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 05:04:28 visual_prompt]: 	Test 300/340. loss: 2.867, 0.2206 s / batch. (data: 3.27e-05)max mem: 7.82369 GB 
[09/28 05:04:38 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2195, average loss: 2.8611
[09/28 05:04:40 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.74	top5: 73.74	
[09/28 05:04:40 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[09/28 05:04:50 visual_prompt]: Epoch 57 / 100: avg data time: 9.40e-02, avg batch time: 0.5526, average train loss: 0.1882
[09/28 05:04:53 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1698, average loss: 0.1493
[09/28 05:04:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:05:17 visual_prompt]: 	Test 100/340. loss: 2.599, 0.2179 s / batch. (data: 3.24e-05)max mem: 7.82369 GB 
[09/28 05:05:39 visual_prompt]: 	Test 200/340. loss: 3.049, 0.2192 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:06:01 visual_prompt]: 	Test 300/340. loss: 2.796, 0.2199 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:06:11 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2194, average loss: 2.8569
[09/28 05:06:12 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.95	top5: 74.12	
[09/28 05:06:12 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[09/28 05:06:22 visual_prompt]: Epoch 58 / 100: avg data time: 9.96e-02, avg batch time: 0.5587, average train loss: 0.1911
[09/28 05:06:25 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1700, average loss: 0.1347
[09/28 05:06:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:06:49 visual_prompt]: 	Test 100/340. loss: 2.597, 0.2198 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:07:11 visual_prompt]: 	Test 200/340. loss: 3.073, 0.2196 s / batch. (data: 3.53e-05)max mem: 7.82369 GB 
[09/28 05:07:33 visual_prompt]: 	Test 300/340. loss: 2.799, 0.2203 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 05:07:43 visual_prompt]: Inference (test):avg data time: 3.18e-05, avg batch time: 0.2195, average loss: 2.8563
[09/28 05:07:44 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.32	top5: 73.81	
[09/28 05:07:44 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[09/28 05:07:54 visual_prompt]: Epoch 59 / 100: avg data time: 1.04e-01, avg batch time: 0.5631, average train loss: 0.1816
[09/28 05:07:57 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1700, average loss: 0.1282
[09/28 05:07:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:08:21 visual_prompt]: 	Test 100/340. loss: 2.574, 0.2197 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 05:08:43 visual_prompt]: 	Test 200/340. loss: 3.021, 0.2196 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:09:05 visual_prompt]: 	Test 300/340. loss: 2.801, 0.2189 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:09:15 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2195, average loss: 2.8497
[09/28 05:09:17 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.70	top5: 74.29	
[09/28 05:09:17 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[09/28 05:09:27 visual_prompt]: Epoch 60 / 100: avg data time: 9.51e-02, avg batch time: 0.5545, average train loss: 0.1848
[09/28 05:09:30 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1698, average loss: 0.1303
[09/28 05:09:30 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:09:54 visual_prompt]: 	Test 100/340. loss: 2.648, 0.2200 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:10:16 visual_prompt]: 	Test 200/340. loss: 3.070, 0.2197 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 05:10:38 visual_prompt]: 	Test 300/340. loss: 2.801, 0.2198 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:10:48 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2194, average loss: 2.8416
[09/28 05:10:50 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.48	top5: 74.56	
[09/28 05:10:50 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[09/28 05:11:00 visual_prompt]: Epoch 61 / 100: avg data time: 9.74e-02, avg batch time: 0.5563, average train loss: 0.1744
[09/28 05:11:03 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1699, average loss: 0.1261
[09/28 05:11:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:11:27 visual_prompt]: 	Test 100/340. loss: 2.618, 0.2203 s / batch. (data: 2.17e-05)max mem: 7.82369 GB 
[09/28 05:11:49 visual_prompt]: 	Test 200/340. loss: 3.016, 0.2194 s / batch. (data: 8.49e-05)max mem: 7.82369 GB 
[09/28 05:12:11 visual_prompt]: 	Test 300/340. loss: 2.738, 0.2199 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 05:12:21 visual_prompt]: Inference (test):avg data time: 4.23e-05, avg batch time: 0.2193, average loss: 2.8308
[09/28 05:12:22 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.98	top5: 74.44	
[09/28 05:12:22 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[09/28 05:12:32 visual_prompt]: Epoch 62 / 100: avg data time: 9.10e-02, avg batch time: 0.5486, average train loss: 0.1639
[09/28 05:12:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1701, average loss: 0.1276
[09/28 05:12:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:12:59 visual_prompt]: 	Test 100/340. loss: 2.566, 0.2193 s / batch. (data: 2.93e-05)max mem: 7.82369 GB 
[09/28 05:13:21 visual_prompt]: 	Test 200/340. loss: 3.049, 0.2200 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:13:43 visual_prompt]: 	Test 300/340. loss: 2.811, 0.2203 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 05:13:53 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2193, average loss: 2.8389
[09/28 05:13:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.14	top5: 74.74	
[09/28 05:13:53 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[09/28 05:14:03 visual_prompt]: Epoch 63 / 100: avg data time: 9.86e-02, avg batch time: 0.5595, average train loss: 0.1612
[09/28 05:14:07 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1699, average loss: 0.1329
[09/28 05:14:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:14:31 visual_prompt]: 	Test 100/340. loss: 2.544, 0.2190 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:14:53 visual_prompt]: 	Test 200/340. loss: 2.967, 0.2189 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:15:15 visual_prompt]: 	Test 300/340. loss: 2.760, 0.2212 s / batch. (data: 7.51e-05)max mem: 7.82369 GB 
[09/28 05:15:25 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2216, average loss: 2.8181
[09/28 05:15:27 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.32	top5: 74.76	
[09/28 05:15:27 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[09/28 05:15:37 visual_prompt]: Epoch 64 / 100: avg data time: 9.75e-02, avg batch time: 0.5555, average train loss: 0.1698
[09/28 05:15:40 visual_prompt]: Inference (val):avg data time: 5.39e-05, avg batch time: 0.1701, average loss: 0.1412
[09/28 05:15:40 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:16:04 visual_prompt]: 	Test 100/340. loss: 2.644, 0.2193 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 05:16:26 visual_prompt]: 	Test 200/340. loss: 3.087, 0.2192 s / batch. (data: 8.94e-05)max mem: 7.82369 GB 
[09/28 05:16:48 visual_prompt]: 	Test 300/340. loss: 2.852, 0.2193 s / batch. (data: 3.05e-05)max mem: 7.82369 GB 
[09/28 05:16:58 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2196, average loss: 2.8736
[09/28 05:16:59 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.62	top5: 74.27	
[09/28 05:16:59 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[09/28 05:17:09 visual_prompt]: Epoch 65 / 100: avg data time: 1.01e-01, avg batch time: 0.5591, average train loss: 0.1769
[09/28 05:17:12 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.1699, average loss: 0.1239
[09/28 05:17:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:17:36 visual_prompt]: 	Test 100/340. loss: 2.620, 0.2182 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 05:17:58 visual_prompt]: 	Test 200/340. loss: 3.017, 0.2200 s / batch. (data: 2.48e-05)max mem: 7.82369 GB 
[09/28 05:18:20 visual_prompt]: 	Test 300/340. loss: 2.758, 0.2196 s / batch. (data: 3.81e-05)max mem: 7.82369 GB 
[09/28 05:18:30 visual_prompt]: Inference (test):avg data time: 3.71e-05, avg batch time: 0.2195, average loss: 2.8277
[09/28 05:18:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.57	top5: 75.07	
[09/28 05:18:31 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[09/28 05:18:41 visual_prompt]: Epoch 66 / 100: avg data time: 1.02e-01, avg batch time: 0.5606, average train loss: 0.1661
[09/28 05:18:44 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1700, average loss: 0.1226
[09/28 05:18:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:19:08 visual_prompt]: 	Test 100/340. loss: 2.563, 0.2189 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:19:30 visual_prompt]: 	Test 200/340. loss: 2.971, 0.2194 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 05:19:52 visual_prompt]: 	Test 300/340. loss: 2.761, 0.2201 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:20:02 visual_prompt]: Inference (test):avg data time: 3.53e-05, avg batch time: 0.2195, average loss: 2.8226
[09/28 05:20:02 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.52	top5: 75.06	
[09/28 05:20:02 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[09/28 05:20:13 visual_prompt]: Epoch 67 / 100: avg data time: 1.00e-01, avg batch time: 0.5594, average train loss: 0.1614
[09/28 05:20:16 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1700, average loss: 0.1203
[09/28 05:20:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:20:39 visual_prompt]: 	Test 100/340. loss: 2.540, 0.2204 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 05:21:01 visual_prompt]: 	Test 200/340. loss: 3.019, 0.2194 s / batch. (data: 8.23e-05)max mem: 7.82369 GB 
[09/28 05:21:23 visual_prompt]: 	Test 300/340. loss: 2.699, 0.2198 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 05:21:34 visual_prompt]: Inference (test):avg data time: 3.02e-05, avg batch time: 0.2194, average loss: 2.8071
[09/28 05:21:34 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.04	top5: 75.31	
[09/28 05:21:34 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[09/28 05:21:44 visual_prompt]: Epoch 68 / 100: avg data time: 1.02e-01, avg batch time: 0.5612, average train loss: 0.1596
[09/28 05:21:47 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1699, average loss: 0.1289
[09/28 05:21:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:22:11 visual_prompt]: 	Test 100/340. loss: 2.582, 0.2199 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 05:22:33 visual_prompt]: 	Test 200/340. loss: 2.971, 0.2194 s / batch. (data: 6.77e-05)max mem: 7.82369 GB 
[09/28 05:22:55 visual_prompt]: 	Test 300/340. loss: 2.718, 0.2205 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 05:23:05 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2195, average loss: 2.8230
[09/28 05:23:08 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.03	top5: 75.21	
[09/28 05:23:08 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[09/28 05:23:18 visual_prompt]: Epoch 69 / 100: avg data time: 9.82e-02, avg batch time: 0.5560, average train loss: 0.1552
[09/28 05:23:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1698, average loss: 0.1135
[09/28 05:23:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:23:45 visual_prompt]: 	Test 100/340. loss: 2.530, 0.2195 s / batch. (data: 2.34e-05)max mem: 7.82369 GB 
[09/28 05:24:07 visual_prompt]: 	Test 200/340. loss: 3.012, 0.2196 s / batch. (data: 6.41e-05)max mem: 7.82369 GB 
[09/28 05:24:29 visual_prompt]: 	Test 300/340. loss: 2.752, 0.2199 s / batch. (data: 4.22e-05)max mem: 7.82369 GB 
[09/28 05:24:39 visual_prompt]: Inference (test):avg data time: 3.63e-05, avg batch time: 0.2193, average loss: 2.8377
[09/28 05:24:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.55	top5: 75.05	
[09/28 05:24:43 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[09/28 05:24:53 visual_prompt]: Epoch 70 / 100: avg data time: 1.02e-01, avg batch time: 0.5584, average train loss: 0.2116
[09/28 05:24:56 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1693, average loss: 0.4916
[09/28 05:24:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:25:20 visual_prompt]: 	Test 100/340. loss: 2.959, 0.2189 s / batch. (data: 3.22e-05)max mem: 7.82369 GB 
[09/28 05:25:42 visual_prompt]: 	Test 200/340. loss: 3.255, 0.2202 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 05:26:04 visual_prompt]: 	Test 300/340. loss: 3.048, 0.2210 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 05:26:14 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2193, average loss: 3.1225
[09/28 05:26:18 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.10	top5: 72.06	
[09/28 05:26:18 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[09/28 05:26:28 visual_prompt]: Epoch 71 / 100: avg data time: 9.73e-02, avg batch time: 0.5548, average train loss: 0.3236
[09/28 05:26:31 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1694, average loss: 0.2227
[09/28 05:26:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:26:55 visual_prompt]: 	Test 100/340. loss: 2.518, 0.2187 s / batch. (data: 3.64e-04)max mem: 7.82369 GB 
[09/28 05:27:17 visual_prompt]: 	Test 200/340. loss: 2.986, 0.2194 s / batch. (data: 2.38e-05)max mem: 7.82369 GB 
[09/28 05:27:39 visual_prompt]: 	Test 300/340. loss: 2.804, 0.2192 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:27:49 visual_prompt]: Inference (test):avg data time: 3.42e-05, avg batch time: 0.2192, average loss: 2.8732
[09/28 05:27:50 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.13	top5: 73.99	
[09/28 05:27:50 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[09/28 05:28:00 visual_prompt]: Epoch 72 / 100: avg data time: 1.00e-01, avg batch time: 0.5594, average train loss: 0.1925
[09/28 05:28:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1700, average loss: 0.1221
[09/28 05:28:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:28:27 visual_prompt]: 	Test 100/340. loss: 2.491, 0.2193 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:28:49 visual_prompt]: 	Test 200/340. loss: 2.960, 0.2193 s / batch. (data: 3.08e-05)max mem: 7.82369 GB 
[09/28 05:29:11 visual_prompt]: 	Test 300/340. loss: 2.748, 0.2190 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:29:21 visual_prompt]: Inference (test):avg data time: 3.28e-05, avg batch time: 0.2195, average loss: 2.7902
[09/28 05:29:22 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.46	top5: 74.98	
[09/28 05:29:22 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[09/28 05:29:32 visual_prompt]: Epoch 73 / 100: avg data time: 9.75e-02, avg batch time: 0.5554, average train loss: 0.1383
[09/28 05:29:35 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1698, average loss: 0.0990
[09/28 05:29:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:29:59 visual_prompt]: 	Test 100/340. loss: 2.449, 0.2187 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:30:21 visual_prompt]: 	Test 200/340. loss: 2.866, 0.2201 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 05:30:43 visual_prompt]: 	Test 300/340. loss: 2.648, 0.2203 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:30:53 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2195, average loss: 2.7643
[09/28 05:30:54 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.81	top5: 75.29	
[09/28 05:30:54 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[09/28 05:31:04 visual_prompt]: Epoch 74 / 100: avg data time: 9.06e-02, avg batch time: 0.5494, average train loss: 0.1193
[09/28 05:31:07 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1703, average loss: 0.0970
[09/28 05:31:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:31:30 visual_prompt]: 	Test 100/340. loss: 2.470, 0.2203 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 05:31:52 visual_prompt]: 	Test 200/340. loss: 2.942, 0.2198 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:32:14 visual_prompt]: 	Test 300/340. loss: 2.647, 0.2195 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:32:25 visual_prompt]: Inference (test):avg data time: 3.61e-05, avg batch time: 0.2194, average loss: 2.7712
[09/28 05:32:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.09	top5: 75.48	
[09/28 05:32:25 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[09/28 05:32:35 visual_prompt]: Epoch 75 / 100: avg data time: 1.04e-01, avg batch time: 0.5617, average train loss: 0.1188
[09/28 05:32:38 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1699, average loss: 0.1030
[09/28 05:32:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:33:02 visual_prompt]: 	Test 100/340. loss: 2.491, 0.2189 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:33:24 visual_prompt]: 	Test 200/340. loss: 2.926, 0.2189 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:33:46 visual_prompt]: 	Test 300/340. loss: 2.682, 0.2192 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:33:56 visual_prompt]: Inference (test):avg data time: 3.55e-05, avg batch time: 0.2195, average loss: 2.7843
[09/28 05:33:57 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.94	top5: 75.34	
[09/28 05:33:57 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[09/28 05:34:07 visual_prompt]: Epoch 76 / 100: avg data time: 1.03e-01, avg batch time: 0.5617, average train loss: 0.1202
[09/28 05:34:10 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1702, average loss: 0.1004
[09/28 05:34:10 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:34:34 visual_prompt]: 	Test 100/340. loss: 2.523, 0.2194 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 05:34:56 visual_prompt]: 	Test 200/340. loss: 2.947, 0.2194 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:35:18 visual_prompt]: 	Test 300/340. loss: 2.697, 0.2192 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:35:28 visual_prompt]: Inference (test):avg data time: 3.41e-05, avg batch time: 0.2195, average loss: 2.8009
[09/28 05:35:28 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.96	top5: 75.45	
[09/28 05:35:28 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[09/28 05:35:38 visual_prompt]: Epoch 77 / 100: avg data time: 9.14e-02, avg batch time: 0.5499, average train loss: 0.1217
[09/28 05:35:41 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1696, average loss: 0.1010
[09/28 05:35:41 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:36:05 visual_prompt]: 	Test 100/340. loss: 2.536, 0.2198 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 05:36:27 visual_prompt]: 	Test 200/340. loss: 2.966, 0.2206 s / batch. (data: 2.96e-05)max mem: 7.82369 GB 
[09/28 05:36:49 visual_prompt]: 	Test 300/340. loss: 2.710, 0.2197 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 05:36:59 visual_prompt]: Inference (test):avg data time: 3.22e-05, avg batch time: 0.2195, average loss: 2.8036
[09/28 05:37:00 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.05	top5: 75.55	
[09/28 05:37:00 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[09/28 05:37:10 visual_prompt]: Epoch 78 / 100: avg data time: 1.07e-01, avg batch time: 0.5667, average train loss: 0.1244
[09/28 05:37:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1702, average loss: 0.1128
[09/28 05:37:13 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:37:37 visual_prompt]: 	Test 100/340. loss: 2.499, 0.2202 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:37:59 visual_prompt]: 	Test 200/340. loss: 2.968, 0.2198 s / batch. (data: 7.58e-05)max mem: 7.82369 GB 
[09/28 05:38:21 visual_prompt]: 	Test 300/340. loss: 2.731, 0.2195 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:38:31 visual_prompt]: Inference (test):avg data time: 3.64e-05, avg batch time: 0.2195, average loss: 2.8178
[09/28 05:38:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.77	top5: 75.56	
[09/28 05:38:31 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[09/28 05:38:41 visual_prompt]: Epoch 79 / 100: avg data time: 1.05e-01, avg batch time: 0.5633, average train loss: 0.1318
[09/28 05:38:45 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1700, average loss: 0.1158
[09/28 05:38:45 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:39:08 visual_prompt]: 	Test 100/340. loss: 2.569, 0.2201 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 05:39:30 visual_prompt]: 	Test 200/340. loss: 2.970, 0.2204 s / batch. (data: 8.13e-05)max mem: 7.82369 GB 
[09/28 05:39:52 visual_prompt]: 	Test 300/340. loss: 2.710, 0.2195 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:40:03 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2195, average loss: 2.8205
[09/28 05:40:06 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.66	top5: 75.41	
[09/28 05:40:06 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[09/28 05:40:16 visual_prompt]: Epoch 80 / 100: avg data time: 9.00e-02, avg batch time: 0.5498, average train loss: 0.1325
[09/28 05:40:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1695, average loss: 0.1151
[09/28 05:40:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:40:43 visual_prompt]: 	Test 100/340. loss: 2.584, 0.2202 s / batch. (data: 2.38e-05)max mem: 7.82369 GB 
[09/28 05:41:05 visual_prompt]: 	Test 200/340. loss: 2.961, 0.2194 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 05:41:27 visual_prompt]: 	Test 300/340. loss: 2.753, 0.2195 s / batch. (data: 3.17e-05)max mem: 7.82369 GB 
[09/28 05:41:37 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2193, average loss: 2.8360
[09/28 05:41:42 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.51	top5: 75.13	
[09/28 05:41:42 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[09/28 05:41:52 visual_prompt]: Epoch 81 / 100: avg data time: 1.02e-01, avg batch time: 0.5591, average train loss: 0.1298
[09/28 05:41:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1698, average loss: 0.1048
[09/28 05:41:56 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:42:19 visual_prompt]: 	Test 100/340. loss: 2.514, 0.2178 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 05:42:41 visual_prompt]: 	Test 200/340. loss: 2.983, 0.2191 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:43:03 visual_prompt]: 	Test 300/340. loss: 2.714, 0.2202 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 05:43:13 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2191, average loss: 2.8344
[09/28 05:43:16 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.09	top5: 75.35	
[09/28 05:43:16 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[09/28 05:43:26 visual_prompt]: Epoch 82 / 100: avg data time: 1.05e-01, avg batch time: 0.5617, average train loss: 0.1235
[09/28 05:43:29 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1688, average loss: 0.1033
[09/28 05:43:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:43:53 visual_prompt]: 	Test 100/340. loss: 2.563, 0.2193 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 05:44:15 visual_prompt]: 	Test 200/340. loss: 2.957, 0.2196 s / batch. (data: 7.77e-05)max mem: 7.82369 GB 
[09/28 05:44:37 visual_prompt]: 	Test 300/340. loss: 2.701, 0.2206 s / batch. (data: 9.11e-05)max mem: 7.82369 GB 
[09/28 05:44:47 visual_prompt]: Inference (test):avg data time: 3.48e-05, avg batch time: 0.2193, average loss: 2.8202
[09/28 05:44:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.12	top5: 75.48	
[09/28 05:44:49 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[09/28 05:44:59 visual_prompt]: Epoch 83 / 100: avg data time: 9.87e-02, avg batch time: 0.5585, average train loss: 0.1197
[09/28 05:45:02 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1699, average loss: 0.0994
[09/28 05:45:02 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:45:26 visual_prompt]: 	Test 100/340. loss: 2.572, 0.2197 s / batch. (data: 2.29e-05)max mem: 7.82369 GB 
[09/28 05:45:48 visual_prompt]: 	Test 200/340. loss: 2.985, 0.2194 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 05:46:10 visual_prompt]: 	Test 300/340. loss: 2.745, 0.2196 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 05:46:20 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2193, average loss: 2.8336
[09/28 05:46:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.82	top5: 75.41	
[09/28 05:46:21 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[09/28 05:46:31 visual_prompt]: Epoch 84 / 100: avg data time: 1.03e-01, avg batch time: 0.5613, average train loss: 0.1166
[09/28 05:46:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1699, average loss: 0.1024
[09/28 05:46:34 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:46:58 visual_prompt]: 	Test 100/340. loss: 2.555, 0.2196 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 05:47:20 visual_prompt]: 	Test 200/340. loss: 2.975, 0.2193 s / batch. (data: 2.41e-05)max mem: 7.82369 GB 
[09/28 05:47:42 visual_prompt]: 	Test 300/340. loss: 2.705, 0.2193 s / batch. (data: 6.87e-05)max mem: 7.82369 GB 
[09/28 05:47:52 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2194, average loss: 2.8237
[09/28 05:47:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 52.17	top5: 75.55	
[09/28 05:47:53 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[09/28 05:48:03 visual_prompt]: Epoch 85 / 100: avg data time: 9.97e-02, avg batch time: 0.5580, average train loss: 0.1167
[09/28 05:48:06 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.1700, average loss: 0.0990
[09/28 05:48:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:48:30 visual_prompt]: 	Test 100/340. loss: 2.588, 0.2194 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 05:48:52 visual_prompt]: 	Test 200/340. loss: 3.015, 0.2201 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:49:14 visual_prompt]: 	Test 300/340. loss: 2.733, 0.2197 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 05:49:24 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2194, average loss: 2.8442
[09/28 05:49:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.89	top5: 75.40	
[09/28 05:49:25 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[09/28 05:49:35 visual_prompt]: Epoch 86 / 100: avg data time: 1.03e-01, avg batch time: 0.5612, average train loss: 0.1153
[09/28 05:49:38 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1697, average loss: 0.0960
[09/28 05:49:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:50:02 visual_prompt]: 	Test 100/340. loss: 2.545, 0.2193 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:50:24 visual_prompt]: 	Test 200/340. loss: 2.997, 0.2195 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 05:50:46 visual_prompt]: 	Test 300/340. loss: 2.737, 0.2191 s / batch. (data: 2.38e-05)max mem: 7.82369 GB 
[09/28 05:50:56 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2195, average loss: 2.8405
[09/28 05:50:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.90	top5: 75.44	
[09/28 05:50:58 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[09/28 05:51:08 visual_prompt]: Epoch 87 / 100: avg data time: 1.01e-01, avg batch time: 0.5589, average train loss: 0.1129
[09/28 05:51:11 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1698, average loss: 0.0973
[09/28 05:51:11 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:51:35 visual_prompt]: 	Test 100/340. loss: 2.581, 0.2203 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 05:51:57 visual_prompt]: 	Test 200/340. loss: 3.020, 0.2201 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:52:22 visual_prompt]: 	Test 300/340. loss: 2.761, 0.2152 s / batch. (data: 3.46e-05)max mem: 7.82369 GB 
[09/28 05:52:32 visual_prompt]: Inference (test):avg data time: 5.71e-05, avg batch time: 0.2196, average loss: 2.8538
[09/28 05:52:33 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.79	top5: 75.49	
[09/28 05:52:33 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[09/28 05:52:43 visual_prompt]: Epoch 88 / 100: avg data time: 1.01e-01, avg batch time: 0.5573, average train loss: 0.1151
[09/28 05:52:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1695, average loss: 0.0973
[09/28 05:52:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:53:10 visual_prompt]: 	Test 100/340. loss: 2.565, 0.2195 s / batch. (data: 7.87e-05)max mem: 7.82369 GB 
[09/28 05:53:32 visual_prompt]: 	Test 200/340. loss: 2.993, 0.2200 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 05:53:54 visual_prompt]: 	Test 300/340. loss: 2.730, 0.2203 s / batch. (data: 2.46e-05)max mem: 7.82369 GB 
[09/28 05:54:04 visual_prompt]: Inference (test):avg data time: 3.12e-05, avg batch time: 0.2193, average loss: 2.8288
[09/28 05:54:05 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.99	top5: 75.56	
[09/28 05:54:05 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[09/28 05:54:15 visual_prompt]: Epoch 89 / 100: avg data time: 1.12e-01, avg batch time: 0.5717, average train loss: 0.1130
[09/28 05:54:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1695, average loss: 0.0946
[09/28 05:54:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:54:42 visual_prompt]: 	Test 100/340. loss: 2.570, 0.2198 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 05:55:04 visual_prompt]: 	Test 200/340. loss: 3.036, 0.2202 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:55:26 visual_prompt]: 	Test 300/340. loss: 2.774, 0.2203 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:55:36 visual_prompt]: Inference (test):avg data time: 1.16e-04, avg batch time: 0.2196, average loss: 2.8365
[09/28 05:55:37 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.94	top5: 75.56	
[09/28 05:55:37 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[09/28 05:55:48 visual_prompt]: Epoch 90 / 100: avg data time: 1.06e-01, avg batch time: 0.5653, average train loss: 0.1101
[09/28 05:55:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1697, average loss: 0.0935
[09/28 05:55:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:56:15 visual_prompt]: 	Test 100/340. loss: 2.563, 0.2200 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:56:37 visual_prompt]: 	Test 200/340. loss: 3.023, 0.2198 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 05:56:59 visual_prompt]: 	Test 300/340. loss: 2.757, 0.2203 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 05:57:09 visual_prompt]: Inference (test):avg data time: 3.16e-05, avg batch time: 0.2194, average loss: 2.8456
[09/28 05:57:12 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.85	top5: 75.46	
[09/28 05:57:12 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[09/28 05:57:22 visual_prompt]: Epoch 91 / 100: avg data time: 9.13e-02, avg batch time: 0.5494, average train loss: 0.1083
[09/28 05:57:25 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1696, average loss: 0.0935
[09/28 05:57:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:57:49 visual_prompt]: 	Test 100/340. loss: 2.578, 0.2202 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 05:58:10 visual_prompt]: 	Test 200/340. loss: 3.027, 0.2204 s / batch. (data: 2.41e-05)max mem: 7.82369 GB 
[09/28 05:58:32 visual_prompt]: 	Test 300/340. loss: 2.777, 0.2193 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 05:58:43 visual_prompt]: Inference (test):avg data time: 3.23e-05, avg batch time: 0.2193, average loss: 2.8468
[09/28 05:58:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.75	top5: 75.52	
[09/28 05:58:43 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[09/28 05:58:53 visual_prompt]: Epoch 92 / 100: avg data time: 9.70e-02, avg batch time: 0.5568, average train loss: 0.1074
[09/28 05:58:57 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.1693, average loss: 0.0931
[09/28 05:58:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 05:59:20 visual_prompt]: 	Test 100/340. loss: 2.588, 0.2201 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 05:59:42 visual_prompt]: 	Test 200/340. loss: 3.032, 0.2204 s / batch. (data: 2.29e-05)max mem: 7.82369 GB 
[09/28 06:00:04 visual_prompt]: 	Test 300/340. loss: 2.765, 0.2197 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 06:00:14 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2194, average loss: 2.8517
[09/28 06:00:15 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.77	top5: 75.48	
[09/28 06:00:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[09/28 06:00:25 visual_prompt]: Epoch 93 / 100: avg data time: 1.01e-01, avg batch time: 0.5599, average train loss: 0.1065
[09/28 06:00:28 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1701, average loss: 0.0923
[09/28 06:00:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:00:52 visual_prompt]: 	Test 100/340. loss: 2.578, 0.2188 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:01:14 visual_prompt]: 	Test 200/340. loss: 3.018, 0.2198 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 06:01:36 visual_prompt]: 	Test 300/340. loss: 2.761, 0.2196 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 06:01:46 visual_prompt]: Inference (test):avg data time: 3.13e-05, avg batch time: 0.2194, average loss: 2.8493
[09/28 06:01:50 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.89	top5: 75.49	
[09/28 06:01:50 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[09/28 06:02:00 visual_prompt]: Epoch 94 / 100: avg data time: 1.02e-01, avg batch time: 0.5590, average train loss: 0.1062
[09/28 06:02:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1696, average loss: 0.0923
[09/28 06:02:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:02:26 visual_prompt]: 	Test 100/340. loss: 2.575, 0.2188 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 06:02:48 visual_prompt]: 	Test 200/340. loss: 3.017, 0.2194 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 06:03:10 visual_prompt]: 	Test 300/340. loss: 2.774, 0.2194 s / batch. (data: 3.65e-05)max mem: 7.82369 GB 
[09/28 06:03:21 visual_prompt]: Inference (test):avg data time: 3.17e-05, avg batch time: 0.2193, average loss: 2.8542
[09/28 06:03:22 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.85	top5: 75.50	
[09/28 06:03:22 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[09/28 06:03:32 visual_prompt]: Epoch 95 / 100: avg data time: 1.06e-01, avg batch time: 0.5658, average train loss: 0.1059
[09/28 06:03:35 visual_prompt]: Inference (val):avg data time: 2.01e-05, avg batch time: 0.1698, average loss: 0.0917
[09/28 06:03:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:03:59 visual_prompt]: 	Test 100/340. loss: 2.579, 0.2192 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 06:04:21 visual_prompt]: 	Test 200/340. loss: 3.027, 0.2204 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 06:04:43 visual_prompt]: 	Test 300/340. loss: 2.778, 0.2196 s / batch. (data: 3.19e-05)max mem: 7.82369 GB 
[09/28 06:04:53 visual_prompt]: Inference (test):avg data time: 3.32e-05, avg batch time: 0.2195, average loss: 2.8557
[09/28 06:04:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.89	top5: 75.46	
[09/28 06:04:53 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[09/28 06:05:04 visual_prompt]: Epoch 96 / 100: avg data time: 1.07e-01, avg batch time: 0.5648, average train loss: 0.1054
[09/28 06:05:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1702, average loss: 0.0916
[09/28 06:05:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:05:30 visual_prompt]: 	Test 100/340. loss: 2.578, 0.2201 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 06:05:52 visual_prompt]: 	Test 200/340. loss: 3.032, 0.2198 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 06:06:14 visual_prompt]: 	Test 300/340. loss: 2.776, 0.2177 s / batch. (data: 3.24e-05)max mem: 7.82369 GB 
[09/28 06:06:25 visual_prompt]: Inference (test):avg data time: 7.00e-05, avg batch time: 0.2195, average loss: 2.8568
[09/28 06:06:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.84	top5: 75.47	
[09/28 06:06:25 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[09/28 06:06:35 visual_prompt]: Epoch 97 / 100: avg data time: 1.10e-01, avg batch time: 0.5684, average train loss: 0.1051
[09/28 06:06:39 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1699, average loss: 0.0914
[09/28 06:06:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:07:02 visual_prompt]: 	Test 100/340. loss: 2.579, 0.2203 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 06:07:24 visual_prompt]: 	Test 200/340. loss: 3.031, 0.2193 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:07:46 visual_prompt]: 	Test 300/340. loss: 2.774, 0.2195 s / batch. (data: 3.27e-05)max mem: 7.82369 GB 
[09/28 06:07:56 visual_prompt]: Inference (test):avg data time: 6.82e-05, avg batch time: 0.2195, average loss: 2.8564
[09/28 06:08:02 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.90	top5: 75.51	
[09/28 06:08:02 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[09/28 06:08:12 visual_prompt]: Epoch 98 / 100: avg data time: 9.69e-02, avg batch time: 0.5539, average train loss: 0.1048
[09/28 06:08:15 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1692, average loss: 0.0915
[09/28 06:08:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:08:39 visual_prompt]: 	Test 100/340. loss: 2.579, 0.2187 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 06:09:01 visual_prompt]: 	Test 200/340. loss: 3.031, 0.2198 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 06:09:23 visual_prompt]: 	Test 300/340. loss: 2.779, 0.2193 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 06:09:33 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2191, average loss: 2.8577
[09/28 06:09:33 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.82	top5: 75.51	
[09/28 06:09:33 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[09/28 06:09:43 visual_prompt]: Epoch 99 / 100: avg data time: 1.01e-01, avg batch time: 0.5590, average train loss: 0.1047
[09/28 06:09:47 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1700, average loss: 0.0916
[09/28 06:09:47 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:10:11 visual_prompt]: 	Test 100/340. loss: 2.578, 0.2190 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:10:33 visual_prompt]: 	Test 200/340. loss: 3.031, 0.2189 s / batch. (data: 2.29e-05)max mem: 7.82369 GB 
[09/28 06:10:55 visual_prompt]: 	Test 300/340. loss: 2.781, 0.2212 s / batch. (data: 1.52e-03)max mem: 7.82369 GB 
[09/28 06:11:05 visual_prompt]: Inference (test):avg data time: 3.73e-05, avg batch time: 0.2194, average loss: 2.8583
[09/28 06:11:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.80	top5: 75.52	
[09/28 06:11:07 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[09/28 06:11:17 visual_prompt]: Epoch 100 / 100: avg data time: 9.12e-02, avg batch time: 0.5493, average train loss: 0.1044
[09/28 06:11:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.1693, average loss: 0.0916
[09/28 06:11:20 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:11:43 visual_prompt]: 	Test 100/340. loss: 2.579, 0.2199 s / batch. (data: 2.98e-05)max mem: 7.82369 GB 
[09/28 06:12:05 visual_prompt]: 	Test 200/340. loss: 3.031, 0.2192 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 06:12:27 visual_prompt]: 	Test 300/340. loss: 2.781, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:12:38 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2193, average loss: 2.8583
[09/28 06:12:41 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.81	top5: 75.52	
[09/28 06:12:41 visual_prompt]: Rank of current process: 0. World size: 1
[09/28 06:12:41 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              0
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[09/28 06:12:41 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'vtab-sun397', 'DATA.NUMBER_CLASSES', '397', 'DATA.CROPSIZE', '224', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir'])
[09/28 06:12:41 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[09/28 06:12:41 visual_prompt]: Training with config:
[09/28 06:12:41 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/vtab-sun397/sup_vitb16_imagenet21k/prompt50/crop224/test/seed9020/lr2.5_wd0.001/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9020, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 300, 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'vtab-sun397', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 397, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'CROPSIZE': 224, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[09/28 06:12:41 visual_prompt]: Loading training data...
[09/28 06:12:41 visual_prompt]: Constructing vtab-sun397 dataset trainval...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split train[:800]+validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 06:12:44 visual_prompt]: Number of images: 1000
[09/28 06:12:44 visual_prompt]: Number of classes: 325 / 397
[09/28 06:12:44 visual_prompt]: Loading validation data...
[09/28 06:12:44 visual_prompt]: Constructing vtab-sun397 dataset val...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split validation[:200], from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 06:12:44 visual_prompt]: Number of images: 200
[09/28 06:12:44 visual_prompt]: Number of classes: 136 / 397
[09/28 06:12:44 visual_prompt]: Loading test data...
[09/28 06:12:44 visual_prompt]: Constructing vtab-sun397 dataset test...
[INFO: dataset_info.py:  599]: Load dataset info from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[INFO: dataset_builder.py:  573]: Reusing dataset sun397 (visual_prompt_tuning/data_path/sun397/tfds/4.0.0)
[INFO: logging_logger.py:   49]: Constructing tf.data.Dataset sun397 for split test, from visual_prompt_tuning/data_path/sun397/tfds/4.0.0
[09/28 06:13:42 visual_prompt]: Number of images: 21750
[09/28 06:13:42 visual_prompt]: Number of classes: 397 / 397
[09/28 06:13:42 visual_prompt]: Constructing models...
[09/28 06:13:46 visual_prompt]: Total Parameters: 86564749	 Gradient Parameters: 766093
[09/28 06:13:46 visual_prompt]: tuned percent:0.885
[09/28 06:13:46 visual_prompt]: Device used for model: 0
[09/28 06:13:46 visual_prompt]: Setting up Evaluator...
[09/28 06:13:46 visual_prompt]: Setting up Trainer...
[09/28 06:13:46 visual_prompt]: 	Setting up the optimizer...
[09/28 06:13:46 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[09/28 06:13:56 visual_prompt]: Epoch 1 / 100: avg data time: 1.30e-01, avg batch time: 0.5812, average train loss: 5.9989
[09/28 06:14:00 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1657, average loss: 5.9872
[09/28 06:14:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.00	top5: 2.00	
[09/28 06:14:23 visual_prompt]: 	Test 100/340. loss: 5.994, 0.2154 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 06:14:45 visual_prompt]: 	Test 200/340. loss: 5.989, 0.2177 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 06:15:07 visual_prompt]: 	Test 300/340. loss: 5.996, 0.2181 s / batch. (data: 3.27e-05)max mem: 7.82369 GB 
[09/28 06:15:20 visual_prompt]: Inference (test):avg data time: 1.07e-04, avg batch time: 0.2188, average loss: 6.0016
[09/28 06:15:20 visual_prompt]: Classification results with test_vtab-sun397: top1: 0.11	top5: 0.86	
[09/28 06:15:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[09/28 06:15:33 visual_prompt]: Epoch 2 / 100: avg data time: 2.31e-01, avg batch time: 0.6852, average train loss: 5.8003
[09/28 06:15:37 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1683, average loss: 5.6067
[09/28 06:15:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 0.50	top5: 5.00	
[09/28 06:16:00 visual_prompt]: 	Test 100/340. loss: 5.746, 0.2185 s / batch. (data: 9.47e-05)max mem: 7.82369 GB 
[09/28 06:16:22 visual_prompt]: 	Test 200/340. loss: 5.776, 0.2190 s / batch. (data: 4.82e-05)max mem: 7.82369 GB 
[09/28 06:16:44 visual_prompt]: 	Test 300/340. loss: 5.776, 0.2195 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:16:55 visual_prompt]: Inference (test):avg data time: 4.17e-05, avg batch time: 0.2185, average loss: 5.7833
[09/28 06:16:55 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.02	top5: 7.56	
[09/28 06:16:55 visual_prompt]: Best epoch 2: best metric: 0.005
[09/28 06:16:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[09/28 06:17:06 visual_prompt]: Epoch 3 / 100: avg data time: 1.27e-01, avg batch time: 0.5837, average train loss: 5.6062
[09/28 06:17:09 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.1691, average loss: 5.4536
[09/28 06:17:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 7.50	
[09/28 06:17:33 visual_prompt]: 	Test 100/340. loss: 5.734, 0.2183 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 06:17:55 visual_prompt]: 	Test 200/340. loss: 5.807, 0.2191 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 06:18:17 visual_prompt]: 	Test 300/340. loss: 5.808, 0.2203 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:18:27 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2190, average loss: 5.7939
[09/28 06:18:28 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.09	top5: 7.95	
[09/28 06:18:28 visual_prompt]: Best epoch 3: best metric: 0.010
[09/28 06:18:28 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[09/28 06:18:38 visual_prompt]: Epoch 4 / 100: avg data time: 1.22e-01, avg batch time: 0.5793, average train loss: 5.6091
[09/28 06:18:42 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1691, average loss: 5.4714
[09/28 06:18:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 1.00	top5: 5.00	
[09/28 06:19:06 visual_prompt]: 	Test 100/340. loss: 5.718, 0.2176 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 06:19:28 visual_prompt]: 	Test 200/340. loss: 5.858, 0.2191 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 06:19:50 visual_prompt]: 	Test 300/340. loss: 5.810, 0.2206 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 06:20:01 visual_prompt]: Inference (test):avg data time: 3.20e-05, avg batch time: 0.2192, average loss: 5.8064
[09/28 06:20:01 visual_prompt]: Classification results with test_vtab-sun397: top1: 1.12	top5: 7.71	
[09/28 06:20:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[09/28 06:20:12 visual_prompt]: Epoch 5 / 100: avg data time: 1.25e-01, avg batch time: 0.5825, average train loss: 5.4126
[09/28 06:20:15 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.1692, average loss: 4.9305
[09/28 06:20:15 visual_prompt]: Classification results with val_vtab-sun397: top1: 3.50	top5: 22.50	
[09/28 06:20:39 visual_prompt]: 	Test 100/340. loss: 5.333, 0.2185 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 06:21:01 visual_prompt]: 	Test 200/340. loss: 5.621, 0.2198 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 06:21:23 visual_prompt]: 	Test 300/340. loss: 5.502, 0.2191 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 06:21:33 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2191, average loss: 5.4406
[09/28 06:21:34 visual_prompt]: Classification results with test_vtab-sun397: top1: 2.92	top5: 14.78	
[09/28 06:21:34 visual_prompt]: Best epoch 5: best metric: 0.035
[09/28 06:21:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[09/28 06:21:44 visual_prompt]: Epoch 6 / 100: avg data time: 1.18e-01, avg batch time: 0.5758, average train loss: 5.0452
[09/28 06:21:48 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1694, average loss: 4.4799
[09/28 06:21:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 14.00	top5: 28.00	
[09/28 06:22:12 visual_prompt]: 	Test 100/340. loss: 5.343, 0.2190 s / batch. (data: 2.26e-05)max mem: 7.82369 GB 
[09/28 06:22:34 visual_prompt]: 	Test 200/340. loss: 5.807, 0.2197 s / batch. (data: 6.63e-05)max mem: 7.82369 GB 
[09/28 06:22:56 visual_prompt]: 	Test 300/340. loss: 5.502, 0.2199 s / batch. (data: 3.24e-05)max mem: 7.82369 GB 
[09/28 06:23:06 visual_prompt]: Inference (test):avg data time: 6.62e-05, avg batch time: 0.2193, average loss: 5.3376
[09/28 06:23:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 8.35	top5: 18.27	
[09/28 06:23:07 visual_prompt]: Best epoch 6: best metric: 0.140
[09/28 06:23:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[09/28 06:23:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.13e-01, avg batch time: 0.5727, average train loss: 4.2338
[09/28 06:23:22 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.1691, average loss: 3.2726
[09/28 06:23:22 visual_prompt]: Classification results with val_vtab-sun397: top1: 35.50	top5: 62.50	
[09/28 06:23:46 visual_prompt]: 	Test 100/340. loss: 4.536, 0.2188 s / batch. (data: 2.91e-05)max mem: 7.82369 GB 
[09/28 06:24:08 visual_prompt]: 	Test 200/340. loss: 4.660, 0.2201 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 06:24:30 visual_prompt]: 	Test 300/340. loss: 4.685, 0.2201 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 06:24:40 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2191, average loss: 4.7128
[09/28 06:24:41 visual_prompt]: Classification results with test_vtab-sun397: top1: 14.70	top5: 32.15	
[09/28 06:24:41 visual_prompt]: Best epoch 7: best metric: 0.355
[09/28 06:24:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[09/28 06:24:51 visual_prompt]: Epoch 8 / 100: avg data time: 1.22e-01, avg batch time: 0.5800, average train loss: 2.9868
[09/28 06:24:55 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1696, average loss: 1.4334
[09/28 06:24:55 visual_prompt]: Classification results with val_vtab-sun397: top1: 68.50	top5: 92.50	
[09/28 06:25:19 visual_prompt]: 	Test 100/340. loss: 4.118, 0.2181 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 06:25:41 visual_prompt]: 	Test 200/340. loss: 4.633, 0.2193 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 06:26:03 visual_prompt]: 	Test 300/340. loss: 4.033, 0.2198 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 06:26:13 visual_prompt]: Inference (test):avg data time: 7.70e-05, avg batch time: 0.2192, average loss: 4.0523
[09/28 06:26:14 visual_prompt]: Classification results with test_vtab-sun397: top1: 29.28	top5: 50.49	
[09/28 06:26:14 visual_prompt]: Best epoch 8: best metric: 0.685
[09/28 06:26:14 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[09/28 06:26:24 visual_prompt]: Epoch 9 / 100: avg data time: 1.26e-01, avg batch time: 0.5842, average train loss: 1.8746
[09/28 06:26:28 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1696, average loss: 1.0881
[09/28 06:26:28 visual_prompt]: Classification results with val_vtab-sun397: top1: 78.00	top5: 97.50	
[09/28 06:26:52 visual_prompt]: 	Test 100/340. loss: 3.893, 0.2190 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 06:27:13 visual_prompt]: 	Test 200/340. loss: 4.983, 0.2189 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:27:35 visual_prompt]: 	Test 300/340. loss: 4.378, 0.2198 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 06:27:46 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2192, average loss: 3.9383
[09/28 06:27:46 visual_prompt]: Classification results with test_vtab-sun397: top1: 29.54	top5: 55.07	
[09/28 06:27:46 visual_prompt]: Best epoch 9: best metric: 0.780
[09/28 06:27:46 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[09/28 06:27:57 visual_prompt]: Epoch 10 / 100: avg data time: 1.16e-01, avg batch time: 0.5747, average train loss: 0.9905
[09/28 06:28:00 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.1694, average loss: 0.3285
[09/28 06:28:00 visual_prompt]: Classification results with val_vtab-sun397: top1: 94.00	top5: 100.00	
[09/28 06:28:24 visual_prompt]: 	Test 100/340. loss: 2.965, 0.2198 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 06:28:46 visual_prompt]: 	Test 200/340. loss: 3.764, 0.2198 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
[09/28 06:29:08 visual_prompt]: 	Test 300/340. loss: 3.330, 0.2195 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 06:29:19 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2192, average loss: 3.2195
[09/28 06:29:19 visual_prompt]: Classification results with test_vtab-sun397: top1: 37.65	top5: 63.82	
[09/28 06:29:19 visual_prompt]: Best epoch 10: best metric: 0.940
[09/28 06:29:19 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[09/28 06:29:30 visual_prompt]: Epoch 11 / 100: avg data time: 1.16e-01, avg batch time: 0.5744, average train loss: 0.4587
[09/28 06:29:33 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1694, average loss: 0.1918
[09/28 06:29:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 06:29:57 visual_prompt]: 	Test 100/340. loss: 2.823, 0.2196 s / batch. (data: 2.48e-05)max mem: 7.82369 GB 
[09/28 06:30:19 visual_prompt]: 	Test 200/340. loss: 3.232, 0.2189 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 06:30:41 visual_prompt]: 	Test 300/340. loss: 3.128, 0.2202 s / batch. (data: 3.03e-05)max mem: 7.82369 GB 
[09/28 06:30:51 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2192, average loss: 3.0475
[09/28 06:30:52 visual_prompt]: Classification results with test_vtab-sun397: top1: 41.44	top5: 67.66	
[09/28 06:30:52 visual_prompt]: Best epoch 11: best metric: 0.995
[09/28 06:30:52 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[09/28 06:31:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.15e-01, avg batch time: 0.5739, average train loss: 0.4488
[09/28 06:31:06 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1694, average loss: 0.3455
[09/28 06:31:06 visual_prompt]: Classification results with val_vtab-sun397: top1: 96.00	top5: 99.50	
[09/28 06:31:30 visual_prompt]: 	Test 100/340. loss: 2.897, 0.2197 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:31:52 visual_prompt]: 	Test 200/340. loss: 3.201, 0.2194 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 06:32:14 visual_prompt]: 	Test 300/340. loss: 3.173, 0.2193 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 06:32:25 visual_prompt]: Inference (test):avg data time: 3.19e-05, avg batch time: 0.2191, average loss: 3.1174
[09/28 06:32:25 visual_prompt]: Classification results with test_vtab-sun397: top1: 40.26	top5: 66.66	
[09/28 06:32:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[09/28 06:32:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.24e-01, avg batch time: 0.5813, average train loss: 0.4124
[09/28 06:32:39 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.1694, average loss: 0.1901
[09/28 06:32:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 06:33:03 visual_prompt]: 	Test 100/340. loss: 2.872, 0.2186 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 06:33:25 visual_prompt]: 	Test 200/340. loss: 3.317, 0.2212 s / batch. (data: 3.17e-05)max mem: 7.82369 GB 
[09/28 06:33:47 visual_prompt]: 	Test 300/340. loss: 3.039, 0.2198 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 06:33:57 visual_prompt]: Inference (test):avg data time: 3.25e-05, avg batch time: 0.2192, average loss: 2.9891
[09/28 06:33:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.47	top5: 69.48	
[09/28 06:33:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[09/28 06:34:08 visual_prompt]: Epoch 14 / 100: avg data time: 1.22e-01, avg batch time: 0.5799, average train loss: 0.3590
[09/28 06:34:12 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1697, average loss: 0.2270
[09/28 06:34:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 06:34:36 visual_prompt]: 	Test 100/340. loss: 2.666, 0.2197 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 06:34:58 visual_prompt]: 	Test 200/340. loss: 3.322, 0.2185 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 06:35:20 visual_prompt]: 	Test 300/340. loss: 2.796, 0.2193 s / batch. (data: 3.41e-05)max mem: 7.82369 GB 
[09/28 06:35:30 visual_prompt]: Inference (test):avg data time: 3.27e-05, avg batch time: 0.2193, average loss: 2.9770
[09/28 06:35:31 visual_prompt]: Classification results with test_vtab-sun397: top1: 43.76	top5: 69.36	
[09/28 06:35:31 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[09/28 06:35:42 visual_prompt]: Epoch 15 / 100: avg data time: 1.17e-01, avg batch time: 0.5748, average train loss: 0.3735
[09/28 06:35:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1693, average loss: 0.2173
[09/28 06:35:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 99.50	
[09/28 06:36:10 visual_prompt]: 	Test 100/340. loss: 2.715, 0.2195 s / batch. (data: 2.29e-05)max mem: 7.82369 GB 
[09/28 06:36:32 visual_prompt]: 	Test 200/340. loss: 3.100, 0.2200 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 06:36:54 visual_prompt]: 	Test 300/340. loss: 2.887, 0.2203 s / batch. (data: 3.91e-05)max mem: 7.82369 GB 
[09/28 06:37:04 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2191, average loss: 2.9176
[09/28 06:37:04 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.24	top5: 70.68	
[09/28 06:37:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[09/28 06:37:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.22e-01, avg batch time: 0.5794, average train loss: 0.4302
[09/28 06:37:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1694, average loss: 0.2086
[09/28 06:37:19 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:37:42 visual_prompt]: 	Test 100/340. loss: 2.683, 0.2185 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 06:38:04 visual_prompt]: 	Test 200/340. loss: 3.211, 0.2195 s / batch. (data: 6.70e-05)max mem: 7.82369 GB 
[09/28 06:38:26 visual_prompt]: 	Test 300/340. loss: 2.962, 0.2186 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 06:38:37 visual_prompt]: Inference (test):avg data time: 9.46e-05, avg batch time: 0.2193, average loss: 2.9397
[09/28 06:38:37 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.22	top5: 70.49	
[09/28 06:38:37 visual_prompt]: Best epoch 16: best metric: 1.000
[09/28 06:38:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[09/28 06:38:48 visual_prompt]: Epoch 17 / 100: avg data time: 1.17e-01, avg batch time: 0.5751, average train loss: 0.3516
[09/28 06:38:51 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1699, average loss: 0.1986
[09/28 06:38:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 100.00	
[09/28 06:39:15 visual_prompt]: 	Test 100/340. loss: 2.541, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:39:37 visual_prompt]: 	Test 200/340. loss: 3.277, 0.2192 s / batch. (data: 2.93e-05)max mem: 7.82369 GB 
[09/28 06:39:59 visual_prompt]: 	Test 300/340. loss: 2.880, 0.2206 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 06:40:11 visual_prompt]: Inference (test):avg data time: 3.34e-05, avg batch time: 0.2192, average loss: 2.8776
[09/28 06:40:11 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.12	top5: 70.82	
[09/28 06:40:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[09/28 06:40:22 visual_prompt]: Epoch 18 / 100: avg data time: 1.14e-01, avg batch time: 0.5720, average train loss: 0.9603
[09/28 06:40:25 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1694, average loss: 1.3571
[09/28 06:40:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 82.00	top5: 98.00	
[09/28 06:40:49 visual_prompt]: 	Test 100/340. loss: 3.513, 0.2183 s / batch. (data: 2.26e-05)max mem: 7.82369 GB 
[09/28 06:41:11 visual_prompt]: 	Test 200/340. loss: 3.813, 0.2181 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 06:41:33 visual_prompt]: 	Test 300/340. loss: 3.688, 0.2199 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 06:41:43 visual_prompt]: Inference (test):avg data time: 1.49e-04, avg batch time: 0.2193, average loss: 3.7144
[09/28 06:41:44 visual_prompt]: Classification results with test_vtab-sun397: top1: 31.26	top5: 56.15	
[09/28 06:41:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[09/28 06:41:54 visual_prompt]: Epoch 19 / 100: avg data time: 1.18e-01, avg batch time: 0.5761, average train loss: 0.6342
[09/28 06:41:58 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1696, average loss: 0.1393
[09/28 06:41:58 visual_prompt]: Classification results with val_vtab-sun397: top1: 97.50	top5: 100.00	
[09/28 06:42:22 visual_prompt]: 	Test 100/340. loss: 2.772, 0.2185 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:42:44 visual_prompt]: 	Test 200/340. loss: 3.257, 0.2189 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 06:43:06 visual_prompt]: 	Test 300/340. loss: 2.739, 0.2196 s / batch. (data: 9.13e-05)max mem: 7.82369 GB 
[09/28 06:43:16 visual_prompt]: Inference (test):avg data time: 3.52e-05, avg batch time: 0.2193, average loss: 2.8831
[09/28 06:43:17 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.74	top5: 70.41	
[09/28 06:43:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[09/28 06:43:27 visual_prompt]: Epoch 20 / 100: avg data time: 1.12e-01, avg batch time: 0.5707, average train loss: 0.2783
[09/28 06:43:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1697, average loss: 0.1477
[09/28 06:43:32 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 06:43:57 visual_prompt]: 	Test 100/340. loss: 2.573, 0.2196 s / batch. (data: 3.89e-04)max mem: 7.82369 GB 
[09/28 06:44:19 visual_prompt]: 	Test 200/340. loss: 3.178, 0.2193 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 06:44:41 visual_prompt]: 	Test 300/340. loss: 2.880, 0.2192 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 06:44:51 visual_prompt]: Inference (test):avg data time: 4.52e-05, avg batch time: 0.2191, average loss: 2.8841
[09/28 06:44:51 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.10	top5: 71.33	
[09/28 06:44:51 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[09/28 06:45:02 visual_prompt]: Epoch 21 / 100: avg data time: 1.05e-01, avg batch time: 0.5635, average train loss: 0.3069
[09/28 06:45:05 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1695, average loss: 0.1923
[09/28 06:45:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 98.50	top5: 100.00	
[09/28 06:45:29 visual_prompt]: 	Test 100/340. loss: 2.626, 0.2201 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:45:51 visual_prompt]: 	Test 200/340. loss: 3.148, 0.2197 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 06:46:13 visual_prompt]: 	Test 300/340. loss: 2.757, 0.2204 s / batch. (data: 3.10e-05)max mem: 7.82369 GB 
[09/28 06:46:24 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2192, average loss: 2.8638
[09/28 06:46:24 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.25	top5: 72.16	
[09/28 06:46:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[09/28 06:46:35 visual_prompt]: Epoch 22 / 100: avg data time: 1.24e-01, avg batch time: 0.5816, average train loss: 3.4923
[09/28 06:46:38 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1696, average loss: 3.7902
[09/28 06:46:38 visual_prompt]: Classification results with val_vtab-sun397: top1: 26.00	top5: 48.50	
[09/28 06:47:13 visual_prompt]: 	Test 100/340. loss: 5.080, 0.2156 s / batch. (data: 3.00e-05)max mem: 7.82369 GB 
[09/28 06:47:41 visual_prompt]: 	Test 200/340. loss: 5.016, 0.2172 s / batch. (data: 2.26e-05)max mem: 7.82369 GB 
[09/28 06:48:03 visual_prompt]: 	Test 300/340. loss: 5.100, 0.2176 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 06:48:14 visual_prompt]: Inference (test):avg data time: 1.26e-04, avg batch time: 0.2199, average loss: 5.0559
[09/28 06:48:14 visual_prompt]: Classification results with test_vtab-sun397: top1: 12.21	top5: 25.58	
[09/28 06:48:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[09/28 06:48:25 visual_prompt]: Epoch 23 / 100: avg data time: 1.19e-01, avg batch time: 0.5769, average train loss: 2.2529
[09/28 06:48:29 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1689, average loss: 0.6291
[09/28 06:48:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 90.50	top5: 99.00	
[09/28 06:49:14 visual_prompt]: 	Test 100/340. loss: 3.210, 0.2179 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 06:49:44 visual_prompt]: 	Test 200/340. loss: 3.755, 0.2376 s / batch. (data: 3.05e-05)max mem: 7.82369 GB 
[09/28 06:50:06 visual_prompt]: 	Test 300/340. loss: 3.237, 0.2183 s / batch. (data: 6.75e-05)max mem: 7.82369 GB 
[09/28 06:50:17 visual_prompt]: Inference (test):avg data time: 1.58e-03, avg batch time: 0.2928, average loss: 3.3062
[09/28 06:50:17 visual_prompt]: Classification results with test_vtab-sun397: top1: 38.46	top5: 63.05	
[09/28 06:50:17 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[09/28 06:50:28 visual_prompt]: Epoch 24 / 100: avg data time: 1.17e-01, avg batch time: 0.5722, average train loss: 0.6054
[09/28 06:50:31 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1687, average loss: 0.3640
[09/28 06:50:31 visual_prompt]: Classification results with val_vtab-sun397: top1: 94.50	top5: 100.00	
[09/28 06:50:55 visual_prompt]: 	Test 100/340. loss: 3.315, 0.2174 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:51:17 visual_prompt]: 	Test 200/340. loss: 3.782, 0.2199 s / batch. (data: 7.01e-05)max mem: 7.82369 GB 
[09/28 06:51:39 visual_prompt]: 	Test 300/340. loss: 3.285, 0.2193 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 06:51:49 visual_prompt]: Inference (test):avg data time: 4.36e-05, avg batch time: 0.2187, average loss: 3.2958
[09/28 06:51:49 visual_prompt]: Classification results with test_vtab-sun397: top1: 37.91	top5: 63.91	
[09/28 06:51:49 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[09/28 06:52:00 visual_prompt]: Epoch 25 / 100: avg data time: 1.20e-01, avg batch time: 0.5789, average train loss: 0.3391
[09/28 06:52:03 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1693, average loss: 0.1380
[09/28 06:52:03 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:52:27 visual_prompt]: 	Test 100/340. loss: 2.860, 0.2176 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 06:52:49 visual_prompt]: 	Test 200/340. loss: 3.094, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 06:53:11 visual_prompt]: 	Test 300/340. loss: 2.939, 0.2189 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 06:53:21 visual_prompt]: Inference (test):avg data time: 3.24e-05, avg batch time: 0.2190, average loss: 2.9552
[09/28 06:53:21 visual_prompt]: Classification results with test_vtab-sun397: top1: 44.91	top5: 70.40	
[09/28 06:53:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[09/28 06:53:32 visual_prompt]: Epoch 26 / 100: avg data time: 1.09e-01, avg batch time: 0.5679, average train loss: 0.2577
[09/28 06:53:35 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1697, average loss: 0.1588
[09/28 06:53:35 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:53:59 visual_prompt]: 	Test 100/340. loss: 2.639, 0.2186 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 06:54:21 visual_prompt]: 	Test 200/340. loss: 3.078, 0.2204 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 06:54:43 visual_prompt]: 	Test 300/340. loss: 2.908, 0.2197 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 06:54:53 visual_prompt]: Inference (test):avg data time: 3.30e-05, avg batch time: 0.2193, average loss: 2.9087
[09/28 06:54:53 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.13	top5: 71.45	
[09/28 06:54:53 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[09/28 06:55:04 visual_prompt]: Epoch 27 / 100: avg data time: 1.25e-01, avg batch time: 0.5884, average train loss: 0.3080
[09/28 06:55:07 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1695, average loss: 0.1752
[09/28 06:55:07 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 06:55:31 visual_prompt]: 	Test 100/340. loss: 2.677, 0.2192 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:55:53 visual_prompt]: 	Test 200/340. loss: 3.175, 0.2198 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 06:56:15 visual_prompt]: 	Test 300/340. loss: 2.872, 0.2199 s / batch. (data: 8.37e-05)max mem: 7.82369 GB 
[09/28 06:56:25 visual_prompt]: Inference (test):avg data time: 3.79e-05, avg batch time: 0.2193, average loss: 2.9455
[09/28 06:56:26 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.96	top5: 71.72	
[09/28 06:56:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[09/28 06:56:36 visual_prompt]: Epoch 28 / 100: avg data time: 1.13e-01, avg batch time: 0.5700, average train loss: 0.2956
[09/28 06:56:39 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.1698, average loss: 0.1700
[09/28 06:56:39 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 06:57:03 visual_prompt]: 	Test 100/340. loss: 2.591, 0.2193 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 06:57:25 visual_prompt]: 	Test 200/340. loss: 3.296, 0.2194 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 06:57:47 visual_prompt]: 	Test 300/340. loss: 2.887, 0.2196 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 06:57:57 visual_prompt]: Inference (test):avg data time: 3.39e-05, avg batch time: 0.2194, average loss: 2.8857
[09/28 06:57:58 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.44	top5: 72.09	
[09/28 06:57:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[09/28 06:58:08 visual_prompt]: Epoch 29 / 100: avg data time: 1.14e-01, avg batch time: 0.5716, average train loss: 0.3155
[09/28 06:58:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1698, average loss: 0.3163
[09/28 06:58:12 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 06:58:35 visual_prompt]: 	Test 100/340. loss: 2.755, 0.2191 s / batch. (data: 6.72e-05)max mem: 7.82369 GB 
[09/28 06:58:57 visual_prompt]: 	Test 200/340. loss: 3.190, 0.2190 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 06:59:19 visual_prompt]: 	Test 300/340. loss: 3.002, 0.2194 s / batch. (data: 4.20e-05)max mem: 7.82369 GB 
[09/28 06:59:30 visual_prompt]: Inference (test):avg data time: 3.68e-05, avg batch time: 0.2192, average loss: 2.9841
[09/28 06:59:30 visual_prompt]: Classification results with test_vtab-sun397: top1: 45.89	top5: 70.28	
[09/28 06:59:30 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[09/28 06:59:41 visual_prompt]: Epoch 30 / 100: avg data time: 1.23e-01, avg batch time: 0.5827, average train loss: 0.3224
[09/28 06:59:44 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1699, average loss: 0.2382
[09/28 06:59:44 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 07:00:08 visual_prompt]: 	Test 100/340. loss: 2.638, 0.2193 s / batch. (data: 7.41e-05)max mem: 7.82369 GB 
[09/28 07:00:30 visual_prompt]: 	Test 200/340. loss: 3.342, 0.2201 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 07:00:52 visual_prompt]: 	Test 300/340. loss: 2.930, 0.2205 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 07:01:02 visual_prompt]: Inference (test):avg data time: 3.31e-05, avg batch time: 0.2192, average loss: 2.9671
[09/28 07:01:02 visual_prompt]: Classification results with test_vtab-sun397: top1: 46.76	top5: 71.73	
[09/28 07:01:02 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[09/28 07:01:13 visual_prompt]: Epoch 31 / 100: avg data time: 1.08e-01, avg batch time: 0.5675, average train loss: 0.3759
[09/28 07:01:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.1698, average loss: 0.2866
[09/28 07:01:16 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 07:01:40 visual_prompt]: 	Test 100/340. loss: 2.813, 0.2205 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 07:02:02 visual_prompt]: 	Test 200/340. loss: 3.210, 0.2192 s / batch. (data: 2.55e-05)max mem: 7.82369 GB 
[09/28 07:02:24 visual_prompt]: 	Test 300/340. loss: 2.932, 0.2200 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 07:02:34 visual_prompt]: Inference (test):avg data time: 3.33e-05, avg batch time: 0.2193, average loss: 2.9615
[09/28 07:02:34 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.37	top5: 71.89	
[09/28 07:02:34 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[09/28 07:02:45 visual_prompt]: Epoch 32 / 100: avg data time: 1.18e-01, avg batch time: 0.5769, average train loss: 0.3414
[09/28 07:02:48 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1696, average loss: 0.1194
[09/28 07:02:48 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:03:12 visual_prompt]: 	Test 100/340. loss: 2.655, 0.2192 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 07:03:34 visual_prompt]: 	Test 200/340. loss: 3.223, 0.2203 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 07:03:56 visual_prompt]: 	Test 300/340. loss: 2.761, 0.2201 s / batch. (data: 9.61e-05)max mem: 7.82369 GB 
[09/28 07:04:06 visual_prompt]: Inference (test):avg data time: 3.58e-05, avg batch time: 0.2193, average loss: 2.8809
[09/28 07:04:07 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.00	top5: 71.96	
[09/28 07:04:07 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[09/28 07:04:17 visual_prompt]: Epoch 33 / 100: avg data time: 1.15e-01, avg batch time: 0.5735, average train loss: 0.5767
[09/28 07:04:21 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1699, average loss: 0.1538
[09/28 07:04:21 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:04:44 visual_prompt]: 	Test 100/340. loss: 2.542, 0.2194 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 07:05:06 visual_prompt]: 	Test 200/340. loss: 3.130, 0.2204 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 07:05:28 visual_prompt]: 	Test 300/340. loss: 2.821, 0.2201 s / batch. (data: 2.79e-05)max mem: 7.82369 GB 
[09/28 07:05:39 visual_prompt]: Inference (test):avg data time: 5.95e-05, avg batch time: 0.2193, average loss: 2.8779
[09/28 07:05:39 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.36	top5: 72.85	
[09/28 07:05:39 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[09/28 07:05:49 visual_prompt]: Epoch 34 / 100: avg data time: 1.04e-01, avg batch time: 0.5622, average train loss: 0.2465
[09/28 07:05:53 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1697, average loss: 0.1542
[09/28 07:05:53 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 07:06:16 visual_prompt]: 	Test 100/340. loss: 2.552, 0.2187 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 07:06:38 visual_prompt]: 	Test 200/340. loss: 3.148, 0.2184 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 07:07:00 visual_prompt]: 	Test 300/340. loss: 2.776, 0.2198 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 07:07:11 visual_prompt]: Inference (test):avg data time: 4.29e-05, avg batch time: 0.2193, average loss: 2.8484
[09/28 07:07:11 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.27	top5: 73.30	
[09/28 07:07:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[09/28 07:07:21 visual_prompt]: Epoch 35 / 100: avg data time: 1.08e-01, avg batch time: 0.5677, average train loss: 0.2582
[09/28 07:07:25 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1697, average loss: 0.1384
[09/28 07:07:25 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:07:48 visual_prompt]: 	Test 100/340. loss: 2.644, 0.2203 s / batch. (data: 2.60e-05)max mem: 7.82369 GB 
[09/28 07:08:10 visual_prompt]: 	Test 200/340. loss: 3.105, 0.2191 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 07:08:32 visual_prompt]: 	Test 300/340. loss: 2.718, 0.2185 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 07:08:43 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2192, average loss: 2.8423
[09/28 07:08:43 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.42	top5: 73.50	
[09/28 07:08:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[09/28 07:08:53 visual_prompt]: Epoch 36 / 100: avg data time: 1.11e-01, avg batch time: 0.5693, average train loss: 0.2439
[09/28 07:08:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1695, average loss: 0.1638
[09/28 07:08:57 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 07:09:21 visual_prompt]: 	Test 100/340. loss: 2.606, 0.2197 s / batch. (data: 2.86e-05)max mem: 7.82369 GB 
[09/28 07:09:43 visual_prompt]: 	Test 200/340. loss: 3.089, 0.2194 s / batch. (data: 2.69e-05)max mem: 7.82369 GB 
[09/28 07:10:05 visual_prompt]: 	Test 300/340. loss: 2.747, 0.2192 s / batch. (data: 5.22e-05)max mem: 7.82369 GB 
[09/28 07:10:15 visual_prompt]: Inference (test):avg data time: 3.93e-05, avg batch time: 0.2193, average loss: 2.8650
[09/28 07:10:15 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.09	top5: 73.05	
[09/28 07:10:15 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[09/28 07:10:25 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e-01, avg batch time: 0.5635, average train loss: 0.2511
[09/28 07:10:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1693, average loss: 0.1639
[09/28 07:10:29 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 07:10:52 visual_prompt]: 	Test 100/340. loss: 2.579, 0.2196 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 07:11:14 visual_prompt]: 	Test 200/340. loss: 3.205, 0.2198 s / batch. (data: 2.26e-05)max mem: 7.82369 GB 
[09/28 07:11:36 visual_prompt]: 	Test 300/340. loss: 2.937, 0.2189 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 07:11:47 visual_prompt]: Inference (test):avg data time: 3.36e-05, avg batch time: 0.2193, average loss: 2.8454
[09/28 07:11:47 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.53	top5: 73.69	
[09/28 07:11:47 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[09/28 07:11:58 visual_prompt]: Epoch 38 / 100: avg data time: 1.20e-01, avg batch time: 0.5768, average train loss: 0.3112
[09/28 07:12:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1698, average loss: 0.2681
[09/28 07:12:01 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 07:12:25 visual_prompt]: 	Test 100/340. loss: 2.707, 0.2196 s / batch. (data: 2.88e-05)max mem: 7.82369 GB 
[09/28 07:12:47 visual_prompt]: 	Test 200/340. loss: 3.157, 0.2196 s / batch. (data: 8.20e-05)max mem: 7.82369 GB 
[09/28 07:13:09 visual_prompt]: 	Test 300/340. loss: 2.894, 0.2197 s / batch. (data: 9.06e-05)max mem: 7.82369 GB 
[09/28 07:13:19 visual_prompt]: Inference (test):avg data time: 3.57e-05, avg batch time: 0.2192, average loss: 2.9248
[09/28 07:13:19 visual_prompt]: Classification results with test_vtab-sun397: top1: 47.60	top5: 72.75	
[09/28 07:13:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[09/28 07:13:30 visual_prompt]: Epoch 39 / 100: avg data time: 1.09e-01, avg batch time: 0.5664, average train loss: 0.2743
[09/28 07:13:33 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1692, average loss: 0.1352
[09/28 07:13:33 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:13:57 visual_prompt]: 	Test 100/340. loss: 2.413, 0.2190 s / batch. (data: 6.56e-05)max mem: 7.82369 GB 
[09/28 07:14:19 visual_prompt]: 	Test 200/340. loss: 3.086, 0.2190 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 07:14:41 visual_prompt]: 	Test 300/340. loss: 2.692, 0.2195 s / batch. (data: 2.67e-05)max mem: 7.82369 GB 
[09/28 07:14:51 visual_prompt]: Inference (test):avg data time: 3.38e-05, avg batch time: 0.2193, average loss: 2.7995
[09/28 07:14:51 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.15	top5: 73.83	
[09/28 07:14:51 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[09/28 07:15:02 visual_prompt]: Epoch 40 / 100: avg data time: 1.16e-01, avg batch time: 0.5743, average train loss: 0.2203
[09/28 07:15:05 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1695, average loss: 0.1443
[09/28 07:15:05 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:15:29 visual_prompt]: 	Test 100/340. loss: 2.464, 0.2194 s / batch. (data: 3.53e-05)max mem: 7.82369 GB 
[09/28 07:15:51 visual_prompt]: 	Test 200/340. loss: 3.171, 0.2200 s / batch. (data: 6.72e-05)max mem: 7.82369 GB 
[09/28 07:16:13 visual_prompt]: 	Test 300/340. loss: 2.923, 0.2198 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 07:16:23 visual_prompt]: Inference (test):avg data time: 3.21e-05, avg batch time: 0.2193, average loss: 2.8268
[09/28 07:16:24 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.02	top5: 73.78	
[09/28 07:16:24 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[09/28 07:16:34 visual_prompt]: Epoch 41 / 100: avg data time: 1.16e-01, avg batch time: 0.5736, average train loss: 0.2213
[09/28 07:16:37 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.1696, average loss: 0.1453
[09/28 07:16:37 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.50	top5: 100.00	
[09/28 07:17:01 visual_prompt]: 	Test 100/340. loss: 2.525, 0.2187 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 07:17:23 visual_prompt]: 	Test 200/340. loss: 2.997, 0.2196 s / batch. (data: 9.11e-05)max mem: 7.82369 GB 
[09/28 07:17:45 visual_prompt]: 	Test 300/340. loss: 2.759, 0.2188 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 07:17:55 visual_prompt]: Inference (test):avg data time: 7.32e-05, avg batch time: 0.2194, average loss: 2.8121
[09/28 07:17:56 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.38	top5: 74.64	
[09/28 07:17:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[09/28 07:18:06 visual_prompt]: Epoch 42 / 100: avg data time: 1.11e-01, avg batch time: 0.5696, average train loss: 0.3065
[09/28 07:18:09 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1699, average loss: 0.1435
[09/28 07:18:09 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:18:33 visual_prompt]: 	Test 100/340. loss: 2.484, 0.2195 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 07:18:55 visual_prompt]: 	Test 200/340. loss: 3.000, 0.2196 s / batch. (data: 2.62e-05)max mem: 7.82369 GB 
[09/28 07:19:17 visual_prompt]: 	Test 300/340. loss: 2.732, 0.2204 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 07:19:27 visual_prompt]: Inference (test):avg data time: 3.15e-05, avg batch time: 0.2193, average loss: 2.8062
[09/28 07:19:28 visual_prompt]: Classification results with test_vtab-sun397: top1: 50.81	top5: 74.00	
[09/28 07:19:28 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[09/28 07:19:38 visual_prompt]: Epoch 43 / 100: avg data time: 1.04e-01, avg batch time: 0.5624, average train loss: 0.2193
[09/28 07:19:42 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1697, average loss: 0.1234
[09/28 07:19:42 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:20:05 visual_prompt]: 	Test 100/340. loss: 2.445, 0.2192 s / batch. (data: 2.84e-05)max mem: 7.82369 GB 
[09/28 07:20:27 visual_prompt]: 	Test 200/340. loss: 3.055, 0.2198 s / batch. (data: 2.50e-05)max mem: 7.82369 GB 
[09/28 07:20:49 visual_prompt]: 	Test 300/340. loss: 2.731, 0.2198 s / batch. (data: 2.57e-05)max mem: 7.82369 GB 
[09/28 07:20:59 visual_prompt]: Inference (test):avg data time: 3.26e-05, avg batch time: 0.2193, average loss: 2.7812
[09/28 07:21:00 visual_prompt]: Classification results with test_vtab-sun397: top1: 51.34	top5: 74.28	
[09/28 07:21:00 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[09/28 07:21:10 visual_prompt]: Epoch 44 / 100: avg data time: 1.08e-01, avg batch time: 0.5661, average train loss: 1.1138
[09/28 07:21:14 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1699, average loss: 2.3345
[09/28 07:21:14 visual_prompt]: Classification results with val_vtab-sun397: top1: 53.50	top5: 87.00	
[09/28 07:21:37 visual_prompt]: 	Test 100/340. loss: 4.157, 0.2181 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 07:21:59 visual_prompt]: 	Test 200/340. loss: 4.054, 0.2192 s / batch. (data: 2.46e-05)max mem: 7.82369 GB 
[09/28 07:22:21 visual_prompt]: 	Test 300/340. loss: 4.127, 0.2190 s / batch. (data: 2.77e-05)max mem: 7.82369 GB 
[09/28 07:22:32 visual_prompt]: Inference (test):avg data time: 3.45e-05, avg batch time: 0.2192, average loss: 4.1160
[09/28 07:22:32 visual_prompt]: Classification results with test_vtab-sun397: top1: 24.84	top5: 50.76	
[09/28 07:22:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[09/28 07:22:42 visual_prompt]: Epoch 45 / 100: avg data time: 1.07e-01, avg batch time: 0.5650, average train loss: 1.2166
[09/28 07:22:46 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1695, average loss: 0.1770
[09/28 07:22:46 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 07:23:10 visual_prompt]: 	Test 100/340. loss: 2.455, 0.2202 s / batch. (data: 2.74e-05)max mem: 7.82369 GB 
[09/28 07:23:32 visual_prompt]: 	Test 200/340. loss: 3.154, 0.2196 s / batch. (data: 3.12e-05)max mem: 7.82369 GB 
[09/28 07:23:54 visual_prompt]: 	Test 300/340. loss: 2.905, 0.2185 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 07:24:04 visual_prompt]: Inference (test):avg data time: 3.76e-05, avg batch time: 0.2193, average loss: 2.8641
[09/28 07:24:04 visual_prompt]: Classification results with test_vtab-sun397: top1: 48.45	top5: 71.83	
[09/28 07:24:04 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[09/28 07:24:15 visual_prompt]: Epoch 46 / 100: avg data time: 1.16e-01, avg batch time: 0.5736, average train loss: 0.2434
[09/28 07:24:18 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1700, average loss: 0.1328
[09/28 07:24:18 visual_prompt]: Classification results with val_vtab-sun397: top1: 99.00	top5: 100.00	
[09/28 07:24:42 visual_prompt]: 	Test 100/340. loss: 2.670, 0.2194 s / batch. (data: 2.53e-05)max mem: 7.82369 GB 
[09/28 07:25:04 visual_prompt]: 	Test 200/340. loss: 2.955, 0.2192 s / batch. (data: 8.94e-05)max mem: 7.82369 GB 
[09/28 07:25:26 visual_prompt]: 	Test 300/340. loss: 2.834, 0.2192 s / batch. (data: 2.72e-05)max mem: 7.82369 GB 
[09/28 07:25:36 visual_prompt]: Inference (test):avg data time: 3.35e-05, avg batch time: 0.2193, average loss: 2.8085
[09/28 07:25:37 visual_prompt]: Classification results with test_vtab-sun397: top1: 49.17	top5: 73.15	
[09/28 07:25:37 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[09/28 07:25:47 visual_prompt]: Epoch 47 / 100: avg data time: 1.14e-01, avg batch time: 0.5709, average train loss: 0.1770
[09/28 07:25:51 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1696, average loss: 0.1208
[09/28 07:25:51 visual_prompt]: Classification results with val_vtab-sun397: top1: 100.00	top5: 100.00	
[09/28 07:26:14 visual_prompt]: 	Test 100/340. loss: 2.505, 0.2195 s / batch. (data: 3.15e-05)max mem: 7.82369 GB 
[09/28 07:26:36 visual_prompt]: 	Test 200/340. loss: 3.041, 0.2199 s / batch. (data: 2.65e-05)max mem: 7.82369 GB 
[09/28 07:26:58 visual_prompt]: 	Test 300/340. loss: 2.810, 0.2201 s / batch. (data: 2.81e-05)max mem: 7.82369 GB 
visual_prompt_tuning/experiments/vit_vtab.sh: line 41: 187355 Killed                  python visual_prompt_tuning/tune_vtab.py --config-file visual_prompt_tuning/configs/prompt/cub.yaml --train-type "prompt" MODEL.TYPE "vit" DATA.BATCH_SIZE "64" MODEL.PROMPT.NUM_TOKENS "50" MODEL.PROMPT.DEEP "True" MODEL.PROMPT.DROPOUT "0.1" DATA.FEATURE "sup_vitb16_imagenet21k" DATA.NAME "vtab-${dataset}" DATA.NUMBER_CLASSES "${num_classes}" DATA.CROPSIZE "224" MODEL.MODEL_ROOT "${model_root}" DATA.DATAPATH "${data_path}" OUTPUT_DIR "${output_dir}"
