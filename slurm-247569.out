/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 16:53:05 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 16:53:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 16:53:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 16:53:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 16:53:05 visual_prompt]: Training with config:
[11/13 16:53:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 16:53:05 visual_prompt]: Loading training data...
[11/13 16:53:05 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 16:53:05 visual_prompt]: Loading validation data...
[11/13 16:53:05 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 16:53:05 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/13 16:53:08 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/13 16:53:08 visual_prompt]: tuned percent:0.532
[11/13 16:53:08 visual_prompt]: Device used for model: 0
[11/13 16:53:08 visual_prompt]: Setting up Evaluator...
[11/13 16:53:08 visual_prompt]: Setting up Trainer...
[11/13 16:53:08 visual_prompt]: 	Setting up the optimizer...
[11/13 16:53:08 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 17:00:58 visual_prompt]: Epoch 1 / 100: avg data time: 5.22e+00, avg batch time: 6.7078, average train loss: 1.4863
[11/13 17:01:55 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.6023, average loss: 1.4553
[11/13 17:01:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/13 17:01:55 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/13 17:08:56 visual_prompt]: Epoch 2 / 100: avg data time: 4.53e+00, avg batch time: 6.0141, average train loss: 1.0889
[11/13 17:09:43 visual_prompt]: Inference (val):avg data time: 1.84e-05, avg batch time: 0.6015, average loss: 0.7247
[11/13 17:09:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/13 17:09:43 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/13 17:16:42 visual_prompt]: Epoch 3 / 100: avg data time: 4.50e+00, avg batch time: 5.9766, average train loss: 0.7219
[11/13 17:17:30 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5936, average loss: 0.8414
[11/13 17:17:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.48	
[11/13 17:17:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/13 17:24:34 visual_prompt]: Epoch 4 / 100: avg data time: 4.59e+00, avg batch time: 6.0649, average train loss: 0.7836
[11/13 17:25:23 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5929, average loss: 0.8061
[11/13 17:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/13 17:25:23 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/13 17:32:23 visual_prompt]: Epoch 5 / 100: avg data time: 4.52e+00, avg batch time: 5.9941, average train loss: 0.8177
[11/13 17:33:11 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5964, average loss: 0.6885
[11/13 17:33:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/13 17:33:11 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/13 17:40:12 visual_prompt]: Epoch 6 / 100: avg data time: 4.55e+00, avg batch time: 6.0205, average train loss: 0.7580
[11/13 17:41:00 visual_prompt]: Inference (val):avg data time: 1.96e-05, avg batch time: 0.5989, average loss: 0.6742
[11/13 17:41:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.82	
[11/13 17:41:00 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/13 17:47:58 visual_prompt]: Epoch 7 / 100: avg data time: 4.50e+00, avg batch time: 5.9751, average train loss: 0.7373
[11/13 17:48:46 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5911, average loss: 1.7252
[11/13 17:48:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.26	
[11/13 17:48:46 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/13 17:55:54 visual_prompt]: Epoch 8 / 100: avg data time: 4.62e+00, avg batch time: 6.1049, average train loss: 0.7694
[11/13 17:56:43 visual_prompt]: Inference (val):avg data time: 1.98e-05, avg batch time: 0.5994, average loss: 1.1083
[11/13 17:56:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.02	
[11/13 17:56:43 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/13 18:03:45 visual_prompt]: Epoch 9 / 100: avg data time: 4.55e+00, avg batch time: 6.0348, average train loss: 0.8029
[11/13 18:04:34 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5930, average loss: 0.6786
[11/13 18:04:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.02	
[11/13 18:04:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/13 18:11:41 visual_prompt]: Epoch 10 / 100: avg data time: 4.62e+00, avg batch time: 6.0943, average train loss: 0.7228
[11/13 18:12:29 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5935, average loss: 0.7685
[11/13 18:12:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[11/13 18:12:29 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/13 18:19:30 visual_prompt]: Epoch 11 / 100: avg data time: 4.53e+00, avg batch time: 6.0176, average train loss: 0.7622
[11/13 18:20:18 visual_prompt]: Inference (val):avg data time: 2.00e-05, avg batch time: 0.5966, average loss: 0.7761
[11/13 18:20:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.23	
[11/13 18:20:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/13 18:27:17 visual_prompt]: Epoch 12 / 100: avg data time: 4.51e+00, avg batch time: 5.9843, average train loss: 0.7614
[11/13 18:28:05 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5966, average loss: 0.7236
[11/13 18:28:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.74	
[11/13 18:28:05 visual_prompt]: Best epoch 12: best metric: -0.724
[11/13 18:28:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/13 18:35:07 visual_prompt]: Epoch 13 / 100: avg data time: 4.55e+00, avg batch time: 6.0261, average train loss: 0.7759
[11/13 18:35:55 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5959, average loss: 0.7158
[11/13 18:35:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/13 18:35:55 visual_prompt]: Best epoch 13: best metric: -0.716
[11/13 18:35:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/13 18:42:55 visual_prompt]: Epoch 14 / 100: avg data time: 4.53e+00, avg batch time: 5.9985, average train loss: 0.7538
[11/13 18:43:43 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5944, average loss: 0.7155
[11/13 18:43:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/13 18:43:43 visual_prompt]: Best epoch 14: best metric: -0.716
[11/13 18:43:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/13 18:50:47 visual_prompt]: Epoch 15 / 100: avg data time: 4.59e+00, avg batch time: 6.0530, average train loss: 0.7450
[11/13 18:51:36 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5862, average loss: 0.7131
[11/13 18:51:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/13 18:51:36 visual_prompt]: Best epoch 15: best metric: -0.713
[11/13 18:51:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/13 18:58:44 visual_prompt]: Epoch 16 / 100: avg data time: 4.65e+00, avg batch time: 6.1048, average train loss: 0.7322
[11/13 18:59:33 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5886, average loss: 0.9053
[11/13 18:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/13 18:59:33 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/13 19:06:41 visual_prompt]: Epoch 17 / 100: avg data time: 4.66e+00, avg batch time: 6.1149, average train loss: 0.7835
[11/13 19:07:29 visual_prompt]: Inference (val):avg data time: 2.08e-05, avg batch time: 0.5855, average loss: 0.8792
[11/13 19:07:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.69	
[11/13 19:07:29 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/13 19:14:37 visual_prompt]: Epoch 18 / 100: avg data time: 4.65e+00, avg batch time: 6.1024, average train loss: 0.7829
[11/13 19:15:26 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5851, average loss: 0.8792
[11/13 19:15:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.64	
[11/13 19:15:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/13 19:22:32 visual_prompt]: Epoch 19 / 100: avg data time: 4.64e+00, avg batch time: 6.0952, average train loss: 0.7793
[11/13 19:23:21 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5855, average loss: 0.7425
[11/13 19:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/13 19:23:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/13 19:30:29 visual_prompt]: Epoch 20 / 100: avg data time: 4.67e+00, avg batch time: 6.1190, average train loss: 0.7126
[11/13 19:31:18 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5886, average loss: 0.6826
[11/13 19:31:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/13 19:31:18 visual_prompt]: Best epoch 20: best metric: -0.683
[11/13 19:31:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/13 19:38:26 visual_prompt]: Epoch 21 / 100: avg data time: 4.65e+00, avg batch time: 6.1096, average train loss: 0.7119
[11/13 19:39:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5909, average loss: 0.6854
[11/13 19:39:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.80	
[11/13 19:39:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/13 19:46:23 visual_prompt]: Epoch 22 / 100: avg data time: 4.66e+00, avg batch time: 6.1146, average train loss: 0.7526
[11/13 19:47:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5893, average loss: 0.9010
[11/13 19:47:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/13 19:47:12 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/13 19:54:18 visual_prompt]: Epoch 23 / 100: avg data time: 4.64e+00, avg batch time: 6.0887, average train loss: 0.8169
[11/13 19:55:05 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5861, average loss: 0.8924
[11/13 19:55:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/13 19:55:05 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/13 20:02:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.21e+00, avg batch time: 6.6668, average train loss: 0.7557
[11/13 20:03:46 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5887, average loss: 0.6873
[11/13 20:03:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 62.08	
[11/13 20:03:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/13 20:12:47 visual_prompt]: Epoch 25 / 100: avg data time: 6.26e+00, avg batch time: 7.7196, average train loss: 0.7295
[11/13 20:13:49 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5838, average loss: 0.6772
[11/13 20:13:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.99	
[11/13 20:13:49 visual_prompt]: Best epoch 25: best metric: -0.677
[11/13 20:13:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/13 20:22:34 visual_prompt]: Epoch 26 / 100: avg data time: 6.04e+00, avg batch time: 7.4933, average train loss: 0.7363
[11/13 20:23:26 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5871, average loss: 0.7935
[11/13 20:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/13 20:23:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/13 20:30:43 visual_prompt]: Epoch 27 / 100: avg data time: 4.78e+00, avg batch time: 6.2337, average train loss: 0.7015
[11/13 20:31:32 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5823, average loss: 0.6977
[11/13 20:31:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 62.49	
[11/13 20:31:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/13 20:38:41 visual_prompt]: Epoch 28 / 100: avg data time: 4.68e+00, avg batch time: 6.1303, average train loss: 0.7252
[11/13 20:39:30 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5878, average loss: 0.6889
[11/13 20:39:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/13 20:39:30 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/13 20:46:38 visual_prompt]: Epoch 29 / 100: avg data time: 4.67e+00, avg batch time: 6.1219, average train loss: 0.7129
[11/13 20:47:27 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5899, average loss: 0.7465
[11/13 20:47:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/13 20:47:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/13 20:54:37 visual_prompt]: Epoch 30 / 100: avg data time: 4.69e+00, avg batch time: 6.1375, average train loss: 0.7191
[11/13 20:55:25 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5888, average loss: 0.8272
[11/13 20:55:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.31	
[11/13 20:55:25 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/13 21:02:32 visual_prompt]: Epoch 31 / 100: avg data time: 4.64e+00, avg batch time: 6.0950, average train loss: 0.7088
[11/13 21:03:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5877, average loss: 0.6902
[11/13 21:03:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.13	
[11/13 21:03:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/13 21:10:25 visual_prompt]: Epoch 32 / 100: avg data time: 4.62e+00, avg batch time: 6.0697, average train loss: 0.7403
[11/13 21:11:14 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5905, average loss: 0.8600
[11/13 21:11:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/13 21:11:14 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/13 21:18:22 visual_prompt]: Epoch 33 / 100: avg data time: 4.65e+00, avg batch time: 6.1072, average train loss: 0.7203
[11/13 21:19:11 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5864, average loss: 0.6888
[11/13 21:19:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.78	
[11/13 21:19:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/13 21:26:18 visual_prompt]: Epoch 34 / 100: avg data time: 4.65e+00, avg batch time: 6.1043, average train loss: 0.7136
[11/13 21:27:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5897, average loss: 0.6986
[11/13 21:27:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.36	
[11/13 21:27:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/13 21:34:13 visual_prompt]: Epoch 35 / 100: avg data time: 4.64e+00, avg batch time: 6.0946, average train loss: 0.7147
[11/13 21:35:02 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5873, average loss: 0.7499
[11/13 21:35:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/13 21:35:02 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/13 21:42:09 visual_prompt]: Epoch 36 / 100: avg data time: 4.64e+00, avg batch time: 6.0929, average train loss: 0.7125
[11/13 21:42:57 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5928, average loss: 0.6890
[11/13 21:42:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.34	
[11/13 21:42:57 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/13 21:50:03 visual_prompt]: Epoch 37 / 100: avg data time: 4.62e+00, avg batch time: 6.0774, average train loss: 0.7257
[11/13 21:50:51 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5883, average loss: 0.7514
[11/13 21:50:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/13 21:50:51 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/13 21:57:57 visual_prompt]: Epoch 38 / 100: avg data time: 4.63e+00, avg batch time: 6.0802, average train loss: 0.7024
[11/13 21:58:46 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5833, average loss: 0.6758
[11/13 21:58:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.01	
[11/13 21:58:46 visual_prompt]: Best epoch 38: best metric: -0.676
[11/13 21:58:46 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/13 22:05:51 visual_prompt]: Epoch 39 / 100: avg data time: 4.62e+00, avg batch time: 6.0763, average train loss: 0.7164
[11/13 22:06:40 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5894, average loss: 0.7275
[11/13 22:06:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[11/13 22:06:40 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/13 22:13:43 visual_prompt]: Epoch 40 / 100: avg data time: 4.60e+00, avg batch time: 6.0492, average train loss: 0.7100
[11/13 22:14:32 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5868, average loss: 0.7220
[11/13 22:14:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/13 22:14:32 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/13 22:21:40 visual_prompt]: Epoch 41 / 100: avg data time: 4.66e+00, avg batch time: 6.1128, average train loss: 0.7213
[11/13 22:22:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5862, average loss: 0.8634
[11/13 22:22:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/13 22:22:29 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/13 22:29:38 visual_prompt]: Epoch 42 / 100: avg data time: 4.67e+00, avg batch time: 6.1232, average train loss: 0.7201
[11/13 22:30:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5870, average loss: 0.6875
[11/13 22:30:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/13 22:30:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/13 22:37:36 visual_prompt]: Epoch 43 / 100: avg data time: 4.67e+00, avg batch time: 6.1270, average train loss: 0.7456
[11/13 22:38:24 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5913, average loss: 0.7035
[11/13 22:38:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.30	
[11/13 22:38:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/13 22:45:34 visual_prompt]: Epoch 44 / 100: avg data time: 4.69e+00, avg batch time: 6.1416, average train loss: 0.7153
[11/13 22:46:23 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5890, average loss: 0.6854
[11/13 22:46:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.85	
[11/13 22:46:23 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/13 22:53:31 visual_prompt]: Epoch 45 / 100: avg data time: 4.65e+00, avg batch time: 6.1044, average train loss: 0.7200
[11/13 22:54:19 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5889, average loss: 0.6873
[11/13 22:54:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[11/13 22:54:19 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/13 23:01:27 visual_prompt]: Epoch 46 / 100: avg data time: 4.65e+00, avg batch time: 6.1075, average train loss: 0.7171
[11/13 23:02:16 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5882, average loss: 0.7302
[11/13 23:02:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.67	
[11/13 23:02:16 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/13 23:09:22 visual_prompt]: Epoch 47 / 100: avg data time: 4.65e+00, avg batch time: 6.0966, average train loss: 0.7280
[11/13 23:10:11 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5845, average loss: 0.7229
[11/13 23:10:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.61	
[11/13 23:10:11 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/13 23:17:18 visual_prompt]: Epoch 48 / 100: avg data time: 4.64e+00, avg batch time: 6.0938, average train loss: 0.7174
[11/13 23:18:06 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5860, average loss: 0.6994
[11/13 23:18:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/13 23:18:06 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/13 23:25:14 visual_prompt]: Epoch 49 / 100: avg data time: 4.66e+00, avg batch time: 6.1134, average train loss: 0.7036
[11/13 23:26:03 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5930, average loss: 0.6869
[11/13 23:26:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.10	
[11/13 23:26:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/13 23:33:11 visual_prompt]: Epoch 50 / 100: avg data time: 4.67e+00, avg batch time: 6.1178, average train loss: 0.7272
[11/13 23:34:00 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5889, average loss: 0.9267
[11/13 23:34:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/13 23:34:00 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/13 23:41:07 visual_prompt]: Epoch 51 / 100: avg data time: 4.65e+00, avg batch time: 6.0986, average train loss: 0.7200
[11/13 23:41:56 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5943, average loss: 0.7696
[11/13 23:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.26	
[11/13 23:41:56 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/13 23:49:04 visual_prompt]: Epoch 52 / 100: avg data time: 4.66e+00, avg batch time: 6.1124, average train loss: 0.7037
[11/13 23:49:53 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5905, average loss: 0.7411
[11/13 23:49:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.82	
[11/13 23:49:53 visual_prompt]: Stopping early.
[11/13 23:49:53 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 23:49:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 23:49:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/13 23:49:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 23:49:53 visual_prompt]: Training with config:
[11/13 23:49:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 23:49:53 visual_prompt]: Loading training data...
[11/13 23:49:53 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 23:49:53 visual_prompt]: Loading validation data...
[11/13 23:49:53 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 23:49:53 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/13 23:49:58 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/13 23:49:58 visual_prompt]: tuned percent:0.532
[11/13 23:49:58 visual_prompt]: Device used for model: 0
[11/13 23:49:58 visual_prompt]: Setting up Evaluator...
[11/13 23:49:58 visual_prompt]: Setting up Trainer...
[11/13 23:49:58 visual_prompt]: 	Setting up the optimizer...
[11/13 23:49:58 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 23:57:07 visual_prompt]: Epoch 1 / 100: avg data time: 4.68e+00, avg batch time: 6.1296, average train loss: 1.4863
[11/13 23:57:56 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5867, average loss: 1.4553
[11/13 23:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/13 23:57:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/14 00:05:04 visual_prompt]: Epoch 2 / 100: avg data time: 4.66e+00, avg batch time: 6.1092, average train loss: 1.0902
[11/14 00:05:53 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5896, average loss: 0.7249
[11/14 00:05:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/14 00:05:53 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/14 00:12:59 visual_prompt]: Epoch 3 / 100: avg data time: 4.64e+00, avg batch time: 6.0936, average train loss: 0.7235
[11/14 00:13:48 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5889, average loss: 0.8395
[11/14 00:13:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.53	
[11/14 00:13:48 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/14 00:20:53 visual_prompt]: Epoch 4 / 100: avg data time: 4.62e+00, avg batch time: 6.0711, average train loss: 0.7893
[11/14 00:21:42 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5873, average loss: 0.8533
[11/14 00:21:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.83	
[11/14 00:21:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/14 00:28:48 visual_prompt]: Epoch 5 / 100: avg data time: 4.63e+00, avg batch time: 6.0874, average train loss: 0.8105
[11/14 00:29:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5851, average loss: 0.7082
[11/14 00:29:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/14 00:29:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/14 00:36:46 visual_prompt]: Epoch 6 / 100: avg data time: 4.69e+00, avg batch time: 6.1359, average train loss: 0.7664
[11/14 00:37:35 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5890, average loss: 0.6719
[11/14 00:37:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/14 00:37:35 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/14 00:44:43 visual_prompt]: Epoch 7 / 100: avg data time: 4.65e+00, avg batch time: 6.1048, average train loss: 0.7331
[11/14 00:45:32 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5860, average loss: 1.1880
[11/14 00:45:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.68	
[11/14 00:45:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/14 00:52:38 visual_prompt]: Epoch 8 / 100: avg data time: 4.63e+00, avg batch time: 6.0867, average train loss: 0.7783
[11/14 00:53:27 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5854, average loss: 1.4210
[11/14 00:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.70	
[11/14 00:53:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/14 01:00:35 visual_prompt]: Epoch 9 / 100: avg data time: 4.66e+00, avg batch time: 6.1160, average train loss: 0.8966
[11/14 01:01:24 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5858, average loss: 0.6636
[11/14 01:01:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.04	
[11/14 01:01:24 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/14 01:08:32 visual_prompt]: Epoch 10 / 100: avg data time: 4.67e+00, avg batch time: 6.1184, average train loss: 0.7290
[11/14 01:09:21 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5897, average loss: 0.8045
[11/14 01:09:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.91	
[11/14 01:09:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/14 01:16:29 visual_prompt]: Epoch 11 / 100: avg data time: 4.67e+00, avg batch time: 6.1152, average train loss: 0.7937
[11/14 01:17:18 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5845, average loss: 1.1487
[11/14 01:17:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.00	
[11/14 01:17:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/14 01:24:25 visual_prompt]: Epoch 12 / 100: avg data time: 4.65e+00, avg batch time: 6.1008, average train loss: 0.7618
[11/14 01:25:14 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5864, average loss: 0.6465
[11/14 01:25:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.15	
[11/14 01:25:14 visual_prompt]: Best epoch 12: best metric: -0.647
[11/14 01:25:14 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/14 01:32:21 visual_prompt]: Epoch 13 / 100: avg data time: 4.65e+00, avg batch time: 6.1028, average train loss: 0.7177
[11/14 01:33:10 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5882, average loss: 0.7420
[11/14 01:33:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.91	
[11/14 01:33:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/14 01:40:18 visual_prompt]: Epoch 14 / 100: avg data time: 4.66e+00, avg batch time: 6.1136, average train loss: 0.6855
[11/14 01:41:07 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5924, average loss: 0.7182
[11/14 01:41:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.02	
[11/14 01:41:07 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/14 01:48:15 visual_prompt]: Epoch 15 / 100: avg data time: 4.66e+00, avg batch time: 6.1078, average train loss: 0.7269
[11/14 01:49:03 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5901, average loss: 0.6450
[11/14 01:49:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/14 01:49:03 visual_prompt]: Best epoch 15: best metric: -0.645
[11/14 01:49:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/14 01:56:11 visual_prompt]: Epoch 16 / 100: avg data time: 4.66e+00, avg batch time: 6.1061, average train loss: 0.7688
[11/14 01:57:00 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5947, average loss: 0.7389
[11/14 01:57:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 65.84	
[11/14 01:57:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/14 02:04:08 visual_prompt]: Epoch 17 / 100: avg data time: 4.67e+00, avg batch time: 6.1229, average train loss: 0.7174
[11/14 02:04:57 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5876, average loss: 0.8170
[11/14 02:04:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.48	
[11/14 02:04:57 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/14 02:12:05 visual_prompt]: Epoch 18 / 100: avg data time: 4.66e+00, avg batch time: 6.1130, average train loss: 0.7280
[11/14 02:12:54 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5889, average loss: 1.0515
[11/14 02:12:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.65	
[11/14 02:12:54 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/14 02:20:01 visual_prompt]: Epoch 19 / 100: avg data time: 4.65e+00, avg batch time: 6.1010, average train loss: 0.7665
[11/14 02:20:50 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5879, average loss: 0.7208
[11/14 02:20:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.37	
[11/14 02:20:50 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/14 02:27:59 visual_prompt]: Epoch 20 / 100: avg data time: 4.68e+00, avg batch time: 6.1283, average train loss: 0.6482
[11/14 02:28:48 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5904, average loss: 0.6210
[11/14 02:28:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.19	
[11/14 02:28:48 visual_prompt]: Best epoch 20: best metric: -0.621
[11/14 02:28:48 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/14 02:35:56 visual_prompt]: Epoch 21 / 100: avg data time: 4.65e+00, avg batch time: 6.1077, average train loss: 0.6475
[11/14 02:36:45 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5893, average loss: 0.9763
[11/14 02:36:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 73.13	
[11/14 02:36:45 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/14 02:43:53 visual_prompt]: Epoch 22 / 100: avg data time: 4.66e+00, avg batch time: 6.1136, average train loss: 0.6757
[11/14 02:44:42 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5907, average loss: 0.8792
[11/14 02:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 73.96	
[11/14 02:44:42 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/14 02:51:48 visual_prompt]: Epoch 23 / 100: avg data time: 4.64e+00, avg batch time: 6.0905, average train loss: 0.6603
[11/14 02:52:37 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5844, average loss: 1.1808
[11/14 02:52:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.05	
[11/14 02:52:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/14 02:59:44 visual_prompt]: Epoch 24 / 100: avg data time: 4.65e+00, avg batch time: 6.0977, average train loss: 0.6834
[11/14 03:00:32 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5869, average loss: 0.6618
[11/14 03:00:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.24	
[11/14 03:00:32 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/14 03:07:42 visual_prompt]: Epoch 25 / 100: avg data time: 4.69e+00, avg batch time: 6.1413, average train loss: 0.6908
[11/14 03:08:31 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5895, average loss: 0.7300
[11/14 03:08:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 74.09	
[11/14 03:08:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/14 03:15:38 visual_prompt]: Epoch 26 / 100: avg data time: 4.66e+00, avg batch time: 6.1079, average train loss: 0.6515
[11/14 03:16:27 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5863, average loss: 0.6007
[11/14 03:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 73.94	
[11/14 03:16:27 visual_prompt]: Best epoch 26: best metric: -0.601
[11/14 03:16:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/14 03:23:34 visual_prompt]: Epoch 27 / 100: avg data time: 4.64e+00, avg batch time: 6.0923, average train loss: 0.6220
[11/14 03:24:23 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5850, average loss: 0.6727
[11/14 03:24:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 76.09	
[11/14 03:24:23 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/14 03:31:32 visual_prompt]: Epoch 28 / 100: avg data time: 4.68e+00, avg batch time: 6.1265, average train loss: 0.6932
[11/14 03:32:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5872, average loss: 0.7420
[11/14 03:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 75.80	
[11/14 03:32:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/14 03:39:27 visual_prompt]: Epoch 29 / 100: avg data time: 4.65e+00, avg batch time: 6.0978, average train loss: 0.6056
[11/14 03:40:15 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5864, average loss: 0.6275
[11/14 03:40:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 75.67	
[11/14 03:40:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/14 03:47:23 visual_prompt]: Epoch 30 / 100: avg data time: 4.66e+00, avg batch time: 6.1151, average train loss: 0.5842
[11/14 03:48:12 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5853, average loss: 1.5055
[11/14 03:48:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 72.48	
[11/14 03:48:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/14 03:55:19 visual_prompt]: Epoch 31 / 100: avg data time: 4.65e+00, avg batch time: 6.1015, average train loss: 0.6911
[11/14 03:56:09 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5889, average loss: 0.6117
[11/14 03:56:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.46	
[11/14 03:56:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/14 04:03:17 visual_prompt]: Epoch 32 / 100: avg data time: 4.67e+00, avg batch time: 6.1227, average train loss: 0.6841
[11/14 04:04:06 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5882, average loss: 1.1420
[11/14 04:04:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.26	
[11/14 04:04:06 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/14 04:11:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.66e+00, avg batch time: 6.1118, average train loss: 0.6362
[11/14 04:12:03 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5890, average loss: 0.6317
[11/14 04:12:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.48	
[11/14 04:12:03 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/14 04:19:09 visual_prompt]: Epoch 34 / 100: avg data time: 4.64e+00, avg batch time: 6.0936, average train loss: 0.6442
[11/14 04:19:58 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.5904, average loss: 0.6702
[11/14 04:19:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.03	
[11/14 04:19:58 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/14 04:27:03 visual_prompt]: Epoch 35 / 100: avg data time: 4.62e+00, avg batch time: 6.0695, average train loss: 0.5889
[11/14 04:27:51 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5884, average loss: 0.6170
[11/14 04:27:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 74.47	
[11/14 04:27:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/14 04:35:00 visual_prompt]: Epoch 36 / 100: avg data time: 4.67e+00, avg batch time: 6.1235, average train loss: 0.5843
[11/14 04:35:49 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5898, average loss: 1.2020
[11/14 04:35:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 74.43	
[11/14 04:35:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/14 04:42:57 visual_prompt]: Epoch 37 / 100: avg data time: 4.66e+00, avg batch time: 6.1116, average train loss: 0.6478
[11/14 04:43:45 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5840, average loss: 0.7317
[11/14 04:43:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.28	
[11/14 04:43:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/14 04:50:52 visual_prompt]: Epoch 38 / 100: avg data time: 4.64e+00, avg batch time: 6.0956, average train loss: 0.5724
[11/14 04:51:41 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5907, average loss: 0.6365
[11/14 04:51:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.94	
[11/14 04:51:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/14 04:58:49 visual_prompt]: Epoch 39 / 100: avg data time: 4.67e+00, avg batch time: 6.1178, average train loss: 0.5634
[11/14 04:59:38 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5858, average loss: 0.7090
[11/14 04:59:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.80	
[11/14 04:59:38 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/14 05:06:47 visual_prompt]: Epoch 40 / 100: avg data time: 4.67e+00, avg batch time: 6.1185, average train loss: 0.6224
[11/14 05:07:36 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5879, average loss: 0.9828
[11/14 05:07:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 73.65	
[11/14 05:07:36 visual_prompt]: Stopping early.
[11/14 05:07:36 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 05:07:36 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 05:07:36 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 05:07:36 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 05:07:36 visual_prompt]: Training with config:
[11/14 05:07:36 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 05:07:36 visual_prompt]: Loading training data...
[11/14 05:07:36 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 05:07:36 visual_prompt]: Loading validation data...
[11/14 05:07:36 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 05:07:36 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 05:07:38 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 05:07:38 visual_prompt]: tuned percent:0.532
[11/14 05:07:38 visual_prompt]: Device used for model: 0
[11/14 05:07:38 visual_prompt]: Setting up Evaluator...
[11/14 05:07:38 visual_prompt]: Setting up Trainer...
[11/14 05:07:38 visual_prompt]: 	Setting up the optimizer...
[11/14 05:07:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 05:14:48 visual_prompt]: Epoch 1 / 100: avg data time: 4.68e+00, avg batch time: 6.1300, average train loss: 1.4863
[11/14 05:15:36 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5856, average loss: 1.4553
[11/14 05:15:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 05:15:36 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/14 05:22:45 visual_prompt]: Epoch 2 / 100: avg data time: 4.67e+00, avg batch time: 6.1262, average train loss: 1.0903
[11/14 05:23:34 visual_prompt]: Inference (val):avg data time: 2.03e-05, avg batch time: 0.5883, average loss: 0.7250
[11/14 05:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[11/14 05:23:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/14 05:30:42 visual_prompt]: Epoch 3 / 100: avg data time: 4.66e+00, avg batch time: 6.1141, average train loss: 0.7237
[11/14 05:31:31 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5916, average loss: 0.8399
[11/14 05:31:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/14 05:31:31 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/14 05:38:38 visual_prompt]: Epoch 4 / 100: avg data time: 4.65e+00, avg batch time: 6.0981, average train loss: 0.7933
[11/14 05:39:27 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5863, average loss: 0.8096
[11/14 05:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/14 05:39:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/14 05:46:35 visual_prompt]: Epoch 5 / 100: avg data time: 4.66e+00, avg batch time: 6.1147, average train loss: 0.8336
[11/14 05:47:24 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5873, average loss: 0.6890
[11/14 05:47:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.67	
[11/14 05:47:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/14 05:54:31 visual_prompt]: Epoch 6 / 100: avg data time: 4.64e+00, avg batch time: 6.0959, average train loss: 0.7535
[11/14 05:55:20 visual_prompt]: Inference (val):avg data time: 2.24e-05, avg batch time: 0.5865, average loss: 0.6721
[11/14 05:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.13	
[11/14 05:55:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/14 06:02:26 visual_prompt]: Epoch 7 / 100: avg data time: 4.63e+00, avg batch time: 6.0836, average train loss: 0.7298
[11/14 06:03:14 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5890, average loss: 1.6587
[11/14 06:03:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[11/14 06:03:14 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/14 06:10:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.67e+00, avg batch time: 6.1219, average train loss: 0.7889
[11/14 06:11:12 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5875, average loss: 1.3869
[11/14 06:11:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.23	
[11/14 06:11:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/14 06:18:18 visual_prompt]: Epoch 9 / 100: avg data time: 4.63e+00, avg batch time: 6.0856, average train loss: 0.9032
[11/14 06:19:07 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5863, average loss: 0.6673
[11/14 06:19:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.27	
[11/14 06:19:07 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/14 06:26:14 visual_prompt]: Epoch 10 / 100: avg data time: 4.65e+00, avg batch time: 6.1002, average train loss: 0.7352
[11/14 06:27:03 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5872, average loss: 0.8182
[11/14 06:27:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/14 06:27:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/14 06:34:11 visual_prompt]: Epoch 11 / 100: avg data time: 4.66e+00, avg batch time: 6.1144, average train loss: 0.7594
[11/14 06:34:59 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5885, average loss: 1.1425
[11/14 06:34:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.76	
[11/14 06:34:59 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/14 06:42:07 visual_prompt]: Epoch 12 / 100: avg data time: 4.66e+00, avg batch time: 6.1093, average train loss: 0.7588
[11/14 06:42:56 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5874, average loss: 0.6451
[11/14 06:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.14	
[11/14 06:42:56 visual_prompt]: Best epoch 12: best metric: -0.645
[11/14 06:42:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/14 06:50:05 visual_prompt]: Epoch 13 / 100: avg data time: 4.67e+00, avg batch time: 6.1232, average train loss: 0.7121
[11/14 06:50:54 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5881, average loss: 0.7472
[11/14 06:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/14 06:50:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/14 06:58:03 visual_prompt]: Epoch 14 / 100: avg data time: 4.68e+00, avg batch time: 6.1287, average train loss: 0.6895
[11/14 06:58:52 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5896, average loss: 0.7282
[11/14 06:58:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.06	
[11/14 06:58:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/14 07:05:58 visual_prompt]: Epoch 15 / 100: avg data time: 4.63e+00, avg batch time: 6.0817, average train loss: 0.7205
[11/14 07:06:47 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5928, average loss: 0.8441
[11/14 07:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[11/14 07:06:47 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/14 07:13:53 visual_prompt]: Epoch 16 / 100: avg data time: 4.64e+00, avg batch time: 6.0959, average train loss: 0.7952
[11/14 07:14:42 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5889, average loss: 0.7576
[11/14 07:14:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 68.69	
[11/14 07:14:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/14 07:21:49 visual_prompt]: Epoch 17 / 100: avg data time: 4.64e+00, avg batch time: 6.0930, average train loss: 0.6727
[11/14 07:22:37 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5904, average loss: 0.6680
[11/14 07:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.51	
[11/14 07:22:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/14 07:29:45 visual_prompt]: Epoch 18 / 100: avg data time: 4.66e+00, avg batch time: 6.1083, average train loss: 0.7205
[11/14 07:30:34 visual_prompt]: Inference (val):avg data time: 2.09e-05, avg batch time: 0.5865, average loss: 1.2647
[11/14 07:30:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[11/14 07:30:34 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/14 07:37:42 visual_prompt]: Epoch 19 / 100: avg data time: 4.65e+00, avg batch time: 6.1063, average train loss: 0.8198
[11/14 07:38:30 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5837, average loss: 0.7814
[11/14 07:38:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.80	
[11/14 07:38:30 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/14 07:45:38 visual_prompt]: Epoch 20 / 100: avg data time: 4.66e+00, avg batch time: 6.1128, average train loss: 0.6516
[11/14 07:46:27 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5917, average loss: 0.6210
[11/14 07:46:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.00	
[11/14 07:46:27 visual_prompt]: Best epoch 20: best metric: -0.621
[11/14 07:46:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/14 07:53:35 visual_prompt]: Epoch 21 / 100: avg data time: 4.66e+00, avg batch time: 6.1139, average train loss: 0.6324
[11/14 07:54:24 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5833, average loss: 1.2250
[11/14 07:54:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.95	
[11/14 07:54:24 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/14 08:01:32 visual_prompt]: Epoch 22 / 100: avg data time: 4.67e+00, avg batch time: 6.1194, average train loss: 0.6627
[11/14 08:02:21 visual_prompt]: Inference (val):avg data time: 2.33e-05, avg batch time: 0.5880, average loss: 1.0498
[11/14 08:02:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.57	
[11/14 08:02:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/14 08:09:27 visual_prompt]: Epoch 23 / 100: avg data time: 4.64e+00, avg batch time: 6.0894, average train loss: 0.6718
[11/14 08:10:16 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5863, average loss: 1.0461
[11/14 08:10:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.55	
[11/14 08:10:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/14 08:17:25 visual_prompt]: Epoch 24 / 100: avg data time: 4.67e+00, avg batch time: 6.1248, average train loss: 0.6677
[11/14 08:18:14 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5894, average loss: 0.8375
[11/14 08:18:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 72.36	
[11/14 08:18:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/14 08:25:23 visual_prompt]: Epoch 25 / 100: avg data time: 4.68e+00, avg batch time: 6.1340, average train loss: 0.7134
[11/14 08:26:12 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5919, average loss: 0.8246
[11/14 08:26:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 72.03	
[11/14 08:26:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/14 08:33:19 visual_prompt]: Epoch 26 / 100: avg data time: 4.65e+00, avg batch time: 6.1009, average train loss: 0.6137
[11/14 08:34:08 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5890, average loss: 0.6522
[11/14 08:34:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.61	
[11/14 08:34:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/14 08:41:13 visual_prompt]: Epoch 27 / 100: avg data time: 4.62e+00, avg batch time: 6.0718, average train loss: 0.6254
[11/14 08:42:02 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5834, average loss: 0.7248
[11/14 08:42:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.15	
[11/14 08:42:02 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/14 08:49:10 visual_prompt]: Epoch 28 / 100: avg data time: 4.66e+00, avg batch time: 6.1102, average train loss: 0.6796
[11/14 08:49:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5843, average loss: 0.9833
[11/14 08:49:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 73.61	
[11/14 08:49:59 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/14 08:57:06 visual_prompt]: Epoch 29 / 100: avg data time: 4.66e+00, avg batch time: 6.1080, average train loss: 0.5688
[11/14 08:57:55 visual_prompt]: Inference (val):avg data time: 2.28e-05, avg batch time: 0.5876, average loss: 0.7330
[11/14 08:57:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.07	
[11/14 08:57:55 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/14 09:05:05 visual_prompt]: Epoch 30 / 100: avg data time: 4.69e+00, avg batch time: 6.1410, average train loss: 0.5600
[11/14 09:05:54 visual_prompt]: Inference (val):avg data time: 2.07e-05, avg batch time: 0.5892, average loss: 0.8735
[11/14 09:05:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.21	
[11/14 09:05:54 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/14 09:13:00 visual_prompt]: Epoch 31 / 100: avg data time: 4.64e+00, avg batch time: 6.0929, average train loss: 0.7012
[11/14 09:13:49 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5844, average loss: 0.8545
[11/14 09:13:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.82	
[11/14 09:13:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/14 09:20:55 visual_prompt]: Epoch 32 / 100: avg data time: 4.64e+00, avg batch time: 6.0889, average train loss: 0.5778
[11/14 09:21:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5903, average loss: 0.8196
[11/14 09:21:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.62	
[11/14 09:21:44 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/14 09:28:52 visual_prompt]: Epoch 33 / 100: avg data time: 4.65e+00, avg batch time: 6.1014, average train loss: 0.4920
[11/14 09:29:41 visual_prompt]: Inference (val):avg data time: 2.10e-05, avg batch time: 0.5862, average loss: 0.6100
[11/14 09:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.01	
[11/14 09:29:41 visual_prompt]: Best epoch 33: best metric: -0.610
[11/14 09:29:41 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/14 09:36:48 visual_prompt]: Epoch 34 / 100: avg data time: 4.65e+00, avg batch time: 6.1058, average train loss: 0.5615
[11/14 09:37:37 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5889, average loss: 0.7080
[11/14 09:37:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.86	
[11/14 09:37:37 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/14 09:44:43 visual_prompt]: Epoch 35 / 100: avg data time: 4.63e+00, avg batch time: 6.0844, average train loss: 0.4871
[11/14 09:45:31 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5851, average loss: 0.7610
[11/14 09:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.58	
[11/14 09:45:31 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/14 09:52:39 visual_prompt]: Epoch 36 / 100: avg data time: 4.66e+00, avg batch time: 6.1119, average train loss: 0.5539
[11/14 09:53:28 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5898, average loss: 0.8829
[11/14 09:53:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.72	
[11/14 09:53:28 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/14 10:00:36 visual_prompt]: Epoch 37 / 100: avg data time: 4.66e+00, avg batch time: 6.1095, average train loss: 0.5321
[11/14 10:01:25 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5894, average loss: 0.7572
[11/14 10:01:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.35	
[11/14 10:01:25 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/14 10:08:33 visual_prompt]: Epoch 38 / 100: avg data time: 4.67e+00, avg batch time: 6.1231, average train loss: 0.4925
[11/14 10:09:22 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5880, average loss: 0.7586
[11/14 10:09:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.71	
[11/14 10:09:22 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/14 10:16:31 visual_prompt]: Epoch 39 / 100: avg data time: 4.67e+00, avg batch time: 6.1264, average train loss: 0.4526
[11/14 10:17:20 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5865, average loss: 0.7618
[11/14 10:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.27	
[11/14 10:17:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/14 10:24:29 visual_prompt]: Epoch 40 / 100: avg data time: 4.67e+00, avg batch time: 6.1203, average train loss: 0.5335
[11/14 10:25:17 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5924, average loss: 0.8272
[11/14 10:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.72	
[11/14 10:25:17 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/14 10:32:27 visual_prompt]: Epoch 41 / 100: avg data time: 4.68e+00, avg batch time: 6.1280, average train loss: 0.4302
[11/14 10:33:15 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5860, average loss: 0.8510
[11/14 10:33:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.20	
[11/14 10:33:15 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/14 10:40:21 visual_prompt]: Epoch 42 / 100: avg data time: 4.63e+00, avg batch time: 6.0826, average train loss: 0.4105
[11/14 10:41:10 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5879, average loss: 0.8181
[11/14 10:41:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 67.17	
[11/14 10:41:10 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/14 10:48:17 visual_prompt]: Epoch 43 / 100: avg data time: 4.65e+00, avg batch time: 6.1048, average train loss: 0.3656
[11/14 10:49:06 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5890, average loss: 0.8438
[11/14 10:49:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.46	
[11/14 10:49:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/14 10:56:14 visual_prompt]: Epoch 44 / 100: avg data time: 4.66e+00, avg batch time: 6.1089, average train loss: 0.5307
[11/14 10:57:02 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5860, average loss: 0.7134
[11/14 10:57:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.65	
[11/14 10:57:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/14 11:04:10 visual_prompt]: Epoch 45 / 100: avg data time: 4.65e+00, avg batch time: 6.1094, average train loss: 0.4474
[11/14 11:04:59 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5901, average loss: 0.9216
[11/14 11:04:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.13	
[11/14 11:04:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/14 11:12:58 visual_prompt]: Epoch 46 / 100: avg data time: 5.40e+00, avg batch time: 6.8472, average train loss: 0.3648
[11/14 11:13:47 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5878, average loss: 0.7875
[11/14 11:13:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.94	
[11/14 11:13:47 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/14 11:20:56 visual_prompt]: Epoch 47 / 100: avg data time: 4.67e+00, avg batch time: 6.1254, average train loss: 0.3626
[11/14 11:21:45 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5862, average loss: 0.9018
[11/14 11:21:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.84	
[11/14 11:21:45 visual_prompt]: Stopping early.
[11/14 11:21:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 11:21:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 11:21:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 11:21:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 11:21:46 visual_prompt]: Training with config:
[11/14 11:21:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 11:21:46 visual_prompt]: Loading training data...
[11/14 11:21:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 11:21:46 visual_prompt]: Loading validation data...
[11/14 11:21:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 11:21:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 11:21:57 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 11:21:57 visual_prompt]: tuned percent:0.532
[11/14 11:21:57 visual_prompt]: Device used for model: 0
[11/14 11:21:57 visual_prompt]: Setting up Evaluator...
[11/14 11:21:57 visual_prompt]: Setting up Trainer...
[11/14 11:21:57 visual_prompt]: 	Setting up the optimizer...
[11/14 11:21:57 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 11:29:14 visual_prompt]: Epoch 1 / 100: avg data time: 4.79e+00, avg batch time: 6.2454, average train loss: 1.4863
[11/14 11:30:06 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5829, average loss: 1.4553
[11/14 11:30:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 11:30:06 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/14 11:37:15 visual_prompt]: Epoch 2 / 100: avg data time: 4.66e+00, avg batch time: 6.1141, average train loss: 0.9713
[11/14 11:38:03 visual_prompt]: Inference (val):avg data time: 2.15e-05, avg batch time: 0.5905, average loss: 0.7147
[11/14 11:38:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.04	
[11/14 11:38:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/14 11:45:19 visual_prompt]: Epoch 3 / 100: avg data time: 4.77e+00, avg batch time: 6.2201, average train loss: 0.7077
[11/14 11:46:08 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5851, average loss: 0.7279
[11/14 11:46:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/14 11:46:08 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/14 11:54:10 visual_prompt]: Epoch 4 / 100: avg data time: 5.44e+00, avg batch time: 6.8918, average train loss: 0.7346
[11/14 11:55:01 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5853, average loss: 0.7681
[11/14 11:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[11/14 11:55:01 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/14 12:02:12 visual_prompt]: Epoch 5 / 100: avg data time: 4.69e+00, avg batch time: 6.1457, average train loss: 0.7304
[11/14 12:03:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5860, average loss: 0.7125
[11/14 12:03:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/14 12:03:01 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/14 12:10:13 visual_prompt]: Epoch 6 / 100: avg data time: 4.71e+00, avg batch time: 6.1633, average train loss: 0.7356
[11/14 12:11:02 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5852, average loss: 0.7261
[11/14 12:11:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.04	
[11/14 12:11:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/14 12:18:11 visual_prompt]: Epoch 7 / 100: avg data time: 4.67e+00, avg batch time: 6.1217, average train loss: 0.7236
[11/14 12:19:00 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5866, average loss: 0.6945
[11/14 12:19:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[11/14 12:19:00 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/14 12:26:09 visual_prompt]: Epoch 8 / 100: avg data time: 4.68e+00, avg batch time: 6.1369, average train loss: 0.7090
[11/14 12:26:58 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5867, average loss: 0.6984
[11/14 12:26:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.53	
[11/14 12:26:58 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/14 12:34:08 visual_prompt]: Epoch 9 / 100: avg data time: 4.68e+00, avg batch time: 6.1290, average train loss: 0.7234
[11/14 12:34:56 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5888, average loss: 0.7273
[11/14 12:34:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[11/14 12:34:56 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/14 12:42:06 visual_prompt]: Epoch 10 / 100: avg data time: 4.68e+00, avg batch time: 6.1326, average train loss: 0.7094
[11/14 12:42:54 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5859, average loss: 0.6893
[11/14 12:42:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[11/14 12:42:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/14 12:50:05 visual_prompt]: Epoch 11 / 100: avg data time: 4.70e+00, avg batch time: 6.1553, average train loss: 0.7365
[11/14 12:50:55 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5849, average loss: 1.6830
[11/14 12:50:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.81	
[11/14 12:50:55 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/14 12:58:04 visual_prompt]: Epoch 12 / 100: avg data time: 4.68e+00, avg batch time: 6.1368, average train loss: 0.8243
[11/14 12:58:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5906, average loss: 0.7700
[11/14 12:58:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.65	
[11/14 12:58:53 visual_prompt]: Best epoch 12: best metric: -0.770
[11/14 12:58:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/14 13:06:04 visual_prompt]: Epoch 13 / 100: avg data time: 4.70e+00, avg batch time: 6.1530, average train loss: 0.7388
[11/14 13:06:53 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5852, average loss: 0.7423
[11/14 13:06:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.05	
[11/14 13:06:53 visual_prompt]: Best epoch 13: best metric: -0.742
[11/14 13:06:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/14 13:14:03 visual_prompt]: Epoch 14 / 100: avg data time: 4.69e+00, avg batch time: 6.1381, average train loss: 0.7283
[11/14 13:14:52 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5886, average loss: 0.6983
[11/14 13:14:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.01	
[11/14 13:14:52 visual_prompt]: Best epoch 14: best metric: -0.698
[11/14 13:14:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/14 13:22:02 visual_prompt]: Epoch 15 / 100: avg data time: 4.69e+00, avg batch time: 6.1404, average train loss: 0.7070
[11/14 13:22:51 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5843, average loss: 0.7123
[11/14 13:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.66	
[11/14 13:22:51 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/14 13:30:01 visual_prompt]: Epoch 16 / 100: avg data time: 4.69e+00, avg batch time: 6.1378, average train loss: 0.7516
[11/14 13:30:50 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5879, average loss: 0.8885
[11/14 13:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[11/14 13:30:50 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/14 13:38:00 visual_prompt]: Epoch 17 / 100: avg data time: 4.68e+00, avg batch time: 6.1356, average train loss: 0.7496
[11/14 13:38:49 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5879, average loss: 0.7649
[11/14 13:38:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/14 13:38:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/14 13:46:00 visual_prompt]: Epoch 18 / 100: avg data time: 4.71e+00, avg batch time: 6.1623, average train loss: 0.7239
[11/14 13:46:49 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5853, average loss: 0.8876
[11/14 13:46:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[11/14 13:46:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/14 13:53:58 visual_prompt]: Epoch 19 / 100: avg data time: 4.67e+00, avg batch time: 6.1224, average train loss: 0.7588
[11/14 13:54:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5867, average loss: 0.9257
[11/14 13:54:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.64	
[11/14 13:54:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/14 14:01:57 visual_prompt]: Epoch 20 / 100: avg data time: 4.70e+00, avg batch time: 6.1485, average train loss: 0.7332
[11/14 14:02:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5898, average loss: 0.6889
[11/14 14:02:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.95	
[11/14 14:02:46 visual_prompt]: Best epoch 20: best metric: -0.689
[11/14 14:02:46 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/14 14:09:57 visual_prompt]: Epoch 21 / 100: avg data time: 4.70e+00, avg batch time: 6.1490, average train loss: 0.7300
[11/14 14:10:46 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5901, average loss: 0.7571
[11/14 14:10:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.96	
[11/14 14:10:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/14 14:17:57 visual_prompt]: Epoch 22 / 100: avg data time: 4.70e+00, avg batch time: 6.1525, average train loss: 0.7172
[11/14 14:18:46 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5896, average loss: 0.6923
[11/14 14:18:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/14 14:18:46 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/14 14:25:59 visual_prompt]: Epoch 23 / 100: avg data time: 4.73e+00, avg batch time: 6.1777, average train loss: 0.7126
[11/14 14:26:48 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5900, average loss: 0.8270
[11/14 14:26:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.00	
[11/14 14:26:48 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/14 14:33:58 visual_prompt]: Epoch 24 / 100: avg data time: 4.69e+00, avg batch time: 6.1418, average train loss: 0.7236
[11/14 14:34:47 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5934, average loss: 0.6880
[11/14 14:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/14 14:34:47 visual_prompt]: Best epoch 24: best metric: -0.688
[11/14 14:34:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/14 14:41:56 visual_prompt]: Epoch 25 / 100: avg data time: 4.68e+00, avg batch time: 6.1291, average train loss: 0.7185
[11/14 14:42:45 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5853, average loss: 0.7078
[11/14 14:42:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/14 14:42:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/14 14:50:35 visual_prompt]: Epoch 26 / 100: avg data time: 5.26e+00, avg batch time: 6.7179, average train loss: 0.7332
[11/14 14:51:27 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5863, average loss: 0.7030
[11/14 14:51:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/14 14:51:27 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/14 14:58:59 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4618, average train loss: 0.7164
[11/14 14:59:51 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5910, average loss: 0.7465
[11/14 14:59:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.03	
[11/14 14:59:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/14 15:07:25 visual_prompt]: Epoch 28 / 100: avg data time: 5.03e+00, avg batch time: 6.4824, average train loss: 0.7176
[11/14 15:08:17 visual_prompt]: Inference (val):avg data time: 2.13e-05, avg batch time: 0.5880, average loss: 0.7000
[11/14 15:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[11/14 15:08:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/14 15:15:35 visual_prompt]: Epoch 29 / 100: avg data time: 4.81e+00, avg batch time: 6.2658, average train loss: 0.7115
[11/14 15:16:24 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5851, average loss: 0.7236
[11/14 15:16:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.00	
[11/14 15:16:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/14 15:24:17 visual_prompt]: Epoch 30 / 100: avg data time: 5.30e+00, avg batch time: 6.7455, average train loss: 0.7374
[11/14 15:25:08 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5910, average loss: 0.7976
[11/14 15:25:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.02	
[11/14 15:25:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/14 15:32:33 visual_prompt]: Epoch 31 / 100: avg data time: 4.91e+00, avg batch time: 6.3598, average train loss: 0.7095
[11/14 15:33:21 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5887, average loss: 0.7002
[11/14 15:33:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[11/14 15:33:21 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/14 15:40:31 visual_prompt]: Epoch 32 / 100: avg data time: 4.69e+00, avg batch time: 6.1428, average train loss: 0.7094
[11/14 15:41:21 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5879, average loss: 0.6956
[11/14 15:41:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.12	
[11/14 15:41:21 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/14 15:48:31 visual_prompt]: Epoch 33 / 100: avg data time: 4.70e+00, avg batch time: 6.1502, average train loss: 0.7092
[11/14 15:49:20 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5906, average loss: 0.6954
[11/14 15:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.81	
[11/14 15:49:20 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/14 15:56:29 visual_prompt]: Epoch 34 / 100: avg data time: 4.68e+00, avg batch time: 6.1281, average train loss: 0.7079
[11/14 15:57:18 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5855, average loss: 0.7223
[11/14 15:57:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.37	
[11/14 15:57:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/14 16:04:27 visual_prompt]: Epoch 35 / 100: avg data time: 4.68e+00, avg batch time: 6.1267, average train loss: 0.7151
[11/14 16:05:16 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5855, average loss: 0.7002
[11/14 16:05:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.15	
[11/14 16:05:16 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/14 16:12:27 visual_prompt]: Epoch 36 / 100: avg data time: 4.70e+00, avg batch time: 6.1449, average train loss: 0.7300
[11/14 16:13:16 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5872, average loss: 0.6908
[11/14 16:13:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.08	
[11/14 16:13:16 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/14 16:20:25 visual_prompt]: Epoch 37 / 100: avg data time: 4.68e+00, avg batch time: 6.1338, average train loss: 0.7034
[11/14 16:21:14 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5833, average loss: 0.7173
[11/14 16:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[11/14 16:21:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/14 16:28:24 visual_prompt]: Epoch 38 / 100: avg data time: 4.69e+00, avg batch time: 6.1417, average train loss: 0.6983
[11/14 16:29:13 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.5905, average loss: 0.6937
[11/14 16:29:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/14 16:29:13 visual_prompt]: Stopping early.
[11/14 16:29:13 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 16:29:13 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 16:29:13 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 16:29:13 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 16:29:13 visual_prompt]: Training with config:
[11/14 16:29:13 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 16:29:13 visual_prompt]: Loading training data...
[11/14 16:29:13 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 16:29:13 visual_prompt]: Loading validation data...
[11/14 16:29:13 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 16:29:13 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 16:29:18 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 16:29:18 visual_prompt]: tuned percent:0.532
[11/14 16:29:18 visual_prompt]: Device used for model: 0
[11/14 16:29:18 visual_prompt]: Setting up Evaluator...
[11/14 16:29:18 visual_prompt]: Setting up Trainer...
[11/14 16:29:18 visual_prompt]: 	Setting up the optimizer...
[11/14 16:29:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 16:36:34 visual_prompt]: Epoch 1 / 100: avg data time: 4.77e+00, avg batch time: 6.2241, average train loss: 1.4863
[11/14 16:37:29 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5847, average loss: 1.4553
[11/14 16:37:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 16:37:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/14 16:44:38 visual_prompt]: Epoch 2 / 100: avg data time: 4.69e+00, avg batch time: 6.1369, average train loss: 0.9787
[11/14 16:45:26 visual_prompt]: Inference (val):avg data time: 2.14e-05, avg batch time: 0.5882, average loss: 0.7197
[11/14 16:45:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.26	
[11/14 16:45:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/14 16:52:54 visual_prompt]: Epoch 3 / 100: avg data time: 4.94e+00, avg batch time: 6.3938, average train loss: 0.7152
[11/14 16:53:42 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5875, average loss: 0.7403
[11/14 16:53:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.92	
[11/14 16:53:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/14 17:01:10 visual_prompt]: Epoch 4 / 100: avg data time: 4.93e+00, avg batch time: 6.3863, average train loss: 0.7463
[11/14 17:01:58 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5888, average loss: 0.8057
[11/14 17:01:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[11/14 17:01:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/14 17:09:00 visual_prompt]: Epoch 5 / 100: avg data time: 4.58e+00, avg batch time: 6.0343, average train loss: 0.7599
[11/14 17:09:49 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5900, average loss: 0.7011
[11/14 17:09:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.33	
[11/14 17:09:49 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/14 17:17:17 visual_prompt]: Epoch 6 / 100: avg data time: 4.96e+00, avg batch time: 6.4086, average train loss: 0.7519
[11/14 17:18:06 visual_prompt]: Inference (val):avg data time: 2.06e-05, avg batch time: 0.5866, average loss: 0.6936
[11/14 17:18:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[11/14 17:18:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/14 17:25:08 visual_prompt]: Epoch 7 / 100: avg data time: 4.58e+00, avg batch time: 6.0331, average train loss: 0.7046
[11/14 17:25:57 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5886, average loss: 1.2620
[11/14 17:25:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.61	
[11/14 17:25:57 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/14 17:33:01 visual_prompt]: Epoch 8 / 100: avg data time: 4.60e+00, avg batch time: 6.0571, average train loss: 0.7436
[11/14 17:33:49 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5883, average loss: 0.8723
[11/14 17:33:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.27	
[11/14 17:33:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/14 17:40:53 visual_prompt]: Epoch 9 / 100: avg data time: 4.60e+00, avg batch time: 6.0497, average train loss: 0.8027
[11/14 17:41:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.5842, average loss: 0.7010
[11/14 17:41:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.93	
[11/14 17:41:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/14 17:48:44 visual_prompt]: Epoch 10 / 100: avg data time: 4.59e+00, avg batch time: 6.0491, average train loss: 0.6891
[11/14 17:49:33 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5848, average loss: 0.6902
[11/14 17:49:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.57	
[11/14 17:49:33 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/14 17:56:34 visual_prompt]: Epoch 11 / 100: avg data time: 4.57e+00, avg batch time: 6.0174, average train loss: 0.7356
[11/14 17:57:22 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.5856, average loss: 0.9048
[11/14 17:57:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.27	
[11/14 17:57:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/14 18:04:21 visual_prompt]: Epoch 12 / 100: avg data time: 4.53e+00, avg batch time: 5.9820, average train loss: 0.7116
[11/14 18:05:09 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5863, average loss: 0.7177
[11/14 18:05:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.19	
[11/14 18:05:09 visual_prompt]: Best epoch 12: best metric: -0.718
[11/14 18:05:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/14 18:12:08 visual_prompt]: Epoch 13 / 100: avg data time: 4.53e+00, avg batch time: 5.9868, average train loss: 0.7795
[11/14 18:12:56 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5865, average loss: 0.7248
[11/14 18:12:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.76	
[11/14 18:12:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/14 18:19:55 visual_prompt]: Epoch 14 / 100: avg data time: 4.53e+00, avg batch time: 5.9840, average train loss: 0.7045
[11/14 18:20:43 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5860, average loss: 0.7934
[11/14 18:20:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.19	
[11/14 18:20:43 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/14 18:27:41 visual_prompt]: Epoch 15 / 100: avg data time: 4.52e+00, avg batch time: 5.9757, average train loss: 0.7067
[11/14 18:28:29 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5913, average loss: 0.6787
[11/14 18:28:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.64	
[11/14 18:28:29 visual_prompt]: Best epoch 15: best metric: -0.679
[11/14 18:28:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/14 18:35:28 visual_prompt]: Epoch 16 / 100: avg data time: 4.52e+00, avg batch time: 5.9744, average train loss: 0.6990
[11/14 18:36:15 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5933, average loss: 0.8309
[11/14 18:36:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.56	
[11/14 18:36:15 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/14 18:43:15 visual_prompt]: Epoch 17 / 100: avg data time: 4.53e+00, avg batch time: 5.9859, average train loss: 0.7265
[11/14 18:44:02 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5851, average loss: 0.6797
[11/14 18:44:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.64	
[11/14 18:44:02 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/14 18:51:13 visual_prompt]: Epoch 18 / 100: avg data time: 4.70e+00, avg batch time: 6.1484, average train loss: 0.7005
[11/14 18:52:08 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5880, average loss: 0.8577
[11/14 18:52:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[11/14 18:52:08 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/14 18:59:53 visual_prompt]: Epoch 19 / 100: avg data time: 5.19e+00, avg batch time: 6.6418, average train loss: 0.7024
[11/14 19:00:52 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5880, average loss: 0.8868
[11/14 19:00:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[11/14 19:00:52 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/14 19:08:52 visual_prompt]: Epoch 20 / 100: avg data time: 5.40e+00, avg batch time: 6.8511, average train loss: 0.6821
[11/14 19:09:47 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5867, average loss: 0.6721
[11/14 19:09:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.12	
[11/14 19:09:47 visual_prompt]: Best epoch 20: best metric: -0.672
[11/14 19:09:47 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/14 19:17:43 visual_prompt]: Epoch 21 / 100: avg data time: 5.35e+00, avg batch time: 6.7971, average train loss: 0.6701
[11/14 19:18:32 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5873, average loss: 0.6847
[11/14 19:18:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.76	
[11/14 19:18:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/14 19:26:23 visual_prompt]: Epoch 22 / 100: avg data time: 5.28e+00, avg batch time: 6.7275, average train loss: 0.7164
[11/14 19:27:17 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5892, average loss: 0.6723
[11/14 19:27:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.43	
[11/14 19:27:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/14 19:35:16 visual_prompt]: Epoch 23 / 100: avg data time: 5.39e+00, avg batch time: 6.8340, average train loss: 0.6818
[11/14 19:36:12 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5848, average loss: 0.6745
[11/14 19:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.96	
[11/14 19:36:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/14 19:44:04 visual_prompt]: Epoch 24 / 100: avg data time: 5.29e+00, avg batch time: 6.7374, average train loss: 0.6996
[11/14 19:44:57 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5839, average loss: 0.6857
[11/14 19:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.95	
[11/14 19:44:57 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/14 19:52:39 visual_prompt]: Epoch 25 / 100: avg data time: 5.15e+00, avg batch time: 6.5983, average train loss: 0.6996
[11/14 19:53:32 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5841, average loss: 0.6993
[11/14 19:53:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/14 19:53:32 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/14 20:01:17 visual_prompt]: Epoch 26 / 100: avg data time: 5.20e+00, avg batch time: 6.6485, average train loss: 0.7013
[11/14 20:02:11 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5865, average loss: 0.6865
[11/14 20:02:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.57	
[11/14 20:02:11 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/14 20:10:00 visual_prompt]: Epoch 27 / 100: avg data time: 5.25e+00, avg batch time: 6.6995, average train loss: 0.6826
[11/14 20:10:54 visual_prompt]: Inference (val):avg data time: 2.31e-05, avg batch time: 0.5892, average loss: 0.6718
[11/14 20:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.49	
[11/14 20:10:54 visual_prompt]: Best epoch 27: best metric: -0.672
[11/14 20:10:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/14 20:18:25 visual_prompt]: Epoch 28 / 100: avg data time: 4.99e+00, avg batch time: 6.4354, average train loss: 0.7039
[11/14 20:19:13 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5857, average loss: 0.6836
[11/14 20:19:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.31	
[11/14 20:19:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/14 20:26:16 visual_prompt]: Epoch 29 / 100: avg data time: 4.59e+00, avg batch time: 6.0440, average train loss: 0.6924
[11/14 20:27:05 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5854, average loss: 0.7310
[11/14 20:27:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.40	
[11/14 20:27:05 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/14 20:34:06 visual_prompt]: Epoch 30 / 100: avg data time: 4.57e+00, avg batch time: 6.0246, average train loss: 0.7119
[11/14 20:34:55 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5878, average loss: 0.7704
[11/14 20:34:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.69	
[11/14 20:34:55 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/14 20:41:58 visual_prompt]: Epoch 31 / 100: avg data time: 4.59e+00, avg batch time: 6.0397, average train loss: 0.6892
[11/14 20:42:46 visual_prompt]: Inference (val):avg data time: 2.22e-05, avg batch time: 0.5823, average loss: 0.6581
[11/14 20:42:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.57	
[11/14 20:42:46 visual_prompt]: Best epoch 31: best metric: -0.658
[11/14 20:42:46 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/14 20:49:49 visual_prompt]: Epoch 32 / 100: avg data time: 4.59e+00, avg batch time: 6.0449, average train loss: 0.6905
[11/14 20:50:38 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5839, average loss: 0.6783
[11/14 20:50:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.53	
[11/14 20:50:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/14 20:57:42 visual_prompt]: Epoch 33 / 100: avg data time: 4.60e+00, avg batch time: 6.0541, average train loss: 0.6884
[11/14 20:58:30 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5892, average loss: 0.7002
[11/14 20:58:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.79	
[11/14 20:58:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/14 21:05:33 visual_prompt]: Epoch 34 / 100: avg data time: 4.59e+00, avg batch time: 6.0391, average train loss: 0.6877
[11/14 21:06:21 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5827, average loss: 0.7005
[11/14 21:06:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.91	
[11/14 21:06:21 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/14 21:13:24 visual_prompt]: Epoch 35 / 100: avg data time: 4.59e+00, avg batch time: 6.0424, average train loss: 0.7012
[11/14 21:14:13 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5839, average loss: 0.7992
[11/14 21:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/14 21:14:13 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/14 21:21:18 visual_prompt]: Epoch 36 / 100: avg data time: 4.62e+00, avg batch time: 6.0673, average train loss: 0.7084
[11/14 21:22:06 visual_prompt]: Inference (val):avg data time: 2.25e-05, avg batch time: 0.5824, average loss: 0.6597
[11/14 21:22:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.41	
[11/14 21:22:06 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/14 21:29:06 visual_prompt]: Epoch 37 / 100: avg data time: 4.54e+00, avg batch time: 5.9968, average train loss: 0.6951
[11/14 21:29:54 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5864, average loss: 0.6763
[11/14 21:29:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.55	
[11/14 21:29:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/14 21:36:53 visual_prompt]: Epoch 38 / 100: avg data time: 4.54e+00, avg batch time: 5.9863, average train loss: 0.6856
[11/14 21:37:41 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5854, average loss: 0.6744
[11/14 21:37:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.77	
[11/14 21:37:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/14 21:44:39 visual_prompt]: Epoch 39 / 100: avg data time: 4.52e+00, avg batch time: 5.9753, average train loss: 0.6952
[11/14 21:45:27 visual_prompt]: Inference (val):avg data time: 2.19e-05, avg batch time: 0.5898, average loss: 0.7184
[11/14 21:45:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[11/14 21:45:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/14 21:52:25 visual_prompt]: Epoch 40 / 100: avg data time: 4.53e+00, avg batch time: 5.9797, average train loss: 0.7074
[11/14 21:53:13 visual_prompt]: Inference (val):avg data time: 2.12e-05, avg batch time: 0.5858, average loss: 0.7180
[11/14 21:53:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.84	
[11/14 21:53:13 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/14 22:00:12 visual_prompt]: Epoch 41 / 100: avg data time: 4.53e+00, avg batch time: 5.9860, average train loss: 0.7145
[11/14 22:01:00 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5870, average loss: 0.8335
[11/14 22:01:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.42	
[11/14 22:01:00 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/14 22:08:11 visual_prompt]: Epoch 42 / 100: avg data time: 4.70e+00, avg batch time: 6.1540, average train loss: 0.6988
[11/14 22:09:04 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.5901, average loss: 0.6622
[11/14 22:09:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.68	
[11/14 22:09:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/14 22:16:41 visual_prompt]: Epoch 43 / 100: avg data time: 5.08e+00, avg batch time: 6.5254, average train loss: 0.7157
[11/14 22:17:33 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5899, average loss: 0.7004
[11/14 22:17:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.63	
[11/14 22:17:33 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/14 22:25:11 visual_prompt]: Epoch 44 / 100: avg data time: 5.09e+00, avg batch time: 6.5413, average train loss: 0.7020
[11/14 22:26:01 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5895, average loss: 0.6900
[11/14 22:26:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.10	
[11/14 22:26:01 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/14 22:33:35 visual_prompt]: Epoch 45 / 100: avg data time: 5.03e+00, avg batch time: 6.4861, average train loss: 0.6992
[11/14 22:34:24 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5878, average loss: 0.7374
[11/14 22:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/14 22:34:24 visual_prompt]: Stopping early.
[11/14 22:34:25 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 22:34:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 22:34:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/14 22:34:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 22:34:25 visual_prompt]: Training with config:
[11/14 22:34:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 22:34:25 visual_prompt]: Loading training data...
[11/14 22:34:25 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 22:34:25 visual_prompt]: Loading validation data...
[11/14 22:34:25 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 22:34:25 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 22:34:27 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 22:34:27 visual_prompt]: tuned percent:0.532
[11/14 22:34:27 visual_prompt]: Device used for model: 0
[11/14 22:34:27 visual_prompt]: Setting up Evaluator...
[11/14 22:34:27 visual_prompt]: Setting up Trainer...
[11/14 22:34:27 visual_prompt]: 	Setting up the optimizer...
[11/14 22:34:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 22:42:32 visual_prompt]: Epoch 1 / 100: avg data time: 5.47e+00, avg batch time: 6.9175, average train loss: 1.4863
[11/14 22:43:29 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5914, average loss: 1.4553
[11/14 22:43:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 22:43:29 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/14 22:51:51 visual_prompt]: Epoch 2 / 100: avg data time: 5.72e+00, avg batch time: 7.1660, average train loss: 0.9796
[11/14 22:52:49 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5919, average loss: 0.7201
[11/14 22:52:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/14 22:52:49 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/14 23:00:29 visual_prompt]: Epoch 3 / 100: avg data time: 5.12e+00, avg batch time: 6.5682, average train loss: 0.7161
[11/14 23:01:23 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5874, average loss: 0.7424
[11/14 23:01:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[11/14 23:01:23 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/14 23:09:03 visual_prompt]: Epoch 4 / 100: avg data time: 5.13e+00, avg batch time: 6.5802, average train loss: 0.7472
[11/14 23:10:00 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5893, average loss: 0.7975
[11/14 23:10:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[11/14 23:10:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/14 23:17:51 visual_prompt]: Epoch 5 / 100: avg data time: 5.27e+00, avg batch time: 6.7235, average train loss: 0.7629
[11/14 23:18:47 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5893, average loss: 0.7072
[11/14 23:18:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.71	
[11/14 23:18:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/14 23:27:47 visual_prompt]: Epoch 6 / 100: avg data time: 6.25e+00, avg batch time: 7.7016, average train loss: 0.7481
[11/14 23:29:00 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5863, average loss: 0.6844
[11/14 23:29:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.57	
[11/14 23:29:00 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/14 23:36:13 visual_prompt]: Epoch 7 / 100: avg data time: 4.72e+00, avg batch time: 6.1754, average train loss: 0.7037
[11/14 23:37:02 visual_prompt]: Inference (val):avg data time: 2.02e-05, avg batch time: 0.5904, average loss: 1.2721
[11/14 23:37:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[11/14 23:37:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/14 23:44:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.72e+00, avg batch time: 6.1807, average train loss: 0.7266
[11/14 23:45:04 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5848, average loss: 1.0836
[11/14 23:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[11/14 23:45:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/14 23:52:13 visual_prompt]: Epoch 9 / 100: avg data time: 4.67e+00, avg batch time: 6.1270, average train loss: 0.8072
[11/14 23:53:02 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5891, average loss: 0.6764
[11/14 23:53:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.50	
[11/14 23:53:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/15 00:00:13 visual_prompt]: Epoch 10 / 100: avg data time: 4.70e+00, avg batch time: 6.1521, average train loss: 0.6825
[11/15 00:01:02 visual_prompt]: Inference (val):avg data time: 2.42e-05, avg batch time: 0.5938, average loss: 0.6855
[11/15 00:01:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.88	
[11/15 00:01:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/15 00:08:33 visual_prompt]: Epoch 11 / 100: avg data time: 5.00e+00, avg batch time: 6.4501, average train loss: 0.7438
[11/15 00:09:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5851, average loss: 0.8196
[11/15 00:09:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.03	
[11/15 00:09:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/15 00:17:01 visual_prompt]: Epoch 12 / 100: avg data time: 5.05e+00, avg batch time: 6.5061, average train loss: 0.7379
[11/15 00:17:53 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5853, average loss: 0.7108
[11/15 00:17:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 65.13	
[11/15 00:17:53 visual_prompt]: Best epoch 12: best metric: -0.711
[11/15 00:17:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/15 00:25:30 visual_prompt]: Epoch 13 / 100: avg data time: 5.07e+00, avg batch time: 6.5283, average train loss: 0.7528
[11/15 00:26:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5913, average loss: 0.6814
[11/15 00:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.50	
[11/15 00:26:23 visual_prompt]: Best epoch 13: best metric: -0.681
[11/15 00:26:23 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/15 00:33:59 visual_prompt]: Epoch 14 / 100: avg data time: 5.07e+00, avg batch time: 6.5201, average train loss: 0.7016
[11/15 00:34:51 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5868, average loss: 0.7179
[11/15 00:34:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 67.36	
[11/15 00:34:51 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/15 00:42:28 visual_prompt]: Epoch 15 / 100: avg data time: 5.07e+00, avg batch time: 6.5209, average train loss: 0.7037
[11/15 00:43:20 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5889, average loss: 0.6512
[11/15 00:43:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.06	
[11/15 00:43:20 visual_prompt]: Best epoch 15: best metric: -0.651
[11/15 00:43:20 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/15 00:51:01 visual_prompt]: Epoch 16 / 100: avg data time: 5.12e+00, avg batch time: 6.5780, average train loss: 0.6772
[11/15 00:51:53 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5867, average loss: 0.6825
[11/15 00:51:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.43	
[11/15 00:51:53 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/15 00:59:33 visual_prompt]: Epoch 17 / 100: avg data time: 5.11e+00, avg batch time: 6.5665, average train loss: 0.7071
[11/15 01:00:25 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.5886, average loss: 0.7372
[11/15 01:00:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.35	
[11/15 01:00:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/15 01:08:04 visual_prompt]: Epoch 18 / 100: avg data time: 5.10e+00, avg batch time: 6.5496, average train loss: 0.6589
[11/15 01:08:56 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5872, average loss: 0.8665
[11/15 01:08:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.24	
[11/15 01:08:56 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/15 01:16:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.11e+00, avg batch time: 6.5625, average train loss: 0.6976
[11/15 01:17:28 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5851, average loss: 0.7330
[11/15 01:17:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.00	
[11/15 01:17:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/15 01:25:10 visual_prompt]: Epoch 20 / 100: avg data time: 5.15e+00, avg batch time: 6.5998, average train loss: 0.6483
[11/15 01:26:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5911, average loss: 0.6675
[11/15 01:26:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.89	
[11/15 01:26:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/15 01:33:44 visual_prompt]: Epoch 21 / 100: avg data time: 5.12e+00, avg batch time: 6.5783, average train loss: 0.6479
[11/15 01:34:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5889, average loss: 0.6294
[11/15 01:34:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.52	
[11/15 01:34:36 visual_prompt]: Best epoch 21: best metric: -0.629
[11/15 01:34:36 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/15 01:42:16 visual_prompt]: Epoch 22 / 100: avg data time: 5.12e+00, avg batch time: 6.5682, average train loss: 0.6924
[11/15 01:43:09 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5865, average loss: 0.7633
[11/15 01:43:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 70.28	
[11/15 01:43:09 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/15 01:50:50 visual_prompt]: Epoch 23 / 100: avg data time: 5.13e+00, avg batch time: 6.5836, average train loss: 0.6249
[11/15 01:51:42 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5869, average loss: 0.6565
[11/15 01:51:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.39	
[11/15 01:51:42 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/15 01:59:23 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e+00, avg batch time: 6.5785, average train loss: 0.6188
[11/15 02:00:15 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5904, average loss: 0.6495
[11/15 02:00:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.65	
[11/15 02:00:15 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/15 02:07:56 visual_prompt]: Epoch 25 / 100: avg data time: 5.13e+00, avg batch time: 6.5816, average train loss: 0.6241
[11/15 02:08:49 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5853, average loss: 0.6280
[11/15 02:08:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.39	
[11/15 02:08:49 visual_prompt]: Best epoch 25: best metric: -0.628
[11/15 02:08:49 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/15 02:16:28 visual_prompt]: Epoch 26 / 100: avg data time: 5.10e+00, avg batch time: 6.5580, average train loss: 0.6357
[11/15 02:17:20 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5842, average loss: 0.7313
[11/15 02:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.71	
[11/15 02:17:20 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/15 02:24:59 visual_prompt]: Epoch 27 / 100: avg data time: 5.10e+00, avg batch time: 6.5525, average train loss: 0.6302
[11/15 02:25:51 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5881, average loss: 0.6566
[11/15 02:25:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.82	
[11/15 02:25:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/15 02:33:32 visual_prompt]: Epoch 28 / 100: avg data time: 5.13e+00, avg batch time: 6.5781, average train loss: 0.6583
[11/15 02:34:25 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5874, average loss: 0.6500
[11/15 02:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.31	
[11/15 02:34:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/15 02:42:04 visual_prompt]: Epoch 29 / 100: avg data time: 5.10e+00, avg batch time: 6.5571, average train loss: 0.5901
[11/15 02:42:56 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5861, average loss: 0.8336
[11/15 02:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.95	
[11/15 02:42:56 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/15 02:50:38 visual_prompt]: Epoch 30 / 100: avg data time: 5.14e+00, avg batch time: 6.5887, average train loss: 0.6291
[11/15 02:51:30 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5884, average loss: 0.7306
[11/15 02:51:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 73.39	
[11/15 02:51:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/15 02:59:09 visual_prompt]: Epoch 31 / 100: avg data time: 5.10e+00, avg batch time: 6.5542, average train loss: 0.5906
[11/15 03:00:02 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5889, average loss: 0.6496
[11/15 03:00:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.02	
[11/15 03:00:02 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/15 03:07:42 visual_prompt]: Epoch 32 / 100: avg data time: 5.13e+00, avg batch time: 6.5791, average train loss: 0.5705
[11/15 03:08:35 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5878, average loss: 0.8293
[11/15 03:08:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 69.90	
[11/15 03:08:35 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/15 03:16:15 visual_prompt]: Epoch 33 / 100: avg data time: 5.12e+00, avg batch time: 6.5711, average train loss: 0.5882
[11/15 03:17:08 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5878, average loss: 0.6304
[11/15 03:17:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.57	
[11/15 03:17:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/15 03:24:47 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e+00, avg batch time: 6.5660, average train loss: 0.5776
[11/15 03:25:40 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5921, average loss: 0.7886
[11/15 03:25:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.24	
[11/15 03:25:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/15 03:33:19 visual_prompt]: Epoch 35 / 100: avg data time: 5.10e+00, avg batch time: 6.5578, average train loss: 0.5387
[11/15 03:34:11 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5858, average loss: 0.7839
[11/15 03:34:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.40	
[11/15 03:34:11 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/15 03:41:52 visual_prompt]: Epoch 36 / 100: avg data time: 5.13e+00, avg batch time: 6.5824, average train loss: 0.5418
[11/15 03:42:45 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5878, average loss: 0.6763
[11/15 03:42:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.05	
[11/15 03:42:45 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/15 03:50:25 visual_prompt]: Epoch 37 / 100: avg data time: 5.12e+00, avg batch time: 6.5705, average train loss: 0.5536
[11/15 03:51:17 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5875, average loss: 0.6677
[11/15 03:51:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.03	
[11/15 03:51:17 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/15 03:58:58 visual_prompt]: Epoch 38 / 100: avg data time: 5.13e+00, avg batch time: 6.5812, average train loss: 0.5113
[11/15 03:59:50 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5867, average loss: 0.7031
[11/15 03:59:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.23	
[11/15 03:59:50 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/15 04:07:30 visual_prompt]: Epoch 39 / 100: avg data time: 5.11e+00, avg batch time: 6.5656, average train loss: 0.5325
[11/15 04:08:23 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5860, average loss: 0.6422
[11/15 04:08:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.11	
[11/15 04:08:23 visual_prompt]: Stopping early.
[11/15 04:08:23 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 04:08:23 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 04:08:23 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/15 04:08:23 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 04:08:23 visual_prompt]: Training with config:
[11/15 04:08:23 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 04:08:23 visual_prompt]: Loading training data...
[11/15 04:08:23 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 04:08:23 visual_prompt]: Loading validation data...
[11/15 04:08:23 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 04:08:23 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 04:08:26 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 04:08:26 visual_prompt]: tuned percent:0.532
[11/15 04:08:26 visual_prompt]: Device used for model: 0
[11/15 04:08:26 visual_prompt]: Setting up Evaluator...
[11/15 04:08:26 visual_prompt]: Setting up Trainer...
[11/15 04:08:26 visual_prompt]: 	Setting up the optimizer...
[11/15 04:08:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 04:16:07 visual_prompt]: Epoch 1 / 100: avg data time: 5.13e+00, avg batch time: 6.5835, average train loss: 1.4863
[11/15 04:16:59 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5871, average loss: 1.4553
[11/15 04:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 04:16:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/15 04:24:40 visual_prompt]: Epoch 2 / 100: avg data time: 5.13e+00, avg batch time: 6.5807, average train loss: 0.9797
[11/15 04:25:33 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.5854, average loss: 0.7201
[11/15 04:25:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.31	
[11/15 04:25:33 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/15 04:33:13 visual_prompt]: Epoch 3 / 100: avg data time: 5.12e+00, avg batch time: 6.5671, average train loss: 0.7163
[11/15 04:34:05 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5878, average loss: 0.7427
[11/15 04:34:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.67	
[11/15 04:34:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/15 04:41:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.10e+00, avg batch time: 6.5518, average train loss: 0.7474
[11/15 04:42:36 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5840, average loss: 0.7969
[11/15 04:42:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[11/15 04:42:36 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/15 04:50:15 visual_prompt]: Epoch 5 / 100: avg data time: 5.10e+00, avg batch time: 6.5525, average train loss: 0.7629
[11/15 04:51:08 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5870, average loss: 0.7053
[11/15 04:51:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/15 04:51:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/15 04:58:49 visual_prompt]: Epoch 6 / 100: avg data time: 5.14e+00, avg batch time: 6.5865, average train loss: 0.7480
[11/15 04:59:41 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5884, average loss: 0.6837
[11/15 04:59:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.51	
[11/15 04:59:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/15 05:07:20 visual_prompt]: Epoch 7 / 100: avg data time: 5.10e+00, avg batch time: 6.5503, average train loss: 0.7033
[11/15 05:08:12 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5849, average loss: 1.2788
[11/15 05:08:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.86	
[11/15 05:08:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/15 05:15:52 visual_prompt]: Epoch 8 / 100: avg data time: 5.12e+00, avg batch time: 6.5673, average train loss: 0.7262
[11/15 05:16:45 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5838, average loss: 1.1075
[11/15 05:16:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.03	
[11/15 05:16:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/15 05:24:24 visual_prompt]: Epoch 9 / 100: avg data time: 5.11e+00, avg batch time: 6.5619, average train loss: 0.7955
[11/15 05:25:17 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5859, average loss: 0.6798
[11/15 05:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.99	
[11/15 05:25:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/15 05:32:56 visual_prompt]: Epoch 10 / 100: avg data time: 5.10e+00, avg batch time: 6.5541, average train loss: 0.6855
[11/15 05:33:48 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5841, average loss: 0.6707
[11/15 05:33:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.98	
[11/15 05:33:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/15 05:41:29 visual_prompt]: Epoch 11 / 100: avg data time: 5.13e+00, avg batch time: 6.5764, average train loss: 0.7567
[11/15 05:42:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5839, average loss: 0.8582
[11/15 05:42:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.06	
[11/15 05:42:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/15 05:50:00 visual_prompt]: Epoch 12 / 100: avg data time: 5.11e+00, avg batch time: 6.5578, average train loss: 0.7438
[11/15 05:50:53 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5863, average loss: 0.6770
[11/15 05:50:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 67.46	
[11/15 05:50:53 visual_prompt]: Best epoch 12: best metric: -0.677
[11/15 05:50:53 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/15 05:58:32 visual_prompt]: Epoch 13 / 100: avg data time: 5.11e+00, avg batch time: 6.5640, average train loss: 0.7849
[11/15 05:59:25 visual_prompt]: Inference (val):avg data time: 9.27e-04, avg batch time: 0.5870, average loss: 0.6623
[11/15 05:59:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 65.83	
[11/15 05:59:25 visual_prompt]: Best epoch 13: best metric: -0.662
[11/15 05:59:25 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/15 06:07:04 visual_prompt]: Epoch 14 / 100: avg data time: 5.11e+00, avg batch time: 6.5639, average train loss: 0.6978
[11/15 06:07:57 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5843, average loss: 0.6987
[11/15 06:07:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 68.24	
[11/15 06:07:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/15 06:15:36 visual_prompt]: Epoch 15 / 100: avg data time: 5.10e+00, avg batch time: 6.5497, average train loss: 0.7028
[11/15 06:16:28 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5886, average loss: 0.6472
[11/15 06:16:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.56	
[11/15 06:16:28 visual_prompt]: Best epoch 15: best metric: -0.647
[11/15 06:16:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/15 06:24:07 visual_prompt]: Epoch 16 / 100: avg data time: 5.10e+00, avg batch time: 6.5567, average train loss: 0.6770
[11/15 06:25:00 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5884, average loss: 0.6824
[11/15 06:25:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[11/15 06:25:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/15 06:32:39 visual_prompt]: Epoch 17 / 100: avg data time: 5.11e+00, avg batch time: 6.5641, average train loss: 0.7268
[11/15 06:33:32 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5852, average loss: 0.7043
[11/15 06:33:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.13	
[11/15 06:33:32 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/15 06:41:11 visual_prompt]: Epoch 18 / 100: avg data time: 5.10e+00, avg batch time: 6.5519, average train loss: 0.6486
[11/15 06:42:03 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5871, average loss: 0.8783
[11/15 06:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.12	
[11/15 06:42:03 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/15 06:49:42 visual_prompt]: Epoch 19 / 100: avg data time: 5.10e+00, avg batch time: 6.5576, average train loss: 0.6995
[11/15 06:50:35 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5853, average loss: 0.7400
[11/15 06:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.44	
[11/15 06:50:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/15 06:58:16 visual_prompt]: Epoch 20 / 100: avg data time: 5.13e+00, avg batch time: 6.5795, average train loss: 0.6414
[11/15 06:59:08 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5888, average loss: 0.6653
[11/15 06:59:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.60	
[11/15 06:59:08 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/15 07:06:49 visual_prompt]: Epoch 21 / 100: avg data time: 5.12e+00, avg batch time: 6.5755, average train loss: 0.6528
[11/15 07:07:41 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5837, average loss: 0.6631
[11/15 07:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.48	
[11/15 07:07:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/15 07:15:21 visual_prompt]: Epoch 22 / 100: avg data time: 5.12e+00, avg batch time: 6.5737, average train loss: 0.6738
[11/15 07:16:14 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5857, average loss: 0.7469
[11/15 07:16:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 71.20	
[11/15 07:16:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/15 07:23:55 visual_prompt]: Epoch 23 / 100: avg data time: 5.14e+00, avg batch time: 6.5849, average train loss: 0.6244
[11/15 07:24:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5841, average loss: 0.6813
[11/15 07:24:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.94	
[11/15 07:24:47 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/15 07:32:27 visual_prompt]: Epoch 24 / 100: avg data time: 5.11e+00, avg batch time: 6.5605, average train loss: 0.6168
[11/15 07:33:19 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5866, average loss: 0.6321
[11/15 07:33:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.16	
[11/15 07:33:19 visual_prompt]: Best epoch 24: best metric: -0.632
[11/15 07:33:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/15 07:41:00 visual_prompt]: Epoch 25 / 100: avg data time: 5.13e+00, avg batch time: 6.5798, average train loss: 0.6264
[11/15 07:41:53 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5885, average loss: 0.6319
[11/15 07:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.70	
[11/15 07:41:53 visual_prompt]: Best epoch 25: best metric: -0.632
[11/15 07:41:53 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/15 07:49:32 visual_prompt]: Epoch 26 / 100: avg data time: 5.11e+00, avg batch time: 6.5607, average train loss: 0.6416
[11/15 07:50:25 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5838, average loss: 0.7645
[11/15 07:50:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 70.99	
[11/15 07:50:25 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/15 07:58:03 visual_prompt]: Epoch 27 / 100: avg data time: 5.10e+00, avg batch time: 6.5485, average train loss: 0.6318
[11/15 07:58:56 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5942, average loss: 0.6800
[11/15 07:58:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.19	
[11/15 07:58:56 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/15 08:06:36 visual_prompt]: Epoch 28 / 100: avg data time: 5.12e+00, avg batch time: 6.5686, average train loss: 0.6410
[11/15 08:07:28 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5855, average loss: 0.6618
[11/15 08:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.80	
[11/15 08:07:28 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/15 08:15:09 visual_prompt]: Epoch 29 / 100: avg data time: 5.12e+00, avg batch time: 6.5756, average train loss: 0.5998
[11/15 08:16:01 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.5861, average loss: 0.8979
[11/15 08:16:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.34	
[11/15 08:16:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/15 08:23:42 visual_prompt]: Epoch 30 / 100: avg data time: 5.13e+00, avg batch time: 6.5778, average train loss: 0.6431
[11/15 08:24:34 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5846, average loss: 0.7204
[11/15 08:24:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.93	
[11/15 08:24:34 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/15 08:32:13 visual_prompt]: Epoch 31 / 100: avg data time: 5.10e+00, avg batch time: 6.5490, average train loss: 0.5813
[11/15 08:33:05 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.5854, average loss: 0.6421
[11/15 08:33:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.18	
[11/15 08:33:05 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/15 08:40:45 visual_prompt]: Epoch 32 / 100: avg data time: 5.12e+00, avg batch time: 6.5675, average train loss: 0.5795
[11/15 08:41:38 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5891, average loss: 0.7390
[11/15 08:41:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 73.18	
[11/15 08:41:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/15 08:49:18 visual_prompt]: Epoch 33 / 100: avg data time: 5.13e+00, avg batch time: 6.5777, average train loss: 0.6177
[11/15 08:50:11 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5875, average loss: 0.6541
[11/15 08:50:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.09	
[11/15 08:50:11 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/15 08:57:50 visual_prompt]: Epoch 34 / 100: avg data time: 5.10e+00, avg batch time: 6.5532, average train loss: 0.5526
[11/15 08:58:42 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5845, average loss: 0.6405
[11/15 08:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.90	
[11/15 08:58:42 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/15 09:06:22 visual_prompt]: Epoch 35 / 100: avg data time: 5.11e+00, avg batch time: 6.5621, average train loss: 0.5288
[11/15 09:07:14 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5857, average loss: 0.6733
[11/15 09:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.59	
[11/15 09:07:14 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/15 09:14:55 visual_prompt]: Epoch 36 / 100: avg data time: 5.13e+00, avg batch time: 6.5836, average train loss: 0.5462
[11/15 09:15:48 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5847, average loss: 0.7197
[11/15 09:15:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.81	
[11/15 09:15:48 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/15 09:23:27 visual_prompt]: Epoch 37 / 100: avg data time: 5.11e+00, avg batch time: 6.5604, average train loss: 0.5590
[11/15 09:24:20 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5849, average loss: 0.6606
[11/15 09:24:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 70.86	
[11/15 09:24:20 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/15 09:32:00 visual_prompt]: Epoch 38 / 100: avg data time: 5.13e+00, avg batch time: 6.5818, average train loss: 0.5231
[11/15 09:32:53 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5860, average loss: 0.6995
[11/15 09:32:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.39	
[11/15 09:32:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/15 09:40:39 visual_prompt]: Epoch 39 / 100: avg data time: 5.20e+00, avg batch time: 6.6517, average train loss: 0.5196
[11/15 09:41:30 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5919, average loss: 0.6612
[11/15 09:41:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.29	
[11/15 09:41:30 visual_prompt]: Stopping early.
[11/15 09:41:30 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 09:41:30 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 09:41:30 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/15 09:41:30 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 09:41:30 visual_prompt]: Training with config:
[11/15 09:41:30 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 09:41:30 visual_prompt]: Loading training data...
[11/15 09:41:30 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 09:41:30 visual_prompt]: Loading validation data...
[11/15 09:41:30 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 09:41:30 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 09:41:33 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 09:41:33 visual_prompt]: tuned percent:0.532
[11/15 09:41:34 visual_prompt]: Device used for model: 0
[11/15 09:41:34 visual_prompt]: Setting up Evaluator...
[11/15 09:41:34 visual_prompt]: Setting up Trainer...
[11/15 09:41:34 visual_prompt]: 	Setting up the optimizer...
[11/15 09:41:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 09:49:26 visual_prompt]: Epoch 1 / 100: avg data time: 5.27e+00, avg batch time: 6.7518, average train loss: 1.4863
[11/15 09:50:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5973, average loss: 1.4553
[11/15 09:50:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 09:50:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/15 09:58:17 visual_prompt]: Epoch 2 / 100: avg data time: 5.32e+00, avg batch time: 6.7985, average train loss: 0.9470
[11/15 09:59:11 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5986, average loss: 0.6877
[11/15 09:59:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.80	
[11/15 09:59:11 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/15 10:06:54 visual_prompt]: Epoch 3 / 100: avg data time: 5.14e+00, avg batch time: 6.6160, average train loss: 0.7053
[11/15 10:07:46 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5950, average loss: 0.7360
[11/15 10:07:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[11/15 10:07:46 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/15 10:15:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.35e+00, avg batch time: 6.8249, average train loss: 0.7236
[11/15 10:16:38 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5953, average loss: 0.7160
[11/15 10:16:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/15 10:16:38 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/15 10:24:31 visual_prompt]: Epoch 5 / 100: avg data time: 5.28e+00, avg batch time: 6.7553, average train loss: 0.7178
[11/15 10:25:25 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5968, average loss: 0.6843
[11/15 10:25:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.98	
[11/15 10:25:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/15 10:33:10 visual_prompt]: Epoch 6 / 100: avg data time: 5.16e+00, avg batch time: 6.6348, average train loss: 0.7115
[11/15 10:34:02 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.6021, average loss: 0.7212
[11/15 10:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/15 10:34:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/15 10:41:49 visual_prompt]: Epoch 7 / 100: avg data time: 5.21e+00, avg batch time: 6.6781, average train loss: 0.7270
[11/15 10:42:44 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5932, average loss: 0.6919
[11/15 10:42:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 58.95	
[11/15 10:42:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/15 10:50:40 visual_prompt]: Epoch 8 / 100: avg data time: 5.32e+00, avg batch time: 6.7962, average train loss: 0.7129
[11/15 10:51:34 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5954, average loss: 0.6984
[11/15 10:51:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/15 10:51:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/15 10:59:18 visual_prompt]: Epoch 9 / 100: avg data time: 5.15e+00, avg batch time: 6.6232, average train loss: 0.7031
[11/15 11:00:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5921, average loss: 0.7259
[11/15 11:00:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[11/15 11:00:10 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/15 11:07:58 visual_prompt]: Epoch 10 / 100: avg data time: 5.21e+00, avg batch time: 6.6830, average train loss: 0.6923
[11/15 11:08:52 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5944, average loss: 0.6895
[11/15 11:08:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.06	
[11/15 11:08:52 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/15 11:16:48 visual_prompt]: Epoch 11 / 100: avg data time: 5.33e+00, avg batch time: 6.7998, average train loss: 0.6961
[11/15 11:17:42 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.6008, average loss: 0.6916
[11/15 11:17:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.39	
[11/15 11:17:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/15 11:25:29 visual_prompt]: Epoch 12 / 100: avg data time: 5.18e+00, avg batch time: 6.6581, average train loss: 0.6969
[11/15 11:26:23 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5980, average loss: 0.6994
[11/15 11:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.45	
[11/15 11:26:23 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/15 11:34:09 visual_prompt]: Epoch 13 / 100: avg data time: 5.18e+00, avg batch time: 6.6590, average train loss: 0.7053
[11/15 11:35:04 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5977, average loss: 0.6900
[11/15 11:35:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[11/15 11:35:04 visual_prompt]: Best epoch 13: best metric: -0.690
[11/15 11:35:04 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/15 11:42:59 visual_prompt]: Epoch 14 / 100: avg data time: 5.31e+00, avg batch time: 6.7838, average train loss: 0.7083
[11/15 11:43:53 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5960, average loss: 0.6885
[11/15 11:43:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.32	
[11/15 11:43:53 visual_prompt]: Best epoch 14: best metric: -0.688
[11/15 11:43:53 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/15 11:51:45 visual_prompt]: Epoch 15 / 100: avg data time: 5.27e+00, avg batch time: 6.7440, average train loss: 0.7088
[11/15 11:52:38 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.6004, average loss: 0.7085
[11/15 11:52:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.31	
[11/15 11:52:38 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/15 12:00:35 visual_prompt]: Epoch 16 / 100: avg data time: 5.35e+00, avg batch time: 6.8164, average train loss: 0.7287
[11/15 12:01:30 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5928, average loss: 0.8338
[11/15 12:01:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.60	
[11/15 12:01:30 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/15 12:09:27 visual_prompt]: Epoch 17 / 100: avg data time: 5.34e+00, avg batch time: 6.8116, average train loss: 0.7250
[11/15 12:10:21 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5947, average loss: 0.6892
[11/15 12:10:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/15 12:10:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/15 12:18:10 visual_prompt]: Epoch 18 / 100: avg data time: 5.22e+00, avg batch time: 6.6931, average train loss: 0.7213
[11/15 12:19:02 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5943, average loss: 0.8450
[11/15 12:19:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.84	
[11/15 12:19:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/15 12:26:43 visual_prompt]: Epoch 19 / 100: avg data time: 5.12e+00, avg batch time: 6.5963, average train loss: 0.7093
[11/15 12:27:38 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5978, average loss: 0.7779
[11/15 12:27:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[11/15 12:27:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/15 12:35:38 visual_prompt]: Epoch 20 / 100: avg data time: 5.38e+00, avg batch time: 6.8540, average train loss: 0.7058
[11/15 12:36:32 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5943, average loss: 0.7007
[11/15 12:36:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.80	
[11/15 12:36:32 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/15 12:44:17 visual_prompt]: Epoch 21 / 100: avg data time: 5.16e+00, avg batch time: 6.6339, average train loss: 0.7006
[11/15 12:45:13 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5956, average loss: 0.7117
[11/15 12:45:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/15 12:45:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/15 12:52:58 visual_prompt]: Epoch 22 / 100: avg data time: 5.16e+00, avg batch time: 6.6319, average train loss: 0.7042
[11/15 12:53:52 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5924, average loss: 0.6975
[11/15 12:53:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[11/15 12:53:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/15 13:01:49 visual_prompt]: Epoch 23 / 100: avg data time: 5.34e+00, avg batch time: 6.8183, average train loss: 0.6960
[11/15 13:02:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.6007, average loss: 0.7023
[11/15 13:02:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.91	
[11/15 13:02:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/15 13:10:31 visual_prompt]: Epoch 24 / 100: avg data time: 5.18e+00, avg batch time: 6.6594, average train loss: 0.6960
[11/15 13:11:24 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5968, average loss: 0.6989
[11/15 13:11:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.51	
[11/15 13:11:24 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/15 13:19:11 visual_prompt]: Epoch 25 / 100: avg data time: 5.19e+00, avg batch time: 6.6685, average train loss: 0.6955
[11/15 13:20:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5970, average loss: 0.7162
[11/15 13:20:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/15 13:20:05 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/15 13:28:01 visual_prompt]: Epoch 26 / 100: avg data time: 5.32e+00, avg batch time: 6.7923, average train loss: 0.7033
[11/15 13:28:55 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5952, average loss: 0.6946
[11/15 13:28:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[11/15 13:28:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/15 13:36:45 visual_prompt]: Epoch 27 / 100: avg data time: 5.23e+00, avg batch time: 6.7125, average train loss: 0.6954
[11/15 13:37:38 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5932, average loss: 0.6879
[11/15 13:37:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/15 13:37:38 visual_prompt]: Best epoch 27: best metric: -0.688
[11/15 13:37:38 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/15 13:45:24 visual_prompt]: Epoch 28 / 100: avg data time: 5.18e+00, avg batch time: 6.6562, average train loss: 0.6974
[11/15 13:46:18 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5959, average loss: 0.6960
[11/15 13:46:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.43	
[11/15 13:46:18 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/15 13:54:14 visual_prompt]: Epoch 29 / 100: avg data time: 5.32e+00, avg batch time: 6.7906, average train loss: 0.6916
[11/15 13:55:08 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.6001, average loss: 0.6871
[11/15 13:55:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.03	
[11/15 13:55:08 visual_prompt]: Best epoch 29: best metric: -0.687
[11/15 13:55:08 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/15 14:02:55 visual_prompt]: Epoch 30 / 100: avg data time: 5.20e+00, avg batch time: 6.6757, average train loss: 0.6998
[11/15 14:03:47 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5963, average loss: 0.6899
[11/15 14:03:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.69	
[11/15 14:03:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/15 14:11:30 visual_prompt]: Epoch 31 / 100: avg data time: 5.13e+00, avg batch time: 6.6069, average train loss: 0.6951
[11/15 14:12:24 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5912, average loss: 0.6898
[11/15 14:12:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.87	
[11/15 14:12:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/15 14:20:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.32e+00, avg batch time: 6.7946, average train loss: 0.7010
[11/15 14:21:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.6003, average loss: 0.7336
[11/15 14:21:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.85	
[11/15 14:21:14 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/15 14:29:04 visual_prompt]: Epoch 33 / 100: avg data time: 5.25e+00, avg batch time: 6.7184, average train loss: 0.6965
[11/15 14:29:57 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.6002, average loss: 0.6917
[11/15 14:29:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 62.27	
[11/15 14:29:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/15 14:37:42 visual_prompt]: Epoch 34 / 100: avg data time: 5.17e+00, avg batch time: 6.6457, average train loss: 0.6946
[11/15 14:38:36 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5905, average loss: 0.6879
[11/15 14:38:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.21	
[11/15 14:38:36 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/15 14:46:36 visual_prompt]: Epoch 35 / 100: avg data time: 5.37e+00, avg batch time: 6.8518, average train loss: 0.7001
[11/15 14:47:30 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.5959, average loss: 0.6938
[11/15 14:47:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.13	
[11/15 14:47:30 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/15 14:55:16 visual_prompt]: Epoch 36 / 100: avg data time: 5.18e+00, avg batch time: 6.6524, average train loss: 0.6927
[11/15 14:56:10 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.6000, average loss: 0.6883
[11/15 14:56:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[11/15 14:56:10 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/15 15:03:54 visual_prompt]: Epoch 37 / 100: avg data time: 5.15e+00, avg batch time: 6.6279, average train loss: 0.6931
[11/15 15:04:48 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5939, average loss: 0.7913
[11/15 15:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.57	
[11/15 15:04:48 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/15 15:12:44 visual_prompt]: Epoch 38 / 100: avg data time: 5.31e+00, avg batch time: 6.7903, average train loss: 0.6962
[11/15 15:13:38 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5959, average loss: 0.6965
[11/15 15:13:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.03	
[11/15 15:13:38 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/15 15:21:28 visual_prompt]: Epoch 39 / 100: avg data time: 5.24e+00, avg batch time: 6.7077, average train loss: 0.7008
[11/15 15:22:20 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5925, average loss: 0.6908
[11/15 15:22:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/15 15:22:20 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/15 15:30:05 visual_prompt]: Epoch 40 / 100: avg data time: 5.16e+00, avg batch time: 6.6453, average train loss: 0.6914
[11/15 15:31:01 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5986, average loss: 0.6844
[11/15 15:31:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.77	
[11/15 15:31:01 visual_prompt]: Best epoch 40: best metric: -0.684
[11/15 15:31:01 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/15 15:39:01 visual_prompt]: Epoch 41 / 100: avg data time: 5.39e+00, avg batch time: 6.8657, average train loss: 0.6982
[11/15 15:39:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.6018, average loss: 0.6918
[11/15 15:39:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[11/15 15:39:59 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/15 15:47:40 visual_prompt]: Epoch 42 / 100: avg data time: 5.11e+00, avg batch time: 6.5847, average train loss: 0.7008
[11/15 15:48:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5975, average loss: 0.7023
[11/15 15:48:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/15 15:48:34 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/15 15:56:27 visual_prompt]: Epoch 43 / 100: avg data time: 5.28e+00, avg batch time: 6.7633, average train loss: 0.6960
[11/15 15:57:23 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5974, average loss: 0.6900
[11/15 15:57:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.63	
[11/15 15:57:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/15 16:05:22 visual_prompt]: Epoch 44 / 100: avg data time: 5.37e+00, avg batch time: 6.8446, average train loss: 0.6979
[11/15 16:06:16 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5957, average loss: 0.7074
[11/15 16:06:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.46	
[11/15 16:06:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/15 16:14:13 visual_prompt]: Epoch 45 / 100: avg data time: 5.33e+00, avg batch time: 6.8107, average train loss: 0.6933
[11/15 16:15:05 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5932, average loss: 0.7020
[11/15 16:15:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.02	
[11/15 16:15:05 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/15 16:22:44 visual_prompt]: Epoch 46 / 100: avg data time: 5.07e+00, avg batch time: 6.5482, average train loss: 0.6962
[11/15 16:23:38 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5981, average loss: 0.6898
[11/15 16:23:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[11/15 16:23:38 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/15 16:31:34 visual_prompt]: Epoch 47 / 100: avg data time: 5.31e+00, avg batch time: 6.7912, average train loss: 0.7006
[11/15 16:32:28 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5944, average loss: 0.6995
[11/15 16:32:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.47	
[11/15 16:32:28 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/15 16:40:20 visual_prompt]: Epoch 48 / 100: avg data time: 5.27e+00, avg batch time: 6.7412, average train loss: 0.7027
[11/15 16:41:12 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5915, average loss: 0.7172
[11/15 16:41:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.75	
[11/15 16:41:12 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/15 16:48:54 visual_prompt]: Epoch 49 / 100: avg data time: 5.11e+00, avg batch time: 6.5908, average train loss: 0.6985
[11/15 16:49:46 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5968, average loss: 0.6913
[11/15 16:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.02	
[11/15 16:49:46 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/15 16:57:40 visual_prompt]: Epoch 50 / 100: avg data time: 5.30e+00, avg batch time: 6.7695, average train loss: 0.6974
[11/15 16:58:34 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.6007, average loss: 0.6969
[11/15 16:58:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.89	
[11/15 16:58:34 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/15 17:06:29 visual_prompt]: Epoch 51 / 100: avg data time: 5.31e+00, avg batch time: 6.7810, average train loss: 0.7010
[11/15 17:07:23 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5963, average loss: 0.6943
[11/15 17:07:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[11/15 17:07:23 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/15 17:15:04 visual_prompt]: Epoch 52 / 100: avg data time: 5.10e+00, avg batch time: 6.5848, average train loss: 0.6984
[11/15 17:15:58 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.6013, average loss: 0.6894
[11/15 17:15:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[11/15 17:15:58 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/15 17:23:59 visual_prompt]: Epoch 53 / 100: avg data time: 5.40e+00, avg batch time: 6.8692, average train loss: 0.6958
[11/15 17:24:53 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5975, average loss: 0.6893
[11/15 17:24:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/15 17:24:53 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/15 17:33:04 visual_prompt]: Epoch 54 / 100: avg data time: 5.53e+00, avg batch time: 7.0075, average train loss: 0.6962
[11/15 17:34:02 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5979, average loss: 0.7089
[11/15 17:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.54	
[11/15 17:34:02 visual_prompt]: Stopping early.
[11/15 17:34:02 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 17:34:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 17:34:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/15 17:34:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 17:34:02 visual_prompt]: Training with config:
[11/15 17:34:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 17:34:02 visual_prompt]: Loading training data...
[11/15 17:34:02 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 17:34:02 visual_prompt]: Loading validation data...
[11/15 17:34:02 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 17:34:02 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 17:34:13 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 17:34:13 visual_prompt]: tuned percent:0.532
[11/15 17:34:13 visual_prompt]: Device used for model: 0
[11/15 17:34:13 visual_prompt]: Setting up Evaluator...
[11/15 17:34:13 visual_prompt]: Setting up Trainer...
[11/15 17:34:13 visual_prompt]: 	Setting up the optimizer...
[11/15 17:34:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 17:41:58 visual_prompt]: Epoch 1 / 100: avg data time: 5.16e+00, avg batch time: 6.6446, average train loss: 1.4863
[11/15 17:42:51 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5983, average loss: 1.4553
[11/15 17:42:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 17:42:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/15 17:50:45 visual_prompt]: Epoch 2 / 100: avg data time: 5.30e+00, avg batch time: 6.7748, average train loss: 0.9491
[11/15 17:51:39 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.6012, average loss: 0.6880
[11/15 17:51:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 52.60	
[11/15 17:51:39 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/15 17:59:34 visual_prompt]: Epoch 3 / 100: avg data time: 5.31e+00, avg batch time: 6.7857, average train loss: 0.7079
[11/15 18:00:28 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5994, average loss: 0.7342
[11/15 18:00:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.19	
[11/15 18:00:28 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/15 18:08:09 visual_prompt]: Epoch 4 / 100: avg data time: 5.10e+00, avg batch time: 6.5755, average train loss: 0.7299
[11/15 18:09:00 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5979, average loss: 0.7114
[11/15 18:09:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/15 18:09:00 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/15 18:17:20 visual_prompt]: Epoch 5 / 100: avg data time: 5.68e+00, avg batch time: 7.1398, average train loss: 0.7246
[11/15 18:18:15 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5892, average loss: 0.6841
[11/15 18:18:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[11/15 18:18:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/15 18:26:30 visual_prompt]: Epoch 6 / 100: avg data time: 5.61e+00, avg batch time: 7.0698, average train loss: 0.7315
[11/15 18:27:28 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5928, average loss: 0.7569
[11/15 18:27:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/15 18:27:28 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/15 18:35:22 visual_prompt]: Epoch 7 / 100: avg data time: 5.31e+00, avg batch time: 6.7758, average train loss: 0.7253
[11/15 18:36:22 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5904, average loss: 0.8021
[11/15 18:36:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.19	
[11/15 18:36:22 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/15 18:44:31 visual_prompt]: Epoch 8 / 100: avg data time: 5.53e+00, avg batch time: 6.9969, average train loss: 0.7479
[11/15 18:45:27 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5931, average loss: 0.6975
[11/15 18:45:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.55	
[11/15 18:45:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/15 18:53:47 visual_prompt]: Epoch 9 / 100: avg data time: 5.68e+00, avg batch time: 7.1403, average train loss: 0.7136
[11/15 18:54:43 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5908, average loss: 0.7153
[11/15 18:54:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.35	
[11/15 18:54:43 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/15 19:03:00 visual_prompt]: Epoch 10 / 100: avg data time: 5.64e+00, avg batch time: 7.1020, average train loss: 0.6824
[11/15 19:03:54 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5912, average loss: 0.6736
[11/15 19:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.72	
[11/15 19:03:54 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/15 19:12:08 visual_prompt]: Epoch 11 / 100: avg data time: 5.58e+00, avg batch time: 7.0435, average train loss: 0.6939
[11/15 19:13:03 visual_prompt]: Inference (val):avg data time: 4.06e-05, avg batch time: 0.5899, average loss: 0.7041
[11/15 19:13:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.79	
[11/15 19:13:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/15 19:21:36 visual_prompt]: Epoch 12 / 100: avg data time: 5.87e+00, avg batch time: 7.3351, average train loss: 0.6945
[11/15 19:22:36 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5949, average loss: 0.7523
[11/15 19:22:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 63.40	
[11/15 19:22:36 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/15 19:30:58 visual_prompt]: Epoch 13 / 100: avg data time: 5.70e+00, avg batch time: 7.1624, average train loss: 0.7125
[11/15 19:31:50 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5940, average loss: 0.6589
[11/15 19:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 65.36	
[11/15 19:31:50 visual_prompt]: Best epoch 13: best metric: -0.659
[11/15 19:31:50 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/15 19:39:52 visual_prompt]: Epoch 14 / 100: avg data time: 5.41e+00, avg batch time: 6.8757, average train loss: 0.6953
[11/15 19:40:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5947, average loss: 0.6672
[11/15 19:40:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.62	
[11/15 19:40:45 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/15 19:49:05 visual_prompt]: Epoch 15 / 100: avg data time: 5.67e+00, avg batch time: 7.1334, average train loss: 0.6676
[11/15 19:50:05 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5920, average loss: 0.6714
[11/15 19:50:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.34	
[11/15 19:50:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/15 19:58:19 visual_prompt]: Epoch 16 / 100: avg data time: 5.60e+00, avg batch time: 7.0620, average train loss: 0.6789
[11/15 19:59:13 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5930, average loss: 0.8728
[11/15 19:59:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[11/15 19:59:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/15 20:07:22 visual_prompt]: Epoch 17 / 100: avg data time: 5.53e+00, avg batch time: 6.9894, average train loss: 0.6780
[11/15 20:08:21 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5835, average loss: 0.7124
[11/15 20:08:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[11/15 20:08:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/15 20:17:11 visual_prompt]: Epoch 18 / 100: avg data time: 6.12e+00, avg batch time: 7.5739, average train loss: 0.6630
[11/15 20:18:12 visual_prompt]: Inference (val):avg data time: 4.15e-05, avg batch time: 0.5843, average loss: 1.0120
[11/15 20:18:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.82	
[11/15 20:18:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/15 20:26:59 visual_prompt]: Epoch 19 / 100: avg data time: 6.07e+00, avg batch time: 7.5180, average train loss: 0.6533
[11/15 20:27:57 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5835, average loss: 0.7548
[11/15 20:27:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.16	
[11/15 20:27:57 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/15 20:36:20 visual_prompt]: Epoch 20 / 100: avg data time: 5.73e+00, avg batch time: 7.1774, average train loss: 0.6409
[11/15 20:37:18 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5840, average loss: 0.6403
[11/15 20:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.84	
[11/15 20:37:18 visual_prompt]: Best epoch 20: best metric: -0.640
[11/15 20:37:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/15 20:45:41 visual_prompt]: Epoch 21 / 100: avg data time: 5.73e+00, avg batch time: 7.1799, average train loss: 0.6575
[11/15 20:46:41 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5904, average loss: 0.6794
[11/15 20:46:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.00	
[11/15 20:46:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/15 20:55:18 visual_prompt]: Epoch 22 / 100: avg data time: 5.92e+00, avg batch time: 7.3741, average train loss: 0.6453
[11/15 20:56:13 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5902, average loss: 0.7086
[11/15 20:56:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.86	
[11/15 20:56:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/15 21:04:25 visual_prompt]: Epoch 23 / 100: avg data time: 5.57e+00, avg batch time: 7.0240, average train loss: 0.6508
[11/15 21:05:20 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5849, average loss: 0.6641
[11/15 21:05:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.18	
[11/15 21:05:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/15 21:14:05 visual_prompt]: Epoch 24 / 100: avg data time: 6.05e+00, avg batch time: 7.5019, average train loss: 0.6235
[11/15 21:15:06 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5892, average loss: 0.6345
[11/15 21:15:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.71	
[11/15 21:15:06 visual_prompt]: Best epoch 24: best metric: -0.635
[11/15 21:15:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/15 21:23:32 visual_prompt]: Epoch 25 / 100: avg data time: 5.78e+00, avg batch time: 7.2273, average train loss: 0.6316
[11/15 21:24:26 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5913, average loss: 0.6336
[11/15 21:24:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.01	
[11/15 21:24:26 visual_prompt]: Best epoch 25: best metric: -0.634
[11/15 21:24:26 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/15 21:32:23 visual_prompt]: Epoch 26 / 100: avg data time: 5.35e+00, avg batch time: 6.8071, average train loss: 0.6342
[11/15 21:33:15 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5861, average loss: 0.6540
[11/15 21:33:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 72.22	
[11/15 21:33:15 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/15 21:41:27 visual_prompt]: Epoch 27 / 100: avg data time: 5.57e+00, avg batch time: 7.0181, average train loss: 0.6237
[11/15 21:42:26 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5893, average loss: 0.6221
[11/15 21:42:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.81	
[11/15 21:42:26 visual_prompt]: Best epoch 27: best metric: -0.622
[11/15 21:42:26 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/15 21:51:27 visual_prompt]: Epoch 28 / 100: avg data time: 6.27e+00, avg batch time: 7.7195, average train loss: 0.6257
[11/15 21:52:25 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5888, average loss: 0.6117
[11/15 21:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.43	
[11/15 21:52:25 visual_prompt]: Best epoch 28: best metric: -0.612
[11/15 21:52:25 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/15 22:00:15 visual_prompt]: Epoch 29 / 100: avg data time: 5.26e+00, avg batch time: 6.7101, average train loss: 0.6023
[11/15 22:01:12 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5835, average loss: 0.6587
[11/15 22:01:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 74.41	
[11/15 22:01:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/15 22:09:42 visual_prompt]: Epoch 30 / 100: avg data time: 5.84e+00, avg batch time: 7.2903, average train loss: 0.6069
[11/15 22:10:40 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5875, average loss: 0.7991
[11/15 22:10:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 66.86	
[11/15 22:10:40 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/15 22:18:55 visual_prompt]: Epoch 31 / 100: avg data time: 5.61e+00, avg batch time: 7.0683, average train loss: 0.6304
[11/15 22:19:48 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5851, average loss: 0.6113
[11/15 22:19:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.51	
[11/15 22:19:48 visual_prompt]: Best epoch 31: best metric: -0.611
[11/15 22:19:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/15 22:27:39 visual_prompt]: Epoch 32 / 100: avg data time: 5.27e+00, avg batch time: 6.7212, average train loss: 0.6053
[11/15 22:28:34 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5891, average loss: 0.6145
[11/15 22:28:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.04	
[11/15 22:28:34 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/15 22:37:01 visual_prompt]: Epoch 33 / 100: avg data time: 5.79e+00, avg batch time: 7.2358, average train loss: 0.6138
[11/15 22:38:00 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5871, average loss: 0.6364
[11/15 22:38:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.65	
[11/15 22:38:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/15 22:46:23 visual_prompt]: Epoch 34 / 100: avg data time: 5.74e+00, avg batch time: 7.1949, average train loss: 0.6090
[11/15 22:47:19 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5836, average loss: 0.7317
[11/15 22:47:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.51	
[11/15 22:47:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/15 22:55:10 visual_prompt]: Epoch 35 / 100: avg data time: 5.27e+00, avg batch time: 6.7238, average train loss: 0.6169
[11/15 22:56:08 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5896, average loss: 0.6880
[11/15 22:56:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.57	
[11/15 22:56:08 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/15 23:04:33 visual_prompt]: Epoch 36 / 100: avg data time: 5.76e+00, avg batch time: 7.2170, average train loss: 0.5850
[11/15 23:05:30 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5833, average loss: 0.7057
[11/15 23:05:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.65	
[11/15 23:05:30 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/15 23:13:30 visual_prompt]: Epoch 37 / 100: avg data time: 5.40e+00, avg batch time: 6.8498, average train loss: 0.5986
[11/15 23:14:24 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5868, average loss: 0.6743
[11/15 23:14:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.61	
[11/15 23:14:24 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/15 23:22:23 visual_prompt]: Epoch 38 / 100: avg data time: 5.39e+00, avg batch time: 6.8402, average train loss: 0.5664
[11/15 23:23:21 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5841, average loss: 0.6420
[11/15 23:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.45	
[11/15 23:23:21 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/15 23:31:46 visual_prompt]: Epoch 39 / 100: avg data time: 5.75e+00, avg batch time: 7.2090, average train loss: 0.5699
[11/15 23:32:43 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5849, average loss: 0.6260
[11/15 23:32:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.13	
[11/15 23:32:43 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/15 23:40:49 visual_prompt]: Epoch 40 / 100: avg data time: 5.49e+00, avg batch time: 6.9402, average train loss: 0.5997
[11/15 23:41:41 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5888, average loss: 0.5932
[11/15 23:41:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 75.42	
[11/15 23:41:41 visual_prompt]: Best epoch 40: best metric: -0.593
[11/15 23:41:41 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/15 23:49:43 visual_prompt]: Epoch 41 / 100: avg data time: 5.43e+00, avg batch time: 6.8862, average train loss: 0.5634
[11/15 23:50:42 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.5878, average loss: 0.7009
[11/15 23:50:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 71.43	
[11/15 23:50:42 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/15 23:59:07 visual_prompt]: Epoch 42 / 100: avg data time: 5.77e+00, avg batch time: 7.2194, average train loss: 0.6058
[11/16 00:00:04 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5853, average loss: 0.5875
[11/16 00:00:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 75.65	
[11/16 00:00:04 visual_prompt]: Best epoch 42: best metric: -0.587
[11/16 00:00:04 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/16 00:08:06 visual_prompt]: Epoch 43 / 100: avg data time: 5.43e+00, avg batch time: 6.8843, average train loss: 0.5846
[11/16 00:09:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5877, average loss: 0.6091
[11/16 00:09:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 75.52	
[11/16 00:09:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/16 00:17:04 visual_prompt]: Epoch 44 / 100: avg data time: 5.43e+00, avg batch time: 6.8849, average train loss: 0.5680
[11/16 00:18:02 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5855, average loss: 0.5974
[11/16 00:18:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 76.07	
[11/16 00:18:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/16 00:26:25 visual_prompt]: Epoch 45 / 100: avg data time: 5.73e+00, avg batch time: 7.1854, average train loss: 0.5466
[11/16 00:27:22 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5876, average loss: 0.6223
[11/16 00:27:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 75.90	
[11/16 00:27:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/16 00:35:10 visual_prompt]: Epoch 46 / 100: avg data time: 5.23e+00, avg batch time: 6.6859, average train loss: 0.5373
[11/16 00:36:05 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5889, average loss: 0.6129
[11/16 00:36:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.76	
[11/16 00:36:05 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/16 00:44:33 visual_prompt]: Epoch 47 / 100: avg data time: 5.80e+00, avg batch time: 7.2546, average train loss: 0.5616
[11/16 00:45:31 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5871, average loss: 0.6943
[11/16 00:45:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.03	
[11/16 00:45:31 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/16 00:53:34 visual_prompt]: Epoch 48 / 100: avg data time: 5.44e+00, avg batch time: 6.8941, average train loss: 0.5120
[11/16 00:54:26 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5873, average loss: 0.6919
[11/16 00:54:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.48	
[11/16 00:54:26 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/16 01:02:19 visual_prompt]: Epoch 49 / 100: avg data time: 5.30e+00, avg batch time: 6.7537, average train loss: 0.5427
[11/16 01:03:15 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5869, average loss: 0.6314
[11/16 01:03:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 75.06	
[11/16 01:03:15 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/16 01:11:38 visual_prompt]: Epoch 50 / 100: avg data time: 5.73e+00, avg batch time: 7.1816, average train loss: 0.5317
[11/16 01:12:36 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5872, average loss: 0.7702
[11/16 01:12:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 76.09	
[11/16 01:12:36 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/16 01:20:50 visual_prompt]: Epoch 51 / 100: avg data time: 5.61e+00, avg batch time: 7.0608, average train loss: 0.4982
[11/16 01:21:43 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5909, average loss: 0.6444
[11/16 01:21:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.14	
[11/16 01:21:43 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/16 01:29:41 visual_prompt]: Epoch 52 / 100: avg data time: 5.38e+00, avg batch time: 6.8312, average train loss: 0.4847
[11/16 01:30:39 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5903, average loss: 0.8787
[11/16 01:30:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.97	
[11/16 01:30:39 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/16 01:39:05 visual_prompt]: Epoch 53 / 100: avg data time: 5.77e+00, avg batch time: 7.2236, average train loss: 0.4954
[11/16 01:40:01 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5861, average loss: 0.6453
[11/16 01:40:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.61	
[11/16 01:40:01 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/16 01:47:55 visual_prompt]: Epoch 54 / 100: avg data time: 5.31e+00, avg batch time: 6.7684, average train loss: 0.5597
[11/16 01:48:52 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5869, average loss: 0.6251
[11/16 01:48:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.91	
[11/16 01:48:52 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[11/16 01:56:49 visual_prompt]: Epoch 55 / 100: avg data time: 5.36e+00, avg batch time: 6.8135, average train loss: 0.4767
[11/16 01:57:46 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5876, average loss: 0.8301
[11/16 01:57:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 74.13	
[11/16 01:57:46 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[11/16 02:06:14 visual_prompt]: Epoch 56 / 100: avg data time: 5.79e+00, avg batch time: 7.2481, average train loss: 0.4914
[11/16 02:07:12 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5856, average loss: 0.7185
[11/16 02:07:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 74.06	
[11/16 02:07:12 visual_prompt]: Stopping early.
[11/16 02:07:12 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 02:07:12 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 02:07:12 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/16 02:07:12 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 02:07:12 visual_prompt]: Training with config:
[11/16 02:07:12 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 02:07:12 visual_prompt]: Loading training data...
[11/16 02:07:12 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 02:07:13 visual_prompt]: Loading validation data...
[11/16 02:07:13 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 02:07:13 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 02:07:19 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 02:07:19 visual_prompt]: tuned percent:0.532
[11/16 02:07:20 visual_prompt]: Device used for model: 0
[11/16 02:07:20 visual_prompt]: Setting up Evaluator...
[11/16 02:07:20 visual_prompt]: Setting up Trainer...
[11/16 02:07:20 visual_prompt]: 	Setting up the optimizer...
[11/16 02:07:20 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 02:15:23 visual_prompt]: Epoch 1 / 100: avg data time: 5.45e+00, avg batch time: 6.9092, average train loss: 1.4863
[11/16 02:16:16 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5898, average loss: 1.4553
[11/16 02:16:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 02:16:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/16 02:24:30 visual_prompt]: Epoch 2 / 100: avg data time: 5.61e+00, avg batch time: 7.0645, average train loss: 0.9493
[11/16 02:25:28 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5863, average loss: 0.6880
[11/16 02:25:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[11/16 02:25:28 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/16 02:33:51 visual_prompt]: Epoch 3 / 100: avg data time: 5.72e+00, avg batch time: 7.1748, average train loss: 0.7082
[11/16 02:34:47 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5905, average loss: 0.7340
[11/16 02:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/16 02:34:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/16 02:42:39 visual_prompt]: Epoch 4 / 100: avg data time: 5.29e+00, avg batch time: 6.7394, average train loss: 0.7307
[11/16 02:43:31 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5860, average loss: 0.7090
[11/16 02:43:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[11/16 02:43:31 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/16 02:51:43 visual_prompt]: Epoch 5 / 100: avg data time: 5.56e+00, avg batch time: 7.0164, average train loss: 0.7252
[11/16 02:52:40 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5903, average loss: 0.6838
[11/16 02:52:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[11/16 02:52:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/16 03:00:59 visual_prompt]: Epoch 6 / 100: avg data time: 5.67e+00, avg batch time: 7.1265, average train loss: 0.7344
[11/16 03:01:56 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5888, average loss: 0.7577
[11/16 03:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/16 03:01:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/16 03:09:44 visual_prompt]: Epoch 7 / 100: avg data time: 5.23e+00, avg batch time: 6.6840, average train loss: 0.7242
[11/16 03:10:42 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.5878, average loss: 0.8504
[11/16 03:10:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.99	
[11/16 03:10:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/16 03:19:10 visual_prompt]: Epoch 8 / 100: avg data time: 5.80e+00, avg batch time: 7.2561, average train loss: 0.7499
[11/16 03:20:07 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5898, average loss: 0.6996
[11/16 03:20:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.74	
[11/16 03:20:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/16 03:28:16 visual_prompt]: Epoch 9 / 100: avg data time: 5.53e+00, avg batch time: 6.9812, average train loss: 0.7138
[11/16 03:29:09 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5871, average loss: 0.7163
[11/16 03:29:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/16 03:29:09 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/16 03:37:03 visual_prompt]: Epoch 10 / 100: avg data time: 5.32e+00, avg batch time: 6.7683, average train loss: 0.6878
[11/16 03:37:59 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5869, average loss: 0.6738
[11/16 03:37:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.82	
[11/16 03:37:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/16 03:46:23 visual_prompt]: Epoch 11 / 100: avg data time: 5.74e+00, avg batch time: 7.1886, average train loss: 0.6977
[11/16 03:47:20 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5881, average loss: 0.7571
[11/16 03:47:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.04	
[11/16 03:47:20 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/16 03:55:21 visual_prompt]: Epoch 12 / 100: avg data time: 5.42e+00, avg batch time: 6.8718, average train loss: 0.6979
[11/16 03:56:13 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5856, average loss: 0.7149
[11/16 03:56:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 65.36	
[11/16 03:56:13 visual_prompt]: Best epoch 12: best metric: -0.715
[11/16 03:56:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/16 04:04:17 visual_prompt]: Epoch 13 / 100: avg data time: 5.45e+00, avg batch time: 6.9002, average train loss: 0.7183
[11/16 04:05:15 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5851, average loss: 0.6856
[11/16 04:05:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.96	
[11/16 04:05:15 visual_prompt]: Best epoch 13: best metric: -0.686
[11/16 04:05:15 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/16 04:13:38 visual_prompt]: Epoch 14 / 100: avg data time: 5.74e+00, avg batch time: 7.1938, average train loss: 0.7036
[11/16 04:14:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5906, average loss: 0.6629
[11/16 04:14:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 66.57	
[11/16 04:14:33 visual_prompt]: Best epoch 14: best metric: -0.663
[11/16 04:14:33 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/16 04:22:22 visual_prompt]: Epoch 15 / 100: avg data time: 5.25e+00, avg batch time: 6.6989, average train loss: 0.6662
[11/16 04:23:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5856, average loss: 0.6723
[11/16 04:23:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.41	
[11/16 04:23:16 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/16 04:31:16 visual_prompt]: Epoch 16 / 100: avg data time: 5.40e+00, avg batch time: 6.8538, average train loss: 0.6771
[11/16 04:32:14 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5867, average loss: 0.8632
[11/16 04:32:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.55	
[11/16 04:32:14 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/16 04:40:42 visual_prompt]: Epoch 17 / 100: avg data time: 5.79e+00, avg batch time: 7.2475, average train loss: 0.6680
[11/16 04:41:39 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5908, average loss: 0.7518
[11/16 04:41:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.51	
[11/16 04:41:39 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/16 04:49:31 visual_prompt]: Epoch 18 / 100: avg data time: 5.28e+00, avg batch time: 6.7340, average train loss: 0.6712
[11/16 04:50:23 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.5869, average loss: 1.0761
[11/16 04:50:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.45	
[11/16 04:50:23 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/16 04:58:42 visual_prompt]: Epoch 19 / 100: avg data time: 5.67e+00, avg batch time: 7.1212, average train loss: 0.6538
[11/16 04:59:41 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5879, average loss: 0.7831
[11/16 04:59:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 65.54	
[11/16 04:59:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/16 05:08:03 visual_prompt]: Epoch 20 / 100: avg data time: 5.72e+00, avg batch time: 7.1766, average train loss: 0.6353
[11/16 05:08:59 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.5874, average loss: 0.6844
[11/16 05:08:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.62	
[11/16 05:08:59 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/16 05:16:51 visual_prompt]: Epoch 21 / 100: avg data time: 5.29e+00, avg batch time: 6.7383, average train loss: 0.6583
[11/16 05:17:43 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5851, average loss: 0.6848
[11/16 05:17:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.09	
[11/16 05:17:43 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/16 05:25:55 visual_prompt]: Epoch 22 / 100: avg data time: 5.57e+00, avg batch time: 7.0194, average train loss: 0.6308
[11/16 05:26:52 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5854, average loss: 0.6568
[11/16 05:26:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.63	
[11/16 05:26:52 visual_prompt]: Best epoch 22: best metric: -0.657
[11/16 05:26:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/16 05:35:11 visual_prompt]: Epoch 23 / 100: avg data time: 5.68e+00, avg batch time: 7.1308, average train loss: 0.6247
[11/16 05:36:05 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5842, average loss: 0.6477
[11/16 05:36:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.17	
[11/16 05:36:05 visual_prompt]: Best epoch 23: best metric: -0.648
[11/16 05:36:05 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/16 05:43:47 visual_prompt]: Epoch 24 / 100: avg data time: 5.14e+00, avg batch time: 6.5974, average train loss: 0.6228
[11/16 05:44:44 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5880, average loss: 0.6699
[11/16 05:44:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.81	
[11/16 05:44:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/16 05:53:14 visual_prompt]: Epoch 25 / 100: avg data time: 5.83e+00, avg batch time: 7.2827, average train loss: 0.6063
[11/16 05:54:12 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5870, average loss: 0.6647
[11/16 05:54:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.21	
[11/16 05:54:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/16 06:02:15 visual_prompt]: Epoch 26 / 100: avg data time: 5.44e+00, avg batch time: 6.8888, average train loss: 0.6318
[11/16 06:03:07 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5863, average loss: 0.6728
[11/16 06:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.67	
[11/16 06:03:07 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/16 06:10:57 visual_prompt]: Epoch 27 / 100: avg data time: 5.26e+00, avg batch time: 6.7114, average train loss: 0.6058
[11/16 06:11:52 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5861, average loss: 0.6466
[11/16 06:11:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.45	
[11/16 06:11:52 visual_prompt]: Best epoch 27: best metric: -0.647
[11/16 06:11:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/16 06:20:15 visual_prompt]: Epoch 28 / 100: avg data time: 5.72e+00, avg batch time: 7.1747, average train loss: 0.6088
[11/16 06:21:13 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5876, average loss: 0.7036
[11/16 06:21:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.76	
[11/16 06:21:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/16 06:29:30 visual_prompt]: Epoch 29 / 100: avg data time: 5.65e+00, avg batch time: 7.1052, average train loss: 0.5846
[11/16 06:30:26 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5887, average loss: 0.7227
[11/16 06:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.44	
[11/16 06:30:26 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/16 06:38:23 visual_prompt]: Epoch 30 / 100: avg data time: 5.37e+00, avg batch time: 6.8169, average train loss: 0.6079
[11/16 06:39:21 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5870, average loss: 0.7836
[11/16 06:39:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.22	
[11/16 06:39:21 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/16 06:47:45 visual_prompt]: Epoch 31 / 100: avg data time: 5.74e+00, avg batch time: 7.1974, average train loss: 0.6060
[11/16 06:48:42 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5915, average loss: 0.7220
[11/16 06:48:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.14	
[11/16 06:48:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/16 06:56:42 visual_prompt]: Epoch 32 / 100: avg data time: 5.41e+00, avg batch time: 6.8599, average train loss: 0.5640
[11/16 06:57:40 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5846, average loss: 0.6857
[11/16 06:57:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.42	
[11/16 06:57:40 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/16 07:05:36 visual_prompt]: Epoch 33 / 100: avg data time: 5.35e+00, avg batch time: 6.8039, average train loss: 0.5462
[11/16 07:06:33 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5893, average loss: 0.7013
[11/16 07:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 64.37	
[11/16 07:06:33 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/16 07:14:55 visual_prompt]: Epoch 34 / 100: avg data time: 5.71e+00, avg batch time: 7.1636, average train loss: 0.5520
[11/16 07:15:52 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5845, average loss: 0.7849
[11/16 07:15:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 65.99	
[11/16 07:15:52 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/16 07:23:42 visual_prompt]: Epoch 35 / 100: avg data time: 5.26e+00, avg batch time: 6.7142, average train loss: 0.5556
[11/16 07:24:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5884, average loss: 0.6753
[11/16 07:24:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 67.29	
[11/16 07:24:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/16 07:32:49 visual_prompt]: Epoch 36 / 100: avg data time: 5.60e+00, avg batch time: 7.0507, average train loss: 0.5255
[11/16 07:33:47 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5851, average loss: 0.6607
[11/16 07:33:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.71	
[11/16 07:33:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/16 07:42:08 visual_prompt]: Epoch 37 / 100: avg data time: 5.71e+00, avg batch time: 7.1627, average train loss: 0.5362
[11/16 07:43:04 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5868, average loss: 0.6948
[11/16 07:43:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.23	
[11/16 07:43:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/16 07:50:47 visual_prompt]: Epoch 38 / 100: avg data time: 5.16e+00, avg batch time: 6.6135, average train loss: 0.4919
[11/16 07:51:40 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5878, average loss: 0.7667
[11/16 07:51:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.60	
[11/16 07:51:40 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/16 07:59:19 visual_prompt]: Epoch 39 / 100: avg data time: 5.11e+00, avg batch time: 6.5676, average train loss: 0.5148
[11/16 08:00:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5881, average loss: 0.8777
[11/16 08:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.50	
[11/16 08:00:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/16 08:07:52 visual_prompt]: Epoch 40 / 100: avg data time: 5.11e+00, avg batch time: 6.5639, average train loss: 0.4917
[11/16 08:08:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.5896, average loss: 0.7124
[11/16 08:08:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 65.92	
[11/16 08:08:44 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/16 08:16:24 visual_prompt]: Epoch 41 / 100: avg data time: 5.11e+00, avg batch time: 6.5682, average train loss: 0.4651
[11/16 08:17:17 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5875, average loss: 0.6851
[11/16 08:17:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.68	
[11/16 08:17:17 visual_prompt]: Stopping early.
[11/16 08:17:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 08:17:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 08:17:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/16 08:17:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 08:17:17 visual_prompt]: Training with config:
[11/16 08:17:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 08:17:17 visual_prompt]: Loading training data...
[11/16 08:17:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 08:17:17 visual_prompt]: Loading validation data...
[11/16 08:17:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 08:17:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 08:17:22 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 08:17:22 visual_prompt]: tuned percent:0.532
[11/16 08:17:22 visual_prompt]: Device used for model: 0
[11/16 08:17:22 visual_prompt]: Setting up Evaluator...
[11/16 08:17:22 visual_prompt]: Setting up Trainer...
[11/16 08:17:22 visual_prompt]: 	Setting up the optimizer...
[11/16 08:17:22 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 08:25:04 visual_prompt]: Epoch 1 / 100: avg data time: 5.14e+00, avg batch time: 6.5960, average train loss: 1.4863
[11/16 08:25:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5849, average loss: 1.4553
[11/16 08:25:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 08:25:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/16 08:33:36 visual_prompt]: Epoch 2 / 100: avg data time: 5.13e+00, avg batch time: 6.5808, average train loss: 0.9493
[11/16 08:34:29 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5889, average loss: 0.6880
[11/16 08:34:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[11/16 08:34:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/16 08:42:09 visual_prompt]: Epoch 3 / 100: avg data time: 5.11e+00, avg batch time: 6.5668, average train loss: 0.7082
[11/16 08:43:01 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.5890, average loss: 0.7340
[11/16 08:43:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/16 08:43:01 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/16 08:50:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.11e+00, avg batch time: 6.5573, average train loss: 0.7307
[11/16 08:51:33 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5861, average loss: 0.7090
[11/16 08:51:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.11	
[11/16 08:51:33 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/16 08:59:13 visual_prompt]: Epoch 5 / 100: avg data time: 5.11e+00, avg batch time: 6.5656, average train loss: 0.7252
[11/16 09:00:05 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5848, average loss: 0.6838
[11/16 09:00:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.10	
[11/16 09:00:05 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/16 09:07:46 visual_prompt]: Epoch 6 / 100: avg data time: 5.13e+00, avg batch time: 6.5793, average train loss: 0.7346
[11/16 09:08:39 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5912, average loss: 0.7580
[11/16 09:08:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.48	
[11/16 09:08:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/16 09:16:18 visual_prompt]: Epoch 7 / 100: avg data time: 5.10e+00, avg batch time: 6.5551, average train loss: 0.7241
[11/16 09:17:10 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5922, average loss: 0.8533
[11/16 09:17:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.05	
[11/16 09:17:10 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/16 09:24:51 visual_prompt]: Epoch 8 / 100: avg data time: 5.13e+00, avg batch time: 6.5817, average train loss: 0.7501
[11/16 09:25:44 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5866, average loss: 0.6991
[11/16 09:25:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.87	
[11/16 09:25:44 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/16 09:33:24 visual_prompt]: Epoch 9 / 100: avg data time: 5.11e+00, avg batch time: 6.5677, average train loss: 0.7138
[11/16 09:34:17 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5879, average loss: 0.7123
[11/16 09:34:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/16 09:34:17 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/16 09:41:58 visual_prompt]: Epoch 10 / 100: avg data time: 5.13e+00, avg batch time: 6.5826, average train loss: 0.6878
[11/16 09:42:50 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5894, average loss: 0.6762
[11/16 09:42:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.28	
[11/16 09:42:50 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/16 09:50:31 visual_prompt]: Epoch 11 / 100: avg data time: 5.13e+00, avg batch time: 6.5795, average train loss: 0.6993
[11/16 09:51:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5873, average loss: 0.7623
[11/16 09:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/16 09:51:24 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/16 09:59:04 visual_prompt]: Epoch 12 / 100: avg data time: 5.12e+00, avg batch time: 6.5680, average train loss: 0.6965
[11/16 09:59:56 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5858, average loss: 0.6973
[11/16 09:59:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 66.15	
[11/16 09:59:56 visual_prompt]: Best epoch 12: best metric: -0.697
[11/16 09:59:56 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/16 10:07:37 visual_prompt]: Epoch 13 / 100: avg data time: 5.12e+00, avg batch time: 6.5744, average train loss: 0.7136
[11/16 10:08:29 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5904, average loss: 0.6711
[11/16 10:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.31	
[11/16 10:08:29 visual_prompt]: Best epoch 13: best metric: -0.671
[11/16 10:08:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/16 10:16:09 visual_prompt]: Epoch 14 / 100: avg data time: 5.11e+00, avg batch time: 6.5685, average train loss: 0.7001
[11/16 10:17:02 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5878, average loss: 0.6705
[11/16 10:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.28	
[11/16 10:17:02 visual_prompt]: Best epoch 14: best metric: -0.671
[11/16 10:17:02 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/16 10:24:40 visual_prompt]: Epoch 15 / 100: avg data time: 5.10e+00, avg batch time: 6.5505, average train loss: 0.6658
[11/16 10:25:33 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5917, average loss: 0.6716
[11/16 10:25:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 64.17	
[11/16 10:25:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/16 10:33:12 visual_prompt]: Epoch 16 / 100: avg data time: 5.11e+00, avg batch time: 6.5597, average train loss: 0.6782
[11/16 10:34:05 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5864, average loss: 0.8483
[11/16 10:34:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.90	
[11/16 10:34:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/16 10:41:45 visual_prompt]: Epoch 17 / 100: avg data time: 5.11e+00, avg batch time: 6.5674, average train loss: 0.6665
[11/16 10:42:37 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5885, average loss: 0.7558
[11/16 10:42:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 67.99	
[11/16 10:42:37 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/16 10:50:17 visual_prompt]: Epoch 18 / 100: avg data time: 5.11e+00, avg batch time: 6.5669, average train loss: 0.6763
[11/16 10:51:10 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5876, average loss: 1.0653
[11/16 10:51:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.73	
[11/16 10:51:10 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/16 10:58:49 visual_prompt]: Epoch 19 / 100: avg data time: 5.11e+00, avg batch time: 6.5634, average train loss: 0.6516
[11/16 10:59:42 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5871, average loss: 0.8032
[11/16 10:59:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.79	
[11/16 10:59:42 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/16 11:07:23 visual_prompt]: Epoch 20 / 100: avg data time: 5.13e+00, avg batch time: 6.5825, average train loss: 0.6418
[11/16 11:08:16 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5889, average loss: 0.7043
[11/16 11:08:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.41	
[11/16 11:08:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/16 11:15:57 visual_prompt]: Epoch 21 / 100: avg data time: 5.14e+00, avg batch time: 6.5857, average train loss: 0.6660
[11/16 11:16:49 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5872, average loss: 0.6824
[11/16 11:16:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.57	
[11/16 11:16:49 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/16 11:24:30 visual_prompt]: Epoch 22 / 100: avg data time: 5.13e+00, avg batch time: 6.5805, average train loss: 0.6309
[11/16 11:25:23 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5897, average loss: 0.6781
[11/16 11:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.91	
[11/16 11:25:23 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/16 11:33:05 visual_prompt]: Epoch 23 / 100: avg data time: 5.15e+00, avg batch time: 6.6041, average train loss: 0.6169
[11/16 11:34:03 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5898, average loss: 0.6407
[11/16 11:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.87	
[11/16 11:34:03 visual_prompt]: Best epoch 23: best metric: -0.641
[11/16 11:34:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/16 11:41:43 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e+00, avg batch time: 6.5690, average train loss: 0.6264
[11/16 11:42:36 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5860, average loss: 0.6560
[11/16 11:42:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.63	
[11/16 11:42:36 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/16 11:50:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.13e+00, avg batch time: 6.5826, average train loss: 0.6078
[11/16 11:51:09 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5911, average loss: 0.6657
[11/16 11:51:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.50	
[11/16 11:51:09 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/16 11:58:49 visual_prompt]: Epoch 26 / 100: avg data time: 5.11e+00, avg batch time: 6.5626, average train loss: 0.6258
[11/16 11:59:41 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5857, average loss: 0.6963
[11/16 11:59:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.07	
[11/16 11:59:41 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/16 12:07:20 visual_prompt]: Epoch 27 / 100: avg data time: 5.10e+00, avg batch time: 6.5507, average train loss: 0.6132
[11/16 12:08:13 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5866, average loss: 0.6699
[11/16 12:08:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.37	
[11/16 12:08:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/16 12:15:53 visual_prompt]: Epoch 28 / 100: avg data time: 5.12e+00, avg batch time: 6.5731, average train loss: 0.6172
[11/16 12:16:46 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5892, average loss: 0.6365
[11/16 12:16:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.74	
[11/16 12:16:46 visual_prompt]: Best epoch 28: best metric: -0.637
[11/16 12:16:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/16 12:24:25 visual_prompt]: Epoch 29 / 100: avg data time: 5.10e+00, avg batch time: 6.5559, average train loss: 0.5780
[11/16 12:25:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5868, average loss: 0.7155
[11/16 12:25:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.52	
[11/16 12:25:17 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/16 12:32:59 visual_prompt]: Epoch 30 / 100: avg data time: 5.14e+00, avg batch time: 6.5960, average train loss: 0.5834
[11/16 12:33:52 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5881, average loss: 0.8498
[11/16 12:33:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 69.05	
[11/16 12:33:52 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/16 12:41:31 visual_prompt]: Epoch 31 / 100: avg data time: 5.11e+00, avg batch time: 6.5610, average train loss: 0.5799
[11/16 12:42:24 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5879, average loss: 0.6682
[11/16 12:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.53	
[11/16 12:42:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/16 12:50:04 visual_prompt]: Epoch 32 / 100: avg data time: 5.12e+00, avg batch time: 6.5742, average train loss: 0.5594
[11/16 12:50:57 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5880, average loss: 0.6407
[11/16 12:50:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.75	
[11/16 12:50:57 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/16 12:58:37 visual_prompt]: Epoch 33 / 100: avg data time: 5.12e+00, avg batch time: 6.5751, average train loss: 0.5476
[11/16 12:59:30 visual_prompt]: Inference (val):avg data time: 2.26e-05, avg batch time: 0.5891, average loss: 0.6488
[11/16 12:59:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.11	
[11/16 12:59:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/16 13:07:10 visual_prompt]: Epoch 34 / 100: avg data time: 5.11e+00, avg batch time: 6.5677, average train loss: 0.5400
[11/16 13:08:02 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5853, average loss: 0.6222
[11/16 13:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.72	
[11/16 13:08:02 visual_prompt]: Best epoch 34: best metric: -0.622
[11/16 13:08:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/16 13:15:42 visual_prompt]: Epoch 35 / 100: avg data time: 5.11e+00, avg batch time: 6.5624, average train loss: 0.5361
[11/16 13:16:35 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5848, average loss: 0.6581
[11/16 13:16:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.89	
[11/16 13:16:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/16 13:24:15 visual_prompt]: Epoch 36 / 100: avg data time: 5.13e+00, avg batch time: 6.5828, average train loss: 0.5185
[11/16 13:25:08 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5869, average loss: 0.6436
[11/16 13:25:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.56	
[11/16 13:25:08 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/16 13:32:49 visual_prompt]: Epoch 37 / 100: avg data time: 5.13e+00, avg batch time: 6.5871, average train loss: 0.5165
[11/16 13:33:42 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5888, average loss: 0.6916
[11/16 13:33:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.67	
[11/16 13:33:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/16 13:41:22 visual_prompt]: Epoch 38 / 100: avg data time: 5.12e+00, avg batch time: 6.5737, average train loss: 0.4875
[11/16 13:42:15 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5870, average loss: 0.7744
[11/16 13:42:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.36	
[11/16 13:42:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/16 13:49:56 visual_prompt]: Epoch 39 / 100: avg data time: 5.13e+00, avg batch time: 6.5791, average train loss: 0.5244
[11/16 13:50:49 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.5849, average loss: 0.7858
[11/16 13:50:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.88	
[11/16 13:50:49 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/16 13:58:27 visual_prompt]: Epoch 40 / 100: avg data time: 5.09e+00, avg batch time: 6.5413, average train loss: 0.4886
[11/16 13:59:19 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5957, average loss: 0.6871
[11/16 13:59:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.20	
[11/16 13:59:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/16 14:06:55 visual_prompt]: Epoch 41 / 100: avg data time: 5.04e+00, avg batch time: 6.5206, average train loss: 0.4619
[11/16 14:07:48 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.6026, average loss: 0.8473
[11/16 14:07:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.15	
[11/16 14:07:48 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/16 14:15:24 visual_prompt]: Epoch 42 / 100: avg data time: 5.04e+00, avg batch time: 6.5158, average train loss: 0.4683
[11/16 14:16:16 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5993, average loss: 0.6786
[11/16 14:16:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.96	
[11/16 14:16:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/16 14:23:53 visual_prompt]: Epoch 43 / 100: avg data time: 5.06e+00, avg batch time: 6.5293, average train loss: 0.4916
[11/16 14:24:46 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5946, average loss: 0.7111
[11/16 14:24:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.59	
[11/16 14:24:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/16 14:32:24 visual_prompt]: Epoch 44 / 100: avg data time: 5.07e+00, avg batch time: 6.5458, average train loss: 0.4377
[11/16 14:33:16 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5936, average loss: 0.7217
[11/16 14:33:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.48	
[11/16 14:33:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/16 14:40:53 visual_prompt]: Epoch 45 / 100: avg data time: 5.06e+00, avg batch time: 6.5305, average train loss: 0.4268
[11/16 14:41:45 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5937, average loss: 0.7279
[11/16 14:41:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.61	
[11/16 14:41:45 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/16 14:49:24 visual_prompt]: Epoch 46 / 100: avg data time: 5.07e+00, avg batch time: 6.5471, average train loss: 0.4284
[11/16 14:50:16 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5952, average loss: 0.7365
[11/16 14:50:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.32	
[11/16 14:50:16 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/16 14:57:53 visual_prompt]: Epoch 47 / 100: avg data time: 5.05e+00, avg batch time: 6.5265, average train loss: 0.4294
[11/16 14:58:45 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5989, average loss: 0.7785
[11/16 14:58:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.86	
[11/16 14:58:45 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/16 15:06:21 visual_prompt]: Epoch 48 / 100: avg data time: 5.04e+00, avg batch time: 6.5101, average train loss: 0.3932
[11/16 15:07:14 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5963, average loss: 0.7197
[11/16 15:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.17	
[11/16 15:07:14 visual_prompt]: Stopping early.
[11/16 15:07:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 15:07:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 15:07:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/16 15:07:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 15:07:14 visual_prompt]: Training with config:
[11/16 15:07:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.01/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 15:07:14 visual_prompt]: Loading training data...
[11/16 15:07:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 15:07:14 visual_prompt]: Loading validation data...
[11/16 15:07:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 15:07:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 15:07:21 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 15:07:21 visual_prompt]: tuned percent:0.532
[11/16 15:07:21 visual_prompt]: Device used for model: 0
[11/16 15:07:21 visual_prompt]: Setting up Evaluator...
[11/16 15:07:21 visual_prompt]: Setting up Trainer...
[11/16 15:07:21 visual_prompt]: 	Setting up the optimizer...
[11/16 15:07:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 15:14:59 visual_prompt]: Epoch 1 / 100: avg data time: 5.07e+00, avg batch time: 6.5410, average train loss: 1.4863
[11/16 15:15:52 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5939, average loss: 1.4553
[11/16 15:15:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 15:15:52 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/16 15:23:29 visual_prompt]: Epoch 2 / 100: avg data time: 5.06e+00, avg batch time: 6.5293, average train loss: 0.8422
[11/16 15:24:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5947, average loss: 0.6853
[11/16 15:24:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.22	
[11/16 15:24:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/16 15:31:58 visual_prompt]: Epoch 3 / 100: avg data time: 5.06e+00, avg batch time: 6.5288, average train loss: 0.7065
[11/16 15:32:50 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5950, average loss: 0.7517
[11/16 15:32:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.97	
[11/16 15:32:50 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/16 15:40:29 visual_prompt]: Epoch 4 / 100: avg data time: 5.08e+00, avg batch time: 6.5558, average train loss: 0.7180
[11/16 15:41:22 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5929, average loss: 0.7093
[11/16 15:41:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/16 15:41:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/16 15:49:01 visual_prompt]: Epoch 5 / 100: avg data time: 5.09e+00, avg batch time: 6.5560, average train loss: 0.7251
[11/16 15:49:53 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5983, average loss: 0.6796
[11/16 15:49:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 62.36	
[11/16 15:49:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/16 15:57:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.29e+00, avg batch time: 6.7678, average train loss: 0.7305
[11/16 15:58:43 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5949, average loss: 0.7493
[11/16 15:58:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.37	
[11/16 15:58:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/16 16:06:24 visual_prompt]: Epoch 7 / 100: avg data time: 5.12e+00, avg batch time: 6.5853, average train loss: 0.7018
[11/16 16:07:17 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5974, average loss: 0.8585
[11/16 16:07:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.09	
[11/16 16:07:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/16 16:15:03 visual_prompt]: Epoch 8 / 100: avg data time: 5.18e+00, avg batch time: 6.6546, average train loss: 0.7259
[11/16 16:15:57 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5939, average loss: 0.6974
[11/16 16:15:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.00	
[11/16 16:15:57 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/16 16:23:43 visual_prompt]: Epoch 9 / 100: avg data time: 5.19e+00, avg batch time: 6.6559, average train loss: 0.6999
[11/16 16:24:36 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5885, average loss: 0.7333
[11/16 16:24:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.43	
[11/16 16:24:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/16 16:32:20 visual_prompt]: Epoch 10 / 100: avg data time: 5.18e+00, avg batch time: 6.6305, average train loss: 0.6850
[11/16 16:33:13 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5891, average loss: 0.6883
[11/16 16:33:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.24	
[11/16 16:33:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/16 16:41:01 visual_prompt]: Epoch 11 / 100: avg data time: 5.23e+00, avg batch time: 6.6848, average train loss: 0.7027
[11/16 16:41:54 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5880, average loss: 0.6872
[11/16 16:41:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.04	
[11/16 16:41:54 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/16 16:49:42 visual_prompt]: Epoch 12 / 100: avg data time: 5.23e+00, avg batch time: 6.6796, average train loss: 0.6914
[11/16 16:50:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5878, average loss: 0.7007
[11/16 16:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.32	
[11/16 16:50:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/16 16:58:19 visual_prompt]: Epoch 13 / 100: avg data time: 5.18e+00, avg batch time: 6.6342, average train loss: 0.7069
[11/16 16:59:14 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5854, average loss: 0.6902
[11/16 16:59:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.51	
[11/16 16:59:14 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/16 17:07:21 visual_prompt]: Epoch 14 / 100: avg data time: 5.50e+00, avg batch time: 6.9599, average train loss: 0.6959
[11/16 17:08:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5994, average loss: 0.7292
[11/16 17:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.10	
[11/16 17:08:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/16 17:16:08 visual_prompt]: Epoch 15 / 100: avg data time: 5.26e+00, avg batch time: 6.7322, average train loss: 0.6943
[11/16 17:17:01 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5925, average loss: 0.6879
[11/16 17:17:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/16 17:17:01 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/16 17:24:48 visual_prompt]: Epoch 16 / 100: avg data time: 5.20e+00, avg batch time: 6.6748, average train loss: 0.6996
[11/16 17:25:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5935, average loss: 0.7077
[11/16 17:25:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.62	
[11/16 17:25:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/16 17:33:34 visual_prompt]: Epoch 17 / 100: avg data time: 5.30e+00, avg batch time: 6.7698, average train loss: 0.6983
[11/16 17:34:27 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5976, average loss: 0.7014
[11/16 17:34:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.40	
[11/16 17:34:27 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/16 17:42:05 visual_prompt]: Epoch 18 / 100: avg data time: 5.07e+00, avg batch time: 6.5428, average train loss: 0.6996
[11/16 17:42:57 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5925, average loss: 0.7535
[11/16 17:42:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.60	
[11/16 17:42:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/16 17:50:37 visual_prompt]: Epoch 19 / 100: avg data time: 5.08e+00, avg batch time: 6.5613, average train loss: 0.7045
[11/16 17:51:29 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.5984, average loss: 0.7193
[11/16 17:51:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/16 17:51:29 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/16 17:59:11 visual_prompt]: Epoch 20 / 100: avg data time: 5.13e+00, avg batch time: 6.6025, average train loss: 0.6974
[11/16 18:00:03 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5956, average loss: 0.6886
[11/16 18:00:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.41	
[11/16 18:00:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/16 18:07:41 visual_prompt]: Epoch 21 / 100: avg data time: 5.06e+00, avg batch time: 6.5389, average train loss: 0.6972
[11/16 18:08:33 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.5961, average loss: 0.6912
[11/16 18:08:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[11/16 18:08:33 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/16 18:16:10 visual_prompt]: Epoch 22 / 100: avg data time: 5.05e+00, avg batch time: 6.5271, average train loss: 0.6963
[11/16 18:17:02 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5952, average loss: 0.6882
[11/16 18:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[11/16 18:17:02 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/16 18:24:39 visual_prompt]: Epoch 23 / 100: avg data time: 5.05e+00, avg batch time: 6.5295, average train loss: 0.6904
[11/16 18:25:32 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.6000, average loss: 0.6909
[11/16 18:25:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[11/16 18:25:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/16 18:33:08 visual_prompt]: Epoch 24 / 100: avg data time: 5.04e+00, avg batch time: 6.5162, average train loss: 0.6938
[11/16 18:34:00 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.6039, average loss: 0.6930
[11/16 18:34:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.48	
[11/16 18:34:00 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/16 18:41:39 visual_prompt]: Epoch 25 / 100: avg data time: 5.07e+00, avg batch time: 6.5523, average train loss: 0.6929
[11/16 18:42:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5942, average loss: 0.6916
[11/16 18:42:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.80	
[11/16 18:42:31 visual_prompt]: Stopping early.
[11/16 18:42:31 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 18:42:31 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 18:42:31 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/16 18:42:31 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 18:42:31 visual_prompt]: Training with config:
[11/16 18:42:31 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 18:42:31 visual_prompt]: Loading training data...
[11/16 18:42:31 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 18:42:31 visual_prompt]: Loading validation data...
[11/16 18:42:31 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 18:42:31 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 18:42:34 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 18:42:34 visual_prompt]: tuned percent:0.532
[11/16 18:42:34 visual_prompt]: Device used for model: 0
[11/16 18:42:34 visual_prompt]: Setting up Evaluator...
[11/16 18:42:34 visual_prompt]: Setting up Trainer...
[11/16 18:42:34 visual_prompt]: 	Setting up the optimizer...
[11/16 18:42:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 18:50:13 visual_prompt]: Epoch 1 / 100: avg data time: 5.09e+00, avg batch time: 6.5549, average train loss: 1.4863
[11/16 18:51:05 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5943, average loss: 1.4553
[11/16 18:51:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 18:51:05 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/16 18:58:44 visual_prompt]: Epoch 2 / 100: avg data time: 5.09e+00, avg batch time: 6.5476, average train loss: 0.8431
[11/16 18:59:36 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5909, average loss: 0.6853
[11/16 18:59:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.14	
[11/16 18:59:36 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/16 19:07:13 visual_prompt]: Epoch 3 / 100: avg data time: 5.07e+00, avg batch time: 6.5350, average train loss: 0.7076
[11/16 19:08:06 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5909, average loss: 0.7529
[11/16 19:08:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.85	
[11/16 19:08:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/16 19:15:44 visual_prompt]: Epoch 4 / 100: avg data time: 5.09e+00, avg batch time: 6.5489, average train loss: 0.7220
[11/16 19:16:37 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5893, average loss: 0.7055
[11/16 19:16:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.66	
[11/16 19:16:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/16 19:24:15 visual_prompt]: Epoch 5 / 100: avg data time: 5.08e+00, avg batch time: 6.5381, average train loss: 0.7266
[11/16 19:25:07 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5965, average loss: 0.6776
[11/16 19:25:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.00	
[11/16 19:25:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/16 19:32:47 visual_prompt]: Epoch 6 / 100: avg data time: 5.11e+00, avg batch time: 6.5753, average train loss: 0.7288
[11/16 19:33:40 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5882, average loss: 0.7306
[11/16 19:33:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[11/16 19:33:40 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/16 19:41:19 visual_prompt]: Epoch 7 / 100: avg data time: 5.10e+00, avg batch time: 6.5618, average train loss: 0.6904
[11/16 19:42:12 visual_prompt]: Inference (val):avg data time: 4.76e-05, avg batch time: 0.5936, average loss: 1.0579
[11/16 19:42:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.54	
[11/16 19:42:12 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/16 19:49:54 visual_prompt]: Epoch 8 / 100: avg data time: 5.14e+00, avg batch time: 6.5974, average train loss: 0.7330
[11/16 19:50:46 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5947, average loss: 0.6750
[11/16 19:50:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 62.60	
[11/16 19:50:46 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/16 19:58:27 visual_prompt]: Epoch 9 / 100: avg data time: 5.11e+00, avg batch time: 6.5728, average train loss: 0.7118
[11/16 19:59:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5944, average loss: 0.6890
[11/16 19:59:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.22	
[11/16 19:59:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/16 20:06:59 visual_prompt]: Epoch 10 / 100: avg data time: 5.10e+00, avg batch time: 6.5617, average train loss: 0.6765
[11/16 20:07:51 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5903, average loss: 0.6570
[11/16 20:07:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.48	
[11/16 20:07:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/16 20:15:34 visual_prompt]: Epoch 11 / 100: avg data time: 5.15e+00, avg batch time: 6.6028, average train loss: 0.6915
[11/16 20:16:27 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5911, average loss: 0.7256
[11/16 20:16:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.81	
[11/16 20:16:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/16 20:24:08 visual_prompt]: Epoch 12 / 100: avg data time: 5.13e+00, avg batch time: 6.5866, average train loss: 0.6836
[11/16 20:25:00 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5904, average loss: 0.7535
[11/16 20:25:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 65.73	
[11/16 20:25:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/16 20:32:43 visual_prompt]: Epoch 13 / 100: avg data time: 5.15e+00, avg batch time: 6.5985, average train loss: 0.6943
[11/16 20:33:35 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5874, average loss: 0.6464
[11/16 20:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.93	
[11/16 20:33:35 visual_prompt]: Best epoch 13: best metric: -0.646
[11/16 20:33:35 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/16 20:41:16 visual_prompt]: Epoch 14 / 100: avg data time: 5.13e+00, avg batch time: 6.5834, average train loss: 0.6748
[11/16 20:42:09 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5872, average loss: 0.7117
[11/16 20:42:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 66.82	
[11/16 20:42:09 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/16 20:49:48 visual_prompt]: Epoch 15 / 100: avg data time: 5.11e+00, avg batch time: 6.5626, average train loss: 0.6696
[11/16 20:50:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5879, average loss: 0.6578
[11/16 20:50:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.53	
[11/16 20:50:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/16 20:58:22 visual_prompt]: Epoch 16 / 100: avg data time: 5.13e+00, avg batch time: 6.5860, average train loss: 0.6590
[11/16 20:59:15 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5882, average loss: 0.7779
[11/16 20:59:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.18	
[11/16 20:59:15 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/16 21:06:55 visual_prompt]: Epoch 17 / 100: avg data time: 5.12e+00, avg batch time: 6.5716, average train loss: 0.6642
[11/16 21:07:48 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5862, average loss: 0.6924
[11/16 21:07:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.02	
[11/16 21:07:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/16 21:15:29 visual_prompt]: Epoch 18 / 100: avg data time: 5.13e+00, avg batch time: 6.5806, average train loss: 0.6564
[11/16 21:16:22 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5847, average loss: 1.0889
[11/16 21:16:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.52	
[11/16 21:16:22 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/16 21:24:02 visual_prompt]: Epoch 19 / 100: avg data time: 5.12e+00, avg batch time: 6.5701, average train loss: 0.6626
[11/16 21:24:55 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.5894, average loss: 0.7817
[11/16 21:24:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.29	
[11/16 21:24:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/16 21:32:36 visual_prompt]: Epoch 20 / 100: avg data time: 5.13e+00, avg batch time: 6.5841, average train loss: 0.6401
[11/16 21:33:29 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.5897, average loss: 0.7243
[11/16 21:33:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.44	
[11/16 21:33:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/16 21:41:10 visual_prompt]: Epoch 21 / 100: avg data time: 5.14e+00, avg batch time: 6.5887, average train loss: 0.6559
[11/16 21:42:03 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5892, average loss: 0.6843
[11/16 21:42:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.96	
[11/16 21:42:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/16 21:49:44 visual_prompt]: Epoch 22 / 100: avg data time: 5.13e+00, avg batch time: 6.5836, average train loss: 0.6299
[11/16 21:50:37 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5874, average loss: 0.6498
[11/16 21:50:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.49	
[11/16 21:50:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/16 21:58:19 visual_prompt]: Epoch 23 / 100: avg data time: 5.15e+00, avg batch time: 6.6049, average train loss: 0.6491
[11/16 21:59:12 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5884, average loss: 0.6622
[11/16 21:59:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.56	
[11/16 21:59:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/16 22:06:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.12e+00, avg batch time: 6.5731, average train loss: 0.6324
[11/16 22:07:45 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5850, average loss: 0.6624
[11/16 22:07:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.60	
[11/16 22:07:45 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/16 22:15:27 visual_prompt]: Epoch 25 / 100: avg data time: 5.15e+00, avg batch time: 6.5968, average train loss: 0.6289
[11/16 22:16:19 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5875, average loss: 0.6822
[11/16 22:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 70.96	
[11/16 22:16:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/16 22:23:59 visual_prompt]: Epoch 26 / 100: avg data time: 5.12e+00, avg batch time: 6.5708, average train loss: 0.6338
[11/16 22:24:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5904, average loss: 0.6584
[11/16 22:24:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.50	
[11/16 22:24:52 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/16 22:32:32 visual_prompt]: Epoch 27 / 100: avg data time: 5.11e+00, avg batch time: 6.5623, average train loss: 0.6139
[11/16 22:33:24 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5893, average loss: 0.6436
[11/16 22:33:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.89	
[11/16 22:33:24 visual_prompt]: Best epoch 27: best metric: -0.644
[11/16 22:33:24 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/16 22:41:07 visual_prompt]: Epoch 28 / 100: avg data time: 5.16e+00, avg batch time: 6.6098, average train loss: 0.6221
[11/16 22:42:00 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5899, average loss: 0.6307
[11/16 22:42:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 71.24	
[11/16 22:42:00 visual_prompt]: Best epoch 28: best metric: -0.631
[11/16 22:42:00 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/16 22:49:41 visual_prompt]: Epoch 29 / 100: avg data time: 5.13e+00, avg batch time: 6.5876, average train loss: 0.5977
[11/16 22:50:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5852, average loss: 0.6694
[11/16 22:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 70.86	
[11/16 22:50:34 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/16 22:58:16 visual_prompt]: Epoch 30 / 100: avg data time: 5.14e+00, avg batch time: 6.5935, average train loss: 0.6014
[11/16 22:59:08 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5873, average loss: 0.8873
[11/16 22:59:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 69.76	
[11/16 22:59:08 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/16 23:06:48 visual_prompt]: Epoch 31 / 100: avg data time: 5.10e+00, avg batch time: 6.5601, average train loss: 0.6307
[11/16 23:07:41 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5881, average loss: 0.6445
[11/16 23:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.04	
[11/16 23:07:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/16 23:15:22 visual_prompt]: Epoch 32 / 100: avg data time: 5.13e+00, avg batch time: 6.5854, average train loss: 0.5969
[11/16 23:16:15 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5876, average loss: 0.6285
[11/16 23:16:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 70.91	
[11/16 23:16:15 visual_prompt]: Best epoch 32: best metric: -0.628
[11/16 23:16:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/16 23:23:56 visual_prompt]: Epoch 33 / 100: avg data time: 5.14e+00, avg batch time: 6.5912, average train loss: 0.5855
[11/16 23:24:49 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5920, average loss: 0.6271
[11/16 23:24:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.76	
[11/16 23:24:49 visual_prompt]: Best epoch 33: best metric: -0.627
[11/16 23:24:49 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/16 23:32:29 visual_prompt]: Epoch 34 / 100: avg data time: 5.12e+00, avg batch time: 6.5762, average train loss: 0.5756
[11/16 23:33:22 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5878, average loss: 0.7462
[11/16 23:33:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 68.40	
[11/16 23:33:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/16 23:41:03 visual_prompt]: Epoch 35 / 100: avg data time: 5.12e+00, avg batch time: 6.5792, average train loss: 0.5896
[11/16 23:41:56 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5860, average loss: 0.7076
[11/16 23:41:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.34	
[11/16 23:41:56 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/16 23:49:38 visual_prompt]: Epoch 36 / 100: avg data time: 5.16e+00, avg batch time: 6.6085, average train loss: 0.5709
[11/16 23:50:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5851, average loss: 0.6264
[11/16 23:50:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.24	
[11/16 23:50:31 visual_prompt]: Best epoch 36: best metric: -0.626
[11/16 23:50:31 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/16 23:58:11 visual_prompt]: Epoch 37 / 100: avg data time: 5.12e+00, avg batch time: 6.5714, average train loss: 0.5619
[11/16 23:59:03 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5918, average loss: 0.6681
[11/16 23:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.46	
[11/16 23:59:03 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/17 00:06:41 visual_prompt]: Epoch 38 / 100: avg data time: 5.08e+00, avg batch time: 6.5293, average train loss: 0.5672
[11/17 00:07:33 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.5982, average loss: 0.6902
[11/17 00:07:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.49	
[11/17 00:07:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/17 00:15:09 visual_prompt]: Epoch 39 / 100: avg data time: 5.04e+00, avg batch time: 6.5154, average train loss: 0.5799
[11/17 00:16:01 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5920, average loss: 0.6602
[11/17 00:16:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.56	
[11/17 00:16:01 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/17 00:23:37 visual_prompt]: Epoch 40 / 100: avg data time: 5.03e+00, avg batch time: 6.5119, average train loss: 0.5735
[11/17 00:24:29 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5940, average loss: 0.6906
[11/17 00:24:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.83	
[11/17 00:24:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/17 00:32:04 visual_prompt]: Epoch 41 / 100: avg data time: 5.02e+00, avg batch time: 6.5015, average train loss: 0.5849
[11/17 00:32:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5955, average loss: 0.7252
[11/17 00:32:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.56	
[11/17 00:32:56 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/17 00:40:30 visual_prompt]: Epoch 42 / 100: avg data time: 5.01e+00, avg batch time: 6.4875, average train loss: 0.5599
[11/17 00:41:22 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5933, average loss: 0.6449
[11/17 00:41:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.32	
[11/17 00:41:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/17 00:48:57 visual_prompt]: Epoch 43 / 100: avg data time: 5.01e+00, avg batch time: 6.4960, average train loss: 0.5567
[11/17 00:49:49 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.5986, average loss: 0.6291
[11/17 00:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.34	
[11/17 00:49:49 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/17 00:57:24 visual_prompt]: Epoch 44 / 100: avg data time: 5.02e+00, avg batch time: 6.5025, average train loss: 0.5366
[11/17 00:58:16 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.6005, average loss: 0.6660
[11/17 00:58:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.39	
[11/17 00:58:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/17 01:05:46 visual_prompt]: Epoch 45 / 100: avg data time: 4.94e+00, avg batch time: 6.4232, average train loss: 0.5454
[11/17 01:06:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5987, average loss: 0.6666
[11/17 01:06:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.39	
[11/17 01:06:38 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/17 01:14:07 visual_prompt]: Epoch 46 / 100: avg data time: 4.94e+00, avg batch time: 6.4205, average train loss: 0.5282
[11/17 01:14:58 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5952, average loss: 0.7362
[11/17 01:14:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.04	
[11/17 01:14:58 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/17 01:22:28 visual_prompt]: Epoch 47 / 100: avg data time: 4.94e+00, avg batch time: 6.4239, average train loss: 0.5651
[11/17 01:23:19 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.5971, average loss: 0.6073
[11/17 01:23:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.34	
[11/17 01:23:19 visual_prompt]: Best epoch 47: best metric: -0.607
[11/17 01:23:19 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[11/17 01:30:48 visual_prompt]: Epoch 48 / 100: avg data time: 4.93e+00, avg batch time: 6.4051, average train loss: 0.5237
[11/17 01:31:39 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5947, average loss: 0.7246
[11/17 01:31:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.25	
[11/17 01:31:39 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[11/17 01:39:09 visual_prompt]: Epoch 49 / 100: avg data time: 4.95e+00, avg batch time: 6.4295, average train loss: 0.5024
[11/17 01:40:00 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5998, average loss: 0.6710
[11/17 01:40:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.08	
[11/17 01:40:00 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[11/17 01:47:30 visual_prompt]: Epoch 50 / 100: avg data time: 4.93e+00, avg batch time: 6.4182, average train loss: 0.5634
[11/17 01:48:21 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5999, average loss: 0.7786
[11/17 01:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 72.90	
[11/17 01:48:21 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[11/17 01:55:50 visual_prompt]: Epoch 51 / 100: avg data time: 4.94e+00, avg batch time: 6.4157, average train loss: 0.5155
[11/17 01:56:41 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5985, average loss: 0.8086
[11/17 01:56:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.38	
[11/17 01:56:41 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[11/17 02:04:12 visual_prompt]: Epoch 52 / 100: avg data time: 4.95e+00, avg batch time: 6.4402, average train loss: 0.4766
[11/17 02:05:04 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.6036, average loss: 0.8776
[11/17 02:05:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/17 02:05:04 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[11/17 02:12:36 visual_prompt]: Epoch 53 / 100: avg data time: 4.97e+00, avg batch time: 6.4591, average train loss: 0.4970
[11/17 02:13:28 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.6032, average loss: 0.7031
[11/17 02:13:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.29	
[11/17 02:13:28 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[11/17 02:21:03 visual_prompt]: Epoch 54 / 100: avg data time: 5.02e+00, avg batch time: 6.4966, average train loss: 0.4744
[11/17 02:21:55 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5961, average loss: 0.7263
[11/17 02:21:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.97	
[11/17 02:21:55 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[11/17 02:29:33 visual_prompt]: Epoch 55 / 100: avg data time: 5.07e+00, avg batch time: 6.5341, average train loss: 0.4531
[11/17 02:30:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5902, average loss: 1.4392
[11/17 02:30:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 69.81	
[11/17 02:30:25 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[11/17 02:38:05 visual_prompt]: Epoch 56 / 100: avg data time: 5.10e+00, avg batch time: 6.5576, average train loss: 0.4702
[11/17 02:38:57 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5866, average loss: 0.7472
[11/17 02:38:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.98	
[11/17 02:38:57 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[11/17 02:46:38 visual_prompt]: Epoch 57 / 100: avg data time: 5.13e+00, avg batch time: 6.5790, average train loss: 0.4749
[11/17 02:47:30 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5887, average loss: 0.7562
[11/17 02:47:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.51	
[11/17 02:47:30 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[11/17 02:55:09 visual_prompt]: Epoch 58 / 100: avg data time: 5.10e+00, avg batch time: 6.5523, average train loss: 0.4300
[11/17 02:56:02 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5893, average loss: 0.7666
[11/17 02:56:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.75	
[11/17 02:56:02 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
[11/17 03:03:44 visual_prompt]: Epoch 59 / 100: avg data time: 5.15e+00, avg batch time: 6.6021, average train loss: 0.4288
[11/17 03:04:37 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5873, average loss: 0.7432
[11/17 03:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 69.49	
[11/17 03:04:37 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.02152067247599837
[11/17 03:12:19 visual_prompt]: Epoch 60 / 100: avg data time: 5.14e+00, avg batch time: 6.5976, average train loss: 0.4378
[11/17 03:13:12 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5871, average loss: 0.7932
[11/17 03:13:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.62	
[11/17 03:13:12 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.020658795558326743
[11/17 03:20:53 visual_prompt]: Epoch 61 / 100: avg data time: 5.13e+00, avg batch time: 6.5867, average train loss: 0.4043
[11/17 03:21:46 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5897, average loss: 0.8499
[11/17 03:21:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 65.49	
[11/17 03:21:46 visual_prompt]: Stopping early.
[11/17 03:21:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 03:21:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 03:21:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/17 03:21:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 03:21:46 visual_prompt]: Training with config:
[11/17 03:21:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.0001/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 03:21:46 visual_prompt]: Loading training data...
[11/17 03:21:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 03:21:46 visual_prompt]: Loading validation data...
[11/17 03:21:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 03:21:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 03:21:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 03:21:51 visual_prompt]: tuned percent:0.532
[11/17 03:21:51 visual_prompt]: Device used for model: 0
[11/17 03:21:51 visual_prompt]: Setting up Evaluator...
[11/17 03:21:51 visual_prompt]: Setting up Trainer...
[11/17 03:21:51 visual_prompt]: 	Setting up the optimizer...
[11/17 03:21:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 03:29:35 visual_prompt]: Epoch 1 / 100: avg data time: 5.18e+00, avg batch time: 6.6282, average train loss: 1.4863
[11/17 03:30:28 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5871, average loss: 1.4553
[11/17 03:30:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 03:30:28 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/17 03:38:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.14e+00, avg batch time: 6.5935, average train loss: 0.8431
[11/17 03:39:03 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.5886, average loss: 0.6853
[11/17 03:39:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.16	
[11/17 03:39:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/17 03:46:45 visual_prompt]: Epoch 3 / 100: avg data time: 5.15e+00, avg batch time: 6.6053, average train loss: 0.7078
[11/17 03:47:38 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5865, average loss: 0.7530
[11/17 03:47:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[11/17 03:47:38 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/17 03:55:19 visual_prompt]: Epoch 4 / 100: avg data time: 5.14e+00, avg batch time: 6.5902, average train loss: 0.7224
[11/17 03:56:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5858, average loss: 0.7051
[11/17 03:56:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[11/17 03:56:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/17 04:03:53 visual_prompt]: Epoch 5 / 100: avg data time: 5.12e+00, avg batch time: 6.5764, average train loss: 0.7267
[11/17 04:04:46 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5894, average loss: 0.6773
[11/17 04:04:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.93	
[11/17 04:04:46 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/17 04:12:29 visual_prompt]: Epoch 6 / 100: avg data time: 5.16e+00, avg batch time: 6.6145, average train loss: 0.7296
[11/17 04:13:22 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5917, average loss: 0.7267
[11/17 04:13:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.25	
[11/17 04:13:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/17 04:21:03 visual_prompt]: Epoch 7 / 100: avg data time: 5.13e+00, avg batch time: 6.5846, average train loss: 0.6895
[11/17 04:21:56 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5864, average loss: 1.0714
[11/17 04:21:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.78	
[11/17 04:21:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/17 04:29:37 visual_prompt]: Epoch 8 / 100: avg data time: 5.14e+00, avg batch time: 6.5870, average train loss: 0.7390
[11/17 04:30:30 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5913, average loss: 0.6757
[11/17 04:30:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 62.14	
[11/17 04:30:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/17 04:38:11 visual_prompt]: Epoch 9 / 100: avg data time: 5.14e+00, avg batch time: 6.5882, average train loss: 0.7079
[11/17 04:39:04 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5880, average loss: 0.6737
[11/17 04:39:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.94	
[11/17 04:39:04 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/17 04:46:46 visual_prompt]: Epoch 10 / 100: avg data time: 5.14e+00, avg batch time: 6.5964, average train loss: 0.6807
[11/17 04:47:39 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5906, average loss: 0.6586
[11/17 04:47:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.20	
[11/17 04:47:39 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/17 04:55:22 visual_prompt]: Epoch 11 / 100: avg data time: 5.15e+00, avg batch time: 6.6069, average train loss: 0.6923
[11/17 04:56:15 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5859, average loss: 0.8105
[11/17 04:56:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.61	
[11/17 04:56:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/17 05:03:56 visual_prompt]: Epoch 12 / 100: avg data time: 5.13e+00, avg batch time: 6.5890, average train loss: 0.6918
[11/17 05:04:49 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5868, average loss: 0.7250
[11/17 05:04:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 65.50	
[11/17 05:04:49 visual_prompt]: Best epoch 12: best metric: -0.725
[11/17 05:04:49 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/17 05:12:31 visual_prompt]: Epoch 13 / 100: avg data time: 5.15e+00, avg batch time: 6.6063, average train loss: 0.6972
[11/17 05:13:24 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5877, average loss: 0.6751
[11/17 05:13:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.41	
[11/17 05:13:24 visual_prompt]: Best epoch 13: best metric: -0.675
[11/17 05:13:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/17 05:21:06 visual_prompt]: Epoch 14 / 100: avg data time: 5.14e+00, avg batch time: 6.5944, average train loss: 0.6911
[11/17 05:21:59 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5917, average loss: 0.6561
[11/17 05:21:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.65	
[11/17 05:21:59 visual_prompt]: Best epoch 14: best metric: -0.656
[11/17 05:21:59 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/17 05:29:39 visual_prompt]: Epoch 15 / 100: avg data time: 5.12e+00, avg batch time: 6.5706, average train loss: 0.6706
[11/17 05:30:32 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5914, average loss: 0.6711
[11/17 05:30:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.49	
[11/17 05:30:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/17 05:38:13 visual_prompt]: Epoch 16 / 100: avg data time: 5.14e+00, avg batch time: 6.5897, average train loss: 0.6559
[11/17 05:39:06 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5901, average loss: 0.7662
[11/17 05:39:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.72	
[11/17 05:39:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/17 05:46:48 visual_prompt]: Epoch 17 / 100: avg data time: 5.14e+00, avg batch time: 6.5988, average train loss: 0.6630
[11/17 05:47:41 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5892, average loss: 0.6724
[11/17 05:47:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.13	
[11/17 05:47:41 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/17 05:55:22 visual_prompt]: Epoch 18 / 100: avg data time: 5.13e+00, avg batch time: 6.5893, average train loss: 0.6605
[11/17 05:56:15 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5921, average loss: 1.0637
[11/17 05:56:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.67	
[11/17 05:56:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/17 06:03:56 visual_prompt]: Epoch 19 / 100: avg data time: 5.13e+00, avg batch time: 6.5801, average train loss: 0.6713
[11/17 06:04:49 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5906, average loss: 0.7874
[11/17 06:04:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.81	
[11/17 06:04:49 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/17 06:12:32 visual_prompt]: Epoch 20 / 100: avg data time: 5.17e+00, avg batch time: 6.6182, average train loss: 0.6501
[11/17 06:13:25 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.5930, average loss: 0.7581
[11/17 06:13:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 68.52	
[11/17 06:13:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/17 06:21:08 visual_prompt]: Epoch 21 / 100: avg data time: 5.16e+00, avg batch time: 6.6106, average train loss: 0.6566
[11/17 06:22:01 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5887, average loss: 0.6609
[11/17 06:22:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.76	
[11/17 06:22:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/17 06:29:43 visual_prompt]: Epoch 22 / 100: avg data time: 5.14e+00, avg batch time: 6.5962, average train loss: 0.6297
[11/17 06:30:36 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5879, average loss: 0.6419
[11/17 06:30:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.03	
[11/17 06:30:36 visual_prompt]: Best epoch 22: best metric: -0.642
[11/17 06:30:36 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/17 06:38:19 visual_prompt]: Epoch 23 / 100: avg data time: 5.15e+00, avg batch time: 6.6078, average train loss: 0.6311
[11/17 06:39:11 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5882, average loss: 0.6729
[11/17 06:39:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.72	
[11/17 06:39:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/17 06:46:54 visual_prompt]: Epoch 24 / 100: avg data time: 5.15e+00, avg batch time: 6.6047, average train loss: 0.6284
[11/17 06:47:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5877, average loss: 0.6512
[11/17 06:47:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.25	
[11/17 06:47:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/17 06:55:29 visual_prompt]: Epoch 25 / 100: avg data time: 5.14e+00, avg batch time: 6.5981, average train loss: 0.6217
[11/17 06:56:22 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5927, average loss: 0.6718
[11/17 06:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.16	
[11/17 06:56:22 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/17 07:04:03 visual_prompt]: Epoch 26 / 100: avg data time: 5.13e+00, avg batch time: 6.5834, average train loss: 0.6380
[11/17 07:04:55 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.5884, average loss: 0.6347
[11/17 07:04:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.25	
[11/17 07:04:55 visual_prompt]: Best epoch 26: best metric: -0.635
[11/17 07:04:55 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/17 07:12:37 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e+00, avg batch time: 6.5854, average train loss: 0.6137
[11/17 07:13:30 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5873, average loss: 0.6418
[11/17 07:13:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.54	
[11/17 07:13:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/17 07:21:12 visual_prompt]: Epoch 28 / 100: avg data time: 5.15e+00, avg batch time: 6.6005, average train loss: 0.6274
[11/17 07:22:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5897, average loss: 0.6696
[11/17 07:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.59	
[11/17 07:22:05 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/17 07:29:45 visual_prompt]: Epoch 29 / 100: avg data time: 5.13e+00, avg batch time: 6.5818, average train loss: 0.6088
[11/17 07:30:38 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5838, average loss: 0.6306
[11/17 07:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.44	
[11/17 07:30:38 visual_prompt]: Best epoch 29: best metric: -0.631
[11/17 07:30:38 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/17 07:38:21 visual_prompt]: Epoch 30 / 100: avg data time: 5.16e+00, avg batch time: 6.6125, average train loss: 0.6092
[11/17 07:39:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5889, average loss: 0.7062
[11/17 07:39:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.40	
[11/17 07:39:14 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/17 07:46:56 visual_prompt]: Epoch 31 / 100: avg data time: 5.14e+00, avg batch time: 6.5900, average train loss: 0.5999
[11/17 07:47:49 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5888, average loss: 0.6650
[11/17 07:47:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.49	
[11/17 07:47:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/17 07:55:30 visual_prompt]: Epoch 32 / 100: avg data time: 5.13e+00, avg batch time: 6.5831, average train loss: 0.5929
[11/17 07:56:22 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5917, average loss: 0.6516
[11/17 07:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.03	
[11/17 07:56:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/17 08:04:04 visual_prompt]: Epoch 33 / 100: avg data time: 5.15e+00, avg batch time: 6.5989, average train loss: 0.5790
[11/17 08:04:57 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5866, average loss: 0.6460
[11/17 08:04:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.78	
[11/17 08:04:57 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/17 08:12:40 visual_prompt]: Epoch 34 / 100: avg data time: 5.15e+00, avg batch time: 6.6036, average train loss: 0.5761
[11/17 08:13:33 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5851, average loss: 0.7361
[11/17 08:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 68.03	
[11/17 08:13:33 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/17 08:21:14 visual_prompt]: Epoch 35 / 100: avg data time: 5.14e+00, avg batch time: 6.5918, average train loss: 0.6047
[11/17 08:22:07 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.5841, average loss: 0.7291
[11/17 08:22:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 66.20	
[11/17 08:22:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/17 08:29:50 visual_prompt]: Epoch 36 / 100: avg data time: 5.16e+00, avg batch time: 6.6154, average train loss: 0.5773
[11/17 08:30:43 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5941, average loss: 0.6869
[11/17 08:30:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.75	
[11/17 08:30:43 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/17 08:38:25 visual_prompt]: Epoch 37 / 100: avg data time: 5.14e+00, avg batch time: 6.5977, average train loss: 0.5445
[11/17 08:39:18 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5844, average loss: 0.6399
[11/17 08:39:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.12	
[11/17 08:39:18 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/17 08:47:00 visual_prompt]: Epoch 38 / 100: avg data time: 5.15e+00, avg batch time: 6.6042, average train loss: 0.5441
[11/17 08:47:53 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5869, average loss: 0.6602
[11/17 08:47:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 69.34	
[11/17 08:47:53 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/17 08:55:35 visual_prompt]: Epoch 39 / 100: avg data time: 5.14e+00, avg batch time: 6.5920, average train loss: 0.5625
[11/17 08:56:28 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5883, average loss: 0.7640
[11/17 08:56:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.06	
[11/17 08:56:28 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/17 09:04:11 visual_prompt]: Epoch 40 / 100: avg data time: 5.16e+00, avg batch time: 6.6159, average train loss: 0.5447
[11/17 09:05:04 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5863, average loss: 0.6610
[11/17 09:05:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.43	
[11/17 09:05:04 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/17 09:12:46 visual_prompt]: Epoch 41 / 100: avg data time: 5.15e+00, avg batch time: 6.6031, average train loss: 0.5229
[11/17 09:13:39 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5874, average loss: 0.7517
[11/17 09:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.97	
[11/17 09:13:39 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/17 09:21:20 visual_prompt]: Epoch 42 / 100: avg data time: 5.12e+00, avg batch time: 6.5779, average train loss: 0.5255
[11/17 09:22:12 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5875, average loss: 0.7114
[11/17 09:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.27	
[11/17 09:22:12 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/17 09:29:55 visual_prompt]: Epoch 43 / 100: avg data time: 5.15e+00, avg batch time: 6.6030, average train loss: 0.5436
[11/17 09:30:48 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5867, average loss: 0.6570
[11/17 09:30:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.37	
[11/17 09:30:48 visual_prompt]: Stopping early.
[11/17 09:30:48 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 09:30:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 09:30:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/17 09:30:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 09:30:48 visual_prompt]: Training with config:
[11/17 09:30:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.0/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 09:30:48 visual_prompt]: Loading training data...
[11/17 09:30:48 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 09:30:48 visual_prompt]: Loading validation data...
[11/17 09:30:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 09:30:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 09:30:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 09:30:51 visual_prompt]: tuned percent:0.532
[11/17 09:30:51 visual_prompt]: Device used for model: 0
[11/17 09:30:51 visual_prompt]: Setting up Evaluator...
[11/17 09:30:51 visual_prompt]: Setting up Trainer...
[11/17 09:30:51 visual_prompt]: 	Setting up the optimizer...
[11/17 09:30:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 09:38:34 visual_prompt]: Epoch 1 / 100: avg data time: 5.16e+00, avg batch time: 6.6129, average train loss: 1.4863
[11/17 09:39:27 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5867, average loss: 1.4553
[11/17 09:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 09:39:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/17 09:47:10 visual_prompt]: Epoch 2 / 100: avg data time: 5.17e+00, avg batch time: 6.6205, average train loss: 0.8432
[11/17 09:48:03 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5850, average loss: 0.6853
[11/17 09:48:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.16	
[11/17 09:48:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/17 09:55:46 visual_prompt]: Epoch 3 / 100: avg data time: 5.16e+00, avg batch time: 6.6076, average train loss: 0.7078
[11/17 09:56:39 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.5862, average loss: 0.7530
[11/17 09:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[11/17 09:56:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/17 10:04:21 visual_prompt]: Epoch 4 / 100: avg data time: 5.14e+00, avg batch time: 6.5951, average train loss: 0.7225
[11/17 10:05:13 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5852, average loss: 0.7051
[11/17 10:05:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.60	
[11/17 10:05:13 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/17 10:12:49 visual_prompt]: Epoch 5 / 100: avg data time: 5.06e+00, avg batch time: 6.5076, average train loss: 0.7267
[11/17 10:13:38 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5878, average loss: 0.6773
[11/17 10:13:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 60.93	
[11/17 10:13:38 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/17 10:20:52 visual_prompt]: Epoch 6 / 100: avg data time: 4.72e+00, avg batch time: 6.1941, average train loss: 0.7297
[11/17 10:21:41 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5951, average loss: 0.7267
[11/17 10:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.22	
[11/17 10:21:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/17 10:29:06 visual_prompt]: Epoch 7 / 100: avg data time: 4.87e+00, avg batch time: 6.3525, average train loss: 0.6895
[11/17 10:29:59 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.5965, average loss: 1.0738
[11/17 10:29:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.76	
[11/17 10:29:59 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/17 10:37:27 visual_prompt]: Epoch 8 / 100: avg data time: 4.92e+00, avg batch time: 6.3977, average train loss: 0.7385
[11/17 10:38:19 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.5893, average loss: 0.6748
[11/17 10:38:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 62.05	
[11/17 10:38:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/17 10:45:56 visual_prompt]: Epoch 9 / 100: avg data time: 5.08e+00, avg batch time: 6.5324, average train loss: 0.7085
[11/17 10:46:49 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.5915, average loss: 0.6724
[11/17 10:46:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.93	
[11/17 10:46:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/17 10:54:26 visual_prompt]: Epoch 10 / 100: avg data time: 5.08e+00, avg batch time: 6.5334, average train loss: 0.6812
[11/17 10:55:18 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5889, average loss: 0.6603
[11/17 10:55:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.03	
[11/17 10:55:18 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/17 11:02:56 visual_prompt]: Epoch 11 / 100: avg data time: 5.09e+00, avg batch time: 6.5418, average train loss: 0.6882
[11/17 11:03:49 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5889, average loss: 0.7809
[11/17 11:03:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.30	
[11/17 11:03:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/17 11:11:25 visual_prompt]: Epoch 12 / 100: avg data time: 5.07e+00, avg batch time: 6.5226, average train loss: 0.6901
[11/17 11:12:17 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5872, average loss: 0.7514
[11/17 11:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 65.45	
[11/17 11:12:17 visual_prompt]: Best epoch 12: best metric: -0.751
[11/17 11:12:17 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/17 11:19:56 visual_prompt]: Epoch 13 / 100: avg data time: 5.10e+00, avg batch time: 6.5509, average train loss: 0.6934
[11/17 11:20:49 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5918, average loss: 0.6889
[11/17 11:20:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.23	
[11/17 11:20:49 visual_prompt]: Best epoch 13: best metric: -0.689
[11/17 11:20:49 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/17 11:28:10 visual_prompt]: Epoch 14 / 100: avg data time: 4.85e+00, avg batch time: 6.3034, average train loss: 0.6939
[11/17 11:28:58 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5982, average loss: 0.6556
[11/17 11:28:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 64.74	
[11/17 11:28:58 visual_prompt]: Best epoch 14: best metric: -0.656
[11/17 11:28:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/17 11:36:15 visual_prompt]: Epoch 15 / 100: avg data time: 4.75e+00, avg batch time: 6.2350, average train loss: 0.6700
[11/17 11:37:03 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.5975, average loss: 0.6707
[11/17 11:37:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.61	
[11/17 11:37:03 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/17 11:44:08 visual_prompt]: Epoch 16 / 100: avg data time: 4.59e+00, avg batch time: 6.0679, average train loss: 0.6586
[11/17 11:44:57 visual_prompt]: Inference (val):avg data time: 2.21e-05, avg batch time: 0.5969, average loss: 0.7681
[11/17 11:44:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.02	
[11/17 11:44:57 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/17 11:52:02 visual_prompt]: Epoch 17 / 100: avg data time: 4.59e+00, avg batch time: 6.0675, average train loss: 0.6625
[11/17 11:52:51 visual_prompt]: Inference (val):avg data time: 2.36e-05, avg batch time: 0.5937, average loss: 0.6725
[11/17 11:52:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.48	
[11/17 11:52:51 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/17 11:59:54 visual_prompt]: Epoch 18 / 100: avg data time: 4.57e+00, avg batch time: 6.0425, average train loss: 0.6607
[11/17 12:00:42 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5948, average loss: 1.0596
[11/17 12:00:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.26	
[11/17 12:00:42 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/17 12:07:49 visual_prompt]: Epoch 19 / 100: avg data time: 4.63e+00, avg batch time: 6.0976, average train loss: 0.6714
[11/17 12:08:38 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5974, average loss: 0.7832
[11/17 12:08:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.68	
[11/17 12:08:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/17 12:15:47 visual_prompt]: Epoch 20 / 100: avg data time: 4.66e+00, avg batch time: 6.1308, average train loss: 0.6487
[11/17 12:16:35 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5973, average loss: 0.7532
[11/17 12:16:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 69.13	
[11/17 12:16:35 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/17 12:23:43 visual_prompt]: Epoch 21 / 100: avg data time: 4.62e+00, avg batch time: 6.0986, average train loss: 0.6566
[11/17 12:24:31 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5986, average loss: 0.6650
[11/17 12:24:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.57	
[11/17 12:24:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/17 12:31:33 visual_prompt]: Epoch 22 / 100: avg data time: 4.56e+00, avg batch time: 6.0361, average train loss: 0.6296
[11/17 12:32:22 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5976, average loss: 0.6475
[11/17 12:32:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.04	
[11/17 12:32:22 visual_prompt]: Best epoch 22: best metric: -0.648
[11/17 12:32:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/17 12:39:26 visual_prompt]: Epoch 23 / 100: avg data time: 4.57e+00, avg batch time: 6.0585, average train loss: 0.6316
[11/17 12:40:14 visual_prompt]: Inference (val):avg data time: 2.05e-05, avg batch time: 0.5987, average loss: 0.6820
[11/17 12:40:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.50	
[11/17 12:40:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/17 12:47:17 visual_prompt]: Epoch 24 / 100: avg data time: 4.56e+00, avg batch time: 6.0367, average train loss: 0.6271
[11/17 12:48:06 visual_prompt]: Inference (val):avg data time: 2.29e-05, avg batch time: 0.5981, average loss: 0.6606
[11/17 12:48:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.80	
[11/17 12:48:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/17 12:55:10 visual_prompt]: Epoch 25 / 100: avg data time: 4.57e+00, avg batch time: 6.0563, average train loss: 0.6238
[11/17 12:55:58 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.6066, average loss: 0.6906
[11/17 12:55:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.54	
[11/17 12:55:58 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/17 13:03:01 visual_prompt]: Epoch 26 / 100: avg data time: 4.57e+00, avg batch time: 6.0386, average train loss: 0.6513
[11/17 13:03:49 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.5948, average loss: 0.6421
[11/17 13:03:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.50	
[11/17 13:03:49 visual_prompt]: Best epoch 26: best metric: -0.642
[11/17 13:03:49 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/17 13:10:49 visual_prompt]: Epoch 27 / 100: avg data time: 4.52e+00, avg batch time: 5.9977, average train loss: 0.6194
[11/17 13:11:37 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.5952, average loss: 0.6408
[11/17 13:11:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.59	
[11/17 13:11:37 visual_prompt]: Best epoch 27: best metric: -0.641
[11/17 13:11:37 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/17 13:18:41 visual_prompt]: Epoch 28 / 100: avg data time: 4.57e+00, avg batch time: 6.0518, average train loss: 0.6269
[11/17 13:19:29 visual_prompt]: Inference (val):avg data time: 2.11e-05, avg batch time: 0.6046, average loss: 0.6471
[11/17 13:19:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.85	
[11/17 13:19:29 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/17 13:26:32 visual_prompt]: Epoch 29 / 100: avg data time: 4.56e+00, avg batch time: 6.0354, average train loss: 0.6018
[11/17 13:27:20 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5907, average loss: 0.6456
[11/17 13:27:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.18	
[11/17 13:27:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/17 13:34:25 visual_prompt]: Epoch 30 / 100: avg data time: 4.58e+00, avg batch time: 6.0613, average train loss: 0.6280
[11/17 13:35:13 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.6009, average loss: 0.6589
[11/17 13:35:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 69.73	
[11/17 13:35:13 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/17 13:42:15 visual_prompt]: Epoch 31 / 100: avg data time: 4.55e+00, avg batch time: 6.0223, average train loss: 0.6087
[11/17 13:43:03 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5905, average loss: 0.6833
[11/17 13:43:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.21	
[11/17 13:43:03 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/17 13:50:06 visual_prompt]: Epoch 32 / 100: avg data time: 4.56e+00, avg batch time: 6.0403, average train loss: 0.6043
[11/17 13:50:54 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5916, average loss: 0.6363
[11/17 13:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.62	
[11/17 13:50:54 visual_prompt]: Best epoch 32: best metric: -0.636
[11/17 13:50:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/17 13:57:56 visual_prompt]: Epoch 33 / 100: avg data time: 4.54e+00, avg batch time: 6.0219, average train loss: 0.5774
[11/17 13:58:44 visual_prompt]: Inference (val):avg data time: 2.20e-05, avg batch time: 0.5986, average loss: 0.6667
[11/17 13:58:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.45	
[11/17 13:58:44 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/17 14:05:47 visual_prompt]: Epoch 34 / 100: avg data time: 4.56e+00, avg batch time: 6.0337, average train loss: 0.5808
[11/17 14:06:35 visual_prompt]: Inference (val):avg data time: 2.18e-05, avg batch time: 0.5913, average loss: 0.7417
[11/17 14:06:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.59	
[11/17 14:06:35 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/17 14:13:38 visual_prompt]: Epoch 35 / 100: avg data time: 4.56e+00, avg batch time: 6.0364, average train loss: 0.5970
[11/17 14:14:26 visual_prompt]: Inference (val):avg data time: 2.16e-05, avg batch time: 0.5933, average loss: 0.7648
[11/17 14:14:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 65.57	
[11/17 14:14:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/17 14:21:29 visual_prompt]: Epoch 36 / 100: avg data time: 4.57e+00, avg batch time: 6.0471, average train loss: 0.5903
[11/17 14:22:18 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.5938, average loss: 0.6946
[11/17 14:22:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 67.53	
[11/17 14:22:18 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/17 14:29:20 visual_prompt]: Epoch 37 / 100: avg data time: 4.55e+00, avg batch time: 6.0292, average train loss: 0.5536
[11/17 14:30:08 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5944, average loss: 0.6790
[11/17 14:30:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.39	
[11/17 14:30:08 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/17 14:37:08 visual_prompt]: Epoch 38 / 100: avg data time: 4.52e+00, avg batch time: 5.9996, average train loss: 0.5459
[11/17 14:37:56 visual_prompt]: Inference (val):avg data time: 2.17e-05, avg batch time: 0.5998, average loss: 0.6606
[11/17 14:37:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.44	
[11/17 14:37:56 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/17 14:44:59 visual_prompt]: Epoch 39 / 100: avg data time: 4.55e+00, avg batch time: 6.0295, average train loss: 0.5585
[11/17 14:45:46 visual_prompt]: Inference (val):avg data time: 2.23e-05, avg batch time: 0.5928, average loss: 0.7769
[11/17 14:45:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.85	
[11/17 14:45:46 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/17 14:52:46 visual_prompt]: Epoch 40 / 100: avg data time: 4.51e+00, avg batch time: 5.9865, average train loss: 0.5547
[11/17 14:53:34 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.5959, average loss: 0.6710
[11/17 14:53:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.24	
[11/17 14:53:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/17 15:00:33 visual_prompt]: Epoch 41 / 100: avg data time: 4.52e+00, avg batch time: 5.9916, average train loss: 0.5301
[11/17 15:01:21 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.5975, average loss: 0.7916
[11/17 15:01:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.70	
[11/17 15:01:21 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/17 15:08:27 visual_prompt]: Epoch 42 / 100: avg data time: 4.61e+00, avg batch time: 6.0837, average train loss: 0.5373
[11/17 15:09:17 visual_prompt]: Inference (val):avg data time: 2.27e-05, avg batch time: 0.5949, average loss: 0.6978
[11/17 15:09:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.96	
[11/17 15:09:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/17 15:16:35 visual_prompt]: Epoch 43 / 100: avg data time: 4.77e+00, avg batch time: 6.2617, average train loss: 0.5485
[11/17 15:17:23 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.6024, average loss: 0.6925
[11/17 15:17:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.48	
[11/17 15:17:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/17 15:24:28 visual_prompt]: Epoch 44 / 100: avg data time: 4.58e+00, avg batch time: 6.0619, average train loss: 0.5330
[11/17 15:25:16 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.6035, average loss: 0.6939
[11/17 15:25:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.14	
[11/17 15:25:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/17 15:32:17 visual_prompt]: Epoch 45 / 100: avg data time: 4.54e+00, avg batch time: 6.0189, average train loss: 0.5118
[11/17 15:33:06 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.5960, average loss: 0.7227
[11/17 15:33:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 67.63	
[11/17 15:33:06 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/17 15:40:24 visual_prompt]: Epoch 46 / 100: avg data time: 4.79e+00, avg batch time: 6.2644, average train loss: 0.5233
[11/17 15:41:15 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.5988, average loss: 0.7341
[11/17 15:41:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.45	
[11/17 15:41:15 visual_prompt]: Stopping early.
[11/17 15:41:16 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 15:41:16 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              1
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 15:41:16 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '14', 'SOLVER.CRITERION', 'loss'])
[11/17 15:41:16 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 15:41:16 visual_prompt]: Training with config:
[11/17 15:41:16 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/test/seed9805/lrNone_wdNone/patience14/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 9805, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': None, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 14, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': None, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 15:41:16 visual_prompt]: Loading training data...
[11/17 15:41:16 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 15:41:16 visual_prompt]: Loading validation data...
[11/17 15:41:16 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 15:41:16 visual_prompt]: Loading test data...
[11/17 15:41:16 visual_prompt]: Constructing mammo-cbis dataset test...
[11/17 15:41:16 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 15:41:19 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 15:41:19 visual_prompt]: tuned percent:0.532
[11/17 15:41:19 visual_prompt]: Device used for model: 0
[11/17 15:41:19 visual_prompt]: Setting up Evaluator...
[11/17 15:41:19 visual_prompt]: Setting up Trainer...
[11/17 15:41:19 visual_prompt]: 	Setting up the optimizer...
Traceback (most recent call last):
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 99, in <module>
    main(args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 94, in main
    train(cfg, args)
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/tune_cbis.py", line 43, in train
    trainer = Trainer(cfg, model, evaluator, cur_device)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/engine/trainer.py", line 46, in __init__
    self.optimizer = make_optimizer([self.model], cfg.SOLVER)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/s1952889/final-project/implementation/visual_prompt_tuning/src/solver/optimizer.py", line 36, in make_optimizer
    if train_params.WEIGHT_DECAY > 0:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: '>' not supported between instances of 'NoneType' and 'int'
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
