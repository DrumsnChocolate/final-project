/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/08 12:47:03 visual_prompt]: Rank of current process: 0. World size: 1
[11/08 12:47:05 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/08 12:47:05 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/08 12:47:05 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/08 12:47:05 visual_prompt]: Training with config:
[11/08 12:47:05 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/08 12:47:05 visual_prompt]: Loading training data...
[11/08 12:47:05 visual_prompt]: Constructing mammo-cbis dataset train...
[11/08 12:47:05 visual_prompt]: Loading validation data...
[11/08 12:47:05 visual_prompt]: Constructing mammo-cbis dataset val...
[11/08 12:47:05 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/08 12:47:26 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/08 12:47:26 visual_prompt]: tuned percent:0.536
[11/08 12:47:26 visual_prompt]: Device used for model: 0
[11/08 12:47:26 visual_prompt]: Setting up Evaluator...
[11/08 12:47:26 visual_prompt]: Setting up Trainer...
[11/08 12:47:26 visual_prompt]: 	Setting up the optimizer...
[11/08 12:47:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/08 12:53:59 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.2213, average train loss: 1.4017
[11/08 12:54:43 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1550, average loss: 1.2969
[11/08 12:54:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/08 12:54:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/08 13:01:12 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1143, average train loss: 41.7326
[11/08 13:01:55 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1546, average loss: 26.4996
[11/08 13:01:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.38	
[11/08 13:01:55 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/08 13:08:22 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.0410, average train loss: 21.3312
[11/08 13:09:06 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1560, average loss: 28.1031
[11/08 13:09:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.55	
[11/08 13:09:06 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/08 13:15:33 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0525, average train loss: 30.9754
[11/08 13:16:16 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1549, average loss: 28.4330
[11/08 13:16:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.87	
[11/08 13:16:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/08 13:22:42 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.0133, average train loss: 61.5555
[11/08 13:23:26 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1550, average loss: 5.5913
[11/08 13:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.85	
[11/08 13:23:26 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/08 13:29:57 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1817, average train loss: 54.7343
[11/08 13:30:41 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1547, average loss: 60.5731
[11/08 13:30:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.52	
[11/08 13:30:41 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/08 13:37:34 visual_prompt]: Epoch 7 / 100: avg data time: 1.14e+01, avg batch time: 11.7853, average train loss: 93.2979
[11/08 13:38:23 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.1570, average loss: 155.7742
[11/08 13:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/08 13:38:23 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/08 13:44:58 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.2966, average train loss: 107.0309
[11/08 13:45:42 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1562, average loss: 78.7135
[11/08 13:45:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.10	
[11/08 13:45:42 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/08 13:52:09 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.0428, average train loss: 150.3894
[11/08 13:52:52 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1549, average loss: 61.5476
[11/08 13:52:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.88	
[11/08 13:52:52 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/08 13:59:19 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0390, average train loss: 113.5575
[11/08 14:00:03 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1550, average loss: 241.0500
[11/08 14:00:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.41	
[11/08 14:00:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/08 14:06:31 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.0952, average train loss: 150.2141
[11/08 14:07:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1546, average loss: 83.8923
[11/08 14:07:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.13	
[11/08 14:07:15 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/08 14:13:41 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.0154, average train loss: 125.9721
[11/08 14:14:25 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1549, average loss: 27.2413
[11/08 14:14:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.39	
[11/08 14:14:25 visual_prompt]: Best epoch 12: best metric: -27.241
[11/08 14:14:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/08 14:20:50 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.0084, average train loss: 193.1136
[11/08 14:21:34 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1548, average loss: 61.8789
[11/08 14:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.29	
[11/08 14:21:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/08 14:27:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9371, average train loss: 118.6384
[11/08 14:28:41 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1566, average loss: 345.6418
[11/08 14:28:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.38	
[11/08 14:28:41 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/08 14:35:03 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9371, average train loss: 161.0755
[11/08 14:35:46 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1550, average loss: 414.8229
[11/08 14:35:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.76	
[11/08 14:35:46 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/08 14:42:08 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9022, average train loss: 172.0898
[11/08 14:42:56 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1570, average loss: 4.8787
[11/08 14:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.59	
[11/08 14:42:56 visual_prompt]: Best epoch 16: best metric: -4.879
[11/08 14:42:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/08 14:49:23 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0516, average train loss: 114.2237
[11/08 14:50:06 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1555, average loss: 185.6744
[11/08 14:50:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 46.68	
[11/08 14:50:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/08 14:56:30 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9650, average train loss: 133.5301
[11/08 14:57:14 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1546, average loss: 40.2502
[11/08 14:57:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.67	
[11/08 14:57:14 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/08 15:03:38 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9550, average train loss: 105.4043
[11/08 15:04:21 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1546, average loss: 47.7231
[11/08 15:04:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.09	
[11/08 15:04:21 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/08 15:10:43 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9149, average train loss: 140.3453
[11/08 15:11:27 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1552, average loss: 145.7717
[11/08 15:11:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.03	
[11/08 15:11:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/08 15:17:49 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9168, average train loss: 162.4553
[11/08 15:18:32 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1551, average loss: 141.7085
[11/08 15:18:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.28	
[11/08 15:18:32 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/08 15:24:54 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9085, average train loss: 164.5457
[11/08 15:25:38 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1558, average loss: 196.1657
[11/08 15:25:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.26	
[11/08 15:25:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/08 15:32:00 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9102, average train loss: 143.4300
[11/08 15:32:43 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1551, average loss: 122.1477
[11/08 15:32:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.24	
[11/08 15:32:43 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/08 15:39:06 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9371, average train loss: 184.5803
[11/08 15:39:50 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1550, average loss: 48.9861
[11/08 15:39:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.93	
[11/08 15:39:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/08 15:46:12 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9226, average train loss: 118.8163
[11/08 15:46:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1551, average loss: 103.0030
[11/08 15:46:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.34	
[11/08 15:46:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/08 15:53:18 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9253, average train loss: 151.4659
[11/08 15:54:02 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1564, average loss: 73.6982
[11/08 15:54:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.63	
[11/08 15:54:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/08 16:00:24 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9279, average train loss: 142.3457
[11/08 16:01:08 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1553, average loss: 171.9545
[11/08 16:01:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.23	
[11/08 16:01:08 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/08 16:07:33 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.0059, average train loss: 130.3624
[11/08 16:08:17 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1551, average loss: 172.0735
[11/08 16:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.24	
[11/08 16:08:17 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/08 16:14:45 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0724, average train loss: 139.5569
[11/08 16:15:28 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1548, average loss: 119.6250
[11/08 16:15:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[11/08 16:15:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/08 16:21:54 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0209, average train loss: 86.2611
[11/08 16:22:38 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1576, average loss: 101.7723
[11/08 16:22:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.94	
[11/08 16:22:38 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/08 16:29:04 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0398, average train loss: 95.6769
[11/08 16:29:49 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1549, average loss: 69.2434
[11/08 16:29:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.02	
[11/08 16:29:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/08 16:36:15 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0319, average train loss: 126.0420
[11/08 16:36:59 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1547, average loss: 256.0590
[11/08 16:36:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.46	
[11/08 16:36:59 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/08 16:43:24 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9984, average train loss: 92.3420
[11/08 16:44:08 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1549, average loss: 45.3893
[11/08 16:44:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.33	
[11/08 16:44:08 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/08 16:50:31 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9580, average train loss: 95.4157
[11/08 16:51:15 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1550, average loss: 232.0104
[11/08 16:51:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.62	
[11/08 16:51:15 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/08 16:57:38 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9466, average train loss: 113.1937
[11/08 16:58:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1547, average loss: 18.7024
[11/08 16:58:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.08	
[11/08 16:58:22 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/08 17:04:46 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9524, average train loss: 132.8776
[11/08 17:05:29 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1576, average loss: 5.3885
[11/08 17:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 43.90	rocauc: 43.39	
[11/08 17:05:29 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/08 17:11:54 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9878, average train loss: 113.8258
[11/08 17:12:38 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1552, average loss: 131.5731
[11/08 17:12:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.53	
[11/08 17:12:38 visual_prompt]: Stopping early.
[11/08 17:12:38 visual_prompt]: Rank of current process: 0. World size: 1
[11/08 17:12:38 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/08 17:12:38 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/08 17:12:38 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/08 17:12:38 visual_prompt]: Training with config:
[11/08 17:12:38 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/08 17:12:38 visual_prompt]: Loading training data...
[11/08 17:12:38 visual_prompt]: Constructing mammo-cbis dataset train...
[11/08 17:12:38 visual_prompt]: Loading validation data...
[11/08 17:12:38 visual_prompt]: Constructing mammo-cbis dataset val...
[11/08 17:12:38 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/08 17:12:41 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/08 17:12:41 visual_prompt]: tuned percent:0.536
[11/08 17:12:41 visual_prompt]: Device used for model: 0
[11/08 17:12:41 visual_prompt]: Setting up Evaluator...
[11/08 17:12:41 visual_prompt]: Setting up Trainer...
[11/08 17:12:41 visual_prompt]: 	Setting up the optimizer...
[11/08 17:12:41 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/08 17:19:07 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0242, average train loss: 1.4017
[11/08 17:19:51 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1553, average loss: 1.2969
[11/08 17:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/08 17:19:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/08 17:26:15 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9786, average train loss: 23.6110
[11/08 17:26:59 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1547, average loss: 5.8490
[11/08 17:26:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.10	
[11/08 17:26:59 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/08 17:33:24 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9965, average train loss: 19.9750
[11/08 17:34:07 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1552, average loss: 15.5227
[11/08 17:34:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.19	
[11/08 17:34:07 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/08 17:40:33 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 11.0038, average train loss: 29.2622
[11/08 17:41:17 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1547, average loss: 42.5903
[11/08 17:41:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.03	
[11/08 17:41:17 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/08 17:47:41 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9849, average train loss: 42.5479
[11/08 17:48:25 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1568, average loss: 91.3031
[11/08 17:48:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.93	
[11/08 17:48:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/08 17:54:50 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.0027, average train loss: 82.3112
[11/08 17:55:34 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1545, average loss: 5.4077
[11/08 17:55:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.87	
[11/08 17:55:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/08 18:01:58 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9553, average train loss: 83.1905
[11/08 18:02:41 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1549, average loss: 17.8734
[11/08 18:02:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.35	
[11/08 18:02:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/08 18:09:04 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9191, average train loss: 120.9400
[11/08 18:09:47 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1551, average loss: 56.7837
[11/08 18:09:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.62	
[11/08 18:09:47 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/08 18:16:09 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9168, average train loss: 93.1148
[11/08 18:16:53 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1549, average loss: 27.9779
[11/08 18:16:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.46	
[11/08 18:16:53 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/08 18:23:16 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9284, average train loss: 94.5493
[11/08 18:23:59 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1551, average loss: 78.7065
[11/08 18:23:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.33	
[11/08 18:23:59 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/08 18:30:22 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9287, average train loss: 100.2712
[11/08 18:31:05 visual_prompt]: Inference (val):avg data time: 2.30e-05, avg batch time: 0.1549, average loss: 213.1924
[11/08 18:31:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.50	
[11/08 18:31:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/08 18:37:28 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9209, average train loss: 140.1140
[11/08 18:38:12 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1575, average loss: 62.5851
[11/08 18:38:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.80	
[11/08 18:38:12 visual_prompt]: Best epoch 12: best metric: -62.585
[11/08 18:38:12 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/08 18:44:35 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9403, average train loss: 161.3989
[11/08 18:45:18 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1587, average loss: 604.5018
[11/08 18:45:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.07	
[11/08 18:45:18 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/08 18:51:40 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9056, average train loss: 97.6883
[11/08 18:52:24 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1548, average loss: 360.5183
[11/08 18:52:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.48	
[11/08 18:52:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/08 18:58:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9522, average train loss: 115.8086
[11/08 18:59:31 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1563, average loss: 43.2895
[11/08 18:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.34	
[11/08 18:59:31 visual_prompt]: Best epoch 15: best metric: -43.289
[11/08 18:59:31 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/08 19:05:54 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9284, average train loss: 93.2741
[11/08 19:06:37 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1562, average loss: 125.7308
[11/08 19:06:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.25	
[11/08 19:06:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/08 19:13:00 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9211, average train loss: 150.8188
[11/08 19:13:43 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1549, average loss: 86.5378
[11/08 19:13:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.85	
[11/08 19:13:43 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/08 19:20:06 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9262, average train loss: 207.3823
[11/08 19:20:50 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1581, average loss: 249.7586
[11/08 19:20:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.08	
[11/08 19:20:50 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/08 19:27:12 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9116, average train loss: 100.9299
[11/08 19:27:55 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1602, average loss: 71.4048
[11/08 19:27:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.79	
[11/08 19:27:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/08 19:34:17 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9125, average train loss: 129.8789
[11/08 19:35:01 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1564, average loss: 109.9322
[11/08 19:35:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.03	
[11/08 19:35:01 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/08 19:41:23 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9125, average train loss: 126.5888
[11/08 19:42:06 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1546, average loss: 43.1655
[11/08 19:42:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.89	
[11/08 19:42:06 visual_prompt]: Best epoch 21: best metric: -43.166
[11/08 19:42:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/08 19:48:29 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9263, average train loss: 106.7672
[11/08 19:49:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1547, average loss: 93.1690
[11/08 19:49:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.11	
[11/08 19:49:13 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/08 19:55:35 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9157, average train loss: 129.5828
[11/08 19:56:18 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1547, average loss: 89.3717
[11/08 19:56:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.39	
[11/08 19:56:18 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/08 20:02:41 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9321, average train loss: 108.7643
[11/08 20:03:25 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1546, average loss: 226.1878
[11/08 20:03:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.34	
[11/08 20:03:25 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/08 20:09:47 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9166, average train loss: 109.0276
[11/08 20:10:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1562, average loss: 47.7153
[11/08 20:10:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.19	
[11/08 20:10:31 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/08 20:16:53 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9159, average train loss: 92.6415
[11/08 20:17:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1568, average loss: 166.3768
[11/08 20:17:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.11	
[11/08 20:17:36 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/08 20:23:59 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9416, average train loss: 142.8833
[11/08 20:24:43 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1587, average loss: 270.1199
[11/08 20:24:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.77	
[11/08 20:24:43 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/08 20:31:06 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9387, average train loss: 110.8392
[11/08 20:31:50 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1549, average loss: 62.8878
[11/08 20:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.45	
[11/08 20:31:50 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/08 20:38:14 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9737, average train loss: 126.6291
[11/08 20:38:57 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1550, average loss: 20.6066
[11/08 20:38:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.90	
[11/08 20:38:57 visual_prompt]: Best epoch 29: best metric: -20.607
[11/08 20:38:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/08 20:45:21 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9683, average train loss: 125.4278
[11/08 20:46:05 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1549, average loss: 149.0784
[11/08 20:46:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.75	
[11/08 20:46:05 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/08 20:52:30 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 11.0009, average train loss: 89.5389
[11/08 20:53:14 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1581, average loss: 82.6392
[11/08 20:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.47	
[11/08 20:53:14 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/08 20:59:40 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0068, average train loss: 109.3117
[11/08 21:00:24 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1552, average loss: 187.4711
[11/08 21:00:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.91	
[11/08 21:00:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/08 21:06:47 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9506, average train loss: 96.1888
[11/08 21:07:31 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1547, average loss: 134.2382
[11/08 21:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.33	
[11/08 21:07:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/08 21:13:55 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9768, average train loss: 99.3844
[11/08 21:14:39 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1576, average loss: 182.4865
[11/08 21:14:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.71	
[11/08 21:14:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/08 21:21:08 visual_prompt]: Epoch 35 / 100: avg data time: 1.08e+01, avg batch time: 11.1124, average train loss: 145.5096
[11/08 21:21:52 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1550, average loss: 148.9748
[11/08 21:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.06	
[11/08 21:21:52 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/08 21:28:17 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9866, average train loss: 92.8905
[11/08 21:29:01 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1547, average loss: 1.0331
[11/08 21:29:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 48.85	
[11/08 21:29:01 visual_prompt]: Best epoch 36: best metric: -1.033
[11/08 21:29:01 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/08 21:35:23 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9274, average train loss: 107.8623
[11/08 21:36:07 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1547, average loss: 107.2041
[11/08 21:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.62	
[11/08 21:36:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/08 21:42:32 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9979, average train loss: 67.0684
[11/08 21:43:16 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1546, average loss: 57.9467
[11/08 21:43:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.32	
[11/08 21:43:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/08 21:49:43 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0441, average train loss: 86.4943
[11/08 21:50:26 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1545, average loss: 49.7563
[11/08 21:50:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.19	
[11/08 21:50:26 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/08 21:56:51 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0127, average train loss: 82.4241
[11/08 21:57:35 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1547, average loss: 104.6452
[11/08 21:57:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.11	
[11/08 21:57:35 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[11/08 22:04:00 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 10.9981, average train loss: 66.2323
[11/08 22:04:44 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1546, average loss: 127.3152
[11/08 22:04:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.74	
[11/08 22:04:44 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/08 22:11:11 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e+01, avg batch time: 11.0427, average train loss: 84.1705
[11/08 22:11:55 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1545, average loss: 40.6323
[11/08 22:11:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.19	
[11/08 22:11:55 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/08 22:18:20 visual_prompt]: Epoch 43 / 100: avg data time: 1.07e+01, avg batch time: 11.0065, average train loss: 105.5226
[11/08 22:19:04 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1549, average loss: 11.7358
[11/08 22:19:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.60	
[11/08 22:19:04 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/08 22:25:30 visual_prompt]: Epoch 44 / 100: avg data time: 1.07e+01, avg batch time: 11.0099, average train loss: 68.8686
[11/08 22:26:14 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1570, average loss: 59.1259
[11/08 22:26:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.06	
[11/08 22:26:14 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/08 22:32:43 visual_prompt]: Epoch 45 / 100: avg data time: 1.08e+01, avg batch time: 11.1142, average train loss: 72.9090
[11/08 22:33:27 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1550, average loss: 97.9094
[11/08 22:33:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.19	
[11/08 22:33:27 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/08 22:39:55 visual_prompt]: Epoch 46 / 100: avg data time: 1.07e+01, avg batch time: 11.0851, average train loss: 67.0704
[11/08 22:40:40 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1574, average loss: 132.7506
[11/08 22:40:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.03	
[11/08 22:40:40 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/08 22:47:07 visual_prompt]: Epoch 47 / 100: avg data time: 1.07e+01, avg batch time: 11.0641, average train loss: 66.6953
[11/08 22:47:51 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1561, average loss: 52.0069
[11/08 22:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.83	
[11/08 22:47:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 31.89093389542498
[11/08 22:54:18 visual_prompt]: Epoch 48 / 100: avg data time: 1.07e+01, avg batch time: 11.0363, average train loss: 57.5547
[11/08 22:55:02 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1570, average loss: 35.9259
[11/08 22:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.91	
[11/08 22:55:02 visual_prompt]: Training 49 / 100 epoch, with learning rate 31.04804738999169
[11/08 23:01:29 visual_prompt]: Epoch 49 / 100: avg data time: 1.07e+01, avg batch time: 11.0612, average train loss: 78.4784
[11/08 23:02:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1558, average loss: 37.3425
[11/08 23:02:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.09	
[11/08 23:02:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 30.19779227044398
[11/08 23:08:41 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e+01, avg batch time: 11.0685, average train loss: 56.3838
[11/08 23:09:25 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1545, average loss: 87.1589
[11/08 23:09:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.51	
[11/08 23:09:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 29.341204441673263
[11/08 23:15:53 visual_prompt]: Epoch 51 / 100: avg data time: 1.07e+01, avg batch time: 11.0734, average train loss: 62.2020
[11/08 23:16:37 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1546, average loss: 97.7682
[11/08 23:16:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.06	
[11/08 23:16:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 28.479327524001636
[11/08 23:23:05 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0860, average train loss: 66.1517
[11/08 23:23:49 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1564, average loss: 107.3238
[11/08 23:23:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.00	
[11/08 23:23:49 visual_prompt]: Training 53 / 100 epoch, with learning rate 27.61321158169134
[11/08 23:30:14 visual_prompt]: Epoch 53 / 100: avg data time: 1.06e+01, avg batch time: 10.9789, average train loss: 59.3902
[11/08 23:30:57 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1570, average loss: 51.7134
[11/08 23:30:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.35	
[11/08 23:30:57 visual_prompt]: Training 54 / 100 epoch, with learning rate 26.74391184360313
[11/08 23:37:19 visual_prompt]: Epoch 54 / 100: avg data time: 1.06e+01, avg batch time: 10.9153, average train loss: 40.6405
[11/08 23:38:03 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1545, average loss: 28.5061
[11/08 23:38:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/08 23:38:03 visual_prompt]: Training 55 / 100 epoch, with learning rate 25.872487417562528
[11/08 23:44:25 visual_prompt]: Epoch 55 / 100: avg data time: 1.06e+01, avg batch time: 10.9200, average train loss: 58.7721
[11/08 23:45:09 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1546, average loss: 21.0842
[11/08 23:45:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.02	
[11/08 23:45:09 visual_prompt]: Training 56 / 100 epoch, with learning rate 25.0
[11/08 23:51:36 visual_prompt]: Epoch 56 / 100: avg data time: 1.07e+01, avg batch time: 11.0529, average train loss: 63.7461
[11/08 23:52:20 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1574, average loss: 66.9890
[11/08 23:52:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.44	
[11/08 23:52:20 visual_prompt]: Training 57 / 100 epoch, with learning rate 24.127512582437483
[11/08 23:58:48 visual_prompt]: Epoch 57 / 100: avg data time: 1.07e+01, avg batch time: 11.0830, average train loss: 69.6650
[11/08 23:59:33 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1546, average loss: 9.6194
[11/08 23:59:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.73	
[11/08 23:59:33 visual_prompt]: Stopping early.
[11/08 23:59:33 visual_prompt]: Rank of current process: 0. World size: 1
[11/08 23:59:33 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/08 23:59:33 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/08 23:59:33 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/08 23:59:33 visual_prompt]: Training with config:
[11/08 23:59:33 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/08 23:59:33 visual_prompt]: Loading training data...
[11/08 23:59:33 visual_prompt]: Constructing mammo-cbis dataset train...
[11/08 23:59:33 visual_prompt]: Loading validation data...
[11/08 23:59:33 visual_prompt]: Constructing mammo-cbis dataset val...
[11/08 23:59:33 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/08 23:59:35 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/08 23:59:35 visual_prompt]: tuned percent:0.536
[11/08 23:59:35 visual_prompt]: Device used for model: 0
[11/08 23:59:35 visual_prompt]: Setting up Evaluator...
[11/08 23:59:35 visual_prompt]: Setting up Trainer...
[11/08 23:59:35 visual_prompt]: 	Setting up the optimizer...
[11/08 23:59:35 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/09 00:06:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0721, average train loss: 1.4017
[11/09 00:06:47 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1558, average loss: 1.2969
[11/09 00:06:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/09 00:06:47 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/09 00:13:12 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.0054, average train loss: 22.1121
[11/09 00:13:56 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1549, average loss: 12.3772
[11/09 00:13:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.20	
[11/09 00:13:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/09 00:20:21 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 11.0002, average train loss: 23.4895
[11/09 00:21:05 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1554, average loss: 32.5041
[11/09 00:21:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.99	
[11/09 00:21:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/09 00:27:30 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9933, average train loss: 39.9400
[11/09 00:28:14 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 73.8900
[11/09 00:28:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.01	
[11/09 00:28:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/09 00:34:39 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9955, average train loss: 68.0024
[11/09 00:35:23 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 63.6253
[11/09 00:35:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.42	
[11/09 00:35:23 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/09 00:41:47 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9887, average train loss: 85.1397
[11/09 00:42:31 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1545, average loss: 82.4955
[11/09 00:42:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.13	
[11/09 00:42:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/09 00:48:57 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0240, average train loss: 45.2378
[11/09 00:49:41 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1577, average loss: 87.7445
[11/09 00:49:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.75	
[11/09 00:49:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/09 00:56:06 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9866, average train loss: 58.8196
[11/09 00:56:50 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1549, average loss: 76.0677
[11/09 00:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.23	
[11/09 00:56:50 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/09 01:03:16 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.0177, average train loss: 84.5682
[11/09 01:04:00 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1563, average loss: 126.4814
[11/09 01:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.42	
[11/09 01:04:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/09 01:10:25 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9987, average train loss: 54.1289
[11/09 01:11:09 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1581, average loss: 132.2860
[11/09 01:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.23	
[11/09 01:11:09 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/09 01:17:34 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9986, average train loss: 89.0246
[11/09 01:18:18 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1547, average loss: 88.2778
[11/09 01:18:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.90	
[11/09 01:18:18 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/09 01:24:41 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9458, average train loss: 60.0773
[11/09 01:25:25 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1550, average loss: 88.3181
[11/09 01:25:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.17	
[11/09 01:25:25 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/09 01:31:50 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9910, average train loss: 102.6829
[11/09 01:32:34 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1580, average loss: 125.7947
[11/09 01:32:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.11	
[11/09 01:32:34 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/09 01:38:57 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9349, average train loss: 98.7248
[11/09 01:39:40 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1563, average loss: 249.8005
[11/09 01:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.81	
[11/09 01:39:40 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/09 01:46:05 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9832, average train loss: 135.1511
[11/09 01:46:49 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1582, average loss: 251.1749
[11/09 01:46:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.82	
[11/09 01:46:49 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/09 01:53:12 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9603, average train loss: 86.3924
[11/09 01:53:56 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1547, average loss: 141.1784
[11/09 01:53:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.99	
[11/09 01:53:56 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/09 02:00:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9610, average train loss: 102.0093
[11/09 02:01:04 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1546, average loss: 48.0747
[11/09 02:01:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.21	
[11/09 02:01:04 visual_prompt]: Best epoch 17: best metric: -48.075
[11/09 02:01:04 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/09 02:07:31 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0493, average train loss: 86.9874
[11/09 02:08:15 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1573, average loss: 57.4515
[11/09 02:08:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.56	
[11/09 02:08:15 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/09 02:14:40 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9923, average train loss: 80.2692
[11/09 02:15:24 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1546, average loss: 135.2312
[11/09 02:15:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.16	
[11/09 02:15:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/09 02:21:49 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0031, average train loss: 98.2957
[11/09 02:22:33 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1549, average loss: 79.6041
[11/09 02:22:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.22	
[11/09 02:22:33 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/09 02:28:58 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9994, average train loss: 95.6013
[11/09 02:29:42 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1548, average loss: 154.4986
[11/09 02:29:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.79	
[11/09 02:29:42 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/09 02:36:07 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 11.0011, average train loss: 61.4619
[11/09 02:36:51 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1551, average loss: 159.0264
[11/09 02:36:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.86	
[11/09 02:36:51 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/09 02:43:16 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9804, average train loss: 92.0237
[11/09 02:44:00 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1545, average loss: 29.3649
[11/09 02:44:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.03	
[11/09 02:44:00 visual_prompt]: Best epoch 23: best metric: -29.365
[11/09 02:44:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/09 02:50:25 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9996, average train loss: 56.4870
[11/09 02:51:09 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1550, average loss: 109.6253
[11/09 02:51:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 39.10	
[11/09 02:51:09 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/09 02:57:34 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 10.9996, average train loss: 63.3988
[11/09 02:58:18 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1548, average loss: 80.8156
[11/09 02:58:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.00	
[11/09 02:58:18 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/09 03:04:45 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0648, average train loss: 53.7435
[11/09 03:05:29 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1548, average loss: 4.8900
[11/09 03:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.38	
[11/09 03:05:29 visual_prompt]: Best epoch 26: best metric: -4.890
[11/09 03:05:29 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/09 03:11:57 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.0628, average train loss: 84.0545
[11/09 03:12:41 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1546, average loss: 231.9026
[11/09 03:12:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.74	
[11/09 03:12:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/09 03:19:09 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.0838, average train loss: 88.4511
[11/09 03:19:53 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1554, average loss: 113.8948
[11/09 03:19:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.78	
[11/09 03:19:53 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/09 03:26:18 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9861, average train loss: 89.1379
[11/09 03:27:02 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1550, average loss: 187.0372
[11/09 03:27:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.06	
[11/09 03:27:02 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/09 03:33:28 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0309, average train loss: 85.3108
[11/09 03:34:12 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1547, average loss: 103.6908
[11/09 03:34:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.96	
[11/09 03:34:12 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/09 03:40:38 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0157, average train loss: 72.5413
[11/09 03:41:22 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1544, average loss: 14.8531
[11/09 03:41:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.09	
[11/09 03:41:22 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/09 03:47:48 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0334, average train loss: 88.2951
[11/09 03:48:32 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1549, average loss: 67.6624
[11/09 03:48:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.32	
[11/09 03:48:32 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/09 03:54:58 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0230, average train loss: 74.5266
[11/09 03:55:42 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1551, average loss: 167.3409
[11/09 03:55:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.54	
[11/09 03:55:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/09 04:02:06 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9658, average train loss: 110.1007
[11/09 04:02:49 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1547, average loss: 204.3955
[11/09 04:02:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.32	
[11/09 04:02:49 visual_prompt]: Training 35 / 100 epoch, with learning rate 41.72826515897145
[11/09 04:09:11 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9108, average train loss: 91.6685
[11/09 04:09:55 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1576, average loss: 36.3514
[11/09 04:09:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.31	
[11/09 04:09:55 visual_prompt]: Training 36 / 100 epoch, with learning rate 41.06969024216348
[11/09 04:16:18 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9418, average train loss: 49.5497
[11/09 04:17:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1575, average loss: 20.5126
[11/09 04:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.04	
[11/09 04:17:02 visual_prompt]: Training 37 / 100 epoch, with learning rate 40.391536883141455
[11/09 04:23:24 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9162, average train loss: 43.9531
[11/09 04:24:08 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1549, average loss: 110.3693
[11/09 04:24:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/09 04:24:08 visual_prompt]: Training 38 / 100 epoch, with learning rate 39.69463130731183
[11/09 04:30:31 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9523, average train loss: 56.9468
[11/09 04:31:15 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1549, average loss: 86.2540
[11/09 04:31:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.34	
[11/09 04:31:15 visual_prompt]: Training 39 / 100 epoch, with learning rate 38.97982258676867
[11/09 04:37:39 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 10.9651, average train loss: 48.1763
[11/09 04:38:23 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1545, average loss: 65.2560
[11/09 04:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.02	
[11/09 04:38:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 38.24798160583012
[11/09 04:44:46 visual_prompt]: Epoch 40 / 100: avg data time: 1.06e+01, avg batch time: 10.9592, average train loss: 31.3766
[11/09 04:45:30 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1544, average loss: 55.8309
[11/09 04:45:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.07	
[11/09 04:45:30 visual_prompt]: Training 41 / 100 epoch, with learning rate 37.5
[11/09 04:51:52 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 10.9205, average train loss: 61.1692
[11/09 04:52:36 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1549, average loss: 48.2909
[11/09 04:52:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/09 04:52:36 visual_prompt]: Training 42 / 100 epoch, with learning rate 36.736789069647266
[11/09 04:59:00 visual_prompt]: Epoch 42 / 100: avg data time: 1.06e+01, avg batch time: 10.9727, average train loss: 63.2853
[11/09 04:59:44 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1574, average loss: 135.7826
[11/09 04:59:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.49	
[11/09 04:59:44 visual_prompt]: Training 43 / 100 epoch, with learning rate 35.959278669726935
[11/09 05:06:08 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 10.9728, average train loss: 49.6684
[11/09 05:06:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1550, average loss: 10.7525
[11/09 05:06:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[11/09 05:06:52 visual_prompt]: Training 44 / 100 epoch, with learning rate 35.16841607689501
[11/09 05:13:15 visual_prompt]: Epoch 44 / 100: avg data time: 1.06e+01, avg batch time: 10.9444, average train loss: 72.2298
[11/09 05:13:59 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1588, average loss: 186.8863
[11/09 05:13:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.29	
[11/09 05:13:59 visual_prompt]: Training 45 / 100 epoch, with learning rate 34.365164835397806
[11/09 05:20:24 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9828, average train loss: 67.7633
[11/09 05:21:08 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1548, average loss: 35.8826
[11/09 05:21:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.92	
[11/09 05:21:08 visual_prompt]: Training 46 / 100 epoch, with learning rate 33.55050358314172
[11/09 05:27:30 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 10.9257, average train loss: 67.1227
[11/09 05:28:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1548, average loss: 37.2472
[11/09 05:28:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.67	
[11/09 05:28:14 visual_prompt]: Training 47 / 100 epoch, with learning rate 32.72542485937369
[11/09 05:34:37 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 10.9430, average train loss: 26.1656
[11/09 05:35:21 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1547, average loss: 12.0804
[11/09 05:35:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.36	
[11/09 05:35:21 visual_prompt]: Stopping early.
[11/09 05:35:24 visual_prompt]: Rank of current process: 0. World size: 1
[11/09 05:35:24 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/09 05:35:24 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/09 05:35:24 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/09 05:35:24 visual_prompt]: Training with config:
[11/09 05:35:24 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr50.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 50.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/09 05:35:24 visual_prompt]: Loading training data...
[11/09 05:35:24 visual_prompt]: Constructing mammo-cbis dataset train...
[11/09 05:35:24 visual_prompt]: Loading validation data...
[11/09 05:35:24 visual_prompt]: Constructing mammo-cbis dataset val...
[11/09 05:35:24 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/09 05:35:27 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/09 05:35:27 visual_prompt]: tuned percent:0.536
[11/09 05:35:27 visual_prompt]: Device used for model: 0
[11/09 05:35:27 visual_prompt]: Setting up Evaluator...
[11/09 05:35:27 visual_prompt]: Setting up Trainer...
[11/09 05:35:27 visual_prompt]: 	Setting up the optimizer...
[11/09 05:35:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/09 05:41:50 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9559, average train loss: 1.4017
[11/09 05:42:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1553, average loss: 1.2969
[11/09 05:42:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/09 05:42:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 5.0
[11/09 05:48:58 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9631, average train loss: 21.7661
[11/09 05:49:42 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1546, average loss: 25.3822
[11/09 05:49:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/09 05:49:42 visual_prompt]: Training 3 / 100 epoch, with learning rate 10.0
[11/09 05:56:04 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9067, average train loss: 34.1849
[11/09 05:56:47 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1546, average loss: 16.2270
[11/09 05:56:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.02	
[11/09 05:56:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 15.0
[11/09 06:03:10 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9396, average train loss: 47.3847
[11/09 06:03:54 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1550, average loss: 92.7004
[11/09 06:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.74	
[11/09 06:03:54 visual_prompt]: Training 5 / 100 epoch, with learning rate 20.0
[11/09 06:10:16 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9126, average train loss: 46.3534
[11/09 06:11:00 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1546, average loss: 17.4367
[11/09 06:11:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.76	
[11/09 06:11:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 25.0
[11/09 06:17:23 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9485, average train loss: 50.4854
[11/09 06:18:07 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1550, average loss: 52.2753
[11/09 06:18:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.56	
[11/09 06:18:07 visual_prompt]: Training 7 / 100 epoch, with learning rate 30.0
[11/09 06:24:32 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 11.0016, average train loss: 60.1930
[11/09 06:25:16 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1556, average loss: 48.0877
[11/09 06:25:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.22	
[11/09 06:25:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 35.0
[11/09 06:31:39 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9482, average train loss: 54.7363
[11/09 06:32:23 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1569, average loss: 58.8555
[11/09 06:32:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/09 06:32:23 visual_prompt]: Training 9 / 100 epoch, with learning rate 40.0
[11/09 06:38:47 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9807, average train loss: 42.7252
[11/09 06:39:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1550, average loss: 2.2491
[11/09 06:39:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.39	
[11/09 06:39:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 45.0
[11/09 06:45:54 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9442, average train loss: 40.9211
[11/09 06:46:38 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1548, average loss: 58.8204
[11/09 06:46:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.17	
[11/09 06:46:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 50.0
[11/09 06:53:01 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9446, average train loss: 26.3818
[11/09 06:53:45 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1575, average loss: 26.9018
[11/09 06:53:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.10	
[11/09 06:53:45 visual_prompt]: Training 12 / 100 epoch, with learning rate 49.9847706754774
[11/09 07:00:10 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9830, average train loss: 31.1934
[11/09 07:00:54 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1591, average loss: 33.0704
[11/09 07:00:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.81	
[11/09 07:00:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 49.939101256495604
[11/09 07:07:18 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9817, average train loss: 31.9190
[11/09 07:08:02 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1550, average loss: 0.7135
[11/09 07:08:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.05	
[11/09 07:08:02 visual_prompt]: Best epoch 13: best metric: -0.713
[11/09 07:08:02 visual_prompt]: Training 14 / 100 epoch, with learning rate 49.86304738420683
[11/09 07:14:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9778, average train loss: 43.5940
[11/09 07:15:10 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1547, average loss: 171.8142
[11/09 07:15:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.90	
[11/09 07:15:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 49.75670171853926
[11/09 07:21:35 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9964, average train loss: 46.4447
[11/09 07:22:19 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1549, average loss: 59.5566
[11/09 07:22:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[11/09 07:22:19 visual_prompt]: Training 16 / 100 epoch, with learning rate 49.6201938253052
[11/09 07:28:43 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9757, average train loss: 43.0909
[11/09 07:29:27 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1549, average loss: 30.7253
[11/09 07:29:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.77	
[11/09 07:29:27 visual_prompt]: Training 17 / 100 epoch, with learning rate 49.45369001834514
[11/09 07:35:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9239, average train loss: 34.5476
[11/09 07:36:33 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1547, average loss: 21.3194
[11/09 07:36:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.23	
[11/09 07:36:33 visual_prompt]: Training 18 / 100 epoch, with learning rate 49.25739315689991
[11/09 07:42:56 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9206, average train loss: 36.2032
[11/09 07:43:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1545, average loss: 36.6952
[11/09 07:43:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.02	
[11/09 07:43:39 visual_prompt]: Training 19 / 100 epoch, with learning rate 49.03154239845797
[11/09 07:50:03 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9615, average train loss: 46.2990
[11/09 07:50:47 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1546, average loss: 86.4099
[11/09 07:50:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.17	
[11/09 07:50:47 visual_prompt]: Training 20 / 100 epoch, with learning rate 48.77641290737884
[11/09 07:57:13 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.0093, average train loss: 27.7558
[11/09 07:57:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1548, average loss: 31.5779
[11/09 07:57:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.16	
[11/09 07:57:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 48.49231551964771
[11/09 08:04:22 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0111, average train loss: 34.4705
[11/09 08:05:06 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1545, average loss: 71.5491
[11/09 08:05:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.82	
[11/09 08:05:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 48.17959636416968
[11/09 08:11:30 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9769, average train loss: 40.6188
[11/09 08:12:14 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1546, average loss: 47.7438
[11/09 08:12:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.54	
[11/09 08:12:14 visual_prompt]: Training 23 / 100 epoch, with learning rate 47.83863644106502
[11/09 08:18:37 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9231, average train loss: 67.4955
[11/09 08:19:21 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1551, average loss: 60.5664
[11/09 08:19:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[11/09 08:19:21 visual_prompt]: Training 24 / 100 epoch, with learning rate 47.46985115747918
[11/09 08:25:45 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9732, average train loss: 65.7247
[11/09 08:26:28 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1545, average loss: 4.4340
[11/09 08:26:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.81	
[11/09 08:26:28 visual_prompt]: Training 25 / 100 epoch, with learning rate 47.073689821473174
[11/09 08:32:52 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9589, average train loss: 37.8975
[11/09 08:33:36 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1550, average loss: 76.4973
[11/09 08:33:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.36	
[11/09 08:33:36 visual_prompt]: Training 26 / 100 epoch, with learning rate 46.65063509461097
[11/09 08:40:02 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0270, average train loss: 40.1408
[11/09 08:40:46 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1552, average loss: 18.5030
[11/09 08:40:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.92	
[11/09 08:40:46 visual_prompt]: Training 27 / 100 epoch, with learning rate 46.20120240391065
[11/09 08:47:11 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9995, average train loss: 34.2878
[11/09 08:47:54 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1546, average loss: 5.8060
[11/09 08:47:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.94	
[11/09 08:47:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 45.72593931387604
[11/09 08:54:17 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9281, average train loss: 27.9739
[11/09 08:55:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1549, average loss: 42.1523
[11/09 08:55:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.55	
[11/09 08:55:01 visual_prompt]: Training 29 / 100 epoch, with learning rate 45.22542485937369
[11/09 09:01:26 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0175, average train loss: 27.1396
[11/09 09:02:10 visual_prompt]: Inference (val):avg data time: 2.54e-05, avg batch time: 0.1546, average loss: 31.2411
[11/09 09:02:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.42	
[11/09 09:02:10 visual_prompt]: Training 30 / 100 epoch, with learning rate 44.70026884016804
[11/09 09:08:35 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9905, average train loss: 29.9594
[11/09 09:09:20 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1550, average loss: 55.9533
[11/09 09:09:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.61	
[11/09 09:09:20 visual_prompt]: Training 31 / 100 epoch, with learning rate 44.15111107797445
[11/09 09:15:44 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9780, average train loss: 46.8040
[11/09 09:16:28 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1557, average loss: 77.8101
[11/09 09:16:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.19	
[11/09 09:16:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 43.57862063693486
[11/09 09:22:51 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9582, average train loss: 44.0014
[11/09 09:23:36 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1576, average loss: 83.5956
[11/09 09:23:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.10	
[11/09 09:23:36 visual_prompt]: Training 33 / 100 epoch, with learning rate 42.98349500846628
[11/09 09:29:58 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9263, average train loss: 39.2778
[11/09 09:30:42 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1550, average loss: 31.7681
[11/09 09:30:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/09 09:30:42 visual_prompt]: Training 34 / 100 epoch, with learning rate 42.36645926147493
[11/09 09:37:05 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9431, average train loss: 23.8874
[11/09 09:37:49 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1550, average loss: 65.1344
[11/09 09:37:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.02	
[11/09 09:37:49 visual_prompt]: Stopping early.
[11/09 09:37:49 visual_prompt]: Rank of current process: 0. World size: 1
[11/09 09:37:49 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/09 09:37:49 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/09 09:37:49 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/09 09:37:49 visual_prompt]: Training with config:
[11/09 09:37:49 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/09 09:37:49 visual_prompt]: Loading training data...
[11/09 09:37:49 visual_prompt]: Constructing mammo-cbis dataset train...
[11/09 09:37:49 visual_prompt]: Loading validation data...
[11/09 09:37:49 visual_prompt]: Constructing mammo-cbis dataset val...
[11/09 09:37:49 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/09 09:37:52 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/09 09:37:52 visual_prompt]: tuned percent:0.536
[11/09 09:37:52 visual_prompt]: Device used for model: 0
[11/09 09:37:52 visual_prompt]: Setting up Evaluator...
[11/09 09:37:52 visual_prompt]: Setting up Trainer...
[11/09 09:37:52 visual_prompt]: 	Setting up the optimizer...
[11/09 09:37:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/09 09:44:16 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9553, average train loss: 1.4017
[11/09 09:45:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1553, average loss: 1.2969
[11/09 09:45:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/09 09:45:00 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/09 09:51:22 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9310, average train loss: 17.7458
[11/09 09:52:06 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1544, average loss: 2.5264
[11/09 09:52:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.93	
[11/09 09:52:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/09 09:58:31 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9933, average train loss: 6.0762
[11/09 09:59:15 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1558, average loss: 10.0471
[11/09 09:59:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.86	
[11/09 09:59:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/09 10:05:42 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0623, average train loss: 13.3022
[11/09 10:06:27 visual_prompt]: Inference (val):avg data time: 2.37e-05, avg batch time: 0.1560, average loss: 0.7905
[11/09 10:06:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.14	
[11/09 10:06:27 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/09 10:12:53 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.0422, average train loss: 20.1636
[11/09 10:13:37 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1550, average loss: 11.0347
[11/09 10:13:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.68	
[11/09 10:13:37 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/09 10:20:02 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9808, average train loss: 28.9459
[11/09 10:20:46 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1547, average loss: 9.0186
[11/09 10:20:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.18	
[11/09 10:20:46 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/09 10:27:12 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0223, average train loss: 33.6986
[11/09 10:27:56 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1555, average loss: 16.0607
[11/09 10:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.59	
[11/09 10:27:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/09 10:34:21 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9881, average train loss: 52.7007
[11/09 10:35:03 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1547, average loss: 47.4837
[11/09 10:35:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.61	
[11/09 10:35:03 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/09 10:41:28 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9973, average train loss: 43.3817
[11/09 10:42:12 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1551, average loss: 47.4411
[11/09 10:42:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.65	
[11/09 10:42:12 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/09 10:48:37 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9869, average train loss: 60.4023
[11/09 10:49:21 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1549, average loss: 99.3796
[11/09 10:49:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.62	
[11/09 10:49:21 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/09 10:55:54 visual_prompt]: Epoch 11 / 100: avg data time: 1.09e+01, avg batch time: 11.2314, average train loss: 67.8739
[11/09 10:56:38 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1548, average loss: 28.6182
[11/09 10:56:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.49	
[11/09 10:56:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/09 11:03:00 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9143, average train loss: 57.0712
[11/09 11:03:44 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1576, average loss: 62.8103
[11/09 11:03:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.88	
[11/09 11:03:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/09 11:10:07 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9392, average train loss: 64.5640
[11/09 11:10:51 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1549, average loss: 52.9235
[11/09 11:10:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.52	
[11/09 11:10:51 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/09 11:17:14 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9389, average train loss: 71.7291
[11/09 11:17:57 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1565, average loss: 26.0238
[11/09 11:17:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.23	
[11/09 11:17:57 visual_prompt]: Best epoch 14: best metric: -26.024
[11/09 11:17:57 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/09 11:24:21 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9512, average train loss: 62.6632
[11/09 11:25:05 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1550, average loss: 131.6016
[11/09 11:25:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.86	
[11/09 11:25:05 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/09 11:31:28 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9476, average train loss: 63.4820
[11/09 11:32:12 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1550, average loss: 138.1876
[11/09 11:32:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.39	
[11/09 11:32:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/09 11:38:35 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9450, average train loss: 82.9967
[11/09 11:39:19 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1584, average loss: 22.7312
[11/09 11:39:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.14	
[11/09 11:39:19 visual_prompt]: Best epoch 17: best metric: -22.731
[11/09 11:39:19 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/09 11:45:43 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9680, average train loss: 59.9483
[11/09 11:46:26 visual_prompt]: Inference (val):avg data time: 2.38e-05, avg batch time: 0.1552, average loss: 54.1222
[11/09 11:46:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.00	
[11/09 11:46:26 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/09 11:52:52 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0097, average train loss: 50.7026
[11/09 11:53:35 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1550, average loss: 39.4407
[11/09 11:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.38	
[11/09 11:53:35 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/09 12:00:12 visual_prompt]: Epoch 20 / 100: avg data time: 1.10e+01, avg batch time: 11.3261, average train loss: 43.7648
[11/09 12:00:55 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1573, average loss: 79.8305
[11/09 12:00:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.47	
[11/09 12:00:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/09 12:07:17 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9220, average train loss: 84.6545
[11/09 12:08:01 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1551, average loss: 201.8625
[11/09 12:08:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.33	
[11/09 12:08:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/09 12:14:24 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9256, average train loss: 95.4676
[11/09 12:15:08 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1544, average loss: 59.5939
[11/09 12:15:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.13	
[11/09 12:15:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/09 12:21:32 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9606, average train loss: 62.8857
[11/09 12:22:15 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1552, average loss: 308.6205
[11/09 12:22:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.81	
[11/09 12:22:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/09 12:28:38 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9320, average train loss: 84.8989
[11/09 12:29:22 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1582, average loss: 29.9426
[11/09 12:29:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.02	
[11/09 12:29:22 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/09 12:35:44 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9218, average train loss: 42.0210
[11/09 12:36:28 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1550, average loss: 52.5575
[11/09 12:36:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.05	
[11/09 12:36:28 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/09 12:42:50 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9231, average train loss: 53.2825
[11/09 12:43:34 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1546, average loss: 15.9819
[11/09 12:43:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.74	
[11/09 12:43:34 visual_prompt]: Best epoch 26: best metric: -15.982
[11/09 12:43:34 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/09 12:49:56 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9320, average train loss: 42.3252
[11/09 12:50:40 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1584, average loss: 33.4570
[11/09 12:50:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.77	
[11/09 12:50:40 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/09 12:57:02 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9169, average train loss: 53.7147
[11/09 12:57:46 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1586, average loss: 37.1718
[11/09 12:57:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.13	
[11/09 12:57:46 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/09 13:04:09 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9423, average train loss: 54.8943
[11/09 13:04:53 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1570, average loss: 8.5962
[11/09 13:04:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.84	
[11/09 13:04:53 visual_prompt]: Best epoch 29: best metric: -8.596
[11/09 13:04:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/09 13:11:15 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9099, average train loss: 43.6914
[11/09 13:12:01 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1555, average loss: 100.2381
[11/09 13:12:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.95	
[11/09 13:12:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/09 13:18:25 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9539, average train loss: 55.4471
[11/09 13:19:08 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1548, average loss: 3.5873
[11/09 13:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 51.18	
[11/09 13:19:08 visual_prompt]: Best epoch 31: best metric: -3.587
[11/09 13:19:08 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/09 13:25:31 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9307, average train loss: 58.7586
[11/09 13:26:15 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1548, average loss: 7.3155
[11/09 13:26:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 50.53	
[11/09 13:26:15 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/09 13:32:47 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2186, average train loss: 50.7995
[11/09 13:33:31 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1548, average loss: 59.6516
[11/09 13:33:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.68	
[11/09 13:33:31 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/09 13:39:54 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9339, average train loss: 46.0693
[11/09 13:40:38 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1549, average loss: 14.4347
[11/09 13:40:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.03	
[11/09 13:40:38 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/09 13:47:01 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9409, average train loss: 40.7974
[11/09 13:47:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1551, average loss: 120.3958
[11/09 13:47:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.94	
[11/09 13:47:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/09 13:54:07 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9286, average train loss: 52.4897
[11/09 13:54:51 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1585, average loss: 28.1935
[11/09 13:54:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.21	
[11/09 13:54:51 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/09 14:01:13 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9143, average train loss: 59.0958
[11/09 14:01:57 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1548, average loss: 188.9174
[11/09 14:01:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.64	
[11/09 14:01:57 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/09 14:08:20 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9441, average train loss: 59.5429
[11/09 14:09:03 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1553, average loss: 183.4667
[11/09 14:09:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.66	
[11/09 14:09:03 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/09 14:15:27 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 10.9627, average train loss: 48.7794
[11/09 14:16:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 26.3649
[11/09 14:16:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.50	
[11/09 14:16:11 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/09 14:22:35 visual_prompt]: Epoch 40 / 100: avg data time: 1.06e+01, avg batch time: 10.9538, average train loss: 53.6892
[11/09 14:23:19 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1547, average loss: 67.7834
[11/09 14:23:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.07	
[11/09 14:23:19 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/09 14:29:42 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 10.9425, average train loss: 53.0017
[11/09 14:30:25 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1584, average loss: 129.6501
[11/09 14:30:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.70	
[11/09 14:30:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/09 14:36:48 visual_prompt]: Epoch 42 / 100: avg data time: 1.06e+01, avg batch time: 10.9397, average train loss: 55.6739
[11/09 14:37:32 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1550, average loss: 80.2822
[11/09 14:37:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.21	
[11/09 14:37:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/09 14:43:55 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 10.9269, average train loss: 47.7076
[11/09 14:44:38 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1553, average loss: 59.8913
[11/09 14:44:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.75	
[11/09 14:44:38 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/09 14:51:00 visual_prompt]: Epoch 44 / 100: avg data time: 1.05e+01, avg batch time: 10.9072, average train loss: 49.3814
[11/09 14:51:44 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1550, average loss: 31.0133
[11/09 14:51:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 50.38	
[11/09 14:51:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/09 14:58:07 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9419, average train loss: 68.1023
[11/09 14:58:50 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1553, average loss: 150.0696
[11/09 14:58:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.90	
[11/09 14:58:50 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/09 15:05:13 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 10.9446, average train loss: 48.6911
[11/09 15:05:57 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1548, average loss: 85.4933
[11/09 15:05:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.48	
[11/09 15:05:57 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/09 15:12:21 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 10.9504, average train loss: 53.2251
[11/09 15:13:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1547, average loss: 67.8667
[11/09 15:13:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.22	
[11/09 15:13:05 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/09 15:19:28 visual_prompt]: Epoch 48 / 100: avg data time: 1.06e+01, avg batch time: 10.9615, average train loss: 39.2967
[11/09 15:20:12 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1572, average loss: 18.7353
[11/09 15:20:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.02	
[11/09 15:20:12 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/09 15:26:35 visual_prompt]: Epoch 49 / 100: avg data time: 1.06e+01, avg batch time: 10.9337, average train loss: 36.0077
[11/09 15:27:19 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1550, average loss: 58.3178
[11/09 15:27:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.16	
[11/09 15:27:19 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/09 15:33:42 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e+01, avg batch time: 10.9309, average train loss: 27.5978
[11/09 15:34:25 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1576, average loss: 8.7403
[11/09 15:34:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.37	
[11/09 15:34:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/09 15:40:47 visual_prompt]: Epoch 51 / 100: avg data time: 1.06e+01, avg batch time: 10.9290, average train loss: 27.4332
[11/09 15:41:31 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1566, average loss: 17.8175
[11/09 15:41:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.02	
[11/09 15:41:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/09 15:47:56 visual_prompt]: Epoch 52 / 100: avg data time: 1.06e+01, avg batch time: 10.9786, average train loss: 37.2250
[11/09 15:48:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1547, average loss: 5.0324
[11/09 15:48:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.27	
[11/09 15:48:39 visual_prompt]: Stopping early.
[11/09 15:48:40 visual_prompt]: Rank of current process: 0. World size: 1
[11/09 15:48:40 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/09 15:48:40 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/09 15:48:40 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/09 15:48:40 visual_prompt]: Training with config:
[11/09 15:48:40 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/09 15:48:40 visual_prompt]: Loading training data...
[11/09 15:48:40 visual_prompt]: Constructing mammo-cbis dataset train...
[11/09 15:48:40 visual_prompt]: Loading validation data...
[11/09 15:48:40 visual_prompt]: Constructing mammo-cbis dataset val...
[11/09 15:48:40 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/09 15:48:42 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/09 15:48:42 visual_prompt]: tuned percent:0.536
[11/09 15:48:42 visual_prompt]: Device used for model: 0
[11/09 15:48:42 visual_prompt]: Setting up Evaluator...
[11/09 15:48:42 visual_prompt]: Setting up Trainer...
[11/09 15:48:42 visual_prompt]: 	Setting up the optimizer...
[11/09 15:48:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/09 15:55:06 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9478, average train loss: 1.4017
[11/09 15:55:50 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1552, average loss: 1.2969
[11/09 15:55:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/09 15:55:50 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/09 16:02:13 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9332, average train loss: 24.8288
[11/09 16:02:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1549, average loss: 2.4321
[11/09 16:02:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.44	
[11/09 16:02:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/09 16:09:19 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9397, average train loss: 7.2929
[11/09 16:10:03 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1548, average loss: 6.2044
[11/09 16:10:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/09 16:10:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/09 16:16:26 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9259, average train loss: 8.7177
[11/09 16:17:09 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1546, average loss: 17.2451
[11/09 16:17:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.74	
[11/09 16:17:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/09 16:23:32 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9238, average train loss: 11.6588
[11/09 16:24:15 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1567, average loss: 14.9135
[11/09 16:24:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.94	
[11/09 16:24:15 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/09 16:30:38 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9373, average train loss: 27.8789
[11/09 16:31:22 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1546, average loss: 7.9302
[11/09 16:31:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.43	
[11/09 16:31:22 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/09 16:37:45 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9384, average train loss: 35.2016
[11/09 16:38:28 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1551, average loss: 73.8037
[11/09 16:38:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.85	
[11/09 16:38:28 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/09 16:44:51 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9218, average train loss: 33.3791
[11/09 16:45:34 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1548, average loss: 12.5573
[11/09 16:45:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.67	
[11/09 16:45:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/09 16:51:57 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9430, average train loss: 25.4118
[11/09 16:52:41 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1546, average loss: 41.1000
[11/09 16:52:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.89	
[11/09 16:52:41 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/09 16:59:04 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9407, average train loss: 46.6766
[11/09 16:59:48 visual_prompt]: Inference (val):avg data time: 2.48e-05, avg batch time: 0.1548, average loss: 23.1010
[11/09 16:59:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.65	
[11/09 16:59:48 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/09 17:06:12 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9729, average train loss: 47.1053
[11/09 17:06:56 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1550, average loss: 35.3989
[11/09 17:06:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.17	
[11/09 17:06:56 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/09 17:13:18 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9143, average train loss: 63.8425
[11/09 17:14:02 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1555, average loss: 126.7082
[11/09 17:14:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.32	
[11/09 17:14:02 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/09 17:20:32 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1160, average train loss: 53.6279
[11/09 17:21:16 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1547, average loss: 56.6610
[11/09 17:21:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.42	
[11/09 17:21:16 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/09 17:27:42 visual_prompt]: Epoch 14 / 100: avg data time: 1.07e+01, avg batch time: 11.0361, average train loss: 56.2397
[11/09 17:28:27 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1572, average loss: 1.8293
[11/09 17:28:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.28	
[11/09 17:28:27 visual_prompt]: Best epoch 14: best metric: -1.829
[11/09 17:28:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/09 17:34:53 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.0288, average train loss: 61.9125
[11/09 17:35:37 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1546, average loss: 41.9314
[11/09 17:35:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/09 17:35:37 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/09 17:42:00 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9520, average train loss: 58.6238
[11/09 17:42:44 visual_prompt]: Inference (val):avg data time: 2.44e-05, avg batch time: 0.1545, average loss: 20.3802
[11/09 17:42:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.60	
[11/09 17:42:44 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/09 17:49:05 visual_prompt]: Epoch 17 / 100: avg data time: 1.05e+01, avg batch time: 10.8874, average train loss: 53.6322
[11/09 17:49:49 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1564, average loss: 58.1741
[11/09 17:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.32	
[11/09 17:49:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/09 17:56:14 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9983, average train loss: 54.9381
[11/09 17:56:58 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1548, average loss: 29.1895
[11/09 17:56:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.14	
[11/09 17:56:58 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/09 18:03:20 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9161, average train loss: 40.6116
[11/09 18:04:04 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1591, average loss: 31.7277
[11/09 18:04:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[11/09 18:04:04 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/09 18:10:27 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9395, average train loss: 41.6645
[11/09 18:11:10 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1549, average loss: 13.8676
[11/09 18:11:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.51	
[11/09 18:11:10 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/09 18:17:33 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9406, average train loss: 64.4864
[11/09 18:18:17 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1549, average loss: 28.7377
[11/09 18:18:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.94	
[11/09 18:18:17 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/09 18:24:38 visual_prompt]: Epoch 22 / 100: avg data time: 1.05e+01, avg batch time: 10.8739, average train loss: 42.9773
[11/09 18:25:21 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1547, average loss: 24.2554
[11/09 18:25:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.69	
[11/09 18:25:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/09 18:31:45 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9604, average train loss: 36.7695
[11/09 18:32:29 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1547, average loss: 5.4603
[11/09 18:32:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.99	
[11/09 18:32:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/09 18:38:54 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0048, average train loss: 58.9333
[11/09 18:39:39 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1563, average loss: 30.2819
[11/09 18:39:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.48	
[11/09 18:39:39 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/09 18:46:04 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0078, average train loss: 49.2231
[11/09 18:46:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1548, average loss: 38.7517
[11/09 18:46:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.95	
[11/09 18:46:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/09 18:53:13 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0113, average train loss: 63.0124
[11/09 18:53:57 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1549, average loss: 37.1460
[11/09 18:53:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.57	
[11/09 18:53:57 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/09 19:00:22 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9761, average train loss: 58.3166
[11/09 19:01:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1549, average loss: 129.7905
[11/09 19:01:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.46	
[11/09 19:01:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/09 19:07:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9858, average train loss: 49.5054
[11/09 19:08:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1545, average loss: 48.8785
[11/09 19:08:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.91	
[11/09 19:08:14 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/09 19:14:40 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0137, average train loss: 77.5008
[11/09 19:15:24 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1558, average loss: 28.4543
[11/09 19:15:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 44.92	
[11/09 19:15:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/09 19:21:51 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0619, average train loss: 69.1997
[11/09 19:22:35 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1548, average loss: 83.5536
[11/09 19:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.02	
[11/09 19:22:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/09 19:29:01 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0282, average train loss: 55.3907
[11/09 19:29:45 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1551, average loss: 29.0444
[11/09 19:29:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.63	
[11/09 19:29:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/09 19:36:09 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9664, average train loss: 39.6922
[11/09 19:36:53 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1547, average loss: 14.2282
[11/09 19:36:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.79	
[11/09 19:36:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/09 19:43:16 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9280, average train loss: 36.9566
[11/09 19:44:00 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1548, average loss: 28.0775
[11/09 19:44:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[11/09 19:44:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/09 19:50:23 visual_prompt]: Epoch 34 / 100: avg data time: 1.06e+01, avg batch time: 10.9538, average train loss: 44.3113
[11/09 19:51:07 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1549, average loss: 106.8938
[11/09 19:51:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.64	
[11/09 19:51:07 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/09 19:57:30 visual_prompt]: Epoch 35 / 100: avg data time: 1.06e+01, avg batch time: 10.9539, average train loss: 65.4070
[11/09 19:58:14 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1568, average loss: 59.5513
[11/09 19:58:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.14	
[11/09 19:58:14 visual_prompt]: Stopping early.
[11/09 19:58:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/09 19:58:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/09 19:58:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/09 19:58:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/09 19:58:14 visual_prompt]: Training with config:
[11/09 19:58:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/09 19:58:14 visual_prompt]: Loading training data...
[11/09 19:58:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/09 19:58:14 visual_prompt]: Loading validation data...
[11/09 19:58:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/09 19:58:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/09 19:58:17 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/09 19:58:17 visual_prompt]: tuned percent:0.536
[11/09 19:58:17 visual_prompt]: Device used for model: 0
[11/09 19:58:17 visual_prompt]: Setting up Evaluator...
[11/09 19:58:17 visual_prompt]: Setting up Trainer...
[11/09 19:58:17 visual_prompt]: 	Setting up the optimizer...
[11/09 19:58:17 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/09 20:04:41 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9584, average train loss: 1.4017
[11/09 20:05:24 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1583, average loss: 1.2969
[11/09 20:05:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/09 20:05:24 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/09 20:11:48 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9574, average train loss: 24.5553
[11/09 20:12:32 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1545, average loss: 8.8651
[11/09 20:12:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.91	
[11/09 20:12:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/09 20:18:56 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9670, average train loss: 8.0350
[11/09 20:19:40 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1557, average loss: 0.7456
[11/09 20:19:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.71	
[11/09 20:19:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/09 20:26:04 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9758, average train loss: 9.3909
[11/09 20:26:48 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1554, average loss: 0.7597
[11/09 20:26:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[11/09 20:26:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/09 20:33:11 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9422, average train loss: 27.1847
[11/09 20:33:55 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1550, average loss: 3.3412
[11/09 20:33:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.56	
[11/09 20:33:55 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/09 20:40:19 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9685, average train loss: 20.2154
[11/09 20:41:03 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1568, average loss: 1.4100
[11/09 20:41:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.93	
[11/09 20:41:03 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/09 20:47:27 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9773, average train loss: 8.7733
[11/09 20:48:11 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1571, average loss: 3.1323
[11/09 20:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.06	
[11/09 20:48:11 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/09 20:54:35 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9728, average train loss: 20.1753
[11/09 20:55:19 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1546, average loss: 7.5689
[11/09 20:55:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.59	
[11/09 20:55:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/09 21:01:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9842, average train loss: 48.7753
[11/09 21:02:27 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1546, average loss: 16.9321
[11/09 21:02:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.95	
[11/09 21:02:27 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/09 21:08:50 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9268, average train loss: 37.2875
[11/09 21:09:34 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1546, average loss: 78.6905
[11/09 21:09:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 38.75	
[11/09 21:09:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/09 21:15:58 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9716, average train loss: 41.0837
[11/09 21:16:41 visual_prompt]: Inference (val):avg data time: 2.32e-05, avg batch time: 0.1551, average loss: 105.0052
[11/09 21:16:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/09 21:16:42 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/09 21:23:05 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9534, average train loss: 42.5592
[11/09 21:23:49 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1579, average loss: 10.8496
[11/09 21:23:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.70	
[11/09 21:23:49 visual_prompt]: Best epoch 12: best metric: -10.850
[11/09 21:23:49 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/09 21:30:13 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9722, average train loss: 37.2229
[11/09 21:30:57 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1545, average loss: 166.4183
[11/09 21:30:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.52	
[11/09 21:30:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/09 21:37:21 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9696, average train loss: 102.9233
[11/09 21:38:05 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1583, average loss: 246.5512
[11/09 21:38:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.40	
[11/09 21:38:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/09 21:44:31 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.0268, average train loss: 65.3282
[11/09 21:45:15 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1547, average loss: 39.3691
[11/09 21:45:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.02	
[11/09 21:45:15 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/09 21:51:41 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0170, average train loss: 56.2067
[11/09 21:52:25 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1548, average loss: 12.3369
[11/09 21:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.25	
[11/09 21:52:25 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/09 21:58:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9831, average train loss: 67.2136
[11/09 21:59:34 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1575, average loss: 129.8758
[11/09 21:59:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.06	
[11/09 21:59:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/09 22:05:58 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9879, average train loss: 59.4263
[11/09 22:06:42 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1588, average loss: 64.5834
[11/09 22:06:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.64	
[11/09 22:06:42 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/09 22:13:04 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9173, average train loss: 65.2182
[11/09 22:13:48 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1546, average loss: 64.0788
[11/09 22:13:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.83	
[11/09 22:13:48 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/09 22:20:13 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9991, average train loss: 102.0278
[11/09 22:20:57 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1547, average loss: 15.7599
[11/09 22:20:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.08	
[11/09 22:20:57 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/09 22:27:21 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9721, average train loss: 35.9703
[11/09 22:28:06 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1549, average loss: 83.9424
[11/09 22:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.57	
[11/09 22:28:06 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/09 22:34:33 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.0495, average train loss: 44.9624
[11/09 22:35:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1564, average loss: 11.4956
[11/09 22:35:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.62	
[11/09 22:35:17 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/09 22:41:45 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0758, average train loss: 53.5935
[11/09 22:42:29 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1548, average loss: 72.5636
[11/09 22:42:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.25	
[11/09 22:42:29 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/09 22:49:03 visual_prompt]: Epoch 24 / 100: avg data time: 1.09e+01, avg batch time: 11.2695, average train loss: 30.1073
[11/09 22:49:47 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1550, average loss: 23.9097
[11/09 22:49:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.07	
[11/09 22:49:47 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/09 22:56:12 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9955, average train loss: 29.6700
[11/09 22:56:55 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1552, average loss: 20.4023
[11/09 22:56:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.54	
[11/09 22:56:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/09 23:03:20 visual_prompt]: Epoch 26 / 100: avg data time: 1.06e+01, avg batch time: 10.9803, average train loss: 21.8951
[11/09 23:04:03 visual_prompt]: Inference (val):avg data time: 2.40e-05, avg batch time: 0.1546, average loss: 19.7375
[11/09 23:04:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.90	
[11/09 23:04:03 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/09 23:10:28 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9756, average train loss: 58.7968
[11/09 23:11:12 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1549, average loss: 14.1617
[11/09 23:11:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[11/09 23:11:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/09 23:17:35 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9450, average train loss: 39.8915
[11/09 23:18:19 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1549, average loss: 5.2070
[11/09 23:18:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.31	
[11/09 23:18:19 visual_prompt]: Best epoch 28: best metric: -5.207
[11/09 23:18:19 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/09 23:24:43 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9819, average train loss: 35.1372
[11/09 23:25:27 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1582, average loss: 20.2286
[11/09 23:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.85	
[11/09 23:25:27 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/09 23:31:52 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9906, average train loss: 19.8444
[11/09 23:32:35 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1563, average loss: 17.1446
[11/09 23:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.44	
[11/09 23:32:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/09 23:38:59 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9518, average train loss: 62.6128
[11/09 23:39:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1550, average loss: 127.3864
[11/09 23:39:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.02	
[11/09 23:39:42 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/09 23:46:07 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9926, average train loss: 84.7154
[11/09 23:46:51 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1551, average loss: 61.0130
[11/09 23:46:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.91	
[11/09 23:46:51 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/09 23:53:15 visual_prompt]: Epoch 33 / 100: avg data time: 1.06e+01, avg batch time: 10.9593, average train loss: 29.3633
[11/09 23:53:59 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1560, average loss: 49.4699
[11/09 23:53:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.69	
[11/09 23:53:59 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/10 00:00:26 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0530, average train loss: 53.0499
[11/10 00:01:11 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1571, average loss: 8.5631
[11/10 00:01:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.79	
[11/10 00:01:11 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/10 00:07:37 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0349, average train loss: 38.4186
[11/10 00:08:21 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1551, average loss: 39.1408
[11/10 00:08:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.15	
[11/10 00:08:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/10 00:14:45 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9788, average train loss: 26.5217
[11/10 00:15:29 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1547, average loss: 31.3831
[11/10 00:15:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.22	
[11/10 00:15:29 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/10 00:21:51 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9126, average train loss: 36.9539
[11/10 00:22:35 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1545, average loss: 2.3713
[11/10 00:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.62	
[11/10 00:22:35 visual_prompt]: Best epoch 37: best metric: -2.371
[11/10 00:22:35 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/10 00:28:58 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9275, average train loss: 27.4193
[11/10 00:29:41 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1551, average loss: 10.7401
[11/10 00:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.38	
[11/10 00:29:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/10 00:36:04 visual_prompt]: Epoch 39 / 100: avg data time: 1.06e+01, avg batch time: 10.9249, average train loss: 25.0526
[11/10 00:36:48 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1545, average loss: 71.7595
[11/10 00:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.86	
[11/10 00:36:48 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/10 00:43:09 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.8916, average train loss: 31.6740
[11/10 00:43:52 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1581, average loss: 56.9948
[11/10 00:43:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.43	
[11/10 00:43:52 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/10 00:50:14 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 10.9091, average train loss: 17.0220
[11/10 00:50:58 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1548, average loss: 8.9631
[11/10 00:50:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.76	
[11/10 00:50:58 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/10 00:57:20 visual_prompt]: Epoch 42 / 100: avg data time: 1.05e+01, avg batch time: 10.9044, average train loss: 21.2450
[11/10 00:58:03 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1547, average loss: 8.6788
[11/10 00:58:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.67	
[11/10 00:58:03 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/10 01:04:25 visual_prompt]: Epoch 43 / 100: avg data time: 1.05e+01, avg batch time: 10.8961, average train loss: 20.1114
[11/10 01:05:08 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1559, average loss: 3.8184
[11/10 01:05:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.63	
[11/10 01:05:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/10 01:11:30 visual_prompt]: Epoch 44 / 100: avg data time: 1.06e+01, avg batch time: 10.9056, average train loss: 21.0826
[11/10 01:12:14 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1550, average loss: 4.0968
[11/10 01:12:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.24	
[11/10 01:12:14 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/10 01:18:38 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9696, average train loss: 17.9420
[11/10 01:19:22 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1570, average loss: 31.0907
[11/10 01:19:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.22	
[11/10 01:19:22 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/10 01:25:46 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 10.9612, average train loss: 24.8721
[11/10 01:26:29 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1545, average loss: 1.1532
[11/10 01:26:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.00	
[11/10 01:26:29 visual_prompt]: Best epoch 46: best metric: -1.153
[11/10 01:26:29 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/10 01:32:53 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 10.9622, average train loss: 10.2620
[11/10 01:33:37 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1585, average loss: 68.9735
[11/10 01:33:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.20	
[11/10 01:33:37 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/10 01:40:03 visual_prompt]: Epoch 48 / 100: avg data time: 1.07e+01, avg batch time: 11.0240, average train loss: 19.5457
[11/10 01:40:47 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1565, average loss: 4.7089
[11/10 01:40:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.58	
[11/10 01:40:47 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/10 01:47:13 visual_prompt]: Epoch 49 / 100: avg data time: 1.07e+01, avg batch time: 11.0238, average train loss: 20.8843
[11/10 01:47:57 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1548, average loss: 26.2734
[11/10 01:47:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.40	
[11/10 01:47:57 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/10 01:54:23 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e+01, avg batch time: 11.0245, average train loss: 14.2765
[11/10 01:55:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1564, average loss: 8.1369
[11/10 01:55:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.09	
[11/10 01:55:07 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/10 02:01:33 visual_prompt]: Epoch 51 / 100: avg data time: 1.07e+01, avg batch time: 11.0269, average train loss: 15.6023
[11/10 02:02:18 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1550, average loss: 22.7864
[11/10 02:02:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.17	
[11/10 02:02:18 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/10 02:08:44 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0317, average train loss: 29.3428
[11/10 02:09:28 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1548, average loss: 8.8954
[11/10 02:09:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.02	
[11/10 02:09:28 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[11/10 02:15:54 visual_prompt]: Epoch 53 / 100: avg data time: 1.07e+01, avg batch time: 11.0317, average train loss: 19.4196
[11/10 02:16:38 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1551, average loss: 5.5785
[11/10 02:16:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.28	
[11/10 02:16:38 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[11/10 02:23:04 visual_prompt]: Epoch 54 / 100: avg data time: 1.07e+01, avg batch time: 11.0193, average train loss: 18.6025
[11/10 02:23:48 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1549, average loss: 16.9389
[11/10 02:23:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.42	
[11/10 02:23:48 visual_prompt]: Training 55 / 100 epoch, with learning rate 12.936243708781264
[11/10 02:30:14 visual_prompt]: Epoch 55 / 100: avg data time: 1.07e+01, avg batch time: 11.0103, average train loss: 19.2371
[11/10 02:30:58 visual_prompt]: Inference (val):avg data time: 2.39e-05, avg batch time: 0.1569, average loss: 9.1722
[11/10 02:30:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.20	
[11/10 02:30:58 visual_prompt]: Training 56 / 100 epoch, with learning rate 12.5
[11/10 02:37:23 visual_prompt]: Epoch 56 / 100: avg data time: 1.07e+01, avg batch time: 11.0045, average train loss: 14.7325
[11/10 02:38:07 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1564, average loss: 11.5116
[11/10 02:38:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.21	
[11/10 02:38:07 visual_prompt]: Training 57 / 100 epoch, with learning rate 12.063756291218741
[11/10 02:44:33 visual_prompt]: Epoch 57 / 100: avg data time: 1.07e+01, avg batch time: 11.0196, average train loss: 17.3763
[11/10 02:45:17 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1545, average loss: 12.3095
[11/10 02:45:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.16	
[11/10 02:45:17 visual_prompt]: Training 58 / 100 epoch, with learning rate 11.628044078198434
[11/10 02:51:42 visual_prompt]: Epoch 58 / 100: avg data time: 1.06e+01, avg batch time: 11.0023, average train loss: 15.2502
[11/10 02:52:26 visual_prompt]: Inference (val):avg data time: 2.67e-05, avg batch time: 0.1562, average loss: 2.1843
[11/10 02:52:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.55	
[11/10 02:52:26 visual_prompt]: Training 59 / 100 epoch, with learning rate 11.193394209154334
[11/10 02:58:52 visual_prompt]: Epoch 59 / 100: avg data time: 1.06e+01, avg batch time: 11.0065, average train loss: 7.9608
[11/10 02:59:36 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 19.0384
[11/10 02:59:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.12	
[11/10 02:59:36 visual_prompt]: Training 60 / 100 epoch, with learning rate 10.760336237999185
[11/10 03:06:02 visual_prompt]: Epoch 60 / 100: avg data time: 1.07e+01, avg batch time: 11.0216, average train loss: 13.3884
[11/10 03:06:46 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1545, average loss: 9.6614
[11/10 03:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.95	
[11/10 03:06:46 visual_prompt]: Training 61 / 100 epoch, with learning rate 10.32939777916337
[11/10 03:13:11 visual_prompt]: Epoch 61 / 100: avg data time: 1.06e+01, avg batch time: 11.0006, average train loss: 15.6140
[11/10 03:13:55 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1549, average loss: 6.0267
[11/10 03:13:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.46	
[11/10 03:13:55 visual_prompt]: Training 62 / 100 epoch, with learning rate 9.90110386477801
[11/10 03:20:19 visual_prompt]: Epoch 62 / 100: avg data time: 1.06e+01, avg batch time: 10.9847, average train loss: 8.6084
[11/10 03:21:04 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1546, average loss: 7.4310
[11/10 03:21:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.93	
[11/10 03:21:04 visual_prompt]: Training 63 / 100 epoch, with learning rate 9.475976305004155
[11/10 03:27:28 visual_prompt]: Epoch 63 / 100: avg data time: 1.06e+01, avg batch time: 10.9896, average train loss: 7.8559
[11/10 03:28:12 visual_prompt]: Inference (val):avg data time: 2.51e-05, avg batch time: 0.1545, average loss: 12.1843
[11/10 03:28:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.10	
[11/10 03:28:12 visual_prompt]: Training 64 / 100 epoch, with learning rate 9.05453305228751
[11/10 03:34:37 visual_prompt]: Epoch 64 / 100: avg data time: 1.06e+01, avg batch time: 10.9942, average train loss: 9.5495
[11/10 03:35:21 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1545, average loss: 9.0359
[11/10 03:35:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.65	
[11/10 03:35:21 visual_prompt]: Training 65 / 100 epoch, with learning rate 8.637287570313159
[11/10 03:41:48 visual_prompt]: Epoch 65 / 100: avg data time: 1.07e+01, avg batch time: 11.0379, average train loss: 6.6576
[11/10 03:42:32 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1549, average loss: 2.8068
[11/10 03:42:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.66	
[11/10 03:42:32 visual_prompt]: Training 66 / 100 epoch, with learning rate 8.224748208429142
[11/10 03:48:59 visual_prompt]: Epoch 66 / 100: avg data time: 1.07e+01, avg batch time: 11.0583, average train loss: 6.8719
[11/10 03:49:43 visual_prompt]: Inference (val):avg data time: 2.35e-05, avg batch time: 0.1568, average loss: 3.1889
[11/10 03:49:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.56	
[11/10 03:49:43 visual_prompt]: Training 67 / 100 epoch, with learning rate 7.817417582301099
[11/10 03:56:06 visual_prompt]: Epoch 67 / 100: avg data time: 1.06e+01, avg batch time: 10.9536, average train loss: 6.0179
[11/10 03:56:49 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1545, average loss: 3.2838
[11/10 03:56:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.18	
[11/10 03:56:49 visual_prompt]: Stopping early.
[11/10 03:56:49 visual_prompt]: Rank of current process: 0. World size: 1
[11/10 03:56:49 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 03:56:49 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/10 03:56:49 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/10 03:56:49 visual_prompt]: Training with config:
[11/10 03:56:49 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr25.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 25.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/10 03:56:49 visual_prompt]: Loading training data...
[11/10 03:56:49 visual_prompt]: Constructing mammo-cbis dataset train...
[11/10 03:56:49 visual_prompt]: Loading validation data...
[11/10 03:56:49 visual_prompt]: Constructing mammo-cbis dataset val...
[11/10 03:56:49 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/10 03:56:52 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/10 03:56:52 visual_prompt]: tuned percent:0.536
[11/10 03:56:52 visual_prompt]: Device used for model: 0
[11/10 03:56:52 visual_prompt]: Setting up Evaluator...
[11/10 03:56:52 visual_prompt]: Setting up Trainer...
[11/10 03:56:52 visual_prompt]: 	Setting up the optimizer...
[11/10 03:56:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/10 04:03:18 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0260, average train loss: 1.4017
[11/10 04:04:02 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1553, average loss: 1.2969
[11/10 04:04:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/10 04:04:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 2.5
[11/10 04:10:26 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9789, average train loss: 25.1135
[11/10 04:11:09 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1548, average loss: 2.0770
[11/10 04:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.43	
[11/10 04:11:09 visual_prompt]: Training 3 / 100 epoch, with learning rate 5.0
[11/10 04:17:32 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9204, average train loss: 5.8461
[11/10 04:18:15 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1565, average loss: 0.8126
[11/10 04:18:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 53.03	
[11/10 04:18:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 7.5
[11/10 04:24:39 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9520, average train loss: 8.5846
[11/10 04:25:22 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1548, average loss: 6.9338
[11/10 04:25:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.46	
[11/10 04:25:22 visual_prompt]: Training 5 / 100 epoch, with learning rate 10.0
[11/10 04:31:44 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9143, average train loss: 33.7006
[11/10 04:32:27 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1544, average loss: 17.0240
[11/10 04:32:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/10 04:32:27 visual_prompt]: Training 6 / 100 epoch, with learning rate 12.5
[11/10 04:38:50 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9404, average train loss: 20.2576
[11/10 04:39:34 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1571, average loss: 26.2030
[11/10 04:39:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.29	
[11/10 04:39:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 15.0
[11/10 04:45:57 visual_prompt]: Epoch 7 / 100: avg data time: 1.06e+01, avg batch time: 10.9264, average train loss: 39.1594
[11/10 04:46:40 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1572, average loss: 39.5488
[11/10 04:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.50	
[11/10 04:46:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 17.5
[11/10 04:53:02 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9071, average train loss: 16.1101
[11/10 04:53:45 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1546, average loss: 7.4987
[11/10 04:53:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.72	
[11/10 04:53:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 20.0
[11/10 05:00:07 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9018, average train loss: 14.4558
[11/10 05:00:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1544, average loss: 22.4585
[11/10 05:00:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.93	
[11/10 05:00:51 visual_prompt]: Training 10 / 100 epoch, with learning rate 22.5
[11/10 05:07:14 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9447, average train loss: 12.4430
[11/10 05:07:58 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1545, average loss: 26.0708
[11/10 05:07:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.19	
[11/10 05:07:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 25.0
[11/10 05:14:21 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9552, average train loss: 64.4758
[11/10 05:15:05 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1554, average loss: 82.2012
[11/10 05:15:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.60	
[11/10 05:15:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 24.9923853377387
[11/10 05:21:29 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9626, average train loss: 47.2654
[11/10 05:22:13 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1548, average loss: 8.8583
[11/10 05:22:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.29	
[11/10 05:22:13 visual_prompt]: Best epoch 12: best metric: -8.858
[11/10 05:22:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 24.969550628247802
[11/10 05:28:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.06e+01, avg batch time: 10.9470, average train loss: 20.9574
[11/10 05:29:20 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1549, average loss: 9.9548
[11/10 05:29:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.13	
[11/10 05:29:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 24.931523692103415
[11/10 05:35:43 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9514, average train loss: 21.7312
[11/10 05:36:27 visual_prompt]: Inference (val):avg data time: 2.45e-05, avg batch time: 0.1590, average loss: 31.0348
[11/10 05:36:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.95	
[11/10 05:36:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 24.87835085926963
[11/10 05:42:51 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9592, average train loss: 20.2959
[11/10 05:43:35 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1549, average loss: 9.5821
[11/10 05:43:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.06	
[11/10 05:43:35 visual_prompt]: Training 16 / 100 epoch, with learning rate 24.8100969126526
[11/10 05:49:58 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9588, average train loss: 26.0469
[11/10 05:50:42 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1549, average loss: 2.4154
[11/10 05:50:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.84	
[11/10 05:50:42 visual_prompt]: Best epoch 16: best metric: -2.415
[11/10 05:50:42 visual_prompt]: Training 17 / 100 epoch, with learning rate 24.72684500917257
[11/10 05:57:05 visual_prompt]: Epoch 17 / 100: avg data time: 1.06e+01, avg batch time: 10.9451, average train loss: 14.7281
[11/10 05:57:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1561, average loss: 16.4192
[11/10 05:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.75	
[11/10 05:57:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 24.628696578449954
[11/10 06:04:13 visual_prompt]: Epoch 18 / 100: avg data time: 1.06e+01, avg batch time: 10.9607, average train loss: 28.4965
[11/10 06:04:57 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1547, average loss: 3.2744
[11/10 06:04:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.05	
[11/10 06:04:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 24.515771199228986
[11/10 06:11:23 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0216, average train loss: 11.5865
[11/10 06:12:07 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1580, average loss: 19.1156
[11/10 06:12:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.21	
[11/10 06:12:07 visual_prompt]: Training 20 / 100 epoch, with learning rate 24.38820645368942
[11/10 06:18:32 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 11.0005, average train loss: 19.0805
[11/10 06:19:16 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1551, average loss: 62.0658
[11/10 06:19:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.25	
[11/10 06:19:16 visual_prompt]: Training 21 / 100 epoch, with learning rate 24.246157759823856
[11/10 06:25:38 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9146, average train loss: 55.4854
[11/10 06:26:22 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1551, average loss: 36.8634
[11/10 06:26:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.60	
[11/10 06:26:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 24.08979818208484
[11/10 06:32:45 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9474, average train loss: 13.7307
[11/10 06:33:28 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1554, average loss: 22.3492
[11/10 06:33:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.46	
[11/10 06:33:28 visual_prompt]: Training 23 / 100 epoch, with learning rate 23.91931822053251
[11/10 06:39:53 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9781, average train loss: 18.4936
[11/10 06:40:37 visual_prompt]: Inference (val):avg data time: 2.56e-05, avg batch time: 0.1554, average loss: 4.2544
[11/10 06:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[11/10 06:40:37 visual_prompt]: Training 24 / 100 epoch, with learning rate 23.73492557873959
[11/10 06:47:02 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9945, average train loss: 32.5384
[11/10 06:47:46 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1550, average loss: 58.2132
[11/10 06:47:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.71	
[11/10 06:47:46 visual_prompt]: Training 25 / 100 epoch, with learning rate 23.536844910736587
[11/10 06:54:12 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0220, average train loss: 28.6706
[11/10 06:54:56 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1550, average loss: 10.7788
[11/10 06:54:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.42	
[11/10 06:54:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 23.325317547305485
[11/10 07:01:22 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0245, average train loss: 19.7969
[11/10 07:02:06 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1550, average loss: 4.3369
[11/10 07:02:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.51	
[11/10 07:02:06 visual_prompt]: Training 27 / 100 epoch, with learning rate 23.100601201955325
[11/10 07:08:29 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9358, average train loss: 18.2679
[11/10 07:09:13 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1548, average loss: 17.1200
[11/10 07:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.20	
[11/10 07:09:13 visual_prompt]: Training 28 / 100 epoch, with learning rate 22.86296965693802
[11/10 07:15:37 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9625, average train loss: 14.9549
[11/10 07:16:21 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1555, average loss: 11.9040
[11/10 07:16:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.47	
[11/10 07:16:21 visual_prompt]: Training 29 / 100 epoch, with learning rate 22.612712429686844
[11/10 07:22:47 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0417, average train loss: 9.3322
[11/10 07:23:32 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1549, average loss: 1.2294
[11/10 07:23:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 56.09	
[11/10 07:23:32 visual_prompt]: Best epoch 29: best metric: -1.229
[11/10 07:23:32 visual_prompt]: Training 30 / 100 epoch, with learning rate 22.35013442008402
[11/10 07:29:58 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0245, average train loss: 13.3013
[11/10 07:30:42 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1549, average loss: 54.8429
[11/10 07:30:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[11/10 07:30:42 visual_prompt]: Training 31 / 100 epoch, with learning rate 22.075555538987224
[11/10 07:37:07 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0177, average train loss: 24.8816
[11/10 07:37:51 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1548, average loss: 5.6384
[11/10 07:37:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.86	
[11/10 07:37:51 visual_prompt]: Training 32 / 100 epoch, with learning rate 21.78931031846743
[11/10 07:44:18 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0426, average train loss: 10.7191
[11/10 07:45:02 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1549, average loss: 19.4790
[11/10 07:45:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.55	
[11/10 07:45:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 21.49174750423314
[11/10 07:51:28 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0211, average train loss: 12.5621
[11/10 07:52:12 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1549, average loss: 0.9083
[11/10 07:52:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 56.96	
[11/10 07:52:12 visual_prompt]: Best epoch 33: best metric: -0.908
[11/10 07:52:12 visual_prompt]: Training 34 / 100 epoch, with learning rate 21.183229630737465
[11/10 07:58:38 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0093, average train loss: 7.2414
[11/10 07:59:22 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1561, average loss: 8.6421
[11/10 07:59:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.35	
[11/10 07:59:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 20.864132579485727
[11/10 08:05:49 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0526, average train loss: 5.0640
[11/10 08:06:33 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1550, average loss: 1.4873
[11/10 08:06:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 57.44	
[11/10 08:06:33 visual_prompt]: Training 36 / 100 epoch, with learning rate 20.53484512108174
[11/10 08:12:57 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9915, average train loss: 14.1968
[11/10 08:13:41 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1581, average loss: 4.7645
[11/10 08:13:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[11/10 08:13:41 visual_prompt]: Training 37 / 100 epoch, with learning rate 20.195768441570728
[11/10 08:20:06 visual_prompt]: Epoch 37 / 100: avg data time: 1.06e+01, avg batch time: 10.9794, average train loss: 8.7651
[11/10 08:20:50 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1570, average loss: 8.2056
[11/10 08:20:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.61	
[11/10 08:20:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 19.847315653655915
[11/10 08:27:14 visual_prompt]: Epoch 38 / 100: avg data time: 1.06e+01, avg batch time: 10.9830, average train loss: 9.2888
[11/10 08:27:59 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1549, average loss: 14.1239
[11/10 08:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.36	
[11/10 08:27:59 visual_prompt]: Training 39 / 100 epoch, with learning rate 19.489911293384335
[11/10 08:34:27 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.1011, average train loss: 18.0899
[11/10 08:35:12 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1550, average loss: 22.9225
[11/10 08:35:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.28	
[11/10 08:35:12 visual_prompt]: Training 40 / 100 epoch, with learning rate 19.12399080291506
[11/10 08:41:41 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e+01, avg batch time: 11.1127, average train loss: 27.1026
[11/10 08:42:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1571, average loss: 18.2548
[11/10 08:42:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.14	
[11/10 08:42:25 visual_prompt]: Training 41 / 100 epoch, with learning rate 18.75
[11/10 08:48:54 visual_prompt]: Epoch 41 / 100: avg data time: 1.07e+01, avg batch time: 11.1021, average train loss: 19.8291
[11/10 08:49:38 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1580, average loss: 8.6998
[11/10 08:49:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.16	
[11/10 08:49:38 visual_prompt]: Training 42 / 100 epoch, with learning rate 18.368394534823633
[11/10 08:56:06 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e+01, avg batch time: 11.0789, average train loss: 12.1576
[11/10 08:56:50 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1551, average loss: 8.0254
[11/10 08:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.63	
[11/10 08:56:50 visual_prompt]: Training 43 / 100 epoch, with learning rate 17.979639334863467
[11/10 09:03:16 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 11.0045, average train loss: 9.6592
[11/10 09:04:00 visual_prompt]: Inference (val):avg data time: 2.58e-05, avg batch time: 0.1547, average loss: 20.0576
[11/10 09:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.66	
[11/10 09:04:00 visual_prompt]: Training 44 / 100 epoch, with learning rate 17.584208038447503
[11/10 09:10:26 visual_prompt]: Epoch 44 / 100: avg data time: 1.07e+01, avg batch time: 11.0206, average train loss: 24.0038
[11/10 09:11:10 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1564, average loss: 23.3357
[11/10 09:11:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.71	
[11/10 09:11:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 17.182582417698903
[11/10 09:17:33 visual_prompt]: Epoch 45 / 100: avg data time: 1.06e+01, avg batch time: 10.9518, average train loss: 18.6006
[11/10 09:18:17 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1550, average loss: 32.9172
[11/10 09:18:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[11/10 09:18:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 16.77525179157086
[11/10 09:24:40 visual_prompt]: Epoch 46 / 100: avg data time: 1.06e+01, avg batch time: 10.9363, average train loss: 13.8948
[11/10 09:25:23 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1550, average loss: 15.0371
[11/10 09:25:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.06	
[11/10 09:25:23 visual_prompt]: Training 47 / 100 epoch, with learning rate 16.362712429686844
[11/10 09:31:46 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 10.9203, average train loss: 11.0886
[11/10 09:32:30 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1551, average loss: 13.5218
[11/10 09:32:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.38	
[11/10 09:32:30 visual_prompt]: Training 48 / 100 epoch, with learning rate 15.94546694771249
[11/10 09:38:53 visual_prompt]: Epoch 48 / 100: avg data time: 1.06e+01, avg batch time: 10.9529, average train loss: 6.7242
[11/10 09:39:37 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1574, average loss: 1.2022
[11/10 09:39:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 57.20	
[11/10 09:39:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 15.524023694995845
[11/10 09:46:00 visual_prompt]: Epoch 49 / 100: avg data time: 1.06e+01, avg batch time: 10.9459, average train loss: 7.1335
[11/10 09:46:44 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1594, average loss: 7.6516
[11/10 09:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.45	
[11/10 09:46:44 visual_prompt]: Training 50 / 100 epoch, with learning rate 15.09889613522199
[11/10 09:53:07 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e+01, avg batch time: 10.9416, average train loss: 10.7263
[11/10 09:53:51 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 17.9064
[11/10 09:53:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.34	
[11/10 09:53:51 visual_prompt]: Training 51 / 100 epoch, with learning rate 14.670602220836631
[11/10 10:00:14 visual_prompt]: Epoch 51 / 100: avg data time: 1.06e+01, avg batch time: 10.9397, average train loss: 9.8771
[11/10 10:00:57 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1563, average loss: 14.0649
[11/10 10:00:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.14	
[11/10 10:00:57 visual_prompt]: Training 52 / 100 epoch, with learning rate 14.239663762000818
[11/10 10:07:20 visual_prompt]: Epoch 52 / 100: avg data time: 1.06e+01, avg batch time: 10.9308, average train loss: 17.7662
[11/10 10:08:04 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1552, average loss: 11.7008
[11/10 10:08:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[11/10 10:08:04 visual_prompt]: Training 53 / 100 epoch, with learning rate 13.80660579084567
[11/10 10:14:27 visual_prompt]: Epoch 53 / 100: avg data time: 1.06e+01, avg batch time: 10.9483, average train loss: 5.6161
[11/10 10:15:11 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1549, average loss: 9.5194
[11/10 10:15:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.29	
[11/10 10:15:11 visual_prompt]: Training 54 / 100 epoch, with learning rate 13.371955921801565
[11/10 10:21:33 visual_prompt]: Epoch 54 / 100: avg data time: 1.05e+01, avg batch time: 10.9030, average train loss: 11.2405
[11/10 10:22:17 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1548, average loss: 2.8846
[11/10 10:22:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 57.87	
[11/10 10:22:17 visual_prompt]: Stopping early.
[11/10 10:22:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/10 10:22:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 10:22:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/10 10:22:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/10 10:22:17 visual_prompt]: Training with config:
[11/10 10:22:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/10 10:22:17 visual_prompt]: Loading training data...
[11/10 10:22:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/10 10:22:17 visual_prompt]: Loading validation data...
[11/10 10:22:17 visual_prompt]: Constructing mammo-cbis dataset val...
[11/10 10:22:17 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/10 10:22:19 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/10 10:22:19 visual_prompt]: tuned percent:0.536
[11/10 10:22:19 visual_prompt]: Device used for model: 0
[11/10 10:22:19 visual_prompt]: Setting up Evaluator...
[11/10 10:22:19 visual_prompt]: Setting up Trainer...
[11/10 10:22:19 visual_prompt]: 	Setting up the optimizer...
[11/10 10:22:19 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/10 10:28:42 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9366, average train loss: 1.4017
[11/10 10:29:26 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1548, average loss: 1.2969
[11/10 10:29:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/10 10:29:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/10 10:35:48 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8992, average train loss: 8.9951
[11/10 10:36:31 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1588, average loss: 2.1304
[11/10 10:36:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.63	
[11/10 10:36:31 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/10 10:42:57 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.0232, average train loss: 2.8160
[11/10 10:43:42 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1570, average loss: 2.6874
[11/10 10:43:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.06	
[11/10 10:43:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/10 10:50:07 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0203, average train loss: 4.5749
[11/10 10:50:51 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1549, average loss: 8.3327
[11/10 10:50:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/10 10:50:51 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/10 10:57:15 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9509, average train loss: 8.0197
[11/10 10:57:59 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1568, average loss: 1.9192
[11/10 10:57:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.87	
[11/10 10:57:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/10 11:04:22 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9599, average train loss: 10.5793
[11/10 11:05:06 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1563, average loss: 7.4902
[11/10 11:05:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.26	
[11/10 11:05:06 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/10 11:11:32 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0146, average train loss: 15.7977
[11/10 11:12:16 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1545, average loss: 5.8549
[11/10 11:12:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.70	
[11/10 11:12:16 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/10 11:18:43 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.0474, average train loss: 10.1090
[11/10 11:19:27 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1558, average loss: 0.8975
[11/10 11:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.06	
[11/10 11:19:27 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/10 11:25:51 visual_prompt]: Epoch 9 / 100: avg data time: 1.06e+01, avg batch time: 10.9557, average train loss: 15.7293
[11/10 11:26:34 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1541, average loss: 13.2975
[11/10 11:26:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.44	
[11/10 11:26:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/10 11:32:59 visual_prompt]: Epoch 10 / 100: avg data time: 1.06e+01, avg batch time: 10.9748, average train loss: 21.5171
[11/10 11:33:41 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1574, average loss: 1.9822
[11/10 11:33:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/10 11:33:41 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/10 11:40:03 visual_prompt]: Epoch 11 / 100: avg data time: 1.06e+01, avg batch time: 10.9110, average train loss: 19.0509
[11/10 11:40:47 visual_prompt]: Inference (val):avg data time: 2.34e-05, avg batch time: 0.1549, average loss: 4.3224
[11/10 11:40:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.27	
[11/10 11:40:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/10 11:47:10 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9371, average train loss: 28.0083
[11/10 11:47:54 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1547, average loss: 22.5628
[11/10 11:47:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.17	
[11/10 11:47:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/10 11:54:15 visual_prompt]: Epoch 13 / 100: avg data time: 1.05e+01, avg batch time: 10.8921, average train loss: 24.5884
[11/10 11:54:59 visual_prompt]: Inference (val):avg data time: 2.41e-05, avg batch time: 0.1548, average loss: 18.4375
[11/10 11:54:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.49	
[11/10 11:54:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/10 12:01:21 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9057, average train loss: 14.8870
[11/10 12:02:05 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1549, average loss: 5.2757
[11/10 12:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.51	
[11/10 12:02:05 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/10 12:08:29 visual_prompt]: Epoch 15 / 100: avg data time: 1.06e+01, avg batch time: 10.9830, average train loss: 21.5277
[11/10 12:09:13 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1546, average loss: 21.8561
[11/10 12:09:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.66	
[11/10 12:09:13 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/10 12:15:39 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0277, average train loss: 21.7384
[11/10 12:16:24 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1572, average loss: 24.6512
[11/10 12:16:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/10 12:16:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/10 12:22:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0254, average train loss: 23.5457
[11/10 12:23:34 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1548, average loss: 52.6756
[11/10 12:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.22	
[11/10 12:23:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/10 12:30:00 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0312, average train loss: 29.2653
[11/10 12:30:44 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1573, average loss: 34.3844
[11/10 12:30:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.41	
[11/10 12:30:44 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/10 12:37:10 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0205, average train loss: 22.8053
[11/10 12:37:54 visual_prompt]: Inference (val):avg data time: 2.47e-05, avg batch time: 0.1546, average loss: 19.4091
[11/10 12:37:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.54	
[11/10 12:37:54 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/10 12:44:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.0234, average train loss: 24.3154
[11/10 12:45:04 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1550, average loss: 78.7616
[11/10 12:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.67	
[11/10 12:45:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/10 12:51:31 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0476, average train loss: 26.3302
[11/10 12:52:15 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1546, average loss: 9.3504
[11/10 12:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.86	
[11/10 12:52:15 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/10 12:58:39 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9560, average train loss: 24.4799
[11/10 12:59:22 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1547, average loss: 14.4221
[11/10 12:59:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.08	
[11/10 12:59:22 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/10 13:05:46 visual_prompt]: Epoch 23 / 100: avg data time: 1.06e+01, avg batch time: 10.9475, average train loss: 17.3368
[11/10 13:06:30 visual_prompt]: Inference (val):avg data time: 2.73e-05, avg batch time: 0.1545, average loss: 43.7636
[11/10 13:06:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.32	
[11/10 13:06:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/10 13:12:55 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0194, average train loss: 21.2936
[11/10 13:13:39 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1574, average loss: 15.6877
[11/10 13:13:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.50	
[11/10 13:13:39 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/10 13:20:03 visual_prompt]: Epoch 25 / 100: avg data time: 1.06e+01, avg batch time: 10.9553, average train loss: 26.3807
[11/10 13:20:47 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1549, average loss: 24.7312
[11/10 13:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.06	
[11/10 13:20:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/10 13:27:15 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.1018, average train loss: 24.8728
[11/10 13:27:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1550, average loss: 34.1030
[11/10 13:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.11	
[11/10 13:27:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/10 13:34:22 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9358, average train loss: 21.2279
[11/10 13:35:06 visual_prompt]: Inference (val):avg data time: 2.72e-05, avg batch time: 0.1547, average loss: 14.3399
[11/10 13:35:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.24	
[11/10 13:35:06 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/10 13:41:28 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9156, average train loss: 18.8490
[11/10 13:42:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1546, average loss: 22.9709
[11/10 13:42:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.17	
[11/10 13:42:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/10 13:48:36 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9705, average train loss: 25.5379
[11/10 13:49:20 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1559, average loss: 9.9906
[11/10 13:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 39.89	
[11/10 13:49:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/10 13:55:45 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9984, average train loss: 18.0275
[11/10 13:56:29 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1551, average loss: 27.5852
[11/10 13:56:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.79	
[11/10 13:56:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/10 14:02:55 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0297, average train loss: 18.4673
[11/10 14:03:39 visual_prompt]: Inference (val):avg data time: 2.53e-05, avg batch time: 0.1547, average loss: 12.4440
[11/10 14:03:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.92	
[11/10 14:03:39 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/10 14:10:02 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9539, average train loss: 19.7019
[11/10 14:10:46 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1547, average loss: 15.7515
[11/10 14:10:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.73	
[11/10 14:10:46 visual_prompt]: Stopping early.
[11/10 14:10:46 visual_prompt]: Rank of current process: 0. World size: 1
[11/10 14:10:46 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 14:10:46 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/10 14:10:46 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/10 14:10:46 visual_prompt]: Training with config:
[11/10 14:10:46 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/10 14:10:46 visual_prompt]: Loading training data...
[11/10 14:10:46 visual_prompt]: Constructing mammo-cbis dataset train...
[11/10 14:10:46 visual_prompt]: Loading validation data...
[11/10 14:10:46 visual_prompt]: Constructing mammo-cbis dataset val...
[11/10 14:10:46 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/10 14:10:49 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/10 14:10:49 visual_prompt]: tuned percent:0.536
[11/10 14:10:49 visual_prompt]: Device used for model: 0
[11/10 14:10:49 visual_prompt]: Setting up Evaluator...
[11/10 14:10:49 visual_prompt]: Setting up Trainer...
[11/10 14:10:49 visual_prompt]: 	Setting up the optimizer...
[11/10 14:10:49 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/10 14:17:12 visual_prompt]: Epoch 1 / 100: avg data time: 1.06e+01, avg batch time: 10.9305, average train loss: 1.4017
[11/10 14:17:56 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1553, average loss: 1.2969
[11/10 14:17:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/10 14:17:56 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/10 14:24:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9645, average train loss: 10.4317
[11/10 14:25:03 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1545, average loss: 2.4653
[11/10 14:25:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.96	
[11/10 14:25:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/10 14:31:33 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1362, average train loss: 2.4359
[11/10 14:32:17 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1547, average loss: 2.0612
[11/10 14:32:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.71	
[11/10 14:32:17 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/10 14:38:41 visual_prompt]: Epoch 4 / 100: avg data time: 1.06e+01, avg batch time: 10.9794, average train loss: 3.2391
[11/10 14:39:25 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1589, average loss: 4.3621
[11/10 14:39:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.53	
[11/10 14:39:25 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/10 14:45:48 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9377, average train loss: 5.8642
[11/10 14:46:32 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1574, average loss: 8.3780
[11/10 14:46:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.63	
[11/10 14:46:32 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/10 14:53:48 visual_prompt]: Epoch 6 / 100: avg data time: 1.21e+01, avg batch time: 12.4500, average train loss: 13.1138
[11/10 14:54:34 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1551, average loss: 16.5069
[11/10 14:54:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.03	
[11/10 14:54:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/10 15:01:17 visual_prompt]: Epoch 7 / 100: avg data time: 1.11e+01, avg batch time: 11.5025, average train loss: 12.8504
[11/10 15:02:03 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1563, average loss: 11.6823
[11/10 15:02:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.76	
[11/10 15:02:03 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/10 15:08:45 visual_prompt]: Epoch 8 / 100: avg data time: 1.11e+01, avg batch time: 11.4799, average train loss: 12.0912
[11/10 15:09:31 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1550, average loss: 16.9862
[11/10 15:09:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.79	
[11/10 15:09:31 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/10 15:16:14 visual_prompt]: Epoch 9 / 100: avg data time: 1.12e+01, avg batch time: 11.5125, average train loss: 8.4848
[11/10 15:17:00 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 5.3961
[11/10 15:17:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.19	
[11/10 15:17:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/10 15:23:42 visual_prompt]: Epoch 10 / 100: avg data time: 1.11e+01, avg batch time: 11.4860, average train loss: 11.0905
[11/10 15:24:28 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1550, average loss: 17.7035
[11/10 15:24:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.49	
[11/10 15:24:28 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/10 15:31:10 visual_prompt]: Epoch 11 / 100: avg data time: 1.11e+01, avg batch time: 11.4870, average train loss: 14.7811
[11/10 15:31:56 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1559, average loss: 6.9861
[11/10 15:31:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.78	
[11/10 15:31:56 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/10 15:38:29 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2236, average train loss: 21.3058
[11/10 15:39:13 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1567, average loss: 36.9276
[11/10 15:39:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.34	
[11/10 15:39:13 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/10 15:46:07 visual_prompt]: Epoch 13 / 100: avg data time: 1.15e+01, avg batch time: 11.8214, average train loss: 15.8511
[11/10 15:46:53 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1552, average loss: 16.0947
[11/10 15:46:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.72	
[11/10 15:46:53 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/10 15:53:41 visual_prompt]: Epoch 14 / 100: avg data time: 1.13e+01, avg batch time: 11.6444, average train loss: 15.7302
[11/10 15:54:27 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.1552, average loss: 7.0918
[11/10 15:54:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.03	
[11/10 15:54:27 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/10 16:01:11 visual_prompt]: Epoch 15 / 100: avg data time: 1.12e+01, avg batch time: 11.5567, average train loss: 21.8307
[11/10 16:01:57 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1550, average loss: 8.7284
[11/10 16:01:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 38.50	
[11/10 16:01:57 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/10 16:08:49 visual_prompt]: Epoch 16 / 100: avg data time: 1.14e+01, avg batch time: 11.7634, average train loss: 11.5582
[11/10 16:09:35 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1551, average loss: 12.9695
[11/10 16:09:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.56	
[11/10 16:09:35 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/10 16:16:20 visual_prompt]: Epoch 17 / 100: avg data time: 1.12e+01, avg batch time: 11.5568, average train loss: 13.2553
[11/10 16:17:06 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1549, average loss: 22.1504
[11/10 16:17:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.76	
[11/10 16:17:06 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/10 16:24:05 visual_prompt]: Epoch 18 / 100: avg data time: 1.16e+01, avg batch time: 11.9530, average train loss: 20.7829
[11/10 16:24:53 visual_prompt]: Inference (val):avg data time: 4.58e-05, avg batch time: 0.1804, average loss: 30.7949
[11/10 16:24:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.03	
[11/10 16:24:53 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/10 16:32:07 visual_prompt]: Epoch 19 / 100: avg data time: 1.18e+01, avg batch time: 12.4067, average train loss: 32.4797
[11/10 16:32:55 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.1552, average loss: 5.2702
[11/10 16:32:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.16	
[11/10 16:32:55 visual_prompt]: Best epoch 19: best metric: -5.270
[11/10 16:32:55 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/10 16:39:52 visual_prompt]: Epoch 20 / 100: avg data time: 1.15e+01, avg batch time: 11.8958, average train loss: 21.1628
[11/10 16:40:40 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1547, average loss: 1.5709
[11/10 16:40:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.09	
[11/10 16:40:40 visual_prompt]: Best epoch 20: best metric: -1.571
[11/10 16:40:40 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/10 16:47:10 visual_prompt]: Epoch 21 / 100: avg data time: 1.08e+01, avg batch time: 11.1504, average train loss: 18.9642
[11/10 16:47:54 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1552, average loss: 12.4924
[11/10 16:47:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.11	
[11/10 16:47:54 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/10 16:54:29 visual_prompt]: Epoch 22 / 100: avg data time: 1.09e+01, avg batch time: 11.2853, average train loss: 13.6308
[11/10 16:55:15 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1544, average loss: 5.2285
[11/10 16:55:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.54	
[11/10 16:55:15 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/10 17:01:48 visual_prompt]: Epoch 23 / 100: avg data time: 1.09e+01, avg batch time: 11.2394, average train loss: 18.9289
[11/10 17:02:32 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1549, average loss: 13.4957
[11/10 17:02:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.12	
[11/10 17:02:32 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/10 17:09:05 visual_prompt]: Epoch 24 / 100: avg data time: 1.09e+01, avg batch time: 11.2166, average train loss: 15.8245
[11/10 17:09:50 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1549, average loss: 0.7552
[11/10 17:09:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.80	
[11/10 17:09:50 visual_prompt]: Best epoch 24: best metric: -0.755
[11/10 17:09:50 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/10 17:16:22 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.2027, average train loss: 15.8604
[11/10 17:17:06 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1588, average loss: 53.8465
[11/10 17:17:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.33	
[11/10 17:17:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/10 17:23:39 visual_prompt]: Epoch 26 / 100: avg data time: 1.09e+01, avg batch time: 11.2152, average train loss: 22.8929
[11/10 17:24:23 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1572, average loss: 33.2935
[11/10 17:24:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.03	
[11/10 17:24:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/10 17:30:57 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2278, average train loss: 16.8460
[11/10 17:31:45 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1548, average loss: 3.3818
[11/10 17:31:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.75	
[11/10 17:31:45 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/10 17:38:20 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e+01, avg batch time: 11.2949, average train loss: 20.6199
[11/10 17:39:04 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.1547, average loss: 2.5201
[11/10 17:39:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.25	
[11/10 17:39:04 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/10 17:45:38 visual_prompt]: Epoch 29 / 100: avg data time: 1.09e+01, avg batch time: 11.2332, average train loss: 12.7314
[11/10 17:46:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1549, average loss: 7.0931
[11/10 17:46:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.73	
[11/10 17:46:22 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/10 17:52:52 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1270, average train loss: 18.3075
[11/10 17:53:35 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1547, average loss: 4.3186
[11/10 17:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.44	
[11/10 17:53:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/10 17:59:58 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9454, average train loss: 18.4186
[11/10 18:00:41 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1552, average loss: 65.3759
[11/10 18:00:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.88	
[11/10 18:00:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/10 18:07:07 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 11.0020, average train loss: 12.0042
[11/10 18:07:50 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1583, average loss: 12.4852
[11/10 18:07:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.93	
[11/10 18:07:50 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/10 18:14:16 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0256, average train loss: 13.9626
[11/10 18:15:00 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1547, average loss: 14.0802
[11/10 18:15:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.05	
[11/10 18:15:00 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/10 18:21:29 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0967, average train loss: 13.8670
[11/10 18:22:13 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.1577, average loss: 11.5005
[11/10 18:22:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.40	
[11/10 18:22:13 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/10 18:28:40 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0476, average train loss: 15.6084
[11/10 18:29:23 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1559, average loss: 26.1400
[11/10 18:29:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.99	
[11/10 18:29:23 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/10 18:35:52 visual_prompt]: Epoch 36 / 100: avg data time: 1.07e+01, avg batch time: 11.1040, average train loss: 16.1361
[11/10 18:36:36 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1549, average loss: 2.2492
[11/10 18:36:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.88	
[11/10 18:36:36 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/10 18:43:01 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.0178, average train loss: 12.0501
[11/10 18:43:45 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1591, average loss: 22.2722
[11/10 18:43:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.41	
[11/10 18:43:45 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/10 18:50:11 visual_prompt]: Epoch 38 / 100: avg data time: 1.07e+01, avg batch time: 11.0176, average train loss: 13.7256
[11/10 18:50:54 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1546, average loss: 12.4697
[11/10 18:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.56	
[11/10 18:50:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/10 18:57:21 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0421, average train loss: 19.7658
[11/10 18:58:05 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1547, average loss: 10.5454
[11/10 18:58:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.74	
[11/10 18:58:05 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/10 19:04:31 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0401, average train loss: 12.9651
[11/10 19:05:15 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1545, average loss: 22.7339
[11/10 19:05:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.25	
[11/10 19:05:15 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/10 19:11:39 visual_prompt]: Epoch 41 / 100: avg data time: 1.06e+01, avg batch time: 10.9734, average train loss: 10.8219
[11/10 19:12:23 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1548, average loss: 10.7377
[11/10 19:12:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.96	
[11/10 19:12:23 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/10 19:18:50 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e+01, avg batch time: 11.0442, average train loss: 11.7616
[11/10 19:19:33 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1618, average loss: 11.9187
[11/10 19:19:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.22	
[11/10 19:19:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/10 19:26:01 visual_prompt]: Epoch 43 / 100: avg data time: 1.07e+01, avg batch time: 11.0820, average train loss: 18.0197
[11/10 19:26:46 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1548, average loss: 15.3912
[11/10 19:26:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.07	
[11/10 19:26:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/10 19:33:18 visual_prompt]: Epoch 44 / 100: avg data time: 1.09e+01, avg batch time: 11.2178, average train loss: 22.0769
[11/10 19:34:03 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1547, average loss: 5.2257
[11/10 19:34:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.14	
[11/10 19:34:03 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/10 19:40:36 visual_prompt]: Epoch 45 / 100: avg data time: 1.09e+01, avg batch time: 11.2296, average train loss: 11.5913
[11/10 19:41:20 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1550, average loss: 8.9516
[11/10 19:41:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.37	
[11/10 19:41:20 visual_prompt]: Stopping early.
[11/10 19:41:21 visual_prompt]: Rank of current process: 0. World size: 1
[11/10 19:41:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 19:41:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/10 19:41:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/10 19:41:21 visual_prompt]: Training with config:
[11/10 19:41:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/10 19:41:21 visual_prompt]: Loading training data...
[11/10 19:41:21 visual_prompt]: Constructing mammo-cbis dataset train...
[11/10 19:41:21 visual_prompt]: Loading validation data...
[11/10 19:41:21 visual_prompt]: Constructing mammo-cbis dataset val...
[11/10 19:41:21 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/10 19:41:26 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/10 19:41:26 visual_prompt]: tuned percent:0.536
[11/10 19:41:26 visual_prompt]: Device used for model: 0
[11/10 19:41:26 visual_prompt]: Setting up Evaluator...
[11/10 19:41:26 visual_prompt]: Setting up Trainer...
[11/10 19:41:26 visual_prompt]: 	Setting up the optimizer...
[11/10 19:41:26 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/10 19:48:00 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.2605, average train loss: 1.4017
[11/10 19:48:46 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1548, average loss: 1.2969
[11/10 19:48:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/10 19:48:46 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/10 19:55:05 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8422, average train loss: 10.4425
[11/10 19:55:50 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1544, average loss: 0.6938
[11/10 19:55:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.53	
[11/10 19:55:50 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/10 20:02:14 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9868, average train loss: 1.1895
[11/10 20:02:59 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1545, average loss: 1.3877
[11/10 20:02:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.12	
[11/10 20:02:59 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/10 20:09:28 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0889, average train loss: 3.4619
[11/10 20:10:12 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1561, average loss: 12.7618
[11/10 20:10:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[11/10 20:10:12 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/10 20:16:41 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.1002, average train loss: 9.8489
[11/10 20:17:25 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1547, average loss: 0.8044
[11/10 20:17:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.56	
[11/10 20:17:25 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/10 20:23:54 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1115, average train loss: 3.7464
[11/10 20:24:38 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1549, average loss: 7.9896
[11/10 20:24:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.63	
[11/10 20:24:38 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/10 20:31:06 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0919, average train loss: 4.7458
[11/10 20:31:50 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1550, average loss: 7.3967
[11/10 20:31:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/10 20:31:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/10 20:38:17 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.0446, average train loss: 4.4850
[11/10 20:39:01 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1546, average loss: 4.1082
[11/10 20:39:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.95	
[11/10 20:39:01 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/10 20:45:35 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2326, average train loss: 7.8319
[11/10 20:46:19 visual_prompt]: Inference (val):avg data time: 2.43e-05, avg batch time: 0.1547, average loss: 3.7704
[11/10 20:46:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[11/10 20:46:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/10 20:52:50 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1565, average train loss: 3.6409
[11/10 20:53:34 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1586, average loss: 5.6437
[11/10 20:53:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.87	
[11/10 20:53:34 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/10 21:00:05 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1657, average train loss: 11.5482
[11/10 21:00:49 visual_prompt]: Inference (val):avg data time: 2.60e-05, avg batch time: 0.1549, average loss: 1.0355
[11/10 21:00:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.05	
[11/10 21:00:49 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/10 21:07:20 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.1675, average train loss: 12.6833
[11/10 21:08:05 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1547, average loss: 6.1286
[11/10 21:08:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.46	
[11/10 21:08:05 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/10 21:14:36 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1676, average train loss: 5.0546
[11/10 21:15:21 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1546, average loss: 0.6965
[11/10 21:15:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.41	
[11/10 21:15:21 visual_prompt]: Best epoch 13: best metric: -0.697
[11/10 21:15:21 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/10 21:21:51 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1450, average train loss: 9.0732
[11/10 21:22:35 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1552, average loss: 3.7761
[11/10 21:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.37	
[11/10 21:22:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/10 21:29:01 visual_prompt]: Epoch 15 / 100: avg data time: 1.07e+01, avg batch time: 11.0181, average train loss: 8.7014
[11/10 21:29:44 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1549, average loss: 8.1259
[11/10 21:29:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.58	
[11/10 21:29:44 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/10 21:36:15 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e+01, avg batch time: 11.1767, average train loss: 5.2885
[11/10 21:37:00 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1547, average loss: 3.1583
[11/10 21:37:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.88	
[11/10 21:37:00 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/10 21:43:33 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e+01, avg batch time: 11.2162, average train loss: 11.5686
[11/10 21:44:18 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1553, average loss: 12.0836
[11/10 21:44:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.03	
[11/10 21:44:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/10 21:50:46 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0828, average train loss: 7.0676
[11/10 21:51:30 visual_prompt]: Inference (val):avg data time: 2.49e-05, avg batch time: 0.1589, average loss: 12.7832
[11/10 21:51:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.02	
[11/10 21:51:30 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/10 21:57:56 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0303, average train loss: 6.4098
[11/10 21:58:40 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1546, average loss: 3.2318
[11/10 21:58:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.06	
[11/10 21:58:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/10 22:05:11 visual_prompt]: Epoch 20 / 100: avg data time: 1.08e+01, avg batch time: 11.1768, average train loss: 5.8050
[11/10 22:05:56 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1544, average loss: 21.2096
[11/10 22:05:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.08	
[11/10 22:05:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/10 22:12:26 visual_prompt]: Epoch 21 / 100: avg data time: 1.08e+01, avg batch time: 11.1655, average train loss: 9.7998
[11/10 22:13:12 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1550, average loss: 0.9961
[11/10 22:13:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.62	
[11/10 22:13:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/10 22:19:44 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.1987, average train loss: 8.2605
[11/10 22:20:27 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1549, average loss: 0.9029
[11/10 22:20:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.86	
[11/10 22:20:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/10 22:26:56 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0993, average train loss: 8.0343
[11/10 22:27:40 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1547, average loss: 10.1423
[11/10 22:27:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.11	
[11/10 22:27:40 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/10 22:34:08 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0867, average train loss: 6.9418
[11/10 22:34:53 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1549, average loss: 1.3006
[11/10 22:34:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.85	
[11/10 22:34:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/10 22:41:23 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1435, average train loss: 4.6415
[11/10 22:42:07 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.1552, average loss: 4.8770
[11/10 22:42:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.18	
[11/10 22:42:07 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/10 22:48:35 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0820, average train loss: 6.4471
[11/10 22:49:19 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1547, average loss: 19.9643
[11/10 22:49:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.57	
[11/10 22:49:19 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/10 22:55:48 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.0888, average train loss: 11.2924
[11/10 22:56:32 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1552, average loss: 7.0592
[11/10 22:56:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.76	
[11/10 22:56:32 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/10 23:02:55 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9179, average train loss: 17.4980
[11/10 23:03:38 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1555, average loss: 26.0919
[11/10 23:03:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.36	
[11/10 23:03:38 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/10 23:10:01 visual_prompt]: Epoch 29 / 100: avg data time: 1.06e+01, avg batch time: 10.9443, average train loss: 13.6935
[11/10 23:10:45 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1546, average loss: 18.0721
[11/10 23:10:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.73	
[11/10 23:10:45 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/10 23:17:07 visual_prompt]: Epoch 30 / 100: avg data time: 1.06e+01, avg batch time: 10.9164, average train loss: 10.5933
[11/10 23:17:50 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1567, average loss: 19.6720
[11/10 23:17:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.90	
[11/10 23:17:50 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/10 23:24:13 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9233, average train loss: 7.5147
[11/10 23:24:56 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1545, average loss: 12.5461
[11/10 23:24:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 40.65	
[11/10 23:24:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/10 23:31:19 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9419, average train loss: 6.6751
[11/10 23:32:03 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1542, average loss: 10.0021
[11/10 23:32:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.65	
[11/10 23:32:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/10 23:38:36 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2407, average train loss: 4.9870
[11/10 23:39:21 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1550, average loss: 1.4972
[11/10 23:39:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.30	
[11/10 23:39:21 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/10 23:45:56 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e+01, avg batch time: 11.2589, average train loss: 2.6152
[11/10 23:46:40 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1549, average loss: 4.7670
[11/10 23:46:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.72	
[11/10 23:46:40 visual_prompt]: Stopping early.
[11/10 23:46:40 visual_prompt]: Rank of current process: 0. World size: 1
[11/10 23:46:40 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/10 23:46:40 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/10 23:46:40 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/10 23:46:40 visual_prompt]: Training with config:
[11/10 23:46:40 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr10.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 10.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/10 23:46:40 visual_prompt]: Loading training data...
[11/10 23:46:40 visual_prompt]: Constructing mammo-cbis dataset train...
[11/10 23:46:40 visual_prompt]: Loading validation data...
[11/10 23:46:40 visual_prompt]: Constructing mammo-cbis dataset val...
[11/10 23:46:40 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/10 23:46:43 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/10 23:46:43 visual_prompt]: tuned percent:0.536
[11/10 23:46:43 visual_prompt]: Device used for model: 0
[11/10 23:46:43 visual_prompt]: Setting up Evaluator...
[11/10 23:46:43 visual_prompt]: Setting up Trainer...
[11/10 23:46:43 visual_prompt]: 	Setting up the optimizer...
[11/10 23:46:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/10 23:53:19 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.2951, average train loss: 1.4017
[11/10 23:54:04 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1552, average loss: 1.2969
[11/10 23:54:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/10 23:54:04 visual_prompt]: Training 2 / 100 epoch, with learning rate 1.0
[11/11 00:00:39 visual_prompt]: Epoch 2 / 100: avg data time: 1.09e+01, avg batch time: 11.2800, average train loss: 10.4418
[11/11 00:01:24 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1546, average loss: 0.6945
[11/11 00:01:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.45	
[11/11 00:01:24 visual_prompt]: Training 3 / 100 epoch, with learning rate 2.0
[11/11 00:07:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.2605, average train loss: 1.1239
[11/11 00:08:43 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1548, average loss: 0.7940
[11/11 00:08:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.82	
[11/11 00:08:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 3.0
[11/11 00:15:17 visual_prompt]: Epoch 4 / 100: avg data time: 1.09e+01, avg batch time: 11.2513, average train loss: 3.3517
[11/11 00:16:02 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1550, average loss: 14.6353
[11/11 00:16:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[11/11 00:16:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 4.0
[11/11 00:22:33 visual_prompt]: Epoch 5 / 100: avg data time: 1.08e+01, avg batch time: 11.1956, average train loss: 7.4177
[11/11 00:23:18 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1549, average loss: 5.1087
[11/11 00:23:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.35	
[11/11 00:23:18 visual_prompt]: Training 6 / 100 epoch, with learning rate 5.0
[11/11 00:29:50 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1932, average train loss: 7.1617
[11/11 00:30:34 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1586, average loss: 8.6704
[11/11 00:30:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.53	
[11/11 00:30:34 visual_prompt]: Training 7 / 100 epoch, with learning rate 6.0
[11/11 00:37:06 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.1996, average train loss: 9.3843
[11/11 00:37:51 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1546, average loss: 1.6088
[11/11 00:37:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.15	
[11/11 00:37:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 7.0
[11/11 00:44:22 visual_prompt]: Epoch 8 / 100: avg data time: 1.08e+01, avg batch time: 11.1637, average train loss: 3.9312
[11/11 00:45:07 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1547, average loss: 10.4945
[11/11 00:45:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.85	
[11/11 00:45:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 8.0
[11/11 00:51:38 visual_prompt]: Epoch 9 / 100: avg data time: 1.08e+01, avg batch time: 11.1887, average train loss: 4.8908
[11/11 00:52:23 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1545, average loss: 2.2516
[11/11 00:52:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.33	
[11/11 00:52:23 visual_prompt]: Training 10 / 100 epoch, with learning rate 9.0
[11/11 00:58:53 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1593, average train loss: 9.2791
[11/11 00:59:38 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1547, average loss: 11.8856
[11/11 00:59:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.17	
[11/11 00:59:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 10.0
[11/11 01:06:09 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1703, average train loss: 8.3222
[11/11 01:06:54 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1571, average loss: 3.1799
[11/11 01:06:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/11 01:06:54 visual_prompt]: Training 12 / 100 epoch, with learning rate 9.996954135095478
[11/11 01:13:26 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2049, average train loss: 18.3171
[11/11 01:14:11 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1546, average loss: 1.1984
[11/11 01:14:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.48	
[11/11 01:14:11 visual_prompt]: Best epoch 12: best metric: -1.198
[11/11 01:14:11 visual_prompt]: Training 13 / 100 epoch, with learning rate 9.987820251299121
[11/11 01:20:44 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2226, average train loss: 13.1095
[11/11 01:21:29 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1583, average loss: 24.5212
[11/11 01:21:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.34	
[11/11 01:21:29 visual_prompt]: Training 14 / 100 epoch, with learning rate 9.972609476841367
[11/11 01:28:07 visual_prompt]: Epoch 14 / 100: avg data time: 1.10e+01, avg batch time: 11.3672, average train loss: 13.2785
[11/11 01:28:52 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1546, average loss: 8.4924
[11/11 01:28:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.66	
[11/11 01:28:52 visual_prompt]: Training 15 / 100 epoch, with learning rate 9.951340343707852
[11/11 01:35:32 visual_prompt]: Epoch 15 / 100: avg data time: 1.11e+01, avg batch time: 11.4073, average train loss: 12.6995
[11/11 01:36:17 visual_prompt]: Inference (val):avg data time: 3.86e-05, avg batch time: 0.1546, average loss: 21.4061
[11/11 01:36:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.34	
[11/11 01:36:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 9.924038765061042
[11/11 01:42:54 visual_prompt]: Epoch 16 / 100: avg data time: 1.10e+01, avg batch time: 11.3500, average train loss: 6.7786
[11/11 01:43:40 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1607, average loss: 3.9845
[11/11 01:43:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.05	
[11/11 01:43:40 visual_prompt]: Training 17 / 100 epoch, with learning rate 9.890738003669028
[11/11 01:50:17 visual_prompt]: Epoch 17 / 100: avg data time: 1.10e+01, avg batch time: 11.3484, average train loss: 4.6889
[11/11 01:51:03 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1545, average loss: 8.7248
[11/11 01:51:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.55	
[11/11 01:51:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 9.851478631379981
[11/11 01:57:38 visual_prompt]: Epoch 18 / 100: avg data time: 1.10e+01, avg batch time: 11.3062, average train loss: 4.7508
[11/11 01:58:24 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1547, average loss: 8.7396
[11/11 01:58:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.20	
[11/11 01:58:24 visual_prompt]: Training 19 / 100 epoch, with learning rate 9.806308479691594
[11/11 02:04:59 visual_prompt]: Epoch 19 / 100: avg data time: 1.09e+01, avg batch time: 11.2862, average train loss: 4.9378
[11/11 02:05:44 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1546, average loss: 10.4313
[11/11 02:05:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.37	
[11/11 02:05:44 visual_prompt]: Training 20 / 100 epoch, with learning rate 9.755282581475768
[11/11 02:12:18 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.2687, average train loss: 6.3862
[11/11 02:13:03 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1545, average loss: 0.9376
[11/11 02:13:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.01	
[11/11 02:13:03 visual_prompt]: Best epoch 20: best metric: -0.938
[11/11 02:13:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 9.698463103929543
[11/11 02:19:37 visual_prompt]: Epoch 21 / 100: avg data time: 1.09e+01, avg batch time: 11.2554, average train loss: 2.5757
[11/11 02:20:23 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1545, average loss: 1.9362
[11/11 02:20:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.12	
[11/11 02:20:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 9.635919272833938
[11/11 02:26:57 visual_prompt]: Epoch 22 / 100: avg data time: 1.09e+01, avg batch time: 11.2540, average train loss: 5.7404
[11/11 02:27:42 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1549, average loss: 4.2995
[11/11 02:27:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.92	
[11/11 02:27:42 visual_prompt]: Training 23 / 100 epoch, with learning rate 9.567727288213003
[11/11 02:34:15 visual_prompt]: Epoch 23 / 100: avg data time: 1.09e+01, avg batch time: 11.2435, average train loss: 3.5707
[11/11 02:35:00 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1545, average loss: 0.7783
[11/11 02:35:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.45	
[11/11 02:35:00 visual_prompt]: Best epoch 23: best metric: -0.778
[11/11 02:35:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 9.493970231495835
[11/11 02:41:35 visual_prompt]: Epoch 24 / 100: avg data time: 1.09e+01, avg batch time: 11.2724, average train loss: 6.0037
[11/11 02:42:20 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1545, average loss: 15.6647
[11/11 02:42:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.05	
[11/11 02:42:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 9.414737964294634
[11/11 02:48:54 visual_prompt]: Epoch 25 / 100: avg data time: 1.09e+01, avg batch time: 11.2609, average train loss: 6.6018
[11/11 02:49:39 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1574, average loss: 4.3701
[11/11 02:49:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.21	
[11/11 02:49:39 visual_prompt]: Training 26 / 100 epoch, with learning rate 9.330127018922195
[11/11 02:56:14 visual_prompt]: Epoch 26 / 100: avg data time: 1.09e+01, avg batch time: 11.2688, average train loss: 4.4561
[11/11 02:56:59 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1579, average loss: 10.0461
[11/11 02:56:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/11 02:56:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 9.240240480782129
[11/11 03:03:33 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2653, average train loss: 6.0585
[11/11 03:04:19 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1548, average loss: 5.4047
[11/11 03:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.21	
[11/11 03:04:19 visual_prompt]: Training 28 / 100 epoch, with learning rate 9.145187862775208
[11/11 03:10:58 visual_prompt]: Epoch 28 / 100: avg data time: 1.10e+01, avg batch time: 11.4019, average train loss: 5.9594
[11/11 03:11:43 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1574, average loss: 2.7271
[11/11 03:11:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.48	
[11/11 03:11:43 visual_prompt]: Training 29 / 100 epoch, with learning rate 9.045084971874736
[11/11 03:18:22 visual_prompt]: Epoch 29 / 100: avg data time: 1.10e+01, avg batch time: 11.3901, average train loss: 3.3172
[11/11 03:19:07 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1554, average loss: 8.7258
[11/11 03:19:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.93	
[11/11 03:19:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 8.940053768033609
[11/11 03:25:44 visual_prompt]: Epoch 30 / 100: avg data time: 1.10e+01, avg batch time: 11.3265, average train loss: 6.7884
[11/11 03:26:29 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1548, average loss: 2.9883
[11/11 03:26:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.15	
[11/11 03:26:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 8.83022221559489
[11/11 03:33:03 visual_prompt]: Epoch 31 / 100: avg data time: 1.09e+01, avg batch time: 11.2536, average train loss: 3.0542
[11/11 03:33:48 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1546, average loss: 0.7429
[11/11 03:33:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.53	
[11/11 03:33:48 visual_prompt]: Best epoch 31: best metric: -0.743
[11/11 03:33:48 visual_prompt]: Training 32 / 100 epoch, with learning rate 8.715724127386972
[11/11 03:40:24 visual_prompt]: Epoch 32 / 100: avg data time: 1.10e+01, avg batch time: 11.3084, average train loss: 2.9631
[11/11 03:41:09 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1550, average loss: 3.9893
[11/11 03:41:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.37	
[11/11 03:41:09 visual_prompt]: Training 33 / 100 epoch, with learning rate 8.596699001693256
[11/11 03:47:45 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2834, average train loss: 4.2813
[11/11 03:48:30 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1570, average loss: 3.7075
[11/11 03:48:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.79	
[11/11 03:48:30 visual_prompt]: Training 34 / 100 epoch, with learning rate 8.473291852294986
[11/11 03:55:03 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e+01, avg batch time: 11.2464, average train loss: 3.4552
[11/11 03:55:48 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1546, average loss: 1.9724
[11/11 03:55:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.03	
[11/11 03:55:48 visual_prompt]: Training 35 / 100 epoch, with learning rate 8.345653031794292
[11/11 04:02:22 visual_prompt]: Epoch 35 / 100: avg data time: 1.09e+01, avg batch time: 11.2477, average train loss: 4.3530
[11/11 04:03:07 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1548, average loss: 3.8353
[11/11 04:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/11 04:03:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 8.213938048432697
[11/11 04:09:42 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e+01, avg batch time: 11.2663, average train loss: 2.6070
[11/11 04:10:27 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1548, average loss: 1.1404
[11/11 04:10:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.25	
[11/11 04:10:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 8.078307376628292
[11/11 04:17:01 visual_prompt]: Epoch 37 / 100: avg data time: 1.09e+01, avg batch time: 11.2517, average train loss: 3.5711
[11/11 04:17:46 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1546, average loss: 4.5995
[11/11 04:17:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.14	
[11/11 04:17:46 visual_prompt]: Training 38 / 100 epoch, with learning rate 7.938926261462366
[11/11 04:24:20 visual_prompt]: Epoch 38 / 100: avg data time: 1.09e+01, avg batch time: 11.2675, average train loss: 1.4723
[11/11 04:25:05 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1546, average loss: 0.6791
[11/11 04:25:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 59.91	
[11/11 04:25:05 visual_prompt]: Best epoch 38: best metric: -0.679
[11/11 04:25:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 7.795964517353734
[11/11 04:31:40 visual_prompt]: Epoch 39 / 100: avg data time: 1.09e+01, avg batch time: 11.2843, average train loss: 2.4549
[11/11 04:32:25 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1546, average loss: 2.1831
[11/11 04:32:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.23	
[11/11 04:32:25 visual_prompt]: Training 40 / 100 epoch, with learning rate 7.649596321166024
[11/11 04:38:57 visual_prompt]: Epoch 40 / 100: avg data time: 1.08e+01, avg batch time: 11.1945, average train loss: 6.3091
[11/11 04:39:43 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1544, average loss: 2.7352
[11/11 04:39:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/11 04:39:43 visual_prompt]: Training 41 / 100 epoch, with learning rate 7.5
[11/11 04:46:23 visual_prompt]: Epoch 41 / 100: avg data time: 1.11e+01, avg batch time: 11.4231, average train loss: 3.6645
[11/11 04:47:08 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1549, average loss: 9.4874
[11/11 04:47:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.43	
[11/11 04:47:08 visual_prompt]: Training 42 / 100 epoch, with learning rate 7.347357813929454
[11/11 04:53:47 visual_prompt]: Epoch 42 / 100: avg data time: 1.10e+01, avg batch time: 11.3984, average train loss: 3.9768
[11/11 04:54:33 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1550, average loss: 2.2904
[11/11 04:54:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.52	
[11/11 04:54:33 visual_prompt]: Training 43 / 100 epoch, with learning rate 7.191855733945387
[11/11 05:01:10 visual_prompt]: Epoch 43 / 100: avg data time: 1.10e+01, avg batch time: 11.3388, average train loss: 5.3237
[11/11 05:01:55 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1550, average loss: 1.9762
[11/11 05:01:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.06	
[11/11 05:01:55 visual_prompt]: Training 44 / 100 epoch, with learning rate 7.033683215379002
[11/11 05:08:30 visual_prompt]: Epoch 44 / 100: avg data time: 1.09e+01, avg batch time: 11.2721, average train loss: 2.9210
[11/11 05:09:15 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1548, average loss: 2.4566
[11/11 05:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/11 05:09:15 visual_prompt]: Training 45 / 100 epoch, with learning rate 6.873032967079561
[11/11 05:15:52 visual_prompt]: Epoch 45 / 100: avg data time: 1.10e+01, avg batch time: 11.3318, average train loss: 3.2157
[11/11 05:16:37 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1548, average loss: 0.7525
[11/11 05:16:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 59.15	
[11/11 05:16:37 visual_prompt]: Training 46 / 100 epoch, with learning rate 6.710100716628345
[11/11 05:23:12 visual_prompt]: Epoch 46 / 100: avg data time: 1.09e+01, avg batch time: 11.2902, average train loss: 6.8554
[11/11 05:23:57 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1544, average loss: 16.7575
[11/11 05:23:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.88	
[11/11 05:23:57 visual_prompt]: Training 47 / 100 epoch, with learning rate 6.545084971874737
[11/11 05:30:31 visual_prompt]: Epoch 47 / 100: avg data time: 1.09e+01, avg batch time: 11.2632, average train loss: 5.5815
[11/11 05:31:16 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1551, average loss: 0.9816
[11/11 05:31:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.51	
[11/11 05:31:16 visual_prompt]: Training 48 / 100 epoch, with learning rate 6.378186779084995
[11/11 05:37:51 visual_prompt]: Epoch 48 / 100: avg data time: 1.09e+01, avg batch time: 11.2601, average train loss: 2.7137
[11/11 05:38:36 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1546, average loss: 0.9326
[11/11 05:38:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 59.31	
[11/11 05:38:36 visual_prompt]: Training 49 / 100 epoch, with learning rate 6.209609477998338
[11/11 05:45:10 visual_prompt]: Epoch 49 / 100: avg data time: 1.09e+01, avg batch time: 11.2586, average train loss: 2.6867
[11/11 05:45:55 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1549, average loss: 4.6516
[11/11 05:45:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.92	
[11/11 05:45:55 visual_prompt]: Training 50 / 100 epoch, with learning rate 6.039558454088796
[11/11 05:52:29 visual_prompt]: Epoch 50 / 100: avg data time: 1.09e+01, avg batch time: 11.2554, average train loss: 3.4468
[11/11 05:53:14 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1549, average loss: 4.0962
[11/11 05:53:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.95	
[11/11 05:53:14 visual_prompt]: Training 51 / 100 epoch, with learning rate 5.868240888334652
[11/11 05:59:48 visual_prompt]: Epoch 51 / 100: avg data time: 1.09e+01, avg batch time: 11.2572, average train loss: 3.0159
[11/11 06:00:33 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1550, average loss: 2.1575
[11/11 06:00:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.45	
[11/11 06:00:33 visual_prompt]: Training 52 / 100 epoch, with learning rate 5.695865504800327
[11/11 06:07:07 visual_prompt]: Epoch 52 / 100: avg data time: 1.09e+01, avg batch time: 11.2664, average train loss: 1.1417
[11/11 06:07:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1550, average loss: 0.7013
[11/11 06:07:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.89	
[11/11 06:07:52 visual_prompt]: Training 53 / 100 epoch, with learning rate 5.522642316338268
[11/11 06:14:21 visual_prompt]: Epoch 53 / 100: avg data time: 1.07e+01, avg batch time: 11.0956, average train loss: 2.4230
[11/11 06:15:06 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1548, average loss: 3.2150
[11/11 06:15:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.56	
[11/11 06:15:06 visual_prompt]: Training 54 / 100 epoch, with learning rate 5.3487823687206255
[11/11 06:21:45 visual_prompt]: Epoch 54 / 100: avg data time: 1.10e+01, avg batch time: 11.3961, average train loss: 1.3091
[11/11 06:22:31 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1549, average loss: 1.2998
[11/11 06:22:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/11 06:22:31 visual_prompt]: Training 55 / 100 epoch, with learning rate 5.174497483512505
[11/11 06:29:10 visual_prompt]: Epoch 55 / 100: avg data time: 1.10e+01, avg batch time: 11.3869, average train loss: 1.4710
[11/11 06:29:55 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1579, average loss: 1.3145
[11/11 06:29:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.61	
[11/11 06:29:55 visual_prompt]: Training 56 / 100 epoch, with learning rate 5.0
[11/11 06:36:32 visual_prompt]: Epoch 56 / 100: avg data time: 1.10e+01, avg batch time: 11.3441, average train loss: 1.1329
[11/11 06:37:17 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1546, average loss: 0.8743
[11/11 06:37:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.86	
[11/11 06:37:18 visual_prompt]: Training 57 / 100 epoch, with learning rate 4.8255025164874965
[11/11 06:43:54 visual_prompt]: Epoch 57 / 100: avg data time: 1.10e+01, avg batch time: 11.3347, average train loss: 1.3961
[11/11 06:44:40 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1555, average loss: 0.7985
[11/11 06:44:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 59.51	
[11/11 06:44:40 visual_prompt]: Training 58 / 100 epoch, with learning rate 4.651217631279374
[11/11 06:51:16 visual_prompt]: Epoch 58 / 100: avg data time: 1.10e+01, avg batch time: 11.3137, average train loss: 1.2228
[11/11 06:52:01 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1579, average loss: 0.7864
[11/11 06:52:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 61.88	
[11/11 06:52:01 visual_prompt]: Training 59 / 100 epoch, with learning rate 4.477357683661733
[11/11 06:58:36 visual_prompt]: Epoch 59 / 100: avg data time: 1.09e+01, avg batch time: 11.2922, average train loss: 1.1165
[11/11 06:59:21 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1559, average loss: 0.8139
[11/11 06:59:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 61.92	
[11/11 06:59:21 visual_prompt]: Stopping early.
[11/11 06:59:21 visual_prompt]: Rank of current process: 0. World size: 1
[11/11 06:59:21 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 06:59:21 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/11 06:59:21 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/11 06:59:21 visual_prompt]: Training with config:
[11/11 06:59:21 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/11 06:59:21 visual_prompt]: Loading training data...
[11/11 06:59:21 visual_prompt]: Constructing mammo-cbis dataset train...
[11/11 06:59:21 visual_prompt]: Loading validation data...
[11/11 06:59:21 visual_prompt]: Constructing mammo-cbis dataset val...
[11/11 06:59:21 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/11 06:59:27 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/11 06:59:27 visual_prompt]: tuned percent:0.536
[11/11 06:59:27 visual_prompt]: Device used for model: 0
[11/11 06:59:27 visual_prompt]: Setting up Evaluator...
[11/11 06:59:27 visual_prompt]: Setting up Trainer...
[11/11 06:59:27 visual_prompt]: 	Setting up the optimizer...
[11/11 06:59:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/11 07:06:03 visual_prompt]: Epoch 1 / 100: avg data time: 1.10e+01, avg batch time: 11.3143, average train loss: 1.4017
[11/11 07:06:49 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1550, average loss: 1.2969
[11/11 07:06:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/11 07:06:49 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/11 07:13:23 visual_prompt]: Epoch 2 / 100: avg data time: 1.09e+01, avg batch time: 11.2780, average train loss: 5.6248
[11/11 07:14:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1581, average loss: 0.8103
[11/11 07:14:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.58	
[11/11 07:14:08 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/11 07:20:44 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.2876, average train loss: 1.2066
[11/11 07:21:29 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1555, average loss: 0.8393
[11/11 07:21:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.35	
[11/11 07:21:29 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/11 07:28:03 visual_prompt]: Epoch 4 / 100: avg data time: 1.09e+01, avg batch time: 11.2701, average train loss: 1.0557
[11/11 07:28:48 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1583, average loss: 1.1743
[11/11 07:28:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.49	
[11/11 07:28:48 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/11 07:35:22 visual_prompt]: Epoch 5 / 100: avg data time: 1.09e+01, avg batch time: 11.2388, average train loss: 2.6304
[11/11 07:36:07 visual_prompt]: Inference (val):avg data time: 4.01e-05, avg batch time: 0.1557, average loss: 1.6485
[11/11 07:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.36	
[11/11 07:36:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/11 07:42:41 visual_prompt]: Epoch 6 / 100: avg data time: 1.09e+01, avg batch time: 11.2576, average train loss: 2.6649
[11/11 07:43:26 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1545, average loss: 4.4023
[11/11 07:43:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.11	
[11/11 07:43:26 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/11 07:49:56 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.1617, average train loss: 4.6162
[11/11 07:50:40 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1546, average loss: 1.1700
[11/11 07:50:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.43	
[11/11 07:50:40 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/11 07:57:18 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e+01, avg batch time: 11.3691, average train loss: 5.3331
[11/11 07:58:04 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.1552, average loss: 1.4131
[11/11 07:58:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.27	
[11/11 07:58:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/11 08:04:43 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.4041, average train loss: 8.9154
[11/11 08:05:28 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.1573, average loss: 0.9131
[11/11 08:05:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.11	
[11/11 08:05:28 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/11 08:12:06 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e+01, avg batch time: 11.3457, average train loss: 9.3795
[11/11 08:12:51 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.1547, average loss: 13.2028
[11/11 08:12:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.27	
[11/11 08:12:51 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/11 08:19:28 visual_prompt]: Epoch 11 / 100: avg data time: 1.10e+01, avg batch time: 11.3328, average train loss: 7.1777
[11/11 08:20:13 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1546, average loss: 3.5527
[11/11 08:20:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.16	
[11/11 08:20:13 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/11 08:26:49 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2994, average train loss: 10.5042
[11/11 08:27:34 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1548, average loss: 14.4873
[11/11 08:27:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.39	
[11/11 08:27:34 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/11 08:34:09 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2943, average train loss: 10.3349
[11/11 08:34:54 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1544, average loss: 1.7624
[11/11 08:34:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.23	
[11/11 08:34:54 visual_prompt]: Best epoch 13: best metric: -1.762
[11/11 08:34:54 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/11 08:41:27 visual_prompt]: Epoch 14 / 100: avg data time: 1.09e+01, avg batch time: 11.2394, average train loss: 11.2342
[11/11 08:42:12 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1545, average loss: 21.3650
[11/11 08:42:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.39	
[11/11 08:42:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/11 08:48:47 visual_prompt]: Epoch 15 / 100: avg data time: 1.09e+01, avg batch time: 11.2721, average train loss: 9.6737
[11/11 08:49:32 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1547, average loss: 12.0789
[11/11 08:49:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.67	
[11/11 08:49:32 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/11 08:56:06 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.2540, average train loss: 13.6611
[11/11 08:56:51 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1573, average loss: 16.7691
[11/11 08:56:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.37	
[11/11 08:56:51 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/11 09:03:24 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e+01, avg batch time: 11.2381, average train loss: 8.3092
[11/11 09:04:09 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1550, average loss: 11.7267
[11/11 09:04:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.58	
[11/11 09:04:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/11 09:10:44 visual_prompt]: Epoch 18 / 100: avg data time: 1.09e+01, avg batch time: 11.2862, average train loss: 9.4240
[11/11 09:11:29 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1589, average loss: 7.8038
[11/11 09:11:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.61	
[11/11 09:11:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/11 09:18:03 visual_prompt]: Epoch 19 / 100: avg data time: 1.09e+01, avg batch time: 11.2401, average train loss: 14.3100
[11/11 09:18:48 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1547, average loss: 14.5410
[11/11 09:18:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.89	
[11/11 09:18:48 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/11 09:25:21 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.2455, average train loss: 8.6450
[11/11 09:26:05 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1550, average loss: 9.2779
[11/11 09:26:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.16	
[11/11 09:26:05 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/11 09:32:38 visual_prompt]: Epoch 21 / 100: avg data time: 1.09e+01, avg batch time: 11.2233, average train loss: 10.1779
[11/11 09:33:23 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1551, average loss: 13.4034
[11/11 09:33:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.40	
[11/11 09:33:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/11 09:40:02 visual_prompt]: Epoch 22 / 100: avg data time: 1.10e+01, avg batch time: 11.3849, average train loss: 9.4261
[11/11 09:40:47 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1581, average loss: 27.3163
[11/11 09:40:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/11 09:40:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/11 09:47:24 visual_prompt]: Epoch 23 / 100: avg data time: 1.10e+01, avg batch time: 11.3344, average train loss: 10.8839
[11/11 09:48:09 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1557, average loss: 7.7333
[11/11 09:48:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 43.55	
[11/11 09:48:09 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/11 09:54:46 visual_prompt]: Epoch 24 / 100: avg data time: 1.10e+01, avg batch time: 11.3209, average train loss: 10.6806
[11/11 09:55:31 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.1549, average loss: 15.2159
[11/11 09:55:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.67	
[11/11 09:55:31 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/11 10:02:05 visual_prompt]: Epoch 25 / 100: avg data time: 1.09e+01, avg batch time: 11.2404, average train loss: 12.6929
[11/11 10:02:50 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1554, average loss: 5.9243
[11/11 10:02:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.36	
[11/11 10:02:50 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/11 10:09:25 visual_prompt]: Epoch 26 / 100: avg data time: 1.09e+01, avg batch time: 11.2920, average train loss: 9.9994
[11/11 10:10:10 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1549, average loss: 3.9487
[11/11 10:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.93	
[11/11 10:10:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/11 10:16:45 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2707, average train loss: 8.8892
[11/11 10:17:30 visual_prompt]: Inference (val):avg data time: 4.32e-05, avg batch time: 0.1552, average loss: 6.4328
[11/11 10:17:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.46	
[11/11 10:17:30 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/11 10:24:04 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e+01, avg batch time: 11.2449, average train loss: 12.4994
[11/11 10:24:48 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1545, average loss: 1.0125
[11/11 10:24:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.52	
[11/11 10:24:48 visual_prompt]: Best epoch 28: best metric: -1.012
[11/11 10:24:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/11 10:31:27 visual_prompt]: Epoch 29 / 100: avg data time: 1.10e+01, avg batch time: 11.3834, average train loss: 10.0180
[11/11 10:32:12 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1546, average loss: 15.3737
[11/11 10:32:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.16	
[11/11 10:32:12 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/11 10:38:45 visual_prompt]: Epoch 30 / 100: avg data time: 1.09e+01, avg batch time: 11.2343, average train loss: 10.0853
[11/11 10:39:30 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1567, average loss: 13.9667
[11/11 10:39:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.84	
[11/11 10:39:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/11 10:46:04 visual_prompt]: Epoch 31 / 100: avg data time: 1.09e+01, avg batch time: 11.2483, average train loss: 5.5552
[11/11 10:46:49 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1550, average loss: 4.7698
[11/11 10:46:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.24	
[11/11 10:46:49 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/11 10:53:23 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2642, average train loss: 9.4077
[11/11 10:54:08 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1550, average loss: 2.0400
[11/11 10:54:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.70	
[11/11 10:54:08 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/11 11:00:42 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2582, average train loss: 11.8067
[11/11 11:01:27 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1547, average loss: 9.0594
[11/11 11:01:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.17	
[11/11 11:01:27 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/11 11:07:54 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0656, average train loss: 8.3179
[11/11 11:08:40 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1545, average loss: 12.4870
[11/11 11:08:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.49	
[11/11 11:08:40 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/11 11:15:18 visual_prompt]: Epoch 35 / 100: avg data time: 1.10e+01, avg batch time: 11.3789, average train loss: 7.3017
[11/11 11:16:04 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1547, average loss: 7.9894
[11/11 11:16:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.28	
[11/11 11:16:04 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/11 11:22:42 visual_prompt]: Epoch 36 / 100: avg data time: 1.10e+01, avg batch time: 11.3752, average train loss: 7.2132
[11/11 11:23:27 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1572, average loss: 5.0138
[11/11 11:23:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.16	
[11/11 11:23:27 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/11 11:30:04 visual_prompt]: Epoch 37 / 100: avg data time: 1.10e+01, avg batch time: 11.3376, average train loss: 7.0348
[11/11 11:30:50 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1547, average loss: 18.4453
[11/11 11:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.24	
[11/11 11:30:50 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/11 11:37:24 visual_prompt]: Epoch 38 / 100: avg data time: 1.09e+01, avg batch time: 11.2705, average train loss: 8.0129
[11/11 11:38:09 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1547, average loss: 2.7561
[11/11 11:38:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.67	
[11/11 11:38:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/11 11:44:44 visual_prompt]: Epoch 39 / 100: avg data time: 1.09e+01, avg batch time: 11.2624, average train loss: 6.9046
[11/11 11:45:29 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1547, average loss: 1.6631
[11/11 11:45:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.47	
[11/11 11:45:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/11 11:52:03 visual_prompt]: Epoch 40 / 100: avg data time: 1.09e+01, avg batch time: 11.2522, average train loss: 6.8371
[11/11 11:52:47 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1544, average loss: 15.9958
[11/11 11:52:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.47	
[11/11 11:52:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/11 11:59:22 visual_prompt]: Epoch 41 / 100: avg data time: 1.09e+01, avg batch time: 11.2604, average train loss: 6.5813
[11/11 12:00:07 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1580, average loss: 17.8745
[11/11 12:00:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.59	
[11/11 12:00:07 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/11 12:06:41 visual_prompt]: Epoch 42 / 100: avg data time: 1.09e+01, avg batch time: 11.2734, average train loss: 9.2279
[11/11 12:07:26 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1546, average loss: 26.2310
[11/11 12:07:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.82	
[11/11 12:07:26 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/11 12:14:02 visual_prompt]: Epoch 43 / 100: avg data time: 1.09e+01, avg batch time: 11.2946, average train loss: 14.6330
[11/11 12:14:47 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1545, average loss: 1.7163
[11/11 12:14:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.53	
[11/11 12:14:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/11 12:21:22 visual_prompt]: Epoch 44 / 100: avg data time: 1.09e+01, avg batch time: 11.2818, average train loss: 9.2455
[11/11 12:22:07 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1550, average loss: 2.7288
[11/11 12:22:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.52	
[11/11 12:22:07 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/11 12:28:43 visual_prompt]: Epoch 45 / 100: avg data time: 1.10e+01, avg batch time: 11.3106, average train loss: 3.7318
[11/11 12:29:28 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1550, average loss: 1.6515
[11/11 12:29:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 41.23	
[11/11 12:29:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/11 12:36:02 visual_prompt]: Epoch 46 / 100: avg data time: 1.09e+01, avg batch time: 11.2570, average train loss: 7.9716
[11/11 12:36:47 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.1550, average loss: 4.3001
[11/11 12:36:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.19	
[11/11 12:36:47 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/11 12:43:14 visual_prompt]: Epoch 47 / 100: avg data time: 1.07e+01, avg batch time: 11.0662, average train loss: 5.1373
[11/11 12:44:00 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1543, average loss: 5.1938
[11/11 12:44:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.72	
[11/11 12:44:00 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/11 12:50:39 visual_prompt]: Epoch 48 / 100: avg data time: 1.10e+01, avg batch time: 11.4033, average train loss: 4.6984
[11/11 12:51:25 visual_prompt]: Inference (val):avg data time: 4.36e-05, avg batch time: 0.1550, average loss: 5.5605
[11/11 12:51:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.52	
[11/11 12:51:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/11 12:58:03 visual_prompt]: Epoch 49 / 100: avg data time: 1.10e+01, avg batch time: 11.3659, average train loss: 5.5546
[11/11 12:58:48 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1563, average loss: 10.1070
[11/11 12:58:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.85	
[11/11 12:58:48 visual_prompt]: Stopping early.
[11/11 12:58:48 visual_prompt]: Rank of current process: 0. World size: 1
[11/11 12:58:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/11 12:58:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/11 12:58:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/11 12:58:48 visual_prompt]: Training with config:
[11/11 12:58:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/11 12:58:48 visual_prompt]: Loading training data...
[11/11 12:58:48 visual_prompt]: Constructing mammo-cbis dataset train...
[11/11 12:58:48 visual_prompt]: Loading validation data...
[11/11 12:58:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/11 12:58:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/11 12:58:51 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/11 12:58:51 visual_prompt]: tuned percent:0.536
[11/11 12:58:51 visual_prompt]: Device used for model: 0
[11/11 12:58:51 visual_prompt]: Setting up Evaluator...
[11/11 12:58:51 visual_prompt]: Setting up Trainer...
[11/11 12:58:51 visual_prompt]: 	Setting up the optimizer...
[11/11 12:58:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/11 13:05:29 visual_prompt]: Epoch 1 / 100: avg data time: 1.10e+01, avg batch time: 11.3736, average train loss: 1.4017
[11/11 13:06:14 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1548, average loss: 1.2969
[11/11 13:06:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/11 13:06:14 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/11 13:12:51 visual_prompt]: Epoch 2 / 100: avg data time: 1.10e+01, avg batch time: 11.3275, average train loss: 5.7731
[11/11 13:13:36 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1550, average loss: 1.2430
[11/11 13:13:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.04	
[11/11 13:13:36 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/11 13:20:12 visual_prompt]: Epoch 3 / 100: avg data time: 1.09e+01, avg batch time: 11.3080, average train loss: 0.8244
[11/11 13:20:57 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1547, average loss: 0.7191
[11/11 13:20:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.04	
[11/11 13:20:57 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/11 13:27:33 visual_prompt]: Epoch 4 / 100: avg data time: 1.09e+01, avg batch time: 11.2973, average train loss: 1.5215
[11/11 13:28:18 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1581, average loss: 1.0503
[11/11 13:28:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/11 13:28:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/11 13:34:51 visual_prompt]: Epoch 5 / 100: avg data time: 1.09e+01, avg batch time: 11.2486, average train loss: 2.0434
[11/11 13:35:36 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1549, average loss: 0.7513
[11/11 13:35:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.70	
[11/11 13:35:36 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/11 13:42:11 visual_prompt]: Epoch 6 / 100: avg data time: 1.09e+01, avg batch time: 11.2655, average train loss: 1.1479
[11/11 13:42:56 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.1546, average loss: 0.7207
[11/11 13:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.36	
[11/11 13:42:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/11 13:49:30 visual_prompt]: Epoch 7 / 100: avg data time: 1.09e+01, avg batch time: 11.2737, average train loss: 1.1843
[11/11 13:50:15 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1564, average loss: 6.4927
[11/11 13:50:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/11 13:50:15 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/11 13:56:49 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.2354, average train loss: 6.4970
[11/11 13:57:34 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1544, average loss: 10.6573
[11/11 13:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.70	
[11/11 13:57:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/11 14:04:09 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2843, average train loss: 6.4295
[11/11 14:04:54 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1550, average loss: 2.9461
[11/11 14:04:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.46	
[11/11 14:04:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/11 14:11:28 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e+01, avg batch time: 11.2621, average train loss: 6.7578
[11/11 14:12:13 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1553, average loss: 23.0779
[11/11 14:12:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.16	
[11/11 14:12:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/11 14:18:44 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1617, average train loss: 13.0989
[11/11 14:19:27 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1565, average loss: 3.6098
[11/11 14:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.79	
[11/11 14:19:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/11 14:26:03 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.3069, average train loss: 9.3778
[11/11 14:26:49 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1586, average loss: 6.1048
[11/11 14:26:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.64	
[11/11 14:26:49 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/11 14:33:27 visual_prompt]: Epoch 13 / 100: avg data time: 1.10e+01, avg batch time: 11.3813, average train loss: 11.8091
[11/11 14:34:13 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1547, average loss: 3.0228
[11/11 14:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.86	
[11/11 14:34:13 visual_prompt]: Best epoch 13: best metric: -3.023
[11/11 14:34:13 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/11 14:40:49 visual_prompt]: Epoch 14 / 100: avg data time: 1.10e+01, avg batch time: 11.3281, average train loss: 5.2985
[11/11 14:41:34 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1544, average loss: 0.8025
[11/11 14:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.36	
[11/11 14:41:34 visual_prompt]: Best epoch 14: best metric: -0.802
[11/11 14:41:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/11 14:48:11 visual_prompt]: Epoch 15 / 100: avg data time: 1.10e+01, avg batch time: 11.3273, average train loss: 5.5812
[11/11 14:48:56 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1583, average loss: 2.5390
[11/11 14:48:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.81	
[11/11 14:48:56 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/11 14:55:30 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.2588, average train loss: 5.5829
[11/11 14:56:16 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1573, average loss: 14.6342
[11/11 14:56:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.24	
[11/11 14:56:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/11 15:02:50 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e+01, avg batch time: 11.2523, average train loss: 6.0420
[11/11 15:03:35 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1556, average loss: 2.2742
[11/11 15:03:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.22	
[11/11 15:03:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/11 15:10:07 visual_prompt]: Epoch 18 / 100: avg data time: 1.09e+01, avg batch time: 11.2145, average train loss: 14.2533
[11/11 15:10:52 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1544, average loss: 8.9785
[11/11 15:10:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.56	
[11/11 15:10:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/11 15:17:23 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.1841, average train loss: 10.0716
[11/11 15:18:08 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1545, average loss: 1.7788
[11/11 15:18:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.62	
[11/11 15:18:08 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/11 15:24:42 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.2485, average train loss: 13.9437
[11/11 15:25:27 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1557, average loss: 16.7936
[11/11 15:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.20	
[11/11 15:25:27 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/11 15:32:01 visual_prompt]: Epoch 21 / 100: avg data time: 1.09e+01, avg batch time: 11.2438, average train loss: 6.9809
[11/11 15:32:46 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1546, average loss: 7.3219
[11/11 15:32:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/11 15:32:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/11 15:39:20 visual_prompt]: Epoch 22 / 100: avg data time: 1.09e+01, avg batch time: 11.2442, average train loss: 4.3314
[11/11 15:40:04 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1547, average loss: 2.1494
[11/11 15:40:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.16	
[11/11 15:40:04 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/11 15:46:38 visual_prompt]: Epoch 23 / 100: avg data time: 1.09e+01, avg batch time: 11.2417, average train loss: 9.0389
[11/11 15:47:23 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1550, average loss: 12.8007
[11/11 15:47:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.62	
[11/11 15:47:23 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/11 15:53:57 visual_prompt]: Epoch 24 / 100: avg data time: 1.09e+01, avg batch time: 11.2547, average train loss: 6.7001
[11/11 15:54:42 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1544, average loss: 3.8032
[11/11 15:54:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.88	
[11/11 15:54:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/11 16:01:13 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1772, average train loss: 11.1263
[11/11 16:01:59 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1556, average loss: 17.2853
[11/11 16:01:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.36	
[11/11 16:01:59 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/11 16:08:38 visual_prompt]: Epoch 26 / 100: avg data time: 1.10e+01, avg batch time: 11.3995, average train loss: 9.0920
[11/11 16:09:23 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1544, average loss: 0.7783
[11/11 16:09:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.86	
[11/11 16:09:23 visual_prompt]: Best epoch 26: best metric: -0.778
[11/11 16:09:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/11 16:16:01 visual_prompt]: Epoch 27 / 100: avg data time: 1.10e+01, avg batch time: 11.3650, average train loss: 7.8992
[11/11 16:16:47 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1551, average loss: 0.7738
[11/11 16:16:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.10	
[11/11 16:16:47 visual_prompt]: Best epoch 27: best metric: -0.774
[11/11 16:16:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/11 16:23:23 visual_prompt]: Epoch 28 / 100: avg data time: 1.10e+01, avg batch time: 11.3088, average train loss: 3.2855
[11/11 16:24:08 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1550, average loss: 5.3887
[11/11 16:24:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.83	
[11/11 16:24:08 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/11 16:30:46 visual_prompt]: Epoch 29 / 100: avg data time: 1.10e+01, avg batch time: 11.3513, average train loss: 7.4374
[11/11 16:31:31 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1571, average loss: 10.2195
[11/11 16:31:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.38	
[11/11 16:31:31 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/11 16:38:06 visual_prompt]: Epoch 30 / 100: avg data time: 1.09e+01, avg batch time: 11.2938, average train loss: 5.2342
[11/11 16:38:51 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1543, average loss: 2.1261
[11/11 16:38:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.99	
[11/11 16:38:51 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/11 16:45:26 visual_prompt]: Epoch 31 / 100: avg data time: 1.09e+01, avg batch time: 11.2849, average train loss: 4.5357
[11/11 16:46:11 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1588, average loss: 0.9390
[11/11 16:46:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.15	
[11/11 16:46:11 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/11 16:52:46 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2722, average train loss: 4.7209
[11/11 16:53:31 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1548, average loss: 1.2624
[11/11 16:53:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.55	
[11/11 16:53:31 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/11 17:00:05 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2643, average train loss: 2.8895
[11/11 17:00:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1550, average loss: 3.4856
[11/11 17:00:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.54	
[11/11 17:00:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/11 17:07:24 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e+01, avg batch time: 11.2390, average train loss: 6.2387
[11/11 17:08:09 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1549, average loss: 8.4090
[11/11 17:08:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/11 17:08:09 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/11 17:14:42 visual_prompt]: Epoch 35 / 100: avg data time: 1.09e+01, avg batch time: 11.2478, average train loss: 5.5720
[11/11 17:15:27 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1545, average loss: 13.3823
[11/11 17:15:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.84	
[11/11 17:15:27 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/11 17:22:01 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e+01, avg batch time: 11.2333, average train loss: 5.9822
[11/11 17:22:46 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1569, average loss: 7.0632
[11/11 17:22:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.49	
[11/11 17:22:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/11 17:29:19 visual_prompt]: Epoch 37 / 100: avg data time: 1.09e+01, avg batch time: 11.2294, average train loss: 3.3210
[11/11 17:30:04 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1559, average loss: 0.7428
[11/11 17:30:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.30	
[11/11 17:30:04 visual_prompt]: Best epoch 37: best metric: -0.743
[11/11 17:30:04 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/11 17:36:33 visual_prompt]: Epoch 38 / 100: avg data time: 1.08e+01, avg batch time: 11.1242, average train loss: 5.5798
[11/11 17:37:19 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.1590, average loss: 12.7927
[11/11 17:37:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.45	
[11/11 17:37:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/11 17:43:59 visual_prompt]: Epoch 39 / 100: avg data time: 1.11e+01, avg batch time: 11.4173, average train loss: 4.1570
[11/11 17:44:44 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1573, average loss: 1.1013
[11/11 17:44:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.71	
[11/11 17:44:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/11 17:51:23 visual_prompt]: Epoch 40 / 100: avg data time: 1.10e+01, avg batch time: 11.3782, average train loss: 3.4442
[11/11 17:52:08 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1559, average loss: 8.1567
[11/11 17:52:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.98	
[11/11 17:52:08 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/11 17:58:46 visual_prompt]: Epoch 41 / 100: avg data time: 1.10e+01, avg batch time: 11.3543, average train loss: 9.2249
[11/11 17:59:31 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1546, average loss: 10.6064
[11/11 17:59:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.92	
[11/11 17:59:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/11 18:06:08 visual_prompt]: Epoch 42 / 100: avg data time: 1.10e+01, avg batch time: 11.3460, average train loss: 6.2021
[11/11 18:06:53 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1544, average loss: 1.6613
[11/11 18:06:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.35	
[11/11 18:06:53 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/11 18:13:28 visual_prompt]: Epoch 43 / 100: avg data time: 1.09e+01, avg batch time: 11.2799, average train loss: 3.4158
[11/11 18:14:13 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1548, average loss: 0.6947
[11/11 18:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 46.71	
[11/11 18:14:13 visual_prompt]: Best epoch 43: best metric: -0.695
[11/11 18:14:13 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/11 18:20:47 visual_prompt]: Epoch 44 / 100: avg data time: 1.09e+01, avg batch time: 11.2340, average train loss: 2.4045
[11/11 18:21:32 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1553, average loss: 0.7049
[11/11 18:21:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.29	
[11/11 18:21:32 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/11 18:28:07 visual_prompt]: Epoch 45 / 100: avg data time: 1.09e+01, avg batch time: 11.2851, average train loss: 5.3100
[11/11 18:28:52 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1546, average loss: 4.2059
[11/11 18:28:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.13	
[11/11 18:28:52 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/11 18:35:26 visual_prompt]: Epoch 46 / 100: avg data time: 1.09e+01, avg batch time: 11.2522, average train loss: 6.0354
[11/11 18:36:11 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1552, average loss: 1.7217
[11/11 18:36:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.76	
[11/11 18:36:11 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/11 18:42:44 visual_prompt]: Epoch 47 / 100: avg data time: 1.09e+01, avg batch time: 11.2201, average train loss: 3.0396
[11/11 18:43:29 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.1549, average loss: 4.8443
[11/11 18:43:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.57	
[11/11 18:43:29 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/11 18:50:03 visual_prompt]: Epoch 48 / 100: avg data time: 1.09e+01, avg batch time: 11.2604, average train loss: 2.1457
[11/11 18:50:48 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1549, average loss: 1.8329
[11/11 18:50:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.62	
[11/11 18:50:48 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/11 18:57:21 visual_prompt]: Epoch 49 / 100: avg data time: 1.09e+01, avg batch time: 11.2413, average train loss: 3.0448
[11/11 18:58:06 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1545, average loss: 3.7563
[11/11 18:58:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.70	
[11/11 18:58:06 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/11 19:04:40 visual_prompt]: Epoch 50 / 100: avg data time: 1.09e+01, avg batch time: 11.2326, average train loss: 10.0050
[11/11 19:05:25 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1566, average loss: 9.5719
[11/11 19:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.57	
[11/11 19:05:25 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/11 19:11:53 visual_prompt]: Epoch 51 / 100: avg data time: 1.07e+01, avg batch time: 11.0865, average train loss: 3.0375
[11/11 19:12:37 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1545, average loss: 4.3539
[11/11 19:12:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.87	
[11/11 19:12:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/11 19:19:16 visual_prompt]: Epoch 52 / 100: avg data time: 1.11e+01, avg batch time: 11.4152, average train loss: 1.5751
[11/11 19:20:02 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1546, average loss: 0.7672
[11/11 19:20:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.44	
[11/11 19:20:02 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/11 19:26:40 visual_prompt]: Epoch 53 / 100: avg data time: 1.10e+01, avg batch time: 11.3803, average train loss: 0.8953
[11/11 19:27:26 visual_prompt]: Inference (val):avg data time: 4.07e-05, avg batch time: 0.1548, average loss: 1.5726
[11/11 19:27:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.46	
[11/11 19:27:26 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/11 19:34:02 visual_prompt]: Epoch 54 / 100: avg data time: 1.10e+01, avg batch time: 11.3291, average train loss: 2.0552
[11/11 19:34:47 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1548, average loss: 0.7511
[11/11 19:34:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.96	
[11/11 19:34:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/11 19:41:23 visual_prompt]: Epoch 55 / 100: avg data time: 1.09e+01, avg batch time: 11.2856, average train loss: 1.0399
[11/11 19:42:08 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1549, average loss: 1.8825
[11/11 19:42:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.25	
[11/11 19:42:08 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/11 19:48:43 visual_prompt]: Epoch 56 / 100: avg data time: 1.09e+01, avg batch time: 11.2807, average train loss: 1.0287
[11/11 19:49:28 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1547, average loss: 0.9585
[11/11 19:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.54	
[11/11 19:49:28 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/11 19:56:02 visual_prompt]: Epoch 57 / 100: avg data time: 1.09e+01, avg batch time: 11.2549, average train loss: 0.9158
[11/11 19:56:47 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.1576, average loss: 2.0755
[11/11 19:56:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.27	
[11/11 19:56:47 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/11 20:03:22 visual_prompt]: Epoch 58 / 100: avg data time: 1.09e+01, avg batch time: 11.2774, average train loss: 2.3462
[11/11 20:04:07 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1583, average loss: 2.5344
[11/11 20:04:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.64	
[11/11 20:04:07 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/11 20:10:40 visual_prompt]: Epoch 59 / 100: avg data time: 1.09e+01, avg batch time: 11.2263, average train loss: 2.8902
[11/11 20:11:25 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1550, average loss: 4.6763
[11/11 20:11:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/11 20:11:25 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/11 20:17:59 visual_prompt]: Epoch 60 / 100: avg data time: 1.09e+01, avg batch time: 11.2503, average train loss: 1.4644
[11/11 20:18:44 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1551, average loss: 1.4661
[11/11 20:18:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.44	
[11/11 20:18:44 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[11/11 20:25:17 visual_prompt]: Epoch 61 / 100: avg data time: 1.09e+01, avg batch time: 11.2365, average train loss: 1.1985
[11/11 20:26:02 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1552, average loss: 0.7946
[11/11 20:26:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.89	
[11/11 20:26:02 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[11/11 20:32:37 visual_prompt]: Epoch 62 / 100: avg data time: 1.09e+01, avg batch time: 11.2704, average train loss: 0.8959
[11/11 20:33:21 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.1546, average loss: 0.6883
[11/11 20:33:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.62	
[11/11 20:33:21 visual_prompt]: Best epoch 62: best metric: -0.688
[11/11 20:33:21 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[11/11 20:39:55 visual_prompt]: Epoch 63 / 100: avg data time: 1.09e+01, avg batch time: 11.2385, average train loss: 0.8355
[11/11 20:40:40 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1553, average loss: 0.6882
[11/11 20:40:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.94	
[11/11 20:40:40 visual_prompt]: Best epoch 63: best metric: -0.688
[11/11 20:40:40 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[11/11 20:47:16 visual_prompt]: Epoch 64 / 100: avg data time: 1.10e+01, avg batch time: 11.3101, average train loss: 0.7840
[11/11 20:48:01 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1547, average loss: 0.7039
[11/11 20:48:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.59	
[11/11 20:48:01 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[11/11 20:54:30 visual_prompt]: Epoch 65 / 100: avg data time: 1.08e+01, avg batch time: 11.1180, average train loss: 0.8468
[11/11 20:55:16 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1567, average loss: 0.7213
[11/11 20:55:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.39	
[11/11 20:55:16 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[11/11 21:01:56 visual_prompt]: Epoch 66 / 100: avg data time: 1.11e+01, avg batch time: 11.4224, average train loss: 0.8054
[11/11 21:02:41 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1551, average loss: 0.7028
[11/11 21:02:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.57	
[11/11 21:02:41 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[11/11 21:09:19 visual_prompt]: Epoch 67 / 100: avg data time: 1.10e+01, avg batch time: 11.3672, average train loss: 0.7846
[11/11 21:10:04 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1548, average loss: 0.8610
[11/11 21:10:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.36	
[11/11 21:10:04 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[11/11 21:16:41 visual_prompt]: Epoch 68 / 100: avg data time: 1.10e+01, avg batch time: 11.3188, average train loss: 0.7558
[11/11 21:17:26 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1559, average loss: 0.7187
[11/11 21:17:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.72	
[11/11 21:17:26 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[11/11 21:24:04 visual_prompt]: Epoch 69 / 100: avg data time: 1.10e+01, avg batch time: 11.3625, average train loss: 0.7851
[11/11 21:24:49 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1545, average loss: 0.8859
[11/11 21:24:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.40	
[11/11 21:24:49 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[11/11 21:31:24 visual_prompt]: Epoch 70 / 100: avg data time: 1.09e+01, avg batch time: 11.2884, average train loss: 0.7541
[11/11 21:32:10 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.1544, average loss: 0.8784
[11/11 21:32:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.55	
[11/11 21:32:10 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[11/11 21:38:44 visual_prompt]: Epoch 71 / 100: avg data time: 1.09e+01, avg batch time: 11.2674, average train loss: 0.7446
[11/11 21:39:29 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1548, average loss: 0.6893
[11/11 21:39:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.92	
[11/11 21:39:29 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[11/11 21:46:03 visual_prompt]: Epoch 72 / 100: avg data time: 1.09e+01, avg batch time: 11.2581, average train loss: 0.7031
[11/11 21:46:48 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1551, average loss: 0.7825
[11/11 21:46:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/11 21:46:48 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[11/11 21:53:22 visual_prompt]: Epoch 73 / 100: avg data time: 1.09e+01, avg batch time: 11.2538, average train loss: 0.7424
[11/11 21:54:07 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1547, average loss: 0.6903
[11/11 21:54:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.83	
[11/11 21:54:07 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[11/11 22:00:41 visual_prompt]: Epoch 74 / 100: avg data time: 1.09e+01, avg batch time: 11.2454, average train loss: 0.7915
[11/11 22:01:26 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1547, average loss: 0.6865
[11/11 22:01:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.76	
[11/11 22:01:26 visual_prompt]: Best epoch 74: best metric: -0.687
[11/11 22:01:26 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[11/11 22:07:59 visual_prompt]: Epoch 75 / 100: avg data time: 1.09e+01, avg batch time: 11.2347, average train loss: 0.9023
[11/11 22:08:44 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1546, average loss: 1.0938
[11/11 22:08:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.64	
[11/11 22:08:44 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[11/11 22:15:17 visual_prompt]: Epoch 76 / 100: avg data time: 1.09e+01, avg batch time: 11.2295, average train loss: 0.8392
[11/11 22:16:02 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1587, average loss: 0.7108
[11/11 22:16:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.37	
[11/11 22:16:02 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[11/11 22:22:36 visual_prompt]: Epoch 77 / 100: avg data time: 1.09e+01, avg batch time: 11.2453, average train loss: 0.7471
[11/11 22:23:21 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1548, average loss: 0.8385
[11/11 22:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.29	
[11/11 22:23:21 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[11/11 22:29:51 visual_prompt]: Epoch 78 / 100: avg data time: 1.08e+01, avg batch time: 11.1278, average train loss: 0.7394
[11/11 22:30:35 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1547, average loss: 0.6998
[11/11 22:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.70	
[11/11 22:30:35 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[11/11 22:37:15 visual_prompt]: Epoch 79 / 100: avg data time: 1.11e+01, avg batch time: 11.4181, average train loss: 0.7312
[11/11 22:38:01 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1547, average loss: 0.6843
[11/11 22:38:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 54.85	
[11/11 22:38:01 visual_prompt]: Best epoch 79: best metric: -0.684
[11/11 22:38:01 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[11/11 22:44:40 visual_prompt]: Epoch 80 / 100: avg data time: 1.10e+01, avg batch time: 11.3969, average train loss: 0.6928
[11/11 22:45:25 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1552, average loss: 0.7502
[11/11 22:45:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.37	
[11/11 22:45:25 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[11/11 22:52:03 visual_prompt]: Epoch 81 / 100: avg data time: 1.10e+01, avg batch time: 11.3599, average train loss: 0.7271
[11/11 22:52:48 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1549, average loss: 0.7084
[11/11 22:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.03	
[11/11 22:52:48 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[11/11 22:59:25 visual_prompt]: Epoch 82 / 100: avg data time: 1.10e+01, avg batch time: 11.3393, average train loss: 0.7460
[11/11 23:00:11 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1548, average loss: 0.6922
[11/11 23:00:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.86	
[11/11 23:00:11 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[11/11 23:06:46 visual_prompt]: Epoch 83 / 100: avg data time: 1.09e+01, avg batch time: 11.2890, average train loss: 0.7128
[11/11 23:07:31 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1546, average loss: 0.6889
[11/11 23:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.89	
[11/11 23:07:31 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[11/11 23:14:05 visual_prompt]: Epoch 84 / 100: avg data time: 1.09e+01, avg batch time: 11.2451, average train loss: 0.7122
[11/11 23:14:50 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1547, average loss: 0.7336
[11/11 23:14:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.91	
[11/11 23:14:50 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[11/11 23:21:24 visual_prompt]: Epoch 85 / 100: avg data time: 1.09e+01, avg batch time: 11.2610, average train loss: 0.7195
[11/11 23:22:09 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1586, average loss: 0.6904
[11/11 23:22:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.18	
[11/11 23:22:09 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[11/11 23:28:44 visual_prompt]: Epoch 86 / 100: avg data time: 1.09e+01, avg batch time: 11.2874, average train loss: 0.7037
[11/11 23:29:29 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1546, average loss: 0.7038
[11/11 23:29:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.66	
[11/11 23:29:29 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[11/11 23:36:02 visual_prompt]: Epoch 87 / 100: avg data time: 1.09e+01, avg batch time: 11.2241, average train loss: 0.7065
[11/11 23:36:47 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1545, average loss: 0.6939
[11/11 23:36:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.05	
[11/11 23:36:47 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[11/11 23:43:21 visual_prompt]: Epoch 88 / 100: avg data time: 1.09e+01, avg batch time: 11.2399, average train loss: 0.6938
[11/11 23:44:06 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1548, average loss: 0.6897
[11/11 23:44:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/11 23:44:06 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[11/11 23:50:40 visual_prompt]: Epoch 89 / 100: avg data time: 1.09e+01, avg batch time: 11.2558, average train loss: 0.6890
[11/11 23:51:25 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1546, average loss: 0.6915
[11/11 23:51:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.72	
[11/11 23:51:25 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[11/11 23:57:57 visual_prompt]: Epoch 90 / 100: avg data time: 1.09e+01, avg batch time: 11.2104, average train loss: 0.6907
[11/11 23:58:42 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1548, average loss: 0.6910
[11/11 23:58:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.24	
[11/11 23:58:42 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[11/12 00:05:15 visual_prompt]: Epoch 91 / 100: avg data time: 1.09e+01, avg batch time: 11.2169, average train loss: 0.6958
[11/12 00:06:00 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1545, average loss: 0.6897
[11/12 00:06:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.93	
[11/12 00:06:00 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[11/12 00:12:29 visual_prompt]: Epoch 92 / 100: avg data time: 1.08e+01, avg batch time: 11.1285, average train loss: 0.6912
[11/12 00:13:15 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1548, average loss: 0.6880
[11/12 00:13:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.93	
[11/12 00:13:15 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[11/12 00:19:52 visual_prompt]: Epoch 93 / 100: avg data time: 1.10e+01, avg batch time: 11.3434, average train loss: 0.6910
[11/12 00:20:37 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.1548, average loss: 0.6946
[11/12 00:20:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.77	
[11/12 00:20:37 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[11/12 00:27:12 visual_prompt]: Epoch 94 / 100: avg data time: 1.09e+01, avg batch time: 11.2829, average train loss: 0.6917
[11/12 00:27:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1549, average loss: 0.6943
[11/12 00:27:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.30	
[11/12 00:27:58 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[11/12 00:34:33 visual_prompt]: Epoch 95 / 100: avg data time: 1.09e+01, avg batch time: 11.2987, average train loss: 0.6950
[11/12 00:35:18 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1547, average loss: 0.6884
[11/12 00:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.29	
[11/12 00:35:18 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[11/12 00:41:53 visual_prompt]: Epoch 96 / 100: avg data time: 1.09e+01, avg batch time: 11.2793, average train loss: 0.6883
[11/12 00:42:38 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1548, average loss: 0.6879
[11/12 00:42:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.03	
[11/12 00:42:38 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[11/12 00:49:13 visual_prompt]: Epoch 97 / 100: avg data time: 1.09e+01, avg batch time: 11.2745, average train loss: 0.6888
[11/12 00:49:58 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1547, average loss: 0.6879
[11/12 00:49:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.73	
[11/12 00:49:58 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[11/12 00:56:31 visual_prompt]: Epoch 98 / 100: avg data time: 1.09e+01, avg batch time: 11.2212, average train loss: 0.6880
[11/12 00:57:16 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.1548, average loss: 0.6872
[11/12 00:57:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/12 00:57:16 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[11/12 01:03:46 visual_prompt]: Epoch 99 / 100: avg data time: 1.08e+01, avg batch time: 11.1522, average train loss: 0.6876
[11/12 01:04:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1581, average loss: 0.6871
[11/12 01:04:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/12 01:04:31 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[11/12 01:11:03 visual_prompt]: Epoch 100 / 100: avg data time: 1.08e+01, avg batch time: 11.1975, average train loss: 0.6872
[11/12 01:11:48 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1548, average loss: 0.6870
[11/12 01:11:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/12 01:11:48 visual_prompt]: Stopping early.
[11/12 01:11:48 visual_prompt]: Rank of current process: 0. World size: 1
[11/12 01:11:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 01:11:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/12 01:11:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/12 01:11:48 visual_prompt]: Training with config:
[11/12 01:11:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/12 01:11:48 visual_prompt]: Loading training data...
[11/12 01:11:48 visual_prompt]: Constructing mammo-cbis dataset train...
[11/12 01:11:48 visual_prompt]: Loading validation data...
[11/12 01:11:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/12 01:11:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/12 01:11:51 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/12 01:11:51 visual_prompt]: tuned percent:0.536
[11/12 01:11:51 visual_prompt]: Device used for model: 0
[11/12 01:11:51 visual_prompt]: Setting up Evaluator...
[11/12 01:11:51 visual_prompt]: Setting up Trainer...
[11/12 01:11:51 visual_prompt]: 	Setting up the optimizer...
[11/12 01:11:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/12 01:18:24 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.2315, average train loss: 1.4017
[11/12 01:19:09 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.1551, average loss: 1.2969
[11/12 01:19:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/12 01:19:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/12 01:25:40 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1780, average train loss: 5.9467
[11/12 01:26:25 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1550, average loss: 1.1333
[11/12 01:26:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/12 01:26:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/12 01:32:57 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1993, average train loss: 0.9754
[11/12 01:33:41 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1545, average loss: 0.6982
[11/12 01:33:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 58.32	
[11/12 01:33:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/12 01:40:13 visual_prompt]: Epoch 4 / 100: avg data time: 1.08e+01, avg batch time: 11.1897, average train loss: 2.6569
[11/12 01:40:58 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1546, average loss: 0.9267
[11/12 01:40:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.34	
[11/12 01:40:58 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/12 01:47:29 visual_prompt]: Epoch 5 / 100: avg data time: 1.08e+01, avg batch time: 11.1897, average train loss: 6.1755
[11/12 01:48:14 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1546, average loss: 5.0799
[11/12 01:48:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[11/12 01:48:14 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/12 01:54:46 visual_prompt]: Epoch 6 / 100: avg data time: 1.08e+01, avg batch time: 11.1908, average train loss: 4.4714
[11/12 01:55:31 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1579, average loss: 4.5129
[11/12 01:55:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.92	
[11/12 01:55:31 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/12 02:02:02 visual_prompt]: Epoch 7 / 100: avg data time: 1.08e+01, avg batch time: 11.1908, average train loss: 3.5116
[11/12 02:02:48 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.1549, average loss: 3.4072
[11/12 02:02:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.30	
[11/12 02:02:48 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/12 02:09:26 visual_prompt]: Epoch 8 / 100: avg data time: 1.10e+01, avg batch time: 11.3622, average train loss: 2.0414
[11/12 02:10:11 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1548, average loss: 0.8509
[11/12 02:10:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.58	
[11/12 02:10:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/12 02:16:49 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.3763, average train loss: 1.5073
[11/12 02:17:34 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1556, average loss: 0.7142
[11/12 02:17:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/12 02:17:34 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/12 02:24:10 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e+01, avg batch time: 11.2980, average train loss: 1.4093
[11/12 02:24:55 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1548, average loss: 0.7343
[11/12 02:24:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.23	
[11/12 02:24:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/12 02:31:31 visual_prompt]: Epoch 11 / 100: avg data time: 1.09e+01, avg batch time: 11.3023, average train loss: 0.8321
[11/12 02:32:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1567, average loss: 1.1717
[11/12 02:32:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.85	
[11/12 02:32:16 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/12 02:38:50 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2620, average train loss: 1.9024
[11/12 02:39:35 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1585, average loss: 3.1157
[11/12 02:39:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.43	
[11/12 02:39:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/12 02:46:10 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2714, average train loss: 5.6455
[11/12 02:46:55 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1546, average loss: 5.9497
[11/12 02:46:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.85	
[11/12 02:46:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/12 02:53:27 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.2066, average train loss: 4.6794
[11/12 02:54:12 visual_prompt]: Inference (val):avg data time: 3.95e-05, avg batch time: 0.1554, average loss: 2.4449
[11/12 02:54:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.18	
[11/12 02:54:12 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/12 03:00:44 visual_prompt]: Epoch 15 / 100: avg data time: 1.09e+01, avg batch time: 11.2094, average train loss: 3.0954
[11/12 03:01:29 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1544, average loss: 6.1072
[11/12 03:01:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.36	
[11/12 03:01:29 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/12 03:08:00 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e+01, avg batch time: 11.1592, average train loss: 2.9854
[11/12 03:08:45 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1546, average loss: 1.7035
[11/12 03:08:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.93	
[11/12 03:08:45 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/12 03:15:18 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e+01, avg batch time: 11.2296, average train loss: 6.3599
[11/12 03:16:03 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1549, average loss: 2.1592
[11/12 03:16:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.12	
[11/12 03:16:03 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/12 03:22:36 visual_prompt]: Epoch 18 / 100: avg data time: 1.09e+01, avg batch time: 11.2219, average train loss: 4.1144
[11/12 03:23:20 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.1549, average loss: 1.3735
[11/12 03:23:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.52	
[11/12 03:23:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/12 03:29:53 visual_prompt]: Epoch 19 / 100: avg data time: 1.08e+01, avg batch time: 11.2012, average train loss: 3.0397
[11/12 03:30:38 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1545, average loss: 4.1696
[11/12 03:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.08	
[11/12 03:30:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/12 03:37:11 visual_prompt]: Epoch 20 / 100: avg data time: 1.09e+01, avg batch time: 11.2251, average train loss: 1.3940
[11/12 03:37:56 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.1543, average loss: 1.1525
[11/12 03:37:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.26	
[11/12 03:37:56 visual_prompt]: Best epoch 20: best metric: -1.153
[11/12 03:37:56 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/12 03:44:26 visual_prompt]: Epoch 21 / 100: avg data time: 1.08e+01, avg batch time: 11.1418, average train loss: 0.9245
[11/12 03:45:09 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1542, average loss: 0.8057
[11/12 03:45:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.75	
[11/12 03:45:09 visual_prompt]: Best epoch 21: best metric: -0.806
[11/12 03:45:09 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/12 03:51:46 visual_prompt]: Epoch 22 / 100: avg data time: 1.10e+01, avg batch time: 11.3384, average train loss: 2.7062
[11/12 03:52:32 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1548, average loss: 1.6460
[11/12 03:52:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.98	
[11/12 03:52:32 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/12 03:59:11 visual_prompt]: Epoch 23 / 100: avg data time: 1.10e+01, avg batch time: 11.3868, average train loss: 0.9325
[11/12 03:59:56 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1546, average loss: 1.3452
[11/12 03:59:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.50	
[11/12 03:59:56 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/12 04:06:34 visual_prompt]: Epoch 24 / 100: avg data time: 1.10e+01, avg batch time: 11.3718, average train loss: 1.5379
[11/12 04:07:19 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1547, average loss: 0.8825
[11/12 04:07:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.15	
[11/12 04:07:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/12 04:13:56 visual_prompt]: Epoch 25 / 100: avg data time: 1.10e+01, avg batch time: 11.3246, average train loss: 1.2776
[11/12 04:14:41 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1546, average loss: 1.1996
[11/12 04:14:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.92	
[11/12 04:14:41 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/12 04:21:17 visual_prompt]: Epoch 26 / 100: avg data time: 1.10e+01, avg batch time: 11.3088, average train loss: 1.4264
[11/12 04:22:02 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.1545, average loss: 0.8779
[11/12 04:22:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.53	
[11/12 04:22:02 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/12 04:28:37 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2888, average train loss: 1.3768
[11/12 04:29:22 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1548, average loss: 1.4372
[11/12 04:29:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.42	
[11/12 04:29:22 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/12 04:35:55 visual_prompt]: Epoch 28 / 100: avg data time: 1.09e+01, avg batch time: 11.2179, average train loss: 1.2243
[11/12 04:36:40 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.1587, average loss: 0.7395
[11/12 04:36:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.68	
[11/12 04:36:40 visual_prompt]: Best epoch 28: best metric: -0.740
[11/12 04:36:40 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/12 04:43:13 visual_prompt]: Epoch 29 / 100: avg data time: 1.09e+01, avg batch time: 11.2276, average train loss: 1.2927
[11/12 04:43:58 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1545, average loss: 1.8952
[11/12 04:43:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.85	
[11/12 04:43:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/12 04:50:31 visual_prompt]: Epoch 30 / 100: avg data time: 1.09e+01, avg batch time: 11.2314, average train loss: 1.0590
[11/12 04:51:16 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1564, average loss: 0.8016
[11/12 04:51:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/12 04:51:16 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/12 04:57:50 visual_prompt]: Epoch 31 / 100: avg data time: 1.09e+01, avg batch time: 11.2453, average train loss: 0.7884
[11/12 04:58:35 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1545, average loss: 1.6545
[11/12 04:58:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.24	
[11/12 04:58:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/12 05:05:09 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2678, average train loss: 2.4074
[11/12 05:05:54 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1546, average loss: 13.1580
[11/12 05:05:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.47	
[11/12 05:05:54 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/12 05:12:29 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2649, average train loss: 17.3763
[11/12 05:13:13 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1543, average loss: 19.2062
[11/12 05:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.79	
[11/12 05:13:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/12 05:19:47 visual_prompt]: Epoch 34 / 100: avg data time: 1.09e+01, avg batch time: 11.2323, average train loss: 9.1981
[11/12 05:20:31 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1553, average loss: 0.8509
[11/12 05:20:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.97	
[11/12 05:20:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 4.172826515897146
[11/12 05:26:58 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0421, average train loss: 7.2060
[11/12 05:27:44 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1582, average loss: 0.7542
[11/12 05:27:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.86	
[11/12 05:27:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 4.106969024216348
[11/12 05:34:23 visual_prompt]: Epoch 36 / 100: avg data time: 1.10e+01, avg batch time: 11.4031, average train loss: 4.5365
[11/12 05:35:09 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.1548, average loss: 2.0567
[11/12 05:35:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.30	
[11/12 05:35:09 visual_prompt]: Training 37 / 100 epoch, with learning rate 4.039153688314146
[11/12 05:41:47 visual_prompt]: Epoch 37 / 100: avg data time: 1.10e+01, avg batch time: 11.3697, average train loss: 6.1631
[11/12 05:42:32 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1549, average loss: 9.6908
[11/12 05:42:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.07	
[11/12 05:42:32 visual_prompt]: Training 38 / 100 epoch, with learning rate 3.969463130731183
[11/12 05:49:09 visual_prompt]: Epoch 38 / 100: avg data time: 1.10e+01, avg batch time: 11.3442, average train loss: 4.0604
[11/12 05:49:54 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1584, average loss: 6.0380
[11/12 05:49:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.11	
[11/12 05:49:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 3.897982258676867
[11/12 05:56:30 visual_prompt]: Epoch 39 / 100: avg data time: 1.09e+01, avg batch time: 11.2899, average train loss: 5.4763
[11/12 05:57:15 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1544, average loss: 9.1300
[11/12 05:57:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.55	
[11/12 05:57:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 3.824798160583012
[11/12 06:03:49 visual_prompt]: Epoch 40 / 100: avg data time: 1.09e+01, avg batch time: 11.2664, average train loss: 2.4046
[11/12 06:04:34 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1581, average loss: 0.7658
[11/12 06:04:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/12 06:04:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 3.75
[11/12 06:11:07 visual_prompt]: Epoch 41 / 100: avg data time: 1.09e+01, avg batch time: 11.2339, average train loss: 1.1717
[11/12 06:11:53 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1547, average loss: 4.7006
[11/12 06:11:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.47	
[11/12 06:11:53 visual_prompt]: Training 42 / 100 epoch, with learning rate 3.673678906964727
[11/12 06:18:27 visual_prompt]: Epoch 42 / 100: avg data time: 1.09e+01, avg batch time: 11.2737, average train loss: 2.0221
[11/12 06:19:12 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1547, average loss: 1.2353
[11/12 06:19:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[11/12 06:19:12 visual_prompt]: Training 43 / 100 epoch, with learning rate 3.5959278669726933
[11/12 06:25:46 visual_prompt]: Epoch 43 / 100: avg data time: 1.09e+01, avg batch time: 11.2564, average train loss: 1.5781
[11/12 06:26:31 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1545, average loss: 3.5288
[11/12 06:26:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.83	
[11/12 06:26:31 visual_prompt]: Training 44 / 100 epoch, with learning rate 3.516841607689501
[11/12 06:33:05 visual_prompt]: Epoch 44 / 100: avg data time: 1.09e+01, avg batch time: 11.2489, average train loss: 1.2657
[11/12 06:33:50 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1545, average loss: 0.6883
[11/12 06:33:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.45	
[11/12 06:33:50 visual_prompt]: Best epoch 44: best metric: -0.688
[11/12 06:33:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 3.4365164835397803
[11/12 06:40:24 visual_prompt]: Epoch 45 / 100: avg data time: 1.09e+01, avg batch time: 11.2528, average train loss: 0.8758
[11/12 06:41:09 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1572, average loss: 0.7086
[11/12 06:41:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.42	
[11/12 06:41:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 3.3550503583141724
[11/12 06:47:42 visual_prompt]: Epoch 46 / 100: avg data time: 1.09e+01, avg batch time: 11.2423, average train loss: 0.7905
[11/12 06:48:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1550, average loss: 0.8919
[11/12 06:48:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.99	
[11/12 06:48:27 visual_prompt]: Training 47 / 100 epoch, with learning rate 3.2725424859373686
[11/12 06:55:01 visual_prompt]: Epoch 47 / 100: avg data time: 1.09e+01, avg batch time: 11.2457, average train loss: 0.8797
[11/12 06:55:46 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1573, average loss: 1.3697
[11/12 06:55:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.82	
[11/12 06:55:46 visual_prompt]: Training 48 / 100 epoch, with learning rate 3.1890933895424975
[11/12 07:02:19 visual_prompt]: Epoch 48 / 100: avg data time: 1.09e+01, avg batch time: 11.2357, average train loss: 1.1035
[11/12 07:03:04 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1547, average loss: 0.7053
[11/12 07:03:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.71	
[11/12 07:03:04 visual_prompt]: Training 49 / 100 epoch, with learning rate 3.104804738999169
[11/12 07:09:40 visual_prompt]: Epoch 49 / 100: avg data time: 1.10e+01, avg batch time: 11.3100, average train loss: 0.9109
[11/12 07:10:26 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1557, average loss: 0.7050
[11/12 07:10:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.75	
[11/12 07:10:26 visual_prompt]: Training 50 / 100 epoch, with learning rate 3.019779227044398
[11/12 07:17:04 visual_prompt]: Epoch 50 / 100: avg data time: 1.10e+01, avg batch time: 11.3844, average train loss: 0.8231
[11/12 07:17:50 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1549, average loss: 0.7678
[11/12 07:17:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.04	
[11/12 07:17:50 visual_prompt]: Training 51 / 100 epoch, with learning rate 2.934120444167326
[11/12 07:24:27 visual_prompt]: Epoch 51 / 100: avg data time: 1.10e+01, avg batch time: 11.3372, average train loss: 0.7489
[11/12 07:25:12 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1548, average loss: 0.6888
[11/12 07:25:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/12 07:25:12 visual_prompt]: Training 52 / 100 epoch, with learning rate 2.8479327524001636
[11/12 07:31:49 visual_prompt]: Epoch 52 / 100: avg data time: 1.10e+01, avg batch time: 11.3329, average train loss: 0.7723
[11/12 07:32:35 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1545, average loss: 1.0445
[11/12 07:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.12	
[11/12 07:32:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 2.761321158169134
[11/12 07:39:10 visual_prompt]: Epoch 53 / 100: avg data time: 1.09e+01, avg batch time: 11.2925, average train loss: 0.9462
[11/12 07:39:55 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1548, average loss: 0.7638
[11/12 07:39:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.91	
[11/12 07:39:55 visual_prompt]: Training 54 / 100 epoch, with learning rate 2.6743911843603128
[11/12 07:46:30 visual_prompt]: Epoch 54 / 100: avg data time: 1.09e+01, avg batch time: 11.2789, average train loss: 0.9740
[11/12 07:47:15 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1575, average loss: 0.8245
[11/12 07:47:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.85	
[11/12 07:47:15 visual_prompt]: Training 55 / 100 epoch, with learning rate 2.5872487417562526
[11/12 07:53:49 visual_prompt]: Epoch 55 / 100: avg data time: 1.09e+01, avg batch time: 11.2624, average train loss: 1.1303
[11/12 07:54:34 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1580, average loss: 0.6902
[11/12 07:54:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.51	
[11/12 07:54:34 visual_prompt]: Training 56 / 100 epoch, with learning rate 2.5
[11/12 08:01:07 visual_prompt]: Epoch 56 / 100: avg data time: 1.09e+01, avg batch time: 11.2253, average train loss: 0.7859
[11/12 08:01:52 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1547, average loss: 0.6923
[11/12 08:01:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.26	
[11/12 08:01:52 visual_prompt]: Training 57 / 100 epoch, with learning rate 2.4127512582437483
[11/12 08:08:27 visual_prompt]: Epoch 57 / 100: avg data time: 1.09e+01, avg batch time: 11.2762, average train loss: 0.8396
[11/12 08:09:12 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1548, average loss: 1.3671
[11/12 08:09:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.46	
[11/12 08:09:12 visual_prompt]: Training 58 / 100 epoch, with learning rate 2.325608815639687
[11/12 08:15:47 visual_prompt]: Epoch 58 / 100: avg data time: 1.09e+01, avg batch time: 11.2827, average train loss: 0.7848
[11/12 08:16:32 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1566, average loss: 1.0587
[11/12 08:16:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.21	
[11/12 08:16:32 visual_prompt]: Training 59 / 100 epoch, with learning rate 2.2386788418308665
[11/12 08:23:07 visual_prompt]: Epoch 59 / 100: avg data time: 1.09e+01, avg batch time: 11.2700, average train loss: 0.8527
[11/12 08:23:52 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1547, average loss: 0.6984
[11/12 08:23:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.59	
[11/12 08:23:52 visual_prompt]: Training 60 / 100 epoch, with learning rate 2.1520672475998373
[11/12 08:30:25 visual_prompt]: Epoch 60 / 100: avg data time: 1.09e+01, avg batch time: 11.2320, average train loss: 0.7458
[11/12 08:31:10 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1552, average loss: 1.0016
[11/12 08:31:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 37.18	
[11/12 08:31:10 visual_prompt]: Training 61 / 100 epoch, with learning rate 2.0658795558326744
[11/12 08:37:43 visual_prompt]: Epoch 61 / 100: avg data time: 1.09e+01, avg batch time: 11.2315, average train loss: 0.7350
[11/12 08:38:28 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1584, average loss: 0.6883
[11/12 08:38:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[11/12 08:38:28 visual_prompt]: Best epoch 61: best metric: -0.688
[11/12 08:38:28 visual_prompt]: Training 62 / 100 epoch, with learning rate 1.980220772955602
[11/12 08:44:59 visual_prompt]: Epoch 62 / 100: avg data time: 1.08e+01, avg batch time: 11.1515, average train loss: 0.8248
[11/12 08:45:43 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1546, average loss: 0.6997
[11/12 08:45:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.45	
[11/12 08:45:43 visual_prompt]: Training 63 / 100 epoch, with learning rate 1.895195261000831
[11/12 08:52:23 visual_prompt]: Epoch 63 / 100: avg data time: 1.11e+01, avg batch time: 11.4063, average train loss: 0.7470
[11/12 08:53:08 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1547, average loss: 0.6960
[11/12 08:53:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.56	
[11/12 08:53:08 visual_prompt]: Training 64 / 100 epoch, with learning rate 1.8109066104575022
[11/12 08:59:46 visual_prompt]: Epoch 64 / 100: avg data time: 1.10e+01, avg batch time: 11.3623, average train loss: 0.7867
[11/12 09:00:31 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1550, average loss: 0.7102
[11/12 09:00:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/12 09:00:31 visual_prompt]: Training 65 / 100 epoch, with learning rate 1.7274575140626316
[11/12 09:07:08 visual_prompt]: Epoch 65 / 100: avg data time: 1.10e+01, avg batch time: 11.3269, average train loss: 0.7641
[11/12 09:07:53 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1548, average loss: 0.7450
[11/12 09:07:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.05	
[11/12 09:07:53 visual_prompt]: Training 66 / 100 epoch, with learning rate 1.6449496416858285
[11/12 09:14:31 visual_prompt]: Epoch 66 / 100: avg data time: 1.10e+01, avg batch time: 11.3600, average train loss: 0.7267
[11/12 09:15:16 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1567, average loss: 0.7563
[11/12 09:15:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/12 09:15:16 visual_prompt]: Training 67 / 100 epoch, with learning rate 1.5634835164602199
[11/12 09:21:52 visual_prompt]: Epoch 67 / 100: avg data time: 1.10e+01, avg batch time: 11.3093, average train loss: 0.8136
[11/12 09:22:37 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1545, average loss: 1.0495
[11/12 09:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.79	
[11/12 09:22:37 visual_prompt]: Training 68 / 100 epoch, with learning rate 1.4831583923104998
[11/12 09:29:13 visual_prompt]: Epoch 68 / 100: avg data time: 1.09e+01, avg batch time: 11.2992, average train loss: 0.7546
[11/12 09:29:58 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.1551, average loss: 0.6799
[11/12 09:29:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 58.45	
[11/12 09:29:58 visual_prompt]: Best epoch 68: best metric: -0.680
[11/12 09:29:58 visual_prompt]: Training 69 / 100 epoch, with learning rate 1.4040721330273063
[11/12 09:36:32 visual_prompt]: Epoch 69 / 100: avg data time: 1.09e+01, avg batch time: 11.2634, average train loss: 0.7479
[11/12 09:37:17 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1583, average loss: 0.6860
[11/12 09:37:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.38	
[11/12 09:37:17 visual_prompt]: Training 70 / 100 epoch, with learning rate 1.3263210930352738
[11/12 09:43:51 visual_prompt]: Epoch 70 / 100: avg data time: 1.09e+01, avg batch time: 11.2424, average train loss: 0.7056
[11/12 09:44:36 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1547, average loss: 0.7865
[11/12 09:44:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/12 09:44:36 visual_prompt]: Training 71 / 100 epoch, with learning rate 1.2500000000000004
[11/12 09:51:09 visual_prompt]: Epoch 71 / 100: avg data time: 1.09e+01, avg batch time: 11.2372, average train loss: 0.7483
[11/12 09:51:54 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1559, average loss: 0.6899
[11/12 09:51:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 58.47	
[11/12 09:51:54 visual_prompt]: Training 72 / 100 epoch, with learning rate 1.175201839416988
[11/12 09:58:28 visual_prompt]: Epoch 72 / 100: avg data time: 1.09e+01, avg batch time: 11.2415, average train loss: 0.7259
[11/12 09:59:12 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1547, average loss: 0.6782
[11/12 09:59:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 60.39	
[11/12 09:59:12 visual_prompt]: Best epoch 72: best metric: -0.678
[11/12 09:59:12 visual_prompt]: Training 73 / 100 epoch, with learning rate 1.1020177413231333
[11/12 10:05:46 visual_prompt]: Epoch 73 / 100: avg data time: 1.09e+01, avg batch time: 11.2484, average train loss: 0.7110
[11/12 10:06:31 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1546, average loss: 0.7030
[11/12 10:06:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.39	
[11/12 10:06:31 visual_prompt]: Training 74 / 100 epoch, with learning rate 1.0305368692688175
[11/12 10:13:05 visual_prompt]: Epoch 74 / 100: avg data time: 1.09e+01, avg batch time: 11.2436, average train loss: 0.7380
[11/12 10:13:50 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1546, average loss: 0.7475
[11/12 10:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.96	
[11/12 10:13:50 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.9608463116858543
[11/12 10:20:23 visual_prompt]: Epoch 75 / 100: avg data time: 1.09e+01, avg batch time: 11.2374, average train loss: 0.7097
[11/12 10:21:08 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1547, average loss: 0.7093
[11/12 10:21:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 59.39	
[11/12 10:21:08 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.8930309757836516
[11/12 10:27:37 visual_prompt]: Epoch 76 / 100: avg data time: 1.08e+01, avg batch time: 11.1167, average train loss: 0.7264
[11/12 10:28:23 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1546, average loss: 0.7322
[11/12 10:28:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.75	
[11/12 10:28:23 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.8271734841028553
[11/12 10:35:02 visual_prompt]: Epoch 77 / 100: avg data time: 1.10e+01, avg batch time: 11.3989, average train loss: 0.7139
[11/12 10:35:47 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.1551, average loss: 0.6804
[11/12 10:35:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.19	
[11/12 10:35:47 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.7633540738525066
[11/12 10:42:25 visual_prompt]: Epoch 78 / 100: avg data time: 1.10e+01, avg batch time: 11.3597, average train loss: 0.7454
[11/12 10:43:10 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1552, average loss: 0.7222
[11/12 10:43:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/12 10:43:10 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.7016504991533725
[11/12 10:49:48 visual_prompt]: Epoch 79 / 100: avg data time: 1.10e+01, avg batch time: 11.3622, average train loss: 0.6710
[11/12 10:50:34 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.1567, average loss: 0.6752
[11/12 10:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 60.90	
[11/12 10:50:34 visual_prompt]: Best epoch 79: best metric: -0.675
[11/12 10:50:34 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.6421379363065141
[11/12 10:57:10 visual_prompt]: Epoch 80 / 100: avg data time: 1.10e+01, avg batch time: 11.3241, average train loss: 0.6852
[11/12 10:57:55 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1551, average loss: 0.9165
[11/12 10:57:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/12 10:57:55 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.5848888922025552
[11/12 11:04:31 visual_prompt]: Epoch 81 / 100: avg data time: 1.09e+01, avg batch time: 11.2984, average train loss: 0.6808
[11/12 11:05:16 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1549, average loss: 0.6710
[11/12 11:05:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 62.06	
[11/12 11:05:16 visual_prompt]: Best epoch 81: best metric: -0.671
[11/12 11:05:16 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.5299731159831953
[11/12 11:11:51 visual_prompt]: Epoch 82 / 100: avg data time: 1.09e+01, avg batch time: 11.2741, average train loss: 0.7142
[11/12 11:12:36 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1545, average loss: 0.6776
[11/12 11:12:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 60.43	
[11/12 11:12:36 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.47745751406263165
[11/12 11:19:10 visual_prompt]: Epoch 83 / 100: avg data time: 1.09e+01, avg batch time: 11.2499, average train loss: 0.6630
[11/12 11:19:54 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.1566, average loss: 0.6653
[11/12 11:19:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.14	
[11/12 11:19:54 visual_prompt]: Best epoch 83: best metric: -0.665
[11/12 11:19:54 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.42740606861239594
[11/12 11:26:29 visual_prompt]: Epoch 84 / 100: avg data time: 1.09e+01, avg batch time: 11.2636, average train loss: 0.6676
[11/12 11:27:14 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1547, average loss: 0.6693
[11/12 11:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.57	
[11/12 11:27:14 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.3798797596089351
[11/12 11:33:47 visual_prompt]: Epoch 85 / 100: avg data time: 1.09e+01, avg batch time: 11.2238, average train loss: 0.6688
[11/12 11:34:31 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1549, average loss: 0.6714
[11/12 11:34:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.26	
[11/12 11:34:31 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.33493649053890323
[11/12 11:41:05 visual_prompt]: Epoch 86 / 100: avg data time: 1.09e+01, avg batch time: 11.2530, average train loss: 0.6698
[11/12 11:41:50 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.1549, average loss: 0.6722
[11/12 11:41:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 62.48	
[11/12 11:41:50 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.29263101785268253
[11/12 11:48:23 visual_prompt]: Epoch 87 / 100: avg data time: 1.09e+01, avg batch time: 11.2217, average train loss: 0.6574
[11/12 11:49:08 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1577, average loss: 0.6843
[11/12 11:49:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 64.06	
[11/12 11:49:08 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.25301488425208296
[11/12 11:55:42 visual_prompt]: Epoch 88 / 100: avg data time: 1.09e+01, avg batch time: 11.2389, average train loss: 0.6611
[11/12 11:56:26 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.1550, average loss: 0.6675
[11/12 11:56:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.62	
[11/12 11:56:26 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.21613635589349756
[11/12 12:03:01 visual_prompt]: Epoch 89 / 100: avg data time: 1.09e+01, avg batch time: 11.2575, average train loss: 0.6441
[11/12 12:03:44 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1571, average loss: 0.6684
[11/12 12:03:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.14	
[11/12 12:03:44 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.18204036358303172
[11/12 12:10:17 visual_prompt]: Epoch 90 / 100: avg data time: 1.09e+01, avg batch time: 11.2057, average train loss: 0.6509
[11/12 12:11:02 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1548, average loss: 0.6797
[11/12 12:11:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 63.74	
[11/12 12:11:02 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.1507684480352292
[11/12 12:17:42 visual_prompt]: Epoch 91 / 100: avg data time: 1.11e+01, avg batch time: 11.4149, average train loss: 0.6601
[11/12 12:18:28 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.1547, average loss: 0.6648
[11/12 12:18:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.76	
[11/12 12:18:28 visual_prompt]: Best epoch 91: best metric: -0.665
[11/12 12:18:28 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.12235870926211617
[11/12 12:25:05 visual_prompt]: Epoch 92 / 100: avg data time: 1.10e+01, avg batch time: 11.3485, average train loss: 0.6390
[11/12 12:25:50 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1551, average loss: 0.6505
[11/12 12:25:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.79	
[11/12 12:25:50 visual_prompt]: Best epoch 92: best metric: -0.650
[11/12 12:25:50 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.09684576015420276
[11/12 12:32:27 visual_prompt]: Epoch 93 / 100: avg data time: 1.10e+01, avg batch time: 11.3183, average train loss: 0.6366
[11/12 12:33:12 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1550, average loss: 0.6558
[11/12 12:33:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.46	
[11/12 12:33:12 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.07426068431000882
[11/12 12:39:46 visual_prompt]: Epoch 94 / 100: avg data time: 1.09e+01, avg batch time: 11.2585, average train loss: 0.6390
[11/12 12:40:31 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1549, average loss: 0.6695
[11/12 12:40:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.01	
[11/12 12:40:31 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.05463099816548578
[11/12 12:47:06 visual_prompt]: Epoch 95 / 100: avg data time: 1.09e+01, avg batch time: 11.2864, average train loss: 0.6343
[11/12 12:47:51 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1546, average loss: 0.6571
[11/12 12:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 65.50	
[11/12 12:47:51 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.03798061746947995
[11/12 12:54:25 visual_prompt]: Epoch 96 / 100: avg data time: 1.09e+01, avg batch time: 11.2626, average train loss: 0.6231
[11/12 12:55:10 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1547, average loss: 0.6688
[11/12 12:55:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.95	
[11/12 12:55:10 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.024329828146074095
[11/12 13:01:45 visual_prompt]: Epoch 97 / 100: avg data time: 1.09e+01, avg batch time: 11.2788, average train loss: 0.6187
[11/12 13:02:30 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1564, average loss: 0.6621
[11/12 13:02:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.63	
[11/12 13:02:30 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.013695261579316775
[11/12 13:09:04 visual_prompt]: Epoch 98 / 100: avg data time: 1.09e+01, avg batch time: 11.2400, average train loss: 0.6149
[11/12 13:09:48 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.1585, average loss: 0.6638
[11/12 13:09:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 66.09	
[11/12 13:09:48 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.006089874350439506
[11/12 13:16:26 visual_prompt]: Epoch 99 / 100: avg data time: 1.10e+01, avg batch time: 11.3453, average train loss: 0.6094
[11/12 13:17:15 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1584, average loss: 0.6647
[11/12 13:17:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.85	
[11/12 13:17:15 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0015229324522605947
[11/12 13:23:59 visual_prompt]: Epoch 100 / 100: avg data time: 1.12e+01, avg batch time: 11.5299, average train loss: 0.6049
[11/12 13:24:44 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.1551, average loss: 0.6657
[11/12 13:24:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 65.75	
[11/12 13:24:44 visual_prompt]: Rank of current process: 0. World size: 1
[11/12 13:24:45 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 13:24:45 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/12 13:24:45 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/12 13:24:45 visual_prompt]: Training with config:
[11/12 13:24:45 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr5.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 5.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/12 13:24:45 visual_prompt]: Loading training data...
[11/12 13:24:45 visual_prompt]: Constructing mammo-cbis dataset train...
[11/12 13:24:45 visual_prompt]: Loading validation data...
[11/12 13:24:45 visual_prompt]: Constructing mammo-cbis dataset val...
[11/12 13:24:45 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/12 13:24:52 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/12 13:24:52 visual_prompt]: tuned percent:0.536
[11/12 13:24:52 visual_prompt]: Device used for model: 0
[11/12 13:24:52 visual_prompt]: Setting up Evaluator...
[11/12 13:24:52 visual_prompt]: Setting up Trainer...
[11/12 13:24:52 visual_prompt]: 	Setting up the optimizer...
[11/12 13:24:52 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/12 13:31:26 visual_prompt]: Epoch 1 / 100: avg data time: 1.09e+01, avg batch time: 11.2497, average train loss: 1.4017
[11/12 13:32:11 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1575, average loss: 1.2969
[11/12 13:32:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/12 13:32:11 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.5
[11/12 13:38:45 visual_prompt]: Epoch 2 / 100: avg data time: 1.09e+01, avg batch time: 11.2423, average train loss: 5.9509
[11/12 13:39:29 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.1559, average loss: 1.1372
[11/12 13:39:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.85	
[11/12 13:39:29 visual_prompt]: Training 3 / 100 epoch, with learning rate 1.0
[11/12 13:45:58 visual_prompt]: Epoch 3 / 100: avg data time: 1.08e+01, avg batch time: 11.1075, average train loss: 0.9748
[11/12 13:46:42 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.1561, average loss: 0.6893
[11/12 13:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.81	rocauc: 58.63	
[11/12 13:46:42 visual_prompt]: Training 4 / 100 epoch, with learning rate 1.5
[11/12 13:53:22 visual_prompt]: Epoch 4 / 100: avg data time: 1.11e+01, avg batch time: 11.4136, average train loss: 2.6736
[11/12 13:54:08 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1548, average loss: 0.9165
[11/12 13:54:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.29	
[11/12 13:54:08 visual_prompt]: Training 5 / 100 epoch, with learning rate 2.0
[11/12 14:00:45 visual_prompt]: Epoch 5 / 100: avg data time: 1.10e+01, avg batch time: 11.3606, average train loss: 3.0461
[11/12 14:01:31 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1548, average loss: 1.7254
[11/12 14:01:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.43	
[11/12 14:01:31 visual_prompt]: Training 6 / 100 epoch, with learning rate 2.5
[11/12 14:08:09 visual_prompt]: Epoch 6 / 100: avg data time: 1.10e+01, avg batch time: 11.3825, average train loss: 3.2436
[11/12 14:08:55 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1590, average loss: 5.7840
[11/12 14:08:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.44	
[11/12 14:08:55 visual_prompt]: Training 7 / 100 epoch, with learning rate 3.0
[11/12 14:15:31 visual_prompt]: Epoch 7 / 100: avg data time: 1.10e+01, avg batch time: 11.3337, average train loss: 4.8327
[11/12 14:16:17 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1552, average loss: 7.7874
[11/12 14:16:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.46	
[11/12 14:16:17 visual_prompt]: Training 8 / 100 epoch, with learning rate 3.5
[11/12 14:22:52 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.2981, average train loss: 8.2628
[11/12 14:23:37 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1546, average loss: 5.8034
[11/12 14:23:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.36	
[11/12 14:23:37 visual_prompt]: Training 9 / 100 epoch, with learning rate 4.0
[11/12 14:30:13 visual_prompt]: Epoch 9 / 100: avg data time: 1.10e+01, avg batch time: 11.3083, average train loss: 3.3418
[11/12 14:30:58 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1549, average loss: 1.6935
[11/12 14:30:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[11/12 14:30:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 4.5
[11/12 14:37:32 visual_prompt]: Epoch 10 / 100: avg data time: 1.09e+01, avg batch time: 11.2575, average train loss: 2.9051
[11/12 14:38:17 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1546, average loss: 1.1303
[11/12 14:38:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.11	
[11/12 14:38:17 visual_prompt]: Training 11 / 100 epoch, with learning rate 5.0
[11/12 14:44:51 visual_prompt]: Epoch 11 / 100: avg data time: 1.09e+01, avg batch time: 11.2321, average train loss: 1.4977
[11/12 14:45:35 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1548, average loss: 1.1440
[11/12 14:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.34	
[11/12 14:45:35 visual_prompt]: Training 12 / 100 epoch, with learning rate 4.998477067547739
[11/12 14:52:08 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2267, average train loss: 3.5161
[11/12 14:52:54 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1545, average loss: 1.1288
[11/12 14:52:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.57	
[11/12 14:52:54 visual_prompt]: Best epoch 12: best metric: -1.129
[11/12 14:52:54 visual_prompt]: Training 13 / 100 epoch, with learning rate 4.993910125649561
[11/12 14:59:27 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2256, average train loss: 3.3973
[11/12 15:00:11 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1548, average loss: 0.7094
[11/12 15:00:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.98	
[11/12 15:00:11 visual_prompt]: Best epoch 13: best metric: -0.709
[11/12 15:00:11 visual_prompt]: Training 14 / 100 epoch, with learning rate 4.986304738420683
[11/12 15:06:44 visual_prompt]: Epoch 14 / 100: avg data time: 1.09e+01, avg batch time: 11.2258, average train loss: 2.4030
[11/12 15:07:30 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1569, average loss: 2.3921
[11/12 15:07:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.71	
[11/12 15:07:30 visual_prompt]: Training 15 / 100 epoch, with learning rate 4.975670171853926
[11/12 15:14:03 visual_prompt]: Epoch 15 / 100: avg data time: 1.09e+01, avg batch time: 11.2328, average train loss: 1.4844
[11/12 15:14:48 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1547, average loss: 1.2943
[11/12 15:14:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.07	
[11/12 15:14:48 visual_prompt]: Training 16 / 100 epoch, with learning rate 4.962019382530521
[11/12 15:21:21 visual_prompt]: Epoch 16 / 100: avg data time: 1.09e+01, avg batch time: 11.2219, average train loss: 1.0320
[11/12 15:22:05 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1543, average loss: 0.7432
[11/12 15:22:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[11/12 15:22:05 visual_prompt]: Training 17 / 100 epoch, with learning rate 4.945369001834514
[11/12 15:28:39 visual_prompt]: Epoch 17 / 100: avg data time: 1.09e+01, avg batch time: 11.2357, average train loss: 2.2063
[11/12 15:29:24 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1579, average loss: 0.8792
[11/12 15:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.50	
[11/12 15:29:24 visual_prompt]: Training 18 / 100 epoch, with learning rate 4.925739315689991
[11/12 15:36:05 visual_prompt]: Epoch 18 / 100: avg data time: 1.11e+01, avg batch time: 11.4462, average train loss: 0.9722
[11/12 15:36:52 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1548, average loss: 0.9630
[11/12 15:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.64	
[11/12 15:36:52 visual_prompt]: Training 19 / 100 epoch, with learning rate 4.903154239845797
[11/12 15:43:33 visual_prompt]: Epoch 19 / 100: avg data time: 1.11e+01, avg batch time: 11.4664, average train loss: 1.2871
[11/12 15:44:19 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.1547, average loss: 1.6609
[11/12 15:44:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.69	
[11/12 15:44:19 visual_prompt]: Training 20 / 100 epoch, with learning rate 4.877641290737884
[11/12 15:50:59 visual_prompt]: Epoch 20 / 100: avg data time: 1.11e+01, avg batch time: 11.4341, average train loss: 2.2097
[11/12 15:51:45 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1545, average loss: 0.8099
[11/12 15:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.47	
[11/12 15:51:45 visual_prompt]: Training 21 / 100 epoch, with learning rate 4.849231551964771
[11/12 15:58:23 visual_prompt]: Epoch 21 / 100: avg data time: 1.10e+01, avg batch time: 11.3564, average train loss: 0.9638
[11/12 15:59:07 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1549, average loss: 2.4989
[11/12 15:59:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.37	
[11/12 15:59:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 4.817959636416969
[11/12 16:05:36 visual_prompt]: Epoch 22 / 100: avg data time: 1.08e+01, avg batch time: 11.1115, average train loss: 2.7280
[11/12 16:06:21 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1552, average loss: 1.0697
[11/12 16:06:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.28	
[11/12 16:06:21 visual_prompt]: Training 23 / 100 epoch, with learning rate 4.783863644106502
[11/12 16:12:48 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0679, average train loss: 1.0777
[11/12 16:13:33 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1550, average loss: 2.9297
[11/12 16:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.45	
[11/12 16:13:33 visual_prompt]: Training 24 / 100 epoch, with learning rate 4.7469851157479175
[11/12 16:20:01 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0997, average train loss: 1.1335
[11/12 16:20:45 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1554, average loss: 1.8306
[11/12 16:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.84	
[11/12 16:20:45 visual_prompt]: Training 25 / 100 epoch, with learning rate 4.707368982147317
[11/12 16:27:12 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0347, average train loss: 1.2860
[11/12 16:27:56 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1548, average loss: 0.9999
[11/12 16:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.76	
[11/12 16:27:56 visual_prompt]: Training 26 / 100 epoch, with learning rate 4.665063509461097
[11/12 16:34:24 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0869, average train loss: 1.1956
[11/12 16:35:08 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1546, average loss: 3.1395
[11/12 16:35:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[11/12 16:35:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 4.620120240391064
[11/12 16:41:37 visual_prompt]: Epoch 27 / 100: avg data time: 1.07e+01, avg batch time: 11.0844, average train loss: 2.7960
[11/12 16:42:21 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1545, average loss: 0.8106
[11/12 16:42:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.25	
[11/12 16:42:21 visual_prompt]: Training 28 / 100 epoch, with learning rate 4.572593931387604
[11/12 16:48:49 visual_prompt]: Epoch 28 / 100: avg data time: 1.07e+01, avg batch time: 11.0769, average train loss: 1.2777
[11/12 16:49:33 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1561, average loss: 2.6815
[11/12 16:49:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[11/12 16:49:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 4.522542485937368
[11/12 16:56:02 visual_prompt]: Epoch 29 / 100: avg data time: 1.07e+01, avg batch time: 11.0993, average train loss: 1.5419
[11/12 16:56:46 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1549, average loss: 1.7606
[11/12 16:56:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.70	
[11/12 16:56:46 visual_prompt]: Training 30 / 100 epoch, with learning rate 4.4700268840168045
[11/12 17:03:13 visual_prompt]: Epoch 30 / 100: avg data time: 1.07e+01, avg batch time: 11.0709, average train loss: 1.6145
[11/12 17:03:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1548, average loss: 1.1683
[11/12 17:03:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.89	
[11/12 17:03:58 visual_prompt]: Training 31 / 100 epoch, with learning rate 4.415111107797445
[11/12 17:10:21 visual_prompt]: Epoch 31 / 100: avg data time: 1.06e+01, avg batch time: 10.9611, average train loss: 1.7477
[11/12 17:11:07 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1549, average loss: 3.1848
[11/12 17:11:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/12 17:11:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 4.357862063693486
[11/12 17:17:41 visual_prompt]: Epoch 32 / 100: avg data time: 1.09e+01, avg batch time: 11.2768, average train loss: 2.9521
[11/12 17:18:26 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.1547, average loss: 4.7839
[11/12 17:18:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.95	
[11/12 17:18:26 visual_prompt]: Training 33 / 100 epoch, with learning rate 4.298349500846628
[11/12 17:25:00 visual_prompt]: Epoch 33 / 100: avg data time: 1.09e+01, avg batch time: 11.2386, average train loss: 2.1358
[11/12 17:25:45 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1601, average loss: 0.7319
[11/12 17:25:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/12 17:25:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 4.236645926147493
[11/12 17:32:15 visual_prompt]: Epoch 34 / 100: avg data time: 1.08e+01, avg batch time: 11.1637, average train loss: 0.9744
[11/12 17:33:00 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1549, average loss: 1.0549
[11/12 17:33:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.50	
[11/12 17:33:00 visual_prompt]: Stopping early.
[11/12 17:33:00 visual_prompt]: Rank of current process: 0. World size: 1
[11/12 17:33:00 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/12 17:33:00 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/12 17:33:00 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/12 17:33:00 visual_prompt]: Training with config:
[11/12 17:33:00 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/12 17:33:00 visual_prompt]: Loading training data...
[11/12 17:33:00 visual_prompt]: Constructing mammo-cbis dataset train...
[11/12 17:33:01 visual_prompt]: Loading validation data...
[11/12 17:33:01 visual_prompt]: Constructing mammo-cbis dataset val...
[11/12 17:33:01 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/12 17:33:04 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/12 17:33:04 visual_prompt]: tuned percent:0.536
[11/12 17:33:04 visual_prompt]: Device used for model: 0
[11/12 17:33:04 visual_prompt]: Setting up Evaluator...
[11/12 17:33:04 visual_prompt]: Setting up Trainer...
[11/12 17:33:04 visual_prompt]: 	Setting up the optimizer...
[11/12 17:33:04 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/12 17:39:36 visual_prompt]: Epoch 1 / 100: avg data time: 1.08e+01, avg batch time: 11.1850, average train loss: 1.4017
[11/12 17:40:20 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1552, average loss: 1.2969
[11/12 17:40:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/12 17:40:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/12 17:46:50 visual_prompt]: Epoch 2 / 100: avg data time: 1.08e+01, avg batch time: 11.1446, average train loss: 3.6919
[11/12 17:47:34 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1547, average loss: 0.8725
[11/12 17:47:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.65	
[11/12 17:47:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/12 17:54:01 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.0556, average train loss: 0.7178
[11/12 17:54:45 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1548, average loss: 0.7616
[11/12 17:54:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.37	
[11/12 17:54:45 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/12 18:01:12 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0385, average train loss: 0.7537
[11/12 18:01:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1578, average loss: 0.7970
[11/12 18:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.56	
[11/12 18:01:56 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/12 18:08:24 visual_prompt]: Epoch 5 / 100: avg data time: 1.07e+01, avg batch time: 11.0744, average train loss: 0.8644
[11/12 18:09:08 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1544, average loss: 0.7015
[11/12 18:09:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.84	
[11/12 18:09:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/12 18:15:36 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.0843, average train loss: 0.9545
[11/12 18:16:20 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1580, average loss: 0.7445
[11/12 18:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.83	
[11/12 18:16:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/12 18:22:48 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0887, average train loss: 1.0405
[11/12 18:23:32 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1552, average loss: 4.0140
[11/12 18:23:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.13	
[11/12 18:23:32 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/12 18:30:01 visual_prompt]: Epoch 8 / 100: avg data time: 1.07e+01, avg batch time: 11.0969, average train loss: 2.3116
[11/12 18:30:45 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1547, average loss: 6.1037
[11/12 18:30:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.65	
[11/12 18:30:45 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/12 18:37:14 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.1036, average train loss: 3.1626
[11/12 18:37:58 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1546, average loss: 1.9523
[11/12 18:37:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.88	
[11/12 18:37:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/12 18:44:26 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0720, average train loss: 2.9009
[11/12 18:45:10 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.1588, average loss: 2.3492
[11/12 18:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.85	
[11/12 18:45:10 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/12 18:51:32 visual_prompt]: Epoch 11 / 100: avg data time: 1.05e+01, avg batch time: 10.9011, average train loss: 4.5700
[11/12 18:52:17 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.1549, average loss: 0.7204
[11/12 18:52:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.40	
[11/12 18:52:17 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/12 18:58:51 visual_prompt]: Epoch 12 / 100: avg data time: 1.09e+01, avg batch time: 11.2608, average train loss: 5.3959
[11/12 18:59:37 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.1549, average loss: 11.3228
[11/12 18:59:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.87	
[11/12 18:59:37 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/12 19:06:10 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2487, average train loss: 5.1083
[11/12 19:06:55 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1547, average loss: 3.4097
[11/12 19:06:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.59	
[11/12 19:06:55 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/12 19:13:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1618, average train loss: 4.9301
[11/12 19:14:10 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1547, average loss: 3.6980
[11/12 19:14:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.01	
[11/12 19:14:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/12 19:20:40 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1356, average train loss: 3.3812
[11/12 19:21:25 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.1563, average loss: 4.4571
[11/12 19:21:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.01	
[11/12 19:21:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/12 19:27:54 visual_prompt]: Epoch 16 / 100: avg data time: 1.08e+01, avg batch time: 11.1163, average train loss: 4.7471
[11/12 19:28:38 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1579, average loss: 4.3415
[11/12 19:28:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.03	
[11/12 19:28:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/12 19:35:05 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0567, average train loss: 4.8584
[11/12 19:35:50 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1587, average loss: 1.6898
[11/12 19:35:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.91	
[11/12 19:35:50 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/12 19:42:18 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0847, average train loss: 4.7254
[11/12 19:43:02 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1570, average loss: 5.6253
[11/12 19:43:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.76	
[11/12 19:43:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/12 19:49:30 visual_prompt]: Epoch 19 / 100: avg data time: 1.07e+01, avg batch time: 11.0695, average train loss: 2.4088
[11/12 19:50:14 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1566, average loss: 2.6369
[11/12 19:50:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.85	
[11/12 19:50:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/12 19:56:42 visual_prompt]: Epoch 20 / 100: avg data time: 1.07e+01, avg batch time: 11.0723, average train loss: 4.3591
[11/12 19:57:26 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1570, average loss: 3.5023
[11/12 19:57:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.09	
[11/12 19:57:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/12 20:03:53 visual_prompt]: Epoch 21 / 100: avg data time: 1.07e+01, avg batch time: 11.0636, average train loss: 3.4407
[11/12 20:04:37 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1544, average loss: 1.1187
[11/12 20:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 42.07	
[11/12 20:04:37 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/12 20:11:05 visual_prompt]: Epoch 22 / 100: avg data time: 1.07e+01, avg batch time: 11.0622, average train loss: 3.3247
[11/12 20:11:49 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.1585, average loss: 1.3826
[11/12 20:11:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.36	
[11/12 20:11:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/12 20:18:16 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0492, average train loss: 3.4836
[11/12 20:19:00 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1577, average loss: 9.7154
[11/12 20:19:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.13	
[11/12 20:19:00 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/12 20:25:28 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0887, average train loss: 4.9655
[11/12 20:26:13 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.1560, average loss: 0.7407
[11/12 20:26:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.31	rocauc: 47.95	
[11/12 20:26:13 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/12 20:32:40 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0555, average train loss: 4.8301
[11/12 20:33:23 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1550, average loss: 9.5990
[11/12 20:33:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.72	
[11/12 20:33:23 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/12 20:39:50 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0682, average train loss: 4.7278
[11/12 20:40:35 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.1568, average loss: 15.4291
[11/12 20:40:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.43	
[11/12 20:40:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/12 20:47:08 visual_prompt]: Epoch 27 / 100: avg data time: 1.09e+01, avg batch time: 11.2330, average train loss: 3.8482
[11/12 20:47:53 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1572, average loss: 1.1746
[11/12 20:47:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.34	
[11/12 20:47:53 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/12 20:54:24 visual_prompt]: Epoch 28 / 100: avg data time: 1.08e+01, avg batch time: 11.1708, average train loss: 6.6130
[11/12 20:55:09 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1551, average loss: 3.3172
[11/12 20:55:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.71	
[11/12 20:55:09 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/12 21:01:40 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1586, average train loss: 3.1751
[11/12 21:02:24 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1550, average loss: 1.8763
[11/12 21:02:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/12 21:02:24 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/12 21:08:54 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1211, average train loss: 5.0169
[11/12 21:09:38 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.1553, average loss: 5.7889
[11/12 21:09:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.87	
[11/12 21:09:38 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/12 21:16:06 visual_prompt]: Epoch 31 / 100: avg data time: 1.07e+01, avg batch time: 11.0940, average train loss: 4.6675
[11/12 21:16:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1547, average loss: 1.7580
[11/12 21:16:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.45	
[11/12 21:16:50 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/12 21:23:17 visual_prompt]: Epoch 32 / 100: avg data time: 1.07e+01, avg batch time: 11.0373, average train loss: 3.5859
[11/12 21:24:01 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1556, average loss: 0.7173
[11/12 21:24:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.57	
[11/12 21:24:01 visual_prompt]: Best epoch 32: best metric: -0.717
[11/12 21:24:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/12 21:30:29 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0814, average train loss: 2.3847
[11/12 21:31:13 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1544, average loss: 2.7919
[11/12 21:31:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.38	
[11/12 21:31:13 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/12 21:37:40 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0440, average train loss: 3.5897
[11/12 21:38:24 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.1549, average loss: 4.0182
[11/12 21:38:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.24	
[11/12 21:38:24 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/12 21:44:50 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0391, average train loss: 3.4943
[11/12 21:45:34 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1546, average loss: 1.3352
[11/12 21:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.74	
[11/12 21:45:35 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/12 21:51:58 visual_prompt]: Epoch 36 / 100: avg data time: 1.06e+01, avg batch time: 10.9548, average train loss: 3.8950
[11/12 21:52:42 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1571, average loss: 2.1752
[11/12 21:52:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.75	
[11/12 21:52:42 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/12 21:59:09 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.0596, average train loss: 2.9914
[11/12 21:59:54 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1548, average loss: 2.2253
[11/12 21:59:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.49	
[11/12 21:59:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/12 22:06:21 visual_prompt]: Epoch 38 / 100: avg data time: 1.07e+01, avg batch time: 11.0679, average train loss: 2.8500
[11/12 22:07:05 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.1543, average loss: 3.5642
[11/12 22:07:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.03	
[11/12 22:07:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/12 22:13:31 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0253, average train loss: 3.4153
[11/12 22:14:15 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1547, average loss: 0.7113
[11/12 22:14:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/12 22:14:15 visual_prompt]: Best epoch 39: best metric: -0.711
[11/12 22:14:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/12 22:20:38 visual_prompt]: Epoch 40 / 100: avg data time: 1.06e+01, avg batch time: 10.9353, average train loss: 3.3889
[11/12 22:21:21 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1545, average loss: 1.4632
[11/12 22:21:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.77	
[11/12 22:21:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/12 22:27:52 visual_prompt]: Epoch 41 / 100: avg data time: 1.08e+01, avg batch time: 11.1869, average train loss: 3.4836
[11/12 22:28:37 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.1568, average loss: 5.0433
[11/12 22:28:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.89	
[11/12 22:28:37 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/12 22:35:11 visual_prompt]: Epoch 42 / 100: avg data time: 1.09e+01, avg batch time: 11.2382, average train loss: 2.5387
[11/12 22:35:56 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1544, average loss: 1.1371
[11/12 22:35:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.24	
[11/12 22:35:56 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/12 22:42:27 visual_prompt]: Epoch 43 / 100: avg data time: 1.08e+01, avg batch time: 11.1762, average train loss: 4.0741
[11/12 22:43:11 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1585, average loss: 2.0485
[11/12 22:43:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.37	
[11/12 22:43:11 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/12 22:49:41 visual_prompt]: Epoch 44 / 100: avg data time: 1.08e+01, avg batch time: 11.1181, average train loss: 4.6827
[11/12 22:50:25 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.1546, average loss: 9.8964
[11/12 22:50:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.72	
[11/12 22:50:25 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/12 22:56:55 visual_prompt]: Epoch 45 / 100: avg data time: 1.08e+01, avg batch time: 11.1322, average train loss: 3.1698
[11/12 22:57:39 visual_prompt]: Inference (val):avg data time: 4.31e-05, avg batch time: 0.1547, average loss: 3.4361
[11/12 22:57:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.35	
[11/12 22:57:39 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/12 23:04:05 visual_prompt]: Epoch 46 / 100: avg data time: 1.07e+01, avg batch time: 11.0153, average train loss: 1.9191
[11/12 23:04:49 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1546, average loss: 2.2786
[11/12 23:04:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.25	
[11/12 23:04:49 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/12 23:11:14 visual_prompt]: Epoch 47 / 100: avg data time: 1.06e+01, avg batch time: 11.0009, average train loss: 3.7677
[11/12 23:11:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1550, average loss: 2.8264
[11/12 23:11:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.83	
[11/12 23:11:58 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/12 23:18:24 visual_prompt]: Epoch 48 / 100: avg data time: 1.07e+01, avg batch time: 11.0188, average train loss: 1.7147
[11/12 23:19:08 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1549, average loss: 2.0010
[11/12 23:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.06	
[11/12 23:19:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/12 23:25:33 visual_prompt]: Epoch 49 / 100: avg data time: 1.06e+01, avg batch time: 11.0012, average train loss: 1.4986
[11/12 23:26:17 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.1544, average loss: 1.1847
[11/12 23:26:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 46.41	
[11/12 23:26:17 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/12 23:32:45 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e+01, avg batch time: 11.0667, average train loss: 2.1073
[11/12 23:33:29 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1549, average loss: 1.1655
[11/12 23:33:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 44.99	
[11/12 23:33:29 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/12 23:39:55 visual_prompt]: Epoch 51 / 100: avg data time: 1.07e+01, avg batch time: 11.0380, average train loss: 1.2805
[11/12 23:40:39 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.1545, average loss: 1.9413
[11/12 23:40:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.00	
[11/12 23:40:39 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/12 23:47:07 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0787, average train loss: 1.3262
[11/12 23:47:51 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1545, average loss: 1.2575
[11/12 23:47:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.35	
[11/12 23:47:51 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/12 23:54:18 visual_prompt]: Epoch 53 / 100: avg data time: 1.07e+01, avg batch time: 11.0288, average train loss: 3.7633
[11/12 23:55:02 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.1570, average loss: 0.9647
[11/12 23:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.10	
[11/12 23:55:02 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/13 00:01:29 visual_prompt]: Epoch 54 / 100: avg data time: 1.07e+01, avg batch time: 11.0562, average train loss: 2.2518
[11/13 00:02:13 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1546, average loss: 1.9259
[11/13 00:02:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.63	
[11/13 00:02:13 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[11/13 00:08:39 visual_prompt]: Epoch 55 / 100: avg data time: 1.07e+01, avg batch time: 11.0178, average train loss: 1.7175
[11/13 00:09:23 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1589, average loss: 1.6195
[11/13 00:09:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.07	
[11/13 00:09:23 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[11/13 00:15:54 visual_prompt]: Epoch 56 / 100: avg data time: 1.08e+01, avg batch time: 11.1662, average train loss: 1.4720
[11/13 00:16:38 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1560, average loss: 1.1097
[11/13 00:16:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.41	
[11/13 00:16:38 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[11/13 00:23:10 visual_prompt]: Epoch 57 / 100: avg data time: 1.08e+01, avg batch time: 11.1951, average train loss: 1.2224
[11/13 00:23:55 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.1573, average loss: 0.7943
[11/13 00:23:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.20	
[11/13 00:23:55 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[11/13 00:30:26 visual_prompt]: Epoch 58 / 100: avg data time: 1.08e+01, avg batch time: 11.1596, average train loss: 0.8482
[11/13 00:31:10 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.1546, average loss: 1.1836
[11/13 00:31:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.36	
[11/13 00:31:10 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[11/13 00:37:39 visual_prompt]: Epoch 59 / 100: avg data time: 1.07e+01, avg batch time: 11.0895, average train loss: 1.6697
[11/13 00:38:23 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.1580, average loss: 1.6692
[11/13 00:38:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.21	
[11/13 00:38:23 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[11/13 00:44:51 visual_prompt]: Epoch 60 / 100: avg data time: 1.07e+01, avg batch time: 11.0725, average train loss: 1.3677
[11/13 00:45:35 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1547, average loss: 1.5280
[11/13 00:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.77	
[11/13 00:45:35 visual_prompt]: Stopping early.
[11/13 00:45:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 00:45:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 00:45:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 00:45:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 00:45:35 visual_prompt]: Training with config:
[11/13 00:45:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 00:45:35 visual_prompt]: Loading training data...
[11/13 00:45:35 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 00:45:35 visual_prompt]: Loading validation data...
[11/13 00:45:35 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 00:45:35 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 00:45:38 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 00:45:38 visual_prompt]: tuned percent:0.536
[11/13 00:45:38 visual_prompt]: Device used for model: 0
[11/13 00:45:38 visual_prompt]: Setting up Evaluator...
[11/13 00:45:38 visual_prompt]: Setting up Trainer...
[11/13 00:45:38 visual_prompt]: 	Setting up the optimizer...
[11/13 00:45:38 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 00:52:04 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0344, average train loss: 1.4017
[11/13 00:52:48 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1588, average loss: 1.2969
[11/13 00:52:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 00:52:48 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/13 00:59:12 visual_prompt]: Epoch 2 / 100: avg data time: 1.06e+01, avg batch time: 10.9599, average train loss: 3.6304
[11/13 00:59:56 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.1547, average loss: 0.6825
[11/13 00:59:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 55.38	
[11/13 00:59:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/13 01:06:20 visual_prompt]: Epoch 3 / 100: avg data time: 1.06e+01, avg batch time: 10.9746, average train loss: 0.7231
[11/13 01:07:04 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1583, average loss: 0.6997
[11/13 01:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 59.25	
[11/13 01:07:04 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/13 01:13:31 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0373, average train loss: 0.9047
[11/13 01:14:15 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1548, average loss: 0.6883
[11/13 01:14:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[11/13 01:14:15 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/13 01:20:40 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9987, average train loss: 1.0396
[11/13 01:21:24 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1548, average loss: 0.6825
[11/13 01:21:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.41	
[11/13 01:21:24 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/13 01:27:49 visual_prompt]: Epoch 6 / 100: avg data time: 1.06e+01, avg batch time: 10.9981, average train loss: 1.0942
[11/13 01:28:33 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1545, average loss: 1.2490
[11/13 01:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.27	
[11/13 01:28:33 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/13 01:34:59 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0444, average train loss: 0.9117
[11/13 01:35:43 visual_prompt]: Inference (val):avg data time: 2.59e-05, avg batch time: 0.1547, average loss: 1.1022
[11/13 01:35:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.14	
[11/13 01:35:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/13 01:42:08 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9952, average train loss: 0.8611
[11/13 01:42:52 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.1547, average loss: 1.0243
[11/13 01:42:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.29	
[11/13 01:42:52 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/13 01:49:19 visual_prompt]: Epoch 9 / 100: avg data time: 1.07e+01, avg batch time: 11.0392, average train loss: 0.8088
[11/13 01:50:03 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1547, average loss: 0.6899
[11/13 01:50:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.63	
[11/13 01:50:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/13 01:56:28 visual_prompt]: Epoch 10 / 100: avg data time: 1.07e+01, avg batch time: 11.0181, average train loss: 0.9031
[11/13 01:57:12 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.1557, average loss: 3.8567
[11/13 01:57:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.05	
[11/13 01:57:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/13 02:03:38 visual_prompt]: Epoch 11 / 100: avg data time: 1.07e+01, avg batch time: 11.0244, average train loss: 3.8047
[11/13 02:04:22 visual_prompt]: Inference (val):avg data time: 2.52e-05, avg batch time: 0.1559, average loss: 1.5610
[11/13 02:04:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 44.07	
[11/13 02:04:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/13 02:10:46 visual_prompt]: Epoch 12 / 100: avg data time: 1.06e+01, avg batch time: 10.9744, average train loss: 1.0283
[11/13 02:11:31 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1569, average loss: 0.8314
[11/13 02:11:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.94	
[11/13 02:11:31 visual_prompt]: Best epoch 12: best metric: -0.831
[11/13 02:11:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/13 02:18:04 visual_prompt]: Epoch 13 / 100: avg data time: 1.09e+01, avg batch time: 11.2064, average train loss: 1.4775
[11/13 02:18:49 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1584, average loss: 4.7126
[11/13 02:18:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.21	
[11/13 02:18:49 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/13 02:25:18 visual_prompt]: Epoch 14 / 100: avg data time: 1.08e+01, avg batch time: 11.1373, average train loss: 2.7144
[11/13 02:26:03 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1547, average loss: 2.6430
[11/13 02:26:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/13 02:26:03 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/13 02:32:33 visual_prompt]: Epoch 15 / 100: avg data time: 1.08e+01, avg batch time: 11.1266, average train loss: 1.2353
[11/13 02:33:17 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1547, average loss: 1.1076
[11/13 02:33:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.77	
[11/13 02:33:17 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/13 02:39:44 visual_prompt]: Epoch 16 / 100: avg data time: 1.07e+01, avg batch time: 11.0618, average train loss: 1.0892
[11/13 02:40:28 visual_prompt]: Inference (val):avg data time: 2.55e-05, avg batch time: 0.1547, average loss: 0.7286
[11/13 02:40:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.76	
[11/13 02:40:28 visual_prompt]: Best epoch 16: best metric: -0.729
[11/13 02:40:28 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/13 02:46:54 visual_prompt]: Epoch 17 / 100: avg data time: 1.07e+01, avg batch time: 11.0165, average train loss: 0.8599
[11/13 02:47:38 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1550, average loss: 0.7720
[11/13 02:47:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.85	
[11/13 02:47:38 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/13 02:54:04 visual_prompt]: Epoch 18 / 100: avg data time: 1.07e+01, avg batch time: 11.0131, average train loss: 0.9803
[11/13 02:54:48 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1548, average loss: 0.6886
[11/13 02:54:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.48	
[11/13 02:54:48 visual_prompt]: Best epoch 18: best metric: -0.689
[11/13 02:54:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/13 03:01:12 visual_prompt]: Epoch 19 / 100: avg data time: 1.06e+01, avg batch time: 10.9835, average train loss: 1.1256
[11/13 03:01:56 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1547, average loss: 1.1808
[11/13 03:01:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.70	
[11/13 03:01:56 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/13 03:08:20 visual_prompt]: Epoch 20 / 100: avg data time: 1.06e+01, avg batch time: 10.9624, average train loss: 1.3883
[11/13 03:09:04 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1549, average loss: 1.0114
[11/13 03:09:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.66	
[11/13 03:09:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/13 03:15:28 visual_prompt]: Epoch 21 / 100: avg data time: 1.06e+01, avg batch time: 10.9562, average train loss: 0.8843
[11/13 03:16:12 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1544, average loss: 0.9811
[11/13 03:16:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.20	
[11/13 03:16:12 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/13 03:22:36 visual_prompt]: Epoch 22 / 100: avg data time: 1.06e+01, avg batch time: 10.9853, average train loss: 1.0432
[11/13 03:23:20 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1553, average loss: 0.6965
[11/13 03:23:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.83	
[11/13 03:23:20 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/13 03:29:46 visual_prompt]: Epoch 23 / 100: avg data time: 1.07e+01, avg batch time: 11.0126, average train loss: 1.1710
[11/13 03:30:30 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1543, average loss: 0.6930
[11/13 03:30:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.37	
[11/13 03:30:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/13 03:36:54 visual_prompt]: Epoch 24 / 100: avg data time: 1.06e+01, avg batch time: 10.9742, average train loss: 0.8601
[11/13 03:37:38 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.1543, average loss: 0.6942
[11/13 03:37:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.00	
[11/13 03:37:38 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/13 03:44:03 visual_prompt]: Epoch 25 / 100: avg data time: 1.07e+01, avg batch time: 11.0105, average train loss: 0.7406
[11/13 03:44:48 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.1544, average loss: 0.7404
[11/13 03:44:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.30	
[11/13 03:44:48 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/13 03:51:14 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0338, average train loss: 2.5731
[11/13 03:51:58 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1546, average loss: 7.3271
[11/13 03:51:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.19	
[11/13 03:51:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/13 03:58:23 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 10.9991, average train loss: 3.8281
[11/13 03:59:07 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1553, average loss: 8.1660
[11/13 03:59:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.72	
[11/13 03:59:07 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/13 04:05:30 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9496, average train loss: 3.0491
[11/13 04:06:13 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.1546, average loss: 1.1203
[11/13 04:06:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.74	
[11/13 04:06:13 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/13 04:12:43 visual_prompt]: Epoch 29 / 100: avg data time: 1.08e+01, avg batch time: 11.1538, average train loss: 1.0541
[11/13 04:13:28 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.1546, average loss: 0.8112
[11/13 04:13:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.07	
[11/13 04:13:28 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/13 04:20:00 visual_prompt]: Epoch 30 / 100: avg data time: 1.08e+01, avg batch time: 11.1936, average train loss: 0.8325
[11/13 04:20:45 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1559, average loss: 0.6978
[11/13 04:20:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.11	
[11/13 04:20:45 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/13 04:27:15 visual_prompt]: Epoch 31 / 100: avg data time: 1.08e+01, avg batch time: 11.1465, average train loss: 1.3920
[11/13 04:27:59 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.1565, average loss: 0.6883
[11/13 04:27:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.93	
[11/13 04:27:59 visual_prompt]: Best epoch 31: best metric: -0.688
[11/13 04:27:59 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/13 04:34:29 visual_prompt]: Epoch 32 / 100: avg data time: 1.08e+01, avg batch time: 11.1178, average train loss: 5.5685
[11/13 04:35:13 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1545, average loss: 2.7832
[11/13 04:35:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.73	
[11/13 04:35:13 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/13 04:41:40 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0337, average train loss: 2.1567
[11/13 04:42:24 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1549, average loss: 0.9179
[11/13 04:42:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/13 04:42:24 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/13 04:48:50 visual_prompt]: Epoch 34 / 100: avg data time: 1.07e+01, avg batch time: 11.0271, average train loss: 1.1733
[11/13 04:49:34 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1552, average loss: 0.7020
[11/13 04:49:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.21	
[11/13 04:49:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/13 04:55:59 visual_prompt]: Epoch 35 / 100: avg data time: 1.07e+01, avg batch time: 11.0085, average train loss: 0.7618
[11/13 04:56:44 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1600, average loss: 0.7684
[11/13 04:56:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.42	
[11/13 04:56:44 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/13 05:03:10 visual_prompt]: Epoch 36 / 100: avg data time: 1.07e+01, avg batch time: 11.0485, average train loss: 0.8461
[11/13 05:03:55 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1546, average loss: 1.0554
[11/13 05:03:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.01	
[11/13 05:03:55 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/13 05:10:21 visual_prompt]: Epoch 37 / 100: avg data time: 1.07e+01, avg batch time: 11.0374, average train loss: 0.8348
[11/13 05:11:05 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.1546, average loss: 1.2173
[11/13 05:11:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.99	
[11/13 05:11:05 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/13 05:17:32 visual_prompt]: Epoch 38 / 100: avg data time: 1.07e+01, avg batch time: 11.0410, average train loss: 0.8725
[11/13 05:18:16 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1548, average loss: 0.6885
[11/13 05:18:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.95	
[11/13 05:18:16 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/13 05:24:43 visual_prompt]: Epoch 39 / 100: avg data time: 1.07e+01, avg batch time: 11.0510, average train loss: 0.7779
[11/13 05:25:27 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1548, average loss: 0.6884
[11/13 05:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.17	
[11/13 05:25:27 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/13 05:31:54 visual_prompt]: Epoch 40 / 100: avg data time: 1.07e+01, avg batch time: 11.0501, average train loss: 0.7741
[11/13 05:32:38 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.1548, average loss: 0.7158
[11/13 05:32:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.40	
[11/13 05:32:38 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/13 05:39:04 visual_prompt]: Epoch 41 / 100: avg data time: 1.07e+01, avg batch time: 11.0327, average train loss: 0.7534
[11/13 05:39:48 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1547, average loss: 0.7000
[11/13 05:39:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.19	
[11/13 05:39:48 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/13 05:46:14 visual_prompt]: Epoch 42 / 100: avg data time: 1.07e+01, avg batch time: 11.0060, average train loss: 0.9151
[11/13 05:46:57 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1547, average loss: 0.9685
[11/13 05:46:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.37	
[11/13 05:46:57 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/13 05:53:22 visual_prompt]: Epoch 43 / 100: avg data time: 1.06e+01, avg batch time: 10.9776, average train loss: 1.0588
[11/13 05:54:06 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.1545, average loss: 1.2951
[11/13 05:54:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.60	
[11/13 05:54:06 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/13 06:00:28 visual_prompt]: Epoch 44 / 100: avg data time: 1.06e+01, avg batch time: 10.9285, average train loss: 1.7069
[11/13 06:01:12 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1543, average loss: 2.0993
[11/13 06:01:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.23	
[11/13 06:01:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/13 06:07:46 visual_prompt]: Epoch 45 / 100: avg data time: 1.09e+01, avg batch time: 11.2556, average train loss: 1.9009
[11/13 06:08:31 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.1569, average loss: 1.4828
[11/13 06:08:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.32	
[11/13 06:08:31 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/13 06:15:03 visual_prompt]: Epoch 46 / 100: avg data time: 1.08e+01, avg batch time: 11.1994, average train loss: 1.1155
[11/13 06:15:48 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.1546, average loss: 0.6884
[11/13 06:15:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.60	
[11/13 06:15:48 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/13 06:22:19 visual_prompt]: Epoch 47 / 100: avg data time: 1.08e+01, avg batch time: 11.1603, average train loss: 0.9121
[11/13 06:23:03 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1548, average loss: 0.9398
[11/13 06:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.83	
[11/13 06:23:03 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/13 06:29:32 visual_prompt]: Epoch 48 / 100: avg data time: 1.08e+01, avg batch time: 11.1062, average train loss: 0.8189
[11/13 06:30:17 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.1550, average loss: 0.7422
[11/13 06:30:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.96	
[11/13 06:30:17 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/13 06:36:45 visual_prompt]: Epoch 49 / 100: avg data time: 1.07e+01, avg batch time: 11.0824, average train loss: 0.7523
[11/13 06:37:29 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1550, average loss: 0.9006
[11/13 06:37:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.93	
[11/13 06:37:29 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/13 06:43:56 visual_prompt]: Epoch 50 / 100: avg data time: 1.07e+01, avg batch time: 11.0591, average train loss: 1.0029
[11/13 06:44:40 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.1560, average loss: 1.1255
[11/13 06:44:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.39	
[11/13 06:44:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/13 06:51:08 visual_prompt]: Epoch 51 / 100: avg data time: 1.07e+01, avg batch time: 11.0686, average train loss: 0.8732
[11/13 06:51:52 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1546, average loss: 0.7061
[11/13 06:51:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.63	
[11/13 06:51:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/13 06:58:19 visual_prompt]: Epoch 52 / 100: avg data time: 1.07e+01, avg batch time: 11.0448, average train loss: 0.7349
[11/13 06:59:03 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.1544, average loss: 0.7472
[11/13 06:59:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.46	
[11/13 06:59:03 visual_prompt]: Stopping early.
[11/13 06:59:03 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 06:59:03 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 06:59:03 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 06:59:03 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 06:59:03 visual_prompt]: Training with config:
[11/13 06:59:03 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 06:59:03 visual_prompt]: Loading training data...
[11/13 06:59:03 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 06:59:03 visual_prompt]: Loading validation data...
[11/13 06:59:03 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 06:59:03 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 06:59:09 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 06:59:09 visual_prompt]: tuned percent:0.536
[11/13 06:59:09 visual_prompt]: Device used for model: 0
[11/13 06:59:09 visual_prompt]: Setting up Evaluator...
[11/13 06:59:09 visual_prompt]: Setting up Trainer...
[11/13 06:59:09 visual_prompt]: 	Setting up the optimizer...
[11/13 06:59:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 07:05:35 visual_prompt]: Epoch 1 / 100: avg data time: 1.07e+01, avg batch time: 11.0396, average train loss: 1.4017
[11/13 07:06:20 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1547, average loss: 1.2969
[11/13 07:06:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 07:06:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/13 07:12:46 visual_prompt]: Epoch 2 / 100: avg data time: 1.07e+01, avg batch time: 11.0237, average train loss: 3.6454
[11/13 07:13:30 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.1546, average loss: 0.6816
[11/13 07:13:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.35	
[11/13 07:13:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/13 07:19:56 visual_prompt]: Epoch 3 / 100: avg data time: 1.07e+01, avg batch time: 11.0463, average train loss: 0.7275
[11/13 07:20:41 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.1569, average loss: 0.6955
[11/13 07:20:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 57.91	
[11/13 07:20:41 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/13 07:27:07 visual_prompt]: Epoch 4 / 100: avg data time: 1.07e+01, avg batch time: 11.0239, average train loss: 0.9362
[11/13 07:27:50 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.1546, average loss: 0.6933
[11/13 07:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/13 07:27:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/13 07:34:15 visual_prompt]: Epoch 5 / 100: avg data time: 1.06e+01, avg batch time: 10.9806, average train loss: 1.1451
[11/13 07:34:59 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1549, average loss: 0.7387
[11/13 07:34:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.34	
[11/13 07:34:59 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/13 07:41:25 visual_prompt]: Epoch 6 / 100: avg data time: 1.07e+01, avg batch time: 11.0255, average train loss: 2.1868
[11/13 07:42:09 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.1573, average loss: 2.5805
[11/13 07:42:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.00	
[11/13 07:42:09 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/13 07:48:36 visual_prompt]: Epoch 7 / 100: avg data time: 1.07e+01, avg batch time: 11.0499, average train loss: 2.1259
[11/13 07:49:20 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.1550, average loss: 3.0898
[11/13 07:49:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.52	
[11/13 07:49:20 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/13 07:55:45 visual_prompt]: Epoch 8 / 100: avg data time: 1.06e+01, avg batch time: 10.9907, average train loss: 3.2019
[11/13 07:56:30 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.1548, average loss: 1.8020
[11/13 07:56:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.57	
[11/13 07:56:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/13 08:03:04 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2539, average train loss: 1.3700
[11/13 08:03:49 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.1554, average loss: 0.6804
[11/13 08:03:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.34	
[11/13 08:03:49 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/13 08:10:20 visual_prompt]: Epoch 10 / 100: avg data time: 1.08e+01, avg batch time: 11.1780, average train loss: 0.8586
[11/13 08:11:04 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.1548, average loss: 1.1703
[11/13 08:11:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.34	
[11/13 08:11:04 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/13 08:17:35 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1579, average train loss: 3.0920
[11/13 08:18:19 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1560, average loss: 0.9227
[11/13 08:18:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.77	
[11/13 08:18:19 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/13 08:24:47 visual_prompt]: Epoch 12 / 100: avg data time: 1.07e+01, avg batch time: 11.0617, average train loss: 1.8829
[11/13 08:25:31 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1553, average loss: 2.9093
[11/13 08:25:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.71	
[11/13 08:25:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/13 08:31:58 visual_prompt]: Epoch 13 / 100: avg data time: 1.07e+01, avg batch time: 11.0520, average train loss: 1.2886
[11/13 08:32:42 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.1552, average loss: 0.7878
[11/13 08:32:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.66	
[11/13 08:32:42 visual_prompt]: Best epoch 13: best metric: -0.788
[11/13 08:32:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/13 08:39:06 visual_prompt]: Epoch 14 / 100: avg data time: 1.06e+01, avg batch time: 10.9669, average train loss: 1.0460
[11/13 08:39:50 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1547, average loss: 1.5405
[11/13 08:39:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.96	
[11/13 08:39:50 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/13 08:46:33 visual_prompt]: Epoch 15 / 100: avg data time: 1.11e+01, avg batch time: 11.4966, average train loss: 1.0369
[11/13 08:47:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1543, average loss: 0.8985
[11/13 08:47:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/13 08:47:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/13 08:53:41 visual_prompt]: Epoch 16 / 100: avg data time: 1.06e+01, avg batch time: 10.9336, average train loss: 0.8825
[11/13 08:54:24 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1547, average loss: 0.7928
[11/13 08:54:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.30	
[11/13 08:54:24 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/13 09:00:37 visual_prompt]: Epoch 17 / 100: avg data time: 1.03e+01, avg batch time: 10.6767, average train loss: 0.8888
[11/13 09:01:20 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.1546, average loss: 1.2473
[11/13 09:01:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.67	
[11/13 09:01:20 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/13 09:07:34 visual_prompt]: Epoch 18 / 100: avg data time: 1.03e+01, avg batch time: 10.6882, average train loss: 0.9067
[11/13 09:08:17 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1546, average loss: 0.8143
[11/13 09:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.55	
[11/13 09:08:17 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/13 09:14:35 visual_prompt]: Epoch 19 / 100: avg data time: 1.04e+01, avg batch time: 10.7928, average train loss: 0.8457
[11/13 09:15:18 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1545, average loss: 0.7060
[11/13 09:15:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.85	
[11/13 09:15:18 visual_prompt]: Best epoch 19: best metric: -0.706
[11/13 09:15:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/13 09:21:31 visual_prompt]: Epoch 20 / 100: avg data time: 1.03e+01, avg batch time: 10.6701, average train loss: 0.7155
[11/13 09:22:14 visual_prompt]: Inference (val):avg data time: 2.63e-05, avg batch time: 0.1547, average loss: 0.7022
[11/13 09:22:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.95	
[11/13 09:22:14 visual_prompt]: Best epoch 20: best metric: -0.702
[11/13 09:22:14 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/13 09:28:28 visual_prompt]: Epoch 21 / 100: avg data time: 1.03e+01, avg batch time: 10.6880, average train loss: 0.7812
[11/13 09:29:11 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.1561, average loss: 0.7009
[11/13 09:29:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.77	
[11/13 09:29:11 visual_prompt]: Best epoch 21: best metric: -0.701
[11/13 09:29:11 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/13 09:35:24 visual_prompt]: Epoch 22 / 100: avg data time: 1.03e+01, avg batch time: 10.6556, average train loss: 0.9935
[11/13 09:36:07 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1549, average loss: 0.7742
[11/13 09:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.47	
[11/13 09:36:07 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/13 09:42:21 visual_prompt]: Epoch 23 / 100: avg data time: 1.03e+01, avg batch time: 10.6778, average train loss: 0.8299
[11/13 09:43:03 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1545, average loss: 1.3047
[11/13 09:43:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.37	
[11/13 09:43:03 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/13 09:49:30 visual_prompt]: Epoch 24 / 100: avg data time: 1.07e+01, avg batch time: 11.0485, average train loss: 0.8788
[11/13 09:50:14 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.1554, average loss: 0.7853
[11/13 09:50:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.79	
[11/13 09:50:14 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/13 09:56:43 visual_prompt]: Epoch 25 / 100: avg data time: 1.08e+01, avg batch time: 11.1146, average train loss: 0.7833
[11/13 09:57:29 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.1549, average loss: 0.9416
[11/13 09:57:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.30	
[11/13 09:57:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/13 10:03:58 visual_prompt]: Epoch 26 / 100: avg data time: 1.07e+01, avg batch time: 11.0947, average train loss: 0.8801
[11/13 10:04:42 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.1551, average loss: 0.8171
[11/13 10:04:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.38	
[11/13 10:04:42 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/13 10:11:07 visual_prompt]: Epoch 27 / 100: avg data time: 1.06e+01, avg batch time: 11.0028, average train loss: 0.7572
[11/13 10:11:51 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.1571, average loss: 0.8759
[11/13 10:11:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[11/13 10:11:51 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/13 10:18:15 visual_prompt]: Epoch 28 / 100: avg data time: 1.06e+01, avg batch time: 10.9562, average train loss: 0.8196
[11/13 10:18:58 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1548, average loss: 0.6887
[11/13 10:18:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.07	
[11/13 10:18:58 visual_prompt]: Best epoch 28: best metric: -0.689
[11/13 10:18:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/13 10:25:18 visual_prompt]: Epoch 29 / 100: avg data time: 1.05e+01, avg batch time: 10.8376, average train loss: 0.7494
[11/13 10:26:01 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1572, average loss: 0.7312
[11/13 10:26:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.85	
[11/13 10:26:01 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/13 10:32:16 visual_prompt]: Epoch 30 / 100: avg data time: 1.04e+01, avg batch time: 10.7230, average train loss: 0.7541
[11/13 10:32:59 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1558, average loss: 0.6784
[11/13 10:32:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.10	
[11/13 10:32:59 visual_prompt]: Best epoch 30: best metric: -0.678
[11/13 10:32:59 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/13 10:39:11 visual_prompt]: Epoch 31 / 100: avg data time: 1.03e+01, avg batch time: 10.6250, average train loss: 0.7567
[11/13 10:39:53 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.1546, average loss: 0.6956
[11/13 10:39:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.21	
[11/13 10:39:53 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/13 10:46:16 visual_prompt]: Epoch 32 / 100: avg data time: 1.06e+01, avg batch time: 10.9261, average train loss: 0.7742
[11/13 10:47:00 visual_prompt]: Inference (val):avg data time: 2.83e-05, avg batch time: 0.1549, average loss: 0.6922
[11/13 10:47:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 60.18	
[11/13 10:47:00 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/13 10:53:26 visual_prompt]: Epoch 33 / 100: avg data time: 1.07e+01, avg batch time: 11.0205, average train loss: 0.7725
[11/13 10:54:10 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1546, average loss: 0.6895
[11/13 10:54:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[11/13 10:54:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/13 11:00:31 visual_prompt]: Epoch 34 / 100: avg data time: 1.05e+01, avg batch time: 10.8858, average train loss: 0.7480
[11/13 11:01:14 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.1584, average loss: 0.7044
[11/13 11:01:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.48	
[11/13 11:01:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/13 11:07:32 visual_prompt]: Epoch 35 / 100: avg data time: 1.04e+01, avg batch time: 10.8068, average train loss: 0.7402
[11/13 11:08:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1543, average loss: 0.7032
[11/13 11:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.59	
[11/13 11:08:17 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/13 11:14:52 visual_prompt]: Epoch 36 / 100: avg data time: 1.09e+01, avg batch time: 11.2753, average train loss: 0.7698
[11/13 11:15:35 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.1546, average loss: 0.7362
[11/13 11:15:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.68	
[11/13 11:15:35 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/13 11:21:54 visual_prompt]: Epoch 37 / 100: avg data time: 1.05e+01, avg batch time: 10.8202, average train loss: 0.7190
[11/13 11:22:37 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1549, average loss: 0.6828
[11/13 11:22:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.80	
[11/13 11:22:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/13 11:28:57 visual_prompt]: Epoch 38 / 100: avg data time: 1.05e+01, avg batch time: 10.8641, average train loss: 0.7689
[11/13 11:29:40 visual_prompt]: Inference (val):avg data time: 2.50e-05, avg batch time: 0.1547, average loss: 0.6992
[11/13 11:29:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/13 11:29:40 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/13 11:36:00 visual_prompt]: Epoch 39 / 100: avg data time: 1.05e+01, avg batch time: 10.8581, average train loss: 0.7800
[11/13 11:36:44 visual_prompt]: Inference (val):avg data time: 2.69e-05, avg batch time: 0.1546, average loss: 0.8712
[11/13 11:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/13 11:36:44 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/13 11:43:05 visual_prompt]: Epoch 40 / 100: avg data time: 1.05e+01, avg batch time: 10.8817, average train loss: 0.7268
[11/13 11:43:47 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.1555, average loss: 0.7165
[11/13 11:43:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.49	
[11/13 11:43:47 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/13 11:50:02 visual_prompt]: Epoch 41 / 100: avg data time: 1.04e+01, avg batch time: 10.7158, average train loss: 0.7328
[11/13 11:50:46 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.1546, average loss: 0.8849
[11/13 11:50:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.70	
[11/13 11:50:46 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/13 11:57:31 visual_prompt]: Epoch 42 / 100: avg data time: 1.12e+01, avg batch time: 11.5766, average train loss: 0.7589
[11/13 11:58:17 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.1545, average loss: 0.7121
[11/13 11:58:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.22	
[11/13 11:58:17 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/13 12:04:50 visual_prompt]: Epoch 43 / 100: avg data time: 1.09e+01, avg batch time: 11.2415, average train loss: 0.8197
[11/13 12:05:34 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.1545, average loss: 0.7307
[11/13 12:05:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.22	
[11/13 12:05:34 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/13 12:12:00 visual_prompt]: Epoch 44 / 100: avg data time: 1.07e+01, avg batch time: 11.0124, average train loss: 0.7516
[11/13 12:12:44 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1549, average loss: 0.7959
[11/13 12:12:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.05	
[11/13 12:12:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/13 12:19:11 visual_prompt]: Epoch 45 / 100: avg data time: 1.07e+01, avg batch time: 11.0505, average train loss: 0.7567
[11/13 12:19:55 visual_prompt]: Inference (val):avg data time: 2.76e-05, avg batch time: 0.1572, average loss: 0.8017
[11/13 12:19:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.89	
[11/13 12:19:55 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/13 12:26:16 visual_prompt]: Epoch 46 / 100: avg data time: 1.05e+01, avg batch time: 10.8863, average train loss: 0.8895
[11/13 12:26:59 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.1543, average loss: 1.1452
[11/13 12:26:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.37	
[11/13 12:26:59 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/13 12:33:18 visual_prompt]: Epoch 47 / 100: avg data time: 1.05e+01, avg batch time: 10.8214, average train loss: 0.7999
[11/13 12:34:02 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1541, average loss: 0.6990
[11/13 12:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 59.92	
[11/13 12:34:02 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/13 12:40:24 visual_prompt]: Epoch 48 / 100: avg data time: 1.06e+01, avg batch time: 10.9283, average train loss: 0.7490
[11/13 12:41:08 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.1546, average loss: 0.7251
[11/13 12:41:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.31	
[11/13 12:41:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/13 12:47:28 visual_prompt]: Epoch 49 / 100: avg data time: 1.05e+01, avg batch time: 10.8614, average train loss: 0.6941
[11/13 12:48:11 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.1551, average loss: 0.7429
[11/13 12:48:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.62	
[11/13 12:48:11 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/13 12:54:34 visual_prompt]: Epoch 50 / 100: avg data time: 1.06e+01, avg batch time: 10.9236, average train loss: 0.8475
[11/13 12:55:17 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.1545, average loss: 1.0725
[11/13 12:55:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.27	
[11/13 12:55:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/13 13:01:40 visual_prompt]: Epoch 51 / 100: avg data time: 1.06e+01, avg batch time: 10.9381, average train loss: 0.7558
[11/13 13:02:27 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.1549, average loss: 0.6823
[11/13 13:02:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.49	
[11/13 13:02:27 visual_prompt]: Stopping early.
[11/13 13:02:27 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 13:02:28 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              3
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 13:02:28 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '64', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.IMGSIZE', '200', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 13:02:28 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 13:02:28 visual_prompt]: Training with config:
[11/13 13:02:28 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size200/val/seed0/lr2.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 200, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 64, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 13:02:28 visual_prompt]: Loading training data...
[11/13 13:02:28 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 13:02:28 visual_prompt]: Loading validation data...
[11/13 13:02:28 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 13:02:28 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 145, 768])
load_pretrained: grid-size from 14 to 12
[11/13 13:02:34 visual_prompt]: Total Parameters: 86221058	 Gradient Parameters: 462338
[11/13 13:02:34 visual_prompt]: tuned percent:0.536
[11/13 13:02:34 visual_prompt]: Device used for model: 0
[11/13 13:02:34 visual_prompt]: Setting up Evaluator...
[11/13 13:02:34 visual_prompt]: Setting up Trainer...
[11/13 13:02:34 visual_prompt]: 	Setting up the optimizer...
[11/13 13:02:34 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 13:09:15 visual_prompt]: Epoch 1 / 100: avg data time: 1.11e+01, avg batch time: 11.4641, average train loss: 1.4017
[11/13 13:09:59 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.1577, average loss: 1.2969
[11/13 13:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.18	
[11/13 13:09:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/13 13:16:20 visual_prompt]: Epoch 2 / 100: avg data time: 1.05e+01, avg batch time: 10.8736, average train loss: 3.6468
[11/13 13:17:03 visual_prompt]: Inference (val):avg data time: 2.66e-05, avg batch time: 0.1574, average loss: 0.6812
[11/13 13:17:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 56.78	
[11/13 13:17:03 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/13 13:23:21 visual_prompt]: Epoch 3 / 100: avg data time: 1.04e+01, avg batch time: 10.7979, average train loss: 0.7277
[11/13 13:24:05 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.1546, average loss: 0.6949
[11/13 13:24:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 59.53	
[11/13 13:24:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/13 13:30:23 visual_prompt]: Epoch 4 / 100: avg data time: 1.04e+01, avg batch time: 10.8003, average train loss: 0.9364
[11/13 13:31:06 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1543, average loss: 0.6894
[11/13 13:31:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.26	
[11/13 13:31:06 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/13 13:37:24 visual_prompt]: Epoch 5 / 100: avg data time: 1.04e+01, avg batch time: 10.7895, average train loss: 1.1632
[11/13 13:38:07 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.1561, average loss: 0.7970
[11/13 13:38:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.89	
[11/13 13:38:07 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/13 13:44:22 visual_prompt]: Epoch 6 / 100: avg data time: 1.04e+01, avg batch time: 10.7153, average train loss: 1.6444
[11/13 13:45:05 visual_prompt]: Inference (val):avg data time: 2.64e-05, avg batch time: 0.1578, average loss: 1.4777
[11/13 13:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.03	
[11/13 13:45:05 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/13 13:51:23 visual_prompt]: Epoch 7 / 100: avg data time: 1.04e+01, avg batch time: 10.7872, average train loss: 2.5634
[11/13 13:52:08 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.1587, average loss: 1.7295
[11/13 13:52:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.24	
[11/13 13:52:08 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/13 13:58:43 visual_prompt]: Epoch 8 / 100: avg data time: 1.09e+01, avg batch time: 11.2826, average train loss: 1.3294
[11/13 13:59:29 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.1548, average loss: 1.5858
[11/13 13:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.43	
[11/13 13:59:29 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/13 14:06:03 visual_prompt]: Epoch 9 / 100: avg data time: 1.09e+01, avg batch time: 11.2612, average train loss: 1.0449
[11/13 14:06:48 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.1550, average loss: 1.5837
[11/13 14:06:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.59	
[11/13 14:06:48 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/13 14:13:27 visual_prompt]: Epoch 10 / 100: avg data time: 1.10e+01, avg batch time: 11.4060, average train loss: 0.9955
[11/13 14:14:13 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.1580, average loss: 1.4498
[11/13 14:14:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.75	
[11/13 14:14:13 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/13 14:20:44 visual_prompt]: Epoch 11 / 100: avg data time: 1.08e+01, avg batch time: 11.1531, average train loss: 2.7400
[11/13 14:21:33 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.1573, average loss: 0.6725
[11/13 14:21:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 60.86	
[11/13 14:21:33 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/13 14:28:05 visual_prompt]: Epoch 12 / 100: avg data time: 1.08e+01, avg batch time: 11.2023, average train loss: 1.7798
[11/13 14:28:50 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.1548, average loss: 1.5732
[11/13 14:28:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.55	
[11/13 14:28:50 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/13 14:35:22 visual_prompt]: Epoch 13 / 100: avg data time: 1.08e+01, avg batch time: 11.1888, average train loss: 3.1057
[11/13 14:36:07 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.1546, average loss: 2.8106
[11/13 14:36:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.71	
[11/13 14:36:07 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/13 14:42:26 visual_prompt]: Epoch 14 / 100: avg data time: 1.05e+01, avg batch time: 10.8409, average train loss: 1.8764
[11/13 14:43:10 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.1542, average loss: 1.8100
[11/13 14:43:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.51	
[11/13 14:43:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/13 14:49:29 visual_prompt]: Epoch 15 / 100: avg data time: 1.05e+01, avg batch time: 10.8363, average train loss: 1.4916
[11/13 14:50:12 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.1547, average loss: 0.6773
[11/13 14:50:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 61.61	
[11/13 14:50:12 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/13 14:56:55 visual_prompt]: Epoch 16 / 100: avg data time: 1.12e+01, avg batch time: 11.5099, average train loss: 0.9782
[11/13 14:57:52 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.1549, average loss: 0.7296
[11/13 14:57:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.93	
[11/13 14:57:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/13 15:05:22 visual_prompt]: Epoch 17 / 100: avg data time: 1.25e+01, avg batch time: 12.8580, average train loss: 2.6419
[11/13 15:06:09 visual_prompt]: Inference (val):avg data time: 2.62e-05, avg batch time: 0.1546, average loss: 3.1785
[11/13 15:06:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.29	
[11/13 15:06:09 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/13 15:12:48 visual_prompt]: Epoch 18 / 100: avg data time: 1.11e+01, avg batch time: 11.4122, average train loss: 2.1624
[11/13 15:13:32 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.1544, average loss: 2.9060
[11/13 15:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.04	
[11/13 15:13:32 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/13 15:19:51 visual_prompt]: Epoch 19 / 100: avg data time: 1.05e+01, avg batch time: 10.8260, average train loss: 0.9419
[11/13 15:20:38 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.1546, average loss: 0.8211
[11/13 15:20:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.41	
[11/13 15:20:38 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/13 15:27:17 visual_prompt]: Epoch 20 / 100: avg data time: 1.11e+01, avg batch time: 11.4097, average train loss: 0.8630
[11/13 15:28:00 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.1560, average loss: 0.6662
[11/13 15:28:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 65.07	
[11/13 15:28:00 visual_prompt]: Best epoch 20: best metric: -0.666
[11/13 15:28:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/13 15:34:18 visual_prompt]: Epoch 21 / 100: avg data time: 1.04e+01, avg batch time: 10.7837, average train loss: 0.8961
[11/13 15:35:01 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.1583, average loss: 1.0804
[11/13 15:35:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.77	
[11/13 15:35:01 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
slurmstepd-ctit086: error: *** JOB 246459 ON ctit086 CANCELLED AT 2023-11-13T15:37:27 ***
/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
