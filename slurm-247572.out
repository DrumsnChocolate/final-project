/bin/bash: /home/s1952889/miniconda3/envs/prompt/lib/libtinfo.so.6: no version information available (required by /bin/bash)
An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.
Traceback (most recent call last):
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/file_io.py", line 946, in __log_tmetry_keys
    handler.log_event()
  File "/home/s1952889/miniconda3/envs/prompt/lib/python3.11/site-packages/iopath/common/event_logger.py", line 97, in log_event
    del self._evt
        ^^^^^^^^^
AttributeError: 'NativePathHandler' object has no attribute '_evt'
Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 16:56:06 visual_prompt]: Rank of current process: 0. World size: 1
[11/13 16:56:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/13 16:56:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/13 16:56:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/13 16:56:06 visual_prompt]: Training with config:
[11/13 16:56:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/13 16:56:06 visual_prompt]: Loading training data...
[11/13 16:56:06 visual_prompt]: Constructing mammo-cbis dataset train...
[11/13 16:56:06 visual_prompt]: Loading validation data...
[11/13 16:56:06 visual_prompt]: Constructing mammo-cbis dataset val...
[11/13 16:56:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/13 16:56:09 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/13 16:56:09 visual_prompt]: tuned percent:0.532
[11/13 16:56:10 visual_prompt]: Device used for model: 0
[11/13 16:56:10 visual_prompt]: Setting up Evaluator...
[11/13 16:56:10 visual_prompt]: Setting up Trainer...
[11/13 16:56:10 visual_prompt]: 	Setting up the optimizer...
[11/13 16:56:10 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/13 17:03:52 visual_prompt]: Epoch 1 / 100: avg data time: 5.12e+00, avg batch time: 6.6104, average train loss: 1.4863
[11/13 17:04:43 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.6066, average loss: 1.4553
[11/13 17:04:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/13 17:04:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/13 17:11:57 visual_prompt]: Epoch 2 / 100: avg data time: 4.73e+00, avg batch time: 6.2004, average train loss: 1.6214
[11/13 17:12:47 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5959, average loss: 1.1949
[11/13 17:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.63	
[11/13 17:12:47 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/13 17:20:00 visual_prompt]: Epoch 3 / 100: avg data time: 4.72e+00, avg batch time: 6.1831, average train loss: 0.8810
[11/13 17:20:49 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5923, average loss: 1.9229
[11/13 17:20:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.67	
[11/13 17:20:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/13 17:28:01 visual_prompt]: Epoch 4 / 100: avg data time: 4.71e+00, avg batch time: 6.1706, average train loss: 0.8860
[11/13 17:28:50 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5889, average loss: 0.6878
[11/13 17:28:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.24	
[11/13 17:28:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/13 17:36:03 visual_prompt]: Epoch 5 / 100: avg data time: 4.71e+00, avg batch time: 6.1744, average train loss: 0.9844
[11/13 17:36:52 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5914, average loss: 1.3880
[11/13 17:36:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/13 17:36:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/13 17:44:06 visual_prompt]: Epoch 6 / 100: avg data time: 4.74e+00, avg batch time: 6.2055, average train loss: 1.5478
[11/13 17:44:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5918, average loss: 0.8937
[11/13 17:44:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.44	
[11/13 17:44:56 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/13 17:52:11 visual_prompt]: Epoch 7 / 100: avg data time: 4.75e+00, avg batch time: 6.2177, average train loss: 1.0173
[11/13 17:53:01 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5885, average loss: 0.7426
[11/13 17:53:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.80	
[11/13 17:53:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/13 18:00:19 visual_prompt]: Epoch 8 / 100: avg data time: 4.78e+00, avg batch time: 6.2560, average train loss: 0.8847
[11/13 18:01:09 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5931, average loss: 1.4942
[11/13 18:01:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/13 18:01:09 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/13 18:08:27 visual_prompt]: Epoch 9 / 100: avg data time: 4.79e+00, avg batch time: 6.2611, average train loss: 2.7653
[11/13 18:09:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5937, average loss: 1.0565
[11/13 18:09:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.41	
[11/13 18:09:19 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/13 18:16:35 visual_prompt]: Epoch 10 / 100: avg data time: 4.77e+00, avg batch time: 6.2341, average train loss: 2.6951
[11/13 18:17:25 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5904, average loss: 4.2018
[11/13 18:17:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.56	
[11/13 18:17:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/13 18:24:38 visual_prompt]: Epoch 11 / 100: avg data time: 4.71e+00, avg batch time: 6.1862, average train loss: 4.0179
[11/13 18:25:27 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5980, average loss: 6.0288
[11/13 18:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.77	
[11/13 18:25:27 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/13 18:32:41 visual_prompt]: Epoch 12 / 100: avg data time: 4.72e+00, avg batch time: 6.1936, average train loss: 2.0882
[11/13 18:33:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5971, average loss: 1.0290
[11/13 18:33:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.19	
[11/13 18:33:31 visual_prompt]: Best epoch 12: best metric: -1.029
[11/13 18:33:31 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/13 18:40:44 visual_prompt]: Epoch 13 / 100: avg data time: 4.71e+00, avg batch time: 6.1919, average train loss: 1.2469
[11/13 18:41:33 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.6007, average loss: 1.4594
[11/13 18:41:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.04	
[11/13 18:41:33 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/13 18:48:46 visual_prompt]: Epoch 14 / 100: avg data time: 4.70e+00, avg batch time: 6.1723, average train loss: 1.1669
[11/13 18:49:35 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5930, average loss: 1.1698
[11/13 18:49:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/13 18:49:35 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/13 18:56:47 visual_prompt]: Epoch 15 / 100: avg data time: 4.70e+00, avg batch time: 6.1667, average train loss: 0.9826
[11/13 18:57:36 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5903, average loss: 0.7357
[11/13 18:57:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.94	
[11/13 18:57:36 visual_prompt]: Best epoch 15: best metric: -0.736
[11/13 18:57:36 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/13 19:04:49 visual_prompt]: Epoch 16 / 100: avg data time: 4.71e+00, avg batch time: 6.1783, average train loss: 1.0206
[11/13 19:05:38 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5889, average loss: 0.6875
[11/13 19:05:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 58.50	
[11/13 19:05:38 visual_prompt]: Best epoch 16: best metric: -0.687
[11/13 19:05:38 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/13 19:12:51 visual_prompt]: Epoch 17 / 100: avg data time: 4.71e+00, avg batch time: 6.1741, average train loss: 0.9372
[11/13 19:13:40 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5931, average loss: 0.7151
[11/13 19:13:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.23	
[11/13 19:13:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/13 19:20:51 visual_prompt]: Epoch 18 / 100: avg data time: 4.70e+00, avg batch time: 6.1642, average train loss: 0.8880
[11/13 19:21:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5908, average loss: 1.1504
[11/13 19:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.23	
[11/13 19:21:41 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/13 19:28:52 visual_prompt]: Epoch 19 / 100: avg data time: 4.69e+00, avg batch time: 6.1572, average train loss: 0.9286
[11/13 19:29:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5921, average loss: 1.1004
[11/13 19:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.36	
[11/13 19:29:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/13 19:36:54 visual_prompt]: Epoch 20 / 100: avg data time: 4.71e+00, avg batch time: 6.1851, average train loss: 1.0324
[11/13 19:37:44 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5905, average loss: 0.7345
[11/13 19:37:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.63	
[11/13 19:37:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/13 19:44:56 visual_prompt]: Epoch 21 / 100: avg data time: 4.71e+00, avg batch time: 6.1788, average train loss: 1.0471
[11/13 19:45:46 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5978, average loss: 1.3865
[11/13 19:45:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.72	
[11/13 19:45:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/13 19:52:58 visual_prompt]: Epoch 22 / 100: avg data time: 4.70e+00, avg batch time: 6.1726, average train loss: 1.2070
[11/13 19:53:47 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5875, average loss: 0.9246
[11/13 19:53:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.99	
[11/13 19:53:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/13 20:00:59 visual_prompt]: Epoch 23 / 100: avg data time: 4.69e+00, avg batch time: 6.1673, average train loss: 0.8842
[11/13 20:01:49 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5944, average loss: 1.4459
[11/13 20:01:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.29	
[11/13 20:01:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/13 20:09:04 visual_prompt]: Epoch 24 / 100: avg data time: 4.75e+00, avg batch time: 6.2128, average train loss: 0.9811
[11/13 20:09:54 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5902, average loss: 0.6807
[11/13 20:09:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.36	
[11/13 20:09:54 visual_prompt]: Best epoch 24: best metric: -0.681
[11/13 20:09:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/13 20:17:10 visual_prompt]: Epoch 25 / 100: avg data time: 4.78e+00, avg batch time: 6.2337, average train loss: 0.9889
[11/13 20:18:00 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5927, average loss: 1.7266
[11/13 20:18:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.85	
[11/13 20:18:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/13 20:25:14 visual_prompt]: Epoch 26 / 100: avg data time: 4.75e+00, avg batch time: 6.2085, average train loss: 1.1506
[11/13 20:26:04 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5867, average loss: 1.0583
[11/13 20:26:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.25	
[11/13 20:26:04 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/13 20:33:18 visual_prompt]: Epoch 27 / 100: avg data time: 4.73e+00, avg batch time: 6.1910, average train loss: 0.9342
[11/13 20:34:07 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5878, average loss: 1.0897
[11/13 20:34:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.55	
[11/13 20:34:07 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/13 20:41:22 visual_prompt]: Epoch 28 / 100: avg data time: 4.75e+00, avg batch time: 6.2132, average train loss: 0.9433
[11/13 20:42:12 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5894, average loss: 1.0355
[11/13 20:42:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.10	
[11/13 20:42:12 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/13 20:49:26 visual_prompt]: Epoch 29 / 100: avg data time: 4.74e+00, avg batch time: 6.1964, average train loss: 0.8282
[11/13 20:50:15 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5855, average loss: 1.9617
[11/13 20:50:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.40	
[11/13 20:50:15 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/13 20:57:31 visual_prompt]: Epoch 30 / 100: avg data time: 4.76e+00, avg batch time: 6.2224, average train loss: 0.8803
[11/13 20:58:21 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5889, average loss: 1.3985
[11/13 20:58:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.14	
[11/13 20:58:21 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/13 21:05:34 visual_prompt]: Epoch 31 / 100: avg data time: 4.73e+00, avg batch time: 6.1915, average train loss: 0.8130
[11/13 21:06:24 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5903, average loss: 0.6648
[11/13 21:06:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 65.11	
[11/13 21:06:24 visual_prompt]: Best epoch 31: best metric: -0.665
[11/13 21:06:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/13 21:13:39 visual_prompt]: Epoch 32 / 100: avg data time: 4.76e+00, avg batch time: 6.2149, average train loss: 0.9211
[11/13 21:14:29 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5849, average loss: 0.9366
[11/13 21:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.68	
[11/13 21:14:29 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/13 21:21:45 visual_prompt]: Epoch 33 / 100: avg data time: 4.77e+00, avg batch time: 6.2213, average train loss: 0.9207
[11/13 21:22:34 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5928, average loss: 0.7185
[11/13 21:22:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.69	
[11/13 21:22:34 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/13 21:29:49 visual_prompt]: Epoch 34 / 100: avg data time: 4.75e+00, avg batch time: 6.2108, average train loss: 0.9264
[11/13 21:30:39 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5865, average loss: 1.7004
[11/13 21:30:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.54	
[11/13 21:30:39 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/13 21:37:53 visual_prompt]: Epoch 35 / 100: avg data time: 4.75e+00, avg batch time: 6.2049, average train loss: 0.9421
[11/13 21:38:43 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5887, average loss: 0.7892
[11/13 21:38:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.04	
[11/13 21:38:43 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/13 21:46:00 visual_prompt]: Epoch 36 / 100: avg data time: 4.78e+00, avg batch time: 6.2322, average train loss: 0.7960
[11/13 21:46:49 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5881, average loss: 0.7737
[11/13 21:46:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.26	
[11/13 21:46:49 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/13 21:54:04 visual_prompt]: Epoch 37 / 100: avg data time: 4.74e+00, avg batch time: 6.2030, average train loss: 0.8507
[11/13 21:54:54 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5865, average loss: 0.8610
[11/13 21:54:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.59	
[11/13 21:54:54 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/13 22:02:09 visual_prompt]: Epoch 38 / 100: avg data time: 4.75e+00, avg batch time: 6.2081, average train loss: 0.7865
[11/13 22:02:58 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5881, average loss: 1.3960
[11/13 22:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.72	
[11/13 22:02:58 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/13 22:10:13 visual_prompt]: Epoch 39 / 100: avg data time: 4.76e+00, avg batch time: 6.2097, average train loss: 0.8903
[11/13 22:11:03 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5916, average loss: 1.3137
[11/13 22:11:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.14	
[11/13 22:11:03 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/13 22:18:17 visual_prompt]: Epoch 40 / 100: avg data time: 4.75e+00, avg batch time: 6.1995, average train loss: 0.7843
[11/13 22:19:06 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5864, average loss: 0.6927
[11/13 22:19:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 70.93	
[11/13 22:19:06 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/13 22:26:21 visual_prompt]: Epoch 41 / 100: avg data time: 4.75e+00, avg batch time: 6.2039, average train loss: 0.7661
[11/13 22:27:10 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5949, average loss: 0.8193
[11/13 22:27:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[11/13 22:27:10 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/13 22:34:25 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e+00, avg batch time: 6.2019, average train loss: 0.7495
[11/13 22:35:14 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5855, average loss: 0.6496
[11/13 22:35:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.28	
[11/13 22:35:14 visual_prompt]: Best epoch 42: best metric: -0.650
[11/13 22:35:14 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/13 22:42:29 visual_prompt]: Epoch 43 / 100: avg data time: 4.75e+00, avg batch time: 6.2073, average train loss: 0.7161
[11/13 22:43:19 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5913, average loss: 1.9414
[11/13 22:43:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.75	
[11/13 22:43:19 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/13 22:50:34 visual_prompt]: Epoch 44 / 100: avg data time: 4.76e+00, avg batch time: 6.2198, average train loss: 0.8816
[11/13 22:51:24 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.5882, average loss: 0.6577
[11/13 22:51:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 65.47	
[11/13 22:51:24 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/13 22:58:38 visual_prompt]: Epoch 45 / 100: avg data time: 4.75e+00, avg batch time: 6.2077, average train loss: 0.7604
[11/13 22:59:28 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5902, average loss: 0.7783
[11/13 22:59:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.51	
[11/13 22:59:28 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/13 23:06:42 visual_prompt]: Epoch 46 / 100: avg data time: 4.74e+00, avg batch time: 6.1976, average train loss: 0.7785
[11/13 23:07:31 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5902, average loss: 0.6453
[11/13 23:07:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.25	
[11/13 23:07:31 visual_prompt]: Best epoch 46: best metric: -0.645
[11/13 23:07:31 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/13 23:14:46 visual_prompt]: Epoch 47 / 100: avg data time: 4.74e+00, avg batch time: 6.2024, average train loss: 0.9601
[11/13 23:15:36 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5861, average loss: 0.7167
[11/13 23:15:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.11	
[11/13 23:15:36 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/13 23:22:49 visual_prompt]: Epoch 48 / 100: avg data time: 4.73e+00, avg batch time: 6.1877, average train loss: 0.6963
[11/13 23:23:38 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5916, average loss: 1.7540
[11/13 23:23:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.67	
[11/13 23:23:38 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/13 23:30:53 visual_prompt]: Epoch 49 / 100: avg data time: 4.75e+00, avg batch time: 6.2074, average train loss: 0.9557
[11/13 23:31:43 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5863, average loss: 1.4158
[11/13 23:31:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.71	
[11/13 23:31:43 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/13 23:38:57 visual_prompt]: Epoch 50 / 100: avg data time: 4.75e+00, avg batch time: 6.2011, average train loss: 0.9288
[11/13 23:39:46 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5919, average loss: 0.7403
[11/13 23:39:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.05	
[11/13 23:39:46 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/13 23:47:01 visual_prompt]: Epoch 51 / 100: avg data time: 4.75e+00, avg batch time: 6.2056, average train loss: 0.7229
[11/13 23:47:50 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5884, average loss: 0.8697
[11/13 23:47:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.91	
[11/13 23:47:50 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/13 23:55:04 visual_prompt]: Epoch 52 / 100: avg data time: 4.74e+00, avg batch time: 6.1965, average train loss: 0.7241
[11/13 23:55:54 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5893, average loss: 0.6523
[11/13 23:55:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.87	
[11/13 23:55:54 visual_prompt]: Training 53 / 100 epoch, with learning rate 1.380660579084567
[11/14 00:03:09 visual_prompt]: Epoch 53 / 100: avg data time: 4.76e+00, avg batch time: 6.2183, average train loss: 0.7654
[11/14 00:03:59 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5890, average loss: 0.6691
[11/14 00:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.50	
[11/14 00:03:59 visual_prompt]: Training 54 / 100 epoch, with learning rate 1.3371955921801564
[11/14 00:11:13 visual_prompt]: Epoch 54 / 100: avg data time: 4.74e+00, avg batch time: 6.2025, average train loss: 0.7238
[11/14 00:12:03 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5910, average loss: 1.7287
[11/14 00:12:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 68.79	
[11/14 00:12:03 visual_prompt]: Training 55 / 100 epoch, with learning rate 1.2936243708781263
[11/14 00:19:16 visual_prompt]: Epoch 55 / 100: avg data time: 4.73e+00, avg batch time: 6.1916, average train loss: 1.0356
[11/14 00:20:06 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5879, average loss: 2.2162
[11/14 00:20:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.28	
[11/14 00:20:06 visual_prompt]: Training 56 / 100 epoch, with learning rate 1.25
[11/14 00:27:19 visual_prompt]: Epoch 56 / 100: avg data time: 4.74e+00, avg batch time: 6.1928, average train loss: 1.2473
[11/14 00:28:09 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5911, average loss: 0.9496
[11/14 00:28:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.13	
[11/14 00:28:09 visual_prompt]: Training 57 / 100 epoch, with learning rate 1.2063756291218741
[11/14 00:35:25 visual_prompt]: Epoch 57 / 100: avg data time: 4.76e+00, avg batch time: 6.2189, average train loss: 0.8415
[11/14 00:36:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5873, average loss: 0.8823
[11/14 00:36:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.23	
[11/14 00:36:14 visual_prompt]: Training 58 / 100 epoch, with learning rate 1.1628044078198434
[11/14 00:43:28 visual_prompt]: Epoch 58 / 100: avg data time: 4.74e+00, avg batch time: 6.1929, average train loss: 0.7703
[11/14 00:44:18 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5835, average loss: 0.9684
[11/14 00:44:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.40	
[11/14 00:44:18 visual_prompt]: Training 59 / 100 epoch, with learning rate 1.1193394209154333
[11/14 00:51:32 visual_prompt]: Epoch 59 / 100: avg data time: 4.75e+00, avg batch time: 6.2101, average train loss: 0.7828
[11/14 00:52:22 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5912, average loss: 0.6654
[11/14 00:52:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.61	
[11/14 00:52:22 visual_prompt]: Training 60 / 100 epoch, with learning rate 1.0760336237999186
[11/14 00:59:36 visual_prompt]: Epoch 60 / 100: avg data time: 4.74e+00, avg batch time: 6.1970, average train loss: 0.6723
[11/14 01:00:25 visual_prompt]: Inference (val):avg data time: 3.91e-05, avg batch time: 0.5910, average loss: 0.6401
[11/14 01:00:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.13	
[11/14 01:00:25 visual_prompt]: Best epoch 60: best metric: -0.640
[11/14 01:00:25 visual_prompt]: Training 61 / 100 epoch, with learning rate 1.0329397779163372
[11/14 01:07:39 visual_prompt]: Epoch 61 / 100: avg data time: 4.74e+00, avg batch time: 6.1946, average train loss: 0.7060
[11/14 01:08:29 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5949, average loss: 0.6808
[11/14 01:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.25	
[11/14 01:08:29 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.990110386477801
[11/14 01:15:42 visual_prompt]: Epoch 62 / 100: avg data time: 4.73e+00, avg batch time: 6.1897, average train loss: 0.6743
[11/14 01:16:32 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5852, average loss: 0.7265
[11/14 01:16:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.70	
[11/14 01:16:32 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.9475976305004155
[11/14 01:23:50 visual_prompt]: Epoch 63 / 100: avg data time: 4.80e+00, avg batch time: 6.2589, average train loss: 0.6645
[11/14 01:24:42 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5899, average loss: 0.6328
[11/14 01:24:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.30	
[11/14 01:24:42 visual_prompt]: Best epoch 63: best metric: -0.633
[11/14 01:24:42 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.9054533052287511
[11/14 01:32:23 visual_prompt]: Epoch 64 / 100: avg data time: 5.10e+00, avg batch time: 6.5833, average train loss: 0.6621
[11/14 01:33:14 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5933, average loss: 0.7139
[11/14 01:33:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.77	
[11/14 01:33:14 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.8637287570313158
[11/14 01:40:28 visual_prompt]: Epoch 65 / 100: avg data time: 4.72e+00, avg batch time: 6.1929, average train loss: 0.6703
[11/14 01:41:17 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5884, average loss: 0.6501
[11/14 01:41:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 67.36	
[11/14 01:41:17 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.8224748208429142
[11/14 01:48:23 visual_prompt]: Epoch 66 / 100: avg data time: 4.61e+00, avg batch time: 6.0782, average train loss: 0.7395
[11/14 01:49:12 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5897, average loss: 0.6679
[11/14 01:49:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.39	
[11/14 01:49:12 visual_prompt]: Training 67 / 100 epoch, with learning rate 0.7817417582301099
[11/14 01:56:40 visual_prompt]: Epoch 67 / 100: avg data time: 4.93e+00, avg batch time: 6.3984, average train loss: 0.6559
[11/14 01:57:32 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5955, average loss: 0.7737
[11/14 01:57:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 68.17	
[11/14 01:57:32 visual_prompt]: Training 68 / 100 epoch, with learning rate 0.7415791961552499
[11/14 02:05:05 visual_prompt]: Epoch 68 / 100: avg data time: 5.00e+00, avg batch time: 6.4724, average train loss: 0.7044
[11/14 02:05:57 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5911, average loss: 0.6332
[11/14 02:05:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.44	
[11/14 02:05:57 visual_prompt]: Training 69 / 100 epoch, with learning rate 0.7020360665136531
[11/14 02:13:12 visual_prompt]: Epoch 69 / 100: avg data time: 4.73e+00, avg batch time: 6.2146, average train loss: 0.6891
[11/14 02:14:01 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5907, average loss: 0.6384
[11/14 02:14:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.15	
[11/14 02:14:01 visual_prompt]: Training 70 / 100 epoch, with learning rate 0.6631605465176369
[11/14 02:21:11 visual_prompt]: Epoch 70 / 100: avg data time: 4.67e+00, avg batch time: 6.1392, average train loss: 0.6296
[11/14 02:21:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5937, average loss: 0.7300
[11/14 02:22:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 69.00	
[11/14 02:22:00 visual_prompt]: Training 71 / 100 epoch, with learning rate 0.6250000000000002
[11/14 02:29:18 visual_prompt]: Epoch 71 / 100: avg data time: 4.80e+00, avg batch time: 6.2677, average train loss: 0.6490
[11/14 02:30:10 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5876, average loss: 0.6348
[11/14 02:30:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.61	
[11/14 02:30:10 visual_prompt]: Training 72 / 100 epoch, with learning rate 0.587600919708494
[11/14 02:37:43 visual_prompt]: Epoch 72 / 100: avg data time: 4.99e+00, avg batch time: 6.4673, average train loss: 0.6206
[11/14 02:38:35 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5914, average loss: 0.6337
[11/14 02:38:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.83	
[11/14 02:38:35 visual_prompt]: Training 73 / 100 epoch, with learning rate 0.5510088706615667
[11/14 02:46:07 visual_prompt]: Epoch 73 / 100: avg data time: 5.00e+00, avg batch time: 6.4682, average train loss: 0.6205
[11/14 02:46:59 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5912, average loss: 0.7726
[11/14 02:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.87	
[11/14 02:46:59 visual_prompt]: Training 74 / 100 epoch, with learning rate 0.5152684346344087
[11/14 02:54:30 visual_prompt]: Epoch 74 / 100: avg data time: 4.97e+00, avg batch time: 6.4376, average train loss: 0.6449
[11/14 02:55:19 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5937, average loss: 0.6412
[11/14 02:55:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.38	
[11/14 02:55:19 visual_prompt]: Training 75 / 100 epoch, with learning rate 0.48042315584292716
[11/14 03:02:27 visual_prompt]: Epoch 75 / 100: avg data time: 4.64e+00, avg batch time: 6.1148, average train loss: 0.6157
[11/14 03:03:16 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5952, average loss: 0.6767
[11/14 03:03:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.55	
[11/14 03:03:16 visual_prompt]: Training 76 / 100 epoch, with learning rate 0.4465154878918258
[11/14 03:10:29 visual_prompt]: Epoch 76 / 100: avg data time: 4.72e+00, avg batch time: 6.1874, average train loss: 0.6182
[11/14 03:11:20 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5902, average loss: 0.6633
[11/14 03:11:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.46	
[11/14 03:11:20 visual_prompt]: Training 77 / 100 epoch, with learning rate 0.41358674205142765
[11/14 03:19:05 visual_prompt]: Epoch 77 / 100: avg data time: 5.18e+00, avg batch time: 6.6408, average train loss: 0.6020
[11/14 03:19:58 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5890, average loss: 0.7176
[11/14 03:19:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.95	
[11/14 03:19:58 visual_prompt]: Training 78 / 100 epoch, with learning rate 0.3816770369262533
[11/14 03:27:21 visual_prompt]: Epoch 78 / 100: avg data time: 4.86e+00, avg batch time: 6.3264, average train loss: 0.5960
[11/14 03:28:11 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5890, average loss: 0.7108
[11/14 03:28:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.09	
[11/14 03:28:11 visual_prompt]: Training 79 / 100 epoch, with learning rate 0.35082524957668626
[11/14 03:35:34 visual_prompt]: Epoch 79 / 100: avg data time: 4.83e+00, avg batch time: 6.3171, average train loss: 0.5873
[11/14 03:36:24 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5970, average loss: 0.6371
[11/14 03:36:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.07	
[11/14 03:36:24 visual_prompt]: Training 80 / 100 epoch, with learning rate 0.32106896815325703
[11/14 03:43:47 visual_prompt]: Epoch 80 / 100: avg data time: 4.85e+00, avg batch time: 6.3272, average train loss: 0.5784
[11/14 03:44:37 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5971, average loss: 0.6325
[11/14 03:44:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 70.33	
[11/14 03:44:37 visual_prompt]: Best epoch 80: best metric: -0.633
[11/14 03:44:37 visual_prompt]: Training 81 / 100 epoch, with learning rate 0.2924444461012776
[11/14 03:51:45 visual_prompt]: Epoch 81 / 100: avg data time: 4.65e+00, avg batch time: 6.1148, average train loss: 0.5605
[11/14 03:52:34 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5858, average loss: 0.7297
[11/14 03:52:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 74.49	
[11/14 03:52:34 visual_prompt]: Training 82 / 100 epoch, with learning rate 0.26498655799159765
[11/14 03:59:47 visual_prompt]: Epoch 82 / 100: avg data time: 4.71e+00, avg batch time: 6.1739, average train loss: 0.5900
[11/14 04:00:36 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5964, average loss: 0.6502
[11/14 04:00:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.00	
[11/14 04:00:36 visual_prompt]: Training 83 / 100 epoch, with learning rate 0.23872875703131582
[11/14 04:07:57 visual_prompt]: Epoch 83 / 100: avg data time: 4.84e+00, avg batch time: 6.3100, average train loss: 0.5643
[11/14 04:08:48 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5945, average loss: 0.6655
[11/14 04:08:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 70.90	
[11/14 04:08:48 visual_prompt]: Training 84 / 100 epoch, with learning rate 0.21370303430619797
[11/14 04:16:10 visual_prompt]: Epoch 84 / 100: avg data time: 4.84e+00, avg batch time: 6.3167, average train loss: 0.5724
[11/14 04:16:59 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5980, average loss: 0.6592
[11/14 04:16:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.76	
[11/14 04:16:59 visual_prompt]: Training 85 / 100 epoch, with learning rate 0.18993987980446755
[11/14 04:24:09 visual_prompt]: Epoch 85 / 100: avg data time: 4.67e+00, avg batch time: 6.1442, average train loss: 0.5365
[11/14 04:24:58 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5996, average loss: 0.6109
[11/14 04:24:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.75	
[11/14 04:24:58 visual_prompt]: Best epoch 85: best metric: -0.611
[11/14 04:24:58 visual_prompt]: Training 86 / 100 epoch, with learning rate 0.16746824526945162
[11/14 04:32:08 visual_prompt]: Epoch 86 / 100: avg data time: 4.66e+00, avg batch time: 6.1414, average train loss: 0.5241
[11/14 04:33:00 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5970, average loss: 0.7347
[11/14 04:33:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.04	
[11/14 04:33:00 visual_prompt]: Training 87 / 100 epoch, with learning rate 0.14631550892634126
[11/14 04:40:21 visual_prompt]: Epoch 87 / 100: avg data time: 4.83e+00, avg batch time: 6.2970, average train loss: 0.5402
[11/14 04:41:10 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5900, average loss: 0.7204
[11/14 04:41:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.43	
[11/14 04:41:10 visual_prompt]: Training 88 / 100 epoch, with learning rate 0.12650744212604148
[11/14 04:48:18 visual_prompt]: Epoch 88 / 100: avg data time: 4.64e+00, avg batch time: 6.1126, average train loss: 0.5067
[11/14 04:49:07 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5935, average loss: 0.7077
[11/14 04:49:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.06	
[11/14 04:49:07 visual_prompt]: Training 89 / 100 epoch, with learning rate 0.10806817794674878
[11/14 04:56:19 visual_prompt]: Epoch 89 / 100: avg data time: 4.70e+00, avg batch time: 6.1768, average train loss: 0.4910
[11/14 04:57:11 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5935, average loss: 0.7293
[11/14 04:57:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 68.86	
[11/14 04:57:11 visual_prompt]: Training 90 / 100 epoch, with learning rate 0.09102018179151586
[11/14 05:04:35 visual_prompt]: Epoch 90 / 100: avg data time: 4.86e+00, avg batch time: 6.3393, average train loss: 0.4973
[11/14 05:05:25 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5986, average loss: 0.7170
[11/14 05:05:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.91	
[11/14 05:05:25 visual_prompt]: Training 91 / 100 epoch, with learning rate 0.0753842240176146
[11/14 05:12:39 visual_prompt]: Epoch 91 / 100: avg data time: 4.72e+00, avg batch time: 6.1904, average train loss: 0.4893
[11/14 05:13:29 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5921, average loss: 0.8093
[11/14 05:13:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.81	
[11/14 05:13:29 visual_prompt]: Training 92 / 100 epoch, with learning rate 0.061179354631058086
[11/14 05:20:49 visual_prompt]: Epoch 92 / 100: avg data time: 4.83e+00, avg batch time: 6.2880, average train loss: 0.4622
[11/14 05:21:41 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5977, average loss: 0.6774
[11/14 05:21:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 68.46	
[11/14 05:21:41 visual_prompt]: Training 93 / 100 epoch, with learning rate 0.04842288007710138
[11/14 05:29:13 visual_prompt]: Epoch 93 / 100: avg data time: 4.98e+00, avg batch time: 6.4471, average train loss: 0.4419
[11/14 05:30:02 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5880, average loss: 0.7900
[11/14 05:30:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.91	
[11/14 05:30:02 visual_prompt]: Training 94 / 100 epoch, with learning rate 0.03713034215500441
[11/14 05:37:08 visual_prompt]: Epoch 94 / 100: avg data time: 4.62e+00, avg batch time: 6.0904, average train loss: 0.4248
[11/14 05:37:57 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5949, average loss: 0.8497
[11/14 05:37:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.43	
[11/14 05:37:57 visual_prompt]: Training 95 / 100 epoch, with learning rate 0.02731549908274289
[11/14 05:45:09 visual_prompt]: Epoch 95 / 100: avg data time: 4.69e+00, avg batch time: 6.1573, average train loss: 0.4215
[11/14 05:46:01 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5916, average loss: 0.8489
[11/14 05:46:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.34	
[11/14 05:46:01 visual_prompt]: Training 96 / 100 epoch, with learning rate 0.018990308734739975
[11/14 05:53:20 visual_prompt]: Epoch 96 / 100: avg data time: 4.80e+00, avg batch time: 6.2692, average train loss: 0.4017
[11/14 05:54:09 visual_prompt]: Inference (val):avg data time: 2.61e-05, avg batch time: 0.5971, average loss: 0.8459
[11/14 05:54:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 64.88	
[11/14 05:54:09 visual_prompt]: Training 97 / 100 epoch, with learning rate 0.012164914073037048
[11/14 06:01:15 visual_prompt]: Epoch 97 / 100: avg data time: 4.61e+00, avg batch time: 6.0836, average train loss: 0.3947
[11/14 06:02:04 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5895, average loss: 0.8532
[11/14 06:02:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 65.91	
[11/14 06:02:04 visual_prompt]: Training 98 / 100 epoch, with learning rate 0.006847630789658388
[11/14 06:09:32 visual_prompt]: Epoch 98 / 100: avg data time: 4.93e+00, avg batch time: 6.4019, average train loss: 0.3824
[11/14 06:10:22 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5999, average loss: 0.9099
[11/14 06:10:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 65.48	
[11/14 06:10:22 visual_prompt]: Training 99 / 100 epoch, with learning rate 0.003044937175219753
[11/14 06:17:31 visual_prompt]: Epoch 99 / 100: avg data time: 4.66e+00, avg batch time: 6.1328, average train loss: 0.3744
[11/14 06:18:20 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5932, average loss: 0.9119
[11/14 06:18:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 64.96	
[11/14 06:18:20 visual_prompt]: Training 100 / 100 epoch, with learning rate 0.0007614662261302974
[11/14 06:25:28 visual_prompt]: Epoch 100 / 100: avg data time: 4.65e+00, avg batch time: 6.1225, average train loss: 0.3741
[11/14 06:26:21 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5948, average loss: 0.9522
[11/14 06:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.01	
[11/14 06:26:22 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 06:26:22 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 06:26:22 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 06:26:22 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 06:26:22 visual_prompt]: Training with config:
[11/14 06:26:22 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr2.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 2.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 06:26:22 visual_prompt]: Loading training data...
[11/14 06:26:22 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 06:26:22 visual_prompt]: Loading validation data...
[11/14 06:26:22 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 06:26:22 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 06:26:27 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 06:26:27 visual_prompt]: tuned percent:0.532
[11/14 06:26:27 visual_prompt]: Device used for model: 0
[11/14 06:26:27 visual_prompt]: Setting up Evaluator...
[11/14 06:26:27 visual_prompt]: Setting up Trainer...
[11/14 06:26:27 visual_prompt]: 	Setting up the optimizer...
[11/14 06:26:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 06:34:09 visual_prompt]: Epoch 1 / 100: avg data time: 5.12e+00, avg batch time: 6.5960, average train loss: 1.4863
[11/14 06:34:58 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5944, average loss: 1.4553
[11/14 06:34:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 06:34:58 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.25
[11/14 06:42:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.66e+00, avg batch time: 6.1297, average train loss: 1.6234
[11/14 06:42:56 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5895, average loss: 1.2002
[11/14 06:42:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.39	
[11/14 06:42:56 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.5
[11/14 06:50:13 visual_prompt]: Epoch 3 / 100: avg data time: 4.78e+00, avg batch time: 6.2471, average train loss: 0.8825
[11/14 06:51:05 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5890, average loss: 1.9262
[11/14 06:51:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.37	
[11/14 06:51:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.75
[11/14 06:58:20 visual_prompt]: Epoch 4 / 100: avg data time: 4.74e+00, avg batch time: 6.2054, average train loss: 0.8895
[11/14 06:59:09 visual_prompt]: Inference (val):avg data time: 2.82e-05, avg batch time: 0.5847, average loss: 0.6904
[11/14 06:59:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 57.46	
[11/14 06:59:09 visual_prompt]: Training 5 / 100 epoch, with learning rate 1.0
[11/14 07:06:15 visual_prompt]: Epoch 5 / 100: avg data time: 4.62e+00, avg batch time: 6.0874, average train loss: 1.0184
[11/14 07:07:04 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5914, average loss: 1.2124
[11/14 07:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.08	
[11/14 07:07:04 visual_prompt]: Training 6 / 100 epoch, with learning rate 1.25
[11/14 07:14:28 visual_prompt]: Epoch 6 / 100: avg data time: 4.87e+00, avg batch time: 6.3396, average train loss: 1.7453
[11/14 07:15:20 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5980, average loss: 2.4215
[11/14 07:15:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.67	
[11/14 07:15:20 visual_prompt]: Training 7 / 100 epoch, with learning rate 1.5
[11/14 07:22:30 visual_prompt]: Epoch 7 / 100: avg data time: 4.68e+00, avg batch time: 6.1413, average train loss: 2.6563
[11/14 07:23:19 visual_prompt]: Inference (val):avg data time: 2.46e-05, avg batch time: 0.5912, average loss: 1.1308
[11/14 07:23:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.90	
[11/14 07:23:19 visual_prompt]: Training 8 / 100 epoch, with learning rate 1.75
[11/14 07:30:29 visual_prompt]: Epoch 8 / 100: avg data time: 4.66e+00, avg batch time: 6.1392, average train loss: 0.9193
[11/14 07:31:20 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5982, average loss: 1.9297
[11/14 07:31:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.54	
[11/14 07:31:20 visual_prompt]: Training 9 / 100 epoch, with learning rate 2.0
[11/14 07:38:51 visual_prompt]: Epoch 9 / 100: avg data time: 4.98e+00, avg batch time: 6.4505, average train loss: 1.5521
[11/14 07:39:44 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5891, average loss: 0.7257
[11/14 07:39:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 62.16	
[11/14 07:39:44 visual_prompt]: Training 10 / 100 epoch, with learning rate 2.25
[11/14 07:47:07 visual_prompt]: Epoch 10 / 100: avg data time: 4.86e+00, avg batch time: 6.3244, average train loss: 1.8357
[11/14 07:47:56 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5897, average loss: 1.1747
[11/14 07:47:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.59	
[11/14 07:47:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 2.5
[11/14 07:55:12 visual_prompt]: Epoch 11 / 100: avg data time: 4.75e+00, avg batch time: 6.2263, average train loss: 1.4509
[11/14 07:56:02 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.6008, average loss: 1.2769
[11/14 07:56:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[11/14 07:56:02 visual_prompt]: Training 12 / 100 epoch, with learning rate 2.4992385337738696
[11/14 08:03:27 visual_prompt]: Epoch 12 / 100: avg data time: 4.89e+00, avg batch time: 6.3575, average train loss: 1.3602
[11/14 08:04:19 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5958, average loss: 0.8997
[11/14 08:04:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.84	
[11/14 08:04:19 visual_prompt]: Best epoch 12: best metric: -0.900
[11/14 08:04:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 2.4969550628247803
[11/14 08:11:30 visual_prompt]: Epoch 13 / 100: avg data time: 4.68e+00, avg batch time: 6.1581, average train loss: 1.4793
[11/14 08:12:20 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5976, average loss: 0.7527
[11/14 08:12:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 61.32	
[11/14 08:12:20 visual_prompt]: Best epoch 13: best metric: -0.753
[11/14 08:12:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 2.4931523692103417
[11/14 08:19:28 visual_prompt]: Epoch 14 / 100: avg data time: 4.65e+00, avg batch time: 6.1209, average train loss: 1.3267
[11/14 08:20:17 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5894, average loss: 0.7889
[11/14 08:20:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.60	
[11/14 08:20:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 2.487835085926963
[11/14 08:27:42 visual_prompt]: Epoch 15 / 100: avg data time: 4.88e+00, avg batch time: 6.3486, average train loss: 0.8805
[11/14 08:28:33 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5855, average loss: 1.0179
[11/14 08:28:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.91	
[11/14 08:28:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 2.4810096912652604
[11/14 08:35:43 visual_prompt]: Epoch 16 / 100: avg data time: 4.66e+00, avg batch time: 6.1329, average train loss: 1.0770
[11/14 08:36:32 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5914, average loss: 0.7695
[11/14 08:36:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 60.53	
[11/14 08:36:32 visual_prompt]: Training 17 / 100 epoch, with learning rate 2.472684500917257
[11/14 08:43:41 visual_prompt]: Epoch 17 / 100: avg data time: 4.66e+00, avg batch time: 6.1297, average train loss: 1.0693
[11/14 08:44:30 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5963, average loss: 1.1426
[11/14 08:44:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.77	
[11/14 08:44:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 2.4628696578449953
[11/14 08:52:02 visual_prompt]: Epoch 18 / 100: avg data time: 5.00e+00, avg batch time: 6.4602, average train loss: 1.7269
[11/14 08:52:58 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5885, average loss: 3.1994
[11/14 08:52:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.98	
[11/14 08:52:58 visual_prompt]: Training 19 / 100 epoch, with learning rate 2.4515771199228986
[11/14 09:00:13 visual_prompt]: Epoch 19 / 100: avg data time: 4.75e+00, avg batch time: 6.2185, average train loss: 0.9595
[11/14 09:01:02 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5937, average loss: 1.2690
[11/14 09:01:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 66.41	
[11/14 09:01:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 2.438820645368942
[11/14 09:08:11 visual_prompt]: Epoch 20 / 100: avg data time: 4.66e+00, avg batch time: 6.1241, average train loss: 0.9201
[11/14 09:09:00 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5919, average loss: 1.3413
[11/14 09:09:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.75	
[11/14 09:09:00 visual_prompt]: Training 21 / 100 epoch, with learning rate 2.4246157759823856
[11/14 09:16:28 visual_prompt]: Epoch 21 / 100: avg data time: 4.92e+00, avg batch time: 6.4015, average train loss: 0.9774
[11/14 09:17:19 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5974, average loss: 1.1516
[11/14 09:17:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.61	
[11/14 09:17:19 visual_prompt]: Training 22 / 100 epoch, with learning rate 2.4089798182084845
[11/14 09:24:29 visual_prompt]: Epoch 22 / 100: avg data time: 4.67e+00, avg batch time: 6.1377, average train loss: 1.1508
[11/14 09:25:18 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5920, average loss: 0.9339
[11/14 09:25:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.30	
[11/14 09:25:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 2.391931822053251
[11/14 09:32:25 visual_prompt]: Epoch 23 / 100: avg data time: 4.62e+00, avg batch time: 6.1020, average train loss: 0.9111
[11/14 09:33:15 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5963, average loss: 1.0304
[11/14 09:33:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.42	
[11/14 09:33:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 2.3734925578739587
[11/14 09:40:43 visual_prompt]: Epoch 24 / 100: avg data time: 4.93e+00, avg batch time: 6.4017, average train loss: 0.8268
[11/14 09:41:34 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5909, average loss: 1.1132
[11/14 09:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 68.37	
[11/14 09:41:34 visual_prompt]: Training 25 / 100 epoch, with learning rate 2.3536844910736585
[11/14 09:48:56 visual_prompt]: Epoch 25 / 100: avg data time: 4.85e+00, avg batch time: 6.3248, average train loss: 1.0879
[11/14 09:49:47 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5941, average loss: 1.8979
[11/14 09:49:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.44	
[11/14 09:49:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 2.3325317547305486
[11/14 09:57:08 visual_prompt]: Epoch 26 / 100: avg data time: 4.84e+00, avg batch time: 6.3064, average train loss: 1.1431
[11/14 09:57:59 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5962, average loss: 0.7541
[11/14 09:57:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 67.81	
[11/14 09:57:59 visual_prompt]: Training 27 / 100 epoch, with learning rate 2.310060120195532
[11/14 10:05:34 visual_prompt]: Epoch 27 / 100: avg data time: 5.04e+00, avg batch time: 6.5000, average train loss: 0.9422
[11/14 10:06:25 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5891, average loss: 0.8976
[11/14 10:06:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 69.41	
[11/14 10:06:25 visual_prompt]: Training 28 / 100 epoch, with learning rate 2.286296965693802
[11/14 10:13:42 visual_prompt]: Epoch 28 / 100: avg data time: 4.76e+00, avg batch time: 6.2325, average train loss: 0.7822
[11/14 10:14:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.6013, average loss: 0.6698
[11/14 10:14:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 70.73	
[11/14 10:14:31 visual_prompt]: Best epoch 28: best metric: -0.670
[11/14 10:14:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 2.261271242968684
[11/14 10:21:39 visual_prompt]: Epoch 29 / 100: avg data time: 4.65e+00, avg batch time: 6.1167, average train loss: 0.6927
[11/14 10:22:29 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5859, average loss: 1.4558
[11/14 10:22:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.04	
[11/14 10:22:29 visual_prompt]: Training 30 / 100 epoch, with learning rate 2.2350134420084022
[11/14 10:29:59 visual_prompt]: Epoch 30 / 100: avg data time: 4.96e+00, avg batch time: 6.4383, average train loss: 0.7463
[11/14 10:30:48 visual_prompt]: Inference (val):avg data time: 2.57e-05, avg batch time: 0.5982, average loss: 1.2907
[11/14 10:30:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.85	
[11/14 10:30:48 visual_prompt]: Training 31 / 100 epoch, with learning rate 2.2075555538987226
[11/14 10:37:56 visual_prompt]: Epoch 31 / 100: avg data time: 4.64e+00, avg batch time: 6.1114, average train loss: 0.7680
[11/14 10:38:45 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5915, average loss: 0.6404
[11/14 10:38:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 69.08	
[11/14 10:38:45 visual_prompt]: Best epoch 31: best metric: -0.640
[11/14 10:38:45 visual_prompt]: Training 32 / 100 epoch, with learning rate 2.178931031846743
[11/14 10:46:08 visual_prompt]: Epoch 32 / 100: avg data time: 4.86e+00, avg batch time: 6.3266, average train loss: 0.9898
[11/14 10:47:01 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5960, average loss: 1.7695
[11/14 10:47:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.22	
[11/14 10:47:01 visual_prompt]: Training 33 / 100 epoch, with learning rate 2.149174750423314
[11/14 10:54:47 visual_prompt]: Epoch 33 / 100: avg data time: 5.18e+00, avg batch time: 6.6529, average train loss: 0.7486
[11/14 10:55:40 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5953, average loss: 0.7089
[11/14 10:55:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 68.69	
[11/14 10:55:40 visual_prompt]: Training 34 / 100 epoch, with learning rate 2.1183229630737466
[11/14 11:03:20 visual_prompt]: Epoch 34 / 100: avg data time: 5.10e+00, avg batch time: 6.5663, average train loss: 0.9704
[11/14 11:04:12 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5869, average loss: 1.0658
[11/14 11:04:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 69.97	
[11/14 11:04:12 visual_prompt]: Training 35 / 100 epoch, with learning rate 2.086413257948573
[11/14 11:12:40 visual_prompt]: Epoch 35 / 100: avg data time: 5.78e+00, avg batch time: 7.2518, average train loss: 0.7812
[11/14 11:13:32 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5944, average loss: 0.6667
[11/14 11:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.03	
[11/14 11:13:32 visual_prompt]: Training 36 / 100 epoch, with learning rate 2.053484512108174
[11/14 11:21:25 visual_prompt]: Epoch 36 / 100: avg data time: 5.28e+00, avg batch time: 6.7488, average train loss: 0.6820
[11/14 11:22:20 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5915, average loss: 1.3235
[11/14 11:22:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.56	rocauc: 70.90	
[11/14 11:22:20 visual_prompt]: Training 37 / 100 epoch, with learning rate 2.019576844157073
[11/14 11:29:55 visual_prompt]: Epoch 37 / 100: avg data time: 5.02e+00, avg batch time: 6.4937, average train loss: 0.7202
[11/14 11:30:47 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5921, average loss: 0.7041
[11/14 11:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 70.96	
[11/14 11:30:47 visual_prompt]: Training 38 / 100 epoch, with learning rate 1.9847315653655915
[11/14 11:38:14 visual_prompt]: Epoch 38 / 100: avg data time: 4.91e+00, avg batch time: 6.3903, average train loss: 0.8081
[11/14 11:39:05 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5943, average loss: 1.4343
[11/14 11:39:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 68.50	
[11/14 11:39:05 visual_prompt]: Training 39 / 100 epoch, with learning rate 1.9489911293384334
[11/14 11:46:36 visual_prompt]: Epoch 39 / 100: avg data time: 4.98e+00, avg batch time: 6.4420, average train loss: 0.7012
[11/14 11:47:29 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5888, average loss: 1.5978
[11/14 11:47:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 69.80	
[11/14 11:47:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 1.912399080291506
[11/14 11:54:55 visual_prompt]: Epoch 40 / 100: avg data time: 4.89e+00, avg batch time: 6.3692, average train loss: 0.7909
[11/14 11:55:46 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5966, average loss: 0.7338
[11/14 11:55:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.81	
[11/14 11:55:46 visual_prompt]: Training 41 / 100 epoch, with learning rate 1.875
[11/14 12:03:08 visual_prompt]: Epoch 41 / 100: avg data time: 4.84e+00, avg batch time: 6.3143, average train loss: 0.6203
[11/14 12:03:59 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5981, average loss: 0.8296
[11/14 12:03:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.49	
[11/14 12:03:59 visual_prompt]: Training 42 / 100 epoch, with learning rate 1.8368394534823635
[11/14 12:11:30 visual_prompt]: Epoch 42 / 100: avg data time: 4.98e+00, avg batch time: 6.4505, average train loss: 0.6744
[11/14 12:12:22 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5881, average loss: 0.9493
[11/14 12:12:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.21	
[11/14 12:12:22 visual_prompt]: Training 43 / 100 epoch, with learning rate 1.7979639334863466
[11/14 12:19:45 visual_prompt]: Epoch 43 / 100: avg data time: 4.85e+00, avg batch time: 6.3299, average train loss: 0.5742
[11/14 12:20:36 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.6041, average loss: 1.5190
[11/14 12:20:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 70.08	
[11/14 12:20:36 visual_prompt]: Training 44 / 100 epoch, with learning rate 1.7584208038447504
[11/14 12:28:00 visual_prompt]: Epoch 44 / 100: avg data time: 4.86e+00, avg batch time: 6.3445, average train loss: 0.8255
[11/14 12:28:51 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5994, average loss: 1.5172
[11/14 12:28:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 67.94	
[11/14 12:28:51 visual_prompt]: Training 45 / 100 epoch, with learning rate 1.7182582417698902
[11/14 12:36:22 visual_prompt]: Epoch 45 / 100: avg data time: 4.98e+00, avg batch time: 6.4524, average train loss: 0.7213
[11/14 12:37:15 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5971, average loss: 0.7054
[11/14 12:37:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 68.92	
[11/14 12:37:15 visual_prompt]: Training 46 / 100 epoch, with learning rate 1.6775251791570862
[11/14 12:44:40 visual_prompt]: Epoch 46 / 100: avg data time: 4.89e+00, avg batch time: 6.3577, average train loss: 0.5498
[11/14 12:45:30 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5873, average loss: 1.0872
[11/14 12:45:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.93	
[11/14 12:45:30 visual_prompt]: Training 47 / 100 epoch, with learning rate 1.6362712429686843
[11/14 12:52:50 visual_prompt]: Epoch 47 / 100: avg data time: 4.79e+00, avg batch time: 6.2746, average train loss: 0.7519
[11/14 12:53:39 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5973, average loss: 0.7525
[11/14 12:53:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.94	
[11/14 12:53:39 visual_prompt]: Training 48 / 100 epoch, with learning rate 1.5945466947712488
[11/14 13:01:06 visual_prompt]: Epoch 48 / 100: avg data time: 4.91e+00, avg batch time: 6.3744, average train loss: 0.5363
[11/14 13:01:58 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5945, average loss: 0.9303
[11/14 13:01:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.16	
[11/14 13:01:58 visual_prompt]: Training 49 / 100 epoch, with learning rate 1.5524023694995845
[11/14 13:09:18 visual_prompt]: Epoch 49 / 100: avg data time: 4.81e+00, avg batch time: 6.2877, average train loss: 0.6011
[11/14 13:10:08 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5998, average loss: 0.9101
[11/14 13:10:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.63	
[11/14 13:10:08 visual_prompt]: Training 50 / 100 epoch, with learning rate 1.509889613522199
[11/14 13:17:24 visual_prompt]: Epoch 50 / 100: avg data time: 4.75e+00, avg batch time: 6.2307, average train loss: 0.6731
[11/14 13:18:14 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5986, average loss: 1.1816
[11/14 13:18:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.92	
[11/14 13:18:14 visual_prompt]: Training 51 / 100 epoch, with learning rate 1.467060222083663
[11/14 13:25:38 visual_prompt]: Epoch 51 / 100: avg data time: 4.87e+00, avg batch time: 6.3370, average train loss: 0.4877
[11/14 13:26:30 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5880, average loss: 0.8983
[11/14 13:26:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 64.95	
[11/14 13:26:30 visual_prompt]: Training 52 / 100 epoch, with learning rate 1.4239663762000818
[11/14 13:33:45 visual_prompt]: Epoch 52 / 100: avg data time: 4.73e+00, avg batch time: 6.2137, average train loss: 0.4420
[11/14 13:34:34 visual_prompt]: Inference (val):avg data time: 2.74e-05, avg batch time: 0.6001, average loss: 0.8331
[11/14 13:34:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.45	
[11/14 13:34:34 visual_prompt]: Stopping early.
[11/14 13:34:34 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 13:34:34 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 13:34:34 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 13:34:34 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 13:34:34 visual_prompt]: Training with config:
[11/14 13:34:34 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 13:34:34 visual_prompt]: Loading training data...
[11/14 13:34:34 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 13:34:34 visual_prompt]: Loading validation data...
[11/14 13:34:34 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 13:34:34 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 13:34:43 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 13:34:43 visual_prompt]: tuned percent:0.532
[11/14 13:34:43 visual_prompt]: Device used for model: 0
[11/14 13:34:43 visual_prompt]: Setting up Evaluator...
[11/14 13:34:43 visual_prompt]: Setting up Trainer...
[11/14 13:34:43 visual_prompt]: 	Setting up the optimizer...
[11/14 13:34:43 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 13:42:31 visual_prompt]: Epoch 1 / 100: avg data time: 5.20e+00, avg batch time: 6.6829, average train loss: 1.4863
[11/14 13:43:21 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5991, average loss: 1.4553
[11/14 13:43:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 13:43:21 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 13:50:39 visual_prompt]: Epoch 2 / 100: avg data time: 4.78e+00, avg batch time: 6.2616, average train loss: 1.1795
[11/14 13:51:32 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5964, average loss: 0.6956
[11/14 13:51:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.36	
[11/14 13:51:32 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 13:59:11 visual_prompt]: Epoch 3 / 100: avg data time: 5.08e+00, avg batch time: 6.5503, average train loss: 0.7272
[11/14 14:00:03 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5877, average loss: 0.7472
[11/14 14:00:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.75	
[11/14 14:00:03 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 14:07:37 visual_prompt]: Epoch 4 / 100: avg data time: 5.03e+00, avg batch time: 6.4923, average train loss: 0.7497
[11/14 14:08:29 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5891, average loss: 0.7911
[11/14 14:08:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/14 14:08:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 14:16:03 visual_prompt]: Epoch 5 / 100: avg data time: 5.02e+00, avg batch time: 6.4861, average train loss: 0.7555
[11/14 14:16:56 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5904, average loss: 1.1662
[11/14 14:16:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.83	
[11/14 14:16:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 14:24:32 visual_prompt]: Epoch 6 / 100: avg data time: 5.05e+00, avg batch time: 6.5171, average train loss: 0.7732
[11/14 14:25:24 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5964, average loss: 0.7100
[11/14 14:25:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 41.75	
[11/14 14:25:24 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 14:32:58 visual_prompt]: Epoch 7 / 100: avg data time: 5.03e+00, avg batch time: 6.4936, average train loss: 0.7512
[11/14 14:33:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5877, average loss: 0.8093
[11/14 14:33:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.93	
[11/14 14:33:50 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 14:41:25 visual_prompt]: Epoch 8 / 100: avg data time: 5.02e+00, avg batch time: 6.4970, average train loss: 0.9242
[11/14 14:42:18 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5932, average loss: 2.3953
[11/14 14:42:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.52	
[11/14 14:42:18 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 14:49:54 visual_prompt]: Epoch 9 / 100: avg data time: 5.04e+00, avg batch time: 6.5125, average train loss: 0.9086
[11/14 14:50:45 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5991, average loss: 0.9776
[11/14 14:50:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.14	
[11/14 14:50:45 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 14:58:20 visual_prompt]: Epoch 10 / 100: avg data time: 5.03e+00, avg batch time: 6.4949, average train loss: 0.9466
[11/14 14:59:12 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5915, average loss: 0.9460
[11/14 14:59:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.76	
[11/14 14:59:12 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 15:06:49 visual_prompt]: Epoch 11 / 100: avg data time: 5.04e+00, avg batch time: 6.5247, average train loss: 1.2816
[11/14 15:07:41 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5977, average loss: 0.8141
[11/14 15:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.91	
[11/14 15:07:41 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 15:15:16 visual_prompt]: Epoch 12 / 100: avg data time: 5.03e+00, avg batch time: 6.5012, average train loss: 1.0734
[11/14 15:16:09 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5929, average loss: 0.7131
[11/14 15:16:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.28	
[11/14 15:16:09 visual_prompt]: Best epoch 12: best metric: -0.713
[11/14 15:16:09 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 15:23:44 visual_prompt]: Epoch 13 / 100: avg data time: 5.04e+00, avg batch time: 6.5087, average train loss: 0.9674
[11/14 15:24:36 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5915, average loss: 0.8383
[11/14 15:24:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.55	
[11/14 15:24:36 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 15:32:12 visual_prompt]: Epoch 14 / 100: avg data time: 5.04e+00, avg batch time: 6.5017, average train loss: 1.3544
[11/14 15:33:04 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5925, average loss: 1.4522
[11/14 15:33:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.14	
[11/14 15:33:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 15:40:37 visual_prompt]: Epoch 15 / 100: avg data time: 5.00e+00, avg batch time: 6.4663, average train loss: 0.9761
[11/14 15:41:28 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5894, average loss: 0.8391
[11/14 15:41:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.29	
[11/14 15:41:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 15:49:02 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e+00, avg batch time: 6.4808, average train loss: 0.8855
[11/14 15:49:54 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5900, average loss: 1.1889
[11/14 15:49:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.95	
[11/14 15:49:54 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 15:57:29 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4960, average train loss: 0.8701
[11/14 15:58:21 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5912, average loss: 0.7937
[11/14 15:58:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.73	
[11/14 15:58:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 16:05:56 visual_prompt]: Epoch 18 / 100: avg data time: 5.04e+00, avg batch time: 6.4999, average train loss: 1.2564
[11/14 16:06:49 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5896, average loss: 0.8474
[11/14 16:06:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.37	
[11/14 16:06:49 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 16:14:26 visual_prompt]: Epoch 19 / 100: avg data time: 5.07e+00, avg batch time: 6.5262, average train loss: 1.0420
[11/14 16:15:18 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5837, average loss: 2.1713
[11/14 16:15:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.38	
[11/14 16:15:18 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/14 16:22:57 visual_prompt]: Epoch 20 / 100: avg data time: 5.10e+00, avg batch time: 6.5543, average train loss: 1.6317
[11/14 16:23:49 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5909, average loss: 2.0296
[11/14 16:23:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 40.89	
[11/14 16:23:49 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/14 16:31:29 visual_prompt]: Epoch 21 / 100: avg data time: 5.12e+00, avg batch time: 6.5712, average train loss: 1.4047
[11/14 16:32:23 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5995, average loss: 2.0380
[11/14 16:32:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.06	
[11/14 16:32:23 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/14 16:40:34 visual_prompt]: Epoch 22 / 100: avg data time: 5.55e+00, avg batch time: 7.0183, average train loss: 1.1997
[11/14 16:41:27 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5909, average loss: 1.0199
[11/14 16:41:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.06	
[11/14 16:41:27 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/14 16:48:59 visual_prompt]: Epoch 23 / 100: avg data time: 4.97e+00, avg batch time: 6.4462, average train loss: 1.6932
[11/14 16:49:49 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5940, average loss: 5.9419
[11/14 16:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.57	
[11/14 16:49:49 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/14 16:57:03 visual_prompt]: Epoch 24 / 100: avg data time: 4.74e+00, avg batch time: 6.2076, average train loss: 1.3954
[11/14 16:57:56 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5933, average loss: 1.0848
[11/14 16:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.81	
[11/14 16:57:56 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/14 17:05:28 visual_prompt]: Epoch 25 / 100: avg data time: 4.97e+00, avg batch time: 6.4494, average train loss: 1.4704
[11/14 17:06:18 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5966, average loss: 2.5826
[11/14 17:06:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.97	
[11/14 17:06:19 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/14 17:13:42 visual_prompt]: Epoch 26 / 100: avg data time: 4.87e+00, avg batch time: 6.3311, average train loss: 1.3950
[11/14 17:14:32 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5975, average loss: 0.7533
[11/14 17:14:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[11/14 17:14:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/14 17:21:53 visual_prompt]: Epoch 27 / 100: avg data time: 4.83e+00, avg batch time: 6.2980, average train loss: 1.0333
[11/14 17:22:44 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5908, average loss: 1.6533
[11/14 17:22:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.78	
[11/14 17:22:44 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/14 17:30:08 visual_prompt]: Epoch 28 / 100: avg data time: 4.85e+00, avg batch time: 6.3356, average train loss: 0.9090
[11/14 17:30:58 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5943, average loss: 1.8687
[11/14 17:30:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.45	
[11/14 17:30:58 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/14 17:38:18 visual_prompt]: Epoch 29 / 100: avg data time: 4.82e+00, avg batch time: 6.2810, average train loss: 0.8678
[11/14 17:39:07 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5885, average loss: 1.9958
[11/14 17:39:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/14 17:39:07 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/14 17:46:30 visual_prompt]: Epoch 30 / 100: avg data time: 4.84e+00, avg batch time: 6.3161, average train loss: 0.9249
[11/14 17:47:21 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5958, average loss: 1.8353
[11/14 17:47:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 50.62	
[11/14 17:47:21 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/14 17:54:45 visual_prompt]: Epoch 31 / 100: avg data time: 4.88e+00, avg batch time: 6.3461, average train loss: 0.8129
[11/14 17:55:36 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5880, average loss: 0.7329
[11/14 17:55:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.03	
[11/14 17:55:36 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/14 18:03:02 visual_prompt]: Epoch 32 / 100: avg data time: 4.89e+00, avg batch time: 6.3603, average train loss: 0.9406
[11/14 18:03:53 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5911, average loss: 2.3936
[11/14 18:03:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.07	
[11/14 18:03:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/14 18:11:18 visual_prompt]: Epoch 33 / 100: avg data time: 4.90e+00, avg batch time: 6.3628, average train loss: 1.1061
[11/14 18:12:09 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5944, average loss: 0.7082
[11/14 18:12:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.29	
[11/14 18:12:09 visual_prompt]: Best epoch 33: best metric: -0.708
[11/14 18:12:09 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/14 18:19:35 visual_prompt]: Epoch 34 / 100: avg data time: 4.90e+00, avg batch time: 6.3684, average train loss: 0.8812
[11/14 18:20:26 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5916, average loss: 1.3829
[11/14 18:20:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.45	
[11/14 18:20:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/14 18:27:51 visual_prompt]: Epoch 35 / 100: avg data time: 4.90e+00, avg batch time: 6.3617, average train loss: 0.8502
[11/14 18:28:42 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5930, average loss: 0.7145
[11/14 18:28:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.13	
[11/14 18:28:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/14 18:36:07 visual_prompt]: Epoch 36 / 100: avg data time: 4.88e+00, avg batch time: 6.3457, average train loss: 1.0954
[11/14 18:36:57 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5901, average loss: 1.6097
[11/14 18:36:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.70	
[11/14 18:36:57 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/14 18:44:20 visual_prompt]: Epoch 37 / 100: avg data time: 4.85e+00, avg batch time: 6.3215, average train loss: 1.1937
[11/14 18:45:10 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5922, average loss: 1.0441
[11/14 18:45:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.13	
[11/14 18:45:10 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/14 18:52:57 visual_prompt]: Epoch 38 / 100: avg data time: 5.19e+00, avg batch time: 6.6599, average train loss: 0.8430
[11/14 18:53:54 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5936, average loss: 1.2344
[11/14 18:53:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.61	
[11/14 18:53:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/14 19:01:52 visual_prompt]: Epoch 39 / 100: avg data time: 5.36e+00, avg batch time: 6.8328, average train loss: 0.8832
[11/14 19:02:54 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5857, average loss: 1.1738
[11/14 19:02:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 43.59	
[11/14 19:02:54 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/14 19:11:04 visual_prompt]: Epoch 40 / 100: avg data time: 5.53e+00, avg batch time: 6.9976, average train loss: 0.9293
[11/14 19:12:05 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5931, average loss: 1.2067
[11/14 19:12:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.77	
[11/14 19:12:05 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/14 19:20:24 visual_prompt]: Epoch 41 / 100: avg data time: 5.67e+00, avg batch time: 7.1349, average train loss: 1.1113
[11/14 19:21:22 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5886, average loss: 0.8516
[11/14 19:21:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 43.90	rocauc: 38.67	
[11/14 19:21:22 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/14 19:29:38 visual_prompt]: Epoch 42 / 100: avg data time: 5.64e+00, avg batch time: 7.0857, average train loss: 1.0737
[11/14 19:30:35 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5822, average loss: 0.7843
[11/14 19:30:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.87	
[11/14 19:30:35 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/14 19:38:54 visual_prompt]: Epoch 43 / 100: avg data time: 5.67e+00, avg batch time: 7.1240, average train loss: 0.8327
[11/14 19:39:53 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5843, average loss: 1.4727
[11/14 19:39:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.17	
[11/14 19:39:53 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/14 19:48:05 visual_prompt]: Epoch 44 / 100: avg data time: 5.57e+00, avg batch time: 7.0211, average train loss: 0.9403
[11/14 19:49:00 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5839, average loss: 0.7704
[11/14 19:49:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.91	
[11/14 19:49:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/14 19:57:04 visual_prompt]: Epoch 45 / 100: avg data time: 5.47e+00, avg batch time: 6.9217, average train loss: 0.8175
[11/14 19:58:01 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5826, average loss: 0.8904
[11/14 19:58:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 46.52	
[11/14 19:58:01 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/14 20:06:06 visual_prompt]: Epoch 46 / 100: avg data time: 5.48e+00, avg batch time: 6.9261, average train loss: 0.9063
[11/14 20:07:04 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5883, average loss: 2.5436
[11/14 20:07:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 49.72	
[11/14 20:07:04 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/14 20:15:11 visual_prompt]: Epoch 47 / 100: avg data time: 5.50e+00, avg batch time: 6.9465, average train loss: 1.1152
[11/14 20:16:10 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5853, average loss: 0.7436
[11/14 20:16:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.38	
[11/14 20:16:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/14 20:23:39 visual_prompt]: Epoch 48 / 100: avg data time: 4.97e+00, avg batch time: 6.4215, average train loss: 0.9349
[11/14 20:24:30 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5815, average loss: 4.4291
[11/14 20:24:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.62	
[11/14 20:24:30 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/14 20:32:00 visual_prompt]: Epoch 49 / 100: avg data time: 4.97e+00, avg batch time: 6.4202, average train loss: 1.6249
[11/14 20:32:51 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5838, average loss: 2.2219
[11/14 20:32:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.61	
[11/14 20:32:51 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/14 20:40:20 visual_prompt]: Epoch 50 / 100: avg data time: 4.96e+00, avg batch time: 6.4085, average train loss: 1.0277
[11/14 20:41:11 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5860, average loss: 1.0336
[11/14 20:41:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.43	
[11/14 20:41:11 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/14 20:48:40 visual_prompt]: Epoch 51 / 100: avg data time: 4.95e+00, avg batch time: 6.4069, average train loss: 0.7908
[11/14 20:49:31 visual_prompt]: Inference (val):avg data time: 3.92e-05, avg batch time: 0.5842, average loss: 0.8196
[11/14 20:49:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 50.21	
[11/14 20:49:31 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/14 20:57:01 visual_prompt]: Epoch 52 / 100: avg data time: 4.98e+00, avg batch time: 6.4284, average train loss: 0.8696
[11/14 20:57:52 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5861, average loss: 0.8693
[11/14 20:57:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.30	
[11/14 20:57:52 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/14 21:05:24 visual_prompt]: Epoch 53 / 100: avg data time: 4.99e+00, avg batch time: 6.4426, average train loss: 0.8747
[11/14 21:06:15 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5872, average loss: 1.3084
[11/14 21:06:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.56	
[11/14 21:06:15 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/14 21:13:44 visual_prompt]: Epoch 54 / 100: avg data time: 4.95e+00, avg batch time: 6.4062, average train loss: 0.8416
[11/14 21:14:35 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5887, average loss: 1.8799
[11/14 21:14:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.29	
[11/14 21:14:35 visual_prompt]: Stopping early.
[11/14 21:14:35 visual_prompt]: Rank of current process: 0. World size: 1
[11/14 21:14:35 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/14 21:14:35 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/14 21:14:35 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/14 21:14:35 visual_prompt]: Training with config:
[11/14 21:14:35 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/14 21:14:35 visual_prompt]: Loading training data...
[11/14 21:14:35 visual_prompt]: Constructing mammo-cbis dataset train...
[11/14 21:14:35 visual_prompt]: Loading validation data...
[11/14 21:14:35 visual_prompt]: Constructing mammo-cbis dataset val...
[11/14 21:14:35 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/14 21:14:42 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/14 21:14:42 visual_prompt]: tuned percent:0.532
[11/14 21:14:42 visual_prompt]: Device used for model: 0
[11/14 21:14:42 visual_prompt]: Setting up Evaluator...
[11/14 21:14:42 visual_prompt]: Setting up Trainer...
[11/14 21:14:42 visual_prompt]: 	Setting up the optimizer...
[11/14 21:14:42 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/14 21:22:12 visual_prompt]: Epoch 1 / 100: avg data time: 4.97e+00, avg batch time: 6.4229, average train loss: 1.4863
[11/14 21:23:03 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5876, average loss: 1.4553
[11/14 21:23:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/14 21:23:03 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/14 21:30:32 visual_prompt]: Epoch 2 / 100: avg data time: 4.96e+00, avg batch time: 6.4157, average train loss: 1.1983
[11/14 21:31:23 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5844, average loss: 0.6985
[11/14 21:31:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/14 21:31:23 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/14 21:38:52 visual_prompt]: Epoch 3 / 100: avg data time: 4.96e+00, avg batch time: 6.4097, average train loss: 0.7529
[11/14 21:39:43 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5884, average loss: 0.7602
[11/14 21:39:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.00	
[11/14 21:39:43 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/14 21:47:11 visual_prompt]: Epoch 4 / 100: avg data time: 4.94e+00, avg batch time: 6.3957, average train loss: 0.8826
[11/14 21:48:02 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5824, average loss: 0.8200
[11/14 21:48:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.32	
[11/14 21:48:02 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/14 21:55:31 visual_prompt]: Epoch 5 / 100: avg data time: 4.95e+00, avg batch time: 6.4006, average train loss: 0.8840
[11/14 21:56:22 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5864, average loss: 1.1470
[11/14 21:56:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.66	
[11/14 21:56:22 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/14 22:03:52 visual_prompt]: Epoch 6 / 100: avg data time: 4.98e+00, avg batch time: 6.4286, average train loss: 0.8625
[11/14 22:04:43 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5874, average loss: 0.6905
[11/14 22:04:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 62.09	
[11/14 22:04:43 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/14 22:12:32 visual_prompt]: Epoch 7 / 100: avg data time: 5.24e+00, avg batch time: 6.6917, average train loss: 0.7278
[11/14 22:13:26 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5859, average loss: 0.7797
[11/14 22:13:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.62	
[11/14 22:13:26 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/14 22:21:24 visual_prompt]: Epoch 8 / 100: avg data time: 5.37e+00, avg batch time: 6.8214, average train loss: 0.8387
[11/14 22:22:19 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5896, average loss: 1.8256
[11/14 22:22:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/14 22:22:19 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/14 22:30:17 visual_prompt]: Epoch 9 / 100: avg data time: 5.38e+00, avg batch time: 6.8294, average train loss: 0.8937
[11/14 22:31:14 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5859, average loss: 1.4170
[11/14 22:31:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.00	
[11/14 22:31:14 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/14 22:39:08 visual_prompt]: Epoch 10 / 100: avg data time: 5.32e+00, avg batch time: 6.7725, average train loss: 0.8014
[11/14 22:40:03 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5872, average loss: 0.7553
[11/14 22:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.26	
[11/14 22:40:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/14 22:48:09 visual_prompt]: Epoch 11 / 100: avg data time: 5.49e+00, avg batch time: 6.9392, average train loss: 0.7719
[11/14 22:49:05 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5857, average loss: 1.0939
[11/14 22:49:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.55	
[11/14 22:49:05 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/14 22:57:11 visual_prompt]: Epoch 12 / 100: avg data time: 5.49e+00, avg batch time: 6.9415, average train loss: 1.2029
[11/14 22:58:06 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5832, average loss: 0.6821
[11/14 22:58:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 59.40	
[11/14 22:58:06 visual_prompt]: Best epoch 12: best metric: -0.682
[11/14 22:58:06 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/14 23:06:05 visual_prompt]: Epoch 13 / 100: avg data time: 5.38e+00, avg batch time: 6.8311, average train loss: 0.9304
[11/14 23:06:58 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5892, average loss: 0.6770
[11/14 23:06:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 61.99	
[11/14 23:06:58 visual_prompt]: Best epoch 13: best metric: -0.677
[11/14 23:06:58 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/14 23:14:52 visual_prompt]: Epoch 14 / 100: avg data time: 5.32e+00, avg batch time: 6.7704, average train loss: 1.0278
[11/14 23:15:47 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5886, average loss: 0.7013
[11/14 23:15:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.30	
[11/14 23:15:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/14 23:23:44 visual_prompt]: Epoch 15 / 100: avg data time: 5.35e+00, avg batch time: 6.8008, average train loss: 0.7587
[11/14 23:24:39 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5865, average loss: 1.3136
[11/14 23:24:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.77	
[11/14 23:24:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/14 23:32:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.26e+00, avg batch time: 6.7113, average train loss: 0.9340
[11/14 23:33:20 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5868, average loss: 0.8048
[11/14 23:33:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.97	
[11/14 23:33:20 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/14 23:40:49 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.4057, average train loss: 0.8456
[11/14 23:41:40 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5875, average loss: 1.1311
[11/14 23:41:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.70	
[11/14 23:41:40 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/14 23:49:08 visual_prompt]: Epoch 18 / 100: avg data time: 4.94e+00, avg batch time: 6.3932, average train loss: 1.0051
[11/14 23:49:59 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5876, average loss: 1.1554
[11/14 23:49:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.01	
[11/14 23:49:59 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/14 23:57:26 visual_prompt]: Epoch 19 / 100: avg data time: 4.92e+00, avg batch time: 6.3869, average train loss: 0.8364
[11/14 23:58:17 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5919, average loss: 0.6971
[11/14 23:58:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.09	
[11/14 23:58:17 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/15 00:05:39 visual_prompt]: Epoch 20 / 100: avg data time: 4.85e+00, avg batch time: 6.3101, average train loss: 0.7105
[11/15 00:06:29 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5925, average loss: 0.6882
[11/15 00:06:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.63	
[11/15 00:06:29 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/15 00:13:41 visual_prompt]: Epoch 21 / 100: avg data time: 4.70e+00, avg batch time: 6.1728, average train loss: 0.7184
[11/15 00:14:31 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5955, average loss: 0.9805
[11/15 00:14:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.33	
[11/15 00:14:31 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/15 00:21:48 visual_prompt]: Epoch 22 / 100: avg data time: 4.77e+00, avg batch time: 6.2448, average train loss: 0.7620
[11/15 00:22:38 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5906, average loss: 0.8825
[11/15 00:22:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[11/15 00:22:38 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/15 00:29:56 visual_prompt]: Epoch 23 / 100: avg data time: 4.77e+00, avg batch time: 6.2450, average train loss: 0.7701
[11/15 00:30:46 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5965, average loss: 1.0716
[11/15 00:30:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.25	
[11/15 00:30:46 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/15 00:38:04 visual_prompt]: Epoch 24 / 100: avg data time: 4.79e+00, avg batch time: 6.2579, average train loss: 0.8550
[11/15 00:38:54 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5910, average loss: 0.7206
[11/15 00:38:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.65	
[11/15 00:38:54 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/15 00:46:07 visual_prompt]: Epoch 25 / 100: avg data time: 4.70e+00, avg batch time: 6.1820, average train loss: 1.0153
[11/15 00:46:57 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.6013, average loss: 1.9391
[11/15 00:46:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.55	
[11/15 00:46:57 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/15 00:54:10 visual_prompt]: Epoch 26 / 100: avg data time: 4.73e+00, avg batch time: 6.1966, average train loss: 1.0461
[11/15 00:55:00 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.6026, average loss: 0.7227
[11/15 00:55:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.77	
[11/15 00:55:00 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/15 01:02:12 visual_prompt]: Epoch 27 / 100: avg data time: 4.69e+00, avg batch time: 6.1616, average train loss: 0.8019
[11/15 01:03:01 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5908, average loss: 0.8428
[11/15 01:03:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.40	
[11/15 01:03:01 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/15 01:10:20 visual_prompt]: Epoch 28 / 100: avg data time: 4.78e+00, avg batch time: 6.2627, average train loss: 0.7877
[11/15 01:11:10 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5970, average loss: 1.0881
[11/15 01:11:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.28	
[11/15 01:11:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/15 01:18:28 visual_prompt]: Epoch 29 / 100: avg data time: 4.79e+00, avg batch time: 6.2477, average train loss: 0.7945
[11/15 01:19:18 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5944, average loss: 1.7512
[11/15 01:19:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/15 01:19:18 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/15 01:26:39 visual_prompt]: Epoch 30 / 100: avg data time: 4.85e+00, avg batch time: 6.3044, average train loss: 0.8148
[11/15 01:27:30 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5991, average loss: 0.8164
[11/15 01:27:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.02	
[11/15 01:27:30 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/15 01:34:50 visual_prompt]: Epoch 31 / 100: avg data time: 4.84e+00, avg batch time: 6.2925, average train loss: 0.7907
[11/15 01:35:41 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5817, average loss: 0.7302
[11/15 01:35:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.44	
[11/15 01:35:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/15 01:43:03 visual_prompt]: Epoch 32 / 100: avg data time: 4.87e+00, avg batch time: 6.3040, average train loss: 0.7645
[11/15 01:43:53 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5824, average loss: 1.1444
[11/15 01:43:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.20	
[11/15 01:43:53 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/15 01:51:14 visual_prompt]: Epoch 33 / 100: avg data time: 4.86e+00, avg batch time: 6.2982, average train loss: 0.9022
[11/15 01:52:04 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5815, average loss: 0.6880
[11/15 01:52:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.10	
[11/15 01:52:04 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/15 01:59:27 visual_prompt]: Epoch 34 / 100: avg data time: 4.88e+00, avg batch time: 6.3179, average train loss: 0.7945
[11/15 02:00:17 visual_prompt]: Inference (val):avg data time: 3.83e-05, avg batch time: 0.5864, average loss: 0.7226
[11/15 02:00:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.08	
[11/15 02:00:17 visual_prompt]: Stopping early.
[11/15 02:00:17 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 02:00:17 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 02:00:17 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 02:00:17 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 02:00:17 visual_prompt]: Training with config:
[11/15 02:00:17 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 02:00:17 visual_prompt]: Loading training data...
[11/15 02:00:17 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 02:00:18 visual_prompt]: Loading validation data...
[11/15 02:00:18 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 02:00:18 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 02:00:23 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 02:00:23 visual_prompt]: tuned percent:0.532
[11/15 02:00:23 visual_prompt]: Device used for model: 0
[11/15 02:00:23 visual_prompt]: Setting up Evaluator...
[11/15 02:00:23 visual_prompt]: Setting up Trainer...
[11/15 02:00:23 visual_prompt]: 	Setting up the optimizer...
[11/15 02:00:23 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 02:07:45 visual_prompt]: Epoch 1 / 100: avg data time: 4.87e+00, avg batch time: 6.3171, average train loss: 1.4863
[11/15 02:08:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5859, average loss: 1.4553
[11/15 02:08:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 02:08:37 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/15 02:16:07 visual_prompt]: Epoch 2 / 100: avg data time: 4.99e+00, avg batch time: 6.4265, average train loss: 1.2004
[11/15 02:16:58 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5846, average loss: 0.6988
[11/15 02:16:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.23	
[11/15 02:16:58 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/15 02:24:28 visual_prompt]: Epoch 3 / 100: avg data time: 4.98e+00, avg batch time: 6.4231, average train loss: 0.7590
[11/15 02:25:19 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5834, average loss: 0.7680
[11/15 02:25:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.84	
[11/15 02:25:19 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/15 02:32:47 visual_prompt]: Epoch 4 / 100: avg data time: 4.96e+00, avg batch time: 6.4005, average train loss: 0.8984
[11/15 02:33:39 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5839, average loss: 0.8087
[11/15 02:33:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.67	
[11/15 02:33:39 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/15 02:41:08 visual_prompt]: Epoch 5 / 100: avg data time: 4.98e+00, avg batch time: 6.4179, average train loss: 0.9182
[11/15 02:42:00 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5856, average loss: 1.3584
[11/15 02:42:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/15 02:42:00 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/15 02:49:31 visual_prompt]: Epoch 6 / 100: avg data time: 5.01e+00, avg batch time: 6.4489, average train loss: 0.8877
[11/15 02:50:23 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5837, average loss: 0.8583
[11/15 02:50:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.88	
[11/15 02:50:23 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/15 02:57:52 visual_prompt]: Epoch 7 / 100: avg data time: 4.97e+00, avg batch time: 6.4093, average train loss: 0.7590
[11/15 02:58:43 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5798, average loss: 0.9747
[11/15 02:58:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[11/15 02:58:43 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/15 03:06:12 visual_prompt]: Epoch 8 / 100: avg data time: 4.97e+00, avg batch time: 6.4142, average train loss: 0.7757
[11/15 03:07:02 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5849, average loss: 1.4752
[11/15 03:07:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.70	
[11/15 03:07:02 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/15 03:14:12 visual_prompt]: Epoch 9 / 100: avg data time: 4.70e+00, avg batch time: 6.1431, average train loss: 0.9687
[11/15 03:15:01 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5825, average loss: 1.7041
[11/15 03:15:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.12	
[11/15 03:15:01 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/15 03:22:12 visual_prompt]: Epoch 10 / 100: avg data time: 4.72e+00, avg batch time: 6.1544, average train loss: 0.9234
[11/15 03:23:02 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5830, average loss: 0.6652
[11/15 03:23:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.91	
[11/15 03:23:02 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/15 03:30:16 visual_prompt]: Epoch 11 / 100: avg data time: 4.75e+00, avg batch time: 6.1960, average train loss: 0.9014
[11/15 03:31:06 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5801, average loss: 1.0716
[11/15 03:31:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.08	
[11/15 03:31:06 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/15 03:38:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.87e+00, avg batch time: 6.3091, average train loss: 0.8637
[11/15 03:39:19 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5853, average loss: 1.0738
[11/15 03:39:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/15 03:39:19 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/15 03:46:35 visual_prompt]: Epoch 13 / 100: avg data time: 4.79e+00, avg batch time: 6.2310, average train loss: 0.7342
[11/15 03:47:26 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5823, average loss: 0.7680
[11/15 03:47:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.86	
[11/15 03:47:26 visual_prompt]: Best epoch 13: best metric: -0.768
[11/15 03:47:26 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/15 03:54:48 visual_prompt]: Epoch 14 / 100: avg data time: 4.86e+00, avg batch time: 6.3039, average train loss: 0.8942
[11/15 03:55:36 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5821, average loss: 0.7401
[11/15 03:55:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.97	rocauc: 62.99	
[11/15 03:55:36 visual_prompt]: Best epoch 14: best metric: -0.740
[11/15 03:55:36 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/15 04:03:02 visual_prompt]: Epoch 15 / 100: avg data time: 4.92e+00, avg batch time: 6.3629, average train loss: 0.8148
[11/15 04:03:53 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5881, average loss: 0.8043
[11/15 04:03:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.22	
[11/15 04:03:53 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/15 04:11:20 visual_prompt]: Epoch 16 / 100: avg data time: 4.95e+00, avg batch time: 6.3857, average train loss: 0.8598
[11/15 04:12:11 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5826, average loss: 0.6505
[11/15 04:12:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.94	
[11/15 04:12:11 visual_prompt]: Best epoch 16: best metric: -0.650
[11/15 04:12:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/15 04:19:39 visual_prompt]: Epoch 17 / 100: avg data time: 4.95e+00, avg batch time: 6.3934, average train loss: 0.7246
[11/15 04:20:30 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5819, average loss: 0.7440
[11/15 04:20:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 66.41	
[11/15 04:20:30 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/15 04:27:56 visual_prompt]: Epoch 18 / 100: avg data time: 4.93e+00, avg batch time: 6.3661, average train loss: 0.9067
[11/15 04:28:47 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5833, average loss: 1.7585
[11/15 04:28:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.82	
[11/15 04:28:47 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/15 04:36:12 visual_prompt]: Epoch 19 / 100: avg data time: 4.91e+00, avg batch time: 6.3517, average train loss: 0.8283
[11/15 04:37:03 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5836, average loss: 1.1293
[11/15 04:37:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/15 04:37:03 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/15 04:44:27 visual_prompt]: Epoch 20 / 100: avg data time: 4.91e+00, avg batch time: 6.3542, average train loss: 0.7449
[11/15 04:45:18 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5818, average loss: 0.6278
[11/15 04:45:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.43	
[11/15 04:45:18 visual_prompt]: Best epoch 20: best metric: -0.628
[11/15 04:45:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/15 04:52:36 visual_prompt]: Epoch 21 / 100: avg data time: 4.81e+00, avg batch time: 6.2611, average train loss: 0.7236
[11/15 04:53:25 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5809, average loss: 1.1887
[11/15 04:53:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.24	
[11/15 04:53:25 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/15 05:00:31 visual_prompt]: Epoch 22 / 100: avg data time: 4.63e+00, avg batch time: 6.0796, average train loss: 0.7983
[11/15 05:01:19 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5818, average loss: 1.2417
[11/15 05:01:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.28	
[11/15 05:01:19 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/15 05:08:26 visual_prompt]: Epoch 23 / 100: avg data time: 4.65e+00, avg batch time: 6.0945, average train loss: 0.8778
[11/15 05:09:15 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5836, average loss: 0.9785
[11/15 05:09:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.27	
[11/15 05:09:15 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/15 05:16:18 visual_prompt]: Epoch 24 / 100: avg data time: 4.60e+00, avg batch time: 6.0492, average train loss: 0.7457
[11/15 05:17:07 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5872, average loss: 1.3981
[11/15 05:17:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.88	
[11/15 05:17:07 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/15 05:24:13 visual_prompt]: Epoch 25 / 100: avg data time: 4.64e+00, avg batch time: 6.0946, average train loss: 0.7502
[11/15 05:25:02 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5829, average loss: 0.7029
[11/15 05:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.09	
[11/15 05:25:02 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/15 05:32:09 visual_prompt]: Epoch 26 / 100: avg data time: 4.65e+00, avg batch time: 6.0959, average train loss: 0.6993
[11/15 05:32:58 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5808, average loss: 0.6264
[11/15 05:32:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.34	
[11/15 05:32:58 visual_prompt]: Best epoch 26: best metric: -0.626
[11/15 05:32:58 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/15 05:40:05 visual_prompt]: Epoch 27 / 100: avg data time: 4.65e+00, avg batch time: 6.0955, average train loss: 0.7001
[11/15 05:40:54 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5824, average loss: 0.8586
[11/15 05:40:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 72.79	
[11/15 05:40:54 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/15 05:48:02 visual_prompt]: Epoch 28 / 100: avg data time: 4.68e+00, avg batch time: 6.1143, average train loss: 0.7071
[11/15 05:48:51 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5822, average loss: 0.7898
[11/15 05:48:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 74.59	
[11/15 05:48:51 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/15 05:55:59 visual_prompt]: Epoch 29 / 100: avg data time: 4.66e+00, avg batch time: 6.1037, average train loss: 0.7472
[11/15 05:56:48 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5795, average loss: 1.2905
[11/15 05:56:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 73.60	
[11/15 05:56:48 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/15 06:03:57 visual_prompt]: Epoch 30 / 100: avg data time: 4.69e+00, avg batch time: 6.1297, average train loss: 0.7447
[11/15 06:04:46 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5813, average loss: 0.7021
[11/15 06:04:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.63	
[11/15 06:04:46 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/15 06:11:52 visual_prompt]: Epoch 31 / 100: avg data time: 4.65e+00, avg batch time: 6.0898, average train loss: 0.7410
[11/15 06:12:41 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5904, average loss: 0.6355
[11/15 06:12:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.55	
[11/15 06:12:41 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/15 06:19:50 visual_prompt]: Epoch 32 / 100: avg data time: 4.68e+00, avg batch time: 6.1205, average train loss: 0.7250
[11/15 06:20:38 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5794, average loss: 0.6228
[11/15 06:20:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 73.43	
[11/15 06:20:38 visual_prompt]: Best epoch 32: best metric: -0.623
[11/15 06:20:38 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/15 06:27:46 visual_prompt]: Epoch 33 / 100: avg data time: 4.67e+00, avg batch time: 6.1075, average train loss: 0.6586
[11/15 06:28:35 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5834, average loss: 0.6086
[11/15 06:28:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 74.28	
[11/15 06:28:35 visual_prompt]: Best epoch 33: best metric: -0.609
[11/15 06:28:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/15 06:35:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.67e+00, avg batch time: 6.1116, average train loss: 0.7196
[11/15 06:36:32 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5831, average loss: 0.6373
[11/15 06:36:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 69.15	
[11/15 06:36:32 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/15 06:43:39 visual_prompt]: Epoch 35 / 100: avg data time: 4.66e+00, avg batch time: 6.1015, average train loss: 0.6718
[11/15 06:44:28 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5857, average loss: 0.6527
[11/15 06:44:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 73.02	
[11/15 06:44:28 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/15 06:51:36 visual_prompt]: Epoch 36 / 100: avg data time: 4.67e+00, avg batch time: 6.1164, average train loss: 0.7162
[11/15 06:52:25 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5805, average loss: 1.2581
[11/15 06:52:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 69.58	
[11/15 06:52:25 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/15 06:59:33 visual_prompt]: Epoch 37 / 100: avg data time: 4.66e+00, avg batch time: 6.1087, average train loss: 0.7757
[11/15 07:00:22 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5797, average loss: 0.8346
[11/15 07:00:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 72.84	
[11/15 07:00:22 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/15 07:07:30 visual_prompt]: Epoch 38 / 100: avg data time: 4.67e+00, avg batch time: 6.1089, average train loss: 0.6646
[11/15 07:08:19 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5826, average loss: 0.6188
[11/15 07:08:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 72.29	
[11/15 07:08:19 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/15 07:15:27 visual_prompt]: Epoch 39 / 100: avg data time: 4.67e+00, avg batch time: 6.1171, average train loss: 0.6615
[11/15 07:16:16 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5866, average loss: 0.6355
[11/15 07:16:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 74.07	
[11/15 07:16:16 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/15 07:23:23 visual_prompt]: Epoch 40 / 100: avg data time: 4.66e+00, avg batch time: 6.1029, average train loss: 0.7041
[11/15 07:24:12 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5851, average loss: 0.7088
[11/15 07:24:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.97	
[11/15 07:24:12 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/15 07:31:19 visual_prompt]: Epoch 41 / 100: avg data time: 4.65e+00, avg batch time: 6.0969, average train loss: 0.6663
[11/15 07:32:08 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5826, average loss: 0.6483
[11/15 07:32:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 73.61	
[11/15 07:32:08 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.7347357813929454
[11/15 07:39:16 visual_prompt]: Epoch 42 / 100: avg data time: 4.67e+00, avg batch time: 6.1077, average train loss: 0.6256
[11/15 07:40:05 visual_prompt]: Inference (val):avg data time: 2.77e-05, avg batch time: 0.5818, average loss: 0.7569
[11/15 07:40:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.87	
[11/15 07:40:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.7191855733945387
[11/15 07:47:13 visual_prompt]: Epoch 43 / 100: avg data time: 4.68e+00, avg batch time: 6.1178, average train loss: 0.6088
[11/15 07:48:02 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5823, average loss: 1.1159
[11/15 07:48:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 75.65	
[11/15 07:48:02 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.7033683215379002
[11/15 07:55:11 visual_prompt]: Epoch 44 / 100: avg data time: 4.69e+00, avg batch time: 6.1268, average train loss: 0.7478
[11/15 07:56:00 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5804, average loss: 0.5945
[11/15 07:56:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 75.54	
[11/15 07:56:00 visual_prompt]: Best epoch 44: best metric: -0.595
[11/15 07:56:00 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.6873032967079561
[11/15 08:03:08 visual_prompt]: Epoch 45 / 100: avg data time: 4.67e+00, avg batch time: 6.1180, average train loss: 0.6332
[11/15 08:03:57 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5830, average loss: 0.5908
[11/15 08:03:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.64	
[11/15 08:03:57 visual_prompt]: Best epoch 45: best metric: -0.591
[11/15 08:03:57 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.6710100716628344
[11/15 08:11:05 visual_prompt]: Epoch 46 / 100: avg data time: 4.67e+00, avg batch time: 6.1092, average train loss: 0.5853
[11/15 08:11:54 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5849, average loss: 0.6293
[11/15 08:11:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.87	
[11/15 08:11:54 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.6545084971874737
[11/15 08:19:02 visual_prompt]: Epoch 47 / 100: avg data time: 4.67e+00, avg batch time: 6.1097, average train loss: 0.6431
[11/15 08:19:51 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5841, average loss: 0.6813
[11/15 08:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 73.84	
[11/15 08:19:51 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.6378186779084996
[11/15 08:26:58 visual_prompt]: Epoch 48 / 100: avg data time: 4.66e+00, avg batch time: 6.1001, average train loss: 0.6118
[11/15 08:27:47 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5850, average loss: 0.7943
[11/15 08:27:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 74.49	
[11/15 08:27:47 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.6209609477998338
[11/15 08:34:55 visual_prompt]: Epoch 49 / 100: avg data time: 4.68e+00, avg batch time: 6.1208, average train loss: 0.6062
[11/15 08:35:44 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5853, average loss: 0.6202
[11/15 08:35:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 75.99	
[11/15 08:35:44 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.6039558454088796
[11/15 08:42:51 visual_prompt]: Epoch 50 / 100: avg data time: 4.66e+00, avg batch time: 6.0995, average train loss: 0.6151
[11/15 08:43:40 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5813, average loss: 0.8952
[11/15 08:43:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 74.80	
[11/15 08:43:40 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.5868240888334653
[11/15 08:50:48 visual_prompt]: Epoch 51 / 100: avg data time: 4.67e+00, avg batch time: 6.1082, average train loss: 0.5953
[11/15 08:51:37 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5860, average loss: 0.8696
[11/15 08:51:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.85	rocauc: 74.88	
[11/15 08:51:37 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.5695865504800327
[11/15 08:58:45 visual_prompt]: Epoch 52 / 100: avg data time: 4.68e+00, avg batch time: 6.1207, average train loss: 0.5918
[11/15 08:59:34 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5815, average loss: 0.6252
[11/15 08:59:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.38	
[11/15 08:59:34 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.5522642316338268
[11/15 09:06:44 visual_prompt]: Epoch 53 / 100: avg data time: 4.70e+00, avg batch time: 6.1400, average train loss: 0.6374
[11/15 09:07:33 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5802, average loss: 0.6561
[11/15 09:07:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 75.69	
[11/15 09:07:33 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.5348782368720626
[11/15 09:14:41 visual_prompt]: Epoch 54 / 100: avg data time: 4.67e+00, avg batch time: 6.1078, average train loss: 0.6122
[11/15 09:15:30 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5812, average loss: 0.6972
[11/15 09:15:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 72.11	
[11/15 09:15:30 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.5174497483512506
[11/15 09:22:37 visual_prompt]: Epoch 55 / 100: avg data time: 4.66e+00, avg batch time: 6.1028, average train loss: 0.6575
[11/15 09:23:26 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5841, average loss: 0.9848
[11/15 09:23:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.64	
[11/15 09:23:26 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.5
[11/15 09:30:34 visual_prompt]: Epoch 56 / 100: avg data time: 4.66e+00, avg batch time: 6.1043, average train loss: 0.6801
[11/15 09:31:22 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5815, average loss: 0.6264
[11/15 09:31:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.30	
[11/15 09:31:22 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.48255025164874965
[11/15 09:38:31 visual_prompt]: Epoch 57 / 100: avg data time: 4.68e+00, avg batch time: 6.1206, average train loss: 0.5297
[11/15 09:39:20 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5809, average loss: 1.1900
[11/15 09:39:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.85	
[11/15 09:39:20 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.46512176312793735
[11/15 09:46:27 visual_prompt]: Epoch 58 / 100: avg data time: 4.66e+00, avg batch time: 6.1001, average train loss: 0.5367
[11/15 09:47:16 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5817, average loss: 0.7478
[11/15 09:47:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 71.04	
[11/15 09:47:16 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.44773576836617335
[11/15 09:54:24 visual_prompt]: Epoch 59 / 100: avg data time: 4.68e+00, avg batch time: 6.1212, average train loss: 0.5299
[11/15 09:55:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5819, average loss: 1.0627
[11/15 09:55:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.03	rocauc: 65.80	
[11/15 09:55:13 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.4304134495199674
[11/15 10:02:22 visual_prompt]: Epoch 60 / 100: avg data time: 4.68e+00, avg batch time: 6.1189, average train loss: 0.5424
[11/15 10:03:11 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5814, average loss: 0.7228
[11/15 10:03:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 71.89	
[11/15 10:03:11 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.41317591116653485
[11/15 10:10:18 visual_prompt]: Epoch 61 / 100: avg data time: 4.66e+00, avg batch time: 6.1027, average train loss: 0.5362
[11/15 10:11:07 visual_prompt]: Inference (val):avg data time: 2.79e-05, avg batch time: 0.5817, average loss: 0.7876
[11/15 10:11:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 72.66	
[11/15 10:11:07 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.3960441545911204
[11/15 10:18:19 visual_prompt]: Epoch 62 / 100: avg data time: 4.72e+00, avg batch time: 6.1602, average train loss: 0.5365
[11/15 10:19:08 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5861, average loss: 0.8229
[11/15 10:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.47	
[11/15 10:19:08 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.3790390522001662
[11/15 10:26:16 visual_prompt]: Epoch 63 / 100: avg data time: 4.68e+00, avg batch time: 6.1236, average train loss: 0.5053
[11/15 10:27:05 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5889, average loss: 0.6705
[11/15 10:27:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.69	
[11/15 10:27:05 visual_prompt]: Training 64 / 100 epoch, with learning rate 0.36218132209150045
[11/15 10:34:13 visual_prompt]: Epoch 64 / 100: avg data time: 4.66e+00, avg batch time: 6.1047, average train loss: 0.4739
[11/15 10:35:02 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5830, average loss: 0.9644
[11/15 10:35:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 71.98	
[11/15 10:35:02 visual_prompt]: Training 65 / 100 epoch, with learning rate 0.34549150281252633
[11/15 10:42:09 visual_prompt]: Epoch 65 / 100: avg data time: 4.67e+00, avg batch time: 6.1091, average train loss: 0.5174
[11/15 10:42:58 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5804, average loss: 0.6204
[11/15 10:42:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.14	
[11/15 10:42:58 visual_prompt]: Training 66 / 100 epoch, with learning rate 0.32898992833716567
[11/15 10:50:04 visual_prompt]: Epoch 66 / 100: avg data time: 4.65e+00, avg batch time: 6.0872, average train loss: 0.4549
[11/15 10:50:54 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5897, average loss: 0.7179
[11/15 10:50:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 69.33	
[11/15 10:50:54 visual_prompt]: Stopping early.
[11/15 10:50:54 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 10:50:54 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 10:50:54 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 10:50:54 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 10:50:54 visual_prompt]: Training with config:
[11/15 10:50:54 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr1.0_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 1.0, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 10:50:54 visual_prompt]: Loading training data...
[11/15 10:50:54 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 10:50:54 visual_prompt]: Loading validation data...
[11/15 10:50:54 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 10:50:54 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 10:51:01 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 10:51:01 visual_prompt]: tuned percent:0.532
[11/15 10:51:01 visual_prompt]: Device used for model: 0
[11/15 10:51:01 visual_prompt]: Setting up Evaluator...
[11/15 10:51:01 visual_prompt]: Setting up Trainer...
[11/15 10:51:01 visual_prompt]: 	Setting up the optimizer...
[11/15 10:51:01 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 10:58:10 visual_prompt]: Epoch 1 / 100: avg data time: 4.68e+00, avg batch time: 6.1238, average train loss: 1.4863
[11/15 10:58:59 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5813, average loss: 1.4553
[11/15 10:58:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 10:58:59 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.1
[11/15 11:06:08 visual_prompt]: Epoch 2 / 100: avg data time: 4.68e+00, avg batch time: 6.1241, average train loss: 1.2006
[11/15 11:06:57 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5831, average loss: 0.6988
[11/15 11:06:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.18	
[11/15 11:06:57 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.2
[11/15 11:14:04 visual_prompt]: Epoch 3 / 100: avg data time: 4.67e+00, avg batch time: 6.1098, average train loss: 0.7595
[11/15 11:14:53 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5818, average loss: 0.7682
[11/15 11:14:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.81	
[11/15 11:14:53 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.3
[11/15 11:22:01 visual_prompt]: Epoch 4 / 100: avg data time: 4.67e+00, avg batch time: 6.1072, average train loss: 0.8947
[11/15 11:22:50 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5842, average loss: 0.8124
[11/15 11:22:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.61	
[11/15 11:22:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.4
[11/15 11:29:58 visual_prompt]: Epoch 5 / 100: avg data time: 4.68e+00, avg batch time: 6.1219, average train loss: 0.9223
[11/15 11:30:47 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5869, average loss: 1.3861
[11/15 11:30:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.24	
[11/15 11:30:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.5
[11/15 11:37:57 visual_prompt]: Epoch 6 / 100: avg data time: 4.69e+00, avg batch time: 6.1351, average train loss: 0.8900
[11/15 11:38:46 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5822, average loss: 0.8766
[11/15 11:38:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[11/15 11:38:46 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.6
[11/15 11:45:52 visual_prompt]: Epoch 7 / 100: avg data time: 4.65e+00, avg batch time: 6.0924, average train loss: 0.7588
[11/15 11:46:42 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5869, average loss: 1.0101
[11/15 11:46:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/15 11:46:42 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.7
[11/15 11:53:55 visual_prompt]: Epoch 8 / 100: avg data time: 4.75e+00, avg batch time: 6.1902, average train loss: 0.7895
[11/15 11:55:11 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5806, average loss: 1.4801
[11/15 11:55:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.99	
[11/15 11:55:11 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.8
[11/15 12:02:52 visual_prompt]: Epoch 9 / 100: avg data time: 5.14e+00, avg batch time: 6.5834, average train loss: 1.0567
[11/15 12:03:42 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5870, average loss: 1.9678
[11/15 12:03:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.97	
[11/15 12:03:42 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.9
[11/15 12:10:56 visual_prompt]: Epoch 10 / 100: avg data time: 4.75e+00, avg batch time: 6.1997, average train loss: 0.8385
[11/15 12:11:46 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5851, average loss: 0.8806
[11/15 12:11:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 67.53	
[11/15 12:11:46 visual_prompt]: Training 11 / 100 epoch, with learning rate 1.0
[11/15 12:19:01 visual_prompt]: Epoch 11 / 100: avg data time: 4.76e+00, avg batch time: 6.2152, average train loss: 0.9429
[11/15 12:19:51 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5885, average loss: 1.2620
[11/15 12:19:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/15 12:19:51 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.9996954135095479
[11/15 12:27:05 visual_prompt]: Epoch 12 / 100: avg data time: 4.75e+00, avg batch time: 6.2004, average train loss: 0.8875
[11/15 12:27:55 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5875, average loss: 1.1847
[11/15 12:27:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 66.54	
[11/15 12:27:55 visual_prompt]: Best epoch 12: best metric: -1.185
[11/15 12:27:55 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.9987820251299121
[11/15 12:35:10 visual_prompt]: Epoch 13 / 100: avg data time: 4.76e+00, avg batch time: 6.2118, average train loss: 0.7386
[11/15 12:35:59 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5858, average loss: 0.9022
[11/15 12:35:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 70.41	
[11/15 12:35:59 visual_prompt]: Best epoch 13: best metric: -0.902
[11/15 12:35:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.9972609476841366
[11/15 12:43:13 visual_prompt]: Epoch 14 / 100: avg data time: 4.75e+00, avg batch time: 6.1964, average train loss: 0.9029
[11/15 12:44:04 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5880, average loss: 0.6527
[11/15 12:44:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.88	
[11/15 12:44:04 visual_prompt]: Best epoch 14: best metric: -0.653
[11/15 12:44:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.9951340343707852
[11/15 12:51:16 visual_prompt]: Epoch 15 / 100: avg data time: 4.73e+00, avg batch time: 6.1767, average train loss: 0.7763
[11/15 12:52:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5917, average loss: 1.0136
[11/15 12:52:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.59	
[11/15 12:52:06 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.9924038765061041
[11/15 12:59:19 visual_prompt]: Epoch 16 / 100: avg data time: 4.72e+00, avg batch time: 6.1766, average train loss: 0.7729
[11/15 13:00:08 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5849, average loss: 0.7274
[11/15 13:00:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.14	
[11/15 13:00:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.9890738003669028
[11/15 13:07:22 visual_prompt]: Epoch 17 / 100: avg data time: 4.74e+00, avg batch time: 6.1918, average train loss: 0.7495
[11/15 13:08:11 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5856, average loss: 0.6481
[11/15 13:08:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 72.01	
[11/15 13:08:11 visual_prompt]: Best epoch 17: best metric: -0.648
[11/15 13:08:11 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.9851478631379982
[11/15 13:15:23 visual_prompt]: Epoch 18 / 100: avg data time: 4.71e+00, avg batch time: 6.1617, average train loss: 1.0452
[11/15 13:16:12 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5841, average loss: 1.8409
[11/15 13:16:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.54	
[11/15 13:16:12 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.9806308479691594
[11/15 13:23:25 visual_prompt]: Epoch 19 / 100: avg data time: 4.73e+00, avg batch time: 6.1786, average train loss: 1.4687
[11/15 13:24:14 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5844, average loss: 0.8980
[11/15 13:24:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.40	
[11/15 13:24:14 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.9755282581475768
[11/15 13:31:28 visual_prompt]: Epoch 20 / 100: avg data time: 4.75e+00, avg batch time: 6.2005, average train loss: 0.7341
[11/15 13:32:18 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5869, average loss: 0.6098
[11/15 13:32:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 73.99	
[11/15 13:32:18 visual_prompt]: Best epoch 20: best metric: -0.610
[11/15 13:32:18 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.9698463103929542
[11/15 13:39:32 visual_prompt]: Epoch 21 / 100: avg data time: 4.74e+00, avg batch time: 6.1948, average train loss: 0.7037
[11/15 13:40:22 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5829, average loss: 1.2582
[11/15 13:40:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 72.44	
[11/15 13:40:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.9635919272833937
[11/15 13:47:35 visual_prompt]: Epoch 22 / 100: avg data time: 4.74e+00, avg batch time: 6.1865, average train loss: 0.9042
[11/15 13:48:24 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5838, average loss: 1.1301
[11/15 13:48:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.60	
[11/15 13:48:24 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.9567727288213004
[11/15 13:55:37 visual_prompt]: Epoch 23 / 100: avg data time: 4.74e+00, avg batch time: 6.1843, average train loss: 0.8556
[11/15 13:56:27 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5833, average loss: 0.7865
[11/15 13:56:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 73.93	
[11/15 13:56:27 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.9493970231495835
[11/15 14:03:38 visual_prompt]: Epoch 24 / 100: avg data time: 4.70e+00, avg batch time: 6.1556, average train loss: 0.7096
[11/15 14:04:27 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.6027, average loss: 1.2536
[11/15 14:04:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 71.79	
[11/15 14:04:27 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.9414737964294635
[11/15 14:11:43 visual_prompt]: Epoch 25 / 100: avg data time: 4.78e+00, avg batch time: 6.2307, average train loss: 0.6866
[11/15 14:12:33 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5817, average loss: 0.8741
[11/15 14:12:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.86	
[11/15 14:12:33 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.9330127018922194
[11/15 14:19:48 visual_prompt]: Epoch 26 / 100: avg data time: 4.76e+00, avg batch time: 6.2038, average train loss: 0.6706
[11/15 14:20:38 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5808, average loss: 0.8436
[11/15 14:20:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 73.76	
[11/15 14:20:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.9240240480782129
[11/15 14:27:52 visual_prompt]: Epoch 27 / 100: avg data time: 4.76e+00, avg batch time: 6.2011, average train loss: 0.7306
[11/15 14:28:42 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5858, average loss: 0.9208
[11/15 14:28:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 75.87	
[11/15 14:28:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.9145187862775208
[11/15 14:35:58 visual_prompt]: Epoch 28 / 100: avg data time: 4.79e+00, avg batch time: 6.2291, average train loss: 0.6340
[11/15 14:36:48 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5817, average loss: 0.6632
[11/15 14:36:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.90	
[11/15 14:36:48 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.9045084971874737
[11/15 14:44:03 visual_prompt]: Epoch 29 / 100: avg data time: 4.78e+00, avg batch time: 6.2233, average train loss: 0.6710
[11/15 14:44:53 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5817, average loss: 1.4244
[11/15 14:44:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 74.79	
[11/15 14:44:53 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.8940053768033609
[11/15 14:52:10 visual_prompt]: Epoch 30 / 100: avg data time: 4.79e+00, avg batch time: 6.2333, average train loss: 0.6302
[11/15 14:53:00 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5803, average loss: 1.2564
[11/15 14:53:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.78	rocauc: 73.18	
[11/15 14:53:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.883022221559489
[11/15 15:00:15 visual_prompt]: Epoch 31 / 100: avg data time: 4.76e+00, avg batch time: 6.2055, average train loss: 0.7490
[11/15 15:01:04 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5831, average loss: 0.6630
[11/15 15:01:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.20	
[11/15 15:01:04 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.8715724127386971
[11/15 15:08:20 visual_prompt]: Epoch 32 / 100: avg data time: 4.78e+00, avg batch time: 6.2241, average train loss: 0.6544
[11/15 15:09:10 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5843, average loss: 0.6319
[11/15 15:09:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.40	
[11/15 15:09:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.8596699001693255
[11/15 15:16:25 visual_prompt]: Epoch 33 / 100: avg data time: 4.78e+00, avg batch time: 6.2197, average train loss: 0.5834
[11/15 15:17:15 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5838, average loss: 0.6300
[11/15 15:17:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.76	
[11/15 15:17:15 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.8473291852294986
[11/15 15:24:30 visual_prompt]: Epoch 34 / 100: avg data time: 4.77e+00, avg batch time: 6.2096, average train loss: 0.6105
[11/15 15:25:20 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5830, average loss: 0.9244
[11/15 15:25:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 72.72	
[11/15 15:25:20 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.8345653031794291
[11/15 15:32:34 visual_prompt]: Epoch 35 / 100: avg data time: 4.77e+00, avg batch time: 6.2067, average train loss: 0.6015
[11/15 15:33:25 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5829, average loss: 0.7921
[11/15 15:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.39	
[11/15 15:33:25 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.8213938048432696
[11/15 15:40:42 visual_prompt]: Epoch 36 / 100: avg data time: 4.80e+00, avg batch time: 6.2414, average train loss: 0.6609
[11/15 15:41:32 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5787, average loss: 0.6925
[11/15 15:41:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.12	
[11/15 15:41:32 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.8078307376628291
[11/15 15:48:47 visual_prompt]: Epoch 37 / 100: avg data time: 4.77e+00, avg batch time: 6.2141, average train loss: 0.5611
[11/15 15:49:36 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5851, average loss: 0.9730
[11/15 15:49:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 73.01	
[11/15 15:49:36 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.7938926261462366
[11/15 15:56:59 visual_prompt]: Epoch 38 / 100: avg data time: 4.87e+00, avg batch time: 6.3178, average train loss: 0.5647
[11/15 15:57:49 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5877, average loss: 0.9228
[11/15 15:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.39	
[11/15 15:57:49 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.7795964517353734
[11/15 16:05:11 visual_prompt]: Epoch 39 / 100: avg data time: 4.85e+00, avg batch time: 6.3001, average train loss: 0.5133
[11/15 16:06:00 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5835, average loss: 0.9365
[11/15 16:06:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.26	
[11/15 16:06:00 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.7649596321166025
[11/15 16:13:15 visual_prompt]: Epoch 40 / 100: avg data time: 4.76e+00, avg batch time: 6.2099, average train loss: 0.5412
[11/15 16:14:06 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5827, average loss: 0.8052
[11/15 16:14:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 72.99	
[11/15 16:14:06 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.75
[11/15 16:21:20 visual_prompt]: Epoch 41 / 100: avg data time: 4.75e+00, avg batch time: 6.2050, average train loss: 0.4893
[11/15 16:22:10 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5866, average loss: 0.6847
[11/15 16:22:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.80	
[11/15 16:22:10 visual_prompt]: Stopping early.
[11/15 16:22:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 16:22:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 16:22:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 16:22:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 16:22:14 visual_prompt]: Training with config:
[11/15 16:22:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 16:22:14 visual_prompt]: Loading training data...
[11/15 16:22:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 16:22:14 visual_prompt]: Loading validation data...
[11/15 16:22:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 16:22:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 16:22:21 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 16:22:21 visual_prompt]: tuned percent:0.532
[11/15 16:22:21 visual_prompt]: Device used for model: 0
[11/15 16:22:21 visual_prompt]: Setting up Evaluator...
[11/15 16:22:21 visual_prompt]: Setting up Trainer...
[11/15 16:22:21 visual_prompt]: 	Setting up the optimizer...
[11/15 16:22:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 16:29:36 visual_prompt]: Epoch 1 / 100: avg data time: 4.76e+00, avg batch time: 6.2145, average train loss: 1.4863
[11/15 16:30:26 visual_prompt]: Inference (val):avg data time: 2.91e-05, avg batch time: 0.5866, average loss: 1.4553
[11/15 16:30:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 16:30:26 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/15 16:37:41 visual_prompt]: Epoch 2 / 100: avg data time: 4.77e+00, avg batch time: 6.2158, average train loss: 1.0767
[11/15 16:38:30 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5829, average loss: 0.7165
[11/15 16:38:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.89	
[11/15 16:38:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 16:45:45 visual_prompt]: Epoch 3 / 100: avg data time: 4.75e+00, avg batch time: 6.2037, average train loss: 0.7123
[11/15 16:46:34 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5877, average loss: 0.8119
[11/15 16:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.06	
[11/15 16:46:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 16:53:47 visual_prompt]: Epoch 4 / 100: avg data time: 4.72e+00, avg batch time: 6.1824, average train loss: 0.7353
[11/15 16:54:37 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5923, average loss: 0.7853
[11/15 16:54:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/15 16:54:37 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 17:01:52 visual_prompt]: Epoch 5 / 100: avg data time: 4.76e+00, avg batch time: 6.2068, average train loss: 0.7493
[11/15 17:02:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5826, average loss: 0.7440
[11/15 17:02:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.62	
[11/15 17:02:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 17:09:59 visual_prompt]: Epoch 6 / 100: avg data time: 4.81e+00, avg batch time: 6.2494, average train loss: 0.7282
[11/15 17:10:49 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5888, average loss: 0.6939
[11/15 17:10:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.75	
[11/15 17:10:49 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 17:18:06 visual_prompt]: Epoch 7 / 100: avg data time: 4.79e+00, avg batch time: 6.2361, average train loss: 0.7207
[11/15 17:18:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5844, average loss: 1.1219
[11/15 17:18:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.51	
[11/15 17:18:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/15 17:26:15 visual_prompt]: Epoch 8 / 100: avg data time: 4.83e+00, avg batch time: 6.2700, average train loss: 0.7393
[11/15 17:27:04 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5830, average loss: 0.8992
[11/15 17:27:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.89	
[11/15 17:27:04 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/15 17:34:29 visual_prompt]: Epoch 9 / 100: avg data time: 4.90e+00, avg batch time: 6.3412, average train loss: 0.7502
[11/15 17:35:18 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5827, average loss: 0.7116
[11/15 17:35:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.54	
[11/15 17:35:18 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/15 17:42:35 visual_prompt]: Epoch 10 / 100: avg data time: 4.79e+00, avg batch time: 6.2375, average train loss: 0.7194
[11/15 17:43:25 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5810, average loss: 0.6989
[11/15 17:43:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.44	
[11/15 17:43:25 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/15 17:50:41 visual_prompt]: Epoch 11 / 100: avg data time: 4.79e+00, avg batch time: 6.2298, average train loss: 0.7433
[11/15 17:51:31 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5865, average loss: 0.8597
[11/15 17:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/15 17:51:31 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/15 17:58:46 visual_prompt]: Epoch 12 / 100: avg data time: 4.77e+00, avg batch time: 6.2116, average train loss: 0.7901
[11/15 17:59:35 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5809, average loss: 0.7401
[11/15 17:59:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 51.09	
[11/15 17:59:35 visual_prompt]: Best epoch 12: best metric: -0.740
[11/15 17:59:35 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/15 18:06:51 visual_prompt]: Epoch 13 / 100: avg data time: 4.79e+00, avg batch time: 6.2267, average train loss: 0.7767
[11/15 18:07:42 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5808, average loss: 0.7056
[11/15 18:07:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 52.08	
[11/15 18:07:42 visual_prompt]: Best epoch 13: best metric: -0.706
[11/15 18:07:42 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/15 18:15:21 visual_prompt]: Epoch 14 / 100: avg data time: 5.12e+00, avg batch time: 6.5587, average train loss: 0.8127
[11/15 18:16:10 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5840, average loss: 1.2457
[11/15 18:16:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.24	
[11/15 18:16:10 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/15 18:23:52 visual_prompt]: Epoch 15 / 100: avg data time: 5.15e+00, avg batch time: 6.5929, average train loss: 0.8469
[11/15 18:24:42 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5868, average loss: 1.0016
[11/15 18:24:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.98	
[11/15 18:24:42 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/15 18:32:15 visual_prompt]: Epoch 16 / 100: avg data time: 5.04e+00, avg batch time: 6.4765, average train loss: 0.7687
[11/15 18:33:06 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5841, average loss: 0.7205
[11/15 18:33:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.86	
[11/15 18:33:06 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/15 18:40:56 visual_prompt]: Epoch 17 / 100: avg data time: 5.27e+00, avg batch time: 6.7053, average train loss: 0.7556
[11/15 18:41:48 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5831, average loss: 0.8274
[11/15 18:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.77	
[11/15 18:41:48 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/15 18:49:29 visual_prompt]: Epoch 18 / 100: avg data time: 5.15e+00, avg batch time: 6.5833, average train loss: 0.8427
[11/15 18:50:20 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5834, average loss: 0.9535
[11/15 18:50:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.84	
[11/15 18:50:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/15 18:57:49 visual_prompt]: Epoch 19 / 100: avg data time: 4.97e+00, avg batch time: 6.4126, average train loss: 0.8264
[11/15 18:58:41 visual_prompt]: Inference (val):avg data time: 3.93e-05, avg batch time: 0.5814, average loss: 0.6885
[11/15 18:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.56	
[11/15 18:58:41 visual_prompt]: Best epoch 19: best metric: -0.689
[11/15 18:58:41 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/15 19:06:36 visual_prompt]: Epoch 20 / 100: avg data time: 5.34e+00, avg batch time: 6.7791, average train loss: 0.8535
[11/15 19:07:28 visual_prompt]: Inference (val):avg data time: 4.11e-05, avg batch time: 0.5819, average loss: 0.6880
[11/15 19:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.41	
[11/15 19:07:28 visual_prompt]: Best epoch 20: best metric: -0.688
[11/15 19:07:28 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/15 19:14:54 visual_prompt]: Epoch 21 / 100: avg data time: 4.93e+00, avg batch time: 6.3708, average train loss: 0.7238
[11/15 19:15:46 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5805, average loss: 1.0100
[11/15 19:15:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.40	
[11/15 19:15:46 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/15 19:23:54 visual_prompt]: Epoch 22 / 100: avg data time: 5.53e+00, avg batch time: 6.9730, average train loss: 0.7808
[11/15 19:24:49 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5852, average loss: 0.8744
[11/15 19:24:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.01	
[11/15 19:24:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/15 19:32:29 visual_prompt]: Epoch 23 / 100: avg data time: 5.13e+00, avg batch time: 6.5734, average train loss: 0.7535
[11/15 19:33:20 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5821, average loss: 1.0724
[11/15 19:33:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.22	
[11/15 19:33:20 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/15 19:41:00 visual_prompt]: Epoch 24 / 100: avg data time: 5.13e+00, avg batch time: 6.5698, average train loss: 0.7305
[11/15 19:41:53 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5826, average loss: 0.6910
[11/15 19:41:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.36	
[11/15 19:41:53 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/15 19:49:40 visual_prompt]: Epoch 25 / 100: avg data time: 5.23e+00, avg batch time: 6.6717, average train loss: 0.7646
[11/15 19:50:34 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5786, average loss: 0.7354
[11/15 19:50:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.28	
[11/15 19:50:34 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/15 19:58:19 visual_prompt]: Epoch 26 / 100: avg data time: 5.21e+00, avg batch time: 6.6471, average train loss: 0.8526
[11/15 19:59:10 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5830, average loss: 1.0537
[11/15 19:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.66	
[11/15 19:59:10 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/15 20:06:58 visual_prompt]: Epoch 27 / 100: avg data time: 5.25e+00, avg batch time: 6.6869, average train loss: 0.8048
[11/15 20:07:50 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5821, average loss: 0.9531
[11/15 20:07:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 42.50	
[11/15 20:07:50 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/15 20:15:37 visual_prompt]: Epoch 28 / 100: avg data time: 5.23e+00, avg batch time: 6.6688, average train loss: 0.8162
[11/15 20:16:32 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5803, average loss: 0.9955
[11/15 20:16:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.38	
[11/15 20:16:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/15 20:24:13 visual_prompt]: Epoch 29 / 100: avg data time: 5.13e+00, avg batch time: 6.5737, average train loss: 0.7588
[11/15 20:25:11 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5819, average loss: 1.0721
[11/15 20:25:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.06	
[11/15 20:25:11 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/15 20:32:50 visual_prompt]: Epoch 30 / 100: avg data time: 5.12e+00, avg batch time: 6.5599, average train loss: 0.7299
[11/15 20:33:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5804, average loss: 0.8199
[11/15 20:33:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.34	
[11/15 20:33:42 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/15 20:41:39 visual_prompt]: Epoch 31 / 100: avg data time: 5.36e+00, avg batch time: 6.8000, average train loss: 0.7621
[11/15 20:42:35 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5841, average loss: 0.7268
[11/15 20:42:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.42	
[11/15 20:42:35 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/15 20:50:07 visual_prompt]: Epoch 32 / 100: avg data time: 5.03e+00, avg batch time: 6.4673, average train loss: 0.7685
[11/15 20:51:02 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5827, average loss: 0.8899
[11/15 20:51:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.62	
[11/15 20:51:02 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/15 20:58:35 visual_prompt]: Epoch 33 / 100: avg data time: 5.04e+00, avg batch time: 6.4801, average train loss: 0.7532
[11/15 20:59:25 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5786, average loss: 0.6912
[11/15 20:59:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.70	
[11/15 20:59:25 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/15 21:07:11 visual_prompt]: Epoch 34 / 100: avg data time: 5.21e+00, avg batch time: 6.6523, average train loss: 0.8270
[11/15 21:08:06 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5786, average loss: 1.1602
[11/15 21:08:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.30	
[11/15 21:08:06 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/15 21:15:42 visual_prompt]: Epoch 35 / 100: avg data time: 5.08e+00, avg batch time: 6.5208, average train loss: 0.8910
[11/15 21:16:34 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5807, average loss: 0.6892
[11/15 21:16:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.77	
[11/15 21:16:34 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/15 21:24:08 visual_prompt]: Epoch 36 / 100: avg data time: 5.05e+00, avg batch time: 6.4898, average train loss: 0.7465
[11/15 21:24:59 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5794, average loss: 0.9442
[11/15 21:24:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 48.88	
[11/15 21:24:59 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/15 21:32:17 visual_prompt]: Epoch 37 / 100: avg data time: 4.82e+00, avg batch time: 6.2579, average train loss: 0.7785
[11/15 21:33:07 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5821, average loss: 0.7648
[11/15 21:33:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.63	
[11/15 21:33:07 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/15 21:40:33 visual_prompt]: Epoch 38 / 100: avg data time: 4.93e+00, avg batch time: 6.3661, average train loss: 0.7660
[11/15 21:41:24 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5836, average loss: 0.7108
[11/15 21:41:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.11	
[11/15 21:41:24 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/15 21:49:11 visual_prompt]: Epoch 39 / 100: avg data time: 5.23e+00, avg batch time: 6.6726, average train loss: 0.9831
[11/15 21:50:02 visual_prompt]: Inference (val):avg data time: 3.80e-05, avg batch time: 0.5858, average loss: 0.7791
[11/15 21:50:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.45	
[11/15 21:50:02 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/15 21:57:18 visual_prompt]: Epoch 40 / 100: avg data time: 4.78e+00, avg batch time: 6.2269, average train loss: 0.7358
[11/15 21:58:07 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5827, average loss: 0.6884
[11/15 21:58:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.04	
[11/15 21:58:07 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/15 22:05:24 visual_prompt]: Epoch 41 / 100: avg data time: 4.80e+00, avg batch time: 6.2401, average train loss: 0.7263
[11/15 22:06:14 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5806, average loss: 0.7577
[11/15 22:06:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.33	
[11/15 22:06:14 visual_prompt]: Stopping early.
[11/15 22:06:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/15 22:06:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/15 22:06:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/15 22:06:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/15 22:06:14 visual_prompt]: Training with config:
[11/15 22:06:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/15 22:06:14 visual_prompt]: Loading training data...
[11/15 22:06:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/15 22:06:15 visual_prompt]: Loading validation data...
[11/15 22:06:15 visual_prompt]: Constructing mammo-cbis dataset val...
[11/15 22:06:15 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/15 22:06:17 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/15 22:06:17 visual_prompt]: tuned percent:0.532
[11/15 22:06:18 visual_prompt]: Device used for model: 0
[11/15 22:06:18 visual_prompt]: Setting up Evaluator...
[11/15 22:06:18 visual_prompt]: Setting up Trainer...
[11/15 22:06:18 visual_prompt]: 	Setting up the optimizer...
[11/15 22:06:18 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/15 22:13:35 visual_prompt]: Epoch 1 / 100: avg data time: 4.80e+00, avg batch time: 6.2414, average train loss: 1.4863
[11/15 22:14:25 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5793, average loss: 1.4553
[11/15 22:14:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/15 22:14:25 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/15 22:21:40 visual_prompt]: Epoch 2 / 100: avg data time: 4.78e+00, avg batch time: 6.2196, average train loss: 1.0889
[11/15 22:22:30 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5814, average loss: 0.7247
[11/15 22:22:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.45	
[11/15 22:22:30 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/15 22:29:49 visual_prompt]: Epoch 3 / 100: avg data time: 4.83e+00, avg batch time: 6.2661, average train loss: 0.7219
[11/15 22:30:39 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5836, average loss: 0.8414
[11/15 22:30:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.48	
[11/15 22:30:39 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/15 22:37:55 visual_prompt]: Epoch 4 / 100: avg data time: 4.78e+00, avg batch time: 6.2255, average train loss: 0.7836
[11/15 22:38:44 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5839, average loss: 0.8061
[11/15 22:38:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/15 22:38:44 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/15 22:45:58 visual_prompt]: Epoch 5 / 100: avg data time: 4.75e+00, avg batch time: 6.1882, average train loss: 0.8177
[11/15 22:46:47 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5837, average loss: 0.6885
[11/15 22:46:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/15 22:46:47 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/15 22:54:03 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e+00, avg batch time: 6.2223, average train loss: 0.7580
[11/15 22:54:53 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5810, average loss: 0.6742
[11/15 22:54:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 63.82	
[11/15 22:54:53 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/15 23:02:07 visual_prompt]: Epoch 7 / 100: avg data time: 4.76e+00, avg batch time: 6.1968, average train loss: 0.7373
[11/15 23:02:56 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5826, average loss: 1.7252
[11/15 23:02:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.26	
[11/15 23:02:56 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/15 23:10:10 visual_prompt]: Epoch 8 / 100: avg data time: 4.76e+00, avg batch time: 6.1951, average train loss: 0.7694
[11/15 23:11:00 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5832, average loss: 1.1083
[11/15 23:11:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.02	
[11/15 23:11:00 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/15 23:18:13 visual_prompt]: Epoch 9 / 100: avg data time: 4.75e+00, avg batch time: 6.1913, average train loss: 0.8029
[11/15 23:19:03 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5852, average loss: 0.6786
[11/15 23:19:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.02	
[11/15 23:19:03 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/15 23:26:18 visual_prompt]: Epoch 10 / 100: avg data time: 4.77e+00, avg batch time: 6.2094, average train loss: 0.7228
[11/15 23:27:08 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5833, average loss: 0.7685
[11/15 23:27:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.08	
[11/15 23:27:08 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/15 23:34:22 visual_prompt]: Epoch 11 / 100: avg data time: 4.76e+00, avg batch time: 6.2003, average train loss: 0.7622
[11/15 23:35:12 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5822, average loss: 0.7761
[11/15 23:35:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.23	
[11/15 23:35:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/15 23:42:26 visual_prompt]: Epoch 12 / 100: avg data time: 4.76e+00, avg batch time: 6.2031, average train loss: 0.7614
[11/15 23:43:16 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5823, average loss: 0.7236
[11/15 23:43:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.74	
[11/15 23:43:16 visual_prompt]: Best epoch 12: best metric: -0.724
[11/15 23:43:16 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/15 23:50:30 visual_prompt]: Epoch 13 / 100: avg data time: 4.76e+00, avg batch time: 6.2039, average train loss: 0.7759
[11/15 23:51:20 visual_prompt]: Inference (val):avg data time: 3.63e-05, avg batch time: 0.5800, average loss: 0.7158
[11/15 23:51:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.96	
[11/15 23:51:20 visual_prompt]: Best epoch 13: best metric: -0.716
[11/15 23:51:20 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/15 23:58:34 visual_prompt]: Epoch 14 / 100: avg data time: 4.76e+00, avg batch time: 6.2029, average train loss: 0.7538
[11/15 23:59:24 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5814, average loss: 0.7155
[11/15 23:59:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 47.32	
[11/15 23:59:24 visual_prompt]: Best epoch 14: best metric: -0.716
[11/15 23:59:24 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/16 00:06:38 visual_prompt]: Epoch 15 / 100: avg data time: 4.76e+00, avg batch time: 6.1992, average train loss: 0.7450
[11/16 00:07:28 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5795, average loss: 0.7131
[11/16 00:07:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.61	
[11/16 00:07:28 visual_prompt]: Best epoch 15: best metric: -0.713
[11/16 00:07:28 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/16 00:14:41 visual_prompt]: Epoch 16 / 100: avg data time: 4.75e+00, avg batch time: 6.1893, average train loss: 0.7322
[11/16 00:15:31 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5825, average loss: 0.9053
[11/16 00:15:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.49	
[11/16 00:15:31 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/16 00:22:45 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e+00, avg batch time: 6.1937, average train loss: 0.7835
[11/16 00:23:34 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5858, average loss: 0.8792
[11/16 00:23:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.69	
[11/16 00:23:34 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/16 00:30:47 visual_prompt]: Epoch 18 / 100: avg data time: 4.74e+00, avg batch time: 6.1797, average train loss: 0.7829
[11/16 00:31:36 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5817, average loss: 0.8792
[11/16 00:31:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.64	
[11/16 00:31:36 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/16 00:38:50 visual_prompt]: Epoch 19 / 100: avg data time: 4.75e+00, avg batch time: 6.1943, average train loss: 0.7793
[11/16 00:39:40 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5828, average loss: 0.7425
[11/16 00:39:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.46	
[11/16 00:39:40 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/16 00:46:54 visual_prompt]: Epoch 20 / 100: avg data time: 4.77e+00, avg batch time: 6.2104, average train loss: 0.7126
[11/16 00:47:44 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5853, average loss: 0.6826
[11/16 00:47:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.20	
[11/16 00:47:44 visual_prompt]: Best epoch 20: best metric: -0.683
[11/16 00:47:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/16 00:54:59 visual_prompt]: Epoch 21 / 100: avg data time: 4.77e+00, avg batch time: 6.2088, average train loss: 0.7119
[11/16 00:55:48 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5836, average loss: 0.6854
[11/16 00:55:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 61.80	
[11/16 00:55:48 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/16 01:03:04 visual_prompt]: Epoch 22 / 100: avg data time: 4.79e+00, avg batch time: 6.2276, average train loss: 0.7526
[11/16 01:03:54 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5832, average loss: 0.9010
[11/16 01:03:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/16 01:03:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/16 01:11:09 visual_prompt]: Epoch 23 / 100: avg data time: 4.77e+00, avg batch time: 6.2088, average train loss: 0.8169
[11/16 01:11:58 visual_prompt]: Inference (val):avg data time: 3.88e-05, avg batch time: 0.5810, average loss: 0.8924
[11/16 01:11:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.24	
[11/16 01:11:58 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/16 01:19:12 visual_prompt]: Epoch 24 / 100: avg data time: 4.75e+00, avg batch time: 6.1963, average train loss: 0.7557
[11/16 01:20:01 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5821, average loss: 0.6873
[11/16 01:20:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 62.08	
[11/16 01:20:01 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/16 01:27:16 visual_prompt]: Epoch 25 / 100: avg data time: 4.77e+00, avg batch time: 6.2100, average train loss: 0.7295
[11/16 01:28:06 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5810, average loss: 0.6772
[11/16 01:28:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.99	
[11/16 01:28:06 visual_prompt]: Best epoch 25: best metric: -0.677
[11/16 01:28:06 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/16 01:35:19 visual_prompt]: Epoch 26 / 100: avg data time: 4.75e+00, avg batch time: 6.1882, average train loss: 0.7363
[11/16 01:36:09 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5823, average loss: 0.7935
[11/16 01:36:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/16 01:36:09 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/16 01:43:22 visual_prompt]: Epoch 27 / 100: avg data time: 4.74e+00, avg batch time: 6.1868, average train loss: 0.7015
[11/16 01:44:12 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5821, average loss: 0.6977
[11/16 01:44:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 62.49	
[11/16 01:44:12 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/16 01:51:26 visual_prompt]: Epoch 28 / 100: avg data time: 4.76e+00, avg batch time: 6.1973, average train loss: 0.7252
[11/16 01:52:15 visual_prompt]: Inference (val):avg data time: 3.84e-05, avg batch time: 0.5805, average loss: 0.6889
[11/16 01:52:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/16 01:52:15 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/16 01:59:29 visual_prompt]: Epoch 29 / 100: avg data time: 4.75e+00, avg batch time: 6.1948, average train loss: 0.7129
[11/16 02:00:20 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5868, average loss: 0.7465
[11/16 02:00:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/16 02:00:20 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/16 02:07:35 visual_prompt]: Epoch 30 / 100: avg data time: 4.77e+00, avg batch time: 6.2116, average train loss: 0.7191
[11/16 02:08:24 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5844, average loss: 0.8272
[11/16 02:08:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.31	
[11/16 02:08:24 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/16 02:15:39 visual_prompt]: Epoch 31 / 100: avg data time: 4.77e+00, avg batch time: 6.2072, average train loss: 0.7088
[11/16 02:16:28 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5843, average loss: 0.6902
[11/16 02:16:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.13	
[11/16 02:16:28 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/16 02:23:42 visual_prompt]: Epoch 32 / 100: avg data time: 4.75e+00, avg batch time: 6.1891, average train loss: 0.7403
[11/16 02:24:32 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5866, average loss: 0.8600
[11/16 02:24:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.96	
[11/16 02:24:32 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/16 02:31:45 visual_prompt]: Epoch 33 / 100: avg data time: 4.75e+00, avg batch time: 6.1942, average train loss: 0.7203
[11/16 02:32:35 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5842, average loss: 0.6888
[11/16 02:32:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 60.78	
[11/16 02:32:35 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/16 02:39:48 visual_prompt]: Epoch 34 / 100: avg data time: 4.74e+00, avg batch time: 6.1840, average train loss: 0.7136
[11/16 02:40:37 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5799, average loss: 0.6986
[11/16 02:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.36	
[11/16 02:40:37 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/16 02:47:50 visual_prompt]: Epoch 35 / 100: avg data time: 4.74e+00, avg batch time: 6.1785, average train loss: 0.7147
[11/16 02:48:40 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5796, average loss: 0.7499
[11/16 02:48:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/16 02:48:40 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/16 02:55:55 visual_prompt]: Epoch 36 / 100: avg data time: 4.77e+00, avg batch time: 6.2142, average train loss: 0.7125
[11/16 02:56:44 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5801, average loss: 0.6890
[11/16 02:56:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 60.34	
[11/16 02:56:44 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/16 03:03:58 visual_prompt]: Epoch 37 / 100: avg data time: 4.75e+00, avg batch time: 6.1927, average train loss: 0.7257
[11/16 03:04:48 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5787, average loss: 0.7514
[11/16 03:04:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.71	
[11/16 03:04:48 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/16 03:12:02 visual_prompt]: Epoch 38 / 100: avg data time: 4.76e+00, avg batch time: 6.1962, average train loss: 0.7024
[11/16 03:12:51 visual_prompt]: Inference (val):avg data time: 2.88e-05, avg batch time: 0.5853, average loss: 0.6758
[11/16 03:12:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 58.01	
[11/16 03:12:51 visual_prompt]: Best epoch 38: best metric: -0.676
[11/16 03:12:51 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/16 03:20:06 visual_prompt]: Epoch 39 / 100: avg data time: 4.76e+00, avg batch time: 6.2002, average train loss: 0.7164
[11/16 03:20:55 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5819, average loss: 0.7275
[11/16 03:20:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.31	
[11/16 03:20:55 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/16 03:28:09 visual_prompt]: Epoch 40 / 100: avg data time: 4.76e+00, avg batch time: 6.1939, average train loss: 0.7100
[11/16 03:28:58 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5840, average loss: 0.7220
[11/16 03:28:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.44	
[11/16 03:28:58 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/16 03:36:12 visual_prompt]: Epoch 41 / 100: avg data time: 4.76e+00, avg batch time: 6.1983, average train loss: 0.7213
[11/16 03:37:02 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5843, average loss: 0.8634
[11/16 03:37:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.46	
[11/16 03:37:02 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/16 03:44:15 visual_prompt]: Epoch 42 / 100: avg data time: 4.74e+00, avg batch time: 6.1859, average train loss: 0.7201
[11/16 03:45:05 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5830, average loss: 0.6875
[11/16 03:45:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.03	
[11/16 03:45:05 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/16 03:52:19 visual_prompt]: Epoch 43 / 100: avg data time: 4.75e+00, avg batch time: 6.1931, average train loss: 0.7456
[11/16 03:53:08 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5815, average loss: 0.7035
[11/16 03:53:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.30	
[11/16 03:53:08 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/16 04:00:23 visual_prompt]: Epoch 44 / 100: avg data time: 4.77e+00, avg batch time: 6.2067, average train loss: 0.7153
[11/16 04:01:12 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5872, average loss: 0.6854
[11/16 04:01:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 60.85	
[11/16 04:01:12 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/16 04:08:26 visual_prompt]: Epoch 45 / 100: avg data time: 4.76e+00, avg batch time: 6.1984, average train loss: 0.7200
[11/16 04:09:16 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5825, average loss: 0.6873
[11/16 04:09:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.62	
[11/16 04:09:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/16 04:16:29 visual_prompt]: Epoch 46 / 100: avg data time: 4.74e+00, avg batch time: 6.1856, average train loss: 0.7171
[11/16 04:17:19 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5790, average loss: 0.7302
[11/16 04:17:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.67	
[11/16 04:17:19 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/16 04:24:32 visual_prompt]: Epoch 47 / 100: avg data time: 4.76e+00, avg batch time: 6.1970, average train loss: 0.7280
[11/16 04:25:22 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5803, average loss: 0.7229
[11/16 04:25:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.61	
[11/16 04:25:22 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/16 04:32:35 visual_prompt]: Epoch 48 / 100: avg data time: 4.74e+00, avg batch time: 6.1819, average train loss: 0.7174
[11/16 04:33:25 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5817, average loss: 0.6994
[11/16 04:33:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.93	
[11/16 04:33:25 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/16 04:40:39 visual_prompt]: Epoch 49 / 100: avg data time: 4.76e+00, avg batch time: 6.1976, average train loss: 0.7036
[11/16 04:41:28 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5814, average loss: 0.6869
[11/16 04:41:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.10	
[11/16 04:41:28 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/16 04:48:42 visual_prompt]: Epoch 50 / 100: avg data time: 4.75e+00, avg batch time: 6.1895, average train loss: 0.7272
[11/16 04:49:31 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5869, average loss: 0.9267
[11/16 04:49:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.26	
[11/16 04:49:31 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/16 04:56:45 visual_prompt]: Epoch 51 / 100: avg data time: 4.75e+00, avg batch time: 6.1875, average train loss: 0.7200
[11/16 04:57:34 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5863, average loss: 0.7696
[11/16 04:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.26	
[11/16 04:57:34 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/16 05:04:48 visual_prompt]: Epoch 52 / 100: avg data time: 4.76e+00, avg batch time: 6.2001, average train loss: 0.7037
[11/16 05:05:38 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5834, average loss: 0.7411
[11/16 05:05:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.82	
[11/16 05:05:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/16 05:12:53 visual_prompt]: Epoch 53 / 100: avg data time: 4.77e+00, avg batch time: 6.2105, average train loss: 0.7169
[11/16 05:13:43 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5822, average loss: 0.6890
[11/16 05:13:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.98	
[11/16 05:13:43 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[11/16 05:20:57 visual_prompt]: Epoch 54 / 100: avg data time: 4.76e+00, avg batch time: 6.2011, average train loss: 0.7059
[11/16 05:21:47 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5776, average loss: 0.7519
[11/16 05:21:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.75	
[11/16 05:21:47 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.2587248741756253
[11/16 05:28:59 visual_prompt]: Epoch 55 / 100: avg data time: 4.74e+00, avg batch time: 6.1782, average train loss: 0.7153
[11/16 05:29:49 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5861, average loss: 0.7024
[11/16 05:29:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.97	
[11/16 05:29:49 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.25
[11/16 05:37:02 visual_prompt]: Epoch 56 / 100: avg data time: 4.74e+00, avg batch time: 6.1821, average train loss: 0.7153
[11/16 05:37:51 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5815, average loss: 0.7652
[11/16 05:37:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.32	
[11/16 05:37:51 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.24127512582437483
[11/16 05:45:06 visual_prompt]: Epoch 57 / 100: avg data time: 4.77e+00, avg batch time: 6.2095, average train loss: 0.7080
[11/16 05:45:56 visual_prompt]: Inference (val):avg data time: 3.52e-05, avg batch time: 0.5834, average loss: 0.7795
[11/16 05:45:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.96	
[11/16 05:45:56 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.23256088156396867
[11/16 05:53:08 visual_prompt]: Epoch 58 / 100: avg data time: 4.73e+00, avg batch time: 6.1761, average train loss: 0.7036
[11/16 05:53:58 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5795, average loss: 0.6841
[11/16 05:53:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 61.21	
[11/16 05:53:58 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.22386788418308667
[11/16 06:01:13 visual_prompt]: Epoch 59 / 100: avg data time: 4.76e+00, avg batch time: 6.2042, average train loss: 0.7108
[11/16 06:02:02 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5842, average loss: 0.6901
[11/16 06:02:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.02	
[11/16 06:02:02 visual_prompt]: Stopping early.
[11/16 06:02:02 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 06:02:02 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 06:02:02 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 06:02:02 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 06:02:02 visual_prompt]: Training with config:
[11/16 06:02:02 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 06:02:02 visual_prompt]: Loading training data...
[11/16 06:02:02 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 06:02:02 visual_prompt]: Loading validation data...
[11/16 06:02:02 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 06:02:02 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 06:02:05 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 06:02:05 visual_prompt]: tuned percent:0.532
[11/16 06:02:05 visual_prompt]: Device used for model: 0
[11/16 06:02:05 visual_prompt]: Setting up Evaluator...
[11/16 06:02:05 visual_prompt]: Setting up Trainer...
[11/16 06:02:05 visual_prompt]: 	Setting up the optimizer...
[11/16 06:02:05 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 06:09:20 visual_prompt]: Epoch 1 / 100: avg data time: 4.77e+00, avg batch time: 6.2070, average train loss: 1.4863
[11/16 06:10:09 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5829, average loss: 1.4553
[11/16 06:10:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 06:10:09 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/16 06:17:23 visual_prompt]: Epoch 2 / 100: avg data time: 4.76e+00, avg batch time: 6.1991, average train loss: 1.0902
[11/16 06:18:13 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5818, average loss: 0.7249
[11/16 06:18:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.43	
[11/16 06:18:13 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/16 06:25:26 visual_prompt]: Epoch 3 / 100: avg data time: 4.74e+00, avg batch time: 6.1862, average train loss: 0.7235
[11/16 06:26:16 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5851, average loss: 0.8395
[11/16 06:26:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.53	
[11/16 06:26:16 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/16 06:33:29 visual_prompt]: Epoch 4 / 100: avg data time: 4.74e+00, avg batch time: 6.1832, average train loss: 0.7893
[11/16 06:34:18 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5823, average loss: 0.8533
[11/16 06:34:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.83	
[11/16 06:34:18 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/16 06:41:31 visual_prompt]: Epoch 5 / 100: avg data time: 4.74e+00, avg batch time: 6.1834, average train loss: 0.8105
[11/16 06:42:21 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5858, average loss: 0.7082
[11/16 06:42:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/16 06:42:21 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/16 06:49:35 visual_prompt]: Epoch 6 / 100: avg data time: 4.76e+00, avg batch time: 6.2053, average train loss: 0.7664
[11/16 06:50:25 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5770, average loss: 0.6719
[11/16 06:50:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.28	
[11/16 06:50:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/16 06:57:38 visual_prompt]: Epoch 7 / 100: avg data time: 4.74e+00, avg batch time: 6.1825, average train loss: 0.7331
[11/16 06:58:27 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5847, average loss: 1.1880
[11/16 06:58:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.68	
[11/16 06:58:27 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/16 07:05:41 visual_prompt]: Epoch 8 / 100: avg data time: 4.75e+00, avg batch time: 6.1915, average train loss: 0.7783
[11/16 07:06:30 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5845, average loss: 1.4210
[11/16 07:06:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.70	
[11/16 07:06:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/16 07:13:43 visual_prompt]: Epoch 9 / 100: avg data time: 4.75e+00, avg batch time: 6.1851, average train loss: 0.8966
[11/16 07:14:33 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5828, average loss: 0.6636
[11/16 07:14:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.04	
[11/16 07:14:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/16 07:21:45 visual_prompt]: Epoch 10 / 100: avg data time: 4.74e+00, avg batch time: 6.1778, average train loss: 0.7290
[11/16 07:22:35 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5828, average loss: 0.8045
[11/16 07:22:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.91	
[11/16 07:22:35 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/16 07:29:48 visual_prompt]: Epoch 11 / 100: avg data time: 4.74e+00, avg batch time: 6.1857, average train loss: 0.7937
[11/16 07:30:38 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5826, average loss: 1.1487
[11/16 07:30:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.00	
[11/16 07:30:38 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/16 07:37:51 visual_prompt]: Epoch 12 / 100: avg data time: 4.74e+00, avg batch time: 6.1886, average train loss: 0.7618
[11/16 07:38:41 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5843, average loss: 0.6465
[11/16 07:38:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.15	
[11/16 07:38:41 visual_prompt]: Best epoch 12: best metric: -0.647
[11/16 07:38:41 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/16 07:45:54 visual_prompt]: Epoch 13 / 100: avg data time: 4.75e+00, avg batch time: 6.1938, average train loss: 0.7177
[11/16 07:46:44 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5834, average loss: 0.7420
[11/16 07:46:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.91	
[11/16 07:46:44 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/16 07:53:57 visual_prompt]: Epoch 14 / 100: avg data time: 4.75e+00, avg batch time: 6.1938, average train loss: 0.6855
[11/16 07:54:47 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5819, average loss: 0.7182
[11/16 07:54:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 71.02	
[11/16 07:54:47 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/16 08:02:00 visual_prompt]: Epoch 15 / 100: avg data time: 4.74e+00, avg batch time: 6.1803, average train loss: 0.7269
[11/16 08:02:50 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5840, average loss: 0.6450
[11/16 08:02:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/16 08:02:50 visual_prompt]: Best epoch 15: best metric: -0.645
[11/16 08:02:50 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/16 08:10:02 visual_prompt]: Epoch 16 / 100: avg data time: 4.74e+00, avg batch time: 6.1773, average train loss: 0.7688
[11/16 08:10:52 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5850, average loss: 0.7389
[11/16 08:10:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.93	rocauc: 65.84	
[11/16 08:10:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/16 08:18:05 visual_prompt]: Epoch 17 / 100: avg data time: 4.75e+00, avg batch time: 6.1883, average train loss: 0.7174
[11/16 08:18:55 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5834, average loss: 0.8170
[11/16 08:18:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 70.48	
[11/16 08:18:55 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/16 08:26:07 visual_prompt]: Epoch 18 / 100: avg data time: 4.74e+00, avg batch time: 6.1799, average train loss: 0.7280
[11/16 08:26:57 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5802, average loss: 1.0515
[11/16 08:26:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 70.65	
[11/16 08:26:57 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/16 08:34:10 visual_prompt]: Epoch 19 / 100: avg data time: 4.75e+00, avg batch time: 6.1861, average train loss: 0.7665
[11/16 08:35:00 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5790, average loss: 0.7208
[11/16 08:35:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.37	
[11/16 08:35:00 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/16 08:42:14 visual_prompt]: Epoch 20 / 100: avg data time: 4.76e+00, avg batch time: 6.2028, average train loss: 0.6482
[11/16 08:43:04 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5887, average loss: 0.6210
[11/16 08:43:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.33	rocauc: 73.19	
[11/16 08:43:04 visual_prompt]: Best epoch 20: best metric: -0.621
[11/16 08:43:04 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/16 08:50:17 visual_prompt]: Epoch 21 / 100: avg data time: 4.75e+00, avg batch time: 6.1902, average train loss: 0.6475
[11/16 08:51:07 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5806, average loss: 0.9763
[11/16 08:51:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 73.13	
[11/16 08:51:07 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/16 08:58:21 visual_prompt]: Epoch 22 / 100: avg data time: 4.76e+00, avg batch time: 6.2009, average train loss: 0.6757
[11/16 08:59:10 visual_prompt]: Inference (val):avg data time: 3.74e-05, avg batch time: 0.5815, average loss: 0.8792
[11/16 08:59:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 73.96	
[11/16 08:59:10 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/16 09:06:25 visual_prompt]: Epoch 23 / 100: avg data time: 4.76e+00, avg batch time: 6.2029, average train loss: 0.6603
[11/16 09:07:14 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5849, average loss: 1.1808
[11/16 09:07:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 72.05	
[11/16 09:07:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/16 09:14:28 visual_prompt]: Epoch 24 / 100: avg data time: 4.75e+00, avg batch time: 6.1891, average train loss: 0.6834
[11/16 09:15:17 visual_prompt]: Inference (val):avg data time: 3.85e-05, avg batch time: 0.5851, average loss: 0.6618
[11/16 09:15:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 71.24	
[11/16 09:15:17 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/16 09:22:31 visual_prompt]: Epoch 25 / 100: avg data time: 4.76e+00, avg batch time: 6.2000, average train loss: 0.6908
[11/16 09:23:21 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5832, average loss: 0.7300
[11/16 09:23:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 74.09	
[11/16 09:23:21 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/16 09:30:34 visual_prompt]: Epoch 26 / 100: avg data time: 4.74e+00, avg batch time: 6.1784, average train loss: 0.6515
[11/16 09:31:23 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5819, average loss: 0.6007
[11/16 09:31:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 73.94	
[11/16 09:31:23 visual_prompt]: Best epoch 26: best metric: -0.601
[11/16 09:31:23 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/16 09:38:37 visual_prompt]: Epoch 27 / 100: avg data time: 4.75e+00, avg batch time: 6.1938, average train loss: 0.6220
[11/16 09:39:27 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5822, average loss: 0.6727
[11/16 09:39:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 76.09	
[11/16 09:39:27 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/16 09:46:41 visual_prompt]: Epoch 28 / 100: avg data time: 4.75e+00, avg batch time: 6.1934, average train loss: 0.6932
[11/16 09:47:31 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5801, average loss: 0.7420
[11/16 09:47:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 75.80	
[11/16 09:47:31 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/16 09:54:43 visual_prompt]: Epoch 29 / 100: avg data time: 4.74e+00, avg batch time: 6.1788, average train loss: 0.6056
[11/16 09:55:33 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5831, average loss: 0.6275
[11/16 09:55:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 75.67	
[11/16 09:55:33 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/16 10:02:47 visual_prompt]: Epoch 30 / 100: avg data time: 4.75e+00, avg batch time: 6.1941, average train loss: 0.5842
[11/16 10:03:37 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5850, average loss: 1.5055
[11/16 10:03:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.34	rocauc: 72.48	
[11/16 10:03:37 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/16 10:10:49 visual_prompt]: Epoch 31 / 100: avg data time: 4.74e+00, avg batch time: 6.1778, average train loss: 0.6911
[11/16 10:11:39 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5883, average loss: 0.6117
[11/16 10:11:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.46	
[11/16 10:11:39 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/16 10:18:53 visual_prompt]: Epoch 32 / 100: avg data time: 4.75e+00, avg batch time: 6.1979, average train loss: 0.6841
[11/16 10:19:42 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5822, average loss: 1.1420
[11/16 10:19:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 72.26	
[11/16 10:19:42 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/16 10:26:55 visual_prompt]: Epoch 33 / 100: avg data time: 4.74e+00, avg batch time: 6.1850, average train loss: 0.6362
[11/16 10:27:45 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5832, average loss: 0.6317
[11/16 10:27:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.48	
[11/16 10:27:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/16 10:34:58 visual_prompt]: Epoch 34 / 100: avg data time: 4.74e+00, avg batch time: 6.1875, average train loss: 0.6442
[11/16 10:35:48 visual_prompt]: Inference (val):avg data time: 3.72e-05, avg batch time: 0.5831, average loss: 0.6702
[11/16 10:35:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 74.03	
[11/16 10:35:48 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/16 10:43:00 visual_prompt]: Epoch 35 / 100: avg data time: 4.73e+00, avg batch time: 6.1783, average train loss: 0.5889
[11/16 10:43:50 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5810, average loss: 0.6170
[11/16 10:43:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.54	rocauc: 74.47	
[11/16 10:43:50 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/16 10:51:05 visual_prompt]: Epoch 36 / 100: avg data time: 4.77e+00, avg batch time: 6.2077, average train loss: 0.5843
[11/16 10:51:54 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5819, average loss: 1.2020
[11/16 10:51:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.19	rocauc: 74.43	
[11/16 10:51:54 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/16 10:59:07 visual_prompt]: Epoch 37 / 100: avg data time: 4.74e+00, avg batch time: 6.1813, average train loss: 0.6478
[11/16 10:59:59 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5861, average loss: 0.7317
[11/16 10:59:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 74.28	
[11/16 10:59:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/16 11:07:28 visual_prompt]: Epoch 38 / 100: avg data time: 4.96e+00, avg batch time: 6.4101, average train loss: 0.5724
[11/16 11:08:17 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5887, average loss: 0.6365
[11/16 11:08:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.94	
[11/16 11:08:17 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/16 11:15:33 visual_prompt]: Epoch 39 / 100: avg data time: 4.77e+00, avg batch time: 6.2262, average train loss: 0.5634
[11/16 11:16:23 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5878, average loss: 0.7090
[11/16 11:16:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.80	
[11/16 11:16:23 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/16 11:23:37 visual_prompt]: Epoch 40 / 100: avg data time: 4.75e+00, avg batch time: 6.2010, average train loss: 0.6224
[11/16 11:24:27 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5845, average loss: 0.9828
[11/16 11:24:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 73.65	
[11/16 11:24:27 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/16 11:31:43 visual_prompt]: Epoch 41 / 100: avg data time: 4.77e+00, avg batch time: 6.2251, average train loss: 0.5899
[11/16 11:32:33 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5822, average loss: 0.7612
[11/16 11:32:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 71.99	
[11/16 11:32:33 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/16 11:39:53 visual_prompt]: Epoch 42 / 100: avg data time: 4.84e+00, avg batch time: 6.2920, average train loss: 0.5473
[11/16 11:40:43 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5856, average loss: 0.6148
[11/16 11:40:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.45	
[11/16 11:40:43 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/16 11:47:58 visual_prompt]: Epoch 43 / 100: avg data time: 4.76e+00, avg batch time: 6.2108, average train loss: 0.5674
[11/16 11:48:47 visual_prompt]: Inference (val):avg data time: 2.81e-05, avg batch time: 0.5851, average loss: 0.6081
[11/16 11:48:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 73.91	
[11/16 11:48:47 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/16 11:56:01 visual_prompt]: Epoch 44 / 100: avg data time: 4.74e+00, avg batch time: 6.1905, average train loss: 0.5809
[11/16 11:56:50 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5993, average loss: 0.6708
[11/16 11:56:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.89	
[11/16 11:56:50 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/16 12:04:07 visual_prompt]: Epoch 45 / 100: avg data time: 4.78e+00, avg batch time: 6.2364, average train loss: 0.5514
[11/16 12:04:57 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5859, average loss: 0.7234
[11/16 12:04:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 74.39	
[11/16 12:04:57 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/16 12:12:12 visual_prompt]: Epoch 46 / 100: avg data time: 4.77e+00, avg batch time: 6.2162, average train loss: 0.5194
[11/16 12:13:02 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5826, average loss: 0.6551
[11/16 12:13:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 76.75	
[11/16 12:13:02 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/16 12:20:17 visual_prompt]: Epoch 47 / 100: avg data time: 4.77e+00, avg batch time: 6.2164, average train loss: 0.5439
[11/16 12:21:07 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5817, average loss: 0.8558
[11/16 12:21:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 71.35	
[11/16 12:21:07 visual_prompt]: Stopping early.
[11/16 12:21:07 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 12:21:07 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 12:21:07 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 12:21:07 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 12:21:07 visual_prompt]: Training with config:
[11/16 12:21:07 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.5_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.5, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 12:21:07 visual_prompt]: Loading training data...
[11/16 12:21:07 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 12:21:07 visual_prompt]: Loading validation data...
[11/16 12:21:07 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 12:21:07 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 12:21:13 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 12:21:13 visual_prompt]: tuned percent:0.532
[11/16 12:21:13 visual_prompt]: Device used for model: 0
[11/16 12:21:13 visual_prompt]: Setting up Evaluator...
[11/16 12:21:13 visual_prompt]: Setting up Trainer...
[11/16 12:21:13 visual_prompt]: 	Setting up the optimizer...
[11/16 12:21:13 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 12:28:29 visual_prompt]: Epoch 1 / 100: avg data time: 4.79e+00, avg batch time: 6.2334, average train loss: 1.4863
[11/16 12:29:19 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5801, average loss: 1.4553
[11/16 12:29:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 12:29:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.05
[11/16 12:36:35 visual_prompt]: Epoch 2 / 100: avg data time: 4.78e+00, avg batch time: 6.2231, average train loss: 1.0903
[11/16 12:37:25 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5824, average loss: 0.7250
[11/16 12:37:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.42	
[11/16 12:37:25 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.1
[11/16 12:44:40 visual_prompt]: Epoch 3 / 100: avg data time: 4.78e+00, avg batch time: 6.2160, average train loss: 0.7237
[11/16 12:45:30 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5808, average loss: 0.8399
[11/16 12:45:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.60	
[11/16 12:45:30 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.15
[11/16 12:52:44 visual_prompt]: Epoch 4 / 100: avg data time: 4.76e+00, avg batch time: 6.2040, average train loss: 0.7933
[11/16 12:53:35 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5854, average loss: 0.8096
[11/16 12:53:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/16 12:53:35 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.2
[11/16 13:00:50 visual_prompt]: Epoch 5 / 100: avg data time: 4.76e+00, avg batch time: 6.2032, average train loss: 0.8336
[11/16 13:01:39 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5829, average loss: 0.6890
[11/16 13:01:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.67	
[11/16 13:01:39 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.25
[11/16 13:08:56 visual_prompt]: Epoch 6 / 100: avg data time: 4.79e+00, avg batch time: 6.2334, average train loss: 0.7535
[11/16 13:09:46 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5812, average loss: 0.6721
[11/16 13:09:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.13	
[11/16 13:09:46 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.3
[11/16 13:17:00 visual_prompt]: Epoch 7 / 100: avg data time: 4.76e+00, avg batch time: 6.2024, average train loss: 0.7298
[11/16 13:17:49 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5778, average loss: 1.6587
[11/16 13:17:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.39	
[11/16 13:17:49 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.35
[11/16 13:25:05 visual_prompt]: Epoch 8 / 100: avg data time: 4.79e+00, avg batch time: 6.2272, average train loss: 0.7889
[11/16 13:25:56 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5837, average loss: 1.3869
[11/16 13:25:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.23	
[11/16 13:25:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.4
[11/16 13:33:12 visual_prompt]: Epoch 9 / 100: avg data time: 4.79e+00, avg batch time: 6.2328, average train loss: 0.9032
[11/16 13:34:02 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5833, average loss: 0.6673
[11/16 13:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 62.27	
[11/16 13:34:02 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.45
[11/16 13:41:17 visual_prompt]: Epoch 10 / 100: avg data time: 4.78e+00, avg batch time: 6.2171, average train loss: 0.7352
[11/16 13:42:07 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5857, average loss: 0.8182
[11/16 13:42:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.40	
[11/16 13:42:07 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.5
[11/16 13:49:23 visual_prompt]: Epoch 11 / 100: avg data time: 4.79e+00, avg batch time: 6.2260, average train loss: 0.7594
[11/16 13:50:12 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5800, average loss: 1.1425
[11/16 13:50:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.76	
[11/16 13:50:12 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.49984770675477397
[11/16 13:57:28 visual_prompt]: Epoch 12 / 100: avg data time: 4.78e+00, avg batch time: 6.2278, average train loss: 0.7588
[11/16 13:58:18 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5814, average loss: 0.6451
[11/16 13:58:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.14	
[11/16 13:58:18 visual_prompt]: Best epoch 12: best metric: -0.645
[11/16 13:58:18 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.49939101256495605
[11/16 14:05:34 visual_prompt]: Epoch 13 / 100: avg data time: 4.78e+00, avg batch time: 6.2233, average train loss: 0.7121
[11/16 14:06:24 visual_prompt]: Inference (val):avg data time: 3.04e-03, avg batch time: 0.5841, average loss: 0.7472
[11/16 14:06:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/16 14:06:24 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.4986304738420683
[11/16 14:13:39 visual_prompt]: Epoch 14 / 100: avg data time: 4.77e+00, avg batch time: 6.2125, average train loss: 0.6895
[11/16 14:14:29 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5805, average loss: 0.7282
[11/16 14:14:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.06	
[11/16 14:14:29 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.4975670171853926
[11/16 14:21:44 visual_prompt]: Epoch 15 / 100: avg data time: 4.77e+00, avg batch time: 6.2043, average train loss: 0.7205
[11/16 14:22:33 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5840, average loss: 0.8441
[11/16 14:22:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.12	
[11/16 14:22:33 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.49620193825305203
[11/16 14:29:48 visual_prompt]: Epoch 16 / 100: avg data time: 4.76e+00, avg batch time: 6.2016, average train loss: 0.7952
[11/16 14:30:37 visual_prompt]: Inference (val):avg data time: 2.65e-05, avg batch time: 0.5842, average loss: 0.7576
[11/16 14:30:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 68.69	
[11/16 14:30:37 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.4945369001834514
[11/16 14:37:53 visual_prompt]: Epoch 17 / 100: avg data time: 4.78e+00, avg batch time: 6.2192, average train loss: 0.6727
[11/16 14:38:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5854, average loss: 0.6680
[11/16 14:38:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.51	
[11/16 14:38:42 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.4925739315689991
[11/16 14:45:58 visual_prompt]: Epoch 18 / 100: avg data time: 4.78e+00, avg batch time: 6.2215, average train loss: 0.7205
[11/16 14:46:48 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5840, average loss: 1.2647
[11/16 14:46:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.77	
[11/16 14:46:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.4903154239845797
[11/16 14:54:02 visual_prompt]: Epoch 19 / 100: avg data time: 4.75e+00, avg batch time: 6.1895, average train loss: 0.8198
[11/16 14:54:51 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5814, average loss: 0.7814
[11/16 14:54:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 69.80	
[11/16 14:54:51 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.4877641290737884
[11/16 15:02:08 visual_prompt]: Epoch 20 / 100: avg data time: 4.79e+00, avg batch time: 6.2311, average train loss: 0.6516
[11/16 15:02:58 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5836, average loss: 0.6210
[11/16 15:02:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.00	
[11/16 15:02:58 visual_prompt]: Best epoch 20: best metric: -0.621
[11/16 15:02:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.4849231551964771
[11/16 15:10:13 visual_prompt]: Epoch 21 / 100: avg data time: 4.78e+00, avg batch time: 6.2225, average train loss: 0.6324
[11/16 15:11:03 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5812, average loss: 1.2250
[11/16 15:11:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 71.95	
[11/16 15:11:03 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.48179596364169686
[11/16 15:18:18 visual_prompt]: Epoch 22 / 100: avg data time: 4.77e+00, avg batch time: 6.2140, average train loss: 0.6627
[11/16 15:19:08 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5874, average loss: 1.0498
[11/16 15:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 72.57	
[11/16 15:19:08 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.4783863644106502
[11/16 15:26:24 visual_prompt]: Epoch 23 / 100: avg data time: 4.78e+00, avg batch time: 6.2250, average train loss: 0.6718
[11/16 15:27:14 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5842, average loss: 1.0461
[11/16 15:27:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 71.55	
[11/16 15:27:14 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.47469851157479176
[11/16 15:34:30 visual_prompt]: Epoch 24 / 100: avg data time: 4.78e+00, avg batch time: 6.2211, average train loss: 0.6677
[11/16 15:35:19 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5796, average loss: 0.8375
[11/16 15:35:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 72.36	
[11/16 15:35:19 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.47073689821473175
[11/16 15:42:37 visual_prompt]: Epoch 25 / 100: avg data time: 4.81e+00, avg batch time: 6.2511, average train loss: 0.7134
[11/16 15:43:27 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5834, average loss: 0.8246
[11/16 15:43:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 72.03	
[11/16 15:43:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.4665063509461097
[11/16 15:50:42 visual_prompt]: Epoch 26 / 100: avg data time: 4.77e+00, avg batch time: 6.2102, average train loss: 0.6137
[11/16 15:51:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5811, average loss: 0.6522
[11/16 15:51:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.61	
[11/16 15:51:32 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.46201202403910646
[11/16 15:59:34 visual_prompt]: Epoch 27 / 100: avg data time: 5.44e+00, avg batch time: 6.8850, average train loss: 0.6254
[11/16 16:00:34 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5862, average loss: 0.7248
[11/16 16:00:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.15	
[11/16 16:00:34 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.4572593931387604
[11/16 16:07:49 visual_prompt]: Epoch 28 / 100: avg data time: 4.77e+00, avg batch time: 6.2178, average train loss: 0.6796
[11/16 16:08:39 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5885, average loss: 0.9833
[11/16 16:08:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 73.61	
[11/16 16:08:39 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.45225424859373686
[11/16 16:16:00 visual_prompt]: Epoch 29 / 100: avg data time: 4.84e+00, avg batch time: 6.2920, average train loss: 0.5688
[11/16 16:16:49 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5859, average loss: 0.7330
[11/16 16:16:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.07	
[11/16 16:16:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.44700268840168045
[11/16 16:24:11 visual_prompt]: Epoch 30 / 100: avg data time: 4.86e+00, avg batch time: 6.3091, average train loss: 0.5600
[11/16 16:25:02 visual_prompt]: Inference (val):avg data time: 2.70e-05, avg batch time: 0.5864, average loss: 0.8735
[11/16 16:25:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.21	
[11/16 16:25:02 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.4415111107797445
[11/16 16:32:20 visual_prompt]: Epoch 31 / 100: avg data time: 4.80e+00, avg batch time: 6.2485, average train loss: 0.7012
[11/16 16:33:09 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5860, average loss: 0.8545
[11/16 16:33:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 71.82	
[11/16 16:33:09 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.43578620636934856
[11/16 16:40:28 visual_prompt]: Epoch 32 / 100: avg data time: 4.82e+00, avg batch time: 6.2712, average train loss: 0.5778
[11/16 16:41:18 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5873, average loss: 0.8196
[11/16 16:41:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.62	
[11/16 16:41:18 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.42983495008466277
[11/16 16:48:38 visual_prompt]: Epoch 33 / 100: avg data time: 4.84e+00, avg batch time: 6.2876, average train loss: 0.4920
[11/16 16:49:28 visual_prompt]: Inference (val):avg data time: 2.68e-05, avg batch time: 0.5852, average loss: 0.6100
[11/16 16:49:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 74.01	
[11/16 16:49:28 visual_prompt]: Best epoch 33: best metric: -0.610
[11/16 16:49:28 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.4236645926147493
[11/16 16:56:43 visual_prompt]: Epoch 34 / 100: avg data time: 4.77e+00, avg batch time: 6.2206, average train loss: 0.5615
[11/16 16:57:34 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5827, average loss: 0.7080
[11/16 16:57:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.86	
[11/16 16:57:34 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.41728265158971456
[11/16 17:05:01 visual_prompt]: Epoch 35 / 100: avg data time: 4.94e+00, avg batch time: 6.3904, average train loss: 0.4871
[11/16 17:05:51 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5836, average loss: 0.7610
[11/16 17:05:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 69.58	
[11/16 17:05:51 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.4106969024216348
[11/16 17:13:14 visual_prompt]: Epoch 36 / 100: avg data time: 4.88e+00, avg batch time: 6.3286, average train loss: 0.5539
[11/16 17:14:03 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5819, average loss: 0.8829
[11/16 17:14:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.72	
[11/16 17:14:03 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.40391536883141455
[11/16 17:21:25 visual_prompt]: Epoch 37 / 100: avg data time: 4.86e+00, avg batch time: 6.3151, average train loss: 0.5321
[11/16 17:22:15 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5857, average loss: 0.7572
[11/16 17:22:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.35	
[11/16 17:22:15 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.3969463130731183
[11/16 17:29:33 visual_prompt]: Epoch 38 / 100: avg data time: 4.79e+00, avg batch time: 6.2517, average train loss: 0.4925
[11/16 17:30:23 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5859, average loss: 0.7586
[11/16 17:30:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.71	
[11/16 17:30:23 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.3897982258676867
[11/16 17:37:39 visual_prompt]: Epoch 39 / 100: avg data time: 4.78e+00, avg batch time: 6.2321, average train loss: 0.4526
[11/16 17:38:29 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5846, average loss: 0.7618
[11/16 17:38:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.27	
[11/16 17:38:29 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.3824798160583012
[11/16 17:45:44 visual_prompt]: Epoch 40 / 100: avg data time: 4.74e+00, avg batch time: 6.2096, average train loss: 0.5335
[11/16 17:46:34 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5856, average loss: 0.8272
[11/16 17:46:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.72	
[11/16 17:46:34 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.375
[11/16 17:53:55 visual_prompt]: Epoch 41 / 100: avg data time: 4.86e+00, avg batch time: 6.3045, average train loss: 0.4302
[11/16 17:54:45 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5856, average loss: 0.8510
[11/16 17:54:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.20	
[11/16 17:54:45 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.3673678906964727
[11/16 18:02:04 visual_prompt]: Epoch 42 / 100: avg data time: 4.82e+00, avg batch time: 6.2660, average train loss: 0.4105
[11/16 18:02:54 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5797, average loss: 0.8181
[11/16 18:02:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 67.17	
[11/16 18:02:54 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.35959278669726935
[11/16 18:10:13 visual_prompt]: Epoch 43 / 100: avg data time: 4.83e+00, avg batch time: 6.2716, average train loss: 0.3656
[11/16 18:11:03 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5809, average loss: 0.8438
[11/16 18:11:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.54	rocauc: 69.46	
[11/16 18:11:03 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.3516841607689501
[11/16 18:18:20 visual_prompt]: Epoch 44 / 100: avg data time: 4.80e+00, avg batch time: 6.2427, average train loss: 0.5307
[11/16 18:19:10 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5801, average loss: 0.7134
[11/16 18:19:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 74.65	
[11/16 18:19:10 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.34365164835397805
[11/16 18:26:26 visual_prompt]: Epoch 45 / 100: avg data time: 4.78e+00, avg batch time: 6.2200, average train loss: 0.4474
[11/16 18:27:16 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5815, average loss: 0.9216
[11/16 18:27:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 72.13	
[11/16 18:27:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.3355050358314172
[11/16 18:34:31 visual_prompt]: Epoch 46 / 100: avg data time: 4.78e+00, avg batch time: 6.2244, average train loss: 0.3648
[11/16 18:35:21 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5855, average loss: 0.7875
[11/16 18:35:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.94	
[11/16 18:35:21 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.32725424859373686
[11/16 18:42:37 visual_prompt]: Epoch 47 / 100: avg data time: 4.78e+00, avg batch time: 6.2217, average train loss: 0.3626
[11/16 18:43:27 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5792, average loss: 0.9018
[11/16 18:43:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.84	
[11/16 18:43:27 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.3189093389542498
[11/16 18:50:41 visual_prompt]: Epoch 48 / 100: avg data time: 4.76e+00, avg batch time: 6.2056, average train loss: 0.3312
[11/16 18:51:31 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5833, average loss: 0.8962
[11/16 18:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.09	
[11/16 18:51:31 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.3104804738999169
[11/16 18:58:48 visual_prompt]: Epoch 49 / 100: avg data time: 4.79e+00, avg batch time: 6.2351, average train loss: 0.3418
[11/16 18:59:38 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5795, average loss: 1.0086
[11/16 18:59:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.90	
[11/16 18:59:38 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.3019779227044398
[11/16 19:06:53 visual_prompt]: Epoch 50 / 100: avg data time: 4.78e+00, avg batch time: 6.2204, average train loss: 0.3455
[11/16 19:07:43 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5832, average loss: 1.0704
[11/16 19:07:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.49	
[11/16 19:07:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.29341204441673263
[11/16 19:14:58 visual_prompt]: Epoch 51 / 100: avg data time: 4.77e+00, avg batch time: 6.2151, average train loss: 0.2895
[11/16 19:15:48 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5862, average loss: 1.0092
[11/16 19:15:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.07	
[11/16 19:15:48 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.28479327524001635
[11/16 19:23:04 visual_prompt]: Epoch 52 / 100: avg data time: 4.78e+00, avg batch time: 6.2248, average train loss: 0.2558
[11/16 19:23:54 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5854, average loss: 1.0656
[11/16 19:23:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.58	
[11/16 19:23:54 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.2761321158169134
[11/16 19:31:11 visual_prompt]: Epoch 53 / 100: avg data time: 4.80e+00, avg batch time: 6.2423, average train loss: 0.2840
[11/16 19:32:01 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5800, average loss: 1.2235
[11/16 19:32:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 64.79	
[11/16 19:32:01 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.2674391184360313
[11/16 19:39:16 visual_prompt]: Epoch 54 / 100: avg data time: 4.78e+00, avg batch time: 6.2204, average train loss: 0.2728
[11/16 19:40:06 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5877, average loss: 1.2895
[11/16 19:40:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 66.99	
[11/16 19:40:06 visual_prompt]: Stopping early.
[11/16 19:40:06 visual_prompt]: Rank of current process: 0. World size: 1
[11/16 19:40:06 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/16 19:40:06 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/16 19:40:06 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/16 19:40:06 visual_prompt]: Training with config:
[11/16 19:40:06 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/16 19:40:06 visual_prompt]: Loading training data...
[11/16 19:40:06 visual_prompt]: Constructing mammo-cbis dataset train...
[11/16 19:40:06 visual_prompt]: Loading validation data...
[11/16 19:40:06 visual_prompt]: Constructing mammo-cbis dataset val...
[11/16 19:40:06 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/16 19:40:09 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/16 19:40:09 visual_prompt]: tuned percent:0.532
[11/16 19:40:09 visual_prompt]: Device used for model: 0
[11/16 19:40:09 visual_prompt]: Setting up Evaluator...
[11/16 19:40:09 visual_prompt]: Setting up Trainer...
[11/16 19:40:09 visual_prompt]: 	Setting up the optimizer...
[11/16 19:40:09 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/16 19:47:26 visual_prompt]: Epoch 1 / 100: avg data time: 4.79e+00, avg batch time: 6.2348, average train loss: 1.4863
[11/16 19:48:16 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5792, average loss: 1.4553
[11/16 19:48:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/16 19:48:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/16 19:55:31 visual_prompt]: Epoch 2 / 100: avg data time: 4.78e+00, avg batch time: 6.2175, average train loss: 0.9713
[11/16 19:56:21 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5835, average loss: 0.7147
[11/16 19:56:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.04	
[11/16 19:56:21 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/16 20:03:36 visual_prompt]: Epoch 3 / 100: avg data time: 4.77e+00, avg batch time: 6.2116, average train loss: 0.7077
[11/16 20:04:25 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5833, average loss: 0.7279
[11/16 20:04:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.31	
[11/16 20:04:25 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/16 20:11:39 visual_prompt]: Epoch 4 / 100: avg data time: 4.76e+00, avg batch time: 6.1997, average train loss: 0.7346
[11/16 20:12:29 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5817, average loss: 0.7681
[11/16 20:12:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.08	
[11/16 20:12:29 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/16 20:19:44 visual_prompt]: Epoch 5 / 100: avg data time: 4.77e+00, avg batch time: 6.2126, average train loss: 0.7304
[11/16 20:20:34 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5833, average loss: 0.7125
[11/16 20:20:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.44	
[11/16 20:20:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/16 20:27:49 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e+00, avg batch time: 6.2204, average train loss: 0.7356
[11/16 20:28:39 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5850, average loss: 0.7261
[11/16 20:28:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.04	
[11/16 20:28:39 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/16 20:35:55 visual_prompt]: Epoch 7 / 100: avg data time: 4.78e+00, avg batch time: 6.2176, average train loss: 0.7236
[11/16 20:36:44 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5846, average loss: 0.6945
[11/16 20:36:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[11/16 20:36:44 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/16 20:44:00 visual_prompt]: Epoch 8 / 100: avg data time: 4.78e+00, avg batch time: 6.2182, average train loss: 0.7090
[11/16 20:44:49 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5815, average loss: 0.6984
[11/16 20:44:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.53	
[11/16 20:44:49 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/16 20:52:04 visual_prompt]: Epoch 9 / 100: avg data time: 4.77e+00, avg batch time: 6.2115, average train loss: 0.7234
[11/16 20:52:54 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5789, average loss: 0.7273
[11/16 20:52:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.54	
[11/16 20:52:54 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/16 21:00:08 visual_prompt]: Epoch 10 / 100: avg data time: 4.76e+00, avg batch time: 6.1972, average train loss: 0.7094
[11/16 21:00:58 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5786, average loss: 0.6893
[11/16 21:00:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.66	
[11/16 21:00:58 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/16 21:08:13 visual_prompt]: Epoch 11 / 100: avg data time: 4.78e+00, avg batch time: 6.2213, average train loss: 0.7365
[11/16 21:09:03 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5788, average loss: 1.6830
[11/16 21:09:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 47.81	
[11/16 21:09:03 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/16 21:16:18 visual_prompt]: Epoch 12 / 100: avg data time: 4.77e+00, avg batch time: 6.2091, average train loss: 0.8243
[11/16 21:17:07 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5807, average loss: 0.7700
[11/16 21:17:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.65	
[11/16 21:17:07 visual_prompt]: Best epoch 12: best metric: -0.770
[11/16 21:17:07 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/16 21:24:22 visual_prompt]: Epoch 13 / 100: avg data time: 4.77e+00, avg batch time: 6.2075, average train loss: 0.7388
[11/16 21:25:12 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5840, average loss: 0.7423
[11/16 21:25:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 55.05	
[11/16 21:25:12 visual_prompt]: Best epoch 13: best metric: -0.742
[11/16 21:25:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/16 21:32:26 visual_prompt]: Epoch 14 / 100: avg data time: 4.76e+00, avg batch time: 6.1989, average train loss: 0.7283
[11/16 21:33:16 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5815, average loss: 0.6983
[11/16 21:33:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.01	
[11/16 21:33:16 visual_prompt]: Best epoch 14: best metric: -0.698
[11/16 21:33:16 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/16 21:40:29 visual_prompt]: Epoch 15 / 100: avg data time: 4.74e+00, avg batch time: 6.1813, average train loss: 0.7070
[11/16 21:41:18 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5844, average loss: 0.7123
[11/16 21:41:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 48.66	
[11/16 21:41:18 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/16 21:48:32 visual_prompt]: Epoch 16 / 100: avg data time: 4.75e+00, avg batch time: 6.1885, average train loss: 0.7516
[11/16 21:49:21 visual_prompt]: Inference (val):avg data time: 3.68e-05, avg batch time: 0.5799, average loss: 0.8885
[11/16 21:49:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.15	
[11/16 21:49:22 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/16 21:56:36 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e+00, avg batch time: 6.2024, average train loss: 0.7496
[11/16 21:57:25 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5851, average loss: 0.7649
[11/16 21:57:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.67	
[11/16 21:57:25 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/16 22:04:39 visual_prompt]: Epoch 18 / 100: avg data time: 4.76e+00, avg batch time: 6.1975, average train loss: 0.7239
[11/16 22:05:29 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5784, average loss: 0.8876
[11/16 22:05:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.50	
[11/16 22:05:29 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/16 22:12:42 visual_prompt]: Epoch 19 / 100: avg data time: 4.75e+00, avg batch time: 6.1891, average train loss: 0.7588
[11/16 22:13:32 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5818, average loss: 0.9257
[11/16 22:13:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.64	
[11/16 22:13:32 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/16 22:20:47 visual_prompt]: Epoch 20 / 100: avg data time: 4.78e+00, avg batch time: 6.2180, average train loss: 0.7332
[11/16 22:21:37 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5837, average loss: 0.6889
[11/16 22:21:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.95	
[11/16 22:21:37 visual_prompt]: Best epoch 20: best metric: -0.689
[11/16 22:21:37 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/16 22:28:52 visual_prompt]: Epoch 21 / 100: avg data time: 4.76e+00, avg batch time: 6.2051, average train loss: 0.7300
[11/16 22:29:41 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5813, average loss: 0.7571
[11/16 22:29:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.96	
[11/16 22:29:41 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/16 22:36:56 visual_prompt]: Epoch 22 / 100: avg data time: 4.77e+00, avg batch time: 6.2129, average train loss: 0.7172
[11/16 22:37:47 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5855, average loss: 0.6923
[11/16 22:37:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.01	
[11/16 22:37:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/16 22:45:23 visual_prompt]: Epoch 23 / 100: avg data time: 5.07e+00, avg batch time: 6.5170, average train loss: 0.7126
[11/16 22:46:16 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5847, average loss: 0.8270
[11/16 22:46:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.00	
[11/16 22:46:16 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/16 22:53:31 visual_prompt]: Epoch 24 / 100: avg data time: 4.76e+00, avg batch time: 6.2114, average train loss: 0.7236
[11/16 22:54:20 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5864, average loss: 0.6880
[11/16 22:54:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.68	
[11/16 22:54:20 visual_prompt]: Best epoch 24: best metric: -0.688
[11/16 22:54:20 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/16 23:01:38 visual_prompt]: Epoch 25 / 100: avg data time: 4.80e+00, avg batch time: 6.2531, average train loss: 0.7185
[11/16 23:02:29 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5964, average loss: 0.7078
[11/16 23:02:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.93	
[11/16 23:02:29 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/16 23:09:49 visual_prompt]: Epoch 26 / 100: avg data time: 4.83e+00, avg batch time: 6.2851, average train loss: 0.7332
[11/16 23:10:39 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5875, average loss: 0.7030
[11/16 23:10:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.86	
[11/16 23:10:39 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/16 23:17:53 visual_prompt]: Epoch 27 / 100: avg data time: 4.75e+00, avg batch time: 6.2024, average train loss: 0.7164
[11/16 23:18:42 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5888, average loss: 0.7465
[11/16 23:18:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.03	
[11/16 23:18:42 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/16 23:25:57 visual_prompt]: Epoch 28 / 100: avg data time: 4.74e+00, avg batch time: 6.2030, average train loss: 0.7176
[11/16 23:26:47 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5895, average loss: 0.7000
[11/16 23:26:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.23	
[11/16 23:26:47 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/16 23:34:00 visual_prompt]: Epoch 29 / 100: avg data time: 4.73e+00, avg batch time: 6.1845, average train loss: 0.7115
[11/16 23:34:49 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5867, average loss: 0.7236
[11/16 23:34:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.00	
[11/16 23:34:49 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/16 23:42:04 visual_prompt]: Epoch 30 / 100: avg data time: 4.76e+00, avg batch time: 6.2110, average train loss: 0.7374
[11/16 23:42:53 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5863, average loss: 0.7976
[11/16 23:42:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.02	
[11/16 23:42:53 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/16 23:50:06 visual_prompt]: Epoch 31 / 100: avg data time: 4.72e+00, avg batch time: 6.1737, average train loss: 0.7095
[11/16 23:50:55 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5865, average loss: 0.7002
[11/16 23:50:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[11/16 23:50:55 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/16 23:58:09 visual_prompt]: Epoch 32 / 100: avg data time: 4.73e+00, avg batch time: 6.1909, average train loss: 0.7094
[11/16 23:58:58 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5871, average loss: 0.6956
[11/16 23:58:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.12	
[11/16 23:58:58 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/17 00:06:12 visual_prompt]: Epoch 33 / 100: avg data time: 4.75e+00, avg batch time: 6.1989, average train loss: 0.7092
[11/17 00:07:02 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5868, average loss: 0.6954
[11/17 00:07:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.81	
[11/17 00:07:02 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/17 00:14:14 visual_prompt]: Epoch 34 / 100: avg data time: 4.71e+00, avg batch time: 6.1711, average train loss: 0.7079
[11/17 00:15:04 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5842, average loss: 0.7223
[11/17 00:15:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 45.37	
[11/17 00:15:04 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/17 00:22:16 visual_prompt]: Epoch 35 / 100: avg data time: 4.72e+00, avg batch time: 6.1792, average train loss: 0.7151
[11/17 00:23:06 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5914, average loss: 0.7002
[11/17 00:23:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.15	
[11/17 00:23:06 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/17 00:30:20 visual_prompt]: Epoch 36 / 100: avg data time: 4.74e+00, avg batch time: 6.1937, average train loss: 0.7300
[11/17 00:31:09 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5867, average loss: 0.6908
[11/17 00:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.08	
[11/17 00:31:09 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/17 00:38:22 visual_prompt]: Epoch 37 / 100: avg data time: 4.72e+00, avg batch time: 6.1786, average train loss: 0.7034
[11/17 00:39:11 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5859, average loss: 0.7173
[11/17 00:39:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.52	
[11/17 00:39:11 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/17 00:46:24 visual_prompt]: Epoch 38 / 100: avg data time: 4.73e+00, avg batch time: 6.1879, average train loss: 0.6983
[11/17 00:47:13 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5869, average loss: 0.6937
[11/17 00:47:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.59	
[11/17 00:47:13 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/17 00:54:26 visual_prompt]: Epoch 39 / 100: avg data time: 4.71e+00, avg batch time: 6.1717, average train loss: 0.7262
[11/17 00:55:15 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5866, average loss: 0.6917
[11/17 00:55:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.28	
[11/17 00:55:15 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/17 01:02:31 visual_prompt]: Epoch 40 / 100: avg data time: 4.79e+00, avg batch time: 6.2290, average train loss: 0.7181
[11/17 01:03:21 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5827, average loss: 0.7256
[11/17 01:03:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.71	
[11/17 01:03:21 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/17 01:10:37 visual_prompt]: Epoch 41 / 100: avg data time: 4.78e+00, avg batch time: 6.2198, average train loss: 0.7110
[11/17 01:11:27 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5799, average loss: 0.7952
[11/17 01:11:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.52	
[11/17 01:11:27 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/17 01:18:42 visual_prompt]: Epoch 42 / 100: avg data time: 4.77e+00, avg batch time: 6.2120, average train loss: 0.7237
[11/17 01:19:32 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5799, average loss: 0.6888
[11/17 01:19:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 45.37	
[11/17 01:19:32 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/17 01:26:48 visual_prompt]: Epoch 43 / 100: avg data time: 4.79e+00, avg batch time: 6.2279, average train loss: 0.7307
[11/17 01:27:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5818, average loss: 0.6896
[11/17 01:27:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 48.58	
[11/17 01:27:37 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/17 01:34:54 visual_prompt]: Epoch 44 / 100: avg data time: 4.80e+00, avg batch time: 6.2397, average train loss: 0.7098
[11/17 01:35:44 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5873, average loss: 0.6942
[11/17 01:35:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 53.92	
[11/17 01:35:44 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/17 01:43:00 visual_prompt]: Epoch 45 / 100: avg data time: 4.79e+00, avg batch time: 6.2273, average train loss: 0.7133
[11/17 01:43:50 visual_prompt]: Inference (val):avg data time: 3.89e-05, avg batch time: 0.5806, average loss: 0.7370
[11/17 01:43:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 37.89	
[11/17 01:43:50 visual_prompt]: Stopping early.
[11/17 01:43:50 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 01:43:50 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 01:43:50 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 01:43:50 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 01:43:50 visual_prompt]: Training with config:
[11/17 01:43:50 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 01:43:50 visual_prompt]: Loading training data...
[11/17 01:43:50 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 01:43:50 visual_prompt]: Loading validation data...
[11/17 01:43:50 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 01:43:50 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 01:43:56 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 01:43:56 visual_prompt]: tuned percent:0.532
[11/17 01:43:56 visual_prompt]: Device used for model: 0
[11/17 01:43:56 visual_prompt]: Setting up Evaluator...
[11/17 01:43:56 visual_prompt]: Setting up Trainer...
[11/17 01:43:56 visual_prompt]: 	Setting up the optimizer...
[11/17 01:43:56 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 01:51:12 visual_prompt]: Epoch 1 / 100: avg data time: 4.78e+00, avg batch time: 6.2256, average train loss: 1.4863
[11/17 01:52:02 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5836, average loss: 1.4553
[11/17 01:52:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 01:52:02 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/17 01:59:17 visual_prompt]: Epoch 2 / 100: avg data time: 4.77e+00, avg batch time: 6.2127, average train loss: 0.9787
[11/17 02:00:06 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5846, average loss: 0.7197
[11/17 02:00:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.26	
[11/17 02:00:06 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/17 02:07:20 visual_prompt]: Epoch 3 / 100: avg data time: 4.76e+00, avg batch time: 6.2012, average train loss: 0.7152
[11/17 02:08:10 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5812, average loss: 0.7403
[11/17 02:08:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.92	
[11/17 02:08:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/17 02:15:25 visual_prompt]: Epoch 4 / 100: avg data time: 4.77e+00, avg batch time: 6.2050, average train loss: 0.7463
[11/17 02:16:14 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5821, average loss: 0.8057
[11/17 02:16:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.20	
[11/17 02:16:14 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/17 02:23:29 visual_prompt]: Epoch 5 / 100: avg data time: 4.77e+00, avg batch time: 6.2079, average train loss: 0.7599
[11/17 02:24:19 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5821, average loss: 0.7011
[11/17 02:24:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.33	
[11/17 02:24:19 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/17 02:31:35 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e+00, avg batch time: 6.2259, average train loss: 0.7519
[11/17 02:32:25 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5809, average loss: 0.6936
[11/17 02:32:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.84	
[11/17 02:32:25 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/17 02:39:39 visual_prompt]: Epoch 7 / 100: avg data time: 4.76e+00, avg batch time: 6.2042, average train loss: 0.7046
[11/17 02:40:29 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5851, average loss: 1.2620
[11/17 02:40:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.61	
[11/17 02:40:29 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/17 02:47:44 visual_prompt]: Epoch 8 / 100: avg data time: 4.77e+00, avg batch time: 6.2137, average train loss: 0.7436
[11/17 02:48:34 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5787, average loss: 0.8723
[11/17 02:48:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.27	
[11/17 02:48:34 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/17 02:55:49 visual_prompt]: Epoch 9 / 100: avg data time: 4.77e+00, avg batch time: 6.2081, average train loss: 0.8027
[11/17 02:56:39 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5805, average loss: 0.7010
[11/17 02:56:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.93	
[11/17 02:56:39 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/17 03:03:53 visual_prompt]: Epoch 10 / 100: avg data time: 4.77e+00, avg batch time: 6.2088, average train loss: 0.6891
[11/17 03:04:43 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5858, average loss: 0.6902
[11/17 03:04:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.57	
[11/17 03:04:43 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/17 03:11:58 visual_prompt]: Epoch 11 / 100: avg data time: 4.76e+00, avg batch time: 6.2063, average train loss: 0.7356
[11/17 03:12:47 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5814, average loss: 0.9048
[11/17 03:12:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.27	
[11/17 03:12:47 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/17 03:20:02 visual_prompt]: Epoch 12 / 100: avg data time: 4.77e+00, avg batch time: 6.2082, average train loss: 0.7116
[11/17 03:20:52 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5827, average loss: 0.7177
[11/17 03:20:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 62.19	
[11/17 03:20:52 visual_prompt]: Best epoch 12: best metric: -0.718
[11/17 03:20:52 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/17 03:28:08 visual_prompt]: Epoch 13 / 100: avg data time: 4.78e+00, avg batch time: 6.2214, average train loss: 0.7795
[11/17 03:28:57 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5838, average loss: 0.7248
[11/17 03:28:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 62.76	
[11/17 03:28:57 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/17 03:36:12 visual_prompt]: Epoch 14 / 100: avg data time: 4.76e+00, avg batch time: 6.1999, average train loss: 0.7045
[11/17 03:37:01 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5807, average loss: 0.7934
[11/17 03:37:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 64.19	
[11/17 03:37:01 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/17 03:44:14 visual_prompt]: Epoch 15 / 100: avg data time: 4.74e+00, avg batch time: 6.1852, average train loss: 0.7067
[11/17 03:45:04 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5812, average loss: 0.6787
[11/17 03:45:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.64	
[11/17 03:45:04 visual_prompt]: Best epoch 15: best metric: -0.679
[11/17 03:45:04 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/17 03:52:19 visual_prompt]: Epoch 16 / 100: avg data time: 4.76e+00, avg batch time: 6.2039, average train loss: 0.6990
[11/17 03:53:08 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5846, average loss: 0.8309
[11/17 03:53:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.56	
[11/17 03:53:08 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/17 04:00:22 visual_prompt]: Epoch 17 / 100: avg data time: 4.75e+00, avg batch time: 6.1954, average train loss: 0.7265
[11/17 04:01:12 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5799, average loss: 0.6797
[11/17 04:01:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.64	
[11/17 04:01:12 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/17 04:08:26 visual_prompt]: Epoch 18 / 100: avg data time: 4.76e+00, avg batch time: 6.2020, average train loss: 0.7005
[11/17 04:09:16 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5811, average loss: 0.8577
[11/17 04:09:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[11/17 04:09:16 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/17 04:16:30 visual_prompt]: Epoch 19 / 100: avg data time: 4.76e+00, avg batch time: 6.2005, average train loss: 0.7024
[11/17 04:17:19 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5794, average loss: 0.8868
[11/17 04:17:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.23	
[11/17 04:17:20 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/17 04:24:35 visual_prompt]: Epoch 20 / 100: avg data time: 4.78e+00, avg batch time: 6.2164, average train loss: 0.6821
[11/17 04:25:25 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5851, average loss: 0.6721
[11/17 04:25:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 66.12	
[11/17 04:25:25 visual_prompt]: Best epoch 20: best metric: -0.672
[11/17 04:25:25 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/17 04:32:39 visual_prompt]: Epoch 21 / 100: avg data time: 4.76e+00, avg batch time: 6.1995, average train loss: 0.6701
[11/17 04:33:29 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5844, average loss: 0.6847
[11/17 04:33:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.76	
[11/17 04:33:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/17 04:40:44 visual_prompt]: Epoch 22 / 100: avg data time: 4.77e+00, avg batch time: 6.2138, average train loss: 0.7164
[11/17 04:41:34 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5828, average loss: 0.6723
[11/17 04:41:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 63.43	
[11/17 04:41:34 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/17 04:48:49 visual_prompt]: Epoch 23 / 100: avg data time: 4.78e+00, avg batch time: 6.2183, average train loss: 0.6818
[11/17 04:49:39 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5819, average loss: 0.6745
[11/17 04:49:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.96	
[11/17 04:49:39 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/17 04:56:52 visual_prompt]: Epoch 24 / 100: avg data time: 4.75e+00, avg batch time: 6.1903, average train loss: 0.6996
[11/17 04:57:42 visual_prompt]: Inference (val):avg data time: 3.65e-05, avg batch time: 0.5856, average loss: 0.6857
[11/17 04:57:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 58.95	
[11/17 04:57:42 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/17 05:04:58 visual_prompt]: Epoch 25 / 100: avg data time: 4.78e+00, avg batch time: 6.2198, average train loss: 0.6996
[11/17 05:05:47 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5836, average loss: 0.6993
[11/17 05:05:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.18	
[11/17 05:05:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/17 05:13:00 visual_prompt]: Epoch 26 / 100: avg data time: 4.74e+00, avg batch time: 6.1854, average train loss: 0.7013
[11/17 05:13:50 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5796, average loss: 0.6865
[11/17 05:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.57	
[11/17 05:13:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/17 05:21:03 visual_prompt]: Epoch 27 / 100: avg data time: 4.75e+00, avg batch time: 6.1861, average train loss: 0.6826
[11/17 05:21:53 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5797, average loss: 0.6718
[11/17 05:21:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 62.49	
[11/17 05:21:53 visual_prompt]: Best epoch 27: best metric: -0.672
[11/17 05:21:53 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/17 05:29:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.75e+00, avg batch time: 6.1950, average train loss: 0.7039
[11/17 05:29:56 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5815, average loss: 0.6836
[11/17 05:29:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 64.31	
[11/17 05:29:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/17 05:37:10 visual_prompt]: Epoch 29 / 100: avg data time: 4.76e+00, avg batch time: 6.1985, average train loss: 0.6924
[11/17 05:38:00 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5827, average loss: 0.7310
[11/17 05:38:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.40	
[11/17 05:38:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/17 05:45:15 visual_prompt]: Epoch 30 / 100: avg data time: 4.76e+00, avg batch time: 6.2017, average train loss: 0.7119
[11/17 05:46:04 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5778, average loss: 0.7704
[11/17 05:46:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 44.72	rocauc: 65.69	
[11/17 05:46:04 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/17 05:53:17 visual_prompt]: Epoch 31 / 100: avg data time: 4.74e+00, avg batch time: 6.1764, average train loss: 0.6892
[11/17 05:54:07 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5825, average loss: 0.6581
[11/17 05:54:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.57	
[11/17 05:54:07 visual_prompt]: Best epoch 31: best metric: -0.658
[11/17 05:54:07 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/17 06:01:20 visual_prompt]: Epoch 32 / 100: avg data time: 4.75e+00, avg batch time: 6.1939, average train loss: 0.6905
[11/17 06:02:10 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5846, average loss: 0.6783
[11/17 06:02:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.53	
[11/17 06:02:10 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/17 06:09:24 visual_prompt]: Epoch 33 / 100: avg data time: 4.77e+00, avg batch time: 6.2066, average train loss: 0.6884
[11/17 06:10:14 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5791, average loss: 0.7002
[11/17 06:10:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.79	
[11/17 06:10:14 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/17 06:17:28 visual_prompt]: Epoch 34 / 100: avg data time: 4.75e+00, avg batch time: 6.1917, average train loss: 0.6877
[11/17 06:18:18 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5793, average loss: 0.7005
[11/17 06:18:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.91	
[11/17 06:18:18 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/17 06:25:31 visual_prompt]: Epoch 35 / 100: avg data time: 4.75e+00, avg batch time: 6.1925, average train loss: 0.7012
[11/17 06:26:21 visual_prompt]: Inference (val):avg data time: 4.13e-05, avg batch time: 0.5869, average loss: 0.7992
[11/17 06:26:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.87	
[11/17 06:26:21 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/17 06:33:36 visual_prompt]: Epoch 36 / 100: avg data time: 4.76e+00, avg batch time: 6.2070, average train loss: 0.7084
[11/17 06:34:25 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5810, average loss: 0.6597
[11/17 06:34:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.41	
[11/17 06:34:26 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/17 06:41:39 visual_prompt]: Epoch 37 / 100: avg data time: 4.76e+00, avg batch time: 6.1967, average train loss: 0.6951
[11/17 06:42:29 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5807, average loss: 0.6763
[11/17 06:42:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.55	
[11/17 06:42:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/17 06:49:43 visual_prompt]: Epoch 38 / 100: avg data time: 4.75e+00, avg batch time: 6.1981, average train loss: 0.6856
[11/17 06:50:33 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5831, average loss: 0.6744
[11/17 06:50:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.77	
[11/17 06:50:33 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/17 06:57:46 visual_prompt]: Epoch 39 / 100: avg data time: 4.75e+00, avg batch time: 6.1930, average train loss: 0.6952
[11/17 06:58:36 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5828, average loss: 0.7184
[11/17 06:58:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.60	
[11/17 06:58:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/17 07:05:50 visual_prompt]: Epoch 40 / 100: avg data time: 4.75e+00, avg batch time: 6.1938, average train loss: 0.7074
[11/17 07:06:40 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5829, average loss: 0.7180
[11/17 07:06:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 65.84	
[11/17 07:06:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/17 07:13:53 visual_prompt]: Epoch 41 / 100: avg data time: 4.74e+00, avg batch time: 6.1856, average train loss: 0.7145
[11/17 07:14:43 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5796, average loss: 0.8335
[11/17 07:14:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.42	
[11/17 07:14:43 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/17 07:21:56 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e+00, avg batch time: 6.1905, average train loss: 0.6988
[11/17 07:22:46 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5830, average loss: 0.6622
[11/17 07:22:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 65.68	
[11/17 07:22:46 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/17 07:30:00 visual_prompt]: Epoch 43 / 100: avg data time: 4.76e+00, avg batch time: 6.2013, average train loss: 0.7157
[11/17 07:30:50 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5824, average loss: 0.7004
[11/17 07:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.63	
[11/17 07:30:50 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/17 07:38:05 visual_prompt]: Epoch 44 / 100: avg data time: 4.78e+00, avg batch time: 6.2230, average train loss: 0.7020
[11/17 07:38:55 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5823, average loss: 0.6900
[11/17 07:38:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.10	
[11/17 07:38:55 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/17 07:46:09 visual_prompt]: Epoch 45 / 100: avg data time: 4.76e+00, avg batch time: 6.2001, average train loss: 0.6992
[11/17 07:46:59 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5832, average loss: 0.7374
[11/17 07:46:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.72	
[11/17 07:46:59 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/17 07:54:13 visual_prompt]: Epoch 46 / 100: avg data time: 4.75e+00, avg batch time: 6.1907, average train loss: 0.7064
[11/17 07:55:02 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5797, average loss: 0.6984
[11/17 07:55:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.66	
[11/17 07:55:02 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.16362712429686843
[11/17 08:02:16 visual_prompt]: Epoch 47 / 100: avg data time: 4.75e+00, avg batch time: 6.1969, average train loss: 0.6976
[11/17 08:03:06 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5827, average loss: 0.7159
[11/17 08:03:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.75	
[11/17 08:03:06 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.1594546694771249
[11/17 08:10:19 visual_prompt]: Epoch 48 / 100: avg data time: 4.75e+00, avg batch time: 6.1917, average train loss: 0.6983
[11/17 08:11:09 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5820, average loss: 0.7039
[11/17 08:11:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.98	
[11/17 08:11:09 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.15524023694995845
[11/17 08:18:23 visual_prompt]: Epoch 49 / 100: avg data time: 4.76e+00, avg batch time: 6.1982, average train loss: 0.6992
[11/17 08:19:13 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5821, average loss: 0.6877
[11/17 08:19:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.16	
[11/17 08:19:13 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.1509889613522199
[11/17 08:26:27 visual_prompt]: Epoch 50 / 100: avg data time: 4.76e+00, avg batch time: 6.1986, average train loss: 0.7008
[11/17 08:27:17 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5821, average loss: 0.8691
[11/17 08:27:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.94	
[11/17 08:27:17 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.14670602220836632
[11/17 08:34:30 visual_prompt]: Epoch 51 / 100: avg data time: 4.75e+00, avg batch time: 6.1904, average train loss: 0.7152
[11/17 08:35:20 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5822, average loss: 0.7722
[11/17 08:35:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.80	
[11/17 08:35:20 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.14239663762000818
[11/17 08:42:35 visual_prompt]: Epoch 52 / 100: avg data time: 4.77e+00, avg batch time: 6.2123, average train loss: 0.6983
[11/17 08:43:25 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5843, average loss: 0.7585
[11/17 08:43:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 61.21	
[11/17 08:43:25 visual_prompt]: Stopping early.
[11/17 08:43:25 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 08:43:25 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 08:43:25 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 08:43:25 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 08:43:25 visual_prompt]: Training with config:
[11/17 08:43:25 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 08:43:25 visual_prompt]: Loading training data...
[11/17 08:43:25 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 08:43:25 visual_prompt]: Loading validation data...
[11/17 08:43:25 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 08:43:25 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 08:43:27 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 08:43:27 visual_prompt]: tuned percent:0.532
[11/17 08:43:27 visual_prompt]: Device used for model: 0
[11/17 08:43:27 visual_prompt]: Setting up Evaluator...
[11/17 08:43:27 visual_prompt]: Setting up Trainer...
[11/17 08:43:27 visual_prompt]: 	Setting up the optimizer...
[11/17 08:43:27 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 08:50:42 visual_prompt]: Epoch 1 / 100: avg data time: 4.76e+00, avg batch time: 6.2054, average train loss: 1.4863
[11/17 08:51:31 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5871, average loss: 1.4553
[11/17 08:51:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 08:51:31 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/17 08:58:45 visual_prompt]: Epoch 2 / 100: avg data time: 4.75e+00, avg batch time: 6.1900, average train loss: 0.9796
[11/17 08:59:34 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5785, average loss: 0.7201
[11/17 08:59:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.32	
[11/17 08:59:34 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/17 09:06:50 visual_prompt]: Epoch 3 / 100: avg data time: 4.77e+00, avg batch time: 6.2144, average train loss: 0.7161
[11/17 09:07:40 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5808, average loss: 0.7424
[11/17 09:07:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.72	
[11/17 09:07:40 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/17 09:14:53 visual_prompt]: Epoch 4 / 100: avg data time: 4.74e+00, avg batch time: 6.1785, average train loss: 0.7472
[11/17 09:15:42 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5834, average loss: 0.7975
[11/17 09:15:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[11/17 09:15:42 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/17 09:22:54 visual_prompt]: Epoch 5 / 100: avg data time: 4.73e+00, avg batch time: 6.1768, average train loss: 0.7629
[11/17 09:23:44 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5840, average loss: 0.7072
[11/17 09:23:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.71	
[11/17 09:23:44 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/17 09:30:58 visual_prompt]: Epoch 6 / 100: avg data time: 4.76e+00, avg batch time: 6.2037, average train loss: 0.7481
[11/17 09:31:48 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5846, average loss: 0.6844
[11/17 09:31:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.57	
[11/17 09:31:48 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/17 09:39:01 visual_prompt]: Epoch 7 / 100: avg data time: 4.75e+00, avg batch time: 6.1884, average train loss: 0.7037
[11/17 09:39:51 visual_prompt]: Inference (val):avg data time: 3.99e-05, avg batch time: 0.5790, average loss: 1.2721
[11/17 09:39:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.71	
[11/17 09:39:51 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/17 09:47:06 visual_prompt]: Epoch 8 / 100: avg data time: 4.77e+00, avg batch time: 6.2130, average train loss: 0.7266
[11/17 09:47:56 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5823, average loss: 1.0836
[11/17 09:47:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[11/17 09:47:56 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/17 09:55:10 visual_prompt]: Epoch 9 / 100: avg data time: 4.76e+00, avg batch time: 6.1992, average train loss: 0.8072
[11/17 09:55:59 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5804, average loss: 0.6764
[11/17 09:55:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.50	
[11/17 09:55:59 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/17 10:03:14 visual_prompt]: Epoch 10 / 100: avg data time: 4.76e+00, avg batch time: 6.2033, average train loss: 0.6825
[11/17 10:04:03 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5839, average loss: 0.6855
[11/17 10:04:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 62.88	
[11/17 10:04:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/17 10:11:18 visual_prompt]: Epoch 11 / 100: avg data time: 4.77e+00, avg batch time: 6.2092, average train loss: 0.7438
[11/17 10:12:08 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5804, average loss: 0.8196
[11/17 10:12:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.03	
[11/17 10:12:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/17 10:19:21 visual_prompt]: Epoch 12 / 100: avg data time: 4.74e+00, avg batch time: 6.1846, average train loss: 0.7379
[11/17 10:20:10 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5826, average loss: 0.7108
[11/17 10:20:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 65.13	
[11/17 10:20:10 visual_prompt]: Best epoch 12: best metric: -0.711
[11/17 10:20:10 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/17 10:27:39 visual_prompt]: Epoch 13 / 100: avg data time: 4.96e+00, avg batch time: 6.4044, average train loss: 0.7528
[11/17 10:28:31 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5803, average loss: 0.6814
[11/17 10:28:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 66.50	
[11/17 10:28:31 visual_prompt]: Best epoch 13: best metric: -0.681
[11/17 10:28:31 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/17 10:36:05 visual_prompt]: Epoch 14 / 100: avg data time: 5.03e+00, avg batch time: 6.4903, average train loss: 0.7016
[11/17 10:36:56 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5983, average loss: 0.7179
[11/17 10:36:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.00	rocauc: 67.36	
[11/17 10:36:56 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/17 10:44:18 visual_prompt]: Epoch 15 / 100: avg data time: 4.85e+00, avg batch time: 6.3102, average train loss: 0.7037
[11/17 10:45:08 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5922, average loss: 0.6512
[11/17 10:45:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.06	
[11/17 10:45:08 visual_prompt]: Best epoch 15: best metric: -0.651
[11/17 10:45:08 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/17 10:52:23 visual_prompt]: Epoch 16 / 100: avg data time: 4.76e+00, avg batch time: 6.2100, average train loss: 0.6772
[11/17 10:53:12 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5884, average loss: 0.6825
[11/17 10:53:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 68.43	
[11/17 10:53:12 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/17 11:00:27 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e+00, avg batch time: 6.2106, average train loss: 0.7071
[11/17 11:01:17 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5873, average loss: 0.7372
[11/17 11:01:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.35	
[11/17 11:01:17 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/17 11:08:30 visual_prompt]: Epoch 18 / 100: avg data time: 4.73e+00, avg batch time: 6.1842, average train loss: 0.6589
[11/17 11:09:19 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5822, average loss: 0.8665
[11/17 11:09:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 67.24	
[11/17 11:09:19 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/17 11:16:33 visual_prompt]: Epoch 19 / 100: avg data time: 4.74e+00, avg batch time: 6.1845, average train loss: 0.6976
[11/17 11:17:22 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5855, average loss: 0.7330
[11/17 11:17:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.00	
[11/17 11:17:22 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/17 11:24:36 visual_prompt]: Epoch 20 / 100: avg data time: 4.75e+00, avg batch time: 6.1991, average train loss: 0.6483
[11/17 11:25:26 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5857, average loss: 0.6675
[11/17 11:25:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.89	
[11/17 11:25:26 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/17 11:32:41 visual_prompt]: Epoch 21 / 100: avg data time: 4.76e+00, avg batch time: 6.2103, average train loss: 0.6479
[11/17 11:33:35 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5860, average loss: 0.6294
[11/17 11:33:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.52	
[11/17 11:33:35 visual_prompt]: Best epoch 21: best metric: -0.629
[11/17 11:33:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/17 11:40:48 visual_prompt]: Epoch 22 / 100: avg data time: 4.72e+00, avg batch time: 6.1739, average train loss: 0.6924
[11/17 11:41:37 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5844, average loss: 0.7633
[11/17 11:41:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 70.28	
[11/17 11:41:37 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/17 11:48:52 visual_prompt]: Epoch 23 / 100: avg data time: 4.75e+00, avg batch time: 6.2081, average train loss: 0.6249
[11/17 11:49:41 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5895, average loss: 0.6565
[11/17 11:49:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.39	
[11/17 11:49:41 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/17 11:56:54 visual_prompt]: Epoch 24 / 100: avg data time: 4.73e+00, avg batch time: 6.1871, average train loss: 0.6188
[11/17 11:57:44 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5875, average loss: 0.6495
[11/17 11:57:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 70.65	
[11/17 11:57:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/17 12:04:58 visual_prompt]: Epoch 25 / 100: avg data time: 4.74e+00, avg batch time: 6.1938, average train loss: 0.6241
[11/17 12:05:47 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5870, average loss: 0.6280
[11/17 12:05:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.39	
[11/17 12:05:47 visual_prompt]: Best epoch 25: best metric: -0.628
[11/17 12:05:47 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/17 12:13:00 visual_prompt]: Epoch 26 / 100: avg data time: 4.73e+00, avg batch time: 6.1846, average train loss: 0.6357
[11/17 12:13:50 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5839, average loss: 0.7313
[11/17 12:13:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.71	
[11/17 12:13:50 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/17 12:21:03 visual_prompt]: Epoch 27 / 100: avg data time: 4.73e+00, avg batch time: 6.1818, average train loss: 0.6302
[11/17 12:21:52 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5873, average loss: 0.6566
[11/17 12:21:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.82	
[11/17 12:21:52 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/17 12:29:07 visual_prompt]: Epoch 28 / 100: avg data time: 4.75e+00, avg batch time: 6.2027, average train loss: 0.6583
[11/17 12:29:56 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5824, average loss: 0.6500
[11/17 12:29:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.31	
[11/17 12:29:56 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/17 12:37:08 visual_prompt]: Epoch 29 / 100: avg data time: 4.72e+00, avg batch time: 6.1742, average train loss: 0.5901
[11/17 12:37:57 visual_prompt]: Inference (val):avg data time: 3.64e-05, avg batch time: 0.5859, average loss: 0.8336
[11/17 12:37:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 70.95	
[11/17 12:37:57 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/17 12:45:11 visual_prompt]: Epoch 30 / 100: avg data time: 4.74e+00, avg batch time: 6.1919, average train loss: 0.6291
[11/17 12:46:00 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5887, average loss: 0.7306
[11/17 12:46:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 73.39	
[11/17 12:46:00 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/17 12:53:10 visual_prompt]: Epoch 31 / 100: avg data time: 4.67e+00, avg batch time: 6.1375, average train loss: 0.5906
[11/17 12:54:00 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5850, average loss: 0.6496
[11/17 12:54:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 71.02	
[11/17 12:54:00 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/17 13:01:15 visual_prompt]: Epoch 32 / 100: avg data time: 4.77e+00, avg batch time: 6.2141, average train loss: 0.5705
[11/17 13:02:05 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5835, average loss: 0.8293
[11/17 13:02:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 69.90	
[11/17 13:02:05 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/17 13:09:20 visual_prompt]: Epoch 33 / 100: avg data time: 4.78e+00, avg batch time: 6.2191, average train loss: 0.5882
[11/17 13:10:10 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5813, average loss: 0.6304
[11/17 13:10:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 71.57	
[11/17 13:10:10 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/17 13:17:24 visual_prompt]: Epoch 34 / 100: avg data time: 4.75e+00, avg batch time: 6.1962, average train loss: 0.5776
[11/17 13:18:14 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5810, average loss: 0.7886
[11/17 13:18:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 69.24	
[11/17 13:18:14 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/17 13:25:29 visual_prompt]: Epoch 35 / 100: avg data time: 4.77e+00, avg batch time: 6.2112, average train loss: 0.5387
[11/17 13:26:18 visual_prompt]: Inference (val):avg data time: 3.66e-05, avg batch time: 0.5811, average loss: 0.7839
[11/17 13:26:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.40	
[11/17 13:26:18 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/17 13:33:34 visual_prompt]: Epoch 36 / 100: avg data time: 4.78e+00, avg batch time: 6.2254, average train loss: 0.5418
[11/17 13:34:24 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5842, average loss: 0.6763
[11/17 13:34:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 73.05	
[11/17 13:34:24 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/17 13:41:39 visual_prompt]: Epoch 37 / 100: avg data time: 4.77e+00, avg batch time: 6.2147, average train loss: 0.5536
[11/17 13:42:29 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5797, average loss: 0.6677
[11/17 13:42:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 72.03	
[11/17 13:42:29 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/17 13:49:45 visual_prompt]: Epoch 38 / 100: avg data time: 4.79e+00, avg batch time: 6.2264, average train loss: 0.5113
[11/17 13:50:35 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5835, average loss: 0.7031
[11/17 13:50:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 69.23	
[11/17 13:50:35 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/17 13:57:49 visual_prompt]: Epoch 39 / 100: avg data time: 4.76e+00, avg batch time: 6.2017, average train loss: 0.5325
[11/17 13:58:39 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5867, average loss: 0.6422
[11/17 13:58:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 72.11	
[11/17 13:58:39 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/17 14:05:54 visual_prompt]: Epoch 40 / 100: avg data time: 4.76e+00, avg batch time: 6.2044, average train loss: 0.5404
[11/17 14:06:43 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5816, average loss: 0.8179
[11/17 14:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.55	
[11/17 14:06:43 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/17 14:13:57 visual_prompt]: Epoch 41 / 100: avg data time: 4.75e+00, avg batch time: 6.1913, average train loss: 0.5060
[11/17 14:14:46 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5806, average loss: 0.7034
[11/17 14:14:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.82	
[11/17 14:14:46 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/17 14:22:00 visual_prompt]: Epoch 42 / 100: avg data time: 4.75e+00, avg batch time: 6.1975, average train loss: 0.4729
[11/17 14:22:51 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5835, average loss: 0.6900
[11/17 14:22:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 67.80	
[11/17 14:22:51 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/17 14:30:05 visual_prompt]: Epoch 43 / 100: avg data time: 4.77e+00, avg batch time: 6.2107, average train loss: 0.4820
[11/17 14:30:56 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5803, average loss: 0.6674
[11/17 14:30:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 72.68	
[11/17 14:30:56 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/17 14:38:12 visual_prompt]: Epoch 44 / 100: avg data time: 4.79e+00, avg batch time: 6.2299, average train loss: 0.4856
[11/17 14:39:02 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5818, average loss: 0.7338
[11/17 14:39:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.77	
[11/17 14:39:02 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/17 14:46:19 visual_prompt]: Epoch 45 / 100: avg data time: 4.80e+00, avg batch time: 6.2441, average train loss: 0.5048
[11/17 14:47:09 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5787, average loss: 0.7481
[11/17 14:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.72	
[11/17 14:47:09 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/17 14:54:23 visual_prompt]: Epoch 46 / 100: avg data time: 4.76e+00, avg batch time: 6.1991, average train loss: 0.4395
[11/17 14:55:12 visual_prompt]: Inference (val):avg data time: 3.62e-05, avg batch time: 0.5874, average loss: 0.7621
[11/17 14:55:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.24	
[11/17 14:55:12 visual_prompt]: Stopping early.
[11/17 14:55:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 14:55:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 14:55:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 14:55:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 14:55:14 visual_prompt]: Training with config:
[11/17 14:55:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.25_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.25, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 14:55:14 visual_prompt]: Loading training data...
[11/17 14:55:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 14:55:14 visual_prompt]: Loading validation data...
[11/17 14:55:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 14:55:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 14:55:29 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 14:55:29 visual_prompt]: tuned percent:0.532
[11/17 14:55:29 visual_prompt]: Device used for model: 0
[11/17 14:55:29 visual_prompt]: Setting up Evaluator...
[11/17 14:55:29 visual_prompt]: Setting up Trainer...
[11/17 14:55:29 visual_prompt]: 	Setting up the optimizer...
[11/17 14:55:29 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 15:02:45 visual_prompt]: Epoch 1 / 100: avg data time: 4.78e+00, avg batch time: 6.2207, average train loss: 1.4863
[11/17 15:03:34 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5789, average loss: 1.4553
[11/17 15:03:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 15:03:34 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.025
[11/17 15:10:50 visual_prompt]: Epoch 2 / 100: avg data time: 4.78e+00, avg batch time: 6.2221, average train loss: 0.9797
[11/17 15:11:40 visual_prompt]: Inference (val):avg data time: 2.75e-05, avg batch time: 0.5801, average loss: 0.7201
[11/17 15:11:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 51.31	
[11/17 15:11:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.05
[11/17 15:18:57 visual_prompt]: Epoch 3 / 100: avg data time: 4.80e+00, avg batch time: 6.2444, average train loss: 0.7163
[11/17 15:19:46 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5813, average loss: 0.7427
[11/17 15:19:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.67	
[11/17 15:19:47 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.075
[11/17 15:27:00 visual_prompt]: Epoch 4 / 100: avg data time: 4.75e+00, avg batch time: 6.1909, average train loss: 0.7474
[11/17 15:27:50 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5790, average loss: 0.7969
[11/17 15:27:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.16	
[11/17 15:27:50 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.1
[11/17 15:35:03 visual_prompt]: Epoch 5 / 100: avg data time: 4.74e+00, avg batch time: 6.1809, average train loss: 0.7629
[11/17 15:35:53 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5838, average loss: 0.7053
[11/17 15:35:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.74	
[11/17 15:35:53 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.125
[11/17 15:43:08 visual_prompt]: Epoch 6 / 100: avg data time: 4.78e+00, avg batch time: 6.2223, average train loss: 0.7480
[11/17 15:44:02 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5809, average loss: 0.6837
[11/17 15:44:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.51	
[11/17 15:44:02 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.15
[11/17 15:51:19 visual_prompt]: Epoch 7 / 100: avg data time: 4.80e+00, avg batch time: 6.2429, average train loss: 0.7033
[11/17 15:52:08 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5860, average loss: 1.2788
[11/17 15:52:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.86	
[11/17 15:52:08 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.175
[11/17 15:59:23 visual_prompt]: Epoch 8 / 100: avg data time: 4.76e+00, avg batch time: 6.2049, average train loss: 0.7262
[11/17 16:00:12 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5816, average loss: 1.1075
[11/17 16:00:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.03	
[11/17 16:00:12 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.2
[11/17 16:07:26 visual_prompt]: Epoch 9 / 100: avg data time: 4.75e+00, avg batch time: 6.1956, average train loss: 0.7955
[11/17 16:08:16 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5839, average loss: 0.6798
[11/17 16:08:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.99	
[11/17 16:08:16 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.225
[11/17 16:15:30 visual_prompt]: Epoch 10 / 100: avg data time: 4.76e+00, avg batch time: 6.1993, average train loss: 0.6855
[11/17 16:16:20 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5861, average loss: 0.6707
[11/17 16:16:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 66.98	
[11/17 16:16:20 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.25
[11/17 16:23:35 visual_prompt]: Epoch 11 / 100: avg data time: 4.78e+00, avg batch time: 6.2159, average train loss: 0.7567
[11/17 16:24:25 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5792, average loss: 0.8582
[11/17 16:24:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.06	
[11/17 16:24:25 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.24992385337738698
[11/17 16:31:42 visual_prompt]: Epoch 12 / 100: avg data time: 4.79e+00, avg batch time: 6.2305, average train loss: 0.7438
[11/17 16:32:33 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5829, average loss: 0.6770
[11/17 16:32:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 67.46	
[11/17 16:32:33 visual_prompt]: Best epoch 12: best metric: -0.677
[11/17 16:32:33 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.24969550628247802
[11/17 16:40:06 visual_prompt]: Epoch 13 / 100: avg data time: 5.02e+00, avg batch time: 6.4598, average train loss: 0.7849
[11/17 16:40:56 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5837, average loss: 0.6623
[11/17 16:40:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 65.83	
[11/17 16:40:56 visual_prompt]: Best epoch 13: best metric: -0.662
[11/17 16:40:56 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.24931523692103416
[11/17 16:48:14 visual_prompt]: Epoch 14 / 100: avg data time: 4.83e+00, avg batch time: 6.2645, average train loss: 0.6978
[11/17 16:49:04 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5817, average loss: 0.6987
[11/17 16:49:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 68.24	
[11/17 16:49:04 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.2487835085926963
[11/17 16:56:19 visual_prompt]: Epoch 15 / 100: avg data time: 4.77e+00, avg batch time: 6.2087, average train loss: 0.7028
[11/17 16:57:09 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5824, average loss: 0.6472
[11/17 16:57:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.56	
[11/17 16:57:09 visual_prompt]: Best epoch 15: best metric: -0.647
[11/17 16:57:09 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.24810096912652602
[11/17 17:04:23 visual_prompt]: Epoch 16 / 100: avg data time: 4.76e+00, avg batch time: 6.2035, average train loss: 0.6770
[11/17 17:05:13 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5825, average loss: 0.6824
[11/17 17:05:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[11/17 17:05:13 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.2472684500917257
[11/17 17:12:28 visual_prompt]: Epoch 17 / 100: avg data time: 4.76e+00, avg batch time: 6.2055, average train loss: 0.7268
[11/17 17:13:18 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5872, average loss: 0.7043
[11/17 17:13:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 69.13	
[11/17 17:13:18 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.24628696578449955
[11/17 17:20:31 visual_prompt]: Epoch 18 / 100: avg data time: 4.74e+00, avg batch time: 6.1828, average train loss: 0.6486
[11/17 17:21:20 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5829, average loss: 0.8783
[11/17 17:21:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.12	
[11/17 17:21:20 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.24515771199228986
[11/17 17:28:34 visual_prompt]: Epoch 19 / 100: avg data time: 4.76e+00, avg batch time: 6.2001, average train loss: 0.6995
[11/17 17:29:24 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5833, average loss: 0.7400
[11/17 17:29:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 68.44	
[11/17 17:29:24 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.2438820645368942
[11/17 17:36:40 visual_prompt]: Epoch 20 / 100: avg data time: 4.78e+00, avg batch time: 6.2272, average train loss: 0.6414
[11/17 17:37:31 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5839, average loss: 0.6653
[11/17 17:37:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.60	
[11/17 17:37:31 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.24246157759823855
[11/17 17:44:45 visual_prompt]: Epoch 21 / 100: avg data time: 4.76e+00, avg batch time: 6.1977, average train loss: 0.6528
[11/17 17:45:35 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5837, average loss: 0.6631
[11/17 17:45:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 70.48	
[11/17 17:45:35 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.24089798182084843
[11/17 17:52:49 visual_prompt]: Epoch 22 / 100: avg data time: 4.76e+00, avg batch time: 6.2023, average train loss: 0.6738
[11/17 17:53:39 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5899, average loss: 0.7469
[11/17 17:53:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 71.20	
[11/17 17:53:39 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.2391931822053251
[11/17 18:00:54 visual_prompt]: Epoch 23 / 100: avg data time: 4.78e+00, avg batch time: 6.2226, average train loss: 0.6244
[11/17 18:01:44 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5813, average loss: 0.6813
[11/17 18:01:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 69.94	
[11/17 18:01:44 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.23734925578739588
[11/17 18:08:58 visual_prompt]: Epoch 24 / 100: avg data time: 4.76e+00, avg batch time: 6.2029, average train loss: 0.6168
[11/17 18:09:48 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5817, average loss: 0.6321
[11/17 18:09:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.16	
[11/17 18:09:48 visual_prompt]: Best epoch 24: best metric: -0.632
[11/17 18:09:48 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.23536844910736587
[11/17 18:17:05 visual_prompt]: Epoch 25 / 100: avg data time: 4.79e+00, avg batch time: 6.2306, average train loss: 0.6264
[11/17 18:17:55 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5823, average loss: 0.6319
[11/17 18:17:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 70.70	
[11/17 18:17:55 visual_prompt]: Best epoch 25: best metric: -0.632
[11/17 18:17:55 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.23325317547305485
[11/17 18:25:22 visual_prompt]: Epoch 26 / 100: avg data time: 4.94e+00, avg batch time: 6.3823, average train loss: 0.6416
[11/17 18:26:26 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5871, average loss: 0.7645
[11/17 18:26:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 70.99	
[11/17 18:26:26 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.23100601201955323
[11/17 18:34:19 visual_prompt]: Epoch 27 / 100: avg data time: 5.31e+00, avg batch time: 6.7600, average train loss: 0.6318
[11/17 18:35:11 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5854, average loss: 0.6800
[11/17 18:35:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 72.19	
[11/17 18:35:11 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.2286296965693802
[11/17 18:42:46 visual_prompt]: Epoch 28 / 100: avg data time: 5.04e+00, avg batch time: 6.4976, average train loss: 0.6410
[11/17 18:43:37 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5836, average loss: 0.6618
[11/17 18:43:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.80	
[11/17 18:43:37 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.22612712429686843
[11/17 18:51:07 visual_prompt]: Epoch 29 / 100: avg data time: 4.96e+00, avg batch time: 6.4255, average train loss: 0.5998
[11/17 18:51:59 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5824, average loss: 0.8979
[11/17 18:51:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 70.34	
[11/17 18:51:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.22350134420084022
[11/17 18:59:32 visual_prompt]: Epoch 30 / 100: avg data time: 5.01e+00, avg batch time: 6.4598, average train loss: 0.6431
[11/17 19:00:23 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5870, average loss: 0.7204
[11/17 19:00:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 70.93	
[11/17 19:00:23 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.22075555538987224
[11/17 19:07:56 visual_prompt]: Epoch 31 / 100: avg data time: 5.01e+00, avg batch time: 6.4623, average train loss: 0.5813
[11/17 19:08:47 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5844, average loss: 0.6421
[11/17 19:08:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 70.18	
[11/17 19:08:47 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.21789310318467428
[11/17 19:16:20 visual_prompt]: Epoch 32 / 100: avg data time: 5.02e+00, avg batch time: 6.4678, average train loss: 0.5795
[11/17 19:17:12 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5879, average loss: 0.7390
[11/17 19:17:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 73.18	
[11/17 19:17:12 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.21491747504233139
[11/17 19:24:45 visual_prompt]: Epoch 33 / 100: avg data time: 5.02e+00, avg batch time: 6.4712, average train loss: 0.6177
[11/17 19:25:37 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5817, average loss: 0.6541
[11/17 19:25:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.09	
[11/17 19:25:37 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.21183229630737466
[11/17 19:33:10 visual_prompt]: Epoch 34 / 100: avg data time: 5.03e+00, avg batch time: 6.4734, average train loss: 0.5526
[11/17 19:34:02 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5814, average loss: 0.6405
[11/17 19:34:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 71.90	
[11/17 19:34:02 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.20864132579485728
[11/17 19:41:35 visual_prompt]: Epoch 35 / 100: avg data time: 5.01e+00, avg batch time: 6.4637, average train loss: 0.5288
[11/17 19:42:26 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5874, average loss: 0.6733
[11/17 19:42:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.59	
[11/17 19:42:26 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.2053484512108174
[11/17 19:50:00 visual_prompt]: Epoch 36 / 100: avg data time: 5.03e+00, avg batch time: 6.4762, average train loss: 0.5462
[11/17 19:50:52 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5834, average loss: 0.7197
[11/17 19:50:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.81	
[11/17 19:50:52 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.20195768441570727
[11/17 19:58:25 visual_prompt]: Epoch 37 / 100: avg data time: 5.02e+00, avg batch time: 6.4701, average train loss: 0.5590
[11/17 19:59:16 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5876, average loss: 0.6606
[11/17 19:59:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 70.86	
[11/17 19:59:16 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.19847315653655914
[11/17 20:06:49 visual_prompt]: Epoch 38 / 100: avg data time: 5.02e+00, avg batch time: 6.4676, average train loss: 0.5231
[11/17 20:07:41 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5824, average loss: 0.6995
[11/17 20:07:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 71.39	
[11/17 20:07:41 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.19489911293384335
[11/17 20:15:13 visual_prompt]: Epoch 39 / 100: avg data time: 5.01e+00, avg batch time: 6.4586, average train loss: 0.5196
[11/17 20:16:05 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5873, average loss: 0.6612
[11/17 20:16:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 72.29	
[11/17 20:16:05 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.1912399080291506
[11/17 20:23:37 visual_prompt]: Epoch 40 / 100: avg data time: 5.01e+00, avg batch time: 6.4526, average train loss: 0.5347
[11/17 20:24:29 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5866, average loss: 0.6859
[11/17 20:24:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.09	
[11/17 20:24:29 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.1875
[11/17 20:32:00 visual_prompt]: Epoch 41 / 100: avg data time: 5.00e+00, avg batch time: 6.4488, average train loss: 0.4957
[11/17 20:32:52 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5835, average loss: 0.7321
[11/17 20:32:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 70.92	
[11/17 20:32:52 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.18368394534823634
[11/17 20:40:24 visual_prompt]: Epoch 42 / 100: avg data time: 5.01e+00, avg batch time: 6.4549, average train loss: 0.4701
[11/17 20:41:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5828, average loss: 0.7339
[11/17 20:41:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.27	
[11/17 20:41:16 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.17979639334863468
[11/17 20:48:54 visual_prompt]: Epoch 43 / 100: avg data time: 5.10e+00, avg batch time: 6.5430, average train loss: 0.4696
[11/17 20:49:46 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5820, average loss: 0.6568
[11/17 20:49:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 73.15	
[11/17 20:49:46 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.17584208038447505
[11/17 20:57:24 visual_prompt]: Epoch 44 / 100: avg data time: 5.10e+00, avg batch time: 6.5371, average train loss: 0.4941
[11/17 20:58:16 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5850, average loss: 0.7012
[11/17 20:58:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 70.78	
[11/17 20:58:16 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.17182582417698902
[11/17 21:05:54 visual_prompt]: Epoch 45 / 100: avg data time: 5.10e+00, avg batch time: 6.5378, average train loss: 0.5093
[11/17 21:06:46 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5838, average loss: 0.8928
[11/17 21:06:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 69.38	
[11/17 21:06:46 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.1677525179157086
[11/17 21:14:21 visual_prompt]: Epoch 46 / 100: avg data time: 5.06e+00, avg batch time: 6.5061, average train loss: 0.4583
[11/17 21:15:14 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5827, average loss: 0.7513
[11/17 21:15:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.17	
[11/17 21:15:14 visual_prompt]: Stopping early.
[11/17 21:15:14 visual_prompt]: Rank of current process: 0. World size: 1
[11/17 21:15:14 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/17 21:15:14 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/17 21:15:14 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/17 21:15:14 visual_prompt]: Training with config:
[11/17 21:15:14 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/17 21:15:14 visual_prompt]: Loading training data...
[11/17 21:15:14 visual_prompt]: Constructing mammo-cbis dataset train...
[11/17 21:15:14 visual_prompt]: Loading validation data...
[11/17 21:15:14 visual_prompt]: Constructing mammo-cbis dataset val...
[11/17 21:15:14 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/17 21:15:20 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/17 21:15:20 visual_prompt]: tuned percent:0.532
[11/17 21:15:20 visual_prompt]: Device used for model: 0
[11/17 21:15:20 visual_prompt]: Setting up Evaluator...
[11/17 21:15:20 visual_prompt]: Setting up Trainer...
[11/17 21:15:20 visual_prompt]: 	Setting up the optimizer...
[11/17 21:15:21 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/17 21:22:59 visual_prompt]: Epoch 1 / 100: avg data time: 5.10e+00, avg batch time: 6.5419, average train loss: 1.4863
[11/17 21:23:51 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5784, average loss: 1.4553
[11/17 21:23:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/17 21:23:51 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/17 21:31:27 visual_prompt]: Epoch 2 / 100: avg data time: 5.08e+00, avg batch time: 6.5220, average train loss: 0.9470
[11/17 21:32:20 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5815, average loss: 0.6877
[11/17 21:32:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 52.80	
[11/17 21:32:20 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/17 21:39:57 visual_prompt]: Epoch 3 / 100: avg data time: 5.09e+00, avg batch time: 6.5267, average train loss: 0.7053
[11/17 21:40:49 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5793, average loss: 0.7360
[11/17 21:40:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.49	
[11/17 21:40:49 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/17 21:48:24 visual_prompt]: Epoch 4 / 100: avg data time: 5.06e+00, avg batch time: 6.4968, average train loss: 0.7236
[11/17 21:49:16 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5861, average loss: 0.7160
[11/17 21:49:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.61	
[11/17 21:49:16 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/17 21:56:50 visual_prompt]: Epoch 5 / 100: avg data time: 5.05e+00, avg batch time: 6.4942, average train loss: 0.7178
[11/17 21:57:42 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5855, average loss: 0.6843
[11/17 21:57:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.98	
[11/17 21:57:42 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/17 22:05:20 visual_prompt]: Epoch 6 / 100: avg data time: 5.09e+00, avg batch time: 6.5300, average train loss: 0.7115
[11/17 22:06:12 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5805, average loss: 0.7212
[11/17 22:06:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.97	
[11/17 22:06:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/17 22:13:47 visual_prompt]: Epoch 7 / 100: avg data time: 5.06e+00, avg batch time: 6.5019, average train loss: 0.7270
[11/17 22:14:39 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5835, average loss: 0.6919
[11/17 22:14:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 50.41	rocauc: 58.95	
[11/17 22:14:39 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/17 22:22:16 visual_prompt]: Epoch 8 / 100: avg data time: 5.08e+00, avg batch time: 6.5211, average train loss: 0.7129
[11/17 22:23:08 visual_prompt]: Inference (val):avg data time: 3.07e-05, avg batch time: 0.5799, average loss: 0.6984
[11/17 22:23:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.30	
[11/17 22:23:08 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/17 22:30:44 visual_prompt]: Epoch 9 / 100: avg data time: 5.07e+00, avg batch time: 6.5078, average train loss: 0.7031
[11/17 22:31:36 visual_prompt]: Inference (val):avg data time: 4.00e-05, avg batch time: 0.5816, average loss: 0.7259
[11/17 22:31:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.53	
[11/17 22:31:36 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/17 22:39:11 visual_prompt]: Epoch 10 / 100: avg data time: 5.06e+00, avg batch time: 6.5049, average train loss: 0.6923
[11/17 22:40:03 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5837, average loss: 0.6895
[11/17 22:40:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.06	
[11/17 22:40:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/17 22:47:40 visual_prompt]: Epoch 11 / 100: avg data time: 5.08e+00, avg batch time: 6.5200, average train loss: 0.6961
[11/17 22:48:32 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5820, average loss: 0.6916
[11/17 22:48:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 56.39	
[11/17 22:48:32 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/17 22:56:09 visual_prompt]: Epoch 12 / 100: avg data time: 5.08e+00, avg batch time: 6.5269, average train loss: 0.6969
[11/17 22:57:01 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5806, average loss: 0.6994
[11/17 22:57:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.45	
[11/17 22:57:01 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/17 23:04:38 visual_prompt]: Epoch 13 / 100: avg data time: 5.08e+00, avg batch time: 6.5226, average train loss: 0.7053
[11/17 23:05:30 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5808, average loss: 0.6900
[11/17 23:05:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.61	
[11/17 23:05:30 visual_prompt]: Best epoch 13: best metric: -0.690
[11/17 23:05:30 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/17 23:13:06 visual_prompt]: Epoch 14 / 100: avg data time: 5.07e+00, avg batch time: 6.5121, average train loss: 0.7083
[11/17 23:13:58 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5868, average loss: 0.6885
[11/17 23:13:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 50.32	
[11/17 23:13:58 visual_prompt]: Best epoch 14: best metric: -0.688
[11/17 23:13:58 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/17 23:21:33 visual_prompt]: Epoch 15 / 100: avg data time: 5.05e+00, avg batch time: 6.4912, average train loss: 0.7088
[11/17 23:22:25 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5821, average loss: 0.7085
[11/17 23:22:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.31	
[11/17 23:22:25 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/17 23:30:00 visual_prompt]: Epoch 16 / 100: avg data time: 5.06e+00, avg batch time: 6.5037, average train loss: 0.7287
[11/17 23:30:52 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5813, average loss: 0.8338
[11/17 23:30:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 52.60	
[11/17 23:30:52 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/17 23:38:28 visual_prompt]: Epoch 17 / 100: avg data time: 5.07e+00, avg batch time: 6.5098, average train loss: 0.7250
[11/17 23:39:21 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5840, average loss: 0.6892
[11/17 23:39:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.81	
[11/17 23:39:21 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/17 23:46:56 visual_prompt]: Epoch 18 / 100: avg data time: 5.07e+00, avg batch time: 6.5080, average train loss: 0.7213
[11/17 23:47:48 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5812, average loss: 0.8450
[11/17 23:47:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.84	
[11/17 23:47:48 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/17 23:55:23 visual_prompt]: Epoch 19 / 100: avg data time: 5.05e+00, avg batch time: 6.4915, average train loss: 0.7093
[11/17 23:56:15 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5789, average loss: 0.7779
[11/17 23:56:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.53	
[11/17 23:56:15 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/18 00:03:52 visual_prompt]: Epoch 20 / 100: avg data time: 5.08e+00, avg batch time: 6.5242, average train loss: 0.7058
[11/18 00:04:44 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5805, average loss: 0.7007
[11/18 00:04:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.80	
[11/18 00:04:44 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/18 00:12:21 visual_prompt]: Epoch 21 / 100: avg data time: 5.09e+00, avg batch time: 6.5252, average train loss: 0.7006
[11/18 00:13:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5799, average loss: 0.7117
[11/18 00:13:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.88	
[11/18 00:13:13 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/18 00:20:50 visual_prompt]: Epoch 22 / 100: avg data time: 5.08e+00, avg batch time: 6.5210, average train loss: 0.7042
[11/18 00:21:42 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5810, average loss: 0.6975
[11/18 00:21:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.84	
[11/18 00:21:42 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/18 00:29:19 visual_prompt]: Epoch 23 / 100: avg data time: 5.09e+00, avg batch time: 6.5245, average train loss: 0.6960
[11/18 00:30:11 visual_prompt]: Inference (val):avg data time: 3.70e-05, avg batch time: 0.5837, average loss: 0.7023
[11/18 00:30:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 63.91	
[11/18 00:30:11 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/18 00:37:47 visual_prompt]: Epoch 24 / 100: avg data time: 5.08e+00, avg batch time: 6.5202, average train loss: 0.6960
[11/18 00:38:40 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5810, average loss: 0.6989
[11/18 00:38:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.51	
[11/18 00:38:40 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/18 00:46:17 visual_prompt]: Epoch 25 / 100: avg data time: 5.09e+00, avg batch time: 6.5261, average train loss: 0.6955
[11/18 00:47:09 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5778, average loss: 0.7162
[11/18 00:47:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.74	
[11/18 00:47:09 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/18 00:54:45 visual_prompt]: Epoch 26 / 100: avg data time: 5.07e+00, avg batch time: 6.5115, average train loss: 0.7033
[11/18 00:55:37 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5831, average loss: 0.6946
[11/18 00:55:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.68	
[11/18 00:55:37 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/18 01:03:12 visual_prompt]: Epoch 27 / 100: avg data time: 5.06e+00, avg batch time: 6.4991, average train loss: 0.6954
[11/18 01:04:04 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5843, average loss: 0.6879
[11/18 01:04:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/18 01:04:04 visual_prompt]: Best epoch 27: best metric: -0.688
[11/18 01:04:04 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/18 01:11:40 visual_prompt]: Epoch 28 / 100: avg data time: 5.07e+00, avg batch time: 6.5111, average train loss: 0.6974
[11/18 01:12:32 visual_prompt]: Inference (val):avg data time: 3.75e-05, avg batch time: 0.5865, average loss: 0.6960
[11/18 01:12:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.43	
[11/18 01:12:32 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/18 01:20:08 visual_prompt]: Epoch 29 / 100: avg data time: 5.06e+00, avg batch time: 6.5039, average train loss: 0.6916
[11/18 01:21:00 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5804, average loss: 0.6871
[11/18 01:21:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.03	
[11/18 01:21:00 visual_prompt]: Best epoch 29: best metric: -0.687
[11/18 01:21:00 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/18 01:28:37 visual_prompt]: Epoch 30 / 100: avg data time: 5.09e+00, avg batch time: 6.5322, average train loss: 0.6998
[11/18 01:29:29 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5817, average loss: 0.6899
[11/18 01:29:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.69	
[11/18 01:29:29 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/18 01:37:04 visual_prompt]: Epoch 31 / 100: avg data time: 5.05e+00, avg batch time: 6.4897, average train loss: 0.6951
[11/18 01:37:56 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5856, average loss: 0.6898
[11/18 01:37:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.87	
[11/18 01:37:56 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/18 01:45:32 visual_prompt]: Epoch 32 / 100: avg data time: 5.07e+00, avg batch time: 6.5072, average train loss: 0.7010
[11/18 01:46:24 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5804, average loss: 0.7336
[11/18 01:46:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 56.85	
[11/18 01:46:24 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/18 01:54:00 visual_prompt]: Epoch 33 / 100: avg data time: 5.08e+00, avg batch time: 6.5205, average train loss: 0.6965
[11/18 01:54:53 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5851, average loss: 0.6917
[11/18 01:54:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 62.27	
[11/18 01:54:53 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/18 02:02:27 visual_prompt]: Epoch 34 / 100: avg data time: 5.05e+00, avg batch time: 6.4910, average train loss: 0.6946
[11/18 02:03:19 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5818, average loss: 0.6879
[11/18 02:03:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.21	
[11/18 02:03:19 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/18 02:10:54 visual_prompt]: Epoch 35 / 100: avg data time: 5.05e+00, avg batch time: 6.4875, average train loss: 0.7001
[11/18 02:11:46 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5829, average loss: 0.6938
[11/18 02:11:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.13	
[11/18 02:11:46 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/18 02:19:22 visual_prompt]: Epoch 36 / 100: avg data time: 5.07e+00, avg batch time: 6.5105, average train loss: 0.6927
[11/18 02:20:14 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5848, average loss: 0.6883
[11/18 02:20:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.65	
[11/18 02:20:14 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/18 02:27:50 visual_prompt]: Epoch 37 / 100: avg data time: 5.07e+00, avg batch time: 6.5100, average train loss: 0.6931
[11/18 02:28:42 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5823, average loss: 0.7913
[11/18 02:28:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.57	
[11/18 02:28:42 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/18 02:36:17 visual_prompt]: Epoch 38 / 100: avg data time: 5.06e+00, avg batch time: 6.5004, average train loss: 0.6962
[11/18 02:37:09 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5800, average loss: 0.6965
[11/18 02:37:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.03	
[11/18 02:37:09 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/18 02:44:44 visual_prompt]: Epoch 39 / 100: avg data time: 5.06e+00, avg batch time: 6.5016, average train loss: 0.7008
[11/18 02:45:36 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5888, average loss: 0.6908
[11/18 02:45:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.58	
[11/18 02:45:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/18 02:53:11 visual_prompt]: Epoch 40 / 100: avg data time: 5.06e+00, avg batch time: 6.4967, average train loss: 0.6914
[11/18 02:54:03 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5849, average loss: 0.6844
[11/18 02:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.77	
[11/18 02:54:03 visual_prompt]: Best epoch 40: best metric: -0.684
[11/18 02:54:03 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/18 03:01:39 visual_prompt]: Epoch 41 / 100: avg data time: 5.06e+00, avg batch time: 6.5056, average train loss: 0.6982
[11/18 03:02:31 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5852, average loss: 0.6918
[11/18 03:02:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.87	
[11/18 03:02:31 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/18 03:10:06 visual_prompt]: Epoch 42 / 100: avg data time: 5.06e+00, avg batch time: 6.5017, average train loss: 0.7008
[11/18 03:10:58 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5770, average loss: 0.7023
[11/18 03:10:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.80	
[11/18 03:10:58 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/18 03:18:35 visual_prompt]: Epoch 43 / 100: avg data time: 5.08e+00, avg batch time: 6.5161, average train loss: 0.6960
[11/18 03:19:27 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5809, average loss: 0.6900
[11/18 03:19:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.63	
[11/18 03:19:27 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/18 03:27:04 visual_prompt]: Epoch 44 / 100: avg data time: 5.09e+00, avg batch time: 6.5264, average train loss: 0.6979
[11/18 03:27:56 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5773, average loss: 0.7074
[11/18 03:27:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 53.46	
[11/18 03:27:56 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/18 03:35:33 visual_prompt]: Epoch 45 / 100: avg data time: 5.09e+00, avg batch time: 6.5258, average train loss: 0.6933
[11/18 03:36:25 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5851, average loss: 0.7020
[11/18 03:36:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.02	
[11/18 03:36:25 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/18 03:44:00 visual_prompt]: Epoch 46 / 100: avg data time: 5.06e+00, avg batch time: 6.5024, average train loss: 0.6962
[11/18 03:44:52 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5791, average loss: 0.6898
[11/18 03:44:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.06	
[11/18 03:44:52 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/18 03:52:28 visual_prompt]: Epoch 47 / 100: avg data time: 5.07e+00, avg batch time: 6.5097, average train loss: 0.7006
[11/18 03:53:20 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5816, average loss: 0.6995
[11/18 03:53:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 60.47	
[11/18 03:53:20 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/18 04:00:56 visual_prompt]: Epoch 48 / 100: avg data time: 5.06e+00, avg batch time: 6.5025, average train loss: 0.7027
[11/18 04:01:48 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5799, average loss: 0.7172
[11/18 04:01:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.75	
[11/18 04:01:48 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/18 04:09:24 visual_prompt]: Epoch 49 / 100: avg data time: 5.07e+00, avg batch time: 6.5083, average train loss: 0.6985
[11/18 04:10:16 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5796, average loss: 0.6913
[11/18 04:10:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.02	
[11/18 04:10:16 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/18 04:17:50 visual_prompt]: Epoch 50 / 100: avg data time: 5.06e+00, avg batch time: 6.4971, average train loss: 0.6974
[11/18 04:18:43 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5785, average loss: 0.6969
[11/18 04:18:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.89	
[11/18 04:18:43 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/18 04:26:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.06e+00, avg batch time: 6.4983, average train loss: 0.7010
[11/18 04:27:10 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5816, average loss: 0.6943
[11/18 04:27:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 54.81	
[11/18 04:27:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/18 04:34:46 visual_prompt]: Epoch 52 / 100: avg data time: 5.08e+00, avg batch time: 6.5170, average train loss: 0.6984
[11/18 04:35:38 visual_prompt]: Inference (val):avg data time: 3.16e-05, avg batch time: 0.5820, average loss: 0.6894
[11/18 04:35:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.22	
[11/18 04:35:38 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/18 04:43:15 visual_prompt]: Epoch 53 / 100: avg data time: 5.09e+00, avg batch time: 6.5280, average train loss: 0.6958
[11/18 04:44:07 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5803, average loss: 0.6893
[11/18 04:44:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.15	
[11/18 04:44:07 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/18 04:51:43 visual_prompt]: Epoch 54 / 100: avg data time: 5.07e+00, avg batch time: 6.5071, average train loss: 0.6962
[11/18 04:52:35 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5806, average loss: 0.7089
[11/18 04:52:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.54	
[11/18 04:52:35 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[11/18 05:00:10 visual_prompt]: Epoch 55 / 100: avg data time: 5.06e+00, avg batch time: 6.4953, average train loss: 0.6967
[11/18 05:01:02 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5786, average loss: 0.6962
[11/18 05:01:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.26	
[11/18 05:01:02 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[11/18 05:08:37 visual_prompt]: Epoch 56 / 100: avg data time: 5.05e+00, avg batch time: 6.4946, average train loss: 0.6972
[11/18 05:09:29 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5822, average loss: 0.6885
[11/18 05:09:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.59	
[11/18 05:09:29 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[11/18 05:17:05 visual_prompt]: Epoch 57 / 100: avg data time: 5.08e+00, avg batch time: 6.5150, average train loss: 0.6957
[11/18 05:17:57 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5825, average loss: 0.6904
[11/18 05:17:57 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 49.51	
[11/18 05:17:57 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[11/18 05:25:31 visual_prompt]: Epoch 58 / 100: avg data time: 5.05e+00, avg batch time: 6.4894, average train loss: 0.6987
[11/18 05:26:23 visual_prompt]: Inference (val):avg data time: 3.73e-05, avg batch time: 0.5785, average loss: 0.6883
[11/18 05:26:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.56	
[11/18 05:26:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[11/18 05:34:00 visual_prompt]: Epoch 59 / 100: avg data time: 5.09e+00, avg batch time: 6.5284, average train loss: 0.6923
[11/18 05:34:52 visual_prompt]: Inference (val):avg data time: 3.71e-05, avg batch time: 0.5801, average loss: 0.6913
[11/18 05:34:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.70	
[11/18 05:34:52 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[11/18 05:42:28 visual_prompt]: Epoch 60 / 100: avg data time: 5.07e+00, avg batch time: 6.5099, average train loss: 0.6916
[11/18 05:43:20 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5836, average loss: 0.7004
[11/18 05:43:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.36	
[11/18 05:43:20 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[11/18 05:50:56 visual_prompt]: Epoch 61 / 100: avg data time: 5.06e+00, avg batch time: 6.5013, average train loss: 0.6921
[11/18 05:51:48 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5821, average loss: 0.6935
[11/18 05:51:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.50	
[11/18 05:51:48 visual_prompt]: Stopping early.
[11/18 05:51:48 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 05:51:48 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 05:51:48 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 05:51:48 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 05:51:48 visual_prompt]: Training with config:
[11/18 05:51:48 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 05:51:48 visual_prompt]: Loading training data...
[11/18 05:51:48 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 05:51:48 visual_prompt]: Loading validation data...
[11/18 05:51:48 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 05:51:48 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/18 05:51:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/18 05:51:51 visual_prompt]: tuned percent:0.532
[11/18 05:51:51 visual_prompt]: Device used for model: 0
[11/18 05:51:51 visual_prompt]: Setting up Evaluator...
[11/18 05:51:51 visual_prompt]: Setting up Trainer...
[11/18 05:51:51 visual_prompt]: 	Setting up the optimizer...
[11/18 05:51:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 05:59:28 visual_prompt]: Epoch 1 / 100: avg data time: 5.08e+00, avg batch time: 6.5221, average train loss: 1.4863
[11/18 06:00:20 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5815, average loss: 1.4553
[11/18 06:00:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/18 06:00:20 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/18 06:07:56 visual_prompt]: Epoch 2 / 100: avg data time: 5.07e+00, avg batch time: 6.5067, average train loss: 0.9491
[11/18 06:08:48 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5826, average loss: 0.6880
[11/18 06:08:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 52.60	
[11/18 06:08:48 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/18 06:16:23 visual_prompt]: Epoch 3 / 100: avg data time: 5.06e+00, avg batch time: 6.5003, average train loss: 0.7079
[11/18 06:17:15 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5855, average loss: 0.7342
[11/18 06:17:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.19	
[11/18 06:17:15 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/18 06:24:49 visual_prompt]: Epoch 4 / 100: avg data time: 5.05e+00, avg batch time: 6.4895, average train loss: 0.7299
[11/18 06:25:41 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5856, average loss: 0.7114
[11/18 06:25:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.37	
[11/18 06:25:41 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/18 06:33:16 visual_prompt]: Epoch 5 / 100: avg data time: 5.04e+00, avg batch time: 6.4860, average train loss: 0.7246
[11/18 06:34:08 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5847, average loss: 0.6841
[11/18 06:34:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.20	
[11/18 06:34:08 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/18 06:41:44 visual_prompt]: Epoch 6 / 100: avg data time: 5.07e+00, avg batch time: 6.5151, average train loss: 0.7315
[11/18 06:42:36 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5815, average loss: 0.7569
[11/18 06:42:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.02	
[11/18 06:42:36 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/18 06:50:10 visual_prompt]: Epoch 7 / 100: avg data time: 5.04e+00, avg batch time: 6.4852, average train loss: 0.7253
[11/18 06:51:02 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5851, average loss: 0.8021
[11/18 06:51:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.19	
[11/18 06:51:02 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/18 06:58:38 visual_prompt]: Epoch 8 / 100: avg data time: 5.07e+00, avg batch time: 6.5128, average train loss: 0.7479
[11/18 06:59:30 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5815, average loss: 0.6975
[11/18 06:59:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 60.55	
[11/18 06:59:30 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/18 07:07:06 visual_prompt]: Epoch 9 / 100: avg data time: 5.07e+00, avg batch time: 6.5062, average train loss: 0.7136
[11/18 07:07:58 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5868, average loss: 0.7153
[11/18 07:07:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.35	
[11/18 07:07:58 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/18 07:15:33 visual_prompt]: Epoch 10 / 100: avg data time: 5.06e+00, avg batch time: 6.4979, average train loss: 0.6824
[11/18 07:16:26 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5775, average loss: 0.6736
[11/18 07:16:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 63.72	
[11/18 07:16:26 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/18 07:24:02 visual_prompt]: Epoch 11 / 100: avg data time: 5.08e+00, avg batch time: 6.5147, average train loss: 0.6939
[11/18 07:24:54 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5798, average loss: 0.7041
[11/18 07:24:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 63.79	
[11/18 07:24:54 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/18 07:32:28 visual_prompt]: Epoch 12 / 100: avg data time: 5.05e+00, avg batch time: 6.4874, average train loss: 0.6945
[11/18 07:33:20 visual_prompt]: Inference (val):avg data time: 3.26e-05, avg batch time: 0.5855, average loss: 0.7523
[11/18 07:33:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 47.15	rocauc: 63.40	
[11/18 07:33:20 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/18 07:40:56 visual_prompt]: Epoch 13 / 100: avg data time: 5.07e+00, avg batch time: 6.5109, average train loss: 0.7125
[11/18 07:41:48 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5789, average loss: 0.6589
[11/18 07:41:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 65.36	
[11/18 07:41:48 visual_prompt]: Best epoch 13: best metric: -0.659
[11/18 07:41:48 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/18 07:49:23 visual_prompt]: Epoch 14 / 100: avg data time: 5.05e+00, avg batch time: 6.4948, average train loss: 0.6953
[11/18 07:50:15 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5809, average loss: 0.6672
[11/18 07:50:15 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 66.62	
[11/18 07:50:15 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/18 07:57:49 visual_prompt]: Epoch 15 / 100: avg data time: 5.04e+00, avg batch time: 6.4850, average train loss: 0.6676
[11/18 07:58:41 visual_prompt]: Inference (val):avg data time: 3.05e-05, avg batch time: 0.5830, average loss: 0.6714
[11/18 07:58:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.34	
[11/18 07:58:41 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/18 08:06:16 visual_prompt]: Epoch 16 / 100: avg data time: 5.06e+00, avg batch time: 6.4998, average train loss: 0.6789
[11/18 08:07:09 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5847, average loss: 0.8728
[11/18 08:07:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 64.69	
[11/18 08:07:09 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/18 08:14:43 visual_prompt]: Epoch 17 / 100: avg data time: 5.05e+00, avg batch time: 6.4927, average train loss: 0.6780
[11/18 08:15:35 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5829, average loss: 0.7124
[11/18 08:15:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 67.82	
[11/18 08:15:35 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/18 08:23:10 visual_prompt]: Epoch 18 / 100: avg data time: 5.05e+00, avg batch time: 6.4898, average train loss: 0.6630
[11/18 08:24:02 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5838, average loss: 1.0120
[11/18 08:24:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.82	
[11/18 08:24:02 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/18 08:31:36 visual_prompt]: Epoch 19 / 100: avg data time: 5.04e+00, avg batch time: 6.4790, average train loss: 0.6533
[11/18 08:32:28 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5845, average loss: 0.7548
[11/18 08:32:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 66.16	
[11/18 08:32:28 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/18 08:40:03 visual_prompt]: Epoch 20 / 100: avg data time: 5.06e+00, avg batch time: 6.5044, average train loss: 0.6409
[11/18 08:40:55 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5857, average loss: 0.6403
[11/18 08:40:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 69.84	
[11/18 08:40:55 visual_prompt]: Best epoch 20: best metric: -0.640
[11/18 08:40:55 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/18 08:48:30 visual_prompt]: Epoch 21 / 100: avg data time: 5.07e+00, avg batch time: 6.5069, average train loss: 0.6575
[11/18 08:49:22 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5802, average loss: 0.6794
[11/18 08:49:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.00	
[11/18 08:49:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/18 08:56:57 visual_prompt]: Epoch 22 / 100: avg data time: 5.05e+00, avg batch time: 6.4913, average train loss: 0.6453
[11/18 08:57:49 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5858, average loss: 0.7086
[11/18 08:57:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 67.86	
[11/18 08:57:49 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/18 09:05:25 visual_prompt]: Epoch 23 / 100: avg data time: 5.07e+00, avg batch time: 6.5084, average train loss: 0.6508
[11/18 09:06:17 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5846, average loss: 0.6641
[11/18 09:06:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.18	
[11/18 09:06:17 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/18 09:13:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.05e+00, avg batch time: 6.4951, average train loss: 0.6235
[11/18 09:14:44 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5871, average loss: 0.6345
[11/18 09:14:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.71	
[11/18 09:14:44 visual_prompt]: Best epoch 24: best metric: -0.635
[11/18 09:14:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/18 09:22:20 visual_prompt]: Epoch 25 / 100: avg data time: 5.07e+00, avg batch time: 6.5112, average train loss: 0.6316
[11/18 09:23:12 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5821, average loss: 0.6336
[11/18 09:23:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 74.01	
[11/18 09:23:12 visual_prompt]: Best epoch 25: best metric: -0.634
[11/18 09:23:12 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/18 09:30:46 visual_prompt]: Epoch 26 / 100: avg data time: 5.04e+00, avg batch time: 6.4881, average train loss: 0.6342
[11/18 09:31:38 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5833, average loss: 0.6540
[11/18 09:31:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 72.22	
[11/18 09:31:38 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/18 09:39:13 visual_prompt]: Epoch 27 / 100: avg data time: 5.05e+00, avg batch time: 6.4922, average train loss: 0.6237
[11/18 09:40:05 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5792, average loss: 0.6221
[11/18 09:40:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 70.81	
[11/18 09:40:05 visual_prompt]: Best epoch 27: best metric: -0.622
[11/18 09:40:05 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/18 09:47:41 visual_prompt]: Epoch 28 / 100: avg data time: 5.07e+00, avg batch time: 6.5119, average train loss: 0.6257
[11/18 09:48:33 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5796, average loss: 0.6117
[11/18 09:48:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 72.43	
[11/18 09:48:33 visual_prompt]: Best epoch 28: best metric: -0.612
[11/18 09:48:33 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/18 09:56:07 visual_prompt]: Epoch 29 / 100: avg data time: 5.04e+00, avg batch time: 6.4856, average train loss: 0.6023
[11/18 09:56:59 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5832, average loss: 0.6587
[11/18 09:56:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 74.41	
[11/18 09:56:59 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/18 10:04:36 visual_prompt]: Epoch 30 / 100: avg data time: 5.08e+00, avg batch time: 6.5177, average train loss: 0.6069
[11/18 10:05:28 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5803, average loss: 0.7991
[11/18 10:05:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 66.86	
[11/18 10:05:28 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/18 10:13:02 visual_prompt]: Epoch 31 / 100: avg data time: 5.05e+00, avg batch time: 6.4881, average train loss: 0.6304
[11/18 10:13:54 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5854, average loss: 0.6113
[11/18 10:13:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 73.51	
[11/18 10:13:54 visual_prompt]: Best epoch 31: best metric: -0.611
[11/18 10:13:54 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/18 10:21:30 visual_prompt]: Epoch 32 / 100: avg data time: 5.06e+00, avg batch time: 6.5038, average train loss: 0.6053
[11/18 10:22:22 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5844, average loss: 0.6145
[11/18 10:22:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 73.04	
[11/18 10:22:22 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/18 10:29:58 visual_prompt]: Epoch 33 / 100: avg data time: 5.07e+00, avg batch time: 6.5075, average train loss: 0.6138
[11/18 10:30:50 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5831, average loss: 0.6364
[11/18 10:30:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 73.65	
[11/18 10:30:50 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/18 10:38:24 visual_prompt]: Epoch 34 / 100: avg data time: 5.04e+00, avg batch time: 6.4829, average train loss: 0.6090
[11/18 10:39:16 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5863, average loss: 0.7317
[11/18 10:39:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 72.51	
[11/18 10:39:16 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/18 10:46:50 visual_prompt]: Epoch 35 / 100: avg data time: 5.04e+00, avg batch time: 6.4855, average train loss: 0.6169
[11/18 10:47:42 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5806, average loss: 0.6880
[11/18 10:47:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 72.57	
[11/18 10:47:42 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/18 10:55:18 visual_prompt]: Epoch 36 / 100: avg data time: 5.07e+00, avg batch time: 6.5122, average train loss: 0.5850
[11/18 10:56:10 visual_prompt]: Inference (val):avg data time: 3.77e-05, avg batch time: 0.5832, average loss: 0.7057
[11/18 10:56:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.65	
[11/18 10:56:10 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/18 11:03:45 visual_prompt]: Epoch 37 / 100: avg data time: 5.05e+00, avg batch time: 6.4925, average train loss: 0.5986
[11/18 11:04:37 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5833, average loss: 0.6743
[11/18 11:04:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 75.61	
[11/18 11:04:37 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/18 11:12:12 visual_prompt]: Epoch 38 / 100: avg data time: 5.06e+00, avg batch time: 6.5020, average train loss: 0.5664
[11/18 11:13:04 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5805, average loss: 0.6420
[11/18 11:13:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.45	
[11/18 11:13:04 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/18 11:20:39 visual_prompt]: Epoch 39 / 100: avg data time: 5.05e+00, avg batch time: 6.4985, average train loss: 0.5699
[11/18 11:21:31 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5839, average loss: 0.6260
[11/18 11:21:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 73.13	
[11/18 11:21:31 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/18 11:29:07 visual_prompt]: Epoch 40 / 100: avg data time: 5.06e+00, avg batch time: 6.5072, average train loss: 0.5997
[11/18 11:29:59 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5833, average loss: 0.5932
[11/18 11:29:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 70.73	rocauc: 75.42	
[11/18 11:29:59 visual_prompt]: Best epoch 40: best metric: -0.593
[11/18 11:29:59 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/18 11:37:33 visual_prompt]: Epoch 41 / 100: avg data time: 5.04e+00, avg batch time: 6.4861, average train loss: 0.5634
[11/18 11:38:25 visual_prompt]: Inference (val):avg data time: 3.54e-05, avg batch time: 0.5830, average loss: 0.7009
[11/18 11:38:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 71.43	
[11/18 11:38:25 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/18 11:46:00 visual_prompt]: Epoch 42 / 100: avg data time: 5.05e+00, avg batch time: 6.4944, average train loss: 0.6058
[11/18 11:46:52 visual_prompt]: Inference (val):avg data time: 3.18e-05, avg batch time: 0.5799, average loss: 0.5875
[11/18 11:46:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 75.65	
[11/18 11:46:52 visual_prompt]: Best epoch 42: best metric: -0.587
[11/18 11:46:52 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/18 11:54:28 visual_prompt]: Epoch 43 / 100: avg data time: 5.07e+00, avg batch time: 6.5137, average train loss: 0.5846
[11/18 11:55:20 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5808, average loss: 0.6091
[11/18 11:55:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 75.52	
[11/18 11:55:20 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/18 12:02:56 visual_prompt]: Epoch 44 / 100: avg data time: 5.08e+00, avg batch time: 6.5210, average train loss: 0.5680
[11/18 12:03:49 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5821, average loss: 0.5974
[11/18 12:03:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.70	rocauc: 76.07	
[11/18 12:03:49 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/18 12:11:24 visual_prompt]: Epoch 45 / 100: avg data time: 5.07e+00, avg batch time: 6.5083, average train loss: 0.5466
[11/18 12:12:17 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5864, average loss: 0.6223
[11/18 12:12:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 75.90	
[11/18 12:12:17 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/18 12:19:52 visual_prompt]: Epoch 46 / 100: avg data time: 5.06e+00, avg batch time: 6.4985, average train loss: 0.5373
[11/18 12:20:44 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5794, average loss: 0.6129
[11/18 12:20:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.07	rocauc: 74.76	
[11/18 12:20:44 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/18 12:28:19 visual_prompt]: Epoch 47 / 100: avg data time: 5.06e+00, avg batch time: 6.4977, average train loss: 0.5616
[11/18 12:29:11 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5846, average loss: 0.6943
[11/18 12:29:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 72.03	
[11/18 12:29:11 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/18 12:36:45 visual_prompt]: Epoch 48 / 100: avg data time: 5.05e+00, avg batch time: 6.4932, average train loss: 0.5120
[11/18 12:37:37 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5851, average loss: 0.6919
[11/18 12:37:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 71.48	
[11/18 12:37:37 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/18 12:45:11 visual_prompt]: Epoch 49 / 100: avg data time: 5.03e+00, avg batch time: 6.4765, average train loss: 0.5427
[11/18 12:46:03 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5823, average loss: 0.6314
[11/18 12:46:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 75.06	
[11/18 12:46:03 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/18 12:53:36 visual_prompt]: Epoch 50 / 100: avg data time: 5.03e+00, avg batch time: 6.4694, average train loss: 0.5317
[11/18 12:54:28 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5805, average loss: 0.7702
[11/18 12:54:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 76.09	
[11/18 12:54:28 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/18 13:02:00 visual_prompt]: Epoch 51 / 100: avg data time: 5.02e+00, avg batch time: 6.4607, average train loss: 0.4982
[11/18 13:02:52 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5887, average loss: 0.6444
[11/18 13:02:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 73.14	
[11/18 13:02:52 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/18 13:10:26 visual_prompt]: Epoch 52 / 100: avg data time: 5.04e+00, avg batch time: 6.4797, average train loss: 0.4847
[11/18 13:11:17 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5827, average loss: 0.8787
[11/18 13:11:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 71.97	
[11/18 13:11:17 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/18 13:18:52 visual_prompt]: Epoch 53 / 100: avg data time: 5.05e+00, avg batch time: 6.4920, average train loss: 0.4954
[11/18 13:19:44 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5818, average loss: 0.6453
[11/18 13:19:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 74.61	
[11/18 13:19:44 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/18 13:27:35 visual_prompt]: Epoch 54 / 100: avg data time: 5.27e+00, avg batch time: 6.7214, average train loss: 0.5597
[11/18 13:28:26 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5856, average loss: 0.6251
[11/18 13:28:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.91	
[11/18 13:28:26 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[11/18 13:36:10 visual_prompt]: Epoch 55 / 100: avg data time: 5.17e+00, avg batch time: 6.6254, average train loss: 0.4767
[11/18 13:37:04 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5880, average loss: 0.8301
[11/18 13:37:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.41	rocauc: 74.13	
[11/18 13:37:04 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.05
[11/18 13:44:38 visual_prompt]: Epoch 56 / 100: avg data time: 5.04e+00, avg batch time: 6.4917, average train loss: 0.4914
[11/18 13:45:32 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5849, average loss: 0.7185
[11/18 13:45:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 74.06	
[11/18 13:45:32 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.04825502516487497
[11/18 13:53:18 visual_prompt]: Epoch 57 / 100: avg data time: 5.20e+00, avg batch time: 6.6507, average train loss: 0.5066
[11/18 13:54:08 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5851, average loss: 0.6712
[11/18 13:54:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 74.36	
[11/18 13:54:08 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.04651217631279374
[11/18 14:01:32 visual_prompt]: Epoch 58 / 100: avg data time: 4.89e+00, avg batch time: 6.3379, average train loss: 0.4873
[11/18 14:02:23 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5852, average loss: 0.6319
[11/18 14:02:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 73.83	
[11/18 14:02:23 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.04477357683661734
[11/18 14:09:49 visual_prompt]: Epoch 59 / 100: avg data time: 4.91e+00, avg batch time: 6.3642, average train loss: 0.4520
[11/18 14:10:39 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5860, average loss: 0.6102
[11/18 14:10:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 76.37	
[11/18 14:10:39 visual_prompt]: Training 60 / 100 epoch, with learning rate 0.04304134495199674
[11/18 14:18:14 visual_prompt]: Epoch 60 / 100: avg data time: 5.04e+00, avg batch time: 6.4953, average train loss: 0.4187
[11/18 14:19:08 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5896, average loss: 0.6204
[11/18 14:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 75.50	
[11/18 14:19:08 visual_prompt]: Training 61 / 100 epoch, with learning rate 0.041317591116653486
[11/18 14:26:54 visual_prompt]: Epoch 61 / 100: avg data time: 5.19e+00, avg batch time: 6.6584, average train loss: 0.4173
[11/18 14:27:45 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5904, average loss: 0.7421
[11/18 14:27:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 68.29	rocauc: 74.18	
[11/18 14:27:45 visual_prompt]: Training 62 / 100 epoch, with learning rate 0.039604415459112044
[11/18 14:35:09 visual_prompt]: Epoch 62 / 100: avg data time: 4.89e+00, avg batch time: 6.3412, average train loss: 0.4491
[11/18 14:36:02 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5842, average loss: 0.6413
[11/18 14:36:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 75.07	
[11/18 14:36:02 visual_prompt]: Training 63 / 100 epoch, with learning rate 0.037903905220016625
[11/18 14:43:50 visual_prompt]: Epoch 63 / 100: avg data time: 5.24e+00, avg batch time: 6.6959, average train loss: 0.3861
[11/18 14:44:42 visual_prompt]: Inference (val):avg data time: 2.89e-05, avg batch time: 0.5880, average loss: 0.6985
[11/18 14:44:42 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.11	rocauc: 77.37	
[11/18 14:44:42 visual_prompt]: Stopping early.
[11/18 14:44:42 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 14:44:42 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 14:44:42 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 14:44:42 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 14:44:42 visual_prompt]: Training with config:
[11/18 14:44:42 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 14:44:42 visual_prompt]: Loading training data...
[11/18 14:44:42 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 14:44:42 visual_prompt]: Loading validation data...
[11/18 14:44:42 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 14:44:42 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/18 14:44:47 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/18 14:44:47 visual_prompt]: tuned percent:0.532
[11/18 14:44:47 visual_prompt]: Device used for model: 0
[11/18 14:44:47 visual_prompt]: Setting up Evaluator...
[11/18 14:44:47 visual_prompt]: Setting up Trainer...
[11/18 14:44:47 visual_prompt]: 	Setting up the optimizer...
[11/18 14:44:47 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 14:52:33 visual_prompt]: Epoch 1 / 100: avg data time: 5.21e+00, avg batch time: 6.6662, average train loss: 1.4863
[11/18 14:53:27 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5877, average loss: 1.4553
[11/18 14:53:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/18 14:53:27 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/18 15:01:08 visual_prompt]: Epoch 2 / 100: avg data time: 5.13e+00, avg batch time: 6.5799, average train loss: 0.9493
[11/18 15:02:01 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5841, average loss: 0.6880
[11/18 15:02:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[11/18 15:02:01 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/18 15:09:43 visual_prompt]: Epoch 3 / 100: avg data time: 5.14e+00, avg batch time: 6.5888, average train loss: 0.7082
[11/18 15:10:34 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5904, average loss: 0.7340
[11/18 15:10:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/18 15:10:34 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/18 15:18:12 visual_prompt]: Epoch 4 / 100: avg data time: 5.07e+00, avg batch time: 6.5278, average train loss: 0.7307
[11/18 15:19:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5919, average loss: 0.7090
[11/18 15:19:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.16	
[11/18 15:19:05 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/18 15:26:49 visual_prompt]: Epoch 5 / 100: avg data time: 5.17e+00, avg batch time: 6.6201, average train loss: 0.7252
[11/18 15:27:40 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5834, average loss: 0.6838
[11/18 15:27:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.11	
[11/18 15:27:40 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/18 15:35:19 visual_prompt]: Epoch 6 / 100: avg data time: 5.11e+00, avg batch time: 6.5601, average train loss: 0.7344
[11/18 15:36:12 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5850, average loss: 0.7577
[11/18 15:36:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.33	
[11/18 15:36:12 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/18 15:43:59 visual_prompt]: Epoch 7 / 100: avg data time: 5.21e+00, avg batch time: 6.6580, average train loss: 0.7242
[11/18 15:44:52 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5845, average loss: 0.8504
[11/18 15:44:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.99	
[11/18 15:44:52 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/18 15:52:30 visual_prompt]: Epoch 8 / 100: avg data time: 5.10e+00, avg batch time: 6.5485, average train loss: 0.7499
[11/18 15:53:24 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5900, average loss: 0.6996
[11/18 15:53:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.74	
[11/18 15:53:24 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/18 16:01:09 visual_prompt]: Epoch 9 / 100: avg data time: 5.19e+00, avg batch time: 6.6453, average train loss: 0.7138
[11/18 16:02:00 visual_prompt]: Inference (val):avg data time: 2.85e-05, avg batch time: 0.5845, average loss: 0.7163
[11/18 16:02:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.63	
[11/18 16:02:00 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/18 16:09:45 visual_prompt]: Epoch 10 / 100: avg data time: 5.19e+00, avg batch time: 6.6361, average train loss: 0.6878
[11/18 16:10:38 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5865, average loss: 0.6738
[11/18 16:10:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 63.82	
[11/18 16:10:38 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/18 16:18:15 visual_prompt]: Epoch 11 / 100: avg data time: 5.06e+00, avg batch time: 6.5178, average train loss: 0.6977
[11/18 16:19:08 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5856, average loss: 0.7571
[11/18 16:19:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.04	
[11/18 16:19:08 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/18 16:26:53 visual_prompt]: Epoch 12 / 100: avg data time: 5.19e+00, avg batch time: 6.6408, average train loss: 0.6979
[11/18 16:27:44 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5838, average loss: 0.7149
[11/18 16:27:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 48.37	rocauc: 65.36	
[11/18 16:27:44 visual_prompt]: Best epoch 12: best metric: -0.715
[11/18 16:27:44 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/18 16:35:08 visual_prompt]: Epoch 13 / 100: avg data time: 4.89e+00, avg batch time: 6.3425, average train loss: 0.7183
[11/18 16:35:59 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5822, average loss: 0.6856
[11/18 16:35:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 63.96	
[11/18 16:35:59 visual_prompt]: Best epoch 13: best metric: -0.686
[11/18 16:35:59 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/18 16:43:26 visual_prompt]: Epoch 14 / 100: avg data time: 4.91e+00, avg batch time: 6.3745, average train loss: 0.7036
[11/18 16:44:17 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5893, average loss: 0.6629
[11/18 16:44:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 66.57	
[11/18 16:44:17 visual_prompt]: Best epoch 14: best metric: -0.663
[11/18 16:44:17 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/18 16:51:48 visual_prompt]: Epoch 15 / 100: avg data time: 4.98e+00, avg batch time: 6.4328, average train loss: 0.6662
[11/18 16:52:39 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5866, average loss: 0.6723
[11/18 16:52:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.41	
[11/18 16:52:39 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/18 17:00:23 visual_prompt]: Epoch 16 / 100: avg data time: 5.18e+00, avg batch time: 6.6269, average train loss: 0.6771
[11/18 17:01:16 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5854, average loss: 0.8632
[11/18 17:01:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.55	
[11/18 17:01:16 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/18 17:08:59 visual_prompt]: Epoch 17 / 100: avg data time: 5.16e+00, avg batch time: 6.6117, average train loss: 0.6680
[11/18 17:09:52 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5833, average loss: 0.7518
[11/18 17:09:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.51	
[11/18 17:09:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/18 17:17:34 visual_prompt]: Epoch 18 / 100: avg data time: 5.15e+00, avg batch time: 6.5999, average train loss: 0.6712
[11/18 17:18:27 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5850, average loss: 1.0761
[11/18 17:18:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.45	
[11/18 17:18:27 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/18 17:26:09 visual_prompt]: Epoch 19 / 100: avg data time: 5.15e+00, avg batch time: 6.5974, average train loss: 0.6538
[11/18 17:27:02 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5890, average loss: 0.7831
[11/18 17:27:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 65.54	
[11/18 17:27:02 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/18 17:34:46 visual_prompt]: Epoch 20 / 100: avg data time: 5.18e+00, avg batch time: 6.6289, average train loss: 0.6353
[11/18 17:35:39 visual_prompt]: Inference (val):avg data time: 2.99e-05, avg batch time: 0.5900, average loss: 0.6844
[11/18 17:35:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.62	
[11/18 17:35:39 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/18 17:43:23 visual_prompt]: Epoch 21 / 100: avg data time: 5.17e+00, avg batch time: 6.6225, average train loss: 0.6583
[11/18 17:44:16 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5872, average loss: 0.6848
[11/18 17:44:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 68.09	
[11/18 17:44:16 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/18 17:51:59 visual_prompt]: Epoch 22 / 100: avg data time: 5.17e+00, avg batch time: 6.6187, average train loss: 0.6308
[11/18 17:52:52 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5881, average loss: 0.6568
[11/18 17:52:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.63	
[11/18 17:52:52 visual_prompt]: Best epoch 22: best metric: -0.657
[11/18 17:52:52 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/18 18:00:37 visual_prompt]: Epoch 23 / 100: avg data time: 5.19e+00, avg batch time: 6.6359, average train loss: 0.6247
[11/18 18:01:30 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5874, average loss: 0.6477
[11/18 18:01:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.17	
[11/18 18:01:30 visual_prompt]: Best epoch 23: best metric: -0.648
[11/18 18:01:30 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/18 18:09:13 visual_prompt]: Epoch 24 / 100: avg data time: 5.17e+00, avg batch time: 6.6228, average train loss: 0.6228
[11/18 18:10:06 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5870, average loss: 0.6699
[11/18 18:10:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 65.81	
[11/18 18:10:06 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/18 18:17:52 visual_prompt]: Epoch 25 / 100: avg data time: 5.19e+00, avg batch time: 6.6423, average train loss: 0.6063
[11/18 18:18:45 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5802, average loss: 0.6647
[11/18 18:18:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.21	
[11/18 18:18:45 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/18 18:26:16 visual_prompt]: Epoch 26 / 100: avg data time: 5.00e+00, avg batch time: 6.4506, average train loss: 0.6318
[11/18 18:27:08 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5868, average loss: 0.6728
[11/18 18:27:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.67	
[11/18 18:27:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/18 18:34:48 visual_prompt]: Epoch 27 / 100: avg data time: 5.12e+00, avg batch time: 6.5694, average train loss: 0.6058
[11/18 18:35:41 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5887, average loss: 0.6466
[11/18 18:35:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.45	
[11/18 18:35:41 visual_prompt]: Best epoch 27: best metric: -0.647
[11/18 18:35:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/18 18:43:27 visual_prompt]: Epoch 28 / 100: avg data time: 5.20e+00, avg batch time: 6.6532, average train loss: 0.6088
[11/18 18:44:20 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5814, average loss: 0.7036
[11/18 18:44:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.76	
[11/18 18:44:20 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/18 18:52:05 visual_prompt]: Epoch 29 / 100: avg data time: 5.19e+00, avg batch time: 6.6412, average train loss: 0.5846
[11/18 18:52:58 visual_prompt]: Inference (val):avg data time: 3.27e-05, avg batch time: 0.5886, average loss: 0.7227
[11/18 18:52:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.44	
[11/18 18:52:58 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/18 19:00:45 visual_prompt]: Epoch 30 / 100: avg data time: 5.22e+00, avg batch time: 6.6777, average train loss: 0.6079
[11/18 19:01:39 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5812, average loss: 0.7836
[11/18 19:01:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 70.22	
[11/18 19:01:39 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/18 19:09:27 visual_prompt]: Epoch 31 / 100: avg data time: 5.24e+00, avg batch time: 6.6815, average train loss: 0.6060
[11/18 19:10:20 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5842, average loss: 0.7220
[11/18 19:10:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.14	
[11/18 19:10:20 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/18 19:18:10 visual_prompt]: Epoch 32 / 100: avg data time: 5.26e+00, avg batch time: 6.7007, average train loss: 0.5640
[11/18 19:19:03 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5813, average loss: 0.6857
[11/18 19:19:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 66.42	
[11/18 19:19:03 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/18 19:26:51 visual_prompt]: Epoch 33 / 100: avg data time: 5.25e+00, avg batch time: 6.6872, average train loss: 0.5462
[11/18 19:27:45 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5791, average loss: 0.7013
[11/18 19:27:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 64.37	
[11/18 19:27:45 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/18 19:35:33 visual_prompt]: Epoch 34 / 100: avg data time: 5.24e+00, avg batch time: 6.6770, average train loss: 0.5520
[11/18 19:36:26 visual_prompt]: Inference (val):avg data time: 3.90e-05, avg batch time: 0.5801, average loss: 0.7849
[11/18 19:36:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 65.99	
[11/18 19:36:26 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/18 19:44:14 visual_prompt]: Epoch 35 / 100: avg data time: 5.24e+00, avg batch time: 6.6781, average train loss: 0.5556
[11/18 19:45:07 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5850, average loss: 0.6753
[11/18 19:45:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 67.29	
[11/18 19:45:07 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/18 19:52:54 visual_prompt]: Epoch 36 / 100: avg data time: 5.23e+00, avg batch time: 6.6752, average train loss: 0.5255
[11/18 19:53:46 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5841, average loss: 0.6607
[11/18 19:53:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.71	
[11/18 19:53:46 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/18 20:01:22 visual_prompt]: Epoch 37 / 100: avg data time: 5.06e+00, avg batch time: 6.5004, average train loss: 0.5362
[11/18 20:02:13 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5854, average loss: 0.6948
[11/18 20:02:14 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.23	
[11/18 20:02:14 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/18 20:10:01 visual_prompt]: Epoch 38 / 100: avg data time: 5.24e+00, avg batch time: 6.6776, average train loss: 0.4919
[11/18 20:10:54 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5784, average loss: 0.7667
[11/18 20:10:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 64.60	
[11/18 20:10:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/18 20:18:43 visual_prompt]: Epoch 39 / 100: avg data time: 5.25e+00, avg batch time: 6.6936, average train loss: 0.5148
[11/18 20:19:37 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5820, average loss: 0.8777
[11/18 20:19:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.50	
[11/18 20:19:37 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/18 20:27:25 visual_prompt]: Epoch 40 / 100: avg data time: 5.24e+00, avg batch time: 6.6850, average train loss: 0.4917
[11/18 20:28:18 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5804, average loss: 0.7124
[11/18 20:28:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 65.92	
[11/18 20:28:18 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/18 20:36:07 visual_prompt]: Epoch 41 / 100: avg data time: 5.25e+00, avg batch time: 6.6870, average train loss: 0.4651
[11/18 20:37:00 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5821, average loss: 0.6851
[11/18 20:37:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.68	
[11/18 20:37:00 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/18 20:44:48 visual_prompt]: Epoch 42 / 100: avg data time: 5.24e+00, avg batch time: 6.6801, average train loss: 0.4644
[11/18 20:45:41 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5860, average loss: 0.7240
[11/18 20:45:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 66.14	
[11/18 20:45:41 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/18 20:53:31 visual_prompt]: Epoch 43 / 100: avg data time: 5.26e+00, avg batch time: 6.6989, average train loss: 0.4817
[11/18 20:54:24 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5816, average loss: 0.7124
[11/18 20:54:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.90	
[11/18 20:54:24 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/18 21:02:14 visual_prompt]: Epoch 44 / 100: avg data time: 5.26e+00, avg batch time: 6.7055, average train loss: 0.4750
[11/18 21:03:07 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5822, average loss: 0.7353
[11/18 21:03:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.23	
[11/18 21:03:07 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/18 21:10:55 visual_prompt]: Epoch 45 / 100: avg data time: 5.24e+00, avg batch time: 6.6867, average train loss: 0.4530
[11/18 21:11:49 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5785, average loss: 0.7804
[11/18 21:11:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 65.96	
[11/18 21:11:49 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/18 21:19:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.24e+00, avg batch time: 6.6864, average train loss: 0.4438
[11/18 21:20:30 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5833, average loss: 0.8097
[11/18 21:20:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 64.23	
[11/18 21:20:30 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/18 21:28:17 visual_prompt]: Epoch 47 / 100: avg data time: 5.22e+00, avg batch time: 6.6619, average train loss: 0.4422
[11/18 21:29:10 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5796, average loss: 0.7893
[11/18 21:29:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 64.52	
[11/18 21:29:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/18 21:36:59 visual_prompt]: Epoch 48 / 100: avg data time: 5.24e+00, avg batch time: 6.6893, average train loss: 0.3943
[11/18 21:37:53 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5840, average loss: 0.8071
[11/18 21:37:53 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 65.30	
[11/18 21:37:53 visual_prompt]: Stopping early.
[11/18 21:37:53 visual_prompt]: Rank of current process: 0. World size: 1
[11/18 21:37:53 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/18 21:37:53 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/18 21:37:53 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/18 21:37:53 visual_prompt]: Training with config:
[11/18 21:37:53 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.1_wd0.0/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.0, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.1, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/18 21:37:53 visual_prompt]: Loading training data...
[11/18 21:37:53 visual_prompt]: Constructing mammo-cbis dataset train...
[11/18 21:37:53 visual_prompt]: Loading validation data...
[11/18 21:37:53 visual_prompt]: Constructing mammo-cbis dataset val...
[11/18 21:37:53 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/18 21:37:59 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/18 21:37:59 visual_prompt]: tuned percent:0.532
[11/18 21:37:59 visual_prompt]: Device used for model: 0
[11/18 21:37:59 visual_prompt]: Setting up Evaluator...
[11/18 21:37:59 visual_prompt]: Setting up Trainer...
[11/18 21:37:59 visual_prompt]: 	Setting up the optimizer...
[11/18 21:37:59 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/18 21:45:49 visual_prompt]: Epoch 1 / 100: avg data time: 5.27e+00, avg batch time: 6.7092, average train loss: 1.4863
[11/18 21:46:43 visual_prompt]: Inference (val):avg data time: 3.36e-05, avg batch time: 0.5807, average loss: 1.4553
[11/18 21:46:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/18 21:46:43 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.010000000000000002
[11/18 21:54:32 visual_prompt]: Epoch 2 / 100: avg data time: 5.27e+00, avg batch time: 6.7087, average train loss: 0.9493
[11/18 21:55:26 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5838, average loss: 0.6880
[11/18 21:55:26 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 52.59	
[11/18 21:55:26 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.020000000000000004
[11/18 22:03:16 visual_prompt]: Epoch 3 / 100: avg data time: 5.28e+00, avg batch time: 6.7151, average train loss: 0.7082
[11/18 22:04:10 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5846, average loss: 0.7340
[11/18 22:04:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.09	
[11/18 22:04:10 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.03
[11/18 22:11:58 visual_prompt]: Epoch 4 / 100: avg data time: 5.25e+00, avg batch time: 6.6829, average train loss: 0.7307
[11/18 22:12:52 visual_prompt]: Inference (val):avg data time: 3.82e-05, avg batch time: 0.5801, average loss: 0.7090
[11/18 22:12:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.11	
[11/18 22:12:52 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.04000000000000001
[11/18 22:20:40 visual_prompt]: Epoch 5 / 100: avg data time: 5.25e+00, avg batch time: 6.6892, average train loss: 0.7252
[11/18 22:21:34 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5845, average loss: 0.6838
[11/18 22:21:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.10	
[11/18 22:21:34 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.05
[11/18 22:29:25 visual_prompt]: Epoch 6 / 100: avg data time: 5.28e+00, avg batch time: 6.7227, average train loss: 0.7346
[11/18 22:30:18 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5802, average loss: 0.7580
[11/18 22:30:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.48	
[11/18 22:30:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.06
[11/18 22:38:07 visual_prompt]: Epoch 7 / 100: avg data time: 5.25e+00, avg batch time: 6.6926, average train loss: 0.7241
[11/18 22:39:01 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5851, average loss: 0.8533
[11/18 22:39:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.05	
[11/18 22:39:01 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.06999999999999999
[11/18 22:46:45 visual_prompt]: Epoch 8 / 100: avg data time: 5.19e+00, avg batch time: 6.6340, average train loss: 0.7501
[11/18 22:47:39 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5801, average loss: 0.6991
[11/18 22:47:39 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.87	
[11/18 22:47:39 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.08000000000000002
[11/18 22:55:27 visual_prompt]: Epoch 9 / 100: avg data time: 5.25e+00, avg batch time: 6.6916, average train loss: 0.7138
[11/18 22:56:21 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5869, average loss: 0.7123
[11/18 22:56:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.66	
[11/18 22:56:21 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.09000000000000001
[11/18 23:04:10 visual_prompt]: Epoch 10 / 100: avg data time: 5.25e+00, avg batch time: 6.6911, average train loss: 0.6878
[11/18 23:05:03 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5812, average loss: 0.6762
[11/18 23:05:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.72	rocauc: 64.28	
[11/18 23:05:03 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.1
[11/18 23:12:52 visual_prompt]: Epoch 11 / 100: avg data time: 5.25e+00, avg batch time: 6.6968, average train loss: 0.6993
[11/18 23:13:46 visual_prompt]: Inference (val):avg data time: 3.20e-05, avg batch time: 0.5849, average loss: 0.7623
[11/18 23:13:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.42	
[11/18 23:13:46 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0999695413509548
[11/18 23:21:33 visual_prompt]: Epoch 12 / 100: avg data time: 5.23e+00, avg batch time: 6.6758, average train loss: 0.6965
[11/18 23:22:27 visual_prompt]: Inference (val):avg data time: 3.41e-05, avg batch time: 0.5858, average loss: 0.6973
[11/18 23:22:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 52.44	rocauc: 66.15	
[11/18 23:22:27 visual_prompt]: Best epoch 12: best metric: -0.697
[11/18 23:22:27 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.09987820251299122
[11/18 23:30:16 visual_prompt]: Epoch 13 / 100: avg data time: 5.26e+00, avg batch time: 6.6954, average train loss: 0.7136
[11/18 23:31:09 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5808, average loss: 0.6711
[11/18 23:31:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.13	rocauc: 66.31	
[11/18 23:31:09 visual_prompt]: Best epoch 13: best metric: -0.671
[11/18 23:31:09 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.09972609476841367
[11/18 23:38:57 visual_prompt]: Epoch 14 / 100: avg data time: 5.24e+00, avg batch time: 6.6803, average train loss: 0.7001
[11/18 23:39:50 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5867, average loss: 0.6705
[11/18 23:39:50 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 67.28	
[11/18 23:39:50 visual_prompt]: Best epoch 14: best metric: -0.671
[11/18 23:39:50 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.09951340343707853
[11/18 23:47:37 visual_prompt]: Epoch 15 / 100: avg data time: 5.23e+00, avg batch time: 6.6663, average train loss: 0.6658
[11/18 23:48:30 visual_prompt]: Inference (val):avg data time: 3.57e-05, avg batch time: 0.5866, average loss: 0.6716
[11/18 23:48:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.50	rocauc: 64.17	
[11/18 23:48:30 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.09924038765061041
[11/18 23:56:18 visual_prompt]: Epoch 16 / 100: avg data time: 5.23e+00, avg batch time: 6.6741, average train loss: 0.6782
[11/18 23:57:11 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5823, average loss: 0.8483
[11/18 23:57:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 66.90	
[11/18 23:57:11 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.09890738003669029
[11/19 00:04:58 visual_prompt]: Epoch 17 / 100: avg data time: 5.23e+00, avg batch time: 6.6734, average train loss: 0.6665
[11/19 00:05:52 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5795, average loss: 0.7558
[11/19 00:05:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 67.99	
[11/19 00:05:52 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.09851478631379983
[11/19 00:13:38 visual_prompt]: Epoch 18 / 100: avg data time: 5.22e+00, avg batch time: 6.6581, average train loss: 0.6763
[11/19 00:14:31 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5867, average loss: 1.0653
[11/19 00:14:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 66.73	
[11/19 00:14:31 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.09806308479691594
[11/19 00:22:18 visual_prompt]: Epoch 19 / 100: avg data time: 5.23e+00, avg batch time: 6.6686, average train loss: 0.6516
[11/19 00:23:12 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5841, average loss: 0.8032
[11/19 00:23:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 64.79	
[11/19 00:23:12 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.09755282581475769
[11/19 00:31:01 visual_prompt]: Epoch 20 / 100: avg data time: 5.26e+00, avg batch time: 6.6976, average train loss: 0.6418
[11/19 00:31:54 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5826, average loss: 0.7043
[11/19 00:31:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 67.41	
[11/19 00:31:54 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.09698463103929543
[11/19 00:39:44 visual_prompt]: Epoch 21 / 100: avg data time: 5.26e+00, avg batch time: 6.7024, average train loss: 0.6660
[11/19 00:40:37 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5808, average loss: 0.6824
[11/19 00:40:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 68.57	
[11/19 00:40:37 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.09635919272833937
[11/19 00:48:25 visual_prompt]: Epoch 22 / 100: avg data time: 5.24e+00, avg batch time: 6.6792, average train loss: 0.6309
[11/19 00:49:18 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5845, average loss: 0.6781
[11/19 00:49:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 58.94	rocauc: 67.91	
[11/19 00:49:18 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.09567727288213004
[11/19 00:57:07 visual_prompt]: Epoch 23 / 100: avg data time: 5.26e+00, avg batch time: 6.6962, average train loss: 0.6169
[11/19 00:58:01 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5817, average loss: 0.6407
[11/19 00:58:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.87	
[11/19 00:58:01 visual_prompt]: Best epoch 23: best metric: -0.641
[11/19 00:58:01 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.09493970231495835
[11/19 01:05:50 visual_prompt]: Epoch 24 / 100: avg data time: 5.26e+00, avg batch time: 6.6988, average train loss: 0.6264
[11/19 01:06:43 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5848, average loss: 0.6560
[11/19 01:06:43 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 67.63	
[11/19 01:06:43 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.09414737964294635
[11/19 01:14:33 visual_prompt]: Epoch 25 / 100: avg data time: 5.26e+00, avg batch time: 6.7048, average train loss: 0.6078
[11/19 01:15:27 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5792, average loss: 0.6657
[11/19 01:15:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 69.50	
[11/19 01:15:27 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.09330127018922195
[11/19 01:23:15 visual_prompt]: Epoch 26 / 100: avg data time: 5.24e+00, avg batch time: 6.6815, average train loss: 0.6258
[11/19 01:24:08 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5843, average loss: 0.6963
[11/19 01:24:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.07	
[11/19 01:24:08 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.0924024048078213
[11/19 01:31:49 visual_prompt]: Epoch 27 / 100: avg data time: 5.13e+00, avg batch time: 6.5766, average train loss: 0.6132
[11/19 01:32:41 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5824, average loss: 0.6699
[11/19 01:32:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 68.37	
[11/19 01:32:41 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.09145187862775209
[11/19 01:40:17 visual_prompt]: Epoch 28 / 100: avg data time: 5.07e+00, avg batch time: 6.5142, average train loss: 0.6172
[11/19 01:41:10 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5810, average loss: 0.6365
[11/19 01:41:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.74	
[11/19 01:41:10 visual_prompt]: Best epoch 28: best metric: -0.637
[11/19 01:41:10 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.09045084971874738
[11/19 01:48:58 visual_prompt]: Epoch 29 / 100: avg data time: 5.24e+00, avg batch time: 6.6814, average train loss: 0.5780
[11/19 01:49:51 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5813, average loss: 0.7155
[11/19 01:49:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.52	
[11/19 01:49:51 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.0894005376803361
[11/19 01:57:41 visual_prompt]: Epoch 30 / 100: avg data time: 5.27e+00, avg batch time: 6.7139, average train loss: 0.5834
[11/19 01:58:35 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5809, average loss: 0.8498
[11/19 01:58:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 69.05	
[11/19 01:58:35 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.0883022221559489
[11/19 02:06:23 visual_prompt]: Epoch 31 / 100: avg data time: 5.24e+00, avg batch time: 6.6844, average train loss: 0.5799
[11/19 02:07:17 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5864, average loss: 0.6682
[11/19 02:07:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.53	
[11/19 02:07:17 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.08715724127386971
[11/19 02:15:05 visual_prompt]: Epoch 32 / 100: avg data time: 5.25e+00, avg batch time: 6.6944, average train loss: 0.5594
[11/19 02:15:59 visual_prompt]: Inference (val):avg data time: 3.67e-05, avg batch time: 0.5856, average loss: 0.6407
[11/19 02:15:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 69.75	
[11/19 02:15:59 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.08596699001693256
[11/19 02:23:47 visual_prompt]: Epoch 33 / 100: avg data time: 5.24e+00, avg batch time: 6.6847, average train loss: 0.5476
[11/19 02:24:40 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5799, average loss: 0.6488
[11/19 02:24:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 67.11	
[11/19 02:24:40 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.08473291852294987
[11/19 02:32:28 visual_prompt]: Epoch 34 / 100: avg data time: 5.24e+00, avg batch time: 6.6821, average train loss: 0.5400
[11/19 02:33:22 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5848, average loss: 0.6222
[11/19 02:33:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.72	
[11/19 02:33:22 visual_prompt]: Best epoch 34: best metric: -0.622
[11/19 02:33:22 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.08345653031794292
[11/19 02:41:11 visual_prompt]: Epoch 35 / 100: avg data time: 5.25e+00, avg batch time: 6.6940, average train loss: 0.5361
[11/19 02:42:04 visual_prompt]: Inference (val):avg data time: 2.95e-05, avg batch time: 0.5847, average loss: 0.6581
[11/19 02:42:04 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 67.89	
[11/19 02:42:04 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.08213938048432697
[11/19 02:49:53 visual_prompt]: Epoch 36 / 100: avg data time: 5.26e+00, avg batch time: 6.6998, average train loss: 0.5185
[11/19 02:50:47 visual_prompt]: Inference (val):avg data time: 3.78e-05, avg batch time: 0.5815, average loss: 0.6436
[11/19 02:50:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 68.56	
[11/19 02:50:47 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.08078307376628291
[11/19 02:58:34 visual_prompt]: Epoch 37 / 100: avg data time: 5.24e+00, avg batch time: 6.6779, average train loss: 0.5165
[11/19 02:59:28 visual_prompt]: Inference (val):avg data time: 3.76e-05, avg batch time: 0.5843, average loss: 0.6916
[11/19 02:59:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 67.67	
[11/19 02:59:28 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.07938926261462366
[11/19 03:07:08 visual_prompt]: Epoch 38 / 100: avg data time: 5.13e+00, avg batch time: 6.5685, average train loss: 0.4875
[11/19 03:08:01 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5778, average loss: 0.7744
[11/19 03:08:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 68.36	
[11/19 03:08:01 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.07795964517353735
[11/19 03:15:42 visual_prompt]: Epoch 39 / 100: avg data time: 5.15e+00, avg batch time: 6.5899, average train loss: 0.5244
[11/19 03:16:36 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5830, average loss: 0.7858
[11/19 03:16:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 67.88	
[11/19 03:16:36 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.07649596321166025
[11/19 03:24:24 visual_prompt]: Epoch 40 / 100: avg data time: 5.25e+00, avg batch time: 6.6934, average train loss: 0.4886
[11/19 03:25:18 visual_prompt]: Inference (val):avg data time: 3.45e-05, avg batch time: 0.5799, average loss: 0.6871
[11/19 03:25:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 68.20	
[11/19 03:25:18 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.07500000000000001
[11/19 03:33:06 visual_prompt]: Epoch 41 / 100: avg data time: 5.24e+00, avg batch time: 6.6812, average train loss: 0.4619
[11/19 03:33:59 visual_prompt]: Inference (val):avg data time: 3.33e-05, avg batch time: 0.5807, average loss: 0.8473
[11/19 03:33:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 68.15	
[11/19 03:33:59 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.07347357813929455
[11/19 03:41:46 visual_prompt]: Epoch 42 / 100: avg data time: 5.23e+00, avg batch time: 6.6723, average train loss: 0.4683
[11/19 03:42:40 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5814, average loss: 0.6786
[11/19 03:42:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 68.96	
[11/19 03:42:40 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.07191855733945388
[11/19 03:50:28 visual_prompt]: Epoch 43 / 100: avg data time: 5.26e+00, avg batch time: 6.6940, average train loss: 0.4916
[11/19 03:51:22 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5785, average loss: 0.7111
[11/19 03:51:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 68.59	
[11/19 03:51:22 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.07033683215379002
[11/19 03:59:12 visual_prompt]: Epoch 44 / 100: avg data time: 5.28e+00, avg batch time: 6.7197, average train loss: 0.4377
[11/19 04:00:06 visual_prompt]: Inference (val):avg data time: 3.69e-05, avg batch time: 0.5810, average loss: 0.7217
[11/19 04:00:06 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.26	rocauc: 68.48	
[11/19 04:00:06 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0687303296707956
[11/19 04:07:55 visual_prompt]: Epoch 45 / 100: avg data time: 5.25e+00, avg batch time: 6.6921, average train loss: 0.4268
[11/19 04:08:48 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5854, average loss: 0.7279
[11/19 04:08:48 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 69.61	
[11/19 04:08:48 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.06710100716628345
[11/19 04:16:37 visual_prompt]: Epoch 46 / 100: avg data time: 5.25e+00, avg batch time: 6.6910, average train loss: 0.4284
[11/19 04:17:30 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5850, average loss: 0.7365
[11/19 04:17:30 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.32	
[11/19 04:17:30 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.06545084971874737
[11/19 04:25:20 visual_prompt]: Epoch 47 / 100: avg data time: 5.27e+00, avg batch time: 6.7046, average train loss: 0.4294
[11/19 04:26:13 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5859, average loss: 0.7785
[11/19 04:26:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 68.86	
[11/19 04:26:13 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.06378186779084996
[11/19 04:34:02 visual_prompt]: Epoch 48 / 100: avg data time: 5.25e+00, avg batch time: 6.6915, average train loss: 0.3932
[11/19 04:34:55 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5847, average loss: 0.7197
[11/19 04:34:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 68.17	
[11/19 04:34:55 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.06209609477998338
[11/19 04:42:28 visual_prompt]: Epoch 49 / 100: avg data time: 5.03e+00, avg batch time: 6.4729, average train loss: 0.3624
[11/19 04:43:20 visual_prompt]: Inference (val):avg data time: 3.48e-05, avg batch time: 0.5789, average loss: 0.7938
[11/19 04:43:20 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 65.25	
[11/19 04:43:20 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.06039558454088796
[11/19 04:50:53 visual_prompt]: Epoch 50 / 100: avg data time: 5.03e+00, avg batch time: 6.4702, average train loss: 0.4148
[11/19 04:51:45 visual_prompt]: Inference (val):avg data time: 3.53e-05, avg batch time: 0.5832, average loss: 0.9198
[11/19 04:51:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 65.42	
[11/19 04:51:45 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.058682408883346526
[11/19 04:59:18 visual_prompt]: Epoch 51 / 100: avg data time: 5.03e+00, avg batch time: 6.4699, average train loss: 0.3522
[11/19 05:00:10 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5842, average loss: 0.8160
[11/19 05:00:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.76	
[11/19 05:00:10 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.05695865504800327
[11/19 05:07:43 visual_prompt]: Epoch 52 / 100: avg data time: 5.04e+00, avg batch time: 6.4767, average train loss: 0.3208
[11/19 05:08:35 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5817, average loss: 1.2260
[11/19 05:08:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.07	rocauc: 64.60	
[11/19 05:08:35 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.05522642316338268
[11/19 05:16:10 visual_prompt]: Epoch 53 / 100: avg data time: 5.05e+00, avg batch time: 6.4966, average train loss: 0.3864
[11/19 05:17:02 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5780, average loss: 0.9157
[11/19 05:17:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 63.23	
[11/19 05:17:02 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.05348782368720626
[11/19 05:24:35 visual_prompt]: Epoch 54 / 100: avg data time: 5.04e+00, avg batch time: 6.4781, average train loss: 0.3588
[11/19 05:25:27 visual_prompt]: Inference (val):avg data time: 3.43e-05, avg batch time: 0.5850, average loss: 0.7953
[11/19 05:25:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 66.52	
[11/19 05:25:27 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.05174497483512506
[11/19 05:33:00 visual_prompt]: Epoch 55 / 100: avg data time: 5.02e+00, avg batch time: 6.4588, average train loss: 0.3227
[11/19 05:33:51 visual_prompt]: Inference (val):avg data time: 3.46e-05, avg batch time: 0.5817, average loss: 0.8700
[11/19 05:33:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 66.93	
[11/19 05:33:51 visual_prompt]: Stopping early.
[11/19 05:33:51 visual_prompt]: Rank of current process: 0. World size: 1
[11/19 05:33:51 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/19 05:33:51 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/19 05:33:51 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/19 05:33:51 visual_prompt]: Training with config:
[11/19 05:33:51 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.01/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.01, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/19 05:33:51 visual_prompt]: Loading training data...
[11/19 05:33:51 visual_prompt]: Constructing mammo-cbis dataset train...
[11/19 05:33:51 visual_prompt]: Loading validation data...
[11/19 05:33:51 visual_prompt]: Constructing mammo-cbis dataset val...
[11/19 05:33:51 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/19 05:33:54 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/19 05:33:54 visual_prompt]: tuned percent:0.532
[11/19 05:33:54 visual_prompt]: Device used for model: 0
[11/19 05:33:54 visual_prompt]: Setting up Evaluator...
[11/19 05:33:54 visual_prompt]: Setting up Trainer...
[11/19 05:33:54 visual_prompt]: 	Setting up the optimizer...
[11/19 05:33:54 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/19 05:41:27 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4696, average train loss: 1.4863
[11/19 05:42:19 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5808, average loss: 1.4553
[11/19 05:42:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/19 05:42:19 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/19 05:49:52 visual_prompt]: Epoch 2 / 100: avg data time: 5.02e+00, avg batch time: 6.4617, average train loss: 0.8422
[11/19 05:50:44 visual_prompt]: Inference (val):avg data time: 2.96e-05, avg batch time: 0.5801, average loss: 0.6853
[11/19 05:50:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.22	
[11/19 05:50:44 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/19 05:58:17 visual_prompt]: Epoch 3 / 100: avg data time: 5.04e+00, avg batch time: 6.4752, average train loss: 0.7065
[11/19 05:59:09 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5834, average loss: 0.7517
[11/19 05:59:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.97	
[11/19 05:59:09 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/19 06:06:40 visual_prompt]: Epoch 4 / 100: avg data time: 5.01e+00, avg batch time: 6.4486, average train loss: 0.7180
[11/19 06:07:32 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5858, average loss: 0.7093
[11/19 06:07:32 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.05	
[11/19 06:07:32 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/19 06:15:04 visual_prompt]: Epoch 5 / 100: avg data time: 5.01e+00, avg batch time: 6.4512, average train loss: 0.7251
[11/19 06:15:56 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5835, average loss: 0.6796
[11/19 06:15:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 62.36	
[11/19 06:15:56 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/19 06:23:29 visual_prompt]: Epoch 6 / 100: avg data time: 5.03e+00, avg batch time: 6.4777, average train loss: 0.7305
[11/19 06:24:21 visual_prompt]: Inference (val):avg data time: 3.04e-05, avg batch time: 0.5817, average loss: 0.7493
[11/19 06:24:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.37	
[11/19 06:24:21 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/19 06:31:53 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4524, average train loss: 0.7018
[11/19 06:32:45 visual_prompt]: Inference (val):avg data time: 3.28e-05, avg batch time: 0.5833, average loss: 0.8585
[11/19 06:32:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.09	
[11/19 06:32:45 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/19 06:40:18 visual_prompt]: Epoch 8 / 100: avg data time: 5.03e+00, avg batch time: 6.4691, average train loss: 0.7259
[11/19 06:41:10 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5850, average loss: 0.6974
[11/19 06:41:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.00	
[11/19 06:41:10 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/19 06:48:41 visual_prompt]: Epoch 9 / 100: avg data time: 5.01e+00, avg batch time: 6.4467, average train loss: 0.6999
[11/19 06:49:33 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5810, average loss: 0.7333
[11/19 06:49:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.43	
[11/19 06:49:33 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/19 06:57:04 visual_prompt]: Epoch 10 / 100: avg data time: 5.01e+00, avg batch time: 6.4476, average train loss: 0.6850
[11/19 06:57:56 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5837, average loss: 0.6883
[11/19 06:57:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.24	
[11/19 06:57:56 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/19 07:05:29 visual_prompt]: Epoch 11 / 100: avg data time: 5.03e+00, avg batch time: 6.4683, average train loss: 0.7027
[11/19 07:06:21 visual_prompt]: Inference (val):avg data time: 3.40e-05, avg batch time: 0.5813, average loss: 0.6872
[11/19 07:06:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 61.04	
[11/19 07:06:21 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/19 07:13:53 visual_prompt]: Epoch 12 / 100: avg data time: 5.02e+00, avg batch time: 6.4572, average train loss: 0.6914
[11/19 07:14:45 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5839, average loss: 0.7007
[11/19 07:14:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.53	rocauc: 60.32	
[11/19 07:14:45 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/19 07:22:18 visual_prompt]: Epoch 13 / 100: avg data time: 5.03e+00, avg batch time: 6.4740, average train loss: 0.7069
[11/19 07:23:10 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5821, average loss: 0.6902
[11/19 07:23:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.51	
[11/19 07:23:10 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/19 07:30:42 visual_prompt]: Epoch 14 / 100: avg data time: 5.02e+00, avg batch time: 6.4647, average train loss: 0.6959
[11/19 07:31:34 visual_prompt]: Inference (val):avg data time: 3.31e-05, avg batch time: 0.5848, average loss: 0.7292
[11/19 07:31:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.10	
[11/19 07:31:34 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/19 07:39:06 visual_prompt]: Epoch 15 / 100: avg data time: 5.01e+00, avg batch time: 6.4532, average train loss: 0.6943
[11/19 07:39:58 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5808, average loss: 0.6879
[11/19 07:39:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.16	
[11/19 07:39:58 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/19 07:47:29 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e+00, avg batch time: 6.4490, average train loss: 0.6996
[11/19 07:48:21 visual_prompt]: Inference (val):avg data time: 2.93e-05, avg batch time: 0.5849, average loss: 0.7077
[11/19 07:48:21 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.62	
[11/19 07:48:21 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/19 07:55:54 visual_prompt]: Epoch 17 / 100: avg data time: 5.03e+00, avg batch time: 6.4666, average train loss: 0.6983
[11/19 07:56:45 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5848, average loss: 0.7014
[11/19 07:56:45 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 59.40	
[11/19 07:56:45 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/19 08:04:17 visual_prompt]: Epoch 18 / 100: avg data time: 5.01e+00, avg batch time: 6.4524, average train loss: 0.6996
[11/19 08:05:09 visual_prompt]: Inference (val):avg data time: 3.29e-05, avg batch time: 0.5799, average loss: 0.7535
[11/19 08:05:09 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.60	
[11/19 08:05:09 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/19 08:12:41 visual_prompt]: Epoch 19 / 100: avg data time: 5.01e+00, avg batch time: 6.4538, average train loss: 0.7045
[11/19 08:13:33 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5818, average loss: 0.7193
[11/19 08:13:33 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 60.47	
[11/19 08:13:33 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/19 08:21:06 visual_prompt]: Epoch 20 / 100: avg data time: 5.04e+00, avg batch time: 6.4715, average train loss: 0.6974
[11/19 08:21:58 visual_prompt]: Inference (val):avg data time: 3.08e-05, avg batch time: 0.5849, average loss: 0.6886
[11/19 08:21:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.41	
[11/19 08:21:58 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/19 08:29:30 visual_prompt]: Epoch 21 / 100: avg data time: 5.02e+00, avg batch time: 6.4642, average train loss: 0.6972
[11/19 08:30:22 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5841, average loss: 0.6912
[11/19 08:30:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.55	
[11/19 08:30:22 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/19 08:37:55 visual_prompt]: Epoch 22 / 100: avg data time: 5.03e+00, avg batch time: 6.4652, average train loss: 0.6963
[11/19 08:38:47 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5821, average loss: 0.6882
[11/19 08:38:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[11/19 08:38:47 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/19 08:46:20 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e+00, avg batch time: 6.4792, average train loss: 0.6904
[11/19 08:47:12 visual_prompt]: Inference (val):avg data time: 3.21e-05, avg batch time: 0.5830, average loss: 0.6909
[11/19 08:47:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.12	
[11/19 08:47:12 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/19 08:54:44 visual_prompt]: Epoch 24 / 100: avg data time: 5.01e+00, avg batch time: 6.4491, average train loss: 0.6938
[11/19 08:55:35 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5872, average loss: 0.6930
[11/19 08:55:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 57.48	
[11/19 08:55:35 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/19 09:03:09 visual_prompt]: Epoch 25 / 100: avg data time: 5.03e+00, avg batch time: 6.4733, average train loss: 0.6929
[11/19 09:04:00 visual_prompt]: Inference (val):avg data time: 3.60e-05, avg batch time: 0.5799, average loss: 0.6916
[11/19 09:04:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 54.80	
[11/19 09:04:00 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/19 09:11:32 visual_prompt]: Epoch 26 / 100: avg data time: 5.01e+00, avg batch time: 6.4525, average train loss: 0.6934
[11/19 09:12:24 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5790, average loss: 0.6946
[11/19 09:12:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 55.71	
[11/19 09:12:24 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/19 09:19:55 visual_prompt]: Epoch 27 / 100: avg data time: 5.00e+00, avg batch time: 6.4378, average train loss: 0.6919
[11/19 09:20:47 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5809, average loss: 0.6883
[11/19 09:20:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.06	
[11/19 09:20:47 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/19 09:28:19 visual_prompt]: Epoch 28 / 100: avg data time: 5.02e+00, avg batch time: 6.4624, average train loss: 0.6916
[11/19 09:29:11 visual_prompt]: Inference (val):avg data time: 2.92e-05, avg batch time: 0.5901, average loss: 0.6925
[11/19 09:29:11 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 56.88	
[11/19 09:29:11 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/19 09:36:43 visual_prompt]: Epoch 29 / 100: avg data time: 5.02e+00, avg batch time: 6.4611, average train loss: 0.6919
[11/19 09:37:35 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5801, average loss: 0.6876
[11/19 09:37:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 59.89	
[11/19 09:37:35 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/19 09:45:09 visual_prompt]: Epoch 30 / 100: avg data time: 5.04e+00, avg batch time: 6.4795, average train loss: 0.6927
[11/19 09:46:01 visual_prompt]: Inference (val):avg data time: 3.23e-05, avg batch time: 0.5784, average loss: 0.6901
[11/19 09:46:01 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.84	
[11/19 09:46:01 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/19 09:53:32 visual_prompt]: Epoch 31 / 100: avg data time: 5.01e+00, avg batch time: 6.4433, average train loss: 0.6951
[11/19 09:54:24 visual_prompt]: Inference (val):avg data time: 3.13e-05, avg batch time: 0.5833, average loss: 0.6891
[11/19 09:54:24 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 57.08	
[11/19 09:54:24 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/19 10:01:55 visual_prompt]: Epoch 32 / 100: avg data time: 5.01e+00, avg batch time: 6.4508, average train loss: 0.6991
[11/19 10:02:47 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5834, average loss: 0.6945
[11/19 10:02:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 57.13	
[11/19 10:02:47 visual_prompt]: Stopping early.
[11/19 10:02:47 visual_prompt]: Rank of current process: 0. World size: 1
[11/19 10:02:47 visual_prompt]: Environment info:
-------------------  -------------------------------------------------
Python               3.11.5 (main, Sep 11 2023, 13:54:46) [GCC 11.2.0]
ENV_MODULE           <not set>
PyTorch              2.0.1+cu118
PyTorch Debug Build  False
CUDA available       True
CUDA ID              2
GPU 0                NVIDIA A40
Pillow               9.3.0
cv2                  4.8.0
-------------------  -------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[11/19 10:02:47 visual_prompt]: Command line arguments: Namespace(config_file='visual_prompt_tuning/configs/prompt/cub.yaml', train_type='prompt', opts=['MODEL.TYPE', 'vit', 'DATA.BATCH_SIZE', '32', 'MODEL.PROMPT.NUM_TOKENS', '50', 'MODEL.PROMPT.DEEP', 'True', 'MODEL.PROMPT.DROPOUT', '0.1', 'DATA.FEATURE', 'sup_vitb16_imagenet21k', 'DATA.IMGSIZE', '500', 'DATA.NAME', 'mammo-cbis', 'DATA.NUMBER_CLASSES', '2', 'DATA.CROP', 'False', 'MODEL.MODEL_ROOT', 'visual_prompt_tuning/model_root', 'DATA.DATAPATH', 'visual_prompt_tuning/data_path', 'OUTPUT_DIR', 'visual_prompt_tuning/output_dir', 'SOLVER.PATIENCE', '21', 'SOLVER.CRITERION', 'loss'])
[11/19 10:02:47 visual_prompt]: Contents of args.config_file=visual_prompt_tuning/configs/prompt/cub.yaml:
_BASE_: "../base-prompt.yaml"
RUN_N_TIMES: 1
DATA:
  NAME: "CUB"
  DATAPATH: ""  #TODO: need to specify here
  NUMBER_CLASSES: 200
  MULTILABEL: False
MODEL:
  TYPE: "vit"
SOLVER:
  BASE_LR: 0.1
  WEIGHT_DECAY: 0.01
[11/19 10:02:47 visual_prompt]: Training with config:
[11/19 10:02:47 visual_prompt]: CfgNode({'DBG': False, 'OUTPUT_DIR': 'visual_prompt_tuning/output_dir/mammo-cbis/sup_vitb16_imagenet21k/prompt50/size500/val/seed0/lr0.05_wd0.001/patience21/run1', 'RUN_N_TIMES': 1, 'CUDNN_BENCHMARK': False, 'NUM_GPUS': 1, 'NUM_SHARDS': 1, 'SEED': 0, 'MODEL': CfgNode({'TRANSFER_TYPE': 'prompt', 'WEIGHT_PATH': '', 'SAVE_CKPT': False, 'MODEL_ROOT': 'visual_prompt_tuning/model_root', 'TYPE': 'vit', 'MLP_NUM': 0, 'LINEAR': CfgNode({'MLP_SIZES': [], 'DROPOUT': 0.1}), 'PROMPT': CfgNode({'NUM_TOKENS': 50, 'LOCATION': 'prepend', 'INITIATION': 'random', 'CLSEMB_FOLDER': '', 'CLSEMB_PATH': '', 'PROJECT': -1, 'DEEP': True, 'NUM_DEEP_LAYERS': None, 'REVERSE_DEEP': False, 'DEEP_SHARED': False, 'FORWARD_DEEP_NOEXPAND': False, 'VIT_POOL_TYPE': 'original', 'DROPOUT': 0.1, 'SAVE_FOR_EACH_EPOCH': False}), 'ADAPTER': CfgNode({'REDUCATION_FACTOR': 8, 'STYLE': 'Pfeiffer'})}), 'SOLVER': CfgNode({'LOSS': 'softmax', 'LOSS_ALPHA': 0.01, 'OPTIMIZER': 'sgd', 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 0.001, 'WEIGHT_DECAY_BIAS': 0, 'PATIENCE': 21, 'CRITERION': 'loss', 'SCHEDULER': 'cosine', 'BASE_LR': 0.05, 'BIAS_MULTIPLIER': 1.0, 'WARMUP_EPOCH': 10, 'TOTAL_EPOCH': 100, 'LOG_EVERY_N': 100, 'DBG_TRAINABLE': False}), 'DATA': CfgNode({'NAME': 'mammo-cbis', 'DATAPATH': 'visual_prompt_tuning/data_path', 'FEATURE': 'sup_vitb16_imagenet21k', 'PERCENTAGE': 1.0, 'NUMBER_CLASSES': 2, 'MULTILABEL': False, 'CLASS_WEIGHTS_TYPE': 'none', 'IMGSIZE': 500, 'CROP': False, 'NO_TEST': False, 'BATCH_SIZE': 32, 'NUM_WORKERS': 4, 'PIN_MEMORY': True})})
[11/19 10:02:47 visual_prompt]: Loading training data...
[11/19 10:02:47 visual_prompt]: Constructing mammo-cbis dataset train...
[11/19 10:02:47 visual_prompt]: Loading validation data...
[11/19 10:02:47 visual_prompt]: Constructing mammo-cbis dataset val...
[11/19 10:02:47 visual_prompt]: Constructing models...
[INFO: vit.py:  342]: load_pretrained: resized variant: torch.Size([1, 197, 768]) to torch.Size([1, 962, 768])
load_pretrained: grid-size from 14 to 31
[11/19 10:02:51 visual_prompt]: Total Parameters: 86848514	 Gradient Parameters: 462338
[11/19 10:02:51 visual_prompt]: tuned percent:0.532
[11/19 10:02:51 visual_prompt]: Device used for model: 0
[11/19 10:02:51 visual_prompt]: Setting up Evaluator...
[11/19 10:02:51 visual_prompt]: Setting up Trainer...
[11/19 10:02:51 visual_prompt]: 	Setting up the optimizer...
[11/19 10:02:51 visual_prompt]: Training 1 / 100 epoch, with learning rate 0.0
[11/19 10:10:24 visual_prompt]: Epoch 1 / 100: avg data time: 5.03e+00, avg batch time: 6.4712, average train loss: 1.4863
[11/19 10:11:16 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5849, average loss: 1.4553
[11/19 10:11:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 43.60	
[11/19 10:11:16 visual_prompt]: Training 2 / 100 epoch, with learning rate 0.005000000000000001
[11/19 10:18:49 visual_prompt]: Epoch 2 / 100: avg data time: 5.03e+00, avg batch time: 6.4713, average train loss: 0.8431
[11/19 10:19:40 visual_prompt]: Inference (val):avg data time: 2.84e-05, avg batch time: 0.5811, average loss: 0.6853
[11/19 10:19:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 53.14	
[11/19 10:19:40 visual_prompt]: Training 3 / 100 epoch, with learning rate 0.010000000000000002
[11/19 10:27:13 visual_prompt]: Epoch 3 / 100: avg data time: 5.02e+00, avg batch time: 6.4620, average train loss: 0.7076
[11/19 10:28:05 visual_prompt]: Inference (val):avg data time: 2.90e-05, avg batch time: 0.5796, average loss: 0.7529
[11/19 10:28:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 45.12	rocauc: 58.85	
[11/19 10:28:05 visual_prompt]: Training 4 / 100 epoch, with learning rate 0.015
[11/19 10:35:37 visual_prompt]: Epoch 4 / 100: avg data time: 5.01e+00, avg batch time: 6.4512, average train loss: 0.7220
[11/19 10:36:28 visual_prompt]: Inference (val):avg data time: 3.10e-05, avg batch time: 0.5818, average loss: 0.7055
[11/19 10:36:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 58.66	
[11/19 10:36:28 visual_prompt]: Training 5 / 100 epoch, with learning rate 0.020000000000000004
[11/19 10:44:00 visual_prompt]: Epoch 5 / 100: avg data time: 5.01e+00, avg batch time: 6.4529, average train loss: 0.7266
[11/19 10:44:52 visual_prompt]: Inference (val):avg data time: 3.34e-05, avg batch time: 0.5825, average loss: 0.6776
[11/19 10:44:52 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.10	rocauc: 61.00	
[11/19 10:44:52 visual_prompt]: Training 6 / 100 epoch, with learning rate 0.025
[11/19 10:52:26 visual_prompt]: Epoch 6 / 100: avg data time: 5.04e+00, avg batch time: 6.4810, average train loss: 0.7288
[11/19 10:53:18 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5804, average loss: 0.7306
[11/19 10:53:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 62.49	
[11/19 10:53:18 visual_prompt]: Training 7 / 100 epoch, with learning rate 0.03
[11/19 11:00:50 visual_prompt]: Epoch 7 / 100: avg data time: 5.01e+00, avg batch time: 6.4513, average train loss: 0.6904
[11/19 11:01:41 visual_prompt]: Inference (val):avg data time: 3.79e-05, avg batch time: 0.5865, average loss: 1.0579
[11/19 11:01:41 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 63.54	
[11/19 11:01:41 visual_prompt]: Training 8 / 100 epoch, with learning rate 0.034999999999999996
[11/19 11:09:15 visual_prompt]: Epoch 8 / 100: avg data time: 5.03e+00, avg batch time: 6.4753, average train loss: 0.7330
[11/19 11:10:07 visual_prompt]: Inference (val):avg data time: 3.30e-05, avg batch time: 0.5812, average loss: 0.6750
[11/19 11:10:07 visual_prompt]: Classification results with val_mammo-cbis: top1: 56.91	rocauc: 62.60	
[11/19 11:10:07 visual_prompt]: Training 9 / 100 epoch, with learning rate 0.04000000000000001
[11/19 11:17:39 visual_prompt]: Epoch 9 / 100: avg data time: 5.02e+00, avg batch time: 6.4608, average train loss: 0.7118
[11/19 11:18:31 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5785, average loss: 0.6890
[11/19 11:18:31 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.69	rocauc: 64.22	
[11/19 11:18:31 visual_prompt]: Training 10 / 100 epoch, with learning rate 0.045000000000000005
[11/19 11:26:03 visual_prompt]: Epoch 10 / 100: avg data time: 5.02e+00, avg batch time: 6.4623, average train loss: 0.6765
[11/19 11:26:55 visual_prompt]: Inference (val):avg data time: 3.06e-05, avg batch time: 0.5828, average loss: 0.6570
[11/19 11:26:55 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 65.48	
[11/19 11:26:55 visual_prompt]: Training 11 / 100 epoch, with learning rate 0.05
[11/19 11:34:30 visual_prompt]: Epoch 11 / 100: avg data time: 5.05e+00, avg batch time: 6.4945, average train loss: 0.6915
[11/19 11:35:22 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5817, average loss: 0.7256
[11/19 11:35:22 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 65.81	
[11/19 11:35:22 visual_prompt]: Training 12 / 100 epoch, with learning rate 0.0499847706754774
[11/19 11:42:55 visual_prompt]: Epoch 12 / 100: avg data time: 5.03e+00, avg batch time: 6.4711, average train loss: 0.6836
[11/19 11:43:47 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5847, average loss: 0.7535
[11/19 11:43:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 49.59	rocauc: 65.73	
[11/19 11:43:47 visual_prompt]: Training 13 / 100 epoch, with learning rate 0.04993910125649561
[11/19 11:51:21 visual_prompt]: Epoch 13 / 100: avg data time: 5.04e+00, avg batch time: 6.4777, average train loss: 0.6943
[11/19 11:52:12 visual_prompt]: Inference (val):avg data time: 3.37e-05, avg batch time: 0.5812, average loss: 0.6464
[11/19 11:52:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.20	rocauc: 67.93	
[11/19 11:52:12 visual_prompt]: Best epoch 13: best metric: -0.646
[11/19 11:52:12 visual_prompt]: Training 14 / 100 epoch, with learning rate 0.049863047384206834
[11/19 11:59:46 visual_prompt]: Epoch 14 / 100: avg data time: 5.03e+00, avg batch time: 6.4741, average train loss: 0.6748
[11/19 12:00:38 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5859, average loss: 0.7117
[11/19 12:00:38 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 66.82	
[11/19 12:00:38 visual_prompt]: Training 15 / 100 epoch, with learning rate 0.04975670171853926
[11/19 12:08:10 visual_prompt]: Epoch 15 / 100: avg data time: 5.01e+00, avg batch time: 6.4541, average train loss: 0.6696
[11/19 12:09:02 visual_prompt]: Inference (val):avg data time: 3.61e-05, avg batch time: 0.5844, average loss: 0.6578
[11/19 12:09:02 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 66.53	
[11/19 12:09:02 visual_prompt]: Training 16 / 100 epoch, with learning rate 0.049620193825305206
[11/19 12:16:33 visual_prompt]: Epoch 16 / 100: avg data time: 5.01e+00, avg batch time: 6.4508, average train loss: 0.6590
[11/19 12:17:25 visual_prompt]: Inference (val):avg data time: 3.51e-05, avg batch time: 0.5839, average loss: 0.7779
[11/19 12:17:25 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.47	rocauc: 68.18	
[11/19 12:17:25 visual_prompt]: Training 17 / 100 epoch, with learning rate 0.049453690018345146
[11/19 12:24:58 visual_prompt]: Epoch 17 / 100: avg data time: 5.02e+00, avg batch time: 6.4640, average train loss: 0.6642
[11/19 12:25:49 visual_prompt]: Inference (val):avg data time: 3.50e-05, avg batch time: 0.5831, average loss: 0.6924
[11/19 12:25:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 57.32	rocauc: 69.02	
[11/19 12:25:49 visual_prompt]: Training 18 / 100 epoch, with learning rate 0.04925739315689991
[11/19 12:33:21 visual_prompt]: Epoch 18 / 100: avg data time: 5.01e+00, avg batch time: 6.4514, average train loss: 0.6564
[11/19 12:34:13 visual_prompt]: Inference (val):avg data time: 3.00e-05, avg batch time: 0.5842, average loss: 1.0889
[11/19 12:34:13 visual_prompt]: Classification results with val_mammo-cbis: top1: 54.88	rocauc: 68.52	
[11/19 12:34:13 visual_prompt]: Training 19 / 100 epoch, with learning rate 0.04903154239845797
[11/19 12:41:45 visual_prompt]: Epoch 19 / 100: avg data time: 5.02e+00, avg batch time: 6.4572, average train loss: 0.6626
[11/19 12:42:37 visual_prompt]: Inference (val):avg data time: 3.49e-05, avg batch time: 0.5805, average loss: 0.7817
[11/19 12:42:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 67.29	
[11/19 12:42:37 visual_prompt]: Training 20 / 100 epoch, with learning rate 0.048776412907378844
[11/19 12:50:11 visual_prompt]: Epoch 20 / 100: avg data time: 5.04e+00, avg batch time: 6.4855, average train loss: 0.6401
[11/19 12:51:03 visual_prompt]: Inference (val):avg data time: 3.42e-05, avg batch time: 0.5833, average loss: 0.7243
[11/19 12:51:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 55.28	rocauc: 68.44	
[11/19 12:51:03 visual_prompt]: Training 21 / 100 epoch, with learning rate 0.048492315519647715
[11/19 12:58:37 visual_prompt]: Epoch 21 / 100: avg data time: 5.04e+00, avg batch time: 6.4805, average train loss: 0.6559
[11/19 12:59:29 visual_prompt]: Inference (val):avg data time: 3.15e-05, avg batch time: 0.5815, average loss: 0.6843
[11/19 12:59:29 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.96	
[11/19 12:59:29 visual_prompt]: Training 22 / 100 epoch, with learning rate 0.048179596364169686
[11/19 13:07:02 visual_prompt]: Epoch 22 / 100: avg data time: 5.03e+00, avg batch time: 6.4744, average train loss: 0.6299
[11/19 13:07:54 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5854, average loss: 0.6498
[11/19 13:07:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 67.49	
[11/19 13:07:54 visual_prompt]: Training 23 / 100 epoch, with learning rate 0.04783863644106502
[11/19 13:15:28 visual_prompt]: Epoch 23 / 100: avg data time: 5.04e+00, avg batch time: 6.4761, average train loss: 0.6491
[11/19 13:16:19 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5834, average loss: 0.6622
[11/19 13:16:19 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 69.56	
[11/19 13:16:19 visual_prompt]: Training 24 / 100 epoch, with learning rate 0.047469851157479176
[11/19 13:23:52 visual_prompt]: Epoch 24 / 100: avg data time: 5.02e+00, avg batch time: 6.4628, average train loss: 0.6324
[11/19 13:24:44 visual_prompt]: Inference (val):avg data time: 3.56e-05, avg batch time: 0.5795, average loss: 0.6624
[11/19 13:24:44 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 66.60	
[11/19 13:24:44 visual_prompt]: Training 25 / 100 epoch, with learning rate 0.047073689821473176
[11/19 13:32:18 visual_prompt]: Epoch 25 / 100: avg data time: 5.04e+00, avg batch time: 6.4791, average train loss: 0.6289
[11/19 13:33:10 visual_prompt]: Inference (val):avg data time: 3.47e-05, avg batch time: 0.5805, average loss: 0.6822
[11/19 13:33:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 70.96	
[11/19 13:33:10 visual_prompt]: Training 26 / 100 epoch, with learning rate 0.046650635094610975
[11/19 13:40:43 visual_prompt]: Epoch 26 / 100: avg data time: 5.03e+00, avg batch time: 6.4724, average train loss: 0.6338
[11/19 13:41:35 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5845, average loss: 0.6584
[11/19 13:41:35 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 71.50	
[11/19 13:41:35 visual_prompt]: Training 27 / 100 epoch, with learning rate 0.04620120240391065
[11/19 13:49:06 visual_prompt]: Epoch 27 / 100: avg data time: 5.01e+00, avg batch time: 6.4517, average train loss: 0.6139
[11/19 13:49:58 visual_prompt]: Inference (val):avg data time: 3.39e-05, avg batch time: 0.5874, average loss: 0.6436
[11/19 13:49:58 visual_prompt]: Classification results with val_mammo-cbis: top1: 66.67	rocauc: 68.89	
[11/19 13:49:58 visual_prompt]: Best epoch 27: best metric: -0.644
[11/19 13:49:58 visual_prompt]: Training 28 / 100 epoch, with learning rate 0.04572593931387604
[11/19 13:57:31 visual_prompt]: Epoch 28 / 100: avg data time: 5.03e+00, avg batch time: 6.4699, average train loss: 0.6221
[11/19 13:58:23 visual_prompt]: Inference (val):avg data time: 3.25e-05, avg batch time: 0.5788, average loss: 0.6307
[11/19 13:58:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 71.14	rocauc: 71.24	
[11/19 13:58:23 visual_prompt]: Best epoch 28: best metric: -0.631
[11/19 13:58:23 visual_prompt]: Training 29 / 100 epoch, with learning rate 0.04522542485937369
[11/19 14:06:39 visual_prompt]: Epoch 29 / 100: avg data time: 5.64e+00, avg batch time: 7.0817, average train loss: 0.5977
[11/19 14:07:36 visual_prompt]: Inference (val):avg data time: 3.59e-05, avg batch time: 0.5956, average loss: 0.6694
[11/19 14:07:36 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.79	rocauc: 70.86	
[11/19 14:07:36 visual_prompt]: Training 30 / 100 epoch, with learning rate 0.04470026884016805
[11/19 14:14:59 visual_prompt]: Epoch 30 / 100: avg data time: 4.87e+00, avg batch time: 6.3214, average train loss: 0.6014
[11/19 14:15:47 visual_prompt]: Inference (val):avg data time: 2.71e-05, avg batch time: 0.5871, average loss: 0.8873
[11/19 14:15:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 51.22	rocauc: 69.76	
[11/19 14:15:47 visual_prompt]: Training 31 / 100 epoch, with learning rate 0.04415111107797445
[11/19 14:22:49 visual_prompt]: Epoch 31 / 100: avg data time: 4.57e+00, avg batch time: 6.0189, average train loss: 0.6307
[11/19 14:23:37 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5868, average loss: 0.6445
[11/19 14:23:37 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 69.04	
[11/19 14:23:37 visual_prompt]: Training 32 / 100 epoch, with learning rate 0.04357862063693486
[11/19 14:30:40 visual_prompt]: Epoch 32 / 100: avg data time: 4.58e+00, avg batch time: 6.0374, average train loss: 0.5969
[11/19 14:31:28 visual_prompt]: Inference (val):avg data time: 3.03e-05, avg batch time: 0.5996, average loss: 0.6285
[11/19 14:31:28 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.51	rocauc: 70.91	
[11/19 14:31:28 visual_prompt]: Best epoch 32: best metric: -0.628
[11/19 14:31:28 visual_prompt]: Training 33 / 100 epoch, with learning rate 0.04298349500846628
[11/19 14:38:34 visual_prompt]: Epoch 33 / 100: avg data time: 4.63e+00, avg batch time: 6.0851, average train loss: 0.5855
[11/19 14:39:23 visual_prompt]: Inference (val):avg data time: 2.94e-05, avg batch time: 0.5831, average loss: 0.6271
[11/19 14:39:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 71.76	
[11/19 14:39:23 visual_prompt]: Best epoch 33: best metric: -0.627
[11/19 14:39:23 visual_prompt]: Training 34 / 100 epoch, with learning rate 0.042366459261474934
[11/19 14:46:28 visual_prompt]: Epoch 34 / 100: avg data time: 4.62e+00, avg batch time: 6.0704, average train loss: 0.5756
[11/19 14:47:17 visual_prompt]: Inference (val):avg data time: 3.01e-05, avg batch time: 0.5834, average loss: 0.7462
[11/19 14:47:17 visual_prompt]: Classification results with val_mammo-cbis: top1: 53.66	rocauc: 68.40	
[11/19 14:47:17 visual_prompt]: Training 35 / 100 epoch, with learning rate 0.04172826515897146
[11/19 14:54:21 visual_prompt]: Epoch 35 / 100: avg data time: 4.62e+00, avg batch time: 6.0639, average train loss: 0.5896
[11/19 14:55:10 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5856, average loss: 0.7076
[11/19 14:55:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 61.38	rocauc: 70.34	
[11/19 14:55:10 visual_prompt]: Training 36 / 100 epoch, with learning rate 0.04106969024216348
[11/19 15:02:16 visual_prompt]: Epoch 36 / 100: avg data time: 4.65e+00, avg batch time: 6.0936, average train loss: 0.5709
[11/19 15:03:05 visual_prompt]: Inference (val):avg data time: 3.22e-05, avg batch time: 0.5858, average loss: 0.6264
[11/19 15:03:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.24	
[11/19 15:03:05 visual_prompt]: Best epoch 36: best metric: -0.626
[11/19 15:03:05 visual_prompt]: Training 37 / 100 epoch, with learning rate 0.040391536883141455
[11/19 15:10:10 visual_prompt]: Epoch 37 / 100: avg data time: 4.62e+00, avg batch time: 6.0697, average train loss: 0.5619
[11/19 15:10:59 visual_prompt]: Inference (val):avg data time: 3.02e-05, avg batch time: 0.5821, average loss: 0.6681
[11/19 15:10:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 71.46	
[11/19 15:10:59 visual_prompt]: Training 38 / 100 epoch, with learning rate 0.03969463130731183
[11/19 15:18:05 visual_prompt]: Epoch 38 / 100: avg data time: 4.64e+00, avg batch time: 6.0845, average train loss: 0.5672
[11/19 15:18:54 visual_prompt]: Inference (val):avg data time: 2.78e-05, avg batch time: 0.5869, average loss: 0.6902
[11/19 15:18:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.45	rocauc: 70.49	
[11/19 15:18:54 visual_prompt]: Training 39 / 100 epoch, with learning rate 0.03897982258676867
[11/19 15:25:59 visual_prompt]: Epoch 39 / 100: avg data time: 4.62e+00, avg batch time: 6.0676, average train loss: 0.5799
[11/19 15:26:47 visual_prompt]: Inference (val):avg data time: 3.19e-05, avg batch time: 0.5846, average loss: 0.6602
[11/19 15:26:47 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.98	rocauc: 70.56	
[11/19 15:26:47 visual_prompt]: Training 40 / 100 epoch, with learning rate 0.03824798160583012
[11/19 15:33:51 visual_prompt]: Epoch 40 / 100: avg data time: 4.61e+00, avg batch time: 6.0567, average train loss: 0.5735
[11/19 15:34:40 visual_prompt]: Inference (val):avg data time: 3.55e-05, avg batch time: 0.5870, average loss: 0.6906
[11/19 15:34:40 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 69.83	
[11/19 15:34:40 visual_prompt]: Training 41 / 100 epoch, with learning rate 0.037500000000000006
[11/19 15:41:46 visual_prompt]: Epoch 41 / 100: avg data time: 4.63e+00, avg batch time: 6.0758, average train loss: 0.5849
[11/19 15:42:34 visual_prompt]: Inference (val):avg data time: 2.86e-05, avg batch time: 0.5848, average loss: 0.7252
[11/19 15:42:34 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.56	
[11/19 15:42:34 visual_prompt]: Training 42 / 100 epoch, with learning rate 0.03673678906964727
[11/19 15:49:39 visual_prompt]: Epoch 42 / 100: avg data time: 4.61e+00, avg batch time: 6.0608, average train loss: 0.5599
[11/19 15:50:27 visual_prompt]: Inference (val):avg data time: 3.35e-05, avg batch time: 0.5854, average loss: 0.6449
[11/19 15:50:27 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 70.32	
[11/19 15:50:27 visual_prompt]: Training 43 / 100 epoch, with learning rate 0.03595927866972694
[11/19 15:57:34 visual_prompt]: Epoch 43 / 100: avg data time: 4.64e+00, avg batch time: 6.0909, average train loss: 0.5567
[11/19 15:58:23 visual_prompt]: Inference (val):avg data time: 3.04e-03, avg batch time: 0.5833, average loss: 0.6291
[11/19 15:58:23 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.48	rocauc: 71.34	
[11/19 15:58:23 visual_prompt]: Training 44 / 100 epoch, with learning rate 0.03516841607689501
[11/19 16:05:29 visual_prompt]: Epoch 44 / 100: avg data time: 4.65e+00, avg batch time: 6.0965, average train loss: 0.5366
[11/19 16:06:18 visual_prompt]: Inference (val):avg data time: 3.14e-05, avg batch time: 0.5860, average loss: 0.6660
[11/19 16:06:18 visual_prompt]: Classification results with val_mammo-cbis: top1: 67.89	rocauc: 70.39	
[11/19 16:06:18 visual_prompt]: Training 45 / 100 epoch, with learning rate 0.0343651648353978
[11/19 16:13:27 visual_prompt]: Epoch 45 / 100: avg data time: 4.67e+00, avg batch time: 6.1202, average train loss: 0.5454
[11/19 16:14:16 visual_prompt]: Inference (val):avg data time: 3.12e-05, avg batch time: 0.5816, average loss: 0.6666
[11/19 16:14:16 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.04	rocauc: 68.39	
[11/19 16:14:16 visual_prompt]: Training 46 / 100 epoch, with learning rate 0.033550503583141725
[11/19 16:21:23 visual_prompt]: Epoch 46 / 100: avg data time: 4.67e+00, avg batch time: 6.1095, average train loss: 0.5282
[11/19 16:22:12 visual_prompt]: Inference (val):avg data time: 3.17e-05, avg batch time: 0.5839, average loss: 0.7362
[11/19 16:22:12 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.35	rocauc: 69.04	
[11/19 16:22:12 visual_prompt]: Training 47 / 100 epoch, with learning rate 0.032725424859373686
[11/19 16:29:21 visual_prompt]: Epoch 47 / 100: avg data time: 4.67e+00, avg batch time: 6.1151, average train loss: 0.5651
[11/19 16:30:10 visual_prompt]: Inference (val):avg data time: 2.97e-05, avg batch time: 0.5797, average loss: 0.6073
[11/19 16:30:10 visual_prompt]: Classification results with val_mammo-cbis: top1: 69.92	rocauc: 72.34	
[11/19 16:30:10 visual_prompt]: Best epoch 47: best metric: -0.607
[11/19 16:30:10 visual_prompt]: Training 48 / 100 epoch, with learning rate 0.03189093389542498
[11/19 16:37:19 visual_prompt]: Epoch 48 / 100: avg data time: 4.68e+00, avg batch time: 6.1265, average train loss: 0.5237
[11/19 16:38:08 visual_prompt]: Inference (val):avg data time: 2.87e-05, avg batch time: 0.5814, average loss: 0.7246
[11/19 16:38:08 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.23	rocauc: 67.25	
[11/19 16:38:08 visual_prompt]: Training 49 / 100 epoch, with learning rate 0.03104804738999169
[11/19 16:45:16 visual_prompt]: Epoch 49 / 100: avg data time: 4.68e+00, avg batch time: 6.1254, average train loss: 0.5024
[11/19 16:46:05 visual_prompt]: Inference (val):avg data time: 3.24e-05, avg batch time: 0.5841, average loss: 0.6710
[11/19 16:46:05 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.57	rocauc: 67.08	
[11/19 16:46:05 visual_prompt]: Training 50 / 100 epoch, with learning rate 0.03019779227044398
[11/19 16:53:14 visual_prompt]: Epoch 50 / 100: avg data time: 4.68e+00, avg batch time: 6.1208, average train loss: 0.5634
[11/19 16:54:03 visual_prompt]: Inference (val):avg data time: 3.58e-05, avg batch time: 0.5873, average loss: 0.7786
[11/19 16:54:03 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.01	rocauc: 72.90	
[11/19 16:54:03 visual_prompt]: Training 51 / 100 epoch, with learning rate 0.029341204441673263
[11/19 17:01:11 visual_prompt]: Epoch 51 / 100: avg data time: 4.67e+00, avg batch time: 6.1112, average train loss: 0.5155
[11/19 17:02:00 visual_prompt]: Inference (val):avg data time: 3.32e-05, avg batch time: 0.5841, average loss: 0.8086
[11/19 17:02:00 visual_prompt]: Classification results with val_mammo-cbis: top1: 59.76	rocauc: 69.38	
[11/19 17:02:00 visual_prompt]: Training 52 / 100 epoch, with learning rate 0.028479327524001636
[11/19 17:09:10 visual_prompt]: Epoch 52 / 100: avg data time: 4.70e+00, avg batch time: 6.1401, average train loss: 0.4766
[11/19 17:09:59 visual_prompt]: Inference (val):avg data time: 3.81e-05, avg batch time: 0.5839, average loss: 0.8776
[11/19 17:09:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 60.16	rocauc: 70.20	
[11/19 17:09:59 visual_prompt]: Training 53 / 100 epoch, with learning rate 0.02761321158169134
[11/19 17:17:10 visual_prompt]: Epoch 53 / 100: avg data time: 4.71e+00, avg batch time: 6.1467, average train loss: 0.4970
[11/19 17:17:59 visual_prompt]: Inference (val):avg data time: 3.38e-05, avg batch time: 0.5851, average loss: 0.7031
[11/19 17:17:59 visual_prompt]: Classification results with val_mammo-cbis: top1: 65.85	rocauc: 71.29	
[11/19 17:17:59 visual_prompt]: Training 54 / 100 epoch, with learning rate 0.02674391184360313
[11/19 17:25:07 visual_prompt]: Epoch 54 / 100: avg data time: 4.68e+00, avg batch time: 6.1187, average train loss: 0.4744
[11/19 17:25:56 visual_prompt]: Inference (val):avg data time: 3.44e-05, avg batch time: 0.5829, average loss: 0.7263
[11/19 17:25:56 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.97	
[11/19 17:25:56 visual_prompt]: Training 55 / 100 epoch, with learning rate 0.02587248741756253
[11/19 17:33:05 visual_prompt]: Epoch 55 / 100: avg data time: 4.68e+00, avg batch time: 6.1202, average train loss: 0.4531
[11/19 17:33:54 visual_prompt]: Inference (val):avg data time: 2.80e-05, avg batch time: 0.5797, average loss: 1.4392
[11/19 17:33:54 visual_prompt]: Classification results with val_mammo-cbis: top1: 46.75	rocauc: 69.81	
[11/19 17:33:54 visual_prompt]: Training 56 / 100 epoch, with learning rate 0.025
[11/19 17:41:01 visual_prompt]: Epoch 56 / 100: avg data time: 4.67e+00, avg batch time: 6.1105, average train loss: 0.4702
[11/19 17:41:51 visual_prompt]: Inference (val):avg data time: 2.98e-05, avg batch time: 0.5852, average loss: 0.7472
[11/19 17:41:51 visual_prompt]: Classification results with val_mammo-cbis: top1: 63.82	rocauc: 68.98	
[11/19 17:41:51 visual_prompt]: Training 57 / 100 epoch, with learning rate 0.024127512582437484
[11/19 17:49:00 visual_prompt]: Epoch 57 / 100: avg data time: 4.69e+00, avg batch time: 6.1321, average train loss: 0.4749
[11/19 17:49:49 visual_prompt]: Inference (val):avg data time: 3.09e-05, avg batch time: 0.5797, average loss: 0.7562
[11/19 17:49:49 visual_prompt]: Classification results with val_mammo-cbis: top1: 64.63	rocauc: 71.51	
[11/19 17:49:49 visual_prompt]: Training 58 / 100 epoch, with learning rate 0.02325608815639687
[11/19 17:56:57 visual_prompt]: Epoch 58 / 100: avg data time: 4.67e+00, avg batch time: 6.1101, average train loss: 0.4300
[11/19 17:57:46 visual_prompt]: Inference (val):avg data time: 3.11e-05, avg batch time: 0.5873, average loss: 0.7666
[11/19 17:57:46 visual_prompt]: Classification results with val_mammo-cbis: top1: 62.60	rocauc: 67.75	
[11/19 17:57:46 visual_prompt]: Training 59 / 100 epoch, with learning rate 0.02238678841830867
